{
    "man_pages": [
        {
            "filename": "file_1.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_1.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_10.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_10.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_100.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_100.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_101.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_101.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_102.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_102.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_103.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_103.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_104.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_104.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_105.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_105.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_106.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_106.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_107.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_107.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_108.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_108.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_109.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_109.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_11.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_11.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_110.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_110.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_111.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_111.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_112.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_112.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_113.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_113.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_114.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_114.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_115.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_115.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_116.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_116.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_117.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_117.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_118.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_118.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_119.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_119.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_12.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_12.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_120.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_120.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_121.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_121.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_122.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_122.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_123.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_123.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_124.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_124.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_125.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_125.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_126.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_126.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_127.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_127.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_128.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_128.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_129.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_129.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_13.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_13.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_130.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_130.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_131.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_131.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_132.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_132.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_133.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_133.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_134.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_134.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_135.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_135.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_136.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_136.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_137.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_137.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_138.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_138.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_139.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_139.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_14.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_14.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_140.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_140.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_141.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_141.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_142.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_142.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_143.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_143.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_144.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_144.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_145.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_145.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_146.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_146.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_147.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_147.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_148.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_148.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_149.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_149.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_15.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_15.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_150.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_150.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_151.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_151.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_152.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_152.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_153.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_153.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_154.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_154.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_155.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_155.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_156.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_156.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_157.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_157.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_158.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_158.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_159.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_159.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_16.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_16.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_160.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_160.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_161.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_161.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_162.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_162.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_163.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_163.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_164.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_164.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_165.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_165.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_166.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_166.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_167.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_167.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_168.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_168.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_169.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_169.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_17.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_17.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_170.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_170.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_171.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_171.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_172.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_172.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_173.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_173.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_174.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_174.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_175.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_175.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_176.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_176.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_177.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_177.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_178.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_178.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_179.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_179.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_18.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_18.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_180.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_180.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_181.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_181.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_182.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_182.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_183.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_183.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_184.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_184.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_185.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_185.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_186.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_186.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_187.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_187.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_188.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_188.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_189.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_189.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_19.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_19.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_190.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_190.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_191.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_191.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_192.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_192.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_193.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_193.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_194.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_194.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_195.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_195.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_196.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_196.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_197.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_197.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_198.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_198.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_199.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_199.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_20.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_20.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_200.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_200.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_201.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_201.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_202.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_202.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_203.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_203.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_204.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_204.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_205.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_205.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_206.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_206.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_207.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_207.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_208.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_208.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_209.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_209.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_21.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_21.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_210.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_210.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_211.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_211.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_212.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_212.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_213.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_213.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_214.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_214.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_215.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_215.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_216.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_216.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_217.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_217.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_218.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_218.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_219.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_219.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_22.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_22.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_220.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_220.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_221.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_221.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_222.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_222.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_223.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_223.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_224.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_224.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_225.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_225.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_226.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_226.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_227.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_227.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_228.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_228.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_229.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_229.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_23.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_23.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_230.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_230.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_231.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_231.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_232.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_232.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_233.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_233.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_234.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_234.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_235.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_235.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_236.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_236.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_237.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_237.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_238.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_238.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_239.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_239.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_24.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_24.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_240.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_240.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_241.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_241.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_242.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_242.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_243.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_243.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_244.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_244.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_245.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_245.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_246.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_246.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_247.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_247.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_248.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_248.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_249.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_249.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_25.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_25.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_250.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_250.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_251.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_251.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_252.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_252.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_253.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_253.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_254.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_254.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_255.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_255.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_256.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_256.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_257.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_257.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_258.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_258.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_259.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_259.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_26.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_26.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_260.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_260.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_261.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_261.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_262.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_262.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_263.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_263.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_264.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_264.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_265.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_265.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_266.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_266.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_267.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_267.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_268.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_268.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_269.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_269.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_27.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_27.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_270.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_270.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_271.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_271.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_272.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_272.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_273.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_273.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_274.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_274.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_275.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_275.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_276.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_276.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_277.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_277.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_278.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_278.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_279.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_279.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_28.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_28.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_280.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_280.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_281.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_281.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_282.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_282.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_283.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_283.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_284.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_284.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_285.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_285.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_286.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_286.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_287.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_287.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_288.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_288.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_289.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_289.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_29.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_29.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_290.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_290.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_291.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_291.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_292.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_292.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_293.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_293.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_294.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_294.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_295.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_295.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_296.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_296.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_297.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_297.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_298.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_298.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_299.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_299.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_3.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_3.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_30.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_30.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_300.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_300.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_301.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_301.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_302.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_302.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_303.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_303.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_304.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_304.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_305.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_305.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_306.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_306.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_307.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_307.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_308.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_308.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_309.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_309.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_31.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_31.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_310.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_310.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_311.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_311.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_312.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_312.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_313.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_313.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_314.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_314.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_315.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_315.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_316.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_316.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_317.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_317.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_318.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_318.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_319.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_319.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_32.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_32.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_320.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_320.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_321.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_321.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_322.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_322.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_323.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_323.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_324.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_324.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_325.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_325.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_326.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_326.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_327.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_327.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_328.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_328.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_329.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_329.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_33.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_33.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_330.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_330.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_331.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_331.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_332.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_332.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_333.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_333.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_334.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_334.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_335.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_335.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_336.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_336.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_337.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_337.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_338.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_338.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_339.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_339.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_34.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_34.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_340.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_340.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_341.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_341.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_342.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_342.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_343.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_343.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_344.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_344.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_345.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_345.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_346.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_346.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_347.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_347.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_348.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_348.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_349.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_349.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_35.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_35.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_350.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_350.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_351.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_351.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_352.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_352.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_353.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_353.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_354.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_354.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_355.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_355.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_356.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_356.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_357.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_357.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_358.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_358.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_359.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_359.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_36.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_36.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_360.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_360.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_361.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_361.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_362.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_362.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_363.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_363.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_364.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_364.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_365.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_365.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_366.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_366.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_367.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_367.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_368.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_368.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_369.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_369.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_37.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_37.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_370.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_370.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_371.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_371.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_372.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_372.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_373.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_373.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_374.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_374.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_375.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_375.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_376.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_376.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_377.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_377.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_378.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_378.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_379.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_379.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_38.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_38.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_380.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_380.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_381.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_381.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_382.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_382.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_383.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_383.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_384.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_384.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_385.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_385.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_386.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_386.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_387.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_387.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_388.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_388.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_389.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_389.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_39.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_39.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_390.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_390.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_391.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_391.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_392.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_392.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_393.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_393.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_394.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_394.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_395.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_395.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_396.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_396.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_397.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_397.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_398.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_398.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_399.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_399.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_4.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_4.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_40.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_40.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_400.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_400.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_401.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_401.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_402.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_402.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_403.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_403.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_404.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_404.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_405.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_405.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_406.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_406.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_407.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_407.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_408.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_408.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_409.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_409.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_41.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_41.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_410.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_410.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_411.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_411.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_412.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_412.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_413.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_413.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_414.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_414.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_415.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_415.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_416.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_416.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_417.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_417.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_418.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_418.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_419.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_419.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_42.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_42.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_420.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_420.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_421.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_421.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_422.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_422.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_423.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_423.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_424.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_424.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_425.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_425.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_426.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_426.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_427.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_427.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_428.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_428.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_429.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_429.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_43.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_43.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_430.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_430.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_431.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_431.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_432.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_432.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_433.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_433.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_434.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_434.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_435.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_435.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_436.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_436.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_437.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_437.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_438.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_438.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_439.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_439.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_44.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_44.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_440.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_440.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_441.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_441.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_442.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_442.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_443.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_443.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_444.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_444.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_445.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_445.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_446.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_446.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_447.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_447.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_448.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_448.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_449.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_449.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_45.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_45.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_450.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_450.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_451.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_451.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_452.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_452.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_453.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_453.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_454.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_454.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_455.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_455.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_456.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_456.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_457.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_457.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_458.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_458.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_459.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_459.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_46.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_46.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_460.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_460.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_461.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_461.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_462.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_462.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_463.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_463.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_464.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_464.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_465.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_465.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_466.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_466.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_467.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_467.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_468.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_468.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_469.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_469.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_47.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_47.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_470.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_470.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_471.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_471.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_472.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_472.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_473.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_473.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_474.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_474.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_475.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_475.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_476.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_476.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_477.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_477.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_478.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_478.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_479.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_479.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_48.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_48.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_480.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_480.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_481.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_481.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_482.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_482.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_483.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_483.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_484.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_484.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_485.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_485.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_486.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_486.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_487.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_487.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_488.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_488.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_489.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_489.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_49.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_49.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_490.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_490.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_491.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_491.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_492.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_492.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_493.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_493.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_494.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_494.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_495.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_495.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_496.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_496.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_497.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_497.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_498.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_498.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_499.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_499.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_5.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_5.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_50.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_50.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_500.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_500.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_501.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_501.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_502.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_502.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_503.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_503.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_504.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_504.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_505.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_505.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_506.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_506.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_507.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_507.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_508.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_508.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_509.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_509.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_51.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_51.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_510.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_510.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_511.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_511.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_512.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_512.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_513.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_513.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_514.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_514.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_515.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_515.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_516.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_516.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_517.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_517.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_518.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_518.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_519.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_519.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_52.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_52.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_520.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_520.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_521.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_521.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_522.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_522.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_523.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_523.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_524.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_524.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_525.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_525.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_526.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_526.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_527.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_527.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_528.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_528.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_529.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_529.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_53.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_53.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_530.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_530.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_531.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_531.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_532.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_532.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_533.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_533.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_534.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_534.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_535.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_535.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_536.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_536.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_537.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_537.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_538.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_538.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_539.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_539.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_54.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_54.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_540.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_540.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_541.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_541.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_542.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_542.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_543.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_543.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_544.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_544.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_545.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_545.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_546.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_546.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_547.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_547.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_548.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_548.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_549.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_549.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_55.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_55.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_550.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_550.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_551.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_551.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_552.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_552.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_553.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_553.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_554.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_554.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_555.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_555.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_556.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_556.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_557.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_557.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_558.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_558.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_559.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_559.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_56.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_56.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_560.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_560.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_561.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_561.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_562.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_562.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_563.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_563.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_564.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_564.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_565.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_565.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_566.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_566.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_567.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_567.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_568.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_568.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_569.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_569.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_57.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_57.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_570.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_570.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_571.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_571.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_572.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_572.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_573.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_573.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_574.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_574.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_575.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_575.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_576.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_576.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_577.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_577.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_578.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_578.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_579.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_579.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_58.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_58.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_580.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_580.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_581.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_581.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_582.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_582.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_583.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_583.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_584.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_584.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_585.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_585.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_586.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_586.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_587.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_587.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_59.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_59.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_6.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_6.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_60.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_60.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_61.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_61.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_62.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_62.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_63.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_63.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_64.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_64.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_65.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_65.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_66.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_66.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_67.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_67.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_68.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_68.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_69.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_69.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_7.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_7.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_70.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_70.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_71.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_71.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_72.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_72.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_73.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_73.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_74.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_74.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_75.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_75.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_76.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_76.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_77.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_77.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_78.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_78.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_79.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_79.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_8.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_8.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_80.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_80.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_81.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_81.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_82.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_82.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_83.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_83.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_84.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_84.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_85.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_85.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_86.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_86.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_87.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_87.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_88.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_88.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_89.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_89.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_9.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_9.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_90.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_90.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_91.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_91.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_92.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_92.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_93.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_93.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_94.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_94.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_95.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_95.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_96.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_96.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_97.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_97.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_98.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_98.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_99.txt",
            "path": "D:/LLLM Data/linux_data/man_pages\\file_99.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        }
    ],
    "syscalls": [
        {
            "filename": "file_1.txt",
            "path": "D:/LLLM Data/linux_data/syscalls\\file_1.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        },
        {
            "filename": "file_2.txt",
            "path": "D:/LLLM Data/linux_data/syscalls\\file_2.txt",
            "content": "This system has been minimized by removing packages and content that are not required on a system that users do not log into. To restore this content, including manpages, you can run the 'unminimize' command. You will still need to ensure the 'man-db' package is installed."
        }
    ],
    "github_shell_scripts": [
        {
            "filename": "file_1.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_1.sh",
            "content": "#!/bin/sh # inpath - verify that a specified program is either valid as-is, # or can be found in the PATH directory list. in_path() { # given a command and the PATH, try to find the command. Returns # 0 if found and executable, 1 if not. Note that this temporarily modifies # the the IFS (input field seperator), but restores it upon completion. cmd=$1 path=$2 retval=1 oldIFS=$IFS IFS=\":\" for directory in $path do if [ -x $directory/$cmd ] ; then retval=0 # if we're here, we found $cmd in $directory fi done IFS=$oldIFS return $retval } checkForCmdInPath() { var=$1 # The variable slicing notation in the following conditional # needs some explanation: ${var#expr} returns everything after # the match for 'expr' in the variable value (if any), and # ${var%expr} returns everything that doesn't match (in this # case just the very first character. You can also do this in # Bash with ${var:0:1} and you could use cut too: cut -c1 if [ \"$var\" != \"\" ] ; then if [ \"${var%${var#?}}\" = \"/\" ] ; then if [ ! -x $var ] ; then return 1 fi elif ! in_path $var $PATH ; then return 2 fi fi } if [ $# -ne 1 ] ; then echo \"Usage: $0 command\" >&2 ; exit 1 fi checkForCmdInPath \"$1\" case $? in 0 ) echo \"$1 found in PATH\" ;; 1 ) echo \"$1 not found or not executable\" ;; 2 ) echo \"$1 not found in PATH\" ;; esac exit 0"
        },
        {
            "filename": "file_10.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_10.sh",
            "content": "#!/bin/sh # filelock - a flexible file locking mechanism retries=\"10\" # default number of retries: 10 action=\"lock\" # default action nullcmd=\"/bin/true\" # null command for lockf while getopts \"lur:\" opt; do case $opt in l ) action=\"lock\" ;; u ) action=\"unlock\" ;; r ) retries=\"$OPTARG\" ;; esac done shift $(($OPTIND - 1)) if [ $# -eq 0 ] ; then cat << EOF >&2 Usage: $0 [-l|-u] [-r retries] lockfilename Where -l requests a lock (the default), -u requests an unlock, -r X specifies a maximum number of retries before it fails (default = $retries). EOF exit 1 fi # ascertain whether we have lockf or lockfile system apps if [ -z \"$(which lockfile | grep -v '^no ')\" ] ; then echo \"$0 failed: 'lockfile' utility not found in PATH.\" >&2 exit 1 fi if [ \"$action\" = \"lock\" ] ; then if ! lockfile -1 -r $retries \"$1\" 2> /dev/null; then echo \"$0: Failed: Couldn't create lockfile in time\" >&2 exit 1 fi else # action = unlock if [ ! -f \"$1\" ] ; then echo \"$0: Warning: lockfile $1 doesn't exist to unlock\" >&2 exit 1 fi rm -f \"$1\" fi exit 0"
        },
        {
            "filename": "file_100.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_100.sh",
            "content": "#!/bin/sh # watch and nice - watch for the specified process name, and renice # to the desired value when seen renicename=\"$HOME/bin/renicename\" if [ $# -ne 2 ] ; then echo \"Usage: $(basename $0) desirednice jobname\" >&2 exit 1 fi pid=\"$($renicename -p \"$2\")\" if [ ! -z \"$(echo $pid | sed 's/[0-9]*//g')\" ] ; then echo \"Failed to make a unique match in the process table for $2\" >&2 exit 1 fi currentnice=\"$(ps -lp $pid | tail -1 | awk '{print $6}')\" if [ $1 -gt $currentnice ] ; then echo \"Adjusting priority of $2 to $1\" renice $1 $pid fi exit 0"
        },
        {
            "filename": "file_101.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_101.sh",
            "content": "#!/bin/sh # addvirtual - add a virtual host to an Apache configuration file # you'll want to modify all of these to point to the proper directories docroot=\"/etc/httpd/html\" logroot=\"/var/log/httpd/\" httpconf=\"/etc/httpd/conf/httpd.conf\" # some sites use 'apachectl' rather than restart_apache: restart=\"/usr/local/bin/restart_apache\" showonly=0 tempout=\"/tmp/addvirtual.$$\"; trap \"rm -f $tempout $tempout.2\" 0 if [ \"$1\" = \"-n\" ] ; then showonly=1 ; shift fi if [ $# -ne 3 ] ; then echo \"Usage: $(basename $0) [-n] domain admin-email owner-id\" >&2 echo \" Where -n shows what it would do, but doesn't do anything\" >&2 exit 1 fi # check for common and probable errors if [ $(id -u) != \"root\" -a $showonly = 0 ] ; then echo \"Error: $(basename $0) can only be run as root.\" >&2 exit 1 fi if [ ! -z \"$(echo $1 | grep -E '^www\\.')\" ] ; then echo \"Please omit the www. prefix on the domain name\" >&2 exit 0 fi if [ \"$(echo $1 | sed 's/ //g')\" != \"$1\" ] ; then echo \"Error: Domain names cannot have spaces.\" >&2 exit 1 fi if [ -z \"$(grep -E \"^$3\" /etc/passwd)\" ] ; then echo \"Account $3 not found in password file\" >&2 exit 1 fi # build the directory structure and drop a few files therein if [ $showonly -eq 1 ] ; then tempout=\"/dev/tty\" # to output virtualhost to stdout echo \"mkdir $docroot/$1 $logroot/$1\" echo \"chown $3 $docroot/$1 $logroot/$1\" else if [ ! -d $docroot/$1 ] ; then if mkdir $docroot/$1 ; then echo \"Failed on mkdir $docroot/$1: exiting.\" >&2 ; exit 1 fi fi if [ ! -d $logroot/$1 ] ; then mkdir $logroot/$1 if [ $? -ne 0 -a $? -ne 17 ] ; then # error code 17 = directory already exists echo \"Failed on mkdir $docroot/$1: exiting.\" >&2 ; exit 1 fi fi chown $3 $docroot/$1 $logroot/$1 fi # now let's drop the necessary block into the httpd.conf file cat << EOF > $tempout ####### Virtual Host setup for $1 ########### <VirtualHost www.$1 $1> ServerName www.$1 ServerAdmin $2 DocumentRoot $docroot/$1 ErrorLog logs/$1/error_log TransferLog logs/$1/access_log </VirtualHost> <Directory $docroot/$1> Options Indexes FollowSymLinks Includes AllowOverride All order allow,deny allow from all </Directory> EOF if [ $showonly -eq 1 ]; then echo \"Tip: Copy the above block into $httpconf and\" echo \"restart the server with $restart and you're done.\" exit 0 fi # let's hack the httpd.conf file date=\"$(date +%m%d%H%m)\" # month day hour minute cp $httpconf $httpconf.$date # backup copy of config file # Figure out what line in the file has the last </VirtualHost> entry # Yes, this means that the script won't work if there are NO virtualhost # entries already in the httpd.conf file. If that's the case, just use # the -n flag and paste the material in manually... addafter=\"$(cat -n $httpconf|grep '</VirtualHost>'|awk 'NR==1 {print $1}')\" if [ -z \"$addafter\" ]; then echo \"Error: Can't find a </VirtualHost> line in $httpconf\" >&2 /bin/rm -f $httpconf.$date; exit 1 fi sed \"${addafter}r $tempout\" < $httpconf > $tempout.2 mv $tempout.2 $httpconf if $restart ; then mv $httpconf $httpconf.failed.$date mv $httpconf.$date $httpconf $restart echo \"Configuration appears to have failed; restarted with old conf file\" >&2 echo \"Failed configuration is in $httpconf.failed.$date\" >&2 exit 1 fi exit 0"
        },
        {
            "filename": "file_102.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_102.sh",
            "content": "#!/bin/sh # Simple script to list users in the Mac OS X NetInfo database # note that Mac OS X also has an /etc/passwd file, but that's # only used during the initial stages of boot time and for # recovery bootups. Otherwise, all data is in the NetInfo db. fields=\"\" while getopts \"Aahnprsu\" opt ; do case $opt in A ) fields=\"uid passwd name realname home shell\" ;; a ) fields=\"uid name realname home shell\" ;; h ) fields=\"$fields home\" ;; n ) fields=\"$fields name\" ;; p ) fields=\"$fields passwd\" ;; r ) fields=\"$fields realname\" ;; s ) fields=\"$fields shell\" ;; u ) fields=\"$fields uid\" ;; ? ) cat << EOF >&2 Usage: $0 [A|a|hnprsu] Where: -A output all known NetInfo user fields -a output only the interesting user fields -h show home directories of accounts -n show account names -p passwd (encrypted) -r show realname/fullname values -s show login shell -u uid EOF exit 1 esac done exec nireport . /users ${fields:=uid name realname home shell}"
        },
        {
            "filename": "file_103.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_103.sh",
            "content": "#!/bin/sh # ADDUSER - add a new user to the system, including building their # home directory, copying in default config data, etc. # You can choose to have every user in their own group (which requires # a few tweaks) or use the default behavior of having everyone put # into the same group. Tweak dgroup and dgid to match your own config. dgroup=\"guest\"; dgid=31 # default group and groupid hmdir=\"/Users\" shell=\"uninitialized\" if [ \"$(/usr/bin/whoami)\" != \"root\" ] ; then echo \"$(basename $0): You must be root to run this command.\" >&2 exit 1 fi echo \"Add new user account to $(hostname)\" echo -n \"login: \" ; read login if nireport . /users name | sed 's/[^[:alnum:]]//g' | grep \"^$login$\" ; then echo \"$0: You already have an account with name $login\" >&2 exit 1 fi uid1=\"$(nireport . /users uid | sort -n | tail -1)\" uid=\"$(( $uid1 + 1 ))\" homedir=$hmdir/$login echo -n \"full name: \" ; read fullname until [ -z \"$shell\" -o -x \"$shell\" ] ; do echo -n \"shell: \" ; read shell done echo \"Setting up account $login for $fullname...\" echo \"uid=$uid gid=$dgid shell=$shell home=$homedir\" niutil -create . /users/$login niutil -createprop . /users/$login passwd niutil -createprop . /users/$login uid $uid niutil -createprop . /users/$login gid $dgid niutil -createprop . /users/$login realname \"$fullname\" niutil -createprop . /users/$login shell $shell niutil -createprop . /users/$login home $homedir niutil -createprop . /users/$login _shadow_passwd \"\" # adding them to the $dgroup group niutil -appendprop . /groups/$dgroup users $login if ! mkdir -m 755 $homedir ; then echo \"$0: Failed making home directory $homedir\" >&2 echo \"(created account in NetInfo database, though. Continue by hand)\" >&2 exit 1 fi if [ -d /etc/skel ] ; then ditto /etc/skel/.[a-zA-Z]* $homedir else ditto \"/System/Library/User Template/English.lproj\" $homedir fi chown -R ${login}:$dgroup $homedir echo \"Please enter an initial password for $login:\" passwd $login echo \"Done. Account set up and ready to use.\" exit 0"
        },
        {
            "filename": "file_104.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_104.sh",
            "content": "#!/bin/sh # addalias - add a new alias to the email alias database on Mac OS X # this presumes that you've enabled sendmail, which can be kind of # tricky. Go to http://www.macdevcenter.com/ and search for 'sendmail' # for some good reference works. showaliases=\"nidump aliases .\" if [ \"$(/usr/bin/whoami)\" != \"root\" ] ; then echo \"$(basename $0): You must be root to run this command.\" >&2 exit 1 fi if [ $# -eq 0 ] ; then echo -n \"Alias to create: \" read alias else alias=$1 fi # now let's check to see if that alias already exists... if $showaliases | grep \"${alias}:\" >/dev/null 2>&1 ; then echo \"$0: mail alias $alias already exists\" >&2 exit 1 fi # looks good. let's get the RHS and inject it into NetInfo echo -n \"pointing to: \" read rhs niutil -create . /aliases/$alias niutil -createprop . /aliases/$alias name $alias niutil -createprop . /aliases/$alias members \"$rhs\" echo \"Alias $alias created without incident.\" exit 0"
        },
        {
            "filename": "file_105.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_105.sh",
            "content": "#! /bin/sh # titleterm - tell the Mac OS X Terminal application to change its name # to the value specified as an argument to this succinct script. # To use this to show your current working directory, for example: # alias precmd 'titleterm \"$PWD\"' [tcsh] # or # export PROMPT_COMMAND=\"titleterm \\\"\\$PWD\\\"\" [bash] if [ $# -eq 0 ]; then echo \"Usage: $0 title\" >&2 exit 1 else echo -ne \"\\033]0;$1\\007\" fi exit 0"
        },
        {
            "filename": "file_106.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_106.sh",
            "content": "#!/bin/sh # itunelist - list your iTunes library in a succinct and attractive # manner, suitable for sharing with others and using (with diff) # to ensure that you have synchronized iTune libraries on different # computers and laptops. itunehome=\"$HOME/Music/iTunes\" ituneconfig=\"$itunehome/iTunes Music Library.xml\" musiclib=\"/$(grep '>Music Folder<' \"$ituneconfig\" | cut -d/ -f5- | \\ cut -d\\< -f1 | sed 's/%20/ /g')\" echo Your music library is at $musiclib if [ ! -d \"$musiclib\" ] ; then echo \"$0: Confused: Music library $musiclib isn't a directory?\" >&2 exit 1 fi exec find \"$musiclib\" -type d -mindepth 2 -maxdepth 2 \\! -name '.*' -print | sed \"s|$musiclib/||\""
        },
        {
            "filename": "file_107.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_107.sh",
            "content": "#!/bin/sh # open2 - a smart wrapper for the cool Mac OS X 'open' command # to make it even more useful. By default, open launches the # appropriate application for a specified file or directory # based on the Aqua bindings, and has a limited ability to # launch applications if they're in the /Applications dir. # first off, whatever argument we're given, try it directly: open=/usr/bin/open if ! $open \"$@\" >/dev/null 2>&1 ; then if ! $open -a \"$@\" >/dev/null 2>&1 ; then # More than one arg? Don't know how to deal with it: quit if [ $# -gt 1 ] ; then echo \"open: Can't figure out how to open or launch $@\" >&2 exit 1 else case $(echo $1 | tr '[:upper:]' '[:lower:]') in acrobat ) app=\"Acrobat Reader\" ;; adress* ) app=\"Address Book\" ;; chat ) app=\"iChat\" ;; cpu ) app=\"CPU Monitor\" ;; dvd ) app=\"DVD Player\" ;; excel ) app=\"Microsoft Excel\" ;; netinfo ) app=\"NetInfo Manager\" ;; prefs ) app=\"System Preferences\" ;; print ) app=\"Print Center\" ;; profil* ) app=\"Apple System Profiler\" ;; qt|quicktime ) app=\"QuickTime Player\" ;; sync ) app=\"iSync\" ;; word ) app=\"Microsoft Word\" ;; * ) echo \"open: Don't know what to do with $1\" >&2 exit 1 esac echo \"You asked for $1 but I think you mean $app.\" >&2 $open -a \"$app\" fi fi fi exit 0"
        },
        {
            "filename": "file_108.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_108.sh",
            "content": "#!/bin/sh # unscramble - pick a word, scramble it, and ask the user to guess # what the original word (or phrase) was... wordlib=\"/usr/lib/games/long-words.txt\" randomquote=\"$HOME/bin/randomquote.sh\" scrambleword() { # pick a word randomly from the wordlib, and scramble it # Original word is 'match' and scrambled word is 'scrambled' match=\"$($randomquote $wordlib)\" echo \"Picked out a word!\" len=$(echo $match | wc -c | sed 's/[^[:digit:]]//g') scrambled=\"\"; lastval=1 for (( val=1; $val < $len ; )) do if [ $(perl -e \"print int rand(2)\") -eq 1 ] ; then scrambled=$scrambled$(echo $match | cut -c$val) else scrambled=$(echo $match | cut -c$val)$scrambled fi val=$(( $val + 1 )) done } if [ ! -r $wordlib ] ; then echo \"$0: Missing word library $wordlib\" >&2 echo \"(online at http://www.intuitive.com/wicked/examples/long-words.txt\" >&2 echo \"save the file as $wordlib and you're ready to play!)\" >&2 exit 1 fi newgame=\"\"; guesses=0; correct=0; total=0 until [ \"$guess\" = \"quit\" ] ; do scrambleword echo \"\" echo \"You need to unscramble: $scrambled\" guess=\"??\" ; guesses=0 total=$(( $total + 1 )) while [ \"$guess\" != \"$match\" -a \"$guess\" != \"quit\" -a \"$guess\" != \"next\" ] do echo \"\" echo -n \"Your guess (quit|next) : \" read guess if [ \"$guess\" = \"$match\" ] ; then guesses=$(( $guesses + 1 )) echo \"\" echo \"*** You got it with tries = ${guesses}! Well done!! ***\" echo \"\" correct=$(( $correct + 1 )) elif [ \"$guess\" = \"next\" -o \"$guess\" = \"quit\" ] ; then echo \"The unscrambled word was \\\"$match\\\". Your tries: $guesses\" else echo \"Nope. That's not the unscrambled word. Try again.\" guesses=$(( $guesses + 1 )) fi done done echo \"Done. You correctly figured out $correct out of $total scrambled words.\" exit 0"
        },
        {
            "filename": "file_109.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_109.sh",
            "content": "#!/bin/sh # hangman - a rudimentary version of the hangman game. Instead of showing a # gradually embodied hanging man, this simply has a bad guess countdown. # You can optionally indicate steps from the gallows as the only arg. wordlib=\"/usr/lib/games/long-words.txt\" randomquote=\"$HOME/bin/randomquote.sh\" empty=\"\\.\" # we need something for the sed [set] when $guessed=\"\" games=0 if [ ! -r $wordlib ] ; then echo \"$0: Missing word library $wordlib\" >&2 echo \"(online at http://www.intuitive.com/wicked/examples/long-words.txt\" >&2 echo \"save the file as $wordlib and you're ready to play!)\" >&2 exit 1 fi while [ \"$guess\" != \"quit\" ] ; do match=\"$($randomquote $wordlib)\" # pick a new word from the library if [ $games -gt 0 ] ; then echo \"\" echo \"*** New Game! ***\" fi games=\"$(( $games + 1 ))\" guessed=\"\" ; guess=\"\" ; bad=${1:-6} partial=\"$(echo $match | sed \"s/[^$empty${guessed}]/-/g\")\" while [ \"$guess\" != \"$match\" -a \"$guess\" != \"quit\" ] ; do echo \"\" if [ ! -z \"$guessed\" ] ; then echo -n \"guessed: $guessed, \" fi echo \"steps from gallows: $bad, word so far: $partial\" echo -n \"Guess a letter: \" read guess echo \"\" if [ \"$guess\" = \"$match\" ] ; then echo \"You got it!\" elif [ \"$guess\" = \"quit\" ] ; then sleep 0 # this is a 'no op' to avoid an error message on 'quit' elif [ $(echo $guess | wc -c | sed 's/[^[:digit:]]//g') -ne 2 ] ; then echo \"Uh oh: You can only guess a single letter at a time\" elif [ ! -z \"$(echo $guess | sed 's/[[:lower:]]//g')\" ] ; then echo \"Uh oh: Please only use lowercase letters for your guesses\" elif [ -z \"$(echo $guess | sed \"s/[$empty$guessed]//g\")\" ] ; then echo \"Uh oh: You have already tried $guess\" elif [ \"$(echo $match | sed \"s/$guess/-/g\")\" != \"$match\" ] ; then guessed=\"$guessed$guess\" partial=\"$(echo $match | sed \"s/[^$empty${guessed}]/-/g\")\" if [ \"$partial\" = \"$match\" ] ; then echo \"** You've been pardoned!! Well done! The word was \\\"$match\\\".\" guess=\"$match\" else echo \"* Great! The letter \\\"$guess\\\" appears in the word!\" fi elif [ $bad -eq 1 ] ; then echo \"** Uh oh: you've run out of steps. You're on the platform.. and <SNAP!>\" echo \"** The word you were trying to guess was \\\"$match\\\"\" guess=\"$match\" else echo \"* Nope, \\\"$guess\\\" does not appear in the word.\" guessed=\"$guessed$guess\" bad=$(( $bad - 1 )) fi done done exit 0"
        },
        {
            "filename": "file_11.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_11.sh",
            "content": "#!/bin/sh # ANSI Color -- use these variables to easily have different color # and format output. Make sure to output the reset sequence after # colors (f = foreground, b = background), and use the 'off' # feature for anything you turn on. initializeANSI() { esc=\"\u001b\" blackf=\"${esc}[30m\"; redf=\"${esc}[31m\"; greenf=\"${esc}[32m\" yellowf=\"${esc}[33m\" bluef=\"${esc}[34m\"; purplef=\"${esc}[35m\" cyanf=\"${esc}[36m\"; whitef=\"${esc}[37m\" blackb=\"${esc}[40m\"; redb=\"${esc}[41m\"; greenb=\"${esc}[42m\" yellowb=\"${esc}[43m\" blueb=\"${esc}[44m\"; purpleb=\"${esc}[45m\" cyanb=\"${esc}[46m\"; whiteb=\"${esc}[47m\" boldon=\"${esc}[1m\"; boldoff=\"${esc}[22m\" italicson=\"${esc}[3m\"; italicsoff=\"${esc}[23m\" ulon=\"${esc}[4m\"; uloff=\"${esc}[24m\" invon=\"${esc}[7m\"; invoff=\"${esc}[27m\" reset=\"${esc}[0m\" } # note in this first use that switching colors doesn't require a reset # first - the new color overrides the old one. initializeANSI cat << EOF ${yellowf}This is a phrase in yellow${redb} and red${reset} ${boldon}This is bold${ulon} this is italics${reset} bye bye ${italicson}This is italics${italicsoff} and this is not ${ulon}This is ul${uloff} and this is not ${invon}This is inv${invoff} and this is not ${yellowf}${redb}Warning I${yellowb}${redf}Warning II${reset} EOF"
        },
        {
            "filename": "file_110.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_110.sh",
            "content": "#!/bin/sh # states - a state capital guessing game. Requires the state capitals # datafile at http://www.intuitive.com/wicked/examples/state.capitals.txt db=\"/usr/lib/games/state.capitals.txt\" randomquote=\"$HOME/bin/randomquote.sh\" if [ ! -r $db ] ; then echo \"$0: Can't open $db for reading.\" >&2 echo \"(online at http://www.intuitive.com/wicked/examples/state.capitals.txt\" >&2 echo \"save the file as $db and you're ready to play!)\" >&2 exit 1 fi guesses=0; correct=0; total=0 while [ \"$guess\" != \"quit\" ] ; do thiskey=\"$($randomquote $db)\" state=\"$(echo $thiskey | cut -d\\ -f1 | sed 's/-/ /g')\" city=\"$(echo $thiskey | cut -d\\ -f2 | sed 's/-/ /g')\" match=\"$(echo $city | tr '[:upper:]' '[:lower:]')\" guess=\"??\" ; total=$(( $total + 1 )) ; echo \"\" echo \"What city is the capital of $state?\" while [ \"$guess\" != \"$match\" -a \"$guess\" != \"next\" -a \"$guess\" != \"quit\" ] do echo -n \"Answer: \" read guess if [ \"$guess\" = \"$match\" -o \"$guess\" = \"$city\" ] ; then echo \"\" echo \"*** Absolutely correct! Well done! ***\" correct=$(( $correct + 1 )) guess=$match elif [ \"$guess\" = \"next\" -o \"$guess\" = \"quit\" ] ; then echo \"\" echo \"$city is the capital of $state.\" else echo \"I'm afraid that's not correct.\" fi done done echo \"You got $correct out of $total presented.\" exit 0"
        },
        {
            "filename": "file_111.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_111.sh",
            "content": "#!/bin/sh # how many commands: a simple script to count how many executable commands # are in your current PATH. myPATH=\"$(echo $PATH | sed -e 's/ /~~/g' -e 's/:/ /g')\" count=0 ; nonex=0 for dirname in $myPATH ; do directory=\"$(echo $dirname | sed 's/~~/ /g')\" if [ -d \"$directory\" ] ; then for command in $(ls \"$directory\") ; do if [ -x \"$directory/$command\" ] ; then count=\"$(( $count + 1 ))\" else nonex=\"$(( $nonex + 1 ))\" fi done fi done echo \"$count commands, and $nonex entires that weren't marked executable\" exit 0"
        },
        {
            "filename": "file_112.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_112.sh",
            "content": "#!/bin/sh # specify palindrome possibility as args if [ $# -eq 0 ] ; then echo Usage: $0 possible palindrome >&2 exit 1 fi testit=\"$(echo $@ | sed 's/[^[:alpha:]]//g' | tr '[:upper:]' '[:lower:]')\" backwards=\"$(echo $testit | rev)\" if [ \"$testit\" = \"$backwards\" ] ; then echo \"$@ is a palindrome\" else echo \"$@ is not a palindrome\" fi exit 0"
        },
        {
            "filename": "file_113.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_113.sh",
            "content": "test=2"
        },
        {
            "filename": "file_12.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_12.sh",
            "content": "#!/bin/sh # Script to demonstrate use of the shell function library . 012-library.sh initializeANSI echon \"First off, do you have echo in your path? (1=yes, 2=no) \" read answer while ! validint $answer 1 2 ; do echon \"${boldon}Try again${boldoff}. Do you have echo \" echon \"in your path? (1=yes, 2=no) \" read answer done if ! checkForCmdInPath \"echo\" ; then echo \"Nope, can't find the echo command.\" else echo \"The echo command is in the PATH.\" fi echo \"\" echon \"Enter a year you think might be a leap year: \" read year while ! validint $year 1 9999 ; do echon \"Please enter a year in the ${boldon}correct${boldoff} format: \" read year done if isLeapYear $year ; then echo \"${greenf}You're right! $year was a leap year.${reset}\" else echo \"${redf}Nope, that's not a leap year.${reset}\" fi exit 0"
        },
        {
            "filename": "file_13.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_13.sh",
            "content": "#!/bin/sh # inpath - verify that a specified program is either valid as-is, # or can be found in the PATH directory list. in_path() { # given a command and the PATH, try to find the command. Returns # 0 if found and executable, 1 if not. Note that this temporarily modifies # the the IFS (input field seperator), but restores it upon completion. # return variable 'directory' contains the directory where the # command was found. cmd=$1 path=$2 retval=1 oldIFS=$IFS IFS=\":\" for directory in $path do if [ -x $directory/$cmd ] ; then retval=0 # if we're here, we found $cmd in $directory fi done IFS=$oldIFS return $retval } checkForCmdInPath() { var=$1 # The variable slicing notation in the following conditional # needs some explanation: ${var#expr} returns everything after # the match for 'expr' in the variable value (if any), and # ${var%expr} returns everything that doesn't match (in this # case just the very first character. You can also do this in # Bash with ${var:0:1} and you could use cut too: cut -c1 if [ \"$var\" != \"\" ] ; then if [ \"${var%${var#?}}\" = \"/\" ] ; then if [ ! -x $var ] ; then return 1 fi elif ! in_path $var $PATH ; then return 2 fi fi return 0 } # cnvalidate - Ensures that input only consists of alphabetical # and numeric characters. cnvalidate() { # validate arg: returns 0 if all upper+lower+digits, 1 otherwise # Remove all unacceptable chars compressed=\"$(echo $1 | sed -e 's/[^[:alnum:]]//g')\" if [ \"$compressed\" != \"$input\" ] ; then return 1 else return 0 fi } monthnoToName() { # sets the variable 'month' to the appropriate value case $1 in 1 ) month=\"Jan\" ;; 2 ) month=\"Feb\" ;; 3 ) month=\"Mar\" ;; 4 ) month=\"Apr\" ;; 5 ) month=\"May\" ;; 6 ) month=\"Jun\" ;; 7 ) month=\"Jul\" ;; 8 ) month=\"Aug\" ;; 9 ) month=\"Sep\" ;; 10) month=\"Oct\" ;; 11) month=\"Nov\" ;; 12) month=\"Dec\" ;; * ) echo \"$0: Unknown numeric month value $1\" >&2; exit 1 esac return 0 } # nicenumber - given a number, show it with comma separated values # expects DD and TD to be instantiated. instantiates nicenum # if arg2 is specified, this function echoes output, rather than # sending it back as a variable nicenumber() { # Note that we use the '.' as the decimal separator for parsing # the INPUT value to this script. The output value is as specified # by the user with the -d flag, if different from a '.' integer=$(echo $1 | cut -d. -f1) # left of the decimal decimal=$(echo $1 | cut -d. -f2) # right of the decimal if [ $decimal != $1 ]; then # there's a fractional part, let's include it. result=\"${DD:=\".\"}$decimal\" fi thousands=$integer while [ $thousands -gt 999 ]; do remainder=$(($thousands % 1000)) # three least significant digits while [ ${#remainder} -lt 3 ] ; do # force leading zeroes as needed remainder=\"0$remainder\" done thousands=$(($thousands / 1000)) # to left of remainder, if any result=\"${TD:=\",\"}${remainder}${result}\" # builds right-to-left done nicenum=\"${thousands}${result}\" if [ ! -z $2 ] ; then echo $nicenum fi } # validint - validate integer input, allow negative ints too validint() { # validate first field. Optionally test against min value $2 and/or # max value $3: if you'd rather skip these tests, send \"\" as values. # returns 1 for error, 0 for success number=\"$1\"; min=\"$2\"; max=\"$3\" if [ -z \"$number\" ] ; then echo \"You didn't enter anything. Unacceptable.\" >&2 ; return 1 fi if [ \"${number%${number#?}}\" = \"-\" ] ; then # first char '-' ? testvalue=\"${number#?}\" # all but first character else testvalue=\"$number\" fi nodigits=\"$(echo $testvalue | sed 's/[[:digit:]]//g')\" if [ ! -z \"$nodigits\" ] ; then echo \"Invalid number format! Only digits, no commas, spaces, etc.\" >&2 return 1 fi if [ ! -z \"$min\" ] ; then if [ \"$number\" -lt \"$min\" ] ; then echo \"Your value is too small: smallest acceptable value is $min\" >&2 return 1 fi fi if [ ! -z \"$max\" ] ; then if [ \"$number\" -gt \"$max\" ] ; then echo \"Your value is too big: largest acceptable value is $max\" >&2 return 1 fi fi return 0 } # validfloat - test whether a number is a valid floating point value. # Note that this cannot accept scientific (1.304e5) notation. # To test whether an entered value is a valid floating point number, we # need to split the value at the decimal point, then test the first part # to see if it's a valid integer, then the second part to see if it's a # valid >=0 integer, so -30.5 is valid, but -30.-8 isn't. Returns 0 on # success, 1 on failure. validfloat() { fvalue=\"$1\" if [ ! -z \"$(echo $fvalue | sed 's/[^.]//g')\" ] ; then decimalPart=\"$(echo $fvalue | cut -d. -f1)\" fractionalPart=\"$(echo $fvalue | cut -d. -f2)\" if [ ! -z \"$decimalPart\" ] ; then if ! validint \"$decimalPart\" \"\" \"\" ; then return 1 fi fi if [ \"${fractionalPart%${fractionalPart#?}}\" = \"-\" ] ; then echo \"Invalid floating point number: '-' not allowed \\ after decimal point\" >&2 return 1 fi if [ \"$fractionalPart\" != \"\" ] ; then if ! validint \"$fractionalPart\" \"0\" \"\" ; then return 1 fi fi if [ \"$decimalPart\" = \"-\" -o -z \"$decimalPart\" ] ; then if [ -z \"$fractionalPart\" ] ; then echo \"Invalid floating point format.\" >&2 ; return 1 fi fi else if [ \"$fvalue\" = \"-\" ] ; then echo \"Invalid floating point format.\" >&2 ; return 1 fi if ! validint \"$fvalue\" \"\" \"\" ; then return 1 fi fi return 0 } exceedsDaysInMonth() { # given a month name, return 0 if the specified day value is # less than or equal to the max days in the month, 1 otherwise case $(echo $1|tr '[:upper:]' '[:lower:]') in jan* ) days=31 ;; feb* ) days=28 ;; mar* ) days=31 ;; apr* ) days=30 ;; may* ) days=31 ;; jun* ) days=30 ;; jul* ) days=31 ;; aug* ) days=31 ;; sep* ) days=30 ;; oct* ) days=31 ;; nov* ) days=30 ;; dec* ) days=31 ;; * ) echo \"$0: Unknown month name $1\" >&2; exit 1 esac if [ $2 -lt 1 -o $2 -gt $days ] ; then return 1 else return 0 # all is well fi } isLeapYear() { # this function returns 0 if a leap year, 1 otherwise # The formula for checking whether a year is a leap year is: # 1. years divisible by four are leap years, unless.. # 2. years also divisible by 100 are not leap years, except... # 3. years divisible by 400 are leap years year=$1 if [ \"$((year % 4))\" -ne 0 ] ; then return 1 # nope, not a leap year elif [ \"$((year % 400))\" -eq 0 ] ; then return 0 # yes, it's a leap year elif [ \"$((year % 100))\" -eq 0 ] ; then return 1 else return 0 fi } validdate() { # expects three values, month, day and year. Returns 0 if success. newdate=\"$(normdate \"$@\")\" if [ $? -eq 1 ] ; then exit 1 # error condition already reported by normdate fi month=\"$(echo $newdate | cut -d\\ -f1)\" day=\"$(echo $newdate | cut -d\\ -f2)\" year=\"$(echo $newdate | cut -d\\ -f3)\" # Now that we have a normalized date, let's check to see if the # day value is logical if ! exceedsDaysInMonth $month \"$2\" ; then if [ \"$month\" = \"Feb\" -a $2 -eq 29 ] ; then if ! isLeapYear $3 ; then echo \"$0: $3 is not a leap year, so Feb doesn't have 29 days\" >&2 exit 1 fi else echo \"$0: bad day value: $month doesn't have $2 days\" >&2 exit 1 fi fi return 0 } echon() { echo \"$*\" | tr -d '\\n' } initializeANSI() { esc=\"\u001b\" blackf=\"${esc}[30m\"; redf=\"${esc}[31m\"; greenf=\"${esc}[32m\" yellowf=\"${esc}[33m\" bluef=\"${esc}[34m\"; purplef=\"${esc}[35m\" cyanf=\"${esc}[36m\"; whitef=\"${esc}[37m\" blackb=\"${esc}[40m\"; redb=\"${esc}[41m\"; greenb=\"${esc}[42m\" yellowb=\"${esc}[43m\" blueb=\"${esc}[44m\"; purpleb=\"${esc}[45m\" cyanb=\"${esc}[46m\"; whiteb=\"${esc}[47m\" boldon=\"${esc}[1m\"; boldoff=\"${esc}[22m\" italicson=\"${esc}[3m\"; italicsoff=\"${esc}[23m\" ulon=\"${esc}[4m\"; uloff=\"${esc}[24m\" invon=\"${esc}[7m\"; invoff=\"${esc}[27m\" reset=\"${esc}[0m\" }"
        },
        {
            "filename": "file_14.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_14.sh",
            "content": "#!/bin/sh # guessword - a simple word guessing game a la hangman blank=\"..................\" # must be longer than longest word getword() { case $(( $$ % 8 )) in 0 ) echo \"pizzazz\" ;; 1 ) echo \"delicious\" ;; 2 ) echo \"gargantuan\" ;; 3 ) echo \"minaret\" ;; 4 ) echo \"paparazzi\" ;; 5 ) echo \"delinquent\" ;; 6 ) echo \"zither\" ;; 7 ) echo \"cuisine\" ;; esac } addLetterToWord() { # This function replaces all '.' in template with guess # then updates remaining to be the number of empty slots left letter=1 while [ $letter -le $letters ] ; do if [ \"$(echo $word | cut -c$letter)\" = \"$guess\" ] ; then before=\"$(( $letter - 1 ))\"; after=\"$(( $letter + 1 ))\" if [ $before -gt 0 ] ; then tbefore=\"$(echo $template | cut -c1-$before)\" else tbefore=\"\" fi if [ $after -gt $letters ] ; then template=\"$tbefore$guess\" else template=\"$tbefore$guess$(echo $template | cut -c$after-$letters)\" fi fi letter=$(( $letter + 1 )) done remaining=$(echo $template|sed 's/[^\\.]//g'|wc -c|sed 's/[[:space:]]//g') remaining=$(( $remaining - 1 )) # fix to ignore '\\n' } word=$(getword) letters=$(echo $word | wc -c | sed 's/[[:space:]]//g') letters=$(( $letters - 1 )) # fix character count to ignore \\n template=\"$(echo $blank | cut -c1-$letters)\" remaining=$letters ; guessed=\"\" ; guesses=0; badguesses=0 echo \"** You're trying to guess a word with $letters letters **\" while [ $remaining -gt 0 ] ; do echo -n \"Word is: $template Try what letter next? \" ; read guess guesses=$(( $guesses + 1 )) if echo $guessed | grep -i $guess > /dev/null ; then echo \"You've already guessed that letter. Try again!\" elif ! echo $word | grep -i $guess > /dev/null ; then echo \"Sorry, the letter \\\"$guess\\\" is not in the word.\" guessed=\"$guessed$guess\" badguesses=$(( $badguesses + 1 )) else echo \"Good going! The letter $guess is in the word!\" addLetterToWord $guess fi done echo -n \"Congratulations! You guessed $word in $guesses guesses\" echo \" with $badguesses bad guesses\" exit 0"
        },
        {
            "filename": "file_15.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_15.sh",
            "content": "#!/bin/sh # hilow - a simple number guessing game biggest=100 # maximum number possible guess=0 # guessed by player guesses=0 # number of guesses made number=$(( $$ % $biggest )) # random number, 1 .. $biggest while [ $guess -ne $number ] ; do echo -n \"Guess? \" ; read guess if [ \"$guess\" -lt $number ] ; then echo \"... bigger!\" elif [ \"$guess\" -gt $number ] ; then echo \"... smaller!\" fi guesses=$(( $guesses + 1 )) done echo \"Right!! Guessed $number in $guesses guesses.\" exit 0"
        },
        {
            "filename": "file_16.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_16.sh",
            "content": "#!/bin/sh # nfmt - A version of fmt, using nroff. Adds two useful flags: -w X for # line width and -h to enable hyphenation for better fills. while getopts \"hw:\" opt; do case $opt in h ) hyph=1 ;; w ) width=\"$OPTARG\" ;; esac done shift $(($OPTIND - 1)) nroff << EOF .ll ${width:-72} .na .hy ${hyph:-0} .pl 1 $(cat \"$@\") EOF exit 0"
        },
        {
            "filename": "file_17.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_17.sh",
            "content": "#!/bin/sh # newrm - a replacement for the existing rm command that allows a # rudimentary unremove capability through utilizing a newly created # directory in the user's home directory. It can handle directories # of content as well as individual files, and if the user specifies # the -f flag, files are NOT archived, but removed. # Big Important Warning: you'll want a cron job or similar to keep the # individual trash directories tamed, otherwise nothing will ever # actually be deleted on the system and you'll run out of disk space! mydir=\"$HOME/.deleted-files\" realrm=\"/bin/rm \" copy=\"/bin/cp -R\" if [ $# -eq 0 ] ; then # let 'rm' ouptut the usage error exec $realrm # our shell dies and is replaced by /bin/rm fi # parse all options looking for '-f' flags=\"\" while getopts \"dfiPRrvW\" opt do case $opt in f ) exec $realrm \"$@\" ;; # exec lets us exit this script directly. * ) flags=\"$flags -$opt\" ;; # other flags are for 'rm', not us esac done shift $(( $OPTIND - 1 )) # make sure that the $mydir exists if [ ! -d $mydir ] ; then if [ ! -w $HOME ] ; then echo \"$0 failed: can't create $mydir in $HOME\" >&2 exit 1 fi mkdir $mydir chmod 700 $mydir # a little bit of privacy, please fi for arg do newname=\"$mydir/$(date \"+%S.%M.%H.%d.%m\").$(basename \"$arg\")\" if [ -f \"$arg\" ] ; then $copy \"$arg\" \"$newname\" elif [ -d \"$arg\" ] ; then $copy \"$arg\" \"$newname\" fi done exec $realrm $flags \"$@\" # our shell is replaced by realrm"
        },
        {
            "filename": "file_18.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_18.sh",
            "content": "#!/bin/sh # unrm - search the deleted files archive for the specified file. If # there is more than one match, show a list ordered by timestamp, and # let the user specify which they want restored. # Big Important Warning: you'll want a cron job or similar to keep the # individual trash directories tamed, otherwise nothing will ever # actually be deleted on the system and you'll run out of disk space! mydir=\"$HOME/.deleted-files\" realrm=\"/bin/rm\" move=\"/bin/mv\" dest=$(pwd) if [ ! -d $mydir ] ; then echo \"$0: No deleted files directory: nothing to unrm\" >&2 ; exit 1 fi cd $mydir if [ $# -eq 0 ] ; then # no args, just show listing echo \"Contents of your deleted files archive (sorted by date):\" # ls -FC | sed -e 's/[[:digit:]][[:digit:]]\\.//g' -e 's/^/ /' ls -FC | sed -e 's/\\([[:digit:]][[:digit:]]\\.\\)\\{5\\}//g' \\ -e 's/^/ /' exit 0 fi # Otherwise we must have a pattern to work with. Let's see if the # user-specified pattern matches more than one file or directory # in the archive. matches=\"$(ls *\"$1\" 2> /dev/null | wc -l)\" if [ $matches -eq 0 ] ; then echo \"No match for \\\"$1\\\" in the deleted file archive.\" >&2 exit 1 fi if [ $matches -gt 1 ] ; then echo \"More than one file or directory match in the archive:\" index=1 for name in $(ls -td *\"$1\") do datetime=\"$(echo $name | cut -c1-14| \\ awk -F. '{ print $5\"/\"$4\" at \"$3\":\"$2\":\"$1 }')\" if [ -d $name ] ; then size=\"$(ls $name | wc -l | sed 's/[^0-9]//g')\" echo \" $index) $1 (contents = ${size} items, deleted = $datetime)\" else size=\"$(ls -sdk1 $name | awk '{print $1}')\" echo \" $index) $1 (size = ${size}Kb, deleted = $datetime)\" fi index=$(( $index + 1)) done echo \"\" echo -n \"Which version of $1 do you want to restore ('0' to quit)? [1] : \" read desired if [ ${desired:=1} -ge $index ] ; then echo \"$0: Restore cancelled by user: index value too big.\" >&2 exit 1 fi if [ $desired -lt 1 ] ; then echo \"$0: restore cancelled by user.\" >&2 ; exit 1 fi restore=\"$(ls -td1 *\"$1\" | sed -n \"${desired}p\")\" if [ -e \"$dest/$1\" ] ; then echo \"\\\"$1\\\" already exists in this directory. Cannot overwrite.\" >&2 exit 1 fi echo -n \"Restoring file \\\"$1\\\" ...\" $move \"$restore\" \"$dest/$1\" echo \"done.\" echo -n \"Delete the additional copies of this file? [y] \" read answer if [ ${answer:=y} = \"y\" ] ; then $realrm -rf *\"$1\" echo \"deleted.\" else echo \"additional copies retained.\" fi else if [ -e \"$dest/$1\" ] ; then echo \"\\\"$1\\\" already exists in this directory. Cannot overwrite.\" >&2 exit 1 fi restore=\"$(ls -d *\"$1\")\" echo -n \"Restoring file \\\"$1\\\" ... \" $move \"$restore\" \"$dest/$1\" echo \"done.\" fi exit 0"
        },
        {
            "filename": "file_19.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_19.sh",
            "content": "#!/bin/sh # logrm - log all file deletion requests unless \"-s\" flag is used removelog=\"/tmp/removelog.log\" if [ $# -eq 0 ] ; then echo \"Usage: $0 [-s] list of files or directories\" >&2 exit 1 fi if [ \"$1\" = \"-s\" ] ; then # silent operation requested... don't log shift else echo \"$(date): ${USER}: $@\" >> $removelog fi /bin/rm \"$@\" exit 0"
        },
        {
            "filename": "file_2.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_2.sh",
            "content": "#!/bin/sh # validalAlphaNum - Ensures that input only consists of alphabetical # and numeric characters. validAlphaNum() { # validate arg: returns 0 if all upper+lower+digits, 1 otherwise # Remove all unacceptable chars compressed=\"$(echo $1 | sed -e 's/[^[:alnum:]]//g')\" if [ \"$compressed\" != \"$input\" ] ; then return 1 else return 0 fi } # Sample usage of this function in a script echo -n \"Enter input: \" read input if ! validAlphaNum \"$input\" ; then echo \"Your input must consist of only letters and numbers.\" >&2 exit 1 else echo \"Input is valid.\" fi exit 0"
        },
        {
            "filename": "file_20.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_20.sh",
            "content": "#!/bin/sh # formatdir - output a directory listing in a friendly and useful format gmk() { # given input in Kb, output in Kb, Mb or Gb for best output format if [ $1 -ge 1000000 ] ; then echo \"$(scriptbc -p 2 $1 / 1000000)Gb\" elif [ $1 -ge 1000 ] ; then echo \"$(scriptbc -p 2 $1 / 1000)Mb\" else echo \"${1}Kb\" fi } if [ $# -gt 1 ] ; then echo \"Usage: $0 [dirname]\" >&2; exit 1 elif [ $# -eq 1 ] ; then cd \"$@\" fi for file in * do if [ -d \"$file\" ] ; then size=$(ls \"$file\" | wc -l | sed 's/[^[:digit:]]//g') if [ $size -eq 1 ] ; then echo \"$file ($size entry)|\" else echo \"$file ($size entries)|\" fi else size=\"$(ls -sk \"$file\" | awk '{print $1}')\" echo \"$file ($(gmk $size))|\" fi done | \\ sed 's/ /^^^/g' | \\ xargs -n 2 | \\ sed 's/\\^\\^\\^/ /g' | \\ awk -F\\| '{ printf \"%-39s %-39s\\n\", $1, $2 }' exit 0"
        },
        {
            "filename": "file_21.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_21.sh",
            "content": "#!/bin/sh # locate - search the locate database for the specified pattern locatedb=\"/var/locate.db\" exec grep -i \"$@\" $locatedb"
        },
        {
            "filename": "file_22.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_22.sh",
            "content": "#!/bin/sh # mklocatedb - build the locate database using find. Must be root to run this locatedb=\"/var/locate.db\" if [ \"$(whoami)\" != \"root\" ] ; then echo \"Must be root to run this command.\" >&2 exit 1 fi find / -print > $locatedb exit 0"
        },
        {
            "filename": "file_23.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_23.sh",
            "content": "#!/bin/sh # DIR - pretend we're the DIR command in DOS and display the contents # of the specified file, accepting some of the standard DIR flags usage() { cat << EOF >&2 Usage: $0 [DOS flags] directory or directories Where: /D sort by columns /H show help for this shell script /N show long listing format with filenames on right /OD sort by oldest to newest /O-D sort by newest to oldest /P pause after each screenful of information /Q show owner of the file /S recursive listing /W use wide listing format EOF exit 0 } postcmd=\"\" flags=\"\" while [ $# -gt 0 ] do case $1 in /D ) flags=\"$flags -x\" ;; /H ) usage ;; /[NQW] ) flags=\"$flags -l\" ;; /OD ) flags=\"$flags -rt\" ;; /O-D ) flags=\"$flags -t\" ;; /P ) postcmd=\"more\" ;; /S ) flags=\"$flags -s\" ;; * ) # unknown flag: probably a dir specifier break; # so let's get outta the while loop esac shift # processed flag, let's see if there's another done # done processing flags, now the command itself: if [ ! -z \"$postcmd\" ] ; then ls $flags \"$@\" | $postcmd else ls $flags \"$@\" fi exit 0"
        },
        {
            "filename": "file_24.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_24.sh",
            "content": "#!/bin/sh # findman -- given a pattern and a man section, show all the matches # for that pattern from within all relevant man pages. match1=\"/tmp/$0.1.$$\" matches=\"/tmp/$0.$$\" manpagelist=\"\" trap \"rm -f $match1 $matches\" EXIT case $# in 3 ) section=\"$1\" cmdpat=\"$2\" manpagepat=\"$3\" ;; 2 ) section=\"\" cmdpat=\"$1\" manpagepat=\"$2\" ;; * ) echo \"Usage: $0 [section] cmdpattern manpagepattern\" >&2 exit 1 esac if ! man -k \"$cmdpat\" | grep \"($section\" > $match1 ; then echo \"No matches to pattern \\\"$cmdpat\\\". Try something broader?\"; exit 1 fi cut -d\\( -f1 < $match1 > $matches # command names only cat /dev/null > $match1 # clear the file... for manpage in $(cat $matches) do manpagelist=\"$manpagelist $manpage\" man $manpage | col -b | grep -i $manpagepat | \\ sed \"s/^/${manpage}: /\" | tee -a $match1 done if [ ! -s $match1 ] ; then cat << EOF Command pattern \"$cmdpat\" had matches, but within those there were no matches to your man page pattern \"$manpagepat\" found in that set. Man pages checked:$manpagelist EOF fi exit 0"
        },
        {
            "filename": "file_25.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_25.sh",
            "content": "#!/bin/sh # timein - show the current time in the specified timezone or # geographic zone. Without any argument, show UTC/GMT. Use # the word \"list\" to see a list of known geographic regions # Note that it's possible to match a zone directory (a region) # but that only timezone files are valid specifications. # Timezone database ref: http://www.twinsun.com/tz/tz-link.htm zonedir=\"/usr/share/zoneinfo\" if [ ! -d $zonedir ] ; then echo \"No timezone database at $zonedir.\" >&2 ; exit 1 fi if [ -d \"$zonedir/posix\" ] ; then zonedir=$zonedir/posix # modern Linux systems fi if [ $# -eq 0 ] ; then timezone=\"UTC\" mixedzone=\"UTC\" elif [ \"$1\" = \"list\" ] ; then ( echo \"All known timezones and regions defined on this system:\" cd $zonedir find * -type f -print | xargs -n 2 | \\ awk '{ printf \" %-38s %-38s\\n\", $1, $2 }' ) | more exit 0 else region=\"$(dirname $1)\" zone=\"$(basename $1)\" # Is it a direct match? If so, we're good to go. Otherwise we need # to dig around a bit to find things. Start by just counting matches matchcnt=\"$(find $zonedir -name $zone -type f -print | wc -l | sed 's/[^[:digit:]]//g' )\" if [ \"$matchcnt\" -gt 0 ] ; then # at least one file matches if [ $matchcnt -gt 1 ] ; then # more than one file match echo \"\\\"$zone\\\" matches more than one possible time zone record.\" >&2 echo \"Please use 'list' to see all known regions and timezones\" >&2 exit 1 fi match=\"$(find $zonedir -name $zone -type f -print)\" mixedzone=\"$zone\" else # Normalize to first upper, rest of word lowercase for region + zone mixedregion=\"$(echo ${region%${region#?}} | tr '[[:lower:]]' '[[:upper:]]')\\ $(echo ${region#?} | tr '[[:upper:]]' '[[:lower:]]')\" mixedzone=\"$(echo ${zone%${zone#?}} | tr '[[:lower:]]' '[[:upper:]]')\\ $(echo ${zone#?} | tr '[[:upper:]]' '[[:lower:]]')\" if [ \"$mixedregion\" != \".\" ] ; then # only look for specified zone in specified region # to let users specify unique matches when there's more than one # possibility (e.g., \"Atlantic\") match=\"$(find $zonedir/$mixedregion -type f -name $mixedzone -print)\" else match=\"$(find $zonedir -name $mixedzone -type f -print)\" fi if [ -z \"$match\" ] ; then # no file matches specified pattern if [ ! -z $(find $zonedir -name $mixedzone -type d -print) ] ; then echo \\ \"The region \\\"$1\\\" has more than one timezone. Please use 'list'\" >&2 else # just not a match at all echo \"Can't find an exact match for \\\"$1\\\". Please use 'list'\" >&2 fi echo \"to see all known regions and timezones.\" >&2 exit 1 fi fi timezone=\"$match\" fi nicetz=$(echo $timezone | sed \"s|$zonedir/||g\") # pretty up the output echo It\\'s $(TZ=$timezone date '+%A, %B %e, %Y, at %l:%M %p') in $nicetz exit 0"
        },
        {
            "filename": "file_26.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_26.sh",
            "content": "#!/bin/sh # remember - an easy command-line based memory pad # search the results with 'remindme' rememberfile=\"$HOME/.remember\" if [ $# -eq 0 ] ; then echo \"Enter note, end with ^D: \" cat - >> $rememberfile else echo \"$@\" >> $rememberfile fi exit 0"
        },
        {
            "filename": "file_27.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_27.sh",
            "content": "#!/bin/sh # remindme - search a datafile for matching lines, or show the contents # of the datafile if no arg is specified rememberfile=\"$HOME/.remember\" if [ $# -eq 0 ] ; then more $rememberfile else grep -i \"$@\" $rememberfile | ${PAGER:-more} fi exit 0"
        },
        {
            "filename": "file_28.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_28.sh",
            "content": "#!/bin/sh # calc - a command-line calculator that acts as a front-end to bc scale=2 show_help() { cat << EOF In addition to standard math functions, calc also supports a % b remainder of a/b a ^ b exponential: a raised to the b power s(x) sine of x, x in radians c(x) cosine of x, x in radians a(x) arctangent of x, returns radians l(x) natural log of x e(x) exponential log of raising e to the x j(n,x) bessel function of integer order n of x scale N show N fractional digits (default = 2) EOF } if [ $# -gt 0 ] ; then exec scriptbc \"$@\" fi echo \"Calc - a simple calculator. Use 'help' for help, 'quit' to quit.\" echo -n \"calc> \" while read command args do case $command in quit|exit) exit 0 ;; help|\\?) show_help ;; scale) scale=$args ;; *) scriptbc -p $scale \"$command\" \"$args\" ;; esac echo -n \"calc> \" done echo \"\" exit 0"
        },
        {
            "filename": "file_29.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_29.sh",
            "content": "#!/bin/sh # checkspelling - check the spelling of a word spell=\"ispell -l\" # if you have ispell installed instead # if not, just define spell=spell or # equivalent. if [ $# -lt 1 ] ; then echo \"Usage: $0 word or words\" >&2 exit 1 fi for word do if [ -z $(echo $word | $spell) ] ; then echo \"$word: spelled correctly.\" else echo \"$word: misspelled.\" fi done exit 0"
        },
        {
            "filename": "file_3.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_3.sh",
            "content": "#!/bin/sh # normdate - Normalizes month field in date specification # to three letters, first letter capitalized. A helper # function for hack #7, validdate. Exits w/ zero if no error. monthnoToName() { # sets the variable 'month' to the appropriate value case $1 in 1 ) month=\"Jan\" ;; 2 ) month=\"Feb\" ;; 3 ) month=\"Mar\" ;; 4 ) month=\"Apr\" ;; 5 ) month=\"May\" ;; 6 ) month=\"Jun\" ;; 7 ) month=\"Jul\" ;; 8 ) month=\"Aug\" ;; 9 ) month=\"Sep\" ;; 10) month=\"Oct\" ;; 11) month=\"Nov\" ;; 12) month=\"Dec\" ;; * ) echo \"$0: Unknown numeric month value $1\" >&2; exit 1 esac return 0 } ## Begin main script if [ $# -eq 1 ] ; then # try to compensate for / or - formats set -- $(echo $1 | sed 's/[\\/\\-]/ /g') fi if [ $# -ne 3 ] ; then echo \"Usage: $0 month day year\" >&2 echo \"Typical input formats are August 3 1962 and 8 3 2002\" >&2 exit 1 fi if [ $3 -lt 99 ] ; then echo \"$0: expected four-digit year value.\" >&2; exit 1 fi if [ -z $(echo $1|sed 's/[[:digit:]]//g') ]; then monthnoToName $1 else # normalize to first three letters, first upper, rest lowercase month=\"$(echo $1|cut -c1|tr '[:lower:]' '[:upper:]')\" month=\"$month$(echo $1|cut -c2-3 | tr '[:upper:]' '[:lower:]')\" fi echo $month $2 $3 exit 0"
        },
        {
            "filename": "file_30.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_30.sh",
            "content": "#!/bin/sh # shpell - An interactive spell checking program that lets you step # through all known spelling errors in a document, indicate which # ones you'd like to fix (and the correction), then applies them # all to the file. The original version of the file is saved with a # .shp suffix and the new version replaces the old. # # Note that you need a standard 'spell' command for this to work, which # might involve you installing aspell, ispell, or pspell on your system. tempfile=\"/tmp/$0.$$\" changerequests=\"/tmp/$0.$$.sed\" spell=\"ispell -l\" # modify as neede for your own spell trap \"rm -f $tempfile $changerequests\" EXIT HUP INT QUIT TERM # include the ansi color sequence definitions . 012-library.sh initializeANSI getfix() { # asks for a correction. Keeps track of nesting, # and only level 1 can output \"replacing\" message. word=$1 filename=$2 misspelled=1 while [ $misspelled -eq 1 ] do echo \"\"; echo \"${boldon}Misspelled word ${word}:${boldoff}\" grep -n $word $filename | sed -e 's/^/ /' -e \"s/$word/$boldon$word$boldoff/g\" echo -n \"i)gnore, q)uit, or type replacement: \" read fix if [ \"$fix\" = \"q\" -o \"$fix\" = \"quit\" ] ; then echo \"Exiting without applying any fixes.\"; exit 0 elif [ \"${fix%${fix#?}}\" = \"!\" ] ; then misspelled=0 # once we see spaces, we stop checking echo \"s/$word/${fix#?}/g\" >> $changerequests elif [ \"$fix\" = \"i\" -o -z \"$fix\" ] ; then misspelled=0 else if [ ! -z \"$(echo $fix | sed 's/[^ ]//g')\" ] ; then misspelled=0 # once we see spaces, we stop checking echo \"s/$word/$fix/g\" >> $changerequests else # it's a single word replacement, let's spell check that too if [ ! -z \"$(echo $fix | $spell)\" ] ; then echo \"\" echo \"*** Your suggested replacement $fix is misspelled.\" echo \"*** Prefix the word with '!' to force acceptance.\" else misspelled=0 # suggested replacement word is acceptable echo \"s/$word/$fix/g\" >> $changerequests fi fi fi done } ### beginning of actual script body if [ $# -lt 1 ] ; then echo \"Usage: $0 filename\" >&2 ; exit 1 fi if [ ! -r $1 ] ; then echo \"$0: Cannot read file $1 to check spelling\" >&2 ; exit 1 fi # note that the following invocation fills $tempfile along the way errors=\"$($spell < $1 | tee $tempfile | wc -l | sed 's/[^[:digit:]]//g')\" if [ $errors -eq 0 ] ; then echo \"There are no spelling errors in $1.\"; exit 0 fi echo \"We need to fix $errors misspellings in the document. Remember that the\" echo \"default answer to the spelling prompt is 'ignore', if you're lazy.\" touch $changerequests for word in $(cat $tempfile) do getfix $word $1 1 done if [ $(wc -l < $changerequests) -gt 0 ] ; then sed -f $changerequests $1 > $1.new mv $1 $1.shp mv $1.new $1 echo Done. Made $(wc -l < $changerequests) changes. fi exit 0"
        },
        {
            "filename": "file_31.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_31.sh",
            "content": "#!/bin/sh # spelldict - use the 'aspell' feature and some filtering to allow easy # command-line spell checking of a given input (file) okaywords=\"$HOME/.okaywords\" tempout=\"/tmp/spell.tmp.$$\" spell=\"virtual aspell\" # tweak as needed trap \"/bin/rm -f $tempout\" EXIT if [ -z \"$1\" ] ; then echo \"Usage: spell file|URL\" >&2; exit 1 elif [ ! -f $okaywords ] ; then echo \"No personal dictionary found. Create one and rerun this command\" >&2 echo \"Your dictionary file: $okaywords\" >&2 exit 1 fi for filename do $spell -a < $filename | \\ grep -v '@(#)' | sed \"s/\\'//g\" | \\ awk '{ if (length($0) > 15 && length($2) > 2) print $2 }' | \\ grep -vif $okaywords | \\ grep '[[:lower:]]' | grep -v '[[:digit:]]' | sort -u | \\ sed 's/^/ /' > $tempout if [ -s $tempout ] ; then sed \"s/^/${filename}: /\" $tempout fi done exit 0"
        },
        {
            "filename": "file_32.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_32.sh",
            "content": "#!/bin/sh # CONVERTATEMP - Temperature conversion script that lets the user enter # a temperature in any of Fahrenheit, Celsius or Kelvin and receive the # equivalent temperature in the other two units as the output. if uname | grep 'SunOS'>/dev/null ; then echo \"Yep, SunOS, let\\'s fix this baby\" PATH=\"/usr/xpg4/bin:$PATH\" fi if [ $# -eq 0 ] ; then cat << EOF >&2 Usage: $0 temperature[F|C|K] where the suffix: F indicates input is in Fahrenheit (default) C indicates input is in Celsius K indicates input is in Kelvin EOF exit 1 fi unit=\"$(echo $1|sed -e 's/[-[[:digit:]]*//g' | tr '[:lower:]' '[:upper:]' )\" temp=\"$(echo $1|sed -e 's/[^-[[:digit:]]*//g')\" case ${unit:=F} in F ) # Fahrenheit to Celsius formula: Tc = (F -32 ) / 1.8 farn=\"$temp\" cels=\"$(echo \"scale=2;($farn - 32) / 1.8\" | bc)\" kelv=\"$(echo \"scale=2;$cels + 273.15\" | bc)\" ;; C ) # Celsius to Fahrenheit formula: Tf = (9/5)*Tc+32 cels=$temp kelv=\"$(echo \"scale=2;$cels + 273.15\" | bc)\" farn=\"$(echo \"scale=2;((9/5) * $cels) + 32\" | bc)\" ;; K ) # Celsius = Kelvin + 273.15, then use Cels -> Fahr formula kelv=$temp cels=\"$(echo \"scale=2; $kelv - 273.15\" | bc)\" farn=\"$(echo \"scale=2; ((9/5) * $cels) + 32\" | bc)\" esac echo \"Fahrenheit = $farn\" echo \"Celsius = $cels\" echo \"Kelvin = $kelv\" exit 0"
        },
        {
            "filename": "file_33.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_33.sh",
            "content": "#!/bin/sh # mortgage - given a principal loan amount, interest rate, and # duration of loan (years), calculate the per-payment amount. # formula is: M = P * ( J / (1 - (1 + J) ** -N)) # where P = principal, J = monthly interest rate, N = duration (months) # # users typically enter P, I (annual interest rate) and L (length, years) . 012-library.sh if [ $# -ne 3 ] ; then echo \"Usage: $0 principal interest loan-duration-years\" >&2 exit 1 fi P=$1 I=$2 L=$3 J=\"$(scriptbc -p 8 $I / \\( 12 \\* 100 \\) )\" N=\"$(( $L * 12 ))\" M=\"$(scriptbc -p 8 $P \\* \\( $J / \\(1 - \\(1 + $J\\) \\^ -$N\\) \\) )\" # now a little prettying up of the value: dollars=\"$(echo $M | cut -d. -f1)\" cents=\"$(echo $M | cut -d. -f2 | cut -c1-2)\" cat << EOF A $L year loan at $I% interest with a principal amount of $(nicenumber $P 1 ) results in a payment of \\$$dollars.$cents each month for the duration of the loan ($N payments). EOF exit 0"
        },
        {
            "filename": "file_34.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_34.sh",
            "content": "#!/bin/sh # addagenda - prompt the user to add a new event for the Agenda script agendafile=\"$HOME/.agenda\" isDayName() { # return = 0 if all is well, 1 on error case $(echo $1 | tr '[[:upper:]]' '[[:lower:]]') in sun*|mon*|tue*|wed*|thu*|fri*|sat*) retval=0 ;; * ) retval=1 ;; esac return $retval } isMonthName() { case $(echo $1 | tr '[[:upper:]]' '[[:lower:]]') in jan*|feb*|mar*|apr*|may*|jun*) return 0 ;; jul*|aug*|sep*|oct*|nov*|dec*) return 0 ;; * ) return 1 ;; esac } normalize() { # return string with first char uppercase, next two lowercase echo -n $1 | cut -c1 | tr '[[:lower:]]' '[[:upper:]]' echo $1 | cut -c2-3| tr '[[:upper:]]' '[[:lower:]]' } if [ ! -w $HOME ] ; then echo \"$0: cannot write in your home directory ($HOME)\" >&2 exit 1 fi echo \"Agenda: The Unix Reminder Service\" echo -n \"Date of event (day mon, day month year, or dayname): \" read word1 word2 word3 junk if isDayName $word1 ; then if [ ! -z \"$word2\" ] ; then echo \"Bad dayname format: just specify the day name by itself.\" >&2 exit 1 fi date=\"$(normalize $word1)\" else if [ -z \"$word2\" ] ; then echo \"Bad dayname format: unknown day name specified\" >&2 exit 1 fi if [ ! -z \"$(echo $word1|sed 's/[[:digit:]]//g')\" ] ; then echo \"Bad date format: please specify day first, by day number\" >&2 exit 1 fi if [ \"$word1\" -lt 1 -o \"$word1\" -gt 31 ] ; then echo \"Bad date format: day number can only be in range 1-31\" >&2 exit 1 fi if ! isMonthName $word2 ; then echo \"Bad date format: unknown month name specified.\" >&2 exit 1 fi word2=\"$(normalize $word2)\" if [ -z \"$word3\" ] ; then date=\"$word1$word2\" else if [ ! -z \"$(echo $word3|sed 's/[[:digit:]]//g')\" ] ; then echo \"Bad date format: third field should be year.\" >&2 exit 1 elif [ $word3 -lt 2000 -o $word3 -gt 2500 ] ; then echo \"Bad date format: year value should be 2000-2500\" >&2 exit 1 fi date=\"$word1$word2$word3\" fi fi echo -n \"One line description: \" read description # ready to write to datafile echo \"$(echo $date|sed 's/ //g')|$description\" >> $agendafile exit 0"
        },
        {
            "filename": "file_35.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_35.sh",
            "content": "#!/bin/sh # agenda - scan through the user's .agenda file to see if there # are any matches for the current or next day agendafile=\"$HOME/.agenda\" checkDate() { # create the possible default values that'll match today weekday=$1 day=$2 month=$3 year=$4 format1=\"$weekday\" format2=\"$day$month\" format3=\"$day$month$year\" # and step through the file comparing dates... IFS=\"|\" # The reads will naturally split at the IFS echo \"On the Agenda for today:\" while read date description ; do if [ \"$date\" = \"$format1\" -o \"$date\" = \"$format2\" -o \"$date\" = \"$format3\" ] then echo \" $description\" fi done < $agendafile } if [ ! -e $agendafile ] ; then echo \"$0: You don't seem to have an .agenda file. \" >&2 echo \"To remedy this, please use 'addagenda' to add events\" >&2 exit 1 fi # now let's get today's date... eval $(date \"+weekday=\\\"%a\\\" month=\\\"%b\\\" day=\\\"%e\\\" year=\\\"%G\\\"\") day=\"$(echo $day|sed 's/ //g')\" # remove possible leading space checkDate $weekday $day $month $year exit 0"
        },
        {
            "filename": "file_36.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_36.sh",
            "content": "#!/bin/sh # numberlines - a simple alternative to cat -n, etc for filename do linecount=\"1\" (while read line do echo \"${linecount}: $line\" linecount=\"$(( $linecount + 1 ))\" done) < $filename done exit 0"
        },
        {
            "filename": "file_37.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_37.sh",
            "content": "#!/bin/sh # showfile - show the contents of a file, including additional useful info width=72 for input do lines=\"$(wc -l < $input | sed 's/ //g')\" chars=\"$(wc -c < $input | sed 's/ //g')\" owner=\"$(ls -ld $input | awk '{print $3}')\" echo \"-----------------------------------------------------------------\" echo \"File $input ($lines lines, $chars characters, owned by $owner):\" echo \"-----------------------------------------------------------------\" while read line do if [ ${#line} -gt $width ] ; then echo \"$line\" | fmt | sed -e '1s/^/ /' -e '2,$s/^/+ /' else echo \" $line\" fi done < $input echo \"-----------------------------------------------------------------\" done | more exit 0"
        },
        {
            "filename": "file_38.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_38.sh",
            "content": "#!/bin/sh # toolong - only feed the fmt command those lines in the input stream # that are longer than the specified length width=72 if [ ! -r \"$1\" ] ; then echo \"Usage: $0 filename\" >&2; exit 1 fi while read input do if [ ${#input} -gt $width ] ; then echo \"$input\" | fmt else echo \"$input\" fi done < $1 exit 0"
        },
        {
            "filename": "file_39.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_39.sh",
            "content": "#!/bin/sh # newquota - a front-end to quota that works with fullword flags a la GNU # quota has three possible flags: -g, -v and -q and in this script # we allow them to be '--group' '--verbose' and '--quiet' too: flags=\"\" realquota=\"/usr/bin/quota\" while [ $# -gt 0 ] do echo checking flag $1 case $1 in --help ) echo \"Usage: $0 [--group --verbose --quiet -gvq]\" >&2 exit 1 ;; --group | -group) flags=\"$flags -g\"; shift ;; --verbose | -verbose) flags=\"$flags -v\"; shift ;; --quiet | -quiet) flags=\"$flags -q\"; shift ;; -- ) shift; break ;; * ) break; # done with 'while' loop! esac done exec $realquota $flags \"$@\""
        },
        {
            "filename": "file_4.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_4.sh",
            "content": "#!/bin/sh # nicenumber - given a number, show it with comma separated values # expects DD and TD to be instantiated. instantiates nicenum # or, if a second arg is specified, the output is echoed to stdout nicenumber() { # Note that we use the '.' as the decimal separator for parsing # the INPUT value to this script. The output value is as specified # by the user with the -d flag, if different from a '.' integer=$(echo $1 | cut -d. -f1) # left of the decimal decimal=$(echo $1 | cut -d. -f2) # right of the decimal if [ $decimal != $1 ]; then # there's a fractional part, let's include it. result=\"${DD:=\".\"}$decimal\" fi thousands=$integer while [ $thousands -gt 999 ]; do remainder=$(($thousands % 1000)) # three least significant digits while [ ${#remainder} -lt 3 ] ; do # force leading zeroes as needed remainder=\"0$remainder\" done thousands=$(($thousands / 1000)) # to left of remainder, if any result=\"${TD:=\",\"}${remainder}${result}\" # builds right-to-left done nicenum=\"${thousands}${result}\" if [ ! -z $2 ] ; then echo $nicenum fi } DD=\".\" # decimal point delimiter, between integer & fractional value TD=\",\" # thousands delimiter, separates every three digits while getopts \"d:t:\" opt; do case $opt in d ) DD=\"$OPTARG\" ;; t ) TD=\"$OPTARG\" ;; esac done shift $(($OPTIND - 1)) if [ $# -eq 0 ] ; then cat << \"EOF\" >&2 Usage: $(basename $0) [-d c] [-t c] numeric value -d specifies the decimal point delimiter (default '.') -t specifies the thousands delimiter (default ',') EOF exit 1 fi nicenumber $1 1 # second arg forces this to 'echo' output exit 0"
        },
        {
            "filename": "file_40.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_40.sh",
            "content": "#!/bin/sh # mysftp - make sftp start up more like ftp echo -n \"User account: \" read account if [ -z \"$account\" ] ; then exit 0; # changed their mind, presumably fi if [ -z \"$1\" ] ; then echo -n \"Remote host: \" read host if [ -z $host ] ; then exit 0 fi else host=$1 fi # echo sftp -C $account@$host exec /usr/bin/sftp -C $account@$host"
        },
        {
            "filename": "file_41.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_41.sh",
            "content": "#!/bin/sh # cgrep - grep with context display and highlighted pattern matches context=0 esc=\"\u001b\" bOn=\"${esc}[1m\" bOff=\"${esc}[22m\" sedscript=\"/tmp/cgrep.sed.$$\" tempout=\"/tmp/cgrep.$$\" showMatches() { matches=0 echo \"s/$pattern/${bOn}$pattern${bOff}/g\" > $sedscript for lineno in $(grep -n \"$pattern\" $1 | cut -d: -f1) do if [ $context -gt 0 ] ; then prev=\"$(( $lineno - $context ))\" if [ \"$(echo $prev | cut -c1)\" = \"-\" ] ; then prev=\"0\" fi next=\"$(( $lineno + $context ))\" if [ $matches -gt 0 ] ; then echo \"${prev}i\\\\\" >> $sedscript echo \"----\" >> $sedscript fi echo \"${prev},${next}p\" >> $sedscript else echo \"${lineno}p\" >> $sedscript fi matches=\"$(( $matches + 1 ))\" done if [ $matches -gt 0 ] ; then sed -n -f $sedscript $1 | uniq | more fi } trap \"/bin/rm -f $tempout $sedscript\" EXIT if [ -z \"$1\" ] ; then echo \"Usage: $0 [-c X] pattern {filename}\" >&2; exit 0 fi if [ \"$1\" = \"-c\" ] ; then context=\"$2\" shift; shift elif [ \"$(echo $1|cut -c1-2)\" = \"-c\" ] ; then context=\"$(echo $1 | cut -c3-)\" shift fi pattern=\"$1\"; shift if [ $# -gt 0 ] ; then for filename ; do echo \"----- $filename -----\" showMatches $filename done else cat - > $tempout # save stream to a temp file showMatches $tempout fi exit 0"
        },
        {
            "filename": "file_42.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_42.sh",
            "content": "#!/bin/sh # zcat, zmore, and zgrep - this script should be either symbolically # linked or hard linked to all three names - it allows users to work # with compressed files transparently. Z=\"compress\"; unZ=\"uncompress\" ; Zlist=\"\" gz=\"gzip\" ; ungz=\"gunzip\" ; gzlist=\"\" bz=\"bzip2\" ; unbz=\"bunzip2\" ; bzlist=\"\" # First step is to try and isolate the filenames in the command line # we'll do this lazily by stepping through each argument testing to # see if it's a filename or not. If it is, and it has a compression # suffix, we'll uncompress the file, rewrite the filename, and proceed. # When done, we'll recompress everything that was uncompressed. for arg do if [ -f \"$arg\" ] ; then case $arg in *.Z) $unZ \"$arg\" arg=\"$(echo $arg | sed 's/\\.Z$//')\" Zlist=\"$Zlist \\\"$arg\\\"\" ;; *.gz) $ungz \"$arg\" arg=\"$(echo $arg | sed 's/\\.gz$//')\" gzlist=\"$gzlist \\\"$arg\\\"\" ;; *.bz2) $unbz \"$arg\" arg=\"$(echo $arg | sed 's/\\.bz2$//')\" bzlist=\"$bzlist \\\"$arg\\\"\" ;; esac fi newargs=\"${newargs:-\"\"} \\\"$arg\\\"\" done case $0 in *zcat* ) eval cat $newargs ;; *zmore* ) eval more $newargs ;; *zgrep* ) eval grep $newargs ;; * ) echo \"$0: unknown base name. Can't proceed.\" >&2; exit 1 esac # now recompress everything if [ ! -z \"$Zlist\" ] ; then eval $Z $Zlist fi if [ ! -z \"$gzlist\" ] ; then eval $gz $gzlist fi if [ ! -z \"$bzlist\" ] ; then eval $bz $bzlist fi # and done exit 0"
        },
        {
            "filename": "file_43.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_43.sh",
            "content": "#!/bin/sh # bestcompress - given a file, try compressing it with all the available # compression tools and keep the compressed file that's smallest, reporting # the result to the user. If '-a' isn't specified, it skips compressed # files in the input stream. Z=\"compress\" gz=\"gzip\" bz=\"bzip2\" Zout=\"/tmp/bestcompress.$$.Z\" gzout=\"/tmp/bestcompress.$$.gz\" bzout=\"/tmp/bestcompress.$$.bz\" skipcompressed=1 if [ \"$1\" = \"-a\" ] ; then skipcompressed=0 ; shift fi if [ $# -eq 0 ]; then echo \"Usage: $0 [-a] file or files to optimally compress\" >&2; exit 1 fi trap \"/bin/rm -f $Zout $gzout $bzout\" EXIT for name do if [ ! -f \"$name\" ] ; then echo \"$0: file $name not found. Skipped.\" >&2 continue fi if [ \"$(echo $name | egrep '(\\.Z$|\\.gz$|\\.bz2$)')\" != \"\" ] ; then if [ $skipcompressed -eq 1 ] ; then echo \"Skipped file ${name}: it's already compressed.\" continue else echo \"Warning: Trying to double-compress $name\" fi fi $Z < \"$name\" > $Zout & $gz < \"$name\" > $gzout & $bz < \"$name\" > $bzout & wait # run compressions in parallel for speed. Wait until all are done smallest=\"$(ls -l \"$name\" $Zout $gzout $bzout | \\ awk '{print $5\"=\"NR}' | sort -n | cut -d= -f2 | head -1)\" case \"$smallest\" in 1 ) echo \"No space savings by compressing $name. Left as-is.\" ;; 2 ) echo Best compression is with compress. File renamed ${name}.Z mv $Zout \"${name}.Z\" ; rm -f \"$name\" ;; 3 ) echo Best compression is with gzip. File renamed ${name}.gz mv $gzout \"${name}.gz\" ; rm -f \"$name\" ;; 4 ) echo Best compression is with bzip2. File renamed ${name}.bz2 mv $bzout \"${name}.bz2\" ; rm -f \"$name\" esac done exit 0"
        },
        {
            "filename": "file_44.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_44.sh",
            "content": "#!/bin/sh # FQUOTA - Disk quota analysis tool for Unix. # Assumes that all user accounts are >= UID 100. MAXDISKUSAGE=20 for name in $(cut -d: -f1,3 /etc/passwd | awk -F: '$2 > 99 { print $1 }') do echo -n \"User $name exceeds disk quota. Disk usage is: \" find / /usr /var /Users -user $name -xdev -type f -ls | \\ awk '{ sum += $7 } END { print sum / (1024*1024) \" Mbytes\" }' done | awk \"\\$9 > $MAXDISKUSAGE { print \\$0 }\" exit 0"
        },
        {
            "filename": "file_45.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_45.sh",
            "content": "#!/bin/sh # DISKHOGS - Disk quota analysis tool for Unix, assumes all user # accounts are >= UID 100. Emails message to each violating user # and reports a summary to the screen MAXDISKUSAGE=20 violators=\"/tmp/diskhogs0.$$\" trap \"/bin/rm -f $violators\" 0 for name in $(cut -d: -f1,3 /etc/passwd | awk -F: '$2 > 99 { print $1 }') do echo -n \"$name \" find / /usr /var /Users -user $name -xdev -type f -ls | \\ awk '{ sum += $7 } END { print sum / (1024*1024) }' done | awk \"\\$2 > $MAXDISKUSAGE { print \\$0 }\" > $violators if [ ! -s $violators ] ; then echo \"No users exceed the disk quota of ${MAXDISKUSAGE}MB\" cat $violators exit 0 fi while read account usage ; do cat << EOF | fmt | mail -s \"Warning: $account Exceeds Quota\" $account Your disk usage is ${usage}MB but you have only been allocated ${MAXDISKUSAGE}MB. This means that either you need to delete some of your files, compress your files (see 'gzip' or 'bzip2' for powerful and easy-to-use compression programs), or talk with us about increasing your disk allocation. Thanks for your cooperation on this matter. Dave Taylor @ x554 EOF echo \"Account $account has $usage MB of disk space. User notified.\" done < $violators exit 0"
        },
        {
            "filename": "file_46.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_46.sh",
            "content": "#!/bin/sh # diskspace - summarize available disk space and present in a logical # and readable fashion tempfile=\"/tmp/available.$$\" trap \"rm -f $tempfile\" EXIT cat << 'EOF' > $tempfile { sum += $4 } END { mb = sum / 1024 gb = mb / 1024 printf \"%.0f MB (%.2fGB) of available disk space\\n\", mb, gb } EOF df -k | awk -f $tempfile exit 0"
        },
        {
            "filename": "file_47.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_47.sh",
            "content": "#!/bin/sh # newdf - a friendlier version of df sedscript=\"/tmp/newdf.$$\" trap \"rm -f $sedscript\" EXIT cat << 'EOF' > $sedscript function showunit(size) { mb = size / 1024; prettymb=(int(mb * 100)) / 100; gb = mb / 1024; prettygb=(int(gb * 100)) / 100; if ( substr(size,1,1) !~ \"[0-9]\" || substr(size,2,1) !~ \"[0-9]\" ) { return size } else if ( mb < 1) { return size \"K\" } else if ( gb < 1) { return prettymb \"M\" } else { return prettygb \"G\" } } BEGIN { printf \"%-27s %7s %7s %7s %8s %-s\\n\", \"Filesystem\", \"Size\", \"Used\", \"Avail\", \"Capacity\", \"Mounted\" } !/Filesystem/ { size=showunit($2); used=showunit($3); avail=showunit($4); printf \"%-27s %7s %7s %7s %8s %-s\\n\", $1, size, used, avail, $5, $6 } EOF df -k | awk -f $sedscript exit 0"
        },
        {
            "filename": "file_48.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_48.sh",
            "content": "#!/bin/sh # mkslocatedb - build the central, public locate database as user nobody, # and simultaneously step through each home directory to find those # that contain a .slocatedb file. If found, an additional, private # version of the locate database will be created for that user. locatedb=\"/var/locate.db\" slocatedb=\".slocatedb\" if [ \"$(whoami)\" != \"root\" ] ; then echo \"$0: Error: You must be root to run this command.\" >&2 exit 1 fi if [ \"$(grep '^nobody:' /etc/passwd)\" = \"\" ] ; then echo \"$0: Error: you must have an account for user 'nobody'\" >&2 echo \"to create the default slocate database.\" >&2; exit 1 fi cd / # sidestep post-su pwd permission problems # first, create or update the public database su -fm nobody -c \"find / -print\" > $locatedb 2>/dev/null echo \"building default slocate database (user = nobody)\" echo ... result is $(wc -l < $locatedb) lines long. # now step through the user accounts on the system to see who has # a $slocatedb file in their home directory.... for account in $(cut -d: -f1 /etc/passwd) do homedir=\"$(grep \"^${account}:\" /etc/passwd | cut -d: -f6)\" if [ \"$homedir\" = \"/\" ] ; then continue # refuse to build one for root dir elif [ -e $homedir/$slocatedb ] ; then echo \"building slocate database for user $account\" su -fm $account -c \"find / -print\" > $homedir/$slocatedb \\ 2>/dev/null chmod 600 $homedir/$slocatedb chown $account $homedir/$slocatedb echo ... result is $(wc -l < $homedir/$slocatedb) lines long. fi done exit 0"
        },
        {
            "filename": "file_49.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_49.sh",
            "content": "#!/bin/sh # slocate - Try to search the user's secure locate database for the # specified pattern. If none exists, output a warning and create # one. If secure locate db is empty, use system one instead. locatedb=\"/var/locate.db\" slocatedb=\"$HOME/.slocatedb\" if [ \"$1\" = \"--explain\" ] ; then cat << \"EOF\" >&2 Warning: Secure locate keeps a private database for each user, and your database hasn't yet been created. Until it is (probably late tonight) I'll just use the public locate database, which will show you all publicly accessible matches, rather than those explicitly available to account ${USER:-$LOGNAME}. EOF if [ \"$1\" = \"--explain\" ] ; then exit 0 fi # before we go, create a .slocatedb so that cron will fill it # the next time the mkslocatedb script is run touch $slocatedb # mkslocatedb will build it next time through chmod 600 $slocatedb # start on the right foot with permissions elif [ -s $slocatedb ] ; then locatedb=$slocatedb else echo \"Warning: using public database. Use \\\"$0 --explain\\\" for details.\" >&2 fi if [ -z \"$1\" ] ; then echo \"Usage: $0 pattern\" >&2; exit 1 fi exec grep -i \"$1\" $locatedb"
        },
        {
            "filename": "file_5.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_5.sh",
            "content": "#!/bin/sh # validint - validate integer input, allow negative ints too validint() { # validate first field. Optionally test against min value $2 and/or # max value $3: if you'd rather skip these tests, send \"\" as values. # returns 1 for error, 0 for success. number=\"$1\"; min=\"$2\"; max=\"$3\" if [ -z $number ] ; then echo \"You didn't enter anything. Unacceptable.\" >&2 ; return 1 fi if [ \"${number%${number#?}}\" = \"-\" ] ; then # first char '-' ? testvalue=\"${number#?}\" # all but first character else testvalue=\"$number\" fi nodigits=\"$(echo $testvalue | sed 's/[[:digit:]]//g')\" if [ ! -z $nodigits ] ; then echo \"Invalid number format! Only digits, no commas, spaces, etc.\" >&2 return 1 fi if [ ! -z $min ] ; then if [ \"$number\" -lt \"$min\" ] ; then echo \"Your value is too small: smallest acceptable value is $min\" >&2 return 1 fi fi if [ ! -z $max ] ; then if [ \"$number\" -gt \"$max\" ] ; then echo \"Your value is too big: largest acceptable value is $max\" >&2 return 1 fi fi return 0 } # uncomment these lines to test, but beware that it'll break Hack #6 # because Hack #6 wants to source this file to get the validint() # function. :-) # if validint \"$1\" \"$2\" \"$3\" ; then # echo \"That input is a valid integer value within your constraints\" # fi"
        },
        {
            "filename": "file_50.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_50.sh",
            "content": "#!/bin/sh # ADDUSER - add a new user to the system, including building their # home directory, copying in default config data, etc. # For a standard Unix/Linux system, not Mac OS X pwfile=\"/etc/passwd\" shadowfile=\"/etc/shadow\" gfile=\"/etc/group\" hdir=\"/home\" if [ \"$(whoami)\" != \"root\" ] ; then echo \"Error: You must be root to run this command.\" >&2 exit 1 fi echo \"Add new user account to $(hostname)\" echo -n \"login: \" ; read login # adjust '5000' to match the top end of your user account namespace # because some system accounts have uid's like 65535 and similar. uid=\"$(awk -F: '{ if (big < $3 && $3 < 5000) big=$3 } END { print big + 1 }' $pwfile)\" homedir=$hdir/$login # we are giving each user their own group, so gid=uid gid=$uid echo -n \"full name: \" ; read fullname echo -n \"shell: \" ; read shell echo \"Setting up account $login for $fullname...\" echo ${login}:x:${uid}:${gid}:${fullname}:${homedir}:$shell >> $pwfile echo ${login}:*:11647:0:99999:7::: >> $shadowfile echo \"${login}:x:${gid}:$login\" >> $gfile mkdir $homedir cp -R /etc/skel/.[a-zA-Z]* $homedir chmod 755 $homedir find $homedir -print | xargs chown ${login}:$login # setting an initial password passwd $login exit 0"
        },
        {
            "filename": "file_51.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_51.sh",
            "content": "#!/bin/sh ## Suspend - suspend a user account for the indefinite future homedir=\"/home\" # home directory for users secs=10 # seconds before user is logged out if [ -z $1 ] ; then echo \"Usage: $0 account\" >&2 ; exit 1 elif [ \"$(whoami)\" != \"root\" ] ; then echo \"Error. You must be 'root' to run this command.\" >&2; exit 1 fi echo \"Please change account $1 password to something new.\" passwd $1 # Now, let's see if they're logged in, and if so, boot 'em if [ ! -z $(who | grep $1) ] ; then tty=\"$(who | grep $1 | tail -1 | awk '{print $2}')\" cat << \"EOF\" > /dev/$tty ************************************************************* URGENT NOTICE FROM THE ADMINISTRATOR: This account is being suspended at the request of management. You are going to be logged out in $secs seconds. Please immediately shut down any processes you have running and log out. If you have any questions, please contact your supervisor or John Doe, Director of Information Technology. ************************************************************* EOF echo \"(Warned $1, now sleeping $secs seconds)\" sleep $secs killall -s HUP -u $1 # send hangup sig to their processes sleep 1 # give it a second... killall -s KILL -u $1 # and kill anything left echo \"$(date): $1 was logged in. Just logged them out.\" fi # Finally, let's close off their home directory from prying eyes: chmod 000 $homedir/$1 echo \"Account $1 has been suspended.\" exit 0"
        },
        {
            "filename": "file_52.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_52.sh",
            "content": "#!/bin/sh ## Delete - delete a user account without a trace... # Not for use with Mac OS X homedir=\"/home\" pwfile=\"/etc/passwd\" shadow=\"/etc/shadow\" newpwfile=\"/etc/passwd.new\" newshadow=\"/etc/shadow.new\" suspend=\"echo suspending \" locker=\"/etc/passwd.lock\" if [ -z $1 ] ; then echo \"Usage: $0 account\" >&2; exit 1 elif [ \"$(whoami)\" != \"root\" ] ; then echo \"Error: you must be 'root' to run this command.\">&2; exit 1 fi # $suspend $1 # suspend their account while we do the dirty work uid=\"$(grep -E \"^${1}:\" $pwfile | cut -d: -f3)\" if [ -z $uid ] ; then echo \"Error: no account $1 found in $pwfile\" >&2; exit 1 fi # remove from the password and shadow files grep -vE \"^${1}:\" $pwfile > $newpwfile grep -vE \"^${1}:\" $shadow > $newshadow lockcmd=\"$(which lockfile)\" # find it in the path if [ ! -z $lockcmd ] ; then # let's use the system lockfile eval $lockcmd -r 15 $locker else # ulp, let's do it ourselves while [ -e $locker ] ; do echo \"waiting for the password file\" ; sleep 1 done touch $locker # created a file-based lock fi mv $newpwfile $pwfile mv $newshadow $shadow rm -f $locker # click! unlocked again chmod 644 $pwfile chmod 400 $shadow # now remove home directory and list anything left... rm -rf $homedir/$1 echo \"Files still left to remove (if any):\" find / -uid $uid -print 2>/dev/null | sed 's/^/ /' echo \"\" echo \"Account $1 (uid $uid) has been deleted, and their home directory \" echo \"($homedir/$1) has been removed.\" exit 0"
        },
        {
            "filename": "file_53.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_53.sh",
            "content": "#!/bin/sh # VALIDATOR - Checks to ensure that all environment variables are valid # looks at SHELL, HOME, PATH, EDITOR, MAIL, and PAGER errors=0 in_path() { # given a command and the PATH, try to find the command. Returns # 1 if found, 0 if not. Note that this temporarily modifies the # the IFS input field seperator, but restores it upon completion. cmd=$1 path=$2 retval=0 oldIFS=$IFS; IFS=\":\" for directory in $path do if [ -x $directory/$cmd ] ; then retval=1 # if we're here, we found $cmd in $directory fi done IFS=$oldIFS return $retval } validate() { varname=$1 varvalue=$2 if [ ! -z $varvalue ] ; then if [ \"${varvalue%${varvalue#?}}\" = \"/\" ] ; then if [ ! -x $varvalue ] ; then echo \"** $varname set to $varvalue, but I cannot find executable.\" errors=$(( $errors + 1 )) fi else if in_path $varvalue $PATH ; then echo \"** $varname set to $varvalue, but I cannot find it in PATH.\" errors=$(( $errors + 1 )) fi fi fi } ####### Beginning of actual shell script ####### if [ ! -x ${SHELL:?\"Cannot proceed without SHELL being defined.\"} ] ; then echo \"** SHELL set to $SHELL, but I cannot find that executable.\" errors=$(( $errors + 1 )) fi if [ ! -d ${HOME:?\"You need to have your HOME set to your home directory\"} ] then echo \"** HOME set to $HOME, but it's not a directory.\" errors=$(( $errors + 1 )) fi # Our first interesting test: are all the paths in PATH valid? oldIFS=$IFS; IFS=\":\" # IFS is the field separator. We'll change to ':' for directory in $PATH do if [ ! -d $directory ] ; then echo \"** PATH contains invalid directory $directory\" errors=$(( $errors + 1 )) fi done IFS=$oldIFS # restore value for rest of script # The following can be undefined, and they can also be a progname, rather # than a fully qualified path. Add additional variables as necessary for # your site and user community. validate \"EDITOR\" $EDITOR validate \"MAILER\" $MAILER validate \"PAGER\" $PAGER # and, finally, a different ending depending on whether errors > 0 if [ $errors -gt 0 ] ; then echo \"Errors encountered. Please notify sysadmin for help.\" else echo \"Your environment checks out fine.\" fi exit 0"
        },
        {
            "filename": "file_54.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_54.sh",
            "content": "#!/bin/sh # fixguest - Clean up the guest account during the logout process # don't trust environment variables: reference read-only sources iam=\"$(whoami)\" myhome=\"$(grep \"^${iam}:\" /etc/passwd | cut -d: -f6)\" # *** Do NOT run this script on a regular user account! if [ \"$iam\" != \"guest\" ] ; then echo \"Error: you really don't want to run fixguest on this account.\" >&2 exit 1 fi if [ ! -d $myhome/..template ] ; then echo \"$0: no template directory found for rebuilding.\" >&2 exit 1 fi # remove all files and directories in the home account cd $myhome rm -rf * $(find . -name \".[a-zA-Z0-9]*\" -print) # now the only thing present should be the ..template directory cp -Rp ..template/* . exit 0"
        },
        {
            "filename": "file_55.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_55.sh",
            "content": "#!/bin/sh # findsuid - find all SUID files or programs on the system other # than those that live in /bin and /usr/bin, and # output the matches in a friendly and useful format. mtime=\"7\" # how far back (in days) to check for modified cmds verbose=0 # by default, let's be quiet about things if [ \"$1\" = \"-v\" ] ; then verbose=1 fi for match in $(find /bin /usr/bin -type f -perm +4000 -print) do if [ -x $match ] ; then owner=\"$(ls -ld $match | awk '{print $3}')\" perms=\"$(ls -ld $match | cut -c5-10 | grep 'w')\" if [ ! -z $perms ] ; then echo \"**** $match (writeable and setuid $owner)\" elif [ ! -z $(find $match -mtime -$mtime -print) ] ; then echo \"**** $match (modified within $mtime days and setuid $owner)\" elif [ $verbose -eq 1 ] ; then lastmod=\"$(ls -ld $match | awk '{print $6, $7, $8}')\" echo \" $match (setuid $owner, last modified $lastmod)\" fi fi done exit 0"
        },
        {
            "filename": "file_56.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_56.sh",
            "content": "#!/bin/sh # setdate - friendly front-end to the date command # Date wants: [[[[[cc]yy]mm]dd]hh]mm[.ss] askvalue() { # $1 = field name, $2 = default value, $3 = max value, # $4 = required char/digit length echo -n \"$1 [$2] : \" read answer if [ ${answer:=$2} -gt $3 ] ; then echo \"$0: $1 $answer is invalid\"; exit 0 elif [ \"$(( $(echo $answer | wc -c) - 1 ))\" -lt $4 ] ; then echo \"$0: $1 $answer is too short: please specify $4 digits\"; exit 0 fi eval $1=$answer } eval $(date \"+nyear=%Y nmon=%m nday=%d nhr=%H nmin=%M\") askvalue year $nyear 3000 4 askvalue month $nmon 12 2 askvalue day $nday 31 2 askvalue hour $nhr 24 2 askvalue minute $nmin 59 2 squished=\"$year$month$day$hour$minute\" # or, if you're running a Linux system: # squished=\"$month$day$hour$minute$year\" echo \"Setting date to $squished. You might need to enter your sudo password:\" sudo date $squished exit 0"
        },
        {
            "filename": "file_57.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_57.sh",
            "content": "#!/bin/sh # enabled - show what services are enabled with inetd and xinetd, # if they're available on the system. iconf=\"/etc/inetd.conf\" xconf=\"/etc/xinetd.conf\" xdir=\"/etc/xinetd.d\" if [ -r $iconf ] ; then echo \"Services enabled in $iconf are:\" grep -v '^#' $iconf | awk '{print \" \" $1}' echo \"\" if [ \"$(ps -aux | grep inetd | egrep -vE '(xinet|grep)')\" = \"\" ] ; then echo \"** warning: inetd does not appear to be running\" fi fi if [ -r $xconf ] ; then # don't need to look in xinietd.conf, just know it exists echo \"Services enabled in $xdir are:\" for service in $xdir/* do if ! $(grep disable $service | grep 'yes' > /dev/null) ; then echo -n \" \" basename $service fi done if ! $(ps -aux | grep xinetd | grep -v 'grep' > /dev/null) ; then echo \"** warning: xinetd does not appear to be running\" fi fi exit 0"
        },
        {
            "filename": "file_58.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_58.sh",
            "content": "#!/bin/sh # killall - send the specified signal to all processes that match a # specific process name # By default it only kills processes owned by the same user, unless # you're root. Use -s SIGNAL to specify a signal to send, -u user to # specify user, -t tty to specify a tty, and -n to only show what'd # be done rather than doing it signal=\"-INT\" # default signal user=\"\" tty=\"\" donothing=0 while getopts \"s:u:t:n\" opt; do case \"$opt\" in # note the trick below: kill wants -SIGNAL but we're asking # for SIGNAL, so we slip the '-' in as part of the assignment s ) signal=\"-$OPTARG\"; ;; u ) if [ ! -z \"$tty\" ] ; then echo \"$0: error: -u and -t are mutually exclusive.\" >&2 exit 1 fi user=$OPTARG; ;; t ) if [ ! -z \"$user\" ] ; then echo \"$0: error: -u and -t are mutually exclusive.\" >&2 exit 1 fi tty=$2; ;; n ) donothing=1; ;; ? ) echo \"Usage: $0 [-s signal] [-u user|-t tty] [-n] pattern\" >&2 exit 1 esac done shift $(( $OPTIND - 1 )) if [ $# -eq 0 ] ; then echo \"Usage: $0 [-s signal] [-u user|-t tty] [-n] pattern\" >&2 exit 1 fi if [ ! -z \"$tty\" ] ; then pids=$(ps cu -t $tty | awk \"/ $1$/ { print \\$2 }\") elif [ ! -z \"$user\" ] ; then pids=$(ps cu -U $user | awk \"/ $1$/ { print \\$2 }\") else pids=$(ps cu -U ${USER:-LOGNAME} | awk \"/ $1$/ { print \\$2 }\") fi if [ -z \"$pids\" ] ; then echo \"$0: no processes match pattern $1\" >&2; exit 1 fi for pid in $pids do # Sending signal $signal to process id $pid: kill might # still complain if the process has finished, user doesn't # have permission, etc, but that's okay. if [ $donothing -eq 1 ] ; then echo \"kill $signal $pid\" else kill $signal $pid fi done exit 0"
        },
        {
            "filename": "file_59.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_59.sh",
            "content": "#!/bin/sh # verifycron - script checks a crontab file to ensure that it's # formatted properly. Expects standard cron notation of # min hr dom mon dow CMD # where min is 0-59, hr 0-23, dom is 1-31, mon is 1-12 (or names) # and dow is 0-7 (or names). Fields can have ranges (a-e), lists # separated by commas (a,c,z), or an asterisk. Note that the step # value notation of Vixie cron is not supported (e.g., 2-6/2). validNum() { # return 0 if valid, 1 if not. Specify number and maxvalue as args num=$1 max=$2 if [ \"$num\" = \"X\" ] ; then return 0 elif [ ! -z $(echo $num | sed 's/[[:digit:]]//g') ] ; then return 1 elif [ $num -lt 0 -o $num -gt $max ] ; then return 1 else return 0 fi } validDay() { # return 0 if a valid dayname, 1 otherwise case $(echo $1 | tr '[:upper:]' '[:lower:]') in sun*|mon*|tue*|wed*|thu*|fri*|sat*) return 0 ;; X) return 0 ;; # special case - it's an \"*\" *) return 1 esac } validMon() { # return 0 if a valid month name, 1 otherwise case $(echo $1 | tr '[:upper:]' '[:lower:]') in jan*|feb*|mar*|apr*|may|jun*|jul*|aug*) return 0 ;; sep*|oct*|nov*|dec*) return 0 ;; X) return 0 ;; # special case, it's an \"*\" *) return 1 ;; esac } fixvars() { # translate all '*' into 'X' to bypass shell expansion hassles # save original as \"sourceline\" for error messages sourceline=\"$min $hour $dom $mon $dow $command\" min=$(echo \"$min\" | tr '*' 'X') hour=$(echo \"$hour\" | tr '*' 'X') dom=$(echo \"$dom\" | tr '*' 'X') mon=$(echo \"$mon\" | tr '*' 'X') dow=$(echo \"$dow\" | tr '*' 'X') } if [ $# -ne 1 ] || [ ! -r $1 ] ; then echo \"Usage: $0 usercrontabfile\" >&2; exit 1 fi lines=0 entries=0 totalerrors=0 while read min hour dom mon dow command do lines=\"$(( $lines + 1 ))\" errors=0 if [ -z \"$min\" -o \"${min%${min#?}}\" = \"#\" ] ; then continue # nothing to check elif [ ! -z $(echo ${min%${min#?}} | sed 's/[[:digit:]]//') ] ; then continue # first char not digit: skip! fi entries=\"$(($entries + 1))\" fixvars #### Broken into fields, all '*' replaced with 'X' # minute check for minslice in $(echo \"$min\" | sed 's/[,-]/ /g') ; do if ! validNum $minslice 60 ; then echo \"Line ${lines}: Invalid minute value \\\"$minslice\\\"\" errors=1 fi done # hour check for hrslice in $(echo \"$hour\" | sed 's/[,-]/ /g') ; do if ! validNum $hrslice 24 ; then echo \"Line ${lines}: Invalid hour value \\\"$hrslice\\\"\" errors=1 fi done # day of month check for domslice in $(echo $dom | sed 's/[,-]/ /g') ; do if ! validNum $domslice 31 ; then echo \"Line ${lines}: Invalid day of month value \\\"$domslice\\\"\" errors=1 fi done # month check for monslice in $(echo \"$mon\" | sed 's/[,-]/ /g') ; do if ! validNum $monslice 12 ; then if ! validMon \"$monslice\" ; then echo \"Line ${lines}: Invalid month value \\\"$monslice\\\"\" errors=1 fi fi done # day of week check for dowslice in $(echo \"$dow\" | sed 's/[,-]/ /g') ; do if ! validNum $dowslice 7 ; then if ! validDay $dowslice ; then echo \"Line ${lines}: Invalid day of week value \\\"$dowslice\\\"\" errors=1 fi fi done if [ $errors -gt 0 ] ; then echo \">>>> ${lines}: $sourceline\" echo \"\" totalerrors=\"$(( $totalerrors + 1 ))\" fi done < $1 echo \"Done. Found $totalerrors errors in $entries crontab entries.\" exit 0"
        },
        {
            "filename": "file_6.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_6.sh",
            "content": "#!/bin/sh # validfloat - test whether a number is a valid floating point value. # Note that this cannot accept scientific (1.304e5) notation. # To test whether an entered value is a valid floating point number, we # need to split the value at the decimal point, then test the first part # to see if it's a valid integer, then the second part to see if it's a # valid >=0 integer, so -30.5 is valid, but -30.-8 isn't. . 005-validint.sh # source the validint function validfloat() { fvalue=\"$1\" if [ ! -z $(echo $fvalue | sed 's/[^.]//g') ] ; then decimalPart=\"$(echo $fvalue | cut -d. -f1)\" fractionalPart=\"$(echo $fvalue | cut -d. -f2)\" if [ ! -z $decimalPart ] ; then if ! validint \"$decimalPart\" \"\" \"\" ; then return 1 fi fi if [ \"${fractionalPart%${fractionalPart#?}}\" = \"-\" ] ; then echo \"Invalid floating point number: '-' not allowed \\ after decimal point\" >&2 return 1 fi if [ \"$fractionalPart\" != \"\" ] ; then if ! validint \"$fractionalPart\" \"0\" \"\" ; then return 1 fi fi if [ \"$decimalPart\" = \"-\" -o -z $decimalPart ] ; then if [ -z $fractionalPart ] ; then echo \"Invalid floating point format.\" >&2 ; return 1 fi fi else if [ \"$fvalue\" = \"-\" ] ; then echo \"Invalid floating point format.\" >&2 ; return 1 fi if ! validint \"$fvalue\" \"\" \"\" ; then return 1 fi fi return 0 } if validfloat $1 ; then echo \"$1 is a valid floating point value\" fi exit 0"
        },
        {
            "filename": "file_60.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_60.sh",
            "content": "#!/bin/sh # DOCRON - simple script to run the daily, weekly and monthly # system cron jobs on a system where it's likely that # it'll be shut down at the usual time of day when # this would occur. rootcron=\"/etc/crontab\" if [ $# -ne 1 ] ; then echo \"Usage: $0 [daily|weekly|monthly]\" >&2 exit 1 fi if [ \"$(id -u)\" -ne 0 ] ; then echo \"$0: Command must be run as 'root'\" >&2 exit 1 fi job=\"$(awk \"NR > 6 && /$1/ { for (i=7;i<=NF;i++) print \\$i }\" $rootcron)\" if [ -z $job ] ; then echo \"$0: Error: no $1 job found in $rootcron\" >&2 exit 1 fi SHELL=/bin/sh # to be consistent with cron's default eval $job"
        },
        {
            "filename": "file_61.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_61.sh",
            "content": "#!/bin/sh # rotatelogs - roll logfiles in /var/log for archival purposes. # uses a config file to allow customization of how frequently # each log should be rolled. That file is in # logfilename=duration # format, where duration is in days. If nothing is configured, # rotatelogs won't rotate more frequently than every seven days. logdir=\"/var/log\" config=\"/var/log/rotatelogs.conf\" mv=\"/bin/mv\" default_duration=7 count=0 duration=$default_duration if [ ! -f $config ] ; then echo \"$0: no config file found. Can't proceed.\" >&2; exit 1 fi if [ ! -w $logdir -o ! -x $logdir ] ; then echo \"$0: you don't have the appropriate permissions in $logdir\" >&2 exit 1 fi cd $logdir # While we'd like to use ':digit:' with the find, many versions of # find don't support Posix character class identifiers, hence [0-9] for name in $(find . -type f -size +0c ! -name '*[0-9]*' \\ ! -name '\\.*' ! -name '*conf' -maxdepth 1 -print | sed 's/^\\.\\///') do count=$(( $count + 1 )) # grab this entry from the config file duration=\"$(grep \"^${name}=\" $config|cut -d= -f2)\" if [ -z $duration ] ; then duration=$default_duration elif [ \"$duration\" = \"0\" ] ; then echo \"Duration set to zero: skipping $name\" continue fi back1=\"${name}.1\"; back2=\"${name}.2\"; back3=\"${name}.3\"; back4=\"${name}.4\"; # If the most recently rolled log file (back1) has been modified within # the specific quantum then it's not time to rotate it. if [ -f \"$back1\" ] ; then if [ -z $(find \"$back1\" -mtime +$duration -print 2>/dev/null) ] then echo \"$name's most recent backup is more recent than $duration days: skipping\" continue fi fi echo \"Rotating log $name (using a $duration day schedule)\" # rotate, starting with the oldest log if [ -f \"$back3\" ] ; then echo \"... $back3 -> $back4\" ; $mv -f \"$back3\" \"$back4\" fi if [ -f \"$back2\" ] ; then echo \"... $back2 -> $back3\" ; $mv -f \"$back2\" \"$back3\" fi if [ -f \"$back1\" ] ; then echo \"... $back1 -> $back2\" ; $mv -f \"$back1\" \"$back2\" fi if [ -f \"$name\" ] ; then echo \"... $name -> $back1\" ; $mv -f \"$name\" \"$back1\" fi touch \"$name\" chmod 0600 \"$name\" done if [ $count -eq 0 ] ; then echo \"Nothing to do: no log files big enough or old enough to rotate\" fi exit 0"
        },
        {
            "filename": "file_62.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_62.sh",
            "content": "#!/bin/sh # Backup - create either a full or incremental backup of a set of # defined directories on the system. By default, the output # file is saved in /tmp with a timestamped filename, compressed. # Otherwise, specify an output device (another disk, a removable). usageQuit() { cat << \"EOF\" >&2 Usage: $0 [-o output] [-i|-f] [-n] -o lets you specify an alternative backup file/device -i is an incremental or -f is a full backup, and -n prevents updating the timestamp if an incremental backup is done. EOF exit 1 } compress=\"bzip2\" # change for your favorite compression app inclist=\"/tmp/backup.inclist.$(date +%d%m%y)\" output=\"/tmp/backup.$(date +%d%m%y).bz2\" tsfile=\"$HOME/.backup.timestamp\" btype=\"incremental\" # default to an incremental backup noinc=0 # and an update of the timestamp trap \"/bin/rm -f $inclist\" EXIT while getopts \"o:ifn\" opt; do case \"$arg\" in o ) output=\"$OPTARG\"; ;; i ) btype=\"incremental\"; ;; f ) btype=\"full\"; ;; n ) noinc=1; ;; ? ) usageQuit ;; esac done shift $(( $OPTIND - 1 )) echo \"Doing $btype backup, saving output to $output\" timestamp=\"$(date +'%m%d%I%M')\" if [ \"$btype\" = \"incremental\" ] ; then if [ ! -f $tsfile ] ; then echo \"Error: can't do an incremental backup: no timestamp file\" >&2 exit 1 fi find $HOME -depth -type f -newer $tsfile -user ${USER:-LOGNAME} | \\ pax -w -x tar | $compress > $output failure=\"$?\" else find $HOME -depth -type f -user ${USER:-LOGNAME} | \\ pax -w -x tar | $compress > $output failure=\"$?\" fi if [ \"$noinc\" = \"0\" -a \"$failure\" = \"0\" ] ; then touch -t $timestamp $tsfile fi exit 0"
        },
        {
            "filename": "file_63.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_63.sh",
            "content": "#!/bin/sh # archivedir - create a compressed archive of the specified directory maxarchivedir=10 # size, in blocks, of 'big' directory, to confirm compress=gzip # change to your favorite compress app progname=$(basename $0) if [ $# -eq 0 ] ; then echo \"Usage: $progname directory\" >&2 ;exit 1 fi if [ ! -d $1 ] ; then echo \"${progname}: can't find directory $1 to archive.\" >&2; exit 1 fi if [ \"$(basename $1)\" != \"$1\" -o \"$1\" = \".\" ] ; then echo \"${progname}: You must specify a subdirectory\" >&2 exit 1 fi if [ ! -w . ] ; then echo \"${progname}: cannot write archive file to current directory.\" >&2 exit 1 fi dirsize=\"$(du -s $1 | awk '{print $1}')\" if [ $dirsize -gt $maxarchivedir ] ; then echo -n \"Warning: directory $1 is $dirsize blocks. Proceed? [n] \" read answer answer=\"$(echo $answer | tr '[:upper:]' '[:lower:]' | cut -c1)\" if [ \"$answer\" != \"y\" ] ; then echo \"${progname}: archive of directory $1 cancelled.\" >&2 exit 0 fi fi archivename=\"$(echo $1 | sed 's/$/.tgz/')\" if tar cf - $1 | $compress > $archivename ; then echo \"Directory $1 archived as $archivename\" else echo \"Warning: tar encountered errors archiving $1\" fi exit 0"
        },
        {
            "filename": "file_64.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_64.sh",
            "content": "#!/bin/sh # connecttime - reports cumulative connection time for month/year entries # found in the system log file. log=\"/var/log/system.log\" tempfile=\"/tmp/$0.$$\" trap \"rm $tempfile\" 0 cat << 'EOF' > $tempfile BEGIN { lastmonth=\"\"; sum = 0 } { if ( $1 != lastmonth && lastmonth != \"\" ) { if (sum > 60) { total = sum/60 \" hours\" } else { total = sum \" minutes\" } print lastmonth \": \" total sum=0 } lastmonth=$1 sum += $8 } END { if (sum > 60) { total = sum/60 \" hours\" } else { total = sum \" minutes\" } print lastmonth \": \" total } EOF grep \"Connect time\" $log | awk -f $tempfile exit 0"
        },
        {
            "filename": "file_65.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_65.sh",
            "content": "#!/bin/sh # ftpget - given an ftp: style URL, unwrap it, and try to obtain the file # using anonymous ftp. anonpass=\"$LOGNAME@$(hostname)\" if [ $# -ne 1 ] ; then echo \"Usage: $0 ftp://...\" >&2 exit 1 fi # Typical URL: ftp://ftp.ncftp.com/2.7.1/ncftpd-2.7.1.tar.gz if [ \"$(echo $1 | cut -c1-6)\" != \"ftp://\" ] ; then echo \"$0: Malformed url. I need it to start with ftp://\" >&2; exit 1 fi server=\"$(echo $1 | cut -d/ -f3)\" filename=\"$(echo $1 | cut -d/ -f4-)\" basefile=\"$(basename $filename)\" echo ${0}: Downloading $basefile from server $server ftp -n << EOF open $server user ftp $anonpass get $filename $basefile quit EOF if [ $? -eq 0 ] ; then ls -l $basefile fi exit 0"
        },
        {
            "filename": "file_66.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_66.sh",
            "content": "#!/bin/sh # bbcnews - report the top stories on the BBC World Service url=\"http://news.bbc.co.uk/2/low/technology/default.stm\" lynx -source $url | \\ sed -n '/Last Updated:/,/newssearch.bbc.co.uk/p' | \\ sed 's/</\\ </g;s/>/>\\ /g' | \\ grep -v -E '(<|>)' | \\ fmt | \\ uniq"
        },
        {
            "filename": "file_67.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_67.sh",
            "content": "#!/bin/sh # getlinks - given a URL, return all of its internal and # external links if [ $# -eq 0 ] ; then echo \"Usage: $0 [-d|-i|-x] url\" >&2 echo \"-d=domains only, -i=internal refs only, -x=external only\" >&2 exit 1 fi if [ $# -gt 1 ] ; then case \"$1\" in -d) lastcmd=\"cut -d/ -f3 | sort | uniq\" shift ;; -i) basedomain=\"http://$(echo $2 | cut -d/ -f3)/\" lastcmd=\"grep \\\"^$basedomain\\\" | sed \\\"s|$basedomain||g\\\" | sort | uniq\" shift ;; -x) basedomain=\"http://$(echo $2 | cut -d/ -f3)/\" lastcmd=\"grep -v \\\"^$basedomain\\\" | sort | uniq\" shift ;; *) echo \"$0: unknown option specified: $1\" >&2; exit 1 esac else lastcmd=\"sort | uniq\" fi lynx -dump \"$1\" | \\ sed -n '/^References$/,$p' | \\ grep -E '[[:digit:]]+\\.' | \\ awk '{print $2}' | \\ cut -d\\? -f1 | \\ eval $lastcmd exit 0"
        },
        {
            "filename": "file_68.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_68.sh",
            "content": "#!/bin/sh # define - given a word, return its definition from dictionary.com url=\"http://www.cogsci.princeton.edu/cgi-bin/webwn2.0?stage=1&word=\" if [ $# -ne 1 ] ; then echo \"Usage: $0 word\" >&2 exit 1 fi lynx -source \"$url$1\" | \\ grep -E '(^[[:digit:]]+\\.| has [[:digit:]]+$)' | \\ sed 's/<[^>]*>//g' | ( while read line do if [ \"${line:0:3}\" = \"The\" ] ; then part=\"$(echo $line | awk '{print $2}')\" echo \"\" echo \"The $part $1:\" else echo \"$line\" | fmt | sed 's/^/ /g' fi done ) exit 0"
        },
        {
            "filename": "file_69.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_69.sh",
            "content": "#!/bin/sh # weather - report weather forecast, including lat/long, for zip llurl=\"http://www.census.gov/cgi-bin/gazetteer?city=&state=&zip=\" wxurl=\"http://wwwa.accuweather.com\" wxurl=\"$wxurl/adcbin/public/local_index_print.asp?zipcode=\" if [ \"$1\" = \"-a\" ] ; then size=999; shift else size=5 fi if [ $# -eq 0 ] ; then echo \"Usage: $0 [-a] zipcode\" >&2 exit 1 fi if [ $size -eq 5 ] ; then echo \"\" # get some information on the zipcode from the Census Bureau lynx -source \"${llurl}$1\" | \\ sed -n '/^<li><strong>/,/^Location:/p' | \\ sed 's/<[^>]*>//g;s/^ //g' fi # the weather forecast itself at accuweather.com lynx -source \"${wxurl}$1\" | \\ sed -n '/Start - Forecast Cell/,/End - Forecast Cell/p' | \\ sed 's/<[^>]*>//g;s/^ [ ]*//g' | \\ uniq | \\ head -$size exit 0"
        },
        {
            "filename": "file_7.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_7.sh",
            "content": "#!/bin/sh # valid-date - validate date, taking into account leap year rules normdate=\"./003-normdate.sh\" # hack #3 for normalizing month name exceedsDaysInMonth() { # given a month name, return 0 if the specified day value is # less than or equal to the max days in the month, 1 otherwise case $(echo $1|tr '[:upper:]' '[:lower:]') in jan* ) days=31 ;; feb* ) days=28 ;; mar* ) days=31 ;; apr* ) days=30 ;; may* ) days=31 ;; jun* ) days=30 ;; jul* ) days=31 ;; aug* ) days=31 ;; sep* ) days=30 ;; oct* ) days=31 ;; nov* ) days=30 ;; dec* ) days=31 ;; * ) echo \"$0: Unknown month name $1\" >&2; exit 1 esac if [ $2 -lt 1 -o $2 -gt $days ] ; then return 1 else return 0 # all is well fi } isLeapYear() { # this function returns 0 if a leap year, 1 otherwise # The formula for checking whether a year is a leap year is: # 1. years divisible by four are leap years, unless.. # 2. years also divisible by 100 are not leap years, except... # 3. years divisible by 400 are leap years year=$1 if [ \"$((year % 4))\" -ne 0 ] ; then return 1 # nope, not a leap year elif [ \"$((year % 400))\" -eq 0 ] ; then return 0 # yes, it's a leap year elif [ \"$((year % 100))\" -eq 0 ] ; then return 1 else return 0 fi } ## Begin main script if [ $# -ne 3 ] ; then echo \"Usage: $0 month day year\" >&2 echo \"Typical input formats are August 3 1962 and 8 3 2002\" >&2 exit 1 fi # normalize date and split back out returned values newdate=\"$($normdate \"$@\")\" if [ $? -eq 1 ] ; then exit 1 # error condition already reported by normdate fi month=\"$(echo $newdate | cut -d\\ -f1)\" day=\"$(echo $newdate | cut -d\\ -f2)\" year=\"$(echo $newdate | cut -d\\ -f3)\" # Now that we have a normalized date, let's check to see if the # day value is logical if ! exceedsDaysInMonth $month \"$2\" ; then if [ \"$month\" = \"Feb\" -a $2 -eq 29 ] ; then if ! isLeapYear $3 ; then echo \"$0: $3 is not a leap year, so Feb doesn't have 29 days\" >&2 exit 1 fi else echo \"$0: bad day value: $month doesn't have $2 days\" >&2 exit 1 fi fi echo \"Valid date: $newdate\" exit 0"
        },
        {
            "filename": "file_70.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_70.sh",
            "content": "#!/bin/sh # check library - log in to the Boulder Public library computer # system and show the due date of everything checked out for # the specified user. A demonstration of how to work with the # method=\"post\" form with lynx. lib1=\"http://nell.boulder.lib.co.us/patroninfo\" lib2=\"items\" libacctdb=\"$HOME/.library.account.info\" postdata=\"/tmp/$(basename $0).$$\" awkdata=\"/tmp/$(basename $0).awk.$$\" # We need: name cardno recordno # Given the first, look for the other two in the libraryaccount database if [ $# -eq 0 ] ; then echo \"Usage: $(basename $0) \\\"card holder\\\"\"; exit 0 fi acctinfo=\"$(grep -i \"$1\" $libacctdb)\" name=\"$(echo $acctinfo | cut -d: -f1 | sed 's/ /+/g')\" cardno=\"$(echo $acctinfo | cut -d: -f2)\" recordno=\"$(echo $acctinfo | cut -d: -f3)\" if [ -z \"$acctinfo\" ] ; then echo \"Problem: account \\\"$1\\\" not found in library account database.\" exit 1 elif [ $(grep -i \"$1\" $libacctdb | wc -l) -gt 1 ] ; then echo \"Problem: account \\\"$1\\\" matches more than one record in library db.\" exit 1 elif [ -z \"$cardno\" -o -z \"$recordno\" ] ; then echo \"Problem: card or record information corrupted in database.\" exit 1 fi trap \"/bin/rm -f $postdata $awkdata\" 0 cat << EOF > $postdata name=${name}&code=${cardno}&submit=Display+record+for+person+named+above EOF cat << \"EOF\" > $awkdata { if ( NR % 3 == 1) { title=$0 } if ( NR % 3 == 2) { print $0 \"|\" title } } EOF lynx -source -post-data \"$lib1/$recordno/$lib2\" < $postdata | \\ grep -E '(^<td |name=\\\"renew)' | \\ sed 's/<[^>]*>//g' | \\ awk -f $awkdata | sort exit 0"
        },
        {
            "filename": "file_71.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_71.sh",
            "content": "#!/bin/sh # moviedata - given a movie title, return a list of matches, if # there's more than one, or a synopsis of the movie if there's # just one. Uses the Internet Movie Database (imdb.com) imdburl=\"http://us.imdb.com/Tsearch?restrict=Movies+only&title=\" titleurl=\"http://us.imdb.com/Title?\" tempout=\"/tmp/moviedata.$$\" summarize_film() { # produce an attractive synopsis of the film grep \"^<title>\" $tempout | sed 's/<[^>]*>//g;s/(more)//' grep '<b class=\"ch\">Plot Outline:</b>' $tempout | \\ sed 's/<[^>]*>//g;s/(more)//;s/(view trailer)//' |fmt|sed 's/^/ /' exit 0 } trap \"rm -f $tempout\" 0 1 15 if [ $# -eq 0 ] ; then echo \"Usage: $0 {movie title | movie ID}\" >&2 exit 1 fi fixedname=\"$(echo $@ | tr ' ' '+')\" # for the URL if [ $# -eq 1 ] ; then nodigits=\"$(echo $1 | sed 's/[[:digit:]]*//g')\" if [ -z \"$nodigits\" ] ; then lynx -source \"$titleurl$fixedname\" > $tempout summarize_film fi fi url=\"$imdburl$fixedname\" lynx -source $url > $tempout if [ ! -z \"$(grep \"IMDb title search\" $tempout)\" ] ; then grep 'HREF=\"/Title?' $tempout | \\ sed 's/<OL><LI><A HREF=\"//;s/<\\/A><\\/LI>//;s/<LI><A HREF=\"//' | \\ sed 's/\">/ -- /;s/<.*//;s/\\/Title?//' | \\ sort -u | \\ more else summarize_film fi exit 0"
        },
        {
            "filename": "file_72.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_72.sh",
            "content": "#!/bin/sh # exchangerate - given a currency amount, convert it into other major # currencies and show the equivalent amounts in each. # ref URL: http://www.ny.frb.org/pihome/statistics/forex12.shtml showrate() { dollars=\"$(echo $1 | cut -d. -f1)\" cents=\"$(echo $1 | cut -d. -f2 | cut -c1-2)\" rate=\"$dollars.${cents:-00}\" } exchratefile=\"/tmp/.exchangerate\" scriptbc=\"scriptbc -p 30\" # tweak this setting as needed . $exchratefile # The 0.0000000001 compensates for a rounding error bug in # many versions of bc, where 1 != 0.99999999999999 useuro=\"$($scriptbc 1 / $euro + 0.000000001)\" uscand=\"$($scriptbc 1 / $canada + 0.000000001)\" usyen=\"$($scriptbc 1 / $japan + 0.000000001)\" uspound=\"$($scriptbc 1 / $uk + 0.000000001)\" if [ $# -ne 2 ] ; then echo \"Usage: $(basename $0) amount currency\" echo \"Where currency can be USD, Euro, Canadian, Yen, or Pound.\" exit 0 fi amount=$1 currency=\"$(echo $2 | tr '[:upper:]' '[:lower:]' | cut -c1-2)\" case $currency in us|do ) if [ -z \"$(echo $1 | grep '\\.')\" ] ; then masterrate=\"$1.00\" else masterrate=\"$1\" fi ;; eu ) masterrate=\"$($scriptbc $1 \\* $euro)\" ;; ca|cd ) masterrate=\"$($scriptbc $1 \\* $canada)\" ;; ye ) masterrate=\"$($scriptbc $1 \\* $japan)\" ;; po|st ) masterrate=\"$($scriptbc $1 \\* $uk)\" ;; * ) echo \"$0: unknown currency specified.\" echo \"I only know USD, EURO, CAND/CDN, YEN and GBP/POUND.\" exit 1 esac echo \"Currency Exchange Rate Equivalents for $1 ${2}:\" showrate $masterrate echo \" US Dollars: $rate\" showrate $($scriptbc $masterrate \\* $useuro) echo \" EC Euros: $rate\" showrate $($scriptbc $masterrate \\* $uscand) echo \"Canadian Dollars: $rate\" showrate $($scriptbc $masterrate \\* $usyen) echo \" Japanese Yen: $rate\" showrate $($scriptbc $masterrate \\* $uspound) echo \" British Pound: $rate\" exit 0"
        },
        {
            "filename": "file_73.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_73.sh",
            "content": "#!/bin/sh # getexchrate - scrape the current currency exchange rates # from CNN's money and finance Web site. # # Without any flags, this grabs the exchange rate values if the # current information is more than 12 hours old. It also shows # success upon completion: something to take into account if # you run this from a cron job. url=\"http://money.cnn.com/markets/currencies/crosscurr.html\" age=\"+720\" # 12 hours, in minutes outf=\"/tmp/.exchangerate\" # Do we need the new exchange rate values? Let's check to see: # if the file is less than 12 hours old, the find fails ... if [ -f $outf ] ; then if [ -z \"$(find $outf -cmin $age -print)\" ]; then echo \"$0: exchange rate data is up-to-date.\" >&2 exit 1 fi fi # Actually get the latest exchange rates, translating into the # format required by the exchrate script. lynx -dump 'http://money.cnn.com/markets/currencies/crosscurr.html' | \\ grep -E '(Japan|Euro|Can|UK)' | \\ awk '{ if (NF == 5 ) { print $1\"=\"$2} }' | \\ tr '[:upper:]' '[:lower:]' | \\ sed 's/dollar/cand/' > $outf echo \"Success. Exchange rates updated at $(date).\" exit 0"
        },
        {
            "filename": "file_74.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_74.sh",
            "content": "#!/bin/sh # getstock - given a stock ticker symbol, return its current value # from the Lycos web site url=\"http://finance.lycos.com/qc/stocks/quotes.aspx?symbols=\" if [ $# -ne 1 ] ; then echo \"Usage: $(basename $0) stocksymbol\" >&2 exit 1 fi value=\"$(lynx -dump \"$url$1\" | grep 'Last price:' | \\ awk -F: 'NF > 1 && $(NF) != \"N/A\" { print $(NF) }')\" if [ -z $value ] ; then echo \"error: no value found for ticker symbol $1.\" >&2 exit 1 fi echo $value exit 0"
        },
        {
            "filename": "file_75.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_75.sh",
            "content": "#!/bin/sh # portfolio - calculate the value of each stock in your holdings, # then calculate the value of your overall portfolio, based on # the latest stock market position. getstock=\"sh 069-getstock.sh\" scriptbc=\"$HOME/bin/scriptbc\" portfolio=\"$HOME/.portfolio\" if [ ! -f $portfolio ] ; then echo \"$(basename $0): No portfolio to check? ($portfolio)\" >&2 exit 1 fi while read holding do eval $(echo $holding | \\ awk -F\\| '{print \"name=\\\"\"$1\"\\\"; ticker=\\\"\"$2\"\\\"; hold=\\\"\"$3\"\\\"\"}') if [ ! -z \"$ticker\" ] ; then value=\"$(eval $getstock $ticker)\" totval=\"$($scriptbc ${value:-0} \\* $hold)\" echo \"$name is trading at $value (your $hold shares = $totval)\" sumvalue=\"$($scriptbc ${sumvalue:-0} + $totval)\" fi done < $portfolio echo \"Total portfolio value: $sumvalue\" exit 0"
        },
        {
            "filename": "file_76.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_76.sh",
            "content": "#!/bin/sh # changetrack - track a given URL, and if it's changed since the last # visit, email the new page to the specified address. sitearchive=\"/tmp/changetrack\" # can change as desired sendmail=\"/usr/sbin/sendmail\" # might need to be tweaked! fromaddr=\"webscraper@intuitive.com\" # change as desired if [ $# -ne 2 ] ; then echo \"Usage: $(basename $0) url email\" >&2 exit 1 fi if [ ! -d $sitearchive ] ; then if ! mkdir $sitearchive ; then echo \"$(basename $0) failed: couldn't create $sitearchive.\" >&2 exit 1 fi chmod 777 $sitearchive # you might change this for privacy fi if [ \"$(echo $1 | cut -c1-5)\" != \"http:\" ] ; then echo \"Please use fully qualified URLs (e.g. start with 'http://')\" >&2 exit 1 fi fname=\"$(echo $1 | sed 's/http:\\/\\///g' | tr '/?&' '...')\" baseurl=\"$(echo $1 | cut -d/ -f1-3)/\" # Grab a copy of the Web page into an archive file. Note that we can # track changes by looking just at the content (e.g. '-dump', not # '-source'), so we can skip any HTML parsing ... lynx -dump \"$1\" | uniq > $sitearchive/${fname}.new if [ -f $sitearchive/$fname ] ; then # we've seen this site before, so compare the two with 'diff' if diff $sitearchive/$fname $sitearchive/${fname}.new > /dev/null ; then echo \"Site $1 has changed since our last check.\" else rm -f $sitearchive/${fname}.new # nothing new... exit 0 # no change, we're outta here. fi else echo \"Note: we've never seen this site before.\" fi # To get here, the site has changed and we need to send the contents # of the .new file to the user and replace the original with the .new # for the next invocation of the script. ( echo \"Content-type: text/html\" echo \"From: $fromaddr (Web Site Change Tracker)\" echo \"Subject: Web Site $1 Has Changed\" echo \"To: $2\" echo \"\" lynx -source $1 | \\ sed -e \"s|[sS][rR][cC]=\\\"|SRC=\\\"$baseurl|g\" \\ -e \"s|[hH][rR][eE][fF]=\\\"|HREF=\\\"$baseurl|g\" \\ -e \"s|$baseurl\\/http:|http:|g\" ) | cat # $sendmail -t # update the saved snapshot of the Web site mv $sitearchive/${fname}.new $sitearchive/$fname chmod 777 $sitearchive/$fname # and we're done. exit 0"
        },
        {
            "filename": "file_77.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_77.sh",
            "content": "#!/bin/sh # show CGI env - display the CGI runtime environment, as given to any # CGI script on this system. echo \"Content-type: text/html\" echo \"\" # now the real information echo \"<html><body bgcolor=\\\"white\\\"><h2>CGI Runtime Environment</h2>\" echo \"<pre>\" env || printenv echo \"</pre>\" echo \"<h3>Input stream is:</h3>\" echo \"<pre>\" cat - echo \"(end of input stream)</pre></body></html>\" exit 0"
        },
        {
            "filename": "file_78.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_78.sh",
            "content": "#!/bin/sh # Within cron set it up so that every Friday, grab the latest column # of 'The Straight Dope' and mail it out to the specified recipient now=\"$(date +%y%m%d)\" url=\"http://www.straightdope.com/columns/${now}.html\" to=\"taylor\" ( cat << EOF Subject: The Straight Dope for $(date \"+%A, %d %B, %Y\") From: Cecil Adams <www@intuitive.com> Content-type: text/html To: $to <html> <body border=0 leftmargin=0 topmargin=0> <div style='background-color:309;color:fC6;font-size:45pt; font-style:sans-serif;font-weight:900;text-align:center; margin:0;padding:3px;'> THE STRAIGHT DOPE</div> <div style='padding:3px;line-height:1.1'> EOF lynx -source \"$url\" | \\ sed -n '/<hr>/,$p' | \\ sed 's|src=\"../art|src=\"http://www.straightdope.com/art|' |\\ sed 's|href=\"..|href=\"http://www.straightdope.com|g' echo \"</div></body></html>\" ) | /usr/sbin/sendmail -t exit 0"
        },
        {
            "filename": "file_79.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_79.sh",
            "content": "#!/bin/sh # counter - a simple text-based page counter, with appropriate locking myhome=\"/home/taylor/web/wicked/examples\" counter=\"$myhome/counter.dat\" lockfile=\"$myhome/counter.lck\" updatecounter=\"$myhome/updatecounter\" # Note that this script is not intended to be called directly from # a web browser so it doesn't use the otherwise obligatory # content-type header material. # ascertain whether we have lockf or lockfile system apps if [ -z $(which lockf) ] ; then if [ -z $(which lockfile) ] ; then echo \"(counter: no locking utility available)<br>\" exit 0 else # proceed with the lockfile command if [ ! -f $counter ] ; then echo \"0\" # it'll be created shortly else cat $counter fi trap \"/bin/rm -f $lockfile\" 0 lockfile -1 -l 10 -s 2 $lockfile if [ $? -ne 0 ] ; then echo \"(counter: couldn't create lockfile in time)\" exit 0 fi $updatecounter $counter fi else if [ ! -f $counter ] ; then echo \"0\" # it'll be created shortly else cat $counter fi lockf -s -t 10 $lockfile $updatecounter $counter if [ $? -ne 0 ] ; then echo \"(counter: couldn't create lockfile in time)\" fi fi exit 0"
        },
        {
            "filename": "file_8.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_8.sh",
            "content": "#!/bin/sh # echon - a script to emulate the -n flag functionality with 'echo' # for Unix systems that don't have that available. echon() { echo \"$*\" | tr -d '\\n' } echon \"this is a test: \" read answer echon this is a test too \" \" read answer2"
        },
        {
            "filename": "file_80.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_80.sh",
            "content": "#!/bin/sh # updatecounter - a tiny script that updates the counter file to # the value specified. Assumes that locking is done elsewhere. if [ $# -ne 1 ] ; then echo \"Usage: $0 countfile\"; exit 1 fi count=\"$(cat $1)\" newcount=\"$(( ${count:-0} + 1 ))\" echo \"$newcount\" > $1 chmod a+rw $1 exit 0"
        },
        {
            "filename": "file_81.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_81.sh",
            "content": "#!/bin/sh # randomquote - given a one-line-per-entry datafile, this # script will randomly pick one and display it. Best used # as an SSI call within a Web page. awkscript=\"/tmp/randomquote.awk.$$\" if [ $# -ne 1 ] ; then echo \"Usage: randomquote datafilename\" >&2 exit 1 elif [ ! -r \"$1\" ] ; then echo \"Error: quote file $1 is missing or not readable\" >&2 exit 1 fi trap \"/bin/rm -f $awkscript\" 0 cat << \"EOF\" > $awkscript BEGIN { srand(); } { s[NR] = $0 } END { print s[randint(NR)] } function randint(n) { return int (n * rand() ) + 1 } EOF awk -f $awkscript < \"$1\" exit 0"
        },
        {
            "filename": "file_82.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_82.sh",
            "content": "#!/bin/sh # checklinks - traverse all internal URLs on a Web site, reporting # any errors in the \"traverse.errors\" file. lynx=\"/usr/local/bin/lynx\" # this might need to be tweaked # remove all the lynx traversal output files upon completion: trap \"/bin/rm -f traverse*.errors reject*.dat traverse*.dat\" 0 if [ -z \"$1\" ] ; then echo \"Usage: checklinks URL\" >&2 ; exit 1 fi $lynx -traversal \"$1\" > /dev/null if [ -s \"traverse.errors\" ] ; then echo -n $(wc -l < traverse.errors) errors encountered. echo \\ Checked $(grep '^http' traverse.dat | wc -l) pages at ${1}: sed \"s|$1||g\" < traverse.errors else echo -n \"No errors encountered. \"; echo Checked $(grep '^http' traverse.dat | wc -l) pages at ${1} exit 0 fi baseurl=\"$(echo $1 | cut -d/ -f3)\" mv traverse.errors ${baseurl}.errors echo \"(A copy of this output has been saved in ${baseurl}.errors)\" exit 0"
        },
        {
            "filename": "file_83.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_83.sh",
            "content": "#!/bin/sh # checkexternal - traverse all internal URLs on a Web site to build a # list of external references, then check each one to ascertain # which might be dead or otherwise broken. The -a flag forces the # script to list all matches, whether they're accessible or not: by # default only unreachable links are shown. lynx=\"/usr/local/bin/lynx\" # might need to be tweaked listall=0; errors=0 # shortcut: two vars on one line! if [ \"$1\" = \"-a\" ] ; then listall=1; shift fi outfile=\"$(echo \"$1\" | cut -d/ -f3).external-errors\" /bin/rm -f $outfile # clean it for new output trap \"/bin/rm -f traverse*.errors reject*.dat traverse*.dat\" 0 if [ -z \"$1\" ] ; then echo \"Usage: $(basename $0) [-a] URL\" >&2 exit 1 fi # create the data files needed $lynx -traversal $1 > /dev/null; if [ -s \"reject.dat\" ] ; then # The following line has a trailing space after the backslash! echo -n $(sort -u reject.dat | wc -l) external links encountered echo \\ in $(grep '^http' traverse.dat | wc -l) pages for URL in $(grep '^http:' reject.dat | sort -u) do if ! $lynx -dump $URL > /dev/null 2>&1 ; then echo \"Failed : $URL\" >> $outfile errors=\"$(( $errors + 1 ))\" elif [ $listall -eq 1 ] ; then echo \"Success: $URL\" >> $outfile fi done if [ -s $outfile ] ; then cat $outfile echo \"(A copy of this output has been saved in ${outfile})\" elif [ $listall -eq 0 -a $errors -eq 0 ] ; then echo \"No problems encountered.\" fi else echo -n \"No external links encountered \" echo in $(grep '^http' traverse.dat | wc -l) pages. fi exit 0"
        },
        {
            "filename": "file_84.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_84.sh",
            "content": "#!/bin/sh # webspell - use the 'aspell' feature + lynx to spell check either a # Web page URL or a file. # Inevitably you'll find that there are words it flags as wrong, but # you think are fine. Simply save them in a file, one-per-line, and # ensure that 'okaywords' points to that file. okaywords=\"$HOME/.okaywords\" tempout=\"/tmp/webspell.$$\" trap \"/bin/rm -f $tempout\" 0 if [ $# -eq 0 ] ; then echo \"Usage: webspell file|URL\" >&2; exit 1 fi for filename do if [ ! -f \"$filename\" -a \"$(echo $filename|cut -c1-7)\" != \"http://\" ] ; then continue; # picked up directory in '*' listing fi lynx -dump $filename | tr ' ' '\\n' | sort -u | \\ grep -vE \"(^[^a-z]|')\" | \\ # adjust the following line to produce just a list of misspelled words ispell -a | awk '/^\\&/ { print $2 }' | \\ sort -u > $tempout if [ -r $okaywords ] ; then # if you have an okaywords file, screen okay words out grep -vif $okaywords < $tempout > ${tempout}.2 mv ${tempout}.2 $tempout fi if [ -s $tempout ] ; then echo \"Probable spelling errors: ${filename}\" echo '-------' ; cat $tempout ; echo '=========' cat $tempout | paste - - - - | sed 's/^/ /' fi done exit 0"
        },
        {
            "filename": "file_85.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_85.sh",
            "content": "#!/bin/sh # ftpsyncup - Given a target directory on an ftp server, make sure that # all new or modified files are uploaded to the remote system. Uses # a timestamp file ingeniously called .timestamp to keep track. timestamp=\".timestamp\" tempfile=\"/tmp/ftpsyncup.$$\" count=0 trap \"/bin/rm -f $tempfile\" 0 1 15 # zap tempfile on exit &sigs if [ $# -eq 0 ] ; then echo \"Usage: $0 user@host { remotedir }\" >&2 exit 1 fi user=\"$(echo $1 | cut -d@ -f1)\" server=\"$(echo $1 | cut -d@ -f2)\" echo \"open $server\" > $tempfile echo \"user $user\" >> $tempfile if [ $# -gt 1 ] ; then echo \"cd $2\" >> $tempfile fi if [ ! -f $timestamp ] ; then # no timestamp file, upload all files for filename in * do if [ -f \"$filename\" ] ; then echo \"put \\\"$filename\\\"\" >> $tempfile count=$(( $count + 1 )) fi done else for filename in $(find . -newer $timestamp -type f -print) do echo \"put \\\"$filename\\\"\" >> $tempfile count=$(( $count + 1 )) done fi if [ $count -eq 0 ] ; then echo \"$0: No files require uploading to $server\" >&2 exit 0 fi echo \"quit\" >> $tempfile echo \"Synchronizing: Found $count files in local folder to upload.\" if ! ftp -n < $tempfile ; then echo \"Done. All files synchronized up with $server\" touch $timestamp fi exit 0"
        },
        {
            "filename": "file_86.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_86.sh",
            "content": "#!/bin/sh # ftpsyncdown - Given a source directory on a remote FTP server, # download all the files therein into the current directory. tempfile=\"/tmp/ftpsyncdown.$$\" trap \"/bin/rm -f $tempfile\" 0 1 15 # zap tempfile on exit if [ $# -eq 0 ] ; then echo \"Usage: $0 user@host { remotedir }\" >&2 exit 1 fi user=\"$(echo $1 | cut -d@ -f1)\" server=\"$(echo $1 | cut -d@ -f2)\" echo \"open $server\" > $tempfile echo \"user $user\" >> $tempfile if [ $# -gt 1 ] ; then echo \"cd $2\" >> $tempfile fi cat << EOF >> $tempfile prompt mget * quit EOF echo \"Synchronizing: Downloading files\" if ! ftp -n < $tempfile ; then echo \"Done. All files on $server downloaded to $(pwd)\" fi exit 0"
        },
        {
            "filename": "file_87.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_87.sh",
            "content": "#!/bin/sh # sftpsync - Given a target directory on an sftp server, make sure that # all new or modified files are uploaded to the remote system. Uses # a timestamp file ingeniously called .timestamp to keep track. timestamp=\".timestamp\" tempfile=\"/tmp/sftpsync.$$\" count=0 trap \"/bin/rm -f $tempfile\" 0 1 15 # zap tempfile on exit &sigs if [ $# -eq 0 ] ; then echo \"Usage: $0 user@host { remotedir }\" >&2 exit 1 fi user=\"$(echo $1 | cut -d@ -f1)\" server=\"$(echo $1 | cut -d@ -f2)\" if [ $# -gt 1 ] ; then echo \"cd $2\" >> $tempfile fi if [ ! -f $timestamp ] ; then # no timestamp file, upload all files for filename in * do if [ -f \"$filename\" ] ; then echo \"put -P \\\"$filename\\\"\" >> $tempfile count=$(( $count + 1 )) fi done else for filename in $(find . -newer $timestamp -type f -print) do echo \"put -P \\\"$filename\\\"\" >> $tempfile count=$(( $count + 1 )) done fi if [ $count -eq 0 ] ; then echo \"$0: No files require uploading to $server\" >&2 exit 1 fi echo \"quit\" >> $tempfile echo \"Synchronizing: Found $count files in local folder to upload.\" if ! sftp -b $tempfile \"$user@$server\" ; then echo \"Done. All files synchronized up with $server\" touch $timestamp fi exit 0"
        },
        {
            "filename": "file_88.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_88.sh",
            "content": "#!/bin/sh # ssync - If anything's changed, Create a tarball and sync a remote # directory via sftp using sftpsync. sftpacct=\"taylor@intuitive.com\" tarballname=\"AllFiles.tgz\" localsource=\"$HOME/scripts\" remotedir=\"shellhacks/scripts\" timestamp=\".timestamp\" sftpsync=\"$HOME/scripts/sftpsync\" # first off, let's see if the local dir exists and has files. if [ ! -d $localsource ] ; then echo \"$0: Error: directory $localsource doesn't exist?\" >&2 exit 1 fi cd $localsource # now let's count files to ensure something's changed: if [ ! -f $timestamp ] ; then for filename in * do if [ -f \"$filename\" ] ; then count=$(( $count + 1 )) fi done else count=$(find . -newer $timestamp -type f -print | wc -l) fi if [ ${count:-0} -eq 0 ] ; then echo \"$0: No files found in $localsource to sync with remote.\" >&2 exit 0 fi echo \"Making tarball archive file for upload\" tar -czf $tarballname ./* # Done! Now let's switch to the sftpsync script exec $sftpsync $sftpacct $remotedir"
        },
        {
            "filename": "file_89.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_89.sh",
            "content": "#!/bin/sh # webaccess - analyze an Apache-format access_log file, extracting # useful and interesting statistics bytes_in_gb=1048576 scriptbc=\"$HOME/bin/scriptbc\" nicenumber=\"$HOME/bin/nicenumber\" host=\"intuitive.com\" if [ $# -eq 0 -o ! -f \"$1\" ] ; then echo \"Usage: $(basename $0) logfile\" >&2 exit 1 fi firstdate=\"$(head -1 \"$1\" | awk '{print $4}' | sed 's/\\[//')\" lastdate=\"$(tail -1 \"$1\" | awk '{print $4}' | sed 's/\\[//')\" echo \"Results of analyzing log file $1\" echo \"\" echo \" Start date: $(echo $firstdate|sed 's/:/ at /')\" echo \" End date: $(echo $lastdate|sed 's/:/ at /')\" hits=\"$(wc -l < \"$1\" | sed 's/[^[:digit:]]//g')\" echo \" Hits: $($nicenumber $hits) (total accesses)\" pages=\"$(grep -ivE '(.txt|.gif|.jpg|.png)' \"$1\" | wc -l | sed 's/[^[:digit:]]//g')\" echo \" Pageviews: $($nicenumber $pages) (hits minus graphics)\" totalbytes=\"$(awk '{sum+=$10} END {print sum}' \"$1\")\" echo -n \" Transferred: $($nicenumber $totalbytes) bytes \" if [ $totalbytes -gt $bytes_in_gb ] ; then echo \"($($scriptbc $totalbytes / $bytes_in_gb) GB)\" elif [ $totalbytes -gt 1024 ] ; then echo \"($($scriptbc $totalbytes / 1024) MB)\" else echo \"\" fi # now let's scrape the log file for some useful data: echo \"\" echo \"The ten most popular pages were:\" awk '{print $7}' \"$1\" | grep -ivE '(.gif|.jpg|.png)' | \\ sed 's/\\/$//g' | sort | \\ uniq -c | sort -rn | head -10 echo \"\" echo \"The ten most common referrer URLs were:\" awk '{print $11}' \"$1\" | \\ grep -vE \"(^\"-\"$|/www.$host|/$host)\" | \\ sort | uniq -c | sort -rn | head -10 echo \"\" exit 0"
        },
        {
            "filename": "file_9.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_9.sh",
            "content": "#!/bin/sh # scriptbc - wrapper for 'bc' that returns the value of a formula if [ $1 = \"-p\" ] ; then precision=$2 shift 2 else precision=2 # default fi bc -q -l << EOF scale=$precision $* quit EOF exit 0"
        },
        {
            "filename": "file_90.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_90.sh",
            "content": "#!/bin/sh # enginehits - extract and analyze search engine traffic in the # referrer field of a Common Log Format access log for a # specified domain name. maxmatches=25 count=0 temp=\"/tmp/$(basename $0).$$\" trap \"/bin/rm -f $temp\" 0 if [ $# -eq 0 -o ! -f \"$1\" ] ; then echo \"Usage: $(basename $0) logfile searchdomain\" >&2 exit 1 fi for URL in $(awk '{ if (length($11) > 4) { print $11 } }' \"$1\" | \\ grep $2) do args=\"$(echo $URL | cut -d\\? -f2 | tr '&' '\\n' | \\ grep -E '(^q=|^sid=|^p=|query=|item=|ask=|name=|topic=)' | \\ cut -d= -f2)\" echo $args | sed -e 's/+/ /g' -e 's/\"//g' >> $temp count=\"$(( $count + 1 ))\" done echo \"Search engine referrer info extracted $2 searches from ${1}:\" sort $temp | uniq -c | sort -rn | head -$maxmatches | sed 's/^/ /g' echo \"\" echo Scanned $count $2 entries in log file out of $(wc -l < \"$1\") total. exit 0"
        },
        {
            "filename": "file_91.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_91.sh",
            "content": "#!/bin/sh # searchinfo - extract and analyze search engine traffic indicated in the # referrer field of a Common Log Format access log. host=\"intuitive.com\" # change to your domain, as desired maxmatches=20 count=0 temp=\"/tmp/$(basename $0).$$\" trap \"/bin/rm -f $temp\" 0 if [ $# -eq 0 ] ; then echo \"Usage: $(basename $0) logfile\" >&2 exit 1 fi if [ ! -r \"$1\" ] ; then echo \"Error: can't open file $1 for analysis.\" >&2 exit 1 fi for URL in $(awk '{ if (length($11) > 4) { print $11 } }' \"$1\" | \\ grep -vE \"(/www.$host|/$host)\" | grep '?') do searchengine=\"$(echo $URL | cut -d/ -f3 | rev | cut -d. -f1-2 | rev)\" args=\"$(echo $URL | cut -d\\? -f2 | tr '&' '\\n' | \\ grep -E '(^q=|^sid=|^p=|query=|item=|ask=|name=|topic=)' | \\ sed -e 's/+/ /g' -e 's/%20/ /g' -e 's/\"//g' | cut -d= -f2)\" if [ ! -z \"$args\" ] ; then echo \"${searchengine}: $args\" >> $temp else # no well-known match, show entire GET string instead... echo \"${searchengine} $(echo $URL | cut -d\\? -f2)\" >> $temp fi count=\"$(( $count + 1 ))\" done echo \"Search engine referrer info extracted from ${1}:\" sort $temp | uniq -c | sort -rn | head -$maxmatches | sed 's/^/ /g' echo \"\" echo Scanned $count entries in log file out of $(wc -l < \"$1\") total. exit 0"
        },
        {
            "filename": "file_92.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_92.sh",
            "content": "#!/bin/sh # weberrors - scan through an Apache error_log file and report the # most important errors, then list additional entries. temp=\"/tmp/$(basename $0).$$\" # the following three lines will need to be customized for your own # installation for this script to work best. htdocs=\"/usr/local/etc/httpd/htdocs/\" myhome=\"/usr/home/taylor/\" cgibin=\"/usr/local/etc/httpd/cgi-bin/\" sedstr=\"s/^/ /g;s|$htdocs|[htdocs] |;s|$myhome|[homedir] |;s|$cgibin|[cgi-bin] |\" screen=\"(File does not exist|Invalid error redirect|premature EOF|Premature end of script|script not found)\" length=5 # entries per category to display checkfor() { grep \"${2}:\" \"$1\" | awk '{print $NF}' |\\ sort | uniq -c | sort -rn | head -$length | sed \"$sedstr\" > $temp if [ $(wc -l < $temp) -gt 0 ] ; then echo \"\" echo \"$2 errors:\" cat $temp fi } trap \"/bin/rm -f $temp\" 0 if [ \"$1\" = \"-l\" ] ; then length=$2; shift 2 fi if [ $# -ne 1 -o ! -r \"$1\" ] ; then echo \"Usage: $(basename $0) [-l len] error_log\" >&2 exit 1 fi echo Input file $1 has $(wc -l < \"$1\") entries. start=\"$(grep -E '\\[.*:.*:.*\\]' \"$1\" | head -1 | awk '{print $1\" \"$2\" \"$3\" \"$4\" \"$5 }')\" end=\"$(grep -E '\\[.*:.*:.*\\]' \"$1\" | tail -1 | awk '{print $1\" \"$2\" \"$3\" \"$4\" \"$5 }')\" echo -n \"Entries from $start to $end\" echo \"\" ### Check for various common and well-known errors: checkfor \"$1\" \"File does not exist\" checkfor \"$1\" \"Invalid error redirection directive\" checkfor \"$1\" \"premature EOF\" checkfor \"$1\" \"script not found or unable to stat\" checkfor \"$1\" \"Premature end of script headers\" grep -vE \"$screen\" \"$1\" | grep \"\\[error\\]\" | grep \"\\[client \" | \\ sed 's/\\[error\\]/\\`/' | cut -d\\` -f2 | cut -d\\ -f4- | \\ sort | uniq -c | sort -rn | sed 's/^/ /' | head -$length > $temp if [ $(wc -l < $temp) -gt 0 ] ; then echo \"\" echo \"Additional error messages in log file:\" cat $temp fi echo \"\" echo \"And non-error messages occurring in the log file:\" grep -vE \"$screen\" \"$1\" | grep -v \"\\[error\\]\" | \\ sort | uniq -c | sort -rn | \\ sed 's/^/ /' | head -$length exit 0"
        },
        {
            "filename": "file_93.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_93.sh",
            "content": "#!/bin/sh # remotebackup - This script takes a list of files and directories, # builds a single archive, compressed, then emails it off to a # remote archive site for safekeeping. It's intended to be run # every night for critical user files, but not intended to # replace a more rigorous backup scheme. You should strongly # consider using 'unpacker' on the remote end too. uuencode=\"/usr/bin/uuencode\" outfile=\"/tmp/rb.$$.tgz\" outfname=\"backup.$(date +%y%m%d).tgz\" infile=\"/tmp/rb.$$.in\" trap \"/bin/rm -f $outfile $infile\" 0 if [ $# -ne 2 -a $# -ne 3 ] ; then echo \"Usage: $(basename $0) backup-file-list remoteaddr {targetdir}\" >&2 exit 1 fi if [ ! -s \"$1\" ] ; then echo \"Error: backup list $1 is empty or missing\" >&2 exit 1 fi # Scan entries and build fixed infile list. This expands wildcards # and escapes spaces in filenames with a backslash, producing a # change: \"this file\" becomes this\\ file so quotes are not needed. while read entry; do echo \"$entry\" | sed -e 's/ /\\\\ /g' >> $infile done < \"$1\" # The actual work of building the archive, encoding it, and sending it tar czf - $(cat $infile) | \\ $uuencode $outfname | \\ mail -s \"${3:-Backup archive for $(date)}\" \"$2\" echo \"Done. $(basename $0) backed up the following files:\" sed 's/^/ /' $infile echo -n \"and mailed them to $2 \" if [ ! -z \"$3\" ] ; then echo \"with requested target directory $3\" else echo \"\" fi exit 0"
        },
        {
            "filename": "file_94.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_94.sh",
            "content": "#!/bin/sh # trimmailbox - a simple script to ensure that only the four most recent # messages remain in the users mailbox. Works with Berkeley Mail # (aka Mailx or mail): will need modifications for other mailers!! keep=4 # by default, let's just keep around the four most recent messages totalmsgs=\"$(echo 'x' | mail | sed -n '2p' | awk '{print $2}')\" if [ $totalmsgs -lt $keep ] ; then exit 0 # nothing to do fi topmsg=\"$(( $totalmsgs - $keep ))\" mail > /dev/null << EOF d1-$topmsg q EOF exit 0"
        },
        {
            "filename": "file_95.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_95.sh",
            "content": "#!/bin/sh # unpacker - given an input stream with a uuencoded archive from # the remotearchive script, this unpacks and installs the archive. temp=\"/tmp/$(basename $0).$$\" home=\"${HOME:-/usr/home/taylor}\" mydir=\"$home/archive\" webhome=\"/usr/home/taylor/web\" notify=\"taylor@intuitive.com\" ( cat - > $temp # shortcut to save stdin to a file target=\"$(grep \"^Subject: \" $temp | cut -d\\ -f2-)\" echo $(basename $0): Saved as $temp, with $(wc -l < $temp) lines echo \"message subject=\\\"$target\\\"\" # move into the temporary unpacking directory... if [ ! -d $mydir ] ; then echo \"Warning: archive dir $mydir not found. Unpacking into $home\" cd $home mydir=$home # for later use else cd $mydir fi # extract the resultant filename from the uuencoded file... fname=\"$(awk '/^begin / {print $3}' $temp)\" uudecode $temp if [ ! -z \"$(echo $target | grep 'Backup archive for')\" ] ; then # all done. no further unpacking needed. echo \"Saved archive as $mydir/$fname\" exit 0 fi # Otherwise, we have a uudecoded file and a target directory if [ \"$(echo $target|cut -c1)\" = \"/\" -o \"$(echo $target|cut -c1-2)\" = \"..\" ] then echo \"Invalid target directory $target. Can't use '/' or '..'\" exit 0 fi targetdir=\"$webhome/$target\" if [ ! -d $targetdir ] ; then echo \"Invalid target directory $target. Can't find in $webhome\" exit 0 fi gunzip $fname fname=\"$(echo $fname | sed 's/.tgz$/.tar/g')\" # are the tar archive filenames in a valid format? if [ ! -z \"$(tar tf $fname | awk '{print $8}' | grep '^/')\" ] ; then echo \"Can't unpack archive: filenames are absolute.\" exit 0 fi echo \"\" echo \"Unpacking archive $fname into $targetdir\" cd $targetdir tar xvf $mydir/$fname | sed 's/^/ /g' echo \"done!\" ) 2>&1 | mail -s \"Unpacker output $(date)\" $notify exit 0"
        },
        {
            "filename": "file_96.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_96.sh",
            "content": "#!/bin/sh # xferlog - analyze and summarize the FTP transfer log. A good doc # detailing the log format: http://aolserver.am.net/docs/2.3/ftp-ch4.htm stdxferlog=\"/var/log/xferlog\" temp=\"/tmp/$(basename $0).$$\" nicenum=\"$HOME/bin/nicenumber\" trap \"/bin/rm -f $temp\" 0 extract() { # called with $1 = desired accessmode, $2 = section name for output if [ ! -z \"$(echo $accessmode | grep $1)\" ] ; then echo \"\" ; echo \"$2\" if [ \"$1\" = \"a\" -o \"$1\" = \"g\" ] ; then echo \" common account (entered password) values:\" else echo \" user accounts accessing server: \" fi awk \"\\$13 == \\\"$1\\\" { print \\$14 }\" $log | sort | \\ uniq -c | sort -rn | head -10 | sed 's/^/ /' awk \"\\$13 == \\\"$1\\\" && \\$12 == \\\"o\\\" { print \\$9 }\" $log | sort | \\ uniq -c | sort -rn | head -10 | sed 's/^/ /' > $temp if [ -s $temp ] ; then echo \" files downloaded from server:\" ; cat $temp fi awk \"\\$13 == \\\"$1\\\" && \\$12 == \\\"i\\\" { print \\$9 }\" $log | sort | \\ uniq -c | sort -rn | head -10 | sed 's/^/ /' > $temp if [ -s $temp ] ; then echo \" files uploaded to server:\" ; cat $temp fi fi } ###### the main script block case $# in 0 ) log=$stdxferlog ;; 1 ) log=\"$1\" ;; * ) echo \"Usage: $(basename $0) {xferlog name}\" >&2 exit 1 esac if [ ! -r $log ] ; then echo \"$(basename $0): can't read $log.\" >&2 exit 1 fi # Ascertain whether it's an abbreviated or standard ftp log file format. If # it's the abbreviated format, output some minimal statistical data and quit: # the format is too difficult to analyze in a short script, unfortunately. if [ ! -z $(awk '$6 == \"get\" { short=1 } END{ print short }' $log) ] ; then bytesin=\"$(awk 'BEGIN{sum=0} $6 == \"get\" {sum += $9} END{ print sum }' $log )\" bytesout=\"$(awk 'BEGIN{sum=0} $6 == \"put\" {sum += $9} END{ print sum }' $log )\" echo -n \"Abbreviated ftpd xferlog from \" echo -n $(head -1 $log | awk '{print $1, $2, $3 }') echo \" to $(tail -1 $log | awk '{print $1, $2, $3}')\" echo \" bytes in: $($nicenum $bytesin)\" echo \" bytes out: $($nicenum $bytesout)\" exit 0 fi bytesin=\"$(awk 'BEGIN{sum=0} $12 == \"i\" {sum += $8} END{ print sum }' $log )\" bytesout=\"$(awk 'BEGIN{sum=0} $12 == \"o\" {sum += $8} END{ print sum }' $log )\" time=\"$(awk 'BEGIN{sum=0} {sum += $6} END{ print sum }' $log)\" echo -n \"Summary of xferlog from \" echo -n $(head -1 $log | awk '{print $1, $2, $3, $4, $5 }') echo \" to $(tail -1 $log | awk '{print $1, $2, $3, $4, $5}')\" echo \" bytes in: $($nicenum $bytesin)\" echo \" bytes out: $($nicenum $bytesout)\" echo \" transfer time: $time seconds\" accessmode=\"$(awk '{print $13}' $log | sort -u)\" extract \"a\" \"Anonymous Access\" extract \"g\" \"Guest Account Access\" extract \"r\" \"Real User Account Access\" exit 0"
        },
        {
            "filename": "file_97.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_97.sh",
            "content": "#!/bin/sh # getstats - every 'n' minutes, grab netstats values (via crontab) logfile=\"/var/log/netstat.log\" temp=\"/tmp/getstats.tmp\" trap \"/bin/rm -f $temp\" 0 ( echo -n \"time=$(date +%s);\" netstat -s -p tcp > $temp sent=\"$(grep 'packets sent' $temp | cut -d\\ -f1 | sed 's/[^[:digit:]]//g')\" resent=\"$(grep 'retransmitted' $temp | cut -d\\ -f1 | sed 's/[^[:digit:]]//g')\" received=\"$(grep 'packets received$' $temp | cut -d\\ -f1 | sed 's/[^[:digit:]]//g')\" dupacks=\"$(grep 'duplicate acks' $temp | cut -d\\ -f1 | sed 's/[^[:digit:]]//g')\" outoforder=\"$(grep 'out-of-order packets' $temp | cut -d\\ -f1 | sed 's/[^[:digit:]]//g')\" connectreq=\"$(grep 'connection requests' $temp | cut -d\\ -f1 | sed 's/[^[:digit:]]//g')\" connectacc=\"$(grep 'connection accepts' $temp | cut -d\\ -f1 | sed 's/[^[:digit:]]//g')\" retmout=\"$(grep 'retransmit timeouts' $temp | cut -d\\ -f1 | sed 's/[^[:digit:]]//g')\" echo -n \"snt=$sent;re=$resent;rec=$received;dup=$dupacks;\" echo -n \"oo=$outoforder;creq=$connectreq;cacc=$connectacc;\" echo \"reto=$retmout\" ) >> $logfile exit 0"
        },
        {
            "filename": "file_98.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_98.sh",
            "content": "#!/bin/sh # netperf - analyze the netstat running performance log, identifying important # results and trends. log=\"/var/log/netstat.log\" scriptbc=\"$HOME/bin/scriptbc\" stats=\"/tmp/netperf.stats.$$\" awktmp=\"/tmp/netperf.awk.$$\" trap \"/bin/rm -f $awktmp $stats\" 0 if [ ! -r $log ] ; then echo \"Error: can't read netstat log file $log\" >&2 exit 1 fi # first, report the basic statistics of the latest entry in the log file... eval $(tail -1 $log) # all values turn into shell variables rep=\"$($scriptbc -p 3 $re/$snt\\*100)\" repn=\"$($scriptbc -p 4 $re/$snt\\*10000 | cut -d. -f1)\" repn=\"$(( $repn / 100 ))\" retop=\"$($scriptbc -p 3 $reto/$snt\\*100)\"; retopn=\"$($scriptbc -p 4 $reto/$snt\\*10000 | cut -d. -f1)\" retopn=\"$(( $retopn / 100 ))\" dupp=\"$($scriptbc -p 3 $dup/$rec\\*100)\"; duppn=\"$($scriptbc -p 4 $dup/$rec\\*10000 | cut -d. -f1)\" duppn=\"$(( $duppn / 100 ))\" oop=\"$($scriptbc -p 3 $oo/$rec\\*100)\"; oopn=\"$($scriptbc -p 4 $oo/$rec\\*10000 | cut -d. -f1)\" oopn=\"$(( $oopn / 100 ))\" echo \"Netstat is currently reporting the following:\" echo -n \" $snt packets sent, with $re retransmits ($rep%) \" echo \"and $reto retransmit timeouts ($retop%)\" echo -n \" $rec packets received, with $dup dupes ($dupp%)\" echo \" and $oo out of order ($oop%)\" echo \" $creq total connection requests, of which $cacc were accepted\" echo \"\" ## now let's see if there are any important problems to flag if [ $repn -ge 5 ] ; then echo \"*** Warning: Retransmits of >= 5% indicates a problem \" echo \"(gateway or router flooded?)\" fi if [ $retopn -ge 5 ] ; then echo \"*** Warning: Transmit timeouts of >= 5% indicates a problem \" echo \"(gateway or router flooded?)\" fi if [ $duppn -ge 5 ] ; then echo \"*** Warning: Duplicate receives of >= 5% indicates a problem \" echo \"(probably on the other end)\" fi if [ $oopn -ge 5 ] ; then echo \"*** Warning: Out of orders of >= 5% indicates a problem \" echo \"(busy network or router/gateway flood)\" fi # now let's look at some historical trends... echo \"analyzing trends....\" while read logline ; do eval \"$logline\" rep2=\"$($scriptbc -p 4 $re / $snt \\* 10000 | cut -d. -f1)\" retop2=\"$($scriptbc -p 4 $reto / $snt \\* 10000 | cut -d. -f1)\" dupp2=\"$($scriptbc -p 4 $dup / $rec \\* 10000 | cut -d. -f1)\" oop2=\"$($scriptbc -p 4 $oo / $rec \\* 10000 | cut -d. -f1)\" echo \"$rep2 $retop2 $dupp2 $oop2\" >> $stats done < $log echo \"\" # now calculate some statistics, and compare them to the current values cat << \"EOF\" > $awktmp { rep += $1; retop += $2; dupp += $3; oop += $4 } END { rep /= 100; retop /= 100; dupp /= 100; oop /= 100; print \"reps=\"int(rep/NR) \";retops=\" int(retop/NR) \\ \";dupps=\" int(dupp/NR) \";oops=\"int(oop/NR) } EOF eval $(awk -f $awktmp < $stats) if [ $repn -gt $reps ] ; then echo \"*** Warning: Retransmit rate is currently higher than average.\" echo \" (average is $reps% and current is $repn%)\" fi if [ $retopn -gt $retops ] ; then echo \"*** Warning: Transmit timeouts are currently higher than average.\" echo \" (average is $retops% and current is $retopn%)\" fi if [ $duppn -gt $dupps ] ; then echo \"*** Warning: Duplicate receives are currently higher than average.\" echo \" (average is $dupps% and current is $duppn%)\" fi if [ $oopn -gt $oops ] ; then echo \"*** Warning: Out of orders are currently higher than average.\" echo \" (average is $oops% and current is $oopn%)\" fi echo \\(analyzed $(wc -l < $stats) netstat log entries for calculations\\) exit 0"
        },
        {
            "filename": "file_99.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\100-shell-script-examples\\file_99.sh",
            "content": "#!/bin/sh # renicename - renice the job that matches the specified name. user=\"\"; tty=\"\"; showpid=0; niceval=\"+1\" # initialize while getopts \"n:u:t:p\" opt; do case $opt in n ) niceval=\"$OPTARG\"; ;; u ) if [ ! -z \"$tty\" ] ; then echo \"$0: error: -u and -t are mutually exclusive.\" >&2 exit 1 fi user=$OPTARG ;; t ) if [ ! -z \"$user\" ] ; then echo \"$0: error: -u and -t are mutually exclusive.\" >&2 exit 1 fi tty=$OPTARG ;; p ) showpid=1; ;; ? ) echo \"Usage: $0 [-n niceval] [-u user|-t tty] [-p] pattern\" >&2 echo \"Default niceval change is \\\"$niceval\\\" (plus is lower\" >&2 echo \"priority, minus is higher, but only root can go below 0)\" >&2 exit 1 esac done shift $(($OPTIND - 1)) # eat all the parsed arguments if [ $# -eq 0 ] ; then echo \"Usage: $0 [-n niceval] [-u user|-t tty] [-p] pattern\" >&2 exit 1 fi if [ ! -z \"$tty\" ] ; then pid=$(ps cu -t $tty | awk \"/ $1/ { print \\\\$2 }\") elif [ ! -z \"$user\" ] ; then pid=$(ps cu -U $user | awk \"/ $1/ { print \\\\$2 }\") else pid=$(ps cu -U ${USER:-LOGNAME} | awk \"/ $1/ { print \\$2 }\") fi if [ -z \"$pid\" ] ; then echo \"$0: no processes match pattern $1\" >&2 ; exit 1 elif [ ! -z \"$(echo $pid | grep ' ')\" ] ; then echo \"$0: more than one process matches pattern ${1}:\" if [ ! -z \"$tty\" ] ; then runme=\"ps cu -t $tty\" elif [ ! -z \"$user\" ] ; then runme=\"ps cu -U $user\" else runme=\"ps cu -U ${USER:-LOGNAME}\" fi eval $runme | \\ awk \"/ $1/ { printf \\\" user %-8.8s pid %-6.6s job %s\\n\\\", \\ \\$1,\\$2,\\$11 }\" echo \"Use -u user or -t tty to narrow down your selection criteria.\" elif [ $showpid -eq 1 ] ; then echo $pid else # ready to go: let's do it! echo -n \"Renicing job \\\"\" echo -n $(ps cp $pid | sed 's/ [ ]*/ /g' | tail -1 | cut -d\\ -f5-) echo \"\\\" ($pid)\" renice $niceval $pid fi exit 0"
        },
        {
            "filename": "file_114.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\file_114.sh",
            "content": "#!/usr/bin/env sh VER=3.1.0 PROJECT_NAME=\"acme.sh\" PROJECT_ENTRY=\"acme.sh\" PROJECT=\"https://github.com/acmesh-official/$PROJECT_NAME\" DEFAULT_INSTALL_HOME=\"$HOME/.$PROJECT_NAME\" _WINDOWS_SCHEDULER_NAME=\"$PROJECT_NAME.cron\" _SCRIPT_=\"$0\" _SUB_FOLDER_NOTIFY=\"notify\" _SUB_FOLDER_DNSAPI=\"dnsapi\" _SUB_FOLDER_DEPLOY=\"deploy\" _SUB_FOLDERS=\"$_SUB_FOLDER_DNSAPI $_SUB_FOLDER_DEPLOY $_SUB_FOLDER_NOTIFY\" CA_LETSENCRYPT_V2=\"https://acme-v02.api.letsencrypt.org/directory\" CA_LETSENCRYPT_V2_TEST=\"https://acme-staging-v02.api.letsencrypt.org/directory\" CA_BUYPASS=\"https://api.buypass.com/acme/directory\" CA_BUYPASS_TEST=\"https://api.test4.buypass.no/acme/directory\" CA_ZEROSSL=\"https://acme.zerossl.com/v2/DV90\" _ZERO_EAB_ENDPOINT=\"https://api.zerossl.com/acme/eab-credentials-email\" CA_SSLCOM_RSA=\"https://acme.ssl.com/sslcom-dv-rsa\" CA_SSLCOM_ECC=\"https://acme.ssl.com/sslcom-dv-ecc\" CA_GOOGLE=\"https://dv.acme-v02.api.pki.goog/directory\" CA_GOOGLE_TEST=\"https://dv.acme-v02.test-api.pki.goog/directory\" DEFAULT_CA=$CA_ZEROSSL DEFAULT_STAGING_CA=$CA_LETSENCRYPT_V2_TEST CA_NAMES=\" ZeroSSL.com,zerossl LetsEncrypt.org,letsencrypt LetsEncrypt.org_test,letsencrypt_test,letsencrypttest BuyPass.com,buypass BuyPass.com_test,buypass_test,buypasstest SSL.com,sslcom Google.com,google Google.com_test,googletest,google_test \" CA_SERVERS=\"$CA_ZEROSSL,$CA_LETSENCRYPT_V2,$CA_LETSENCRYPT_V2_TEST,$CA_BUYPASS,$CA_BUYPASS_TEST,$CA_SSLCOM_RSA,$CA_GOOGLE,$CA_GOOGLE_TEST\" DEFAULT_USER_AGENT=\"$PROJECT_NAME/$VER ($PROJECT)\" DEFAULT_ACCOUNT_KEY_LENGTH=ec-256 DEFAULT_DOMAIN_KEY_LENGTH=ec-256 DEFAULT_OPENSSL_BIN=\"openssl\" VTYPE_HTTP=\"http-01\" VTYPE_DNS=\"dns-01\" VTYPE_ALPN=\"tls-alpn-01\" ID_TYPE_DNS=\"dns\" ID_TYPE_IP=\"ip\" LOCAL_ANY_ADDRESS=\"0.0.0.0\" DEFAULT_RENEW=60 NO_VALUE=\"no\" W_DNS=\"dns\" W_ALPN=\"alpn\" DNS_ALIAS_PREFIX=\"=\" MODE_STATELESS=\"stateless\" STATE_VERIFIED=\"verified_ok\" NGINX=\"nginx:\" NGINX_START=\"#ACME_NGINX_START\" NGINX_END=\"#ACME_NGINX_END\" BEGIN_CSR=\"-----BEGIN [NEW ]\\{0,4\\}CERTIFICATE REQUEST-----\" END_CSR=\"-----END [NEW ]\\{0,4\\}CERTIFICATE REQUEST-----\" BEGIN_CERT=\"-----BEGIN CERTIFICATE-----\" END_CERT=\"-----END CERTIFICATE-----\" CONTENT_TYPE_JSON=\"application/jose+json\" RENEW_SKIP=2 CODE_DNS_MANUAL=3 B64CONF_START=\"__ACME_BASE64__START_\" B64CONF_END=\"__ACME_BASE64__END_\" ECC_SEP=\"_\" ECC_SUFFIX=\"${ECC_SEP}ecc\" LOG_LEVEL_1=1 LOG_LEVEL_2=2 LOG_LEVEL_3=3 DEFAULT_LOG_LEVEL=\"$LOG_LEVEL_2\" DEBUG_LEVEL_1=1 DEBUG_LEVEL_2=2 DEBUG_LEVEL_3=3 DEBUG_LEVEL_DEFAULT=$DEBUG_LEVEL_2 DEBUG_LEVEL_NONE=0 DOH_CLOUDFLARE=1 DOH_GOOGLE=2 DOH_ALI=3 DOH_DP=4 HIDDEN_VALUE=\"[hidden](please add '--output-insecure' to see this value)\" SYSLOG_ERROR=\"user.error\" SYSLOG_INFO=\"user.info\" SYSLOG_DEBUG=\"user.debug\" #error SYSLOG_LEVEL_ERROR=3 #info SYSLOG_LEVEL_INFO=6 #debug SYSLOG_LEVEL_DEBUG=7 #debug2 SYSLOG_LEVEL_DEBUG_2=8 #debug3 SYSLOG_LEVEL_DEBUG_3=9 SYSLOG_LEVEL_DEFAULT=$SYSLOG_LEVEL_ERROR #none SYSLOG_LEVEL_NONE=0 NOTIFY_LEVEL_DISABLE=0 NOTIFY_LEVEL_ERROR=1 NOTIFY_LEVEL_RENEW=2 NOTIFY_LEVEL_SKIP=3 NOTIFY_LEVEL_DEFAULT=$NOTIFY_LEVEL_RENEW NOTIFY_MODE_BULK=0 NOTIFY_MODE_CERT=1 NOTIFY_MODE_DEFAULT=$NOTIFY_MODE_BULK _BASE64_ENCODED_CFGS=\"Le_PreHook Le_PostHook Le_RenewHook Le_Preferred_Chain Le_ReloadCmd\" _DEBUG_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/How-to-debug-acme.sh\" _PREPARE_LINK=\"https://github.com/acmesh-official/acme.sh/wiki/Install-preparations\" _STATELESS_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/Stateless-Mode\" _DNS_ALIAS_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/DNS-alias-mode\" _DNS_MANUAL_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/dns-manual-mode\" _DNS_API_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/dnsapi\" _NOTIFY_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/notify\" _SUDO_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/sudo\" _REVOKE_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/revokecert\" _ZEROSSL_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/ZeroSSL.com-CA\" _SSLCOM_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/SSL.com-CA\" _SERVER_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/Server\" _PREFERRED_CHAIN_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/Preferred-Chain\" _VALIDITY_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/Validity\" _DNSCHECK_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/dnscheck\" _DNS_MANUAL_ERR=\"The dns manual mode can not renew automatically, you must issue it again manually. You'd better use the other modes instead.\" _DNS_MANUAL_WARN=\"It seems that you are using dns manual mode. please take care: $_DNS_MANUAL_ERR\" _DNS_MANUAL_ERROR=\"It seems that you are using dns manual mode. Read this link first: $_DNS_MANUAL_WIKI\" __INTERACTIVE=\"\" if [ -t 1 ]; then __INTERACTIVE=\"1\" fi __green() { if [ \"${__INTERACTIVE}${ACME_NO_COLOR:-0}\" = \"10\" -o \"${ACME_FORCE_COLOR}\" = \"1\" ]; then printf '\\33[1;32m%b\\33[0m' \"$1\" return fi printf -- \"%b\" \"$1\" } __red() { if [ \"${__INTERACTIVE}${ACME_NO_COLOR:-0}\" = \"10\" -o \"${ACME_FORCE_COLOR}\" = \"1\" ]; then printf '\\33[1;31m%b\\33[0m' \"$1\" return fi printf -- \"%b\" \"$1\" } _printargs() { _exitstatus=\"$?\" if [ -z \"$NO_TIMESTAMP\" ] || [ \"$NO_TIMESTAMP\" = \"0\" ]; then printf -- \"%s\" \"[$(date)] \" fi if [ -z \"$2\" ]; then printf -- \"%s\" \"$1\" else printf -- \"%s\" \"$1='$2'\" fi printf \"\\n\" # return the saved exit status return \"$_exitstatus\" } _dlg_versions() { echo \"Diagnosis versions: \" echo \"openssl:$ACME_OPENSSL_BIN\" if _exists \"${ACME_OPENSSL_BIN:-openssl}\"; then ${ACME_OPENSSL_BIN:-openssl} version 2>&1 else echo \"$ACME_OPENSSL_BIN doesn't exist.\" fi echo \"Apache:\" if [ \"$_APACHECTL\" ] && _exists \"$_APACHECTL\"; then $_APACHECTL -V 2>&1 else echo \"Apache doesn't exist.\" fi echo \"nginx:\" if _exists \"nginx\"; then nginx -V 2>&1 else echo \"nginx doesn't exist.\" fi echo \"socat:\" if _exists \"socat\"; then socat -V 2>&1 else _debug \"socat doesn't exist.\" fi } #class _syslog() { _exitstatus=\"$?\" if [ \"${SYS_LOG:-$SYSLOG_LEVEL_NONE}\" = \"$SYSLOG_LEVEL_NONE\" ]; then return fi _logclass=\"$1\" shift if [ -z \"$__logger_i\" ]; then if _contains \"$(logger --help 2>&1)\" \"-i\"; then __logger_i=\"logger -i\" else __logger_i=\"logger\" fi fi $__logger_i -t \"$PROJECT_NAME\" -p \"$_logclass\" \"$(_printargs \"$@\")\" >/dev/null 2>&1 return \"$_exitstatus\" } _log() { [ -z \"$LOG_FILE\" ] && return _printargs \"$@\" >>\"$LOG_FILE\" } _info() { _log \"$@\" if [ \"${SYS_LOG:-$SYSLOG_LEVEL_NONE}\" -ge \"$SYSLOG_LEVEL_INFO\" ]; then _syslog \"$SYSLOG_INFO\" \"$@\" fi _printargs \"$@\" } _err() { _syslog \"$SYSLOG_ERROR\" \"$@\" _log \"$@\" if [ -z \"$NO_TIMESTAMP\" ] || [ \"$NO_TIMESTAMP\" = \"0\" ]; then printf -- \"%s\" \"[$(date)] \" >&2 fi if [ -z \"$2\" ]; then __red \"$1\" >&2 else __red \"$1='$2'\" >&2 fi printf \"\\n\" >&2 return 1 } _usage() { __red \"$@\" >&2 printf \"\\n\" >&2 } __debug_bash_helper() { # At this point only do for --debug 3 if [ \"${DEBUG:-$DEBUG_LEVEL_NONE}\" -lt \"$DEBUG_LEVEL_3\" ]; then return fi # Return extra debug info when running with bash, otherwise return empty # string. if [ -z \"${BASH_VERSION}\" ]; then return fi # We are a bash shell at this point, return the filename, function name, and # line number as a string _dbh_saveIFS=$IFS IFS=\" \" # Must use eval or syntax error happens under dash. The eval should use # single quotes as older versions of busybox had a bug with double quotes and # eval. # Use 'caller 1' as we want one level up the stack as we should be called # by one of the _debug* functions eval '_dbh_called=($(caller 1))' IFS=$_dbh_saveIFS eval '_dbh_file=${_dbh_called[2]}' if [ -n \"${_script_home}\" ]; then # Trim off the _script_home directory name eval '_dbh_file=${_dbh_file#$_script_home/}' fi eval '_dbh_function=${_dbh_called[1]}' eval '_dbh_lineno=${_dbh_called[0]}' printf \"%-40s \" \"$_dbh_file:${_dbh_function}:${_dbh_lineno}\" } _debug() { if [ \"${LOG_LEVEL:-$DEFAULT_LOG_LEVEL}\" -ge \"$LOG_LEVEL_1\" ]; then _log \"$@\" fi if [ \"${SYS_LOG:-$SYSLOG_LEVEL_NONE}\" -ge \"$SYSLOG_LEVEL_DEBUG\" ]; then _syslog \"$SYSLOG_DEBUG\" \"$@\" fi if [ \"${DEBUG:-$DEBUG_LEVEL_NONE}\" -ge \"$DEBUG_LEVEL_1\" ]; then _bash_debug=$(__debug_bash_helper) _printargs \"${_bash_debug}$@\" >&2 fi } #output the sensitive messages _secure_debug() { if [ \"${LOG_LEVEL:-$DEFAULT_LOG_LEVEL}\" -ge \"$LOG_LEVEL_1\" ]; then if [ \"$OUTPUT_INSECURE\" = \"1\" ]; then _log \"$@\" else _log \"$1\" \"$HIDDEN_VALUE\" fi fi if [ \"${SYS_LOG:-$SYSLOG_LEVEL_NONE}\" -ge \"$SYSLOG_LEVEL_DEBUG\" ]; then _syslog \"$SYSLOG_DEBUG\" \"$1\" \"$HIDDEN_VALUE\" fi if [ \"${DEBUG:-$DEBUG_LEVEL_NONE}\" -ge \"$DEBUG_LEVEL_1\" ]; then if [ \"$OUTPUT_INSECURE\" = \"1\" ]; then _printargs \"$@\" >&2 else _printargs \"$1\" \"$HIDDEN_VALUE\" >&2 fi fi } _debug2() { if [ \"${LOG_LEVEL:-$DEFAULT_LOG_LEVEL}\" -ge \"$LOG_LEVEL_2\" ]; then _log \"$@\" fi if [ \"${SYS_LOG:-$SYSLOG_LEVEL_NONE}\" -ge \"$SYSLOG_LEVEL_DEBUG_2\" ]; then _syslog \"$SYSLOG_DEBUG\" \"$@\" fi if [ \"${DEBUG:-$DEBUG_LEVEL_NONE}\" -ge \"$DEBUG_LEVEL_2\" ]; then _bash_debug=$(__debug_bash_helper) _printargs \"${_bash_debug}$@\" >&2 fi } _secure_debug2() { if [ \"${LOG_LEVEL:-$DEFAULT_LOG_LEVEL}\" -ge \"$LOG_LEVEL_2\" ]; then if [ \"$OUTPUT_INSECURE\" = \"1\" ]; then _log \"$@\" else _log \"$1\" \"$HIDDEN_VALUE\" fi fi if [ \"${SYS_LOG:-$SYSLOG_LEVEL_NONE}\" -ge \"$SYSLOG_LEVEL_DEBUG_2\" ]; then _syslog \"$SYSLOG_DEBUG\" \"$1\" \"$HIDDEN_VALUE\" fi if [ \"${DEBUG:-$DEBUG_LEVEL_NONE}\" -ge \"$DEBUG_LEVEL_2\" ]; then if [ \"$OUTPUT_INSECURE\" = \"1\" ]; then _printargs \"$@\" >&2 else _printargs \"$1\" \"$HIDDEN_VALUE\" >&2 fi fi } _debug3() { if [ \"${LOG_LEVEL:-$DEFAULT_LOG_LEVEL}\" -ge \"$LOG_LEVEL_3\" ]; then _log \"$@\" fi if [ \"${SYS_LOG:-$SYSLOG_LEVEL_NONE}\" -ge \"$SYSLOG_LEVEL_DEBUG_3\" ]; then _syslog \"$SYSLOG_DEBUG\" \"$@\" fi if [ \"${DEBUG:-$DEBUG_LEVEL_NONE}\" -ge \"$DEBUG_LEVEL_3\" ]; then _bash_debug=$(__debug_bash_helper) _printargs \"${_bash_debug}$@\" >&2 fi } _secure_debug3() { if [ \"${LOG_LEVEL:-$DEFAULT_LOG_LEVEL}\" -ge \"$LOG_LEVEL_3\" ]; then if [ \"$OUTPUT_INSECURE\" = \"1\" ]; then _log \"$@\" else _log \"$1\" \"$HIDDEN_VALUE\" fi fi if [ \"${SYS_LOG:-$SYSLOG_LEVEL_NONE}\" -ge \"$SYSLOG_LEVEL_DEBUG_3\" ]; then _syslog \"$SYSLOG_DEBUG\" \"$1\" \"$HIDDEN_VALUE\" fi if [ \"${DEBUG:-$DEBUG_LEVEL_NONE}\" -ge \"$DEBUG_LEVEL_3\" ]; then if [ \"$OUTPUT_INSECURE\" = \"1\" ]; then _printargs \"$@\" >&2 else _printargs \"$1\" \"$HIDDEN_VALUE\" >&2 fi fi } _upper_case() { # shellcheck disable=SC2018,SC2019 tr '[a-z]' '[A-Z]' } _lower_case() { # shellcheck disable=SC2018,SC2019 tr '[A-Z]' '[a-z]' } _startswith() { _str=\"$1\" _sub=\"$2\" echo \"$_str\" | grep -- \"^$_sub\" >/dev/null 2>&1 } _endswith() { _str=\"$1\" _sub=\"$2\" echo \"$_str\" | grep -- \"$_sub\\$\" >/dev/null 2>&1 } _contains() { _str=\"$1\" _sub=\"$2\" echo \"$_str\" | grep -- \"$_sub\" >/dev/null 2>&1 } _hasfield() { _str=\"$1\" _field=\"$2\" _sep=\"$3\" if [ -z \"$_field\" ]; then _usage \"Usage: str field [sep]\" return 1 fi if [ -z \"$_sep\" ]; then _sep=\",\" fi for f in $(echo \"$_str\" | tr \"$_sep\" ' '); do if [ \"$f\" = \"$_field\" ]; then _debug2 \"'$_str' contains '$_field'\" return 0 #contains ok fi done _debug2 \"'$_str' does not contain '$_field'\" return 1 #not contains } # str index [sep] _getfield() { _str=\"$1\" _findex=\"$2\" _sep=\"$3\" if [ -z \"$_findex\" ]; then _usage \"Usage: str field [sep]\" return 1 fi if [ -z \"$_sep\" ]; then _sep=\",\" fi _ffi=\"$_findex\" while [ \"$_ffi\" -gt \"0\" ]; do _fv=\"$(echo \"$_str\" | cut -d \"$_sep\" -f \"$_ffi\")\" if [ \"$_fv\" ]; then printf -- \"%s\" \"$_fv\" return 0 fi _ffi=\"$(_math \"$_ffi\" - 1)\" done printf -- \"%s\" \"$_str\" } _exists() { cmd=\"$1\" if [ -z \"$cmd\" ]; then _usage \"Usage: _exists cmd\" return 1 fi if eval type type >/dev/null 2>&1; then eval type \"$cmd\" >/dev/null 2>&1 elif command >/dev/null 2>&1; then command -v \"$cmd\" >/dev/null 2>&1 else which \"$cmd\" >/dev/null 2>&1 fi ret=\"$?\" _debug3 \"$cmd exists=$ret\" return $ret } #a + b _math() { _m_opts=\"$@\" printf \"%s\" \"$(($_m_opts))\" } _h_char_2_dec() { _ch=$1 case \"${_ch}\" in a | A) printf \"10\" ;; b | B) printf \"11\" ;; c | C) printf \"12\" ;; d | D) printf \"13\" ;; e | E) printf \"14\" ;; f | F) printf \"15\" ;; *) printf \"%s\" \"$_ch\" ;; esac } _URGLY_PRINTF=\"\" if [ \"$(printf '\\x41')\" != 'A' ]; then _URGLY_PRINTF=1 fi _ESCAPE_XARGS=\"\" if _exists xargs && [ \"$(printf %s '\\\\x41' | xargs printf)\" = 'A' ]; then _ESCAPE_XARGS=1 fi _h2b() { if _exists xxd; then if _contains \"$(xxd --help 2>&1)\" \"assumes -c30\"; then if xxd -r -p -c 9999 2>/dev/null; then return fi else if xxd -r -p 2>/dev/null; then return fi fi fi hex=$(cat) ic=\"\" jc=\"\" _debug2 _URGLY_PRINTF \"$_URGLY_PRINTF\" if [ -z \"$_URGLY_PRINTF\" ]; then if [ \"$_ESCAPE_XARGS\" ] && _exists xargs; then _debug2 \"xargs\" echo \"$hex\" | _upper_case | sed 's/\\([0-9A-F]\\{2\\}\\)/\\\\\\\\\\\\x\\1/g' | xargs printf else for h in $(echo \"$hex\" | _upper_case | sed 's/\\([0-9A-F]\\{2\\}\\)/ \\1/g'); do if [ -z \"$h\" ]; then break fi printf \"\\x$h%s\" done fi else for c in $(echo \"$hex\" | _upper_case | sed 's/\\([0-9A-F]\\)/ \\1/g'); do if [ -z \"$ic\" ]; then ic=$c continue fi jc=$c ic=\"$(_h_char_2_dec \"$ic\")\" jc=\"$(_h_char_2_dec \"$jc\")\" printf '\\'\"$(printf \"%o\" \"$(_math \"$ic\" \\* 16 + $jc)\")\"\"%s\" ic=\"\" jc=\"\" done fi } _is_solaris() { _contains \"${__OS__:=$(uname -a)}\" \"solaris\" || _contains \"${__OS__:=$(uname -a)}\" \"SunOS\" } #_ascii_hex str #this can only process ascii chars, should only be used when od command is missing as a backup way. _ascii_hex() { _debug2 \"Using _ascii_hex\" _str=\"$1\" _str_len=${#_str} _h_i=1 while [ \"$_h_i\" -le \"$_str_len\" ]; do _str_c=\"$(printf \"%s\" \"$_str\" | cut -c \"$_h_i\")\" printf \" %02x\" \"'$_str_c\" _h_i=\"$(_math \"$_h_i\" + 1)\" done } #stdin output hexstr splited by one space #input:\"abc\" #output: \" 61 62 63\" _hex_dump() { if _exists od; then od -A n -v -t x1 | tr -s \" \" | sed 's/ $//' | tr -d \"\\r\\t\\n\" elif _exists hexdump; then _debug3 \"using hexdump\" hexdump -v -e '/1 \"\"' -e '/1 \" %02x\" \"\"' elif _exists xxd; then _debug3 \"using xxd\" xxd -ps -c 20 -i | sed \"s/ 0x/ /g\" | tr -d \",\\n\" | tr -s \" \" else _debug3 \"using _ascii_hex\" str=$(cat) _ascii_hex \"$str\" fi } #url encode, no-preserved chars #A B C D E F G H I J K L M N O P Q R S T U V W X Y Z #41 42 43 44 45 46 47 48 49 4a 4b 4c 4d 4e 4f 50 51 52 53 54 55 56 57 58 59 5a #a b c d e f g h i j k l m n o p q r s t u v w x y z #61 62 63 64 65 66 67 68 69 6a 6b 6c 6d 6e 6f 70 71 72 73 74 75 76 77 78 79 7a #0 1 2 3 4 5 6 7 8 9 - _ . ~ #30 31 32 33 34 35 36 37 38 39 2d 5f 2e 7e #_url_encode [upper-hex] the encoded hex will be upper-case if the argument upper-hex is followed #stdin stdout _url_encode() { _upper_hex=$1 _hex_str=$(_hex_dump) _debug3 \"_url_encode\" _debug3 \"_hex_str\" \"$_hex_str\" for _hex_code in $_hex_str; do #upper case case \"${_hex_code}\" in \"41\") printf \"%s\" \"A\" ;; \"42\") printf \"%s\" \"B\" ;; \"43\") printf \"%s\" \"C\" ;; \"44\") printf \"%s\" \"D\" ;; \"45\") printf \"%s\" \"E\" ;; \"46\") printf \"%s\" \"F\" ;; \"47\") printf \"%s\" \"G\" ;; \"48\") printf \"%s\" \"H\" ;; \"49\") printf \"%s\" \"I\" ;; \"4a\") printf \"%s\" \"J\" ;; \"4b\") printf \"%s\" \"K\" ;; \"4c\") printf \"%s\" \"L\" ;; \"4d\") printf \"%s\" \"M\" ;; \"4e\") printf \"%s\" \"N\" ;; \"4f\") printf \"%s\" \"O\" ;; \"50\") printf \"%s\" \"P\" ;; \"51\") printf \"%s\" \"Q\" ;; \"52\") printf \"%s\" \"R\" ;; \"53\") printf \"%s\" \"S\" ;; \"54\") printf \"%s\" \"T\" ;; \"55\") printf \"%s\" \"U\" ;; \"56\") printf \"%s\" \"V\" ;; \"57\") printf \"%s\" \"W\" ;; \"58\") printf \"%s\" \"X\" ;; \"59\") printf \"%s\" \"Y\" ;; \"5a\") printf \"%s\" \"Z\" ;; #lower case \"61\") printf \"%s\" \"a\" ;; \"62\") printf \"%s\" \"b\" ;; \"63\") printf \"%s\" \"c\" ;; \"64\") printf \"%s\" \"d\" ;; \"65\") printf \"%s\" \"e\" ;; \"66\") printf \"%s\" \"f\" ;; \"67\") printf \"%s\" \"g\" ;; \"68\") printf \"%s\" \"h\" ;; \"69\") printf \"%s\" \"i\" ;; \"6a\") printf \"%s\" \"j\" ;; \"6b\") printf \"%s\" \"k\" ;; \"6c\") printf \"%s\" \"l\" ;; \"6d\") printf \"%s\" \"m\" ;; \"6e\") printf \"%s\" \"n\" ;; \"6f\") printf \"%s\" \"o\" ;; \"70\") printf \"%s\" \"p\" ;; \"71\") printf \"%s\" \"q\" ;; \"72\") printf \"%s\" \"r\" ;; \"73\") printf \"%s\" \"s\" ;; \"74\") printf \"%s\" \"t\" ;; \"75\") printf \"%s\" \"u\" ;; \"76\") printf \"%s\" \"v\" ;; \"77\") printf \"%s\" \"w\" ;; \"78\") printf \"%s\" \"x\" ;; \"79\") printf \"%s\" \"y\" ;; \"7a\") printf \"%s\" \"z\" ;; #numbers \"30\") printf \"%s\" \"0\" ;; \"31\") printf \"%s\" \"1\" ;; \"32\") printf \"%s\" \"2\" ;; \"33\") printf \"%s\" \"3\" ;; \"34\") printf \"%s\" \"4\" ;; \"35\") printf \"%s\" \"5\" ;; \"36\") printf \"%s\" \"6\" ;; \"37\") printf \"%s\" \"7\" ;; \"38\") printf \"%s\" \"8\" ;; \"39\") printf \"%s\" \"9\" ;; \"2d\") printf \"%s\" \"-\" ;; \"5f\") printf \"%s\" \"_\" ;; \"2e\") printf \"%s\" \".\" ;; \"7e\") printf \"%s\" \"~\" ;; #other hex *) if [ \"$_upper_hex\" = \"upper-hex\" ]; then _hex_code=$(printf \"%s\" \"$_hex_code\" | _upper_case) fi printf '%%%s' \"$_hex_code\" ;; esac done } _json_encode() { _j_str=\"$(sed 's/\"/\\\\\"/g' | sed \"s/\\r/\\\\r/g\")\" _debug3 \"_json_encode\" _debug3 \"_j_str\" \"$_j_str\" echo \"$_j_str\" | _hex_dump | _lower_case | sed 's/0a/5c 6e/g' | tr -d ' ' | _h2b | tr -d \"\\r\\n\" } #from: http:\\/\\/ to http:// _json_decode() { _j_str=\"$(sed 's#\\\\/#/#g')\" _debug3 \"_json_decode\" _debug3 \"_j_str\" \"$_j_str\" echo \"$_j_str\" } #options file _sed_i() { options=\"$1\" filename=\"$2\" if [ -z \"$filename\" ]; then _usage \"Usage:_sed_i options filename\" return 1 fi _debug2 options \"$options\" if sed -h 2>&1 | grep \"\\-i\\[SUFFIX]\" >/dev/null 2>&1; then _debug \"Using sed -i\" sed -i \"$options\" \"$filename\" else _debug \"No -i support in sed\" text=\"$(cat \"$filename\")\" echo \"$text\" | sed \"$options\" >\"$filename\" fi } if [ \"$(echo abc | egrep -o b 2>/dev/null)\" = \"b\" ]; then __USE_EGREP=1 else __USE_EGREP=\"\" fi _egrep_o() { if [ \"$__USE_EGREP\" ]; then egrep -o -- \"$1\" 2>/dev/null else sed -n 's/.*\\('\"$1\"'\\).*/\\1/p' fi } #Usage: file startline endline _getfile() { filename=\"$1\" startline=\"$2\" endline=\"$3\" if [ -z \"$endline\" ]; then _usage \"Usage: file startline endline\" return 1 fi i=\"$(grep -n -- \"$startline\" \"$filename\" | cut -d : -f 1)\" if [ -z \"$i\" ]; then _err \"Cannot find start line: $startline\" return 1 fi i=\"$(_math \"$i\" + 1)\" _debug i \"$i\" j=\"$(grep -n -- \"$endline\" \"$filename\" | cut -d : -f 1)\" if [ -z \"$j\" ]; then _err \"Cannot find end line: $endline\" return 1 fi j=\"$(_math \"$j\" - 1)\" _debug j \"$j\" sed -n \"$i,${j}p\" \"$filename\" } #Usage: multiline _base64() { [ \"\" ] #urgly if [ \"$1\" ]; then _debug3 \"base64 multiline:'$1'\" ${ACME_OPENSSL_BIN:-openssl} base64 -e else _debug3 \"base64 single line.\" ${ACME_OPENSSL_BIN:-openssl} base64 -e | tr -d '\\r\\n' fi } #Usage: multiline _dbase64() { if [ \"$1\" ]; then ${ACME_OPENSSL_BIN:-openssl} base64 -d else ${ACME_OPENSSL_BIN:-openssl} base64 -d -A fi } #file _checkcert() { _cf=\"$1\" if [ \"$DEBUG\" ]; then ${ACME_OPENSSL_BIN:-openssl} x509 -noout -text -in \"$_cf\" else ${ACME_OPENSSL_BIN:-openssl} x509 -noout -text -in \"$_cf\" >/dev/null 2>&1 fi } #Usage: hashalg [outputhex] #Output Base64-encoded digest _digest() { alg=\"$1\" if [ -z \"$alg\" ]; then _usage \"Usage: _digest hashalg\" return 1 fi outputhex=\"$2\" if [ \"$alg\" = \"sha256\" ] || [ \"$alg\" = \"sha1\" ] || [ \"$alg\" = \"md5\" ]; then if [ \"$outputhex\" ]; then ${ACME_OPENSSL_BIN:-openssl} dgst -\"$alg\" -hex | cut -d = -f 2 | tr -d ' ' else ${ACME_OPENSSL_BIN:-openssl} dgst -\"$alg\" -binary | _base64 fi else _err \"$alg is not supported yet\" return 1 fi } #Usage: hashalg secret_hex [outputhex] #Output binary hmac _hmac() { alg=\"$1\" secret_hex=\"$2\" outputhex=\"$3\" if [ -z \"$secret_hex\" ]; then _usage \"Usage: _hmac hashalg secret [outputhex]\" return 1 fi if [ \"$alg\" = \"sha256\" ] || [ \"$alg\" = \"sha1\" ]; then if [ \"$outputhex\" ]; then (${ACME_OPENSSL_BIN:-openssl} dgst -\"$alg\" -mac HMAC -macopt \"hexkey:$secret_hex\" 2>/dev/null || ${ACME_OPENSSL_BIN:-openssl} dgst -\"$alg\" -hmac \"$(printf \"%s\" \"$secret_hex\" | _h2b)\") | cut -d = -f 2 | tr -d ' ' else ${ACME_OPENSSL_BIN:-openssl} dgst -\"$alg\" -mac HMAC -macopt \"hexkey:$secret_hex\" -binary 2>/dev/null || ${ACME_OPENSSL_BIN:-openssl} dgst -\"$alg\" -hmac \"$(printf \"%s\" \"$secret_hex\" | _h2b)\" -binary fi else _err \"$alg is not supported yet\" return 1 fi } #Usage: keyfile hashalg #Output: Base64-encoded signature value _sign() { keyfile=\"$1\" alg=\"$2\" if [ -z \"$alg\" ]; then _usage \"Usage: _sign keyfile hashalg\" return 1 fi _sign_openssl=\"${ACME_OPENSSL_BIN:-openssl} dgst -sign $keyfile \" if _isRSA \"$keyfile\" >/dev/null 2>&1; then $_sign_openssl -$alg | _base64 elif _isEcc \"$keyfile\" >/dev/null 2>&1; then if ! _signedECText=\"$($_sign_openssl -sha$__ECC_KEY_LEN | ${ACME_OPENSSL_BIN:-openssl} asn1parse -inform DER)\"; then _err \"Sign failed: $_sign_openssl\" _err \"Key file: $keyfile\" _err \"Key content: $(wc -l <\"$keyfile\") lines\" return 1 fi _debug3 \"_signedECText\" \"$_signedECText\" _ec_r=\"$(echo \"$_signedECText\" | _head_n 2 | _tail_n 1 | cut -d : -f 4 | tr -d \"\\r\\n\")\" _ec_s=\"$(echo \"$_signedECText\" | _head_n 3 | _tail_n 1 | cut -d : -f 4 | tr -d \"\\r\\n\")\" if [ \"$__ECC_KEY_LEN\" -eq \"256\" ]; then while [ \"${#_ec_r}\" -lt \"64\" ]; do _ec_r=\"0${_ec_r}\" done while [ \"${#_ec_s}\" -lt \"64\" ]; do _ec_s=\"0${_ec_s}\" done fi if [ \"$__ECC_KEY_LEN\" -eq \"384\" ]; then while [ \"${#_ec_r}\" -lt \"96\" ]; do _ec_r=\"0${_ec_r}\" done while [ \"${#_ec_s}\" -lt \"96\" ]; do _ec_s=\"0${_ec_s}\" done fi if [ \"$__ECC_KEY_LEN\" -eq \"512\" ]; then while [ \"${#_ec_r}\" -lt \"132\" ]; do _ec_r=\"0${_ec_r}\" done while [ \"${#_ec_s}\" -lt \"132\" ]; do _ec_s=\"0${_ec_s}\" done fi _debug3 \"_ec_r\" \"$_ec_r\" _debug3 \"_ec_s\" \"$_ec_s\" printf \"%s\" \"$_ec_r$_ec_s\" | _h2b | _base64 else _err \"Unknown key file format.\" return 1 fi } #keylength or isEcc flag (empty str => not ecc) _isEccKey() { _length=\"$1\" if [ -z \"$_length\" ]; then return 1 fi [ \"$_length\" != \"1024\" ] && [ \"$_length\" != \"2048\" ] && [ \"$_length\" != \"3072\" ] && [ \"$_length\" != \"4096\" ] && [ \"$_length\" != \"8192\" ] } # _createkey 2048|ec-256 file _createkey() { length=\"$1\" f=\"$2\" _debug2 \"_createkey for file:$f\" eccname=\"$length\" if _startswith \"$length\" \"ec-\"; then length=$(printf \"%s\" \"$length\" | cut -d '-' -f 2-100) if [ \"$length\" = \"256\" ]; then eccname=\"prime256v1\" fi if [ \"$length\" = \"384\" ]; then eccname=\"secp384r1\" fi if [ \"$length\" = \"521\" ]; then eccname=\"secp521r1\" fi fi if [ -z \"$length\" ]; then length=2048 fi _debug \"Using length $length\" if ! [ -e \"$f\" ]; then if ! touch \"$f\" >/dev/null 2>&1; then _f_path=\"$(dirname \"$f\")\" _debug _f_path \"$_f_path\" if ! mkdir -p \"$_f_path\"; then _err \"Cannot create path: $_f_path\" return 1 fi fi if ! touch \"$f\" >/dev/null 2>&1; then return 1 fi chmod 600 \"$f\" fi if _isEccKey \"$length\"; then _debug \"Using EC name: $eccname\" if _opkey=\"$(${ACME_OPENSSL_BIN:-openssl} ecparam -name \"$eccname\" -noout -genkey 2>/dev/null)\"; then echo \"$_opkey\" >\"$f\" else _err \"Error encountered for ECC key named $eccname\" return 1 fi else _debug \"Using RSA: $length\" __traditional=\"\" if _contains \"$(${ACME_OPENSSL_BIN:-openssl} help genrsa 2>&1)\" \"-traditional\"; then __traditional=\"-traditional\" fi if _opkey=\"$(${ACME_OPENSSL_BIN:-openssl} genrsa $__traditional \"$length\" 2>/dev/null)\"; then echo \"$_opkey\" >\"$f\" else _err \"Error encountered for RSA key of length $length\" return 1 fi fi if [ \"$?\" != \"0\" ]; then _err \"Key creation error.\" return 1 fi } #domain _is_idn() { _is_idn_d=\"$1\" _debug2 _is_idn_d \"$_is_idn_d\" _idn_temp=$(printf \"%s\" \"$_is_idn_d\" | tr -d '[0-9]' | tr -d '[a-z]' | tr -d '[A-Z]' | tr -d '*.,-_') _debug2 _idn_temp \"$_idn_temp\" [ \"$_idn_temp\" ] } #aa.com #aa.com,bb.com,cc.com _idn() { __idn_d=\"$1\" if ! _is_idn \"$__idn_d\"; then printf \"%s\" \"$__idn_d\" return 0 fi if _exists idn; then if _contains \"$__idn_d\" ','; then _i_first=\"1\" for f in $(echo \"$__idn_d\" | tr ',' ' '); do [ -z \"$f\" ] && continue if [ -z \"$_i_first\" ]; then printf \"%s\" \",\" else _i_first=\"\" fi idn --quiet \"$f\" | tr -d \"\\r\\n\" done else idn \"$__idn_d\" | tr -d \"\\r\\n\" fi else _err \"Please install idn to process IDN names.\" fi } #_createcsr cn san_list keyfile csrfile conf acmeValidationv1 _createcsr() { _debug _createcsr domain=\"$1\" domainlist=\"$2\" csrkey=\"$3\" csr=\"$4\" csrconf=\"$5\" acmeValidationv1=\"$6\" _debug2 domain \"$domain\" _debug2 domainlist \"$domainlist\" _debug2 csrkey \"$csrkey\" _debug2 csr \"$csr\" _debug2 csrconf \"$csrconf\" printf \"[ req_distinguished_name ]\\n[ req ]\\ndistinguished_name = req_distinguished_name\\nreq_extensions = v3_req\\n[ v3_req ]\" >\"$csrconf\" if [ \"$Le_ExtKeyUse\" ]; then _savedomainconf Le_ExtKeyUse \"$Le_ExtKeyUse\" printf \"\\nextendedKeyUsage=$Le_ExtKeyUse\\n\" >>\"$csrconf\" else printf \"\\nextendedKeyUsage=serverAuth,clientAuth\\n\" >>\"$csrconf\" fi if [ \"$acmeValidationv1\" ]; then domainlist=\"$(_idn \"$domainlist\")\" _debug2 domainlist \"$domainlist\" alt=\"\" for dl in $(echo \"$domainlist\" | tr \",\" ' '); do if [ \"$alt\" ]; then alt=\"$alt,$(_getIdType \"$dl\" | _upper_case):$dl\" else alt=\"$(_getIdType \"$dl\" | _upper_case):$dl\" fi done printf -- \"\\nsubjectAltName=$alt\" >>\"$csrconf\" elif [ -z \"$domainlist\" ] || [ \"$domainlist\" = \"$NO_VALUE\" ]; then #single domain _info \"Single domain\" \"$domain\" printf -- \"\\nsubjectAltName=$(_getIdType \"$domain\" | _upper_case):$(_idn \"$domain\")\" >>\"$csrconf\" else domainlist=\"$(_idn \"$domainlist\")\" _debug2 domainlist \"$domainlist\" alt=\"$(_getIdType \"$domain\" | _upper_case):$(_idn \"$domain\")\" for dl in $(echo \"'$domainlist'\" | sed \"s/,/' '/g\"); do dl=$(echo \"$dl\" | tr -d \"'\") alt=\"$alt,$(_getIdType \"$dl\" | _upper_case):$dl\" done #multi _info \"Multi domain\" \"$alt\" printf -- \"\\nsubjectAltName=$alt\" >>\"$csrconf\" fi if [ \"$Le_OCSP_Staple\" = \"1\" ]; then _savedomainconf Le_OCSP_Staple \"$Le_OCSP_Staple\" printf -- \"\\nbasicConstraints = CA:FALSE\\n1.3.6.1.5.5.7.1.24=DER:30:03:02:01:05\" >>\"$csrconf\" fi if [ \"$acmeValidationv1\" ]; then printf \"\\n1.3.6.1.5.5.7.1.31=critical,DER:04:20:${acmeValidationv1}\" >>\"${csrconf}\" fi _csr_cn=\"$(_idn \"$domain\")\" _debug2 _csr_cn \"$_csr_cn\" if _contains \"$(uname -a)\" \"MINGW\"; then if _isIP \"$_csr_cn\"; then ${ACME_OPENSSL_BIN:-openssl} req -new -sha256 -key \"$csrkey\" -subj \"//O=$PROJECT_NAME\" -config \"$csrconf\" -out \"$csr\" else ${ACME_OPENSSL_BIN:-openssl} req -new -sha256 -key \"$csrkey\" -subj \"//CN=$_csr_cn\" -config \"$csrconf\" -out \"$csr\" fi else if _isIP \"$_csr_cn\"; then ${ACME_OPENSSL_BIN:-openssl} req -new -sha256 -key \"$csrkey\" -subj \"/O=$PROJECT_NAME\" -config \"$csrconf\" -out \"$csr\" else ${ACME_OPENSSL_BIN:-openssl} req -new -sha256 -key \"$csrkey\" -subj \"/CN=$_csr_cn\" -config \"$csrconf\" -out \"$csr\" fi fi } #_signcsr key csr conf cert _signcsr() { key=\"$1\" csr=\"$2\" conf=\"$3\" cert=\"$4\" _debug \"_signcsr\" _msg=\"$(${ACME_OPENSSL_BIN:-openssl} x509 -req -days 365 -in \"$csr\" -signkey \"$key\" -extensions v3_req -extfile \"$conf\" -out \"$cert\" 2>&1)\" _ret=\"$?\" _debug \"$_msg\" return $_ret } #_csrfile _readSubjectFromCSR() { _csrfile=\"$1\" if [ -z \"$_csrfile\" ]; then _usage \"_readSubjectFromCSR mycsr.csr\" return 1 fi ${ACME_OPENSSL_BIN:-openssl} req -noout -in \"$_csrfile\" -subject | tr ',' \"\\n\" | _egrep_o \"CN *=.*\" | cut -d = -f 2 | cut -d / -f 1 | tr -d ' \\n' } #_csrfile #echo comma separated domain list _readSubjectAltNamesFromCSR() { _csrfile=\"$1\" if [ -z \"$_csrfile\" ]; then _usage \"_readSubjectAltNamesFromCSR mycsr.csr\" return 1 fi _csrsubj=\"$(_readSubjectFromCSR \"$_csrfile\")\" _debug _csrsubj \"$_csrsubj\" _dnsAltnames=\"$(${ACME_OPENSSL_BIN:-openssl} req -noout -text -in \"$_csrfile\" | grep \"^ *DNS:.*\" | tr -d ' \\n')\" _debug _dnsAltnames \"$_dnsAltnames\" if _contains \"$_dnsAltnames,\" \"DNS:$_csrsubj,\"; then _debug \"AltNames contains subject\" _excapedAlgnames=\"$(echo \"$_dnsAltnames\" | tr '*' '#')\" _debug _excapedAlgnames \"$_excapedAlgnames\" _escapedSubject=\"$(echo \"$_csrsubj\" | tr '*' '#')\" _debug _escapedSubject \"$_escapedSubject\" _dnsAltnames=\"$(echo \"$_excapedAlgnames,\" | sed \"s/DNS:$_escapedSubject,//g\" | tr '#' '*' | sed \"s/,\\$//g\")\" _debug _dnsAltnames \"$_dnsAltnames\" else _debug \"AltNames doesn't contain subject\" fi echo \"$_dnsAltnames\" | sed \"s/DNS://g\" } #_csrfile _readKeyLengthFromCSR() { _csrfile=\"$1\" if [ -z \"$_csrfile\" ]; then _usage \"_readKeyLengthFromCSR mycsr.csr\" return 1 fi _outcsr=\"$(${ACME_OPENSSL_BIN:-openssl} req -noout -text -in \"$_csrfile\")\" _debug2 _outcsr \"$_outcsr\" if _contains \"$_outcsr\" \"Public Key Algorithm: id-ecPublicKey\"; then _debug \"ECC CSR\" echo \"$_outcsr\" | tr \"\\t\" \" \" | _egrep_o \"^ *ASN1 OID:.*\" | cut -d ':' -f 2 | tr -d ' ' else _debug \"RSA CSR\" _rkl=\"$(echo \"$_outcsr\" | tr \"\\t\" \" \" | _egrep_o \"^ *Public.Key:.*\" | cut -d '(' -f 2 | cut -d ' ' -f 1)\" if [ \"$_rkl\" ]; then echo \"$_rkl\" else echo \"$_outcsr\" | tr \"\\t\" \" \" | _egrep_o \"RSA Public.Key:.*\" | cut -d '(' -f 2 | cut -d ' ' -f 1 fi fi } _ss() { _port=\"$1\" if _exists \"ss\"; then _debug \"Using: ss\" ss -ntpl 2>/dev/null | grep \":$_port \" return 0 fi if _exists \"netstat\"; then _debug \"Using: netstat\" if netstat -help 2>&1 | grep \"\\-p proto\" >/dev/null; then #for windows version netstat tool netstat -an -p tcp | grep \"LISTENING\" | grep \":$_port \" else if netstat -help 2>&1 | grep \"\\-p protocol\" >/dev/null; then netstat -an -p tcp | grep LISTEN | grep \":$_port \" elif netstat -help 2>&1 | grep -- '-P protocol' >/dev/null; then #for solaris netstat -an -P tcp | grep \"\\.$_port \" | grep \"LISTEN\" elif netstat -help 2>&1 | grep \"\\-p\" >/dev/null; then #for full linux netstat -ntpl | grep \":$_port \" else #for busybox (embedded linux; no pid support) netstat -ntl 2>/dev/null | grep \":$_port \" fi fi return 0 fi return 1 } #outfile key cert cacert [password [name [caname]]] _toPkcs() { _cpfx=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" pfxPassword=\"$5\" pfxName=\"$6\" pfxCaname=\"$7\" if [ \"$pfxCaname\" ]; then ${ACME_OPENSSL_BIN:-openssl} pkcs12 -export -out \"$_cpfx\" -inkey \"$_ckey\" -in \"$_ccert\" -certfile \"$_cca\" -password \"pass:$pfxPassword\" -name \"$pfxName\" -caname \"$pfxCaname\" elif [ \"$pfxName\" ]; then ${ACME_OPENSSL_BIN:-openssl} pkcs12 -export -out \"$_cpfx\" -inkey \"$_ckey\" -in \"$_ccert\" -certfile \"$_cca\" -password \"pass:$pfxPassword\" -name \"$pfxName\" elif [ \"$pfxPassword\" ]; then ${ACME_OPENSSL_BIN:-openssl} pkcs12 -export -out \"$_cpfx\" -inkey \"$_ckey\" -in \"$_ccert\" -certfile \"$_cca\" -password \"pass:$pfxPassword\" else ${ACME_OPENSSL_BIN:-openssl} pkcs12 -export -out \"$_cpfx\" -inkey \"$_ckey\" -in \"$_ccert\" -certfile \"$_cca\" fi if [ \"$?\" == \"0\" ]; then _savedomainconf \"Le_PFXPassword\" \"$pfxPassword\" fi } #domain [password] [isEcc] toPkcs() { domain=\"$1\" pfxPassword=\"$2\" if [ -z \"$domain\" ]; then _usage \"Usage: $PROJECT_ENTRY --to-pkcs12 --domain <domain.tld> [--password <password>] [--ecc]\" return 1 fi _isEcc=\"$3\" _initpath \"$domain\" \"$_isEcc\" _toPkcs \"$CERT_PFX_PATH\" \"$CERT_KEY_PATH\" \"$CERT_PATH\" \"$CA_CERT_PATH\" \"$pfxPassword\" if [ \"$?\" = \"0\" ]; then _info \"Success, PFX has been exported to: $CERT_PFX_PATH\" fi } #domain [isEcc] toPkcs8() { domain=\"$1\" if [ -z \"$domain\" ]; then _usage \"Usage: $PROJECT_ENTRY --to-pkcs8 --domain <domain.tld> [--ecc]\" return 1 fi _isEcc=\"$2\" _initpath \"$domain\" \"$_isEcc\" ${ACME_OPENSSL_BIN:-openssl} pkcs8 -topk8 -inform PEM -outform PEM -nocrypt -in \"$CERT_KEY_PATH\" -out \"$CERT_PKCS8_PATH\" if [ \"$?\" = \"0\" ]; then _info \"Success, $CERT_PKCS8_PATH\" fi } #[2048] createAccountKey() { _info \"Creating account key\" if [ -z \"$1\" ]; then _usage \"Usage: $PROJECT_ENTRY --create-account-key [--accountkeylength <bits>]\" return fi length=$1 _create_account_key \"$length\" } _create_account_key() { length=$1 if [ -z \"$length\" ] || [ \"$length\" = \"$NO_VALUE\" ]; then _debug \"Using default length $DEFAULT_ACCOUNT_KEY_LENGTH\" length=\"$DEFAULT_ACCOUNT_KEY_LENGTH\" fi _debug length \"$length\" _initpath mkdir -p \"$CA_DIR\" if [ -s \"$ACCOUNT_KEY_PATH\" ]; then _info \"Account key exists, skipping\" return 0 else #generate account key if _createkey \"$length\" \"$ACCOUNT_KEY_PATH\"; then _info \"Account key creation OK.\" return 0 else _err \"Account key creation error.\" return 1 fi fi } #domain [length] createDomainKey() { _info \"Creating domain key\" if [ -z \"$1\" ]; then _usage \"Usage: $PROJECT_ENTRY --create-domain-key --domain <domain.tld> [--keylength <bits>]\" return fi domain=$1 _cdl=$2 if [ -z \"$_cdl\" ]; then _debug \"Using DEFAULT_DOMAIN_KEY_LENGTH=$DEFAULT_DOMAIN_KEY_LENGTH\" _cdl=\"$DEFAULT_DOMAIN_KEY_LENGTH\" fi _initpath \"$domain\" \"$_cdl\" if [ ! -f \"$CERT_KEY_PATH\" ] || [ ! -s \"$CERT_KEY_PATH\" ] || ([ \"$FORCE\" ] && ! [ \"$_ACME_IS_RENEW\" ]) || [ \"$Le_ForceNewDomainKey\" = \"1\" ]; then if _createkey \"$_cdl\" \"$CERT_KEY_PATH\"; then _savedomainconf Le_Keylength \"$_cdl\" _info \"The domain key is here: $(__green $CERT_KEY_PATH)\" return 0 else _err \"Cannot create domain key\" return 1 fi else if [ \"$_ACME_IS_RENEW\" ]; then _info \"Domain key exists, skipping\" return 0 else _err \"Domain key exists, do you want to overwrite it?\" _err \"If so, add '--force' and try again.\" return 1 fi fi } # domain domainlist isEcc createCSR() { _info \"Creating CSR\" if [ -z \"$1\" ]; then _usage \"Usage: $PROJECT_ENTRY --create-csr --domain <domain.tld> [--domain <domain2.tld> ...] [--ecc]\" return fi domain=\"$1\" domainlist=\"$2\" _isEcc=\"$3\" _initpath \"$domain\" \"$_isEcc\" if [ -f \"$CSR_PATH\" ] && [ \"$_ACME_IS_RENEW\" ] && [ -z \"$FORCE\" ]; then _info \"CSR exists, skipping\" return fi if [ ! -f \"$CERT_KEY_PATH\" ]; then _err \"This key file was not found: $CERT_KEY_PATH\" _err \"Please create it first.\" return 1 fi _createcsr \"$domain\" \"$domainlist\" \"$CERT_KEY_PATH\" \"$CSR_PATH\" \"$DOMAIN_SSL_CONF\" } _url_replace() { tr '/+' '_-' | tr -d '= ' } #base64 string _durl_replace_base64() { _l=$((${#1} % 4)) if [ $_l -eq 2 ]; then _s=\"$1\"'==' elif [ $_l -eq 3 ]; then _s=\"$1\"'=' else _s=\"$1\" fi echo \"$_s\" | tr '_-' '/+' } _time2str() { #BSD if date -u -r \"$1\" -j \"+%Y-%m-%dT%H:%M:%SZ\" 2>/dev/null; then return fi #Linux if date -u --date=@\"$1\" \"+%Y-%m-%dT%H:%M:%SZ\" 2>/dev/null; then return fi #Solaris if printf \"%(%Y-%m-%dT%H:%M:%SZ)T\\n\" $1 2>/dev/null; then return fi #Busybox if echo \"$1\" | awk '{ print strftime(\"%Y-%m-%dT%H:%M:%SZ\", $0); }' 2>/dev/null; then return fi } _normalizeJson() { sed \"s/\\\" *: *\\([\\\"{\\[]\\)/\\\":\\1/g\" | sed \"s/^ *\\([^ ]\\)/\\1/\" | tr -d \"\\r\\n\" } _stat() { #Linux if stat -c '%U:%G' \"$1\" 2>/dev/null; then return fi #BSD if stat -f '%Su:%Sg' \"$1\" 2>/dev/null; then return fi return 1 #error, 'stat' not found } #keyfile _isRSA() { keyfile=$1 if grep \"BEGIN RSA PRIVATE KEY\" \"$keyfile\" >/dev/null 2>&1 || ${ACME_OPENSSL_BIN:-openssl} rsa -in \"$keyfile\" -noout -text 2>&1 | grep \"^publicExponent:\" 2>&1 >/dev/null; then return 0 fi return 1 } #keyfile _isEcc() { keyfile=$1 if grep \"BEGIN EC PRIVATE KEY\" \"$keyfile\" >/dev/null 2>&1 || ${ACME_OPENSSL_BIN:-openssl} ec -in \"$keyfile\" -noout -text 2>/dev/null | grep \"^NIST CURVE:\" 2>&1 >/dev/null; then return 0 fi return 1 } #keyfile _calcjwk() { keyfile=\"$1\" if [ -z \"$keyfile\" ]; then _usage \"Usage: _calcjwk keyfile\" return 1 fi if [ \"$JWK_HEADER\" ] && [ \"$__CACHED_JWK_KEY_FILE\" = \"$keyfile\" ]; then _debug2 \"Use cached jwk for file: $__CACHED_JWK_KEY_FILE\" return 0 fi if _isRSA \"$keyfile\"; then _debug \"RSA key\" pub_exp=$(${ACME_OPENSSL_BIN:-openssl} rsa -in \"$keyfile\" -noout -text | grep \"^publicExponent:\" | cut -d '(' -f 2 | cut -d 'x' -f 2 | cut -d ')' -f 1) if [ \"${#pub_exp}\" = \"5\" ]; then pub_exp=0$pub_exp fi _debug3 pub_exp \"$pub_exp\" e=$(echo \"$pub_exp\" | _h2b | _base64) _debug3 e \"$e\" modulus=$(${ACME_OPENSSL_BIN:-openssl} rsa -in \"$keyfile\" -modulus -noout | cut -d '=' -f 2) _debug3 modulus \"$modulus\" n=\"$(printf \"%s\" \"$modulus\" | _h2b | _base64 | _url_replace)\" _debug3 n \"$n\" jwk='{\"e\": \"'$e'\", \"kty\": \"RSA\", \"n\": \"'$n'\"}' _debug3 jwk \"$jwk\" JWK_HEADER='{\"alg\": \"RS256\", \"jwk\": '$jwk'}' JWK_HEADERPLACE_PART1='{\"nonce\": \"' JWK_HEADERPLACE_PART2='\", \"alg\": \"RS256\"' elif _isEcc \"$keyfile\"; then _debug \"EC key\" crv=\"$(${ACME_OPENSSL_BIN:-openssl} ec -in \"$keyfile\" -noout -text 2>/dev/null | grep \"^NIST CURVE:\" | cut -d \":\" -f 2 | tr -d \" \\r\\n\")\" _debug3 crv \"$crv\" __ECC_KEY_LEN=$(echo \"$crv\" | cut -d \"-\" -f 2) if [ \"$__ECC_KEY_LEN\" = \"521\" ]; then __ECC_KEY_LEN=512 fi _debug3 __ECC_KEY_LEN \"$__ECC_KEY_LEN\" if [ -z \"$crv\" ]; then _debug \"Let's try ASN1 OID\" crv_oid=\"$(${ACME_OPENSSL_BIN:-openssl} ec -in \"$keyfile\" -noout -text 2>/dev/null | grep \"^ASN1 OID:\" | cut -d \":\" -f 2 | tr -d \" \\r\\n\")\" _debug3 crv_oid \"$crv_oid\" case \"${crv_oid}\" in \"prime256v1\") crv=\"P-256\" __ECC_KEY_LEN=256 ;; \"secp384r1\") crv=\"P-384\" __ECC_KEY_LEN=384 ;; \"secp521r1\") crv=\"P-521\" __ECC_KEY_LEN=512 ;; *) _err \"ECC oid: $crv_oid\" return 1 ;; esac _debug3 crv \"$crv\" fi pubi=\"$(${ACME_OPENSSL_BIN:-openssl} ec -in \"$keyfile\" -noout -text 2>/dev/null | grep -n pub: | cut -d : -f 1)\" pubi=$(_math \"$pubi\" + 1) _debug3 pubi \"$pubi\" pubj=\"$(${ACME_OPENSSL_BIN:-openssl} ec -in \"$keyfile\" -noout -text 2>/dev/null | grep -n \"ASN1 OID:\" | cut -d : -f 1)\" pubj=$(_math \"$pubj\" - 1) _debug3 pubj \"$pubj\" pubtext=\"$(${ACME_OPENSSL_BIN:-openssl} ec -in \"$keyfile\" -noout -text 2>/dev/null | sed -n \"$pubi,${pubj}p\" | tr -d \" \\n\\r\")\" _debug3 pubtext \"$pubtext\" xlen=\"$(printf \"%s\" \"$pubtext\" | tr -d ':' | wc -c)\" xlen=$(_math \"$xlen\" / 4) _debug3 xlen \"$xlen\" xend=$(_math \"$xlen\" + 1) x=\"$(printf \"%s\" \"$pubtext\" | cut -d : -f 2-\"$xend\")\" _debug3 x \"$x\" x64=\"$(printf \"%s\" \"$x\" | tr -d : | _h2b | _base64 | _url_replace)\" _debug3 x64 \"$x64\" xend=$(_math \"$xend\" + 1) y=\"$(printf \"%s\" \"$pubtext\" | cut -d : -f \"$xend\"-2048)\" _debug3 y \"$y\" y64=\"$(printf \"%s\" \"$y\" | tr -d : | _h2b | _base64 | _url_replace)\" _debug3 y64 \"$y64\" jwk='{\"crv\": \"'$crv'\", \"kty\": \"EC\", \"x\": \"'$x64'\", \"y\": \"'$y64'\"}' _debug3 jwk \"$jwk\" JWK_HEADER='{\"alg\": \"ES'$__ECC_KEY_LEN'\", \"jwk\": '$jwk'}' JWK_HEADERPLACE_PART1='{\"nonce\": \"' JWK_HEADERPLACE_PART2='\", \"alg\": \"ES'$__ECC_KEY_LEN'\"' else _err \"Only RSA or EC keys are supported. keyfile=$keyfile\" _debug2 \"$(cat \"$keyfile\")\" return 1 fi _debug3 JWK_HEADER \"$JWK_HEADER\" __CACHED_JWK_KEY_FILE=\"$keyfile\" } _time() { date -u \"+%s\" } #support 2 formats: # 2022-04-01 08:10:33 to 1648800633 #or 2022-04-01T08:10:33Z to 1648800633 _date2time() { #Linux if date -u -d \"$(echo \"$1\" | tr -d \"Z\" | tr \"T\" ' ')\" +\"%s\" 2>/dev/null; then return fi #Solaris if gdate -u -d \"$(echo \"$1\" | tr -d \"Z\" | tr \"T\" ' ')\" +\"%s\" 2>/dev/null; then return fi #Mac/BSD if date -u -j -f \"%Y-%m-%d %H:%M:%S\" \"$(echo \"$1\" | tr -d \"Z\" | tr \"T\" ' ')\" +\"%s\" 2>/dev/null; then return fi #Omnios if da=\"$(echo \"$1\" | tr -d \"Z\" | tr \"T\" ' ')\" perl -MTime::Piece -e 'print Time::Piece->strptime($ENV{da}, \"%Y-%m-%d %H:%M:%S\")->epoch, \"\\n\";' 2>/dev/null; then return fi _err \"Cannot parse _date2time $1\" return 1 } _utc_date() { date -u \"+%Y-%m-%d %H:%M:%S\" } _mktemp() { if _exists mktemp; then if mktemp 2>/dev/null; then return 0 elif _contains \"$(mktemp 2>&1)\" \"-t prefix\" && mktemp -t \"$PROJECT_NAME\" 2>/dev/null; then #for Mac osx return 0 fi fi if [ -d \"/tmp\" ]; then echo \"/tmp/${PROJECT_NAME}wefADf24sf.$(_time).tmp\" return 0 elif [ \"$LE_TEMP_DIR\" ] && mkdir -p \"$LE_TEMP_DIR\"; then echo \"/$LE_TEMP_DIR/wefADf24sf.$(_time).tmp\" return 0 fi _err \"Cannot create temp file.\" } #clear all the https envs to cause _inithttp() to run next time. _resethttp() { __HTTP_INITIALIZED=\"\" _ACME_CURL=\"\" _ACME_WGET=\"\" ACME_HTTP_NO_REDIRECTS=\"\" } _inithttp() { if [ -z \"$HTTP_HEADER\" ] || ! touch \"$HTTP_HEADER\"; then HTTP_HEADER=\"$(_mktemp)\" _debug2 HTTP_HEADER \"$HTTP_HEADER\" fi if [ \"$__HTTP_INITIALIZED\" ]; then if [ \"$_ACME_CURL$_ACME_WGET\" ]; then _debug2 \"Http already initialized.\" return 0 fi fi if [ -z \"$_ACME_CURL\" ] && _exists \"curl\"; then _ACME_CURL=\"curl --silent --dump-header $HTTP_HEADER \" if [ -z \"$ACME_HTTP_NO_REDIRECTS\" ]; then _ACME_CURL=\"$_ACME_CURL -L \" fi if [ \"$DEBUG\" ] && [ \"$DEBUG\" -ge 2 ]; then _CURL_DUMP=\"$(_mktemp)\" _ACME_CURL=\"$_ACME_CURL --trace-ascii $_CURL_DUMP \" fi if [ \"$CA_PATH\" ]; then _ACME_CURL=\"$_ACME_CURL --capath $CA_PATH \" elif [ \"$CA_BUNDLE\" ]; then _ACME_CURL=\"$_ACME_CURL --cacert $CA_BUNDLE \" fi if _contains \"$(curl --help 2>&1)\" \"--globoff\" || _contains \"$(curl --help curl 2>&1)\" \"--globoff\"; then _ACME_CURL=\"$_ACME_CURL -g \" fi #don't use --fail-with-body ##from curl 7.76: return fail on HTTP errors but keep the body #if _contains \"$(curl --help http 2>&1)\" \"--fail-with-body\"; then # _ACME_CURL=\"$_ACME_CURL --fail-with-body \" #fi fi if [ -z \"$_ACME_WGET\" ] && _exists \"wget\"; then _ACME_WGET=\"wget -q\" if [ \"$ACME_HTTP_NO_REDIRECTS\" ]; then _ACME_WGET=\"$_ACME_WGET --max-redirect 0 \" fi if [ \"$DEBUG\" ] && [ \"$DEBUG\" -ge \"2\" ]; then if [ \"$_ACME_WGET\" ] && _contains \"$($_ACME_WGET --help 2>&1)\" \"--debug\"; then _ACME_WGET=\"$_ACME_WGET -d \" fi fi if [ \"$CA_PATH\" ]; then _ACME_WGET=\"$_ACME_WGET --ca-directory=$CA_PATH \" elif [ \"$CA_BUNDLE\" ]; then _ACME_WGET=\"$_ACME_WGET --ca-certificate=$CA_BUNDLE \" fi #from wget 1.14: do not skip body on 404 error if _contains \"$(wget --help 2>&1)\" \"--content-on-error\"; then _ACME_WGET=\"$_ACME_WGET --content-on-error \" fi fi __HTTP_INITIALIZED=1 } # body url [needbase64] [POST|PUT|DELETE] [ContentType] _post() { body=\"$1\" _post_url=\"$2\" needbase64=\"$3\" httpmethod=\"$4\" _postContentType=\"$5\" if [ -z \"$httpmethod\" ]; then httpmethod=\"POST\" fi _debug $httpmethod _debug \"_post_url\" \"$_post_url\" _debug2 \"body\" \"$body\" _debug2 \"_postContentType\" \"$_postContentType\" _inithttp if [ \"$_ACME_CURL\" ] && [ \"${ACME_USE_WGET:-0}\" = \"0\" ]; then _CURL=\"$_ACME_CURL\" if [ \"$HTTPS_INSECURE\" ]; then _CURL=\"$_CURL --insecure \" fi if [ \"$httpmethod\" = \"HEAD\" ]; then _CURL=\"$_CURL -I \" fi _debug \"_CURL\" \"$_CURL\" if [ \"$needbase64\" ]; then if [ \"$body\" ]; then if [ \"$_postContentType\" ]; then response=\"$($_CURL --user-agent \"$USER_AGENT\" -X $httpmethod -H \"Content-Type: $_postContentType\" -H \"$_H1\" -H \"$_H2\" -H \"$_H3\" -H \"$_H4\" -H \"$_H5\" --data \"$body\" \"$_post_url\" | _base64)\" else response=\"$($_CURL --user-agent \"$USER_AGENT\" -X $httpmethod -H \"$_H1\" -H \"$_H2\" -H \"$_H3\" -H \"$_H4\" -H \"$_H5\" --data \"$body\" \"$_post_url\" | _base64)\" fi else if [ \"$_postContentType\" ]; then response=\"$($_CURL --user-agent \"$USER_AGENT\" -X $httpmethod -H \"Content-Type: $_postContentType\" -H \"$_H1\" -H \"$_H2\" -H \"$_H3\" -H \"$_H4\" -H \"$_H5\" \"$_post_url\" | _base64)\" else response=\"$($_CURL --user-agent \"$USER_AGENT\" -X $httpmethod -H \"$_H1\" -H \"$_H2\" -H \"$_H3\" -H \"$_H4\" -H \"$_H5\" \"$_post_url\" | _base64)\" fi fi else if [ \"$body\" ]; then if [ \"$_postContentType\" ]; then response=\"$($_CURL --user-agent \"$USER_AGENT\" -X $httpmethod -H \"Content-Type: $_postContentType\" -H \"$_H1\" -H \"$_H2\" -H \"$_H3\" -H \"$_H4\" -H \"$_H5\" --data \"$body\" \"$_post_url\")\" else response=\"$($_CURL --user-agent \"$USER_AGENT\" -X $httpmethod -H \"$_H1\" -H \"$_H2\" -H \"$_H3\" -H \"$_H4\" -H \"$_H5\" --data \"$body\" \"$_post_url\")\" fi else if [ \"$_postContentType\" ]; then response=\"$($_CURL --user-agent \"$USER_AGENT\" -X $httpmethod -H \"Content-Type: $_postContentType\" -H \"$_H1\" -H \"$_H2\" -H \"$_H3\" -H \"$_H4\" -H \"$_H5\" \"$_post_url\")\" else response=\"$($_CURL --user-agent \"$USER_AGENT\" -X $httpmethod -H \"$_H1\" -H \"$_H2\" -H \"$_H3\" -H \"$_H4\" -H \"$_H5\" \"$_post_url\")\" fi fi fi _ret=\"$?\" if [ \"$_ret\" != \"0\" ]; then _err \"Please refer to https://curl.haxx.se/libcurl/c/libcurl-errors.html for error code: $_ret\" if [ \"$DEBUG\" ] && [ \"$DEBUG\" -ge \"2\" ]; then _err \"Here is the curl dump log:\" _err \"$(cat \"$_CURL_DUMP\")\" fi fi elif [ \"$_ACME_WGET\" ]; then _WGET=\"$_ACME_WGET\" if [ \"$HTTPS_INSECURE\" ]; then _WGET=\"$_WGET --no-check-certificate \" fi if [ \"$httpmethod\" = \"HEAD\" ]; then _WGET=\"$_WGET --read-timeout=3.0 --tries=2 \" fi _debug \"_WGET\" \"$_WGET\" if [ \"$needbase64\" ]; then if [ \"$httpmethod\" = \"POST\" ]; then if [ \"$_postContentType\" ]; then response=\"$($_WGET -S -O - --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" --header \"Content-Type: $_postContentType\" --post-data=\"$body\" \"$_post_url\" 2>\"$HTTP_HEADER\" | _base64)\" else response=\"$($_WGET -S -O - --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" --post-data=\"$body\" \"$_post_url\" 2>\"$HTTP_HEADER\" | _base64)\" fi else if [ \"$_postContentType\" ]; then response=\"$($_WGET -S -O - --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" --header \"Content-Type: $_postContentType\" --method $httpmethod --body-data=\"$body\" \"$_post_url\" 2>\"$HTTP_HEADER\" | _base64)\" else response=\"$($_WGET -S -O - --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" --method $httpmethod --body-data=\"$body\" \"$_post_url\" 2>\"$HTTP_HEADER\" | _base64)\" fi fi else if [ \"$httpmethod\" = \"POST\" ]; then if [ \"$_postContentType\" ]; then response=\"$($_WGET -S -O - --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" --header \"Content-Type: $_postContentType\" --post-data=\"$body\" \"$_post_url\" 2>\"$HTTP_HEADER\")\" else response=\"$($_WGET -S -O - --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" --post-data=\"$body\" \"$_post_url\" 2>\"$HTTP_HEADER\")\" fi elif [ \"$httpmethod\" = \"HEAD\" ]; then if [ \"$_postContentType\" ]; then response=\"$($_WGET --spider -S -O - --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" --header \"Content-Type: $_postContentType\" --post-data=\"$body\" \"$_post_url\" 2>\"$HTTP_HEADER\")\" else response=\"$($_WGET --spider -S -O - --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" --post-data=\"$body\" \"$_post_url\" 2>\"$HTTP_HEADER\")\" fi else if [ \"$_postContentType\" ]; then response=\"$($_WGET -S -O - --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" --header \"Content-Type: $_postContentType\" --method $httpmethod --body-data=\"$body\" \"$_post_url\" 2>\"$HTTP_HEADER\")\" else response=\"$($_WGET -S -O - --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" --method $httpmethod --body-data=\"$body\" \"$_post_url\" 2>\"$HTTP_HEADER\")\" fi fi fi _ret=\"$?\" if [ \"$_ret\" = \"8\" ]; then _ret=0 _debug \"wget returned 8 as the server returned a 'Bad Request' response. Let's process the response later.\" fi if [ \"$_ret\" != \"0\" ]; then _err \"Please refer to https://www.gnu.org/software/wget/manual/html_node/Exit-Status.html for error code: $_ret\" fi if _contains \"$_WGET\" \" -d \"; then # Demultiplex wget debug output cat \"$HTTP_HEADER\" >&2 _sed_i '/^[^ ][^ ]/d; /^ *$/d' \"$HTTP_HEADER\" fi # remove leading whitespaces from header to match curl format _sed_i 's/^ //g' \"$HTTP_HEADER\" else _ret=\"$?\" _err \"Neither curl nor wget have been found, cannot make $httpmethod request.\" fi _debug \"_ret\" \"$_ret\" printf \"%s\" \"$response\" return $_ret } # url getheader timeout _get() { _debug GET url=\"$1\" onlyheader=\"$2\" t=\"$3\" _debug url \"$url\" _debug \"timeout=$t\" _inithttp if [ \"$_ACME_CURL\" ] && [ \"${ACME_USE_WGET:-0}\" = \"0\" ]; then _CURL=\"$_ACME_CURL\" if [ \"$HTTPS_INSECURE\" ]; then _CURL=\"$_CURL --insecure \" fi if [ \"$t\" ]; then _CURL=\"$_CURL --connect-timeout $t\" fi _debug \"_CURL\" \"$_CURL\" if [ \"$onlyheader\" ]; then $_CURL -I --user-agent \"$USER_AGENT\" -H \"$_H1\" -H \"$_H2\" -H \"$_H3\" -H \"$_H4\" -H \"$_H5\" \"$url\" else $_CURL --user-agent \"$USER_AGENT\" -H \"$_H1\" -H \"$_H2\" -H \"$_H3\" -H \"$_H4\" -H \"$_H5\" \"$url\" fi ret=$? if [ \"$ret\" != \"0\" ]; then _err \"Please refer to https://curl.haxx.se/libcurl/c/libcurl-errors.html for error code: $ret\" if [ \"$DEBUG\" ] && [ \"$DEBUG\" -ge \"2\" ]; then _err \"Here is the curl dump log:\" _err \"$(cat \"$_CURL_DUMP\")\" fi fi elif [ \"$_ACME_WGET\" ]; then _WGET=\"$_ACME_WGET\" if [ \"$HTTPS_INSECURE\" ]; then _WGET=\"$_WGET --no-check-certificate \" fi if [ \"$t\" ]; then _WGET=\"$_WGET --timeout=$t\" fi _debug \"_WGET\" \"$_WGET\" if [ \"$onlyheader\" ]; then _wget_out=\"$($_WGET --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" -S -O /dev/null \"$url\" 2>&1)\" if _contains \"$_WGET\" \" -d \"; then # Demultiplex wget debug output echo \"$_wget_out\" >&2 echo \"$_wget_out\" | sed '/^[^ ][^ ]/d; /^ *$/d; s/^ //g' - fi else $_WGET --user-agent=\"$USER_AGENT\" --header \"$_H5\" --header \"$_H4\" --header \"$_H3\" --header \"$_H2\" --header \"$_H1\" -S -O - \"$url\" 2>\"$HTTP_HEADER\" if _contains \"$_WGET\" \" -d \"; then # Demultiplex wget debug output cat \"$HTTP_HEADER\" >&2 _sed_i '/^[^ ][^ ]/d; /^ *$/d' \"$HTTP_HEADER\" fi # remove leading whitespaces from header to match curl format _sed_i 's/^ //g' \"$HTTP_HEADER\" fi ret=$? if [ \"$ret\" = \"8\" ]; then ret=0 _debug \"wget returned 8 as the server returned a 'Bad Request' response. Let's process the response later.\" fi if [ \"$ret\" != \"0\" ]; then _err \"Please refer to https://www.gnu.org/software/wget/manual/html_node/Exit-Status.html for error code: $ret\" fi else ret=$? _err \"Neither curl nor wget have been found, cannot make GET request.\" fi _debug \"ret\" \"$ret\" return $ret } _head_n() { head -n \"$1\" } _tail_n() { if _is_solaris; then #fix for solaris tail -\"$1\" else tail -n \"$1\" fi } _tail_c() { tail -c \"$1\" 2>/dev/null || tail -\"$1\"c } # url payload needbase64 keyfile _send_signed_request() { url=$1 payload=$2 needbase64=$3 keyfile=$4 if [ -z \"$keyfile\" ]; then keyfile=\"$ACCOUNT_KEY_PATH\" fi _debug \"=======Sending Signed Request=======\" _debug url \"$url\" _debug payload \"$payload\" if ! _calcjwk \"$keyfile\"; then return 1 fi __request_conent_type=\"$CONTENT_TYPE_JSON\" payload64=$(printf \"%s\" \"$payload\" | _base64 | _url_replace) _debug3 payload64 \"$payload64\" MAX_REQUEST_RETRY_TIMES=20 _sleep_retry_sec=1 _request_retry_times=0 while [ \"${_request_retry_times}\" -lt \"$MAX_REQUEST_RETRY_TIMES\" ]; do _request_retry_times=$(_math \"$_request_retry_times\" + 1) _debug3 _request_retry_times \"$_request_retry_times\" if [ -z \"$_CACHED_NONCE\" ]; then _headers=\"\" if [ \"$ACME_NEW_NONCE\" ]; then _debug2 \"Get nonce with HEAD. ACME_NEW_NONCE\" \"$ACME_NEW_NONCE\" nonceurl=\"$ACME_NEW_NONCE\" if _post \"\" \"$nonceurl\" \"\" \"HEAD\" \"$__request_conent_type\" >/dev/null; then _headers=\"$(cat \"$HTTP_HEADER\")\" _debug2 _headers \"$_headers\" _CACHED_NONCE=\"$(echo \"$_headers\" | grep -i \"Replay-Nonce:\" | _head_n 1 | tr -d \"\\r\\n \" | cut -d ':' -f 2 | cut -d , -f 1)\" fi fi if [ -z \"$_CACHED_NONCE\" ]; then _debug2 \"Get nonce with GET. ACME_DIRECTORY\" \"$ACME_DIRECTORY\" nonceurl=\"$ACME_DIRECTORY\" _headers=\"$(_get \"$nonceurl\" \"onlyheader\")\" _debug2 _headers \"$_headers\" _CACHED_NONCE=\"$(echo \"$_headers\" | grep -i \"Replay-Nonce:\" | _head_n 1 | tr -d \"\\r\\n \" | cut -d ':' -f 2)\" fi if [ -z \"$_CACHED_NONCE\" ] && [ \"$ACME_NEW_NONCE\" ]; then _debug2 \"Get nonce with GET. ACME_NEW_NONCE\" \"$ACME_NEW_NONCE\" nonceurl=\"$ACME_NEW_NONCE\" _headers=\"$(_get \"$nonceurl\" \"onlyheader\")\" _debug2 _headers \"$_headers\" _CACHED_NONCE=\"$(echo \"$_headers\" | grep -i \"Replay-Nonce:\" | _head_n 1 | tr -d \"\\r\\n \" | cut -d ':' -f 2)\" fi _debug2 _CACHED_NONCE \"$_CACHED_NONCE\" if [ \"$?\" != \"0\" ]; then _err \"Cannot connect to $nonceurl to get nonce.\" return 1 fi else _debug2 \"Use _CACHED_NONCE\" \"$_CACHED_NONCE\" fi nonce=\"$_CACHED_NONCE\" _debug2 nonce \"$nonce\" if [ -z \"$nonce\" ]; then _info \"Could not get nonce, let's try again.\" _sleep 2 continue fi if [ \"$url\" = \"$ACME_NEW_ACCOUNT\" ]; then protected=\"$JWK_HEADERPLACE_PART1$nonce\\\", \\\"url\\\": \\\"${url}$JWK_HEADERPLACE_PART2, \\\"jwk\\\": $jwk\"'}' elif [ \"$url\" = \"$ACME_REVOKE_CERT\" ] && [ \"$keyfile\" != \"$ACCOUNT_KEY_PATH\" ]; then protected=\"$JWK_HEADERPLACE_PART1$nonce\\\", \\\"url\\\": \\\"${url}$JWK_HEADERPLACE_PART2, \\\"jwk\\\": $jwk\"'}' else protected=\"$JWK_HEADERPLACE_PART1$nonce\\\", \\\"url\\\": \\\"${url}$JWK_HEADERPLACE_PART2, \\\"kid\\\": \\\"${ACCOUNT_URL}\\\"\"'}' fi _debug3 protected \"$protected\" protected64=\"$(printf \"%s\" \"$protected\" | _base64 | _url_replace)\" _debug3 protected64 \"$protected64\" if ! _sig_t=\"$(printf \"%s\" \"$protected64.$payload64\" | _sign \"$keyfile\" \"sha256\")\"; then _err \"Sign request failed.\" return 1 fi _debug3 _sig_t \"$_sig_t\" sig=\"$(printf \"%s\" \"$_sig_t\" | _url_replace)\" _debug3 sig \"$sig\" body=\"{\\\"protected\\\": \\\"$protected64\\\", \\\"payload\\\": \\\"$payload64\\\", \\\"signature\\\": \\\"$sig\\\"}\" _debug3 body \"$body\" response=\"$(_post \"$body\" \"$url\" \"$needbase64\" \"POST\" \"$__request_conent_type\")\" _CACHED_NONCE=\"\" if [ \"$?\" != \"0\" ]; then _err \"Cannot make POST request to $url\" return 1 fi responseHeaders=\"$(cat \"$HTTP_HEADER\")\" _debug2 responseHeaders \"$responseHeaders\" code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\r\\n\")\" _debug code \"$code\" _debug2 original \"$response\" if echo \"$responseHeaders\" | grep -i \"Content-Type: *application/json\" >/dev/null 2>&1; then response=\"$(echo \"$response\" | _json_decode | _normalizeJson)\" fi _debug2 response \"$response\" _CACHED_NONCE=\"$(echo \"$responseHeaders\" | grep -i \"Replay-Nonce:\" | _head_n 1 | tr -d \"\\r\\n \" | cut -d ':' -f 2 | cut -d , -f 1)\" if ! _startswith \"$code\" \"2\"; then _body=\"$response\" if [ \"$needbase64\" ]; then _body=\"$(echo \"$_body\" | _dbase64 multiline)\" _debug3 _body \"$_body\" fi _retryafter=$(echo \"$responseHeaders\" | grep -i \"^Retry-After *: *[0-9]\\+ *\" | cut -d : -f 2 | tr -d ' ' | tr -d '\\r') if [ \"$code\" = '503' ]; then _sleep_overload_retry_sec=$_retryafter if [ -z \"$_sleep_overload_retry_sec\" ]; then _sleep_overload_retry_sec=5 fi if [ $_sleep_overload_retry_sec -le 600 ]; then _info \"It seems the CA server is currently overloaded, let's wait and retry. Sleeping for $_sleep_overload_retry_sec seconds.\" _sleep $_sleep_overload_retry_sec continue else _info \"The retryafter=$_retryafter value is too large (> 600), will not retry anymore.\" fi fi if _contains \"$_body\" \"JWS has invalid anti-replay nonce\" || _contains \"$_body\" \"JWS has an invalid anti-replay nonce\"; then _info \"It seems the CA server is busy now, let's wait and retry. Sleeping for $_sleep_retry_sec seconds.\" _CACHED_NONCE=\"\" _sleep $_sleep_retry_sec continue fi if _contains \"$_body\" \"The Replay Nonce is not recognized\"; then _info \"The replay nonce is not valid, let's get a new one. Sleeping for $_sleep_retry_sec seconds.\" _CACHED_NONCE=\"\" _sleep $_sleep_retry_sec continue fi fi return 0 done _info \"Giving up sending to CA server after $MAX_REQUEST_RETRY_TIMES retries.\" return 1 } #setopt \"file\" \"opt\" \"=\" \"value\" [\";\"] _setopt() { __conf=\"$1\" __opt=\"$2\" __sep=\"$3\" __val=\"$4\" __end=\"$5\" if [ -z \"$__opt\" ]; then _usage usage: _setopt '\"file\" \"opt\" \"=\" \"value\" [\";\"]' return fi if [ ! -f \"$__conf\" ]; then touch \"$__conf\" fi if [ -n \"$(_tail_c 1 <\"$__conf\")\" ]; then echo >>\"$__conf\" fi if grep -n \"^$__opt$__sep\" \"$__conf\" >/dev/null; then _debug3 OK if _contains \"$__val\" \"&\"; then __val=\"$(echo \"$__val\" | sed 's/&/\\\\&/g')\" fi if _contains \"$__val\" \"|\"; then __val=\"$(echo \"$__val\" | sed 's/|/\\\\|/g')\" fi text=\"$(cat \"$__conf\")\" printf -- \"%s\\n\" \"$text\" | sed \"s|^$__opt$__sep.*$|$__opt$__sep$__val$__end|\" >\"$__conf\" elif grep -n \"^#$__opt$__sep\" \"$__conf\" >/dev/null; then if _contains \"$__val\" \"&\"; then __val=\"$(echo \"$__val\" | sed 's/&/\\\\&/g')\" fi if _contains \"$__val\" \"|\"; then __val=\"$(echo \"$__val\" | sed 's/|/\\\\|/g')\" fi text=\"$(cat \"$__conf\")\" printf -- \"%s\\n\" \"$text\" | sed \"s|^#$__opt$__sep.*$|$__opt$__sep$__val$__end|\" >\"$__conf\" else _debug3 APP echo \"$__opt$__sep$__val$__end\" >>\"$__conf\" fi _debug3 \"$(grep -n \"^$__opt$__sep\" \"$__conf\")\" } #_save_conf file key value base64encode #save to conf _save_conf() { _s_c_f=\"$1\" _sdkey=\"$2\" _sdvalue=\"$3\" _b64encode=\"$4\" if [ \"$_sdvalue\" ] && [ \"$_b64encode\" ]; then _sdvalue=\"${B64CONF_START}$(printf \"%s\" \"${_sdvalue}\" | _base64)${B64CONF_END}\" fi if [ \"$_s_c_f\" ]; then _setopt \"$_s_c_f\" \"$_sdkey\" \"=\" \"'$_sdvalue'\" else _err \"Config file is empty, cannot save $_sdkey=$_sdvalue\" fi } #_clear_conf file key _clear_conf() { _c_c_f=\"$1\" _sdkey=\"$2\" if [ \"$_c_c_f\" ]; then _conf_data=\"$(cat \"$_c_c_f\")\" echo \"$_conf_data\" | sed \"/^$_sdkey *=.*$/d\" >\"$_c_c_f\" else _err \"Config file is empty, cannot clear\" fi } #_read_conf file key _read_conf() { _r_c_f=\"$1\" _sdkey=\"$2\" if [ -f \"$_r_c_f\" ]; then _sdv=\"$( eval \"$(grep \"^$_sdkey *=\" \"$_r_c_f\")\" eval \"printf \\\"%s\\\" \\\"\\$$_sdkey\\\"\" )\" if _startswith \"$_sdv\" \"${B64CONF_START}\" && _endswith \"$_sdv\" \"${B64CONF_END}\"; then _sdv=\"$(echo \"$_sdv\" | sed \"s/${B64CONF_START}//\" | sed \"s/${B64CONF_END}//\" | _dbase64)\" fi printf \"%s\" \"$_sdv\" else _debug \"Config file is empty, cannot read $_sdkey\" fi } #_savedomainconf key value base64encode #save to domain.conf _savedomainconf() { _save_conf \"$DOMAIN_CONF\" \"$@\" } #_cleardomainconf key _cleardomainconf() { _clear_conf \"$DOMAIN_CONF\" \"$1\" } #_readdomainconf key _readdomainconf() { _read_conf \"$DOMAIN_CONF\" \"$1\" } #_migratedomainconf oldkey newkey base64encode _migratedomainconf() { _old_key=\"$1\" _new_key=\"$2\" _b64encode=\"$3\" _old_value=$(_readdomainconf \"$_old_key\") _cleardomainconf \"$_old_key\" if [ -z \"$_old_value\" ]; then return 1 # migrated failed: old value is empty fi _new_value=$(_readdomainconf \"$_new_key\") if [ -n \"$_new_value\" ]; then _debug \"Domain config new key exists, old key $_old_key='$_old_value' has been removed.\" return 1 # migrated failed: old value replaced by new value fi _savedomainconf \"$_new_key\" \"$_old_value\" \"$_b64encode\" _debug \"Domain config $_old_key has been migrated to $_new_key.\" } #_migratedeployconf oldkey newkey base64encode _migratedeployconf() { _migratedomainconf \"$1\" \"SAVED_$2\" \"$3\" || _migratedomainconf \"SAVED_$1\" \"SAVED_$2\" \"$3\" # try only when oldkey itself is not found } #key value base64encode _savedeployconf() { _savedomainconf \"SAVED_$1\" \"$2\" \"$3\" #remove later _cleardomainconf \"$1\" } #key _getdeployconf() { _rac_key=\"$1\" _rac_value=\"$(eval echo \\$\"$_rac_key\")\" if [ \"$_rac_value\" ]; then if _startswith \"$_rac_value\" '\"' && _endswith \"$_rac_value\" '\"'; then _debug2 \"trim quotation marks\" eval $_rac_key=$_rac_value export $_rac_key fi return 0 # do nothing fi _saved=\"$(_readdomainconf \"SAVED_$_rac_key\")\" eval $_rac_key=\\$_saved export $_rac_key } #_saveaccountconf key value base64encode _saveaccountconf() { _save_conf \"$ACCOUNT_CONF_PATH\" \"$@\" } #key value base64encode _saveaccountconf_mutable() { _save_conf \"$ACCOUNT_CONF_PATH\" \"SAVED_$1\" \"$2\" \"$3\" #remove later _clearaccountconf \"$1\" } #key _readaccountconf() { _read_conf \"$ACCOUNT_CONF_PATH\" \"$1\" } #key _readaccountconf_mutable() { _rac_key=\"$1\" _readaccountconf \"SAVED_$_rac_key\" } #_clearaccountconf key _clearaccountconf() { _clear_conf \"$ACCOUNT_CONF_PATH\" \"$1\" } #key _clearaccountconf_mutable() { _clearaccountconf \"SAVED_$1\" #remove later _clearaccountconf \"$1\" } #_savecaconf key value _savecaconf() { _save_conf \"$CA_CONF\" \"$1\" \"$2\" } #_readcaconf key _readcaconf() { _read_conf \"$CA_CONF\" \"$1\" } #_clearaccountconf key _clearcaconf() { _clear_conf \"$CA_CONF\" \"$1\" } # content localaddress _startserver() { content=\"$1\" ncaddr=\"$2\" _debug \"content\" \"$content\" _debug \"ncaddr\" \"$ncaddr\" _debug \"startserver: $$\" _debug Le_HTTPPort \"$Le_HTTPPort\" _debug Le_Listen_V4 \"$Le_Listen_V4\" _debug Le_Listen_V6 \"$Le_Listen_V6\" _NC=\"socat\" if [ \"$Le_Listen_V6\" ]; then _NC=\"$_NC -6\" else _NC=\"$_NC -4\" fi if [ \"$DEBUG\" ] && [ \"$DEBUG\" -gt \"1\" ]; then _NC=\"$_NC -d -d -v\" fi SOCAT_OPTIONS=TCP-LISTEN:$Le_HTTPPort,crlf,reuseaddr,fork #Adding bind to local-address if [ \"$ncaddr\" ]; then SOCAT_OPTIONS=\"$SOCAT_OPTIONS,bind=${ncaddr}\" fi _content_len=\"$(printf \"%s\" \"$content\" | wc -c)\" _debug _content_len \"$_content_len\" _debug \"_NC\" \"$_NC $SOCAT_OPTIONS\" export _SOCAT_ERR=\"$(_mktemp)\" $_NC $SOCAT_OPTIONS SYSTEM:\"sleep 1; \\ echo 'HTTP/1.0 200 OK'; \\ echo 'Content-Length\\: $_content_len'; \\ echo ''; \\ printf '%s' '$content';\" 2>\"$_SOCAT_ERR\" & serverproc=\"$!\" if [ -f \"$_SOCAT_ERR\" ]; then if grep \"Permission denied\" \"$_SOCAT_ERR\" >/dev/null; then _err \"socat: $(cat $_SOCAT_ERR)\" _err \"Can not listen for user: $(whoami)\" _err \"Maybe try with root again?\" rm -f \"$_SOCAT_ERR\" return 1 fi fi } _stopserver() { pid=\"$1\" _debug \"pid\" \"$pid\" if [ -z \"$pid\" ]; then rm -f \"$_SOCAT_ERR\" return fi kill $pid rm -f \"$_SOCAT_ERR\" } # sleep sec _sleep() { _sleep_sec=\"$1\" if [ \"$__INTERACTIVE\" ]; then _sleep_c=\"$_sleep_sec\" while [ \"$_sleep_c\" -ge \"0\" ]; do printf \"\\r \\r\" __green \"$_sleep_c\" _sleep_c=\"$(_math \"$_sleep_c\" - 1)\" sleep 1 done printf \"\\r\" else sleep \"$_sleep_sec\" fi } # _starttlsserver san_a san_b port content _ncaddr acmeValidationv1 _starttlsserver() { _info \"Starting tls server.\" san_a=\"$1\" san_b=\"$2\" port=\"$3\" content=\"$4\" opaddr=\"$5\" acmeValidationv1=\"$6\" _debug san_a \"$san_a\" _debug san_b \"$san_b\" _debug port \"$port\" _debug acmeValidationv1 \"$acmeValidationv1\" #create key TLS_KEY if ! _createkey \"2048\" \"$TLS_KEY\"; then _err \"Error creating TLS validation key.\" return 1 fi #create csr alt=\"$san_a\" if [ \"$san_b\" ]; then alt=\"$alt,$san_b\" fi if ! _createcsr \"tls.acme.sh\" \"$alt\" \"$TLS_KEY\" \"$TLS_CSR\" \"$TLS_CONF\" \"$acmeValidationv1\"; then _err \"Error creating TLS validation CSR.\" return 1 fi #self signed if ! _signcsr \"$TLS_KEY\" \"$TLS_CSR\" \"$TLS_CONF\" \"$TLS_CERT\"; then _err \"Error creating TLS validation cert.\" return 1 fi __S_OPENSSL=\"${ACME_OPENSSL_BIN:-openssl} s_server -www -cert $TLS_CERT -key $TLS_KEY \" if [ \"$opaddr\" ]; then __S_OPENSSL=\"$__S_OPENSSL -accept $opaddr:$port\" else __S_OPENSSL=\"$__S_OPENSSL -accept $port\" fi _debug Le_Listen_V4 \"$Le_Listen_V4\" _debug Le_Listen_V6 \"$Le_Listen_V6\" if [ \"$Le_Listen_V4\" ]; then __S_OPENSSL=\"$__S_OPENSSL -4\" elif [ \"$Le_Listen_V6\" ]; then __S_OPENSSL=\"$__S_OPENSSL -6\" fi if [ \"$acmeValidationv1\" ]; then __S_OPENSSL=\"$__S_OPENSSL -alpn acme-tls/1\" fi _debug \"$__S_OPENSSL\" if [ \"$DEBUG\" ] && [ \"$DEBUG\" -ge \"2\" ]; then $__S_OPENSSL -tlsextdebug & else $__S_OPENSSL >/dev/null 2>&1 & fi serverproc=\"$!\" sleep 1 _debug serverproc \"$serverproc\" } #file _readlink() { _rf=\"$1\" if ! readlink -f \"$_rf\" 2>/dev/null; then if _startswith \"$_rf\" \"/\"; then echo \"$_rf\" return 0 fi echo \"$(pwd)/$_rf\" | _conapath fi } _conapath() { sed \"s#/\\./#/#g\" } __initHome() { if [ -z \"$_SCRIPT_HOME\" ]; then if _exists readlink && _exists dirname; then _debug \"Let's find the script directory.\" _debug \"_SCRIPT_\" \"$_SCRIPT_\" _script=\"$(_readlink \"$_SCRIPT_\")\" _debug \"_script\" \"$_script\" _script_home=\"$(dirname \"$_script\")\" _debug \"_script_home\" \"$_script_home\" if [ -d \"$_script_home\" ]; then export _SCRIPT_HOME=\"$_script_home\" else _err \"It seems the script home is not correct: $_script_home\" fi fi fi # if [ -z \"$LE_WORKING_DIR\" ]; then # if [ -f \"$DEFAULT_INSTALL_HOME/account.conf\" ]; then # _debug \"It seems that $PROJECT_NAME is already installed in $DEFAULT_INSTALL_HOME\" # LE_WORKING_DIR=\"$DEFAULT_INSTALL_HOME\" # else # LE_WORKING_DIR=\"$_SCRIPT_HOME\" # fi # fi if [ -z \"$LE_WORKING_DIR\" ]; then _debug \"Using default home: $DEFAULT_INSTALL_HOME\" LE_WORKING_DIR=\"$DEFAULT_INSTALL_HOME\" fi export LE_WORKING_DIR if [ -z \"$LE_CONFIG_HOME\" ]; then LE_CONFIG_HOME=\"$LE_WORKING_DIR\" fi _debug \"Using config home: $LE_CONFIG_HOME\" export LE_CONFIG_HOME _DEFAULT_ACCOUNT_CONF_PATH=\"$LE_CONFIG_HOME/account.conf\" if [ -z \"$ACCOUNT_CONF_PATH\" ]; then if [ -f \"$_DEFAULT_ACCOUNT_CONF_PATH\" ]; then . \"$_DEFAULT_ACCOUNT_CONF_PATH\" fi fi if [ -z \"$ACCOUNT_CONF_PATH\" ]; then ACCOUNT_CONF_PATH=\"$_DEFAULT_ACCOUNT_CONF_PATH\" fi _debug3 ACCOUNT_CONF_PATH \"$ACCOUNT_CONF_PATH\" DEFAULT_LOG_FILE=\"$LE_CONFIG_HOME/$PROJECT_NAME.log\" DEFAULT_CA_HOME=\"$LE_CONFIG_HOME/ca\" if [ -z \"$LE_TEMP_DIR\" ]; then LE_TEMP_DIR=\"$LE_CONFIG_HOME/tmp\" fi } _clearAPI() { ACME_NEW_ACCOUNT=\"\" ACME_KEY_CHANGE=\"\" ACME_NEW_AUTHZ=\"\" ACME_NEW_ORDER=\"\" ACME_REVOKE_CERT=\"\" ACME_NEW_NONCE=\"\" ACME_AGREEMENT=\"\" } #server _initAPI() { _api_server=\"${1:-$ACME_DIRECTORY}\" _debug \"_init API for server: $_api_server\" MAX_API_RETRY_TIMES=10 _sleep_retry_sec=10 _request_retry_times=0 while [ -z \"$ACME_NEW_ACCOUNT\" ] && [ \"${_request_retry_times}\" -lt \"$MAX_API_RETRY_TIMES\" ]; do _request_retry_times=$(_math \"$_request_retry_times\" + 1) response=$(_get \"$_api_server\") if [ \"$?\" != \"0\" ]; then _debug2 \"response\" \"$response\" _info \"Cannot init API for: $_api_server.\" _info \"Sleeping for $_sleep_retry_sec seconds and retrying.\" _sleep \"$_sleep_retry_sec\" continue fi response=$(echo \"$response\" | _json_decode) _debug2 \"response\" \"$response\" ACME_KEY_CHANGE=$(echo \"$response\" | _egrep_o 'keyChange\" *: *\"[^\"]*\"' | cut -d '\"' -f 3) export ACME_KEY_CHANGE ACME_NEW_AUTHZ=$(echo \"$response\" | _egrep_o 'newAuthz\" *: *\"[^\"]*\"' | cut -d '\"' -f 3) export ACME_NEW_AUTHZ ACME_NEW_ORDER=$(echo \"$response\" | _egrep_o 'newOrder\" *: *\"[^\"]*\"' | cut -d '\"' -f 3) export ACME_NEW_ORDER ACME_NEW_ACCOUNT=$(echo \"$response\" | _egrep_o 'newAccount\" *: *\"[^\"]*\"' | cut -d '\"' -f 3) export ACME_NEW_ACCOUNT ACME_REVOKE_CERT=$(echo \"$response\" | _egrep_o 'revokeCert\" *: *\"[^\"]*\"' | cut -d '\"' -f 3) export ACME_REVOKE_CERT ACME_NEW_NONCE=$(echo \"$response\" | _egrep_o 'newNonce\" *: *\"[^\"]*\"' | cut -d '\"' -f 3) export ACME_NEW_NONCE ACME_AGREEMENT=$(echo \"$response\" | _egrep_o 'termsOfService\" *: *\"[^\"]*\"' | cut -d '\"' -f 3) export ACME_AGREEMENT _debug \"ACME_KEY_CHANGE\" \"$ACME_KEY_CHANGE\" _debug \"ACME_NEW_AUTHZ\" \"$ACME_NEW_AUTHZ\" _debug \"ACME_NEW_ORDER\" \"$ACME_NEW_ORDER\" _debug \"ACME_NEW_ACCOUNT\" \"$ACME_NEW_ACCOUNT\" _debug \"ACME_REVOKE_CERT\" \"$ACME_REVOKE_CERT\" _debug \"ACME_AGREEMENT\" \"$ACME_AGREEMENT\" _debug \"ACME_NEW_NONCE\" \"$ACME_NEW_NONCE\" if [ \"$ACME_NEW_ACCOUNT\" ] && [ \"$ACME_NEW_ORDER\" ]; then return 0 fi _info \"Sleeping for $_sleep_retry_sec seconds and retrying.\" _sleep \"$_sleep_retry_sec\" done if [ \"$ACME_NEW_ACCOUNT\" ] && [ \"$ACME_NEW_ORDER\" ]; then return 0 fi _err \"Cannot init API for $_api_server\" return 1 } _clearCA() { export CA_CONF= export ACCOUNT_KEY_PATH= export ACCOUNT_JSON_PATH= } #[domain] [keylength or isEcc flag] _initpath() { domain=\"$1\" _ilength=\"$2\" __initHome if [ -f \"$ACCOUNT_CONF_PATH\" ]; then . \"$ACCOUNT_CONF_PATH\" fi if [ \"$_ACME_IN_CRON\" ]; then if [ ! \"$_USER_PATH_EXPORTED\" ]; then _USER_PATH_EXPORTED=1 export PATH=\"$USER_PATH:$PATH\" fi fi if [ -z \"$CA_HOME\" ]; then CA_HOME=\"$DEFAULT_CA_HOME\" fi if [ -z \"$ACME_DIRECTORY\" ]; then if [ \"$STAGE\" ]; then ACME_DIRECTORY=\"$DEFAULT_STAGING_CA\" _info \"Using ACME_DIRECTORY: $ACME_DIRECTORY\" else default_acme_server=$(_readaccountconf \"DEFAULT_ACME_SERVER\") _debug default_acme_server \"$default_acme_server\" if [ \"$default_acme_server\" ]; then ACME_DIRECTORY=\"$default_acme_server\" else ACME_DIRECTORY=\"$DEFAULT_CA\" fi fi fi _debug ACME_DIRECTORY \"$ACME_DIRECTORY\" _ACME_SERVER_HOST=\"$(echo \"$ACME_DIRECTORY\" | cut -d : -f 2 | tr -s / | cut -d / -f 2)\" _debug2 \"_ACME_SERVER_HOST\" \"$_ACME_SERVER_HOST\" _ACME_SERVER_PATH=\"$(echo \"$ACME_DIRECTORY\" | cut -d : -f 2- | tr -s / | cut -d / -f 3-)\" _debug2 \"_ACME_SERVER_PATH\" \"$_ACME_SERVER_PATH\" CA_DIR=\"$CA_HOME/$_ACME_SERVER_HOST/$_ACME_SERVER_PATH\" _DEFAULT_CA_CONF=\"$CA_DIR/ca.conf\" if [ -z \"$CA_CONF\" ]; then CA_CONF=\"$_DEFAULT_CA_CONF\" fi _debug3 CA_CONF \"$CA_CONF\" _OLD_CADIR=\"$CA_HOME/$_ACME_SERVER_HOST\" _OLD_ACCOUNT_KEY=\"$_OLD_CADIR/account.key\" _OLD_ACCOUNT_JSON=\"$_OLD_CADIR/account.json\" _OLD_CA_CONF=\"$_OLD_CADIR/ca.conf\" _DEFAULT_ACCOUNT_KEY_PATH=\"$CA_DIR/account.key\" _DEFAULT_ACCOUNT_JSON_PATH=\"$CA_DIR/account.json\" if [ -z \"$ACCOUNT_KEY_PATH\" ]; then ACCOUNT_KEY_PATH=\"$_DEFAULT_ACCOUNT_KEY_PATH\" if [ -f \"$_OLD_ACCOUNT_KEY\" ] && ! [ -f \"$ACCOUNT_KEY_PATH\" ]; then mkdir -p \"$CA_DIR\" mv \"$_OLD_ACCOUNT_KEY\" \"$ACCOUNT_KEY_PATH\" fi fi if [ -z \"$ACCOUNT_JSON_PATH\" ]; then ACCOUNT_JSON_PATH=\"$_DEFAULT_ACCOUNT_JSON_PATH\" if [ -f \"$_OLD_ACCOUNT_JSON\" ] && ! [ -f \"$ACCOUNT_JSON_PATH\" ]; then mkdir -p \"$CA_DIR\" mv \"$_OLD_ACCOUNT_JSON\" \"$ACCOUNT_JSON_PATH\" fi fi if [ -f \"$_OLD_CA_CONF\" ] && ! [ -f \"$CA_CONF\" ]; then mkdir -p \"$CA_DIR\" mv \"$_OLD_CA_CONF\" \"$CA_CONF\" fi if [ -f \"$CA_CONF\" ]; then . \"$CA_CONF\" fi if [ -z \"$ACME_DIR\" ]; then ACME_DIR=\"/home/.acme\" fi if [ -z \"$APACHE_CONF_BACKUP_DIR\" ]; then APACHE_CONF_BACKUP_DIR=\"$LE_CONFIG_HOME\" fi if [ -z \"$USER_AGENT\" ]; then USER_AGENT=\"$DEFAULT_USER_AGENT\" fi if [ -z \"$HTTP_HEADER\" ]; then HTTP_HEADER=\"$LE_CONFIG_HOME/http.header\" fi _DEFAULT_CERT_HOME=\"$LE_CONFIG_HOME\" if [ -z \"$CERT_HOME\" ]; then CERT_HOME=\"$_DEFAULT_CERT_HOME\" fi if [ -z \"$ACME_OPENSSL_BIN\" ] || [ ! -f \"$ACME_OPENSSL_BIN\" ] || [ ! -x \"$ACME_OPENSSL_BIN\" ]; then ACME_OPENSSL_BIN=\"$DEFAULT_OPENSSL_BIN\" fi if [ -z \"$domain\" ]; then return 0 fi if [ -z \"$DOMAIN_PATH\" ]; then domainhome=\"$CERT_HOME/$domain\" domainhomeecc=\"$CERT_HOME/$domain$ECC_SUFFIX\" DOMAIN_PATH=\"$domainhome\" if _isEccKey \"$_ilength\"; then DOMAIN_PATH=\"$domainhomeecc\" elif [ -z \"$__SELECTED_RSA_KEY\" ]; then if [ ! -d \"$domainhome\" ] && [ -d \"$domainhomeecc\" ]; then _info \"The domain '$domain' seems to already have an ECC cert, let's use it.\" DOMAIN_PATH=\"$domainhomeecc\" fi fi _debug DOMAIN_PATH \"$DOMAIN_PATH\" export DOMAIN_PATH fi if [ -z \"$DOMAIN_BACKUP_PATH\" ]; then DOMAIN_BACKUP_PATH=\"$DOMAIN_PATH/backup\" fi if [ -z \"$DOMAIN_CONF\" ]; then DOMAIN_CONF=\"$DOMAIN_PATH/$domain.conf\" fi if [ -z \"$DOMAIN_SSL_CONF\" ]; then DOMAIN_SSL_CONF=\"$DOMAIN_PATH/$domain.csr.conf\" fi if [ -z \"$CSR_PATH\" ]; then CSR_PATH=\"$DOMAIN_PATH/$domain.csr\" fi if [ -z \"$CERT_KEY_PATH\" ]; then CERT_KEY_PATH=\"$DOMAIN_PATH/$domain.key\" fi if [ -z \"$CERT_PATH\" ]; then CERT_PATH=\"$DOMAIN_PATH/$domain.cer\" fi if [ -z \"$CA_CERT_PATH\" ]; then CA_CERT_PATH=\"$DOMAIN_PATH/ca.cer\" fi if [ -z \"$CERT_FULLCHAIN_PATH\" ]; then CERT_FULLCHAIN_PATH=\"$DOMAIN_PATH/fullchain.cer\" fi if [ -z \"$CERT_PFX_PATH\" ]; then CERT_PFX_PATH=\"$DOMAIN_PATH/$domain.pfx\" fi if [ -z \"$CERT_PKCS8_PATH\" ]; then CERT_PKCS8_PATH=\"$DOMAIN_PATH/$domain.pkcs8\" fi if [ -z \"$TLS_CONF\" ]; then TLS_CONF=\"$DOMAIN_PATH/tls.validation.conf\" fi if [ -z \"$TLS_CERT\" ]; then TLS_CERT=\"$DOMAIN_PATH/tls.validation.cert\" fi if [ -z \"$TLS_KEY\" ]; then TLS_KEY=\"$DOMAIN_PATH/tls.validation.key\" fi if [ -z \"$TLS_CSR\" ]; then TLS_CSR=\"$DOMAIN_PATH/tls.validation.csr\" fi } _apachePath() { _APACHECTL=\"apachectl\" if ! _exists apachectl; then if _exists apache2ctl; then _APACHECTL=\"apache2ctl\" else _err \"'apachectl not found. It seems that Apache is not installed or you are not root.'\" _err \"Please use webroot mode to try again.\" return 1 fi fi if ! $_APACHECTL -V >/dev/null; then return 1 fi if [ \"$APACHE_HTTPD_CONF\" ]; then _saveaccountconf APACHE_HTTPD_CONF \"$APACHE_HTTPD_CONF\" httpdconf=\"$APACHE_HTTPD_CONF\" httpdconfname=\"$(basename \"$httpdconfname\")\" else httpdconfname=\"$($_APACHECTL -V | grep SERVER_CONFIG_FILE= | cut -d = -f 2 | tr -d '\"')\" _debug httpdconfname \"$httpdconfname\" if [ -z \"$httpdconfname\" ]; then _err \"Cannot read Apache config file.\" return 1 fi if _startswith \"$httpdconfname\" '/'; then httpdconf=\"$httpdconfname\" httpdconfname=\"$(basename \"$httpdconfname\")\" else httpdroot=\"$($_APACHECTL -V | grep HTTPD_ROOT= | cut -d = -f 2 | tr -d '\"')\" _debug httpdroot \"$httpdroot\" httpdconf=\"$httpdroot/$httpdconfname\" httpdconfname=\"$(basename \"$httpdconfname\")\" fi fi _debug httpdconf \"$httpdconf\" _debug httpdconfname \"$httpdconfname\" if [ ! -f \"$httpdconf\" ]; then _err \"Apache config file not found\" \"$httpdconf\" return 1 fi return 0 } _restoreApache() { if [ -z \"$usingApache\" ]; then return 0 fi _initpath if ! _apachePath; then return 1 fi if [ ! -f \"$APACHE_CONF_BACKUP_DIR/$httpdconfname\" ]; then _debug \"No config file to restore.\" return 0 fi cat \"$APACHE_CONF_BACKUP_DIR/$httpdconfname\" >\"$httpdconf\" _debug \"Restored: $httpdconf.\" if ! $_APACHECTL -t; then _err \"Sorry, there's been an error restoring the Apache config. Please ask for support on $PROJECT.\" return 1 fi _debug \"Restored successfully.\" rm -f \"$APACHE_CONF_BACKUP_DIR/$httpdconfname\" return 0 } _setApache() { _initpath if ! _apachePath; then return 1 fi #test the conf first _info \"Checking if there is an error in the Apache config file before starting.\" if ! $_APACHECTL -t >/dev/null; then _err \"The Apache config file has errors, please fix them first then try again.\" _err \"Don't worry, no changes to your system have been made.\" return 1 else _info \"OK\" fi #backup the conf _debug \"Backing up Apache config file\" \"$httpdconf\" if ! cp \"$httpdconf\" \"$APACHE_CONF_BACKUP_DIR/\"; then _err \"Cannot backup Apache config file, aborting. Don't worry, the Apache config has not been changed.\" _err \"This might be an $PROJECT_NAME bug, please open an issue on $PROJECT\" return 1 fi _info \"Config file $httpdconf has been backed up to $APACHE_CONF_BACKUP_DIR/$httpdconfname\" _info \"In case an error causes it to not be restored automatically, you can restore it yourself.\" _info \"You do not need to do anything on success, as the backup file will automatically be deleted.\" #add alias apacheVer=\"$($_APACHECTL -V | grep \"Server version:\" | cut -d : -f 2 | cut -d \" \" -f 2 | cut -d '/' -f 2)\" _debug \"apacheVer\" \"$apacheVer\" apacheMajor=\"$(echo \"$apacheVer\" | cut -d . -f 1)\" apacheMinor=\"$(echo \"$apacheVer\" | cut -d . -f 2)\" if [ \"$apacheVer\" ] && [ \"$apacheMajor$apacheMinor\" -ge \"24\" ]; then echo \" Alias /.well-known/acme-challenge $ACME_DIR <Directory $ACME_DIR > Require all granted </Directory> \" >>\"$httpdconf\" else echo \" Alias /.well-known/acme-challenge $ACME_DIR <Directory $ACME_DIR > Order allow,deny Allow from all </Directory> \" >>\"$httpdconf\" fi _msg=\"$($_APACHECTL -t 2>&1)\" if [ \"$?\" != \"0\" ]; then _err \"Sorry, an Apache config error has occurred\" if _restoreApache; then _err \"The Apache config file has been restored.\" else _err \"Sorry, the Apache config file cannot be restored, please open an issue on $PROJECT.\" fi return 1 fi if [ ! -d \"$ACME_DIR\" ]; then mkdir -p \"$ACME_DIR\" chmod 755 \"$ACME_DIR\" fi if ! $_APACHECTL graceful; then _err \"$_APACHECTL graceful error, please open an issue on $PROJECT.\" _restoreApache return 1 fi usingApache=\"1\" return 0 } #find the real nginx conf file #backup #set the nginx conf #returns the real nginx conf file _setNginx() { _d=\"$1\" _croot=\"$2\" _thumbpt=\"$3\" FOUND_REAL_NGINX_CONF=\"\" FOUND_REAL_NGINX_CONF_LN=\"\" BACKUP_NGINX_CONF=\"\" _debug _croot \"$_croot\" _start_f=\"$(echo \"$_croot\" | cut -d : -f 2)\" _debug _start_f \"$_start_f\" if [ -z \"$_start_f\" ]; then _debug \"Finding config using the nginx command\" if [ -z \"$NGINX_CONF\" ]; then if ! _exists \"nginx\"; then _err \"nginx command not found.\" return 1 fi NGINX_CONF=\"$(nginx -V 2>&1 | _egrep_o \"\\-\\-conf-path=[^ ]* \" | tr -d \" \")\" _debug NGINX_CONF \"$NGINX_CONF\" NGINX_CONF=\"$(echo \"$NGINX_CONF\" | cut -d = -f 2)\" _debug NGINX_CONF \"$NGINX_CONF\" if [ -z \"$NGINX_CONF\" ]; then _err \"Cannot find nginx config.\" NGINX_CONF=\"\" return 1 fi if [ ! -f \"$NGINX_CONF\" ]; then _err \"'$NGINX_CONF' doesn't exist.\" NGINX_CONF=\"\" return 1 fi _debug \"Found nginx config file: $NGINX_CONF\" fi _start_f=\"$NGINX_CONF\" fi _debug \"Detecting nginx conf for $_d from: $_start_f\" if ! _checkConf \"$_d\" \"$_start_f\"; then _err \"Cannot find config file for domain $d\" return 1 fi _info \"Found config file: $FOUND_REAL_NGINX_CONF\" _ln=$FOUND_REAL_NGINX_CONF_LN _debug \"_ln\" \"$_ln\" _lnn=$(_math $_ln + 1) _debug _lnn \"$_lnn\" _start_tag=\"$(sed -n \"$_lnn,${_lnn}p\" \"$FOUND_REAL_NGINX_CONF\")\" _debug \"_start_tag\" \"$_start_tag\" if [ \"$_start_tag\" = \"$NGINX_START\" ]; then _info \"The domain $_d is already configured, skipping\" FOUND_REAL_NGINX_CONF=\"\" return 0 fi mkdir -p \"$DOMAIN_BACKUP_PATH\" _backup_conf=\"$DOMAIN_BACKUP_PATH/$_d.nginx.conf\" _debug _backup_conf \"$_backup_conf\" BACKUP_NGINX_CONF=\"$_backup_conf\" _info \"Backing $FOUND_REAL_NGINX_CONF up to $_backup_conf\" if ! cp \"$FOUND_REAL_NGINX_CONF\" \"$_backup_conf\"; then _err \"Backup error.\" FOUND_REAL_NGINX_CONF=\"\" return 1 fi if ! _exists \"nginx\"; then _err \"nginx command not found.\" return 1 fi _info \"Checking the nginx config before setting up.\" if ! nginx -t >/dev/null 2>&1; then _err \"It seems that the nginx config is not correct, cannot continue.\" return 1 fi _info \"OK, setting up the nginx config file\" if ! sed -n \"1,${_ln}p\" \"$_backup_conf\" >\"$FOUND_REAL_NGINX_CONF\"; then cat \"$_backup_conf\" >\"$FOUND_REAL_NGINX_CONF\" _err \"Error writing nginx config. Restoring it to its original version.\" return 1 fi echo \"$NGINX_START location ~ \\\"^/\\.well-known/acme-challenge/([-_a-zA-Z0-9]+)\\$\\\" { default_type text/plain; return 200 \\\"\\$1.$_thumbpt\\\"; } #NGINX_START \" >>\"$FOUND_REAL_NGINX_CONF\" if ! sed -n \"${_lnn},99999p\" \"$_backup_conf\" >>\"$FOUND_REAL_NGINX_CONF\"; then cat \"$_backup_conf\" >\"$FOUND_REAL_NGINX_CONF\" _err \"Error writing nginx config. Restoring it to its original version.\" return 1 fi _debug3 \"Modified config:$(cat $FOUND_REAL_NGINX_CONF)\" _info \"nginx config has been written, let's check it again.\" if ! nginx -t >/dev/null 2>&1; then _err \"There seems to be a problem with the nginx config, let's restore it to its original version.\" cat \"$_backup_conf\" >\"$FOUND_REAL_NGINX_CONF\" return 1 fi _info \"Reloading nginx\" if ! nginx -s reload >/dev/null 2>&1; then _err \"There seems to be a problem with the nginx config, let's restore it to its original version.\" cat \"$_backup_conf\" >\"$FOUND_REAL_NGINX_CONF\" return 1 fi return 0 } #d , conf _checkConf() { _d=\"$1\" _c_file=\"$2\" _debug \"Starting _checkConf from: $_c_file\" if [ ! -f \"$2\" ] && ! echo \"$2\" | grep '*$' >/dev/null && echo \"$2\" | grep '*' >/dev/null; then _debug \"wildcard\" for _w_f in $2; do if [ -f \"$_w_f\" ] && _checkConf \"$1\" \"$_w_f\"; then return 0 fi done #not found return 1 elif [ -f \"$2\" ]; then _debug \"single\" if _isRealNginxConf \"$1\" \"$2\"; then _debug \"$2 found.\" FOUND_REAL_NGINX_CONF=\"$2\" return 0 fi if cat \"$2\" | tr \"\\t\" \" \" | grep \"^ *include *.*;\" >/dev/null; then _debug \"Trying include files\" for included in $(cat \"$2\" | tr \"\\t\" \" \" | grep \"^ *include *.*;\" | sed \"s/include //\" | tr -d \" ;\"); do _debug \"Checking included $included\" if ! _startswith \"$included\" \"/\" && _exists dirname; then _relpath=\"$(dirname \"$2\")\" _debug \"_relpath\" \"$_relpath\" included=\"$_relpath/$included\" fi if _checkConf \"$1\" \"$included\"; then return 0 fi done fi return 1 else _debug \"$2 not found.\" return 1 fi return 1 } #d , conf _isRealNginxConf() { _debug \"_isRealNginxConf $1 $2\" if [ -f \"$2\" ]; then for _fln in $(tr \"\\t\" ' ' <\"$2\" | grep -n \"^ *server_name.* $1\" | cut -d : -f 1); do _debug _fln \"$_fln\" if [ \"$_fln\" ]; then _start=$(tr \"\\t\" ' ' <\"$2\" | _head_n \"$_fln\" | grep -n \"^ *server *\" | grep -v server_name | _tail_n 1) _debug \"_start\" \"$_start\" _start_n=$(echo \"$_start\" | cut -d : -f 1) _start_nn=$(_math $_start_n + 1) _debug \"_start_n\" \"$_start_n\" _debug \"_start_nn\" \"$_start_nn\" _left=\"$(sed -n \"${_start_nn},99999p\" \"$2\")\" _debug2 _left \"$_left\" _end=\"$(echo \"$_left\" | tr \"\\t\" ' ' | grep -n \"^ *server *\" | grep -v server_name | _head_n 1)\" _debug \"_end\" \"$_end\" if [ \"$_end\" ]; then _end_n=$(echo \"$_end\" | cut -d : -f 1) _debug \"_end_n\" \"$_end_n\" _seg_n=$(echo \"$_left\" | sed -n \"1,${_end_n}p\") else _seg_n=\"$_left\" fi _debug \"_seg_n\" \"$_seg_n\" _skip_ssl=1 for _listen_i in $(echo \"$_seg_n\" | tr \"\\t\" ' ' | grep \"^ *listen\" | tr -d \" \"); do if [ \"$_listen_i\" ]; then if [ \"$(echo \"$_listen_i\" | _egrep_o \"listen.*ssl\")\" ]; then _debug2 \"$_listen_i is ssl\" else _debug2 \"$_listen_i is plain text\" _skip_ssl=\"\" break fi fi done if [ \"$_skip_ssl\" = \"1\" ]; then _debug \"ssl on, skip\" else FOUND_REAL_NGINX_CONF_LN=$_fln _debug3 \"found FOUND_REAL_NGINX_CONF_LN\" \"$FOUND_REAL_NGINX_CONF_LN\" return 0 fi fi done fi return 1 } #restore all the nginx conf _restoreNginx() { if [ -z \"$NGINX_RESTORE_VLIST\" ]; then _debug \"No need to restore nginx config, skipping.\" return fi _debug \"_restoreNginx\" _debug \"NGINX_RESTORE_VLIST\" \"$NGINX_RESTORE_VLIST\" for ng_entry in $(echo \"$NGINX_RESTORE_VLIST\" | tr \"$dvsep\" ' '); do _debug \"ng_entry\" \"$ng_entry\" _nd=$(echo \"$ng_entry\" | cut -d \"$sep\" -f 1) _ngconf=$(echo \"$ng_entry\" | cut -d \"$sep\" -f 2) _ngbackupconf=$(echo \"$ng_entry\" | cut -d \"$sep\" -f 3) _info \"Restoring from $_ngbackupconf to $_ngconf\" cat \"$_ngbackupconf\" >\"$_ngconf\" done _info \"Reloading nginx\" if ! nginx -s reload >/dev/null; then _err \"An error occurred while reloading nginx, please open an issue on $PROJECT.\" return 1 fi return 0 } _clearup() { _stopserver \"$serverproc\" serverproc=\"\" _restoreApache _restoreNginx _clearupdns if [ -z \"$DEBUG\" ]; then rm -f \"$TLS_CONF\" rm -f \"$TLS_CERT\" rm -f \"$TLS_KEY\" rm -f \"$TLS_CSR\" fi } _clearupdns() { _debug \"_clearupdns\" _debug \"dns_entries\" \"$dns_entries\" if [ -z \"$dns_entries\" ]; then _debug \"Skipping dns.\" return fi _info \"Removing DNS records.\" for entry in $dns_entries; do d=$(_getfield \"$entry\" 1) txtdomain=$(_getfield \"$entry\" 2) aliasDomain=$(_getfield \"$entry\" 3) _currentRoot=$(_getfield \"$entry\" 4) txt=$(_getfield \"$entry\" 5) d_api=$(_getfield \"$entry\" 6) _debug \"d\" \"$d\" _debug \"txtdomain\" \"$txtdomain\" _debug \"aliasDomain\" \"$aliasDomain\" _debug \"_currentRoot\" \"$_currentRoot\" _debug \"txt\" \"$txt\" _debug \"d_api\" \"$d_api\" if [ \"$d_api\" = \"$txt\" ]; then d_api=\"\" fi if [ -z \"$d_api\" ]; then _info \"Domain API file was not found: $d_api\" continue fi if [ \"$aliasDomain\" ]; then txtdomain=\"$aliasDomain\" fi ( if ! . \"$d_api\"; then _err \"Error loading file $d_api. Please check your API file and try again.\" return 1 fi rmcommand=\"${_currentRoot}_rm\" if ! _exists \"$rmcommand\"; then _err \"It seems that your API file doesn't define $rmcommand\" return 1 fi _info \"Removing txt: $txt for domain: $txtdomain\" if ! $rmcommand \"$txtdomain\" \"$txt\"; then _err \"Error removing txt for domain: $txtdomain\" return 1 fi _info \"Successfully removed\" ) done } # webroot removelevel tokenfile _clearupwebbroot() { __webroot=\"$1\" if [ -z \"$__webroot\" ]; then _debug \"No webroot specified, skipping\" return 0 fi _rmpath=\"\" if [ \"$2\" = '1' ]; then _rmpath=\"$__webroot/.well-known\" elif [ \"$2\" = '2' ]; then _rmpath=\"$__webroot/.well-known/acme-challenge\" elif [ \"$2\" = '3' ]; then _rmpath=\"$__webroot/.well-known/acme-challenge/$3\" else _debug \"Skipping for removelevel: $2\" fi if [ \"$_rmpath\" ]; then if [ \"$DEBUG\" ]; then _debug \"Debugging, not removing: $_rmpath\" else rm -rf \"$_rmpath\" fi fi return 0 } _on_before_issue() { _chk_web_roots=\"$1\" _chk_main_domain=\"$2\" _chk_alt_domains=\"$3\" _chk_pre_hook=\"$4\" _chk_local_addr=\"$5\" _debug _on_before_issue _debug _chk_main_domain \"$_chk_main_domain\" _debug _chk_alt_domains \"$_chk_alt_domains\" #run pre hook if [ \"$_chk_pre_hook\" ]; then _info \"Runing pre hook:'$_chk_pre_hook'\" if ! ( export Le_Domain=\"$_chk_main_domain\" export Le_Alt=\"$_chk_alt_domains\" cd \"$DOMAIN_PATH\" && eval \"$_chk_pre_hook\" ); then _err \"Error occurred when running pre hook.\" return 1 fi fi if _hasfield \"$_chk_web_roots\" \"$NO_VALUE\"; then if ! _exists \"socat\"; then _err \"Please install socat tools first.\" return 1 fi fi _debug Le_LocalAddress \"$_chk_local_addr\" _index=1 _currentRoot=\"\" _addrIndex=1 _w_index=1 while true; do d=\"$(echo \"$_chk_main_domain,$_chk_alt_domains,\" | cut -d , -f \"$_w_index\")\" _w_index=\"$(_math \"$_w_index\" + 1)\" _debug d \"$d\" if [ -z \"$d\" ]; then break fi _debug \"Checking for domain\" \"$d\" _currentRoot=\"$(_getfield \"$_chk_web_roots\" $_index)\" _debug \"_currentRoot\" \"$_currentRoot\" _index=$(_math $_index + 1) _checkport=\"\" if [ \"$_currentRoot\" = \"$NO_VALUE\" ]; then _info \"Standalone mode.\" if [ -z \"$Le_HTTPPort\" ]; then Le_HTTPPort=80 _cleardomainconf \"Le_HTTPPort\" else _savedomainconf \"Le_HTTPPort\" \"$Le_HTTPPort\" fi _checkport=\"$Le_HTTPPort\" elif [ \"$_currentRoot\" = \"$W_ALPN\" ]; then _info \"Standalone alpn mode.\" if [ -z \"$Le_TLSPort\" ]; then Le_TLSPort=443 else _savedomainconf \"Le_TLSPort\" \"$Le_TLSPort\" fi _checkport=\"$Le_TLSPort\" fi if [ \"$_checkport\" ]; then _debug _checkport \"$_checkport\" _checkaddr=\"$(_getfield \"$_chk_local_addr\" $_addrIndex)\" _debug _checkaddr \"$_checkaddr\" _addrIndex=\"$(_math $_addrIndex + 1)\" _netprc=\"$(_ss \"$_checkport\" | grep \"$_checkport\")\" netprc=\"$(echo \"$_netprc\" | grep \"$_checkaddr\")\" if [ -z \"$netprc\" ]; then netprc=\"$(echo \"$_netprc\" | grep \"$LOCAL_ANY_ADDRESS:$_checkport\")\" fi if [ \"$netprc\" ]; then _err \"$netprc\" _err \"tcp port $_checkport is already used by $(echo \"$netprc\" | cut -d : -f 4)\" _err \"Please stop it first\" return 1 fi fi done if _hasfield \"$_chk_web_roots\" \"apache\"; then if ! _setApache; then _err \"Error setting up Apache. Please open an issue on $PROJECT.\" return 1 fi else usingApache=\"\" fi } _on_issue_err() { _chk_post_hook=\"$1\" _chk_vlist=\"$2\" _debug _on_issue_err if [ \"$LOG_FILE\" ]; then _err \"Please check log file for more details: $LOG_FILE\" else _err \"Please add '--debug' or '--log' to see more information.\" _err \"See: $_DEBUG_WIKI\" fi #run the post hook if [ \"$_chk_post_hook\" ]; then _info \"Running post hook: '$_chk_post_hook'\" if ! ( cd \"$DOMAIN_PATH\" && eval \"$_chk_post_hook\" ); then _err \"Error encountered while running post hook.\" return 1 fi fi #trigger the validation to flush the pending authz _debug2 \"_chk_vlist\" \"$_chk_vlist\" if [ \"$_chk_vlist\" ]; then ( _debug2 \"start to deactivate authz\" ventries=$(echo \"$_chk_vlist\" | tr \"$dvsep\" ' ') for ventry in $ventries; do d=$(echo \"$ventry\" | cut -d \"$sep\" -f 1) keyauthorization=$(echo \"$ventry\" | cut -d \"$sep\" -f 2) uri=$(echo \"$ventry\" | cut -d \"$sep\" -f 3) vtype=$(echo \"$ventry\" | cut -d \"$sep\" -f 4) _currentRoot=$(echo \"$ventry\" | cut -d \"$sep\" -f 5) __trigger_validation \"$uri\" \"$keyauthorization\" done ) fi if [ \"$_ACME_IS_RENEW\" = \"1\" ] && _hasfield \"$Le_Webroot\" \"$W_DNS\"; then _err \"$_DNS_MANUAL_ERR\" fi if [ \"$DEBUG\" ] && [ \"$DEBUG\" -gt \"0\" ]; then _debug \"$(_dlg_versions)\" fi } _on_issue_success() { _chk_post_hook=\"$1\" _chk_renew_hook=\"$2\" _debug _on_issue_success #run the post hook if [ \"$_chk_post_hook\" ]; then _info \"Running post hook:'$_chk_post_hook'\" if ! ( export CERT_PATH export CERT_KEY_PATH export CA_CERT_PATH export CERT_FULLCHAIN_PATH export Le_Domain=\"$_main_domain\" cd \"$DOMAIN_PATH\" && eval \"$_chk_post_hook\" ); then _err \"Error encountered while running post hook.\" return 1 fi fi #run renew hook if [ \"$_ACME_IS_RENEW\" ] && [ \"$_chk_renew_hook\" ]; then _info \"Running renew hook: '$_chk_renew_hook'\" if ! ( export CERT_PATH export CERT_KEY_PATH export CA_CERT_PATH export CERT_FULLCHAIN_PATH export Le_Domain=\"$_main_domain\" cd \"$DOMAIN_PATH\" && eval \"$_chk_renew_hook\" ); then _err \"Error encountered while running renew hook.\" return 1 fi fi if _hasfield \"$Le_Webroot\" \"$W_DNS\" && [ -z \"$FORCE_DNS_MANUAL\" ]; then _err \"$_DNS_MANUAL_WARN\" fi } #account_key_length eab-kid eab-hmac-key registeraccount() { _account_key_length=\"$1\" _eab_id=\"$2\" _eab_hmac_key=\"$3\" _initpath _regAccount \"$_account_key_length\" \"$_eab_id\" \"$_eab_hmac_key\" } __calcAccountKeyHash() { [ -f \"$ACCOUNT_KEY_PATH\" ] && _digest sha256 <\"$ACCOUNT_KEY_PATH\" } __calc_account_thumbprint() { printf \"%s\" \"$jwk\" | tr -d ' ' | _digest \"sha256\" | _url_replace } _getAccountEmail() { if [ \"$ACCOUNT_EMAIL\" ]; then echo \"$ACCOUNT_EMAIL\" return 0 fi if [ -z \"$CA_EMAIL\" ]; then CA_EMAIL=\"$(_readcaconf CA_EMAIL)\" fi if [ \"$CA_EMAIL\" ]; then echo \"$CA_EMAIL\" return 0 fi _readaccountconf \"ACCOUNT_EMAIL\" } #keylength _regAccount() { _initpath _reg_length=\"$1\" _eab_id=\"$2\" _eab_hmac_key=\"$3\" _debug3 _regAccount \"$_regAccount\" _initAPI mkdir -p \"$CA_DIR\" if [ ! -f \"$ACCOUNT_KEY_PATH\" ]; then if ! _create_account_key \"$_reg_length\"; then _err \"Error creating account key.\" return 1 fi fi if ! _calcjwk \"$ACCOUNT_KEY_PATH\"; then return 1 fi if [ \"$_eab_id\" ] && [ \"$_eab_hmac_key\" ]; then _savecaconf CA_EAB_KEY_ID \"$_eab_id\" _savecaconf CA_EAB_HMAC_KEY \"$_eab_hmac_key\" fi _eab_id=$(_readcaconf \"CA_EAB_KEY_ID\") _eab_hmac_key=$(_readcaconf \"CA_EAB_HMAC_KEY\") _secure_debug3 _eab_id \"$_eab_id\" _secure_debug3 _eab_hmac_key \"$_eab_hmac_key\" _email=\"$(_getAccountEmail)\" if [ \"$_email\" ]; then _savecaconf \"CA_EMAIL\" \"$_email\" fi if [ \"$ACME_DIRECTORY\" = \"$CA_ZEROSSL\" ]; then if [ -z \"$_eab_id\" ] || [ -z \"$_eab_hmac_key\" ]; then _info \"No EAB credentials found for ZeroSSL, let's obtain them\" if [ -z \"$_email\" ]; then _info \"$(__green \"$PROJECT_NAME is using ZeroSSL as default CA now.\")\" _info \"$(__green \"Please update your account with an email address first.\")\" _info \"$(__green \"$PROJECT_ENTRY --register-account -m my@example.com\")\" _info \"See: $(__green \"$_ZEROSSL_WIKI\")\" return 1 fi _eabresp=$(_post \"email=$_email\" $_ZERO_EAB_ENDPOINT) if [ \"$?\" != \"0\" ]; then _debug2 \"$_eabresp\" _err \"Cannot get EAB credentials from ZeroSSL.\" return 1 fi _secure_debug2 _eabresp \"$_eabresp\" _eab_id=\"$(echo \"$_eabresp\" | tr ',}' '\\n\\n' | grep '\"eab_kid\"' | cut -d : -f 2 | tr -d '\"')\" _secure_debug2 _eab_id \"$_eab_id\" if [ -z \"$_eab_id\" ]; then _err \"Cannot resolve _eab_id\" return 1 fi _eab_hmac_key=\"$(echo \"$_eabresp\" | tr ',}' '\\n\\n' | grep '\"eab_hmac_key\"' | cut -d : -f 2 | tr -d '\"')\" _secure_debug2 _eab_hmac_key \"$_eab_hmac_key\" if [ -z \"$_eab_hmac_key\" ]; then _err \"Cannot resolve _eab_hmac_key\" return 1 fi _savecaconf CA_EAB_KEY_ID \"$_eab_id\" _savecaconf CA_EAB_HMAC_KEY \"$_eab_hmac_key\" fi fi if [ \"$_eab_id\" ] && [ \"$_eab_hmac_key\" ]; then eab_protected=\"{\\\"alg\\\":\\\"HS256\\\",\\\"kid\\\":\\\"$_eab_id\\\",\\\"url\\\":\\\"${ACME_NEW_ACCOUNT}\\\"}\" _debug3 eab_protected \"$eab_protected\" eab_protected64=$(printf \"%s\" \"$eab_protected\" | _base64 | _url_replace) _debug3 eab_protected64 \"$eab_protected64\" eab_payload64=$(printf \"%s\" \"$jwk\" | _base64 | _url_replace) _debug3 eab_payload64 \"$eab_payload64\" eab_sign_t=\"$eab_protected64.$eab_payload64\" _debug3 eab_sign_t \"$eab_sign_t\" key_hex=\"$(_durl_replace_base64 \"$_eab_hmac_key\" | _dbase64 | _hex_dump | tr -d ' ')\" _debug3 key_hex \"$key_hex\" eab_signature=$(printf \"%s\" \"$eab_sign_t\" | _hmac sha256 $key_hex | _base64 | _url_replace) _debug3 eab_signature \"$eab_signature\" externalBinding=\",\\\"externalAccountBinding\\\":{\\\"protected\\\":\\\"$eab_protected64\\\", \\\"payload\\\":\\\"$eab_payload64\\\", \\\"signature\\\":\\\"$eab_signature\\\"}\" _debug3 externalBinding \"$externalBinding\" fi if [ \"$_email\" ]; then email_sg=\"\\\"contact\\\": [\\\"mailto:$_email\\\"], \" fi regjson=\"{$email_sg\\\"termsOfServiceAgreed\\\": true$externalBinding}\" _info \"Registering account: $ACME_DIRECTORY\" if ! _send_signed_request \"${ACME_NEW_ACCOUNT}\" \"$regjson\"; then _err \"Error registering account: $response\" return 1 fi _eabAlreadyBound=\"\" if [ \"$code\" = \"\" ] || [ \"$code\" = '201' ]; then echo \"$response\" >\"$ACCOUNT_JSON_PATH\" _info \"Registered\" elif [ \"$code\" = '409' ] || [ \"$code\" = '200' ]; then _info \"Already registered\" elif [ \"$code\" = '400' ] && _contains \"$response\" 'The account is not awaiting external account binding'; then _info \"EAB already registered\" _eabAlreadyBound=1 else _err \"Account registration error: $response\" return 1 fi if [ -z \"$_eabAlreadyBound\" ]; then _debug2 responseHeaders \"$responseHeaders\" _accUri=\"$(echo \"$responseHeaders\" | grep -i \"^Location:\" | _head_n 1 | cut -d ':' -f 2- | tr -d \"\\r\\n \")\" _debug \"_accUri\" \"$_accUri\" if [ -z \"$_accUri\" ]; then _err \"Cannot find account id url.\" _err \"$responseHeaders\" return 1 fi _savecaconf \"ACCOUNT_URL\" \"$_accUri\" else ACCOUNT_URL=\"$(_readcaconf ACCOUNT_URL)\" fi export ACCOUNT_URL=\"$_accUri\" CA_KEY_HASH=\"$(__calcAccountKeyHash)\" _debug \"Calc CA_KEY_HASH\" \"$CA_KEY_HASH\" _savecaconf CA_KEY_HASH \"$CA_KEY_HASH\" if [ \"$code\" = '403' ]; then _err \"It seems that the account key has been deactivated, please use a new account key.\" return 1 fi ACCOUNT_THUMBPRINT=\"$(__calc_account_thumbprint)\" _info \"ACCOUNT_THUMBPRINT\" \"$ACCOUNT_THUMBPRINT\" } #implement updateaccount updateaccount() { _initpath if [ ! -f \"$ACCOUNT_KEY_PATH\" ]; then _err \"Account key not found at: $ACCOUNT_KEY_PATH\" return 1 fi _accUri=$(_readcaconf \"ACCOUNT_URL\") _debug _accUri \"$_accUri\" if [ -z \"$_accUri\" ]; then _err \"The account URL is empty, please run '--update-account' first to update the account info, then try again.\" return 1 fi if ! _calcjwk \"$ACCOUNT_KEY_PATH\"; then return 1 fi _initAPI _email=\"$(_getAccountEmail)\" if [ \"$_email\" ]; then updjson='{\"contact\": [\"mailto:'$_email'\"]}' else updjson='{\"contact\": []}' fi _send_signed_request \"$_accUri\" \"$updjson\" if [ \"$code\" = '200' ]; then echo \"$response\" >\"$ACCOUNT_JSON_PATH\" _info \"Account update success for $_accUri.\" ACCOUNT_THUMBPRINT=\"$(__calc_account_thumbprint)\" _info \"ACCOUNT_THUMBPRINT\" \"$ACCOUNT_THUMBPRINT\" else _info \"An error occurred and the account was not updated.\" return 1 fi } #Implement deactivate account deactivateaccount() { _initpath if [ ! -f \"$ACCOUNT_KEY_PATH\" ]; then _err \"Account key not found at: $ACCOUNT_KEY_PATH\" return 1 fi _accUri=$(_readcaconf \"ACCOUNT_URL\") _debug _accUri \"$_accUri\" if [ -z \"$_accUri\" ]; then _err \"The account URL is empty, please run '--update-account' first to update the account info, then try again.\" return 1 fi if ! _calcjwk \"$ACCOUNT_KEY_PATH\"; then return 1 fi _initAPI _djson=\"{\\\"status\\\":\\\"deactivated\\\"}\" if _send_signed_request \"$_accUri\" \"$_djson\" && _contains \"$response\" '\"deactivated\"'; then _info \"Successfully deactivated account $_accUri.\" _accid=$(echo \"$response\" | _egrep_o \"\\\"id\\\" *: *[^,]*,\" | cut -d : -f 2 | tr -d ' ,') elif [ \"$code\" = \"403\" ]; then _info \"The account is already deactivated.\" _accid=$(_getfield \"$_accUri\" \"999\" \"/\") else _err \"Account deactivation failed for $_accUri.\" return 1 fi _debug \"Account id: $_accid\" if [ \"$_accid\" ]; then _deactivated_account_path=\"$CA_DIR/deactivated/$_accid\" _debug _deactivated_account_path \"$_deactivated_account_path\" if mkdir -p \"$_deactivated_account_path\"; then _info \"Moving deactivated account info to $_deactivated_account_path/\" mv \"$CA_CONF\" \"$_deactivated_account_path/\" mv \"$ACCOUNT_JSON_PATH\" \"$_deactivated_account_path/\" mv \"$ACCOUNT_KEY_PATH\" \"$_deactivated_account_path/\" else _err \"Cannot create dir: $_deactivated_account_path, try to remove the deactivated account key.\" rm -f \"$CA_CONF\" rm -f \"$ACCOUNT_JSON_PATH\" rm -f \"$ACCOUNT_KEY_PATH\" fi fi } # domain folder file _findHook() { _hookdomain=\"$1\" _hookcat=\"$2\" _hookname=\"$3\" if [ -f \"$_SCRIPT_HOME/$_hookcat/$_hookname\" ]; then d_api=\"$_SCRIPT_HOME/$_hookcat/$_hookname\" elif [ -f \"$_SCRIPT_HOME/$_hookcat/$_hookname.sh\" ]; then d_api=\"$_SCRIPT_HOME/$_hookcat/$_hookname.sh\" elif [ \"$_hookdomain\" ] && [ -f \"$LE_WORKING_DIR/$_hookdomain/$_hookname\" ]; then d_api=\"$LE_WORKING_DIR/$_hookdomain/$_hookname\" elif [ \"$_hookdomain\" ] && [ -f \"$LE_WORKING_DIR/$_hookdomain/$_hookname.sh\" ]; then d_api=\"$LE_WORKING_DIR/$_hookdomain/$_hookname.sh\" elif [ -f \"$LE_WORKING_DIR/$_hookname\" ]; then d_api=\"$LE_WORKING_DIR/$_hookname\" elif [ -f \"$LE_WORKING_DIR/$_hookname.sh\" ]; then d_api=\"$LE_WORKING_DIR/$_hookname.sh\" elif [ -f \"$LE_WORKING_DIR/$_hookcat/$_hookname\" ]; then d_api=\"$LE_WORKING_DIR/$_hookcat/$_hookname\" elif [ -f \"$LE_WORKING_DIR/$_hookcat/$_hookname.sh\" ]; then d_api=\"$LE_WORKING_DIR/$_hookcat/$_hookname.sh\" fi printf \"%s\" \"$d_api\" } #domain __get_domain_new_authz() { _gdnd=\"$1\" _info \"Getting new-authz for domain\" \"$_gdnd\" _initAPI _Max_new_authz_retry_times=5 _authz_i=0 while [ \"$_authz_i\" -lt \"$_Max_new_authz_retry_times\" ]; do _debug \"Trying new-authz, attempt number $_authz_i.\" if ! _send_signed_request \"${ACME_NEW_AUTHZ}\" \"{\\\"resource\\\": \\\"new-authz\\\", \\\"identifier\\\": {\\\"type\\\": \\\"dns\\\", \\\"value\\\": \\\"$(_idn \"$_gdnd\")\\\"}}\"; then _err \"Cannot get new authz for domain.\" return 1 fi if _contains \"$response\" \"No registration exists matching provided key\"; then _err \"There has been an error, but it might now be resolved, please try again.\" _err \"If you see this message for a second time, please report this as a bug: $(__green \"$PROJECT\")\" _clearcaconf \"CA_KEY_HASH\" break fi if ! _contains \"$response\" \"An error occurred while processing your request\"; then _info \"new-authz request successful.\" break fi _authz_i=\"$(_math \"$_authz_i\" + 1)\" _info \"The server is busy, sleeping for $_authz_i seconds and retrying.\" _sleep \"$_authz_i\" done if [ \"$_authz_i\" = \"$_Max_new_authz_retry_times\" ]; then _err \"new-authz has been retried $_Max_new_authz_retry_times times, stopping.\" fi if [ \"$code\" ] && [ \"$code\" != '201' ]; then _err \"new-authz error: $response\" return 1 fi } #uri keyAuthorization __trigger_validation() { _debug2 \"Trigger domain validation.\" _t_url=\"$1\" _debug2 _t_url \"$_t_url\" _t_key_authz=\"$2\" _debug2 _t_key_authz \"$_t_key_authz\" _t_vtype=\"$3\" _debug2 _t_vtype \"$_t_vtype\" _send_signed_request \"$_t_url\" \"{}\" } #endpoint domain type _ns_lookup_impl() { _ns_ep=\"$1\" _ns_domain=\"$2\" _ns_type=\"$3\" _debug2 \"_ns_ep\" \"$_ns_ep\" _debug2 \"_ns_domain\" \"$_ns_domain\" _debug2 \"_ns_type\" \"$_ns_type\" response=\"$(_H1=\"accept: application/dns-json\" _get \"$_ns_ep?name=$_ns_domain&type=$_ns_type\")\" _ret=$? _debug2 \"response\" \"$response\" if [ \"$_ret\" != \"0\" ]; then return $_ret fi _answers=\"$(echo \"$response\" | tr '{}' '<>' | _egrep_o '\"Answer\":\\[[^]]*]' | tr '<>' '\\n\\n')\" _debug2 \"_answers\" \"$_answers\" echo \"$_answers\" } #domain, type _ns_lookup_cf() { _cf_ld=\"$1\" _cf_ld_type=\"$2\" _cf_ep=\"https://cloudflare-dns.com/dns-query\" _ns_lookup_impl \"$_cf_ep\" \"$_cf_ld\" \"$_cf_ld_type\" } #domain, type _ns_purge_cf() { _cf_d=\"$1\" _cf_d_type=\"$2\" _debug \"Purging Cloudflare $_cf_d_type record for domain $_cf_d\" _cf_purl=\"https://cloudflare-dns.com/api/v1/purge?domain=$_cf_d&type=$_cf_d_type\" response=\"$(_post \"\" \"$_cf_purl\")\" _debug2 response \"$response\" } #checks if cf server is available _ns_is_available_cf() { if _get \"https://cloudflare-dns.com\" \"\" 10 >/dev/null; then return 0 else return 1 fi } _ns_is_available_google() { if _get \"https://dns.google\" \"\" 10 >/dev/null; then return 0 else return 1 fi } #domain, type _ns_lookup_google() { _cf_ld=\"$1\" _cf_ld_type=\"$2\" _cf_ep=\"https://dns.google/resolve\" _ns_lookup_impl \"$_cf_ep\" \"$_cf_ld\" \"$_cf_ld_type\" } _ns_is_available_ali() { if _get \"https://dns.alidns.com\" \"\" 10 >/dev/null; then return 0 else return 1 fi } #domain, type _ns_lookup_ali() { _cf_ld=\"$1\" _cf_ld_type=\"$2\" _cf_ep=\"https://dns.alidns.com/resolve\" _ns_lookup_impl \"$_cf_ep\" \"$_cf_ld\" \"$_cf_ld_type\" } _ns_is_available_dp() { if _get \"https://doh.pub\" \"\" 10 >/dev/null; then return 0 else return 1 fi } #dnspod _ns_lookup_dp() { _cf_ld=\"$1\" _cf_ld_type=\"$2\" _cf_ep=\"https://doh.pub/dns-query\" _ns_lookup_impl \"$_cf_ep\" \"$_cf_ld\" \"$_cf_ld_type\" } _ns_select_doh() { if [ -z \"$DOH_USE\" ]; then _debug \"Detecting DNS server first.\" if _ns_is_available_cf; then _debug \"Using Cloudflare doh server\" export DOH_USE=$DOH_CLOUDFLARE elif _ns_is_available_google; then _debug \"Using Google DOH server\" export DOH_USE=$DOH_GOOGLE elif _ns_is_available_ali; then _debug \"Using Aliyun DOH server\" export DOH_USE=$DOH_ALI elif _ns_is_available_dp; then _debug \"Using DNS POD DOH server\" export DOH_USE=$DOH_DP else _err \"No DOH\" fi fi } #domain, type _ns_lookup() { _ns_select_doh if [ \"$DOH_USE\" = \"$DOH_CLOUDFLARE\" ] || [ -z \"$DOH_USE\" ]; then _ns_lookup_cf \"$@\" elif [ \"$DOH_USE\" = \"$DOH_GOOGLE\" ]; then _ns_lookup_google \"$@\" elif [ \"$DOH_USE\" = \"$DOH_ALI\" ]; then _ns_lookup_ali \"$@\" elif [ \"$DOH_USE\" = \"$DOH_DP\" ]; then _ns_lookup_dp \"$@\" else _err \"Unknown DOH provider: DOH_USE=$DOH_USE\" fi } #txtdomain, alias, txt __check_txt() { _c_txtdomain=\"$1\" _c_aliasdomain=\"$2\" _c_txt=\"$3\" _debug \"_c_txtdomain\" \"$_c_txtdomain\" _debug \"_c_aliasdomain\" \"$_c_aliasdomain\" _debug \"_c_txt\" \"$_c_txt\" _ns_select_doh _answers=\"$(_ns_lookup \"$_c_aliasdomain\" TXT)\" _contains \"$_answers\" \"$_c_txt\" } #txtdomain __purge_txt() { _p_txtdomain=\"$1\" _debug _p_txtdomain \"$_p_txtdomain\" if [ \"$DOH_USE\" = \"$DOH_CLOUDFLARE\" ] || [ -z \"$DOH_USE\" ]; then _ns_purge_cf \"$_p_txtdomain\" \"TXT\" else _debug \"No purge API for this DOH API, just sleeping for 5 seconds\" _sleep 5 fi } #wait and check each dns entries _check_dns_entries() { _success_txt=\",\" _end_time=\"$(_time)\" _end_time=\"$(_math \"$_end_time\" + 1200)\" #let's check no more than 20 minutes. while [ \"$(_time)\" -le \"$_end_time\" ]; do _info \"You can use '--dnssleep' to disable public dns checks.\" _info \"See: $_DNSCHECK_WIKI\" _left=\"\" for entry in $dns_entries; do d=$(_getfield \"$entry\" 1) txtdomain=$(_getfield \"$entry\" 2) txtdomain=$(_idn \"$txtdomain\") aliasDomain=$(_getfield \"$entry\" 3) aliasDomain=$(_idn \"$aliasDomain\") txt=$(_getfield \"$entry\" 5) d_api=$(_getfield \"$entry\" 6) _debug \"d\" \"$d\" _debug \"txtdomain\" \"$txtdomain\" _debug \"aliasDomain\" \"$aliasDomain\" _debug \"txt\" \"$txt\" _debug \"d_api\" \"$d_api\" _info \"Checking $d for $aliasDomain\" if _contains \"$_success_txt\" \",$txt,\"; then _info \"Already succeeded, continuing.\" continue fi if __check_txt \"$txtdomain\" \"$aliasDomain\" \"$txt\"; then _info \"Success for domain $d '$aliasDomain'.\" _success_txt=\"$_success_txt,$txt,\" continue fi _left=1 _info \"Not valid yet, let's wait for 10 seconds then check the next one.\" __purge_txt \"$txtdomain\" if [ \"$txtdomain\" != \"$aliasDomain\" ]; then __purge_txt \"$aliasDomain\" fi _sleep 10 done if [ \"$_left\" ]; then _info \"Let's wait for 10 seconds and check again\". _sleep 10 else _info \"All checks succeeded\" return 0 fi done _info \"Timed out waiting for DNS.\" return 1 } #file _get_chain_issuers() { _cfile=\"$1\" if _contains \"$(${ACME_OPENSSL_BIN:-openssl} help crl2pkcs7 2>&1)\" \"Usage: crl2pkcs7\" || _contains \"$(${ACME_OPENSSL_BIN:-openssl} crl2pkcs7 -help 2>&1)\" \"Usage: crl2pkcs7\" || _contains \"$(${ACME_OPENSSL_BIN:-openssl} crl2pkcs7 help 2>&1)\" \"unknown option help\"; then ${ACME_OPENSSL_BIN:-openssl} crl2pkcs7 -nocrl -certfile $_cfile | ${ACME_OPENSSL_BIN:-openssl} pkcs7 -print_certs -text -noout | grep -i 'Issuer:' | _egrep_o \"CN *=[^,]*\" | cut -d = -f 2 else _cindex=1 for _startn in $(grep -n -- \"$BEGIN_CERT\" \"$_cfile\" | cut -d : -f 1); do _endn=\"$(grep -n -- \"$END_CERT\" \"$_cfile\" | cut -d : -f 1 | _head_n $_cindex | _tail_n 1)\" _debug2 \"_startn\" \"$_startn\" _debug2 \"_endn\" \"$_endn\" if [ \"$DEBUG\" ]; then _debug2 \"cert$_cindex\" \"$(sed -n \"$_startn,${_endn}p\" \"$_cfile\")\" fi sed -n \"$_startn,${_endn}p\" \"$_cfile\" | ${ACME_OPENSSL_BIN:-openssl} x509 -text -noout | grep 'Issuer:' | _egrep_o \"CN *=[^,]*\" | cut -d = -f 2 | sed \"s/ *\\(.*\\)/\\1/\" _cindex=$(_math $_cindex + 1) done fi } # _get_chain_subjects() { _cfile=\"$1\" if _contains \"$(${ACME_OPENSSL_BIN:-openssl} help crl2pkcs7 2>&1)\" \"Usage: crl2pkcs7\" || _contains \"$(${ACME_OPENSSL_BIN:-openssl} crl2pkcs7 -help 2>&1)\" \"Usage: crl2pkcs7\" || _contains \"$(${ACME_OPENSSL_BIN:-openssl} crl2pkcs7 help 2>&1)\" \"unknown option help\"; then ${ACME_OPENSSL_BIN:-openssl} crl2pkcs7 -nocrl -certfile $_cfile | ${ACME_OPENSSL_BIN:-openssl} pkcs7 -print_certs -text -noout | grep -i 'Subject:' | _egrep_o \"CN *=[^,]*\" | cut -d = -f 2 else _cindex=1 for _startn in $(grep -n -- \"$BEGIN_CERT\" \"$_cfile\" | cut -d : -f 1); do _endn=\"$(grep -n -- \"$END_CERT\" \"$_cfile\" | cut -d : -f 1 | _head_n $_cindex | _tail_n 1)\" _debug2 \"_startn\" \"$_startn\" _debug2 \"_endn\" \"$_endn\" if [ \"$DEBUG\" ]; then _debug2 \"cert$_cindex\" \"$(sed -n \"$_startn,${_endn}p\" \"$_cfile\")\" fi sed -n \"$_startn,${_endn}p\" \"$_cfile\" | ${ACME_OPENSSL_BIN:-openssl} x509 -text -noout | grep -i 'Subject:' | _egrep_o \"CN *=[^,]*\" | cut -d = -f 2 | sed \"s/ *\\(.*\\)/\\1/\" _cindex=$(_math $_cindex + 1) done fi } #cert issuer _match_issuer() { _cfile=\"$1\" _missuer=\"$2\" _fissuers=\"$(_get_chain_issuers $_cfile)\" _debug2 _fissuers \"$_fissuers\" _rootissuer=\"$(echo \"$_fissuers\" | _lower_case | _tail_n 1)\" _debug2 _rootissuer \"$_rootissuer\" _missuer=\"$(echo \"$_missuer\" | _lower_case)\" _contains \"$_rootissuer\" \"$_missuer\" } #ip _isIPv4() { for seg in $(echo \"$1\" | tr '.' ' '); do _debug2 seg \"$seg\" if [ \"$(echo \"$seg\" | tr -d '[0-9]')\" ]; then #not all number return 1 fi if [ $seg -ge 0 ] && [ $seg -lt 256 ]; then continue fi return 1 done return 0 } #ip6 _isIPv6() { _contains \"$1\" \":\" } #ip _isIP() { _isIPv4 \"$1\" || _isIPv6 \"$1\" } #identifier _getIdType() { if _isIP \"$1\"; then echo \"$ID_TYPE_IP\" else echo \"$ID_TYPE_DNS\" fi } # beginTime dateTo # beginTime is full string format(\"2022-04-01T08:10:33Z\"), beginTime can be empty, to use current time # dateTo can be ether in full string format(\"2022-04-01T08:10:33Z\") or in delta format(+5d or +20h) _convertValidaty() { _beginTime=\"$1\" _dateTo=\"$2\" _debug2 \"_beginTime\" \"$_beginTime\" _debug2 \"_dateTo\" \"$_dateTo\" if _startswith \"$_dateTo\" \"+\"; then _v_begin=$(_time) if [ \"$_beginTime\" ]; then _v_begin=\"$(_date2time \"$_beginTime\")\" fi _debug2 \"_v_begin\" \"$_v_begin\" if _endswith \"$_dateTo\" \"h\"; then _v_end=$(_math \"$_v_begin + 60 * 60 * $(echo \"$_dateTo\" | tr -d '+h')\") elif _endswith \"$_dateTo\" \"d\"; then _v_end=$(_math \"$_v_begin + 60 * 60 * 24 * $(echo \"$_dateTo\" | tr -d '+d')\") else _err \"Unrecognized format for _dateTo: $_dateTo\" return 1 fi _debug2 \"_v_end\" \"$_v_end\" _time2str \"$_v_end\" else if [ \"$(_time)\" -gt \"$(_date2time \"$_dateTo\")\" ]; then _err \"The validity end date is in the past: _dateTo = $_dateTo\" return 1 fi echo \"$_dateTo\" fi } #webroot, domain domainlist keylength issue() { if [ -z \"$2\" ]; then _usage \"Usage: $PROJECT_ENTRY --issue --domain <domain.tld> --webroot <directory>\" return 1 fi if [ -z \"$1\" ]; then _usage \"Please specify at least one validation method: '--webroot', '--standalone', '--apache', '--nginx' or '--dns' etc.\" return 1 fi _web_roots=\"$1\" _main_domain=\"$2\" _alt_domains=\"$3\" if _contains \"$_main_domain\" \",\"; then _main_domain=$(echo \"$2,$3\" | cut -d , -f 1) _alt_domains=$(echo \"$2,$3\" | cut -d , -f 2- | sed \"s/,${NO_VALUE}$//\") fi _debug _main_domain \"$_main_domain\" _debug _alt_domains \"$_alt_domains\" _key_length=\"$4\" _real_cert=\"$5\" _real_key=\"$6\" _real_ca=\"$7\" _reload_cmd=\"$8\" _real_fullchain=\"$9\" _pre_hook=\"${10}\" _post_hook=\"${11}\" _renew_hook=\"${12}\" _local_addr=\"${13}\" _challenge_alias=\"${14}\" _preferred_chain=\"${15}\" _valid_from=\"${16}\" _valid_to=\"${17}\" if [ -z \"$_ACME_IS_RENEW\" ]; then _initpath \"$_main_domain\" \"$_key_length\" mkdir -p \"$DOMAIN_PATH\" elif ! _hasfield \"$_web_roots\" \"$W_DNS\"; then Le_OrderFinalize=\"\" Le_LinkOrder=\"\" Le_LinkCert=\"\" fi if _hasfield \"$_web_roots\" \"$W_DNS\" && [ -z \"$FORCE_DNS_MANUAL\" ]; then _err \"$_DNS_MANUAL_ERROR\" return 1 fi if [ -f \"$DOMAIN_CONF\" ]; then Le_NextRenewTime=$(_readdomainconf Le_NextRenewTime) _debug Le_NextRenewTime \"$Le_NextRenewTime\" if [ -z \"$FORCE\" ] && [ \"$Le_NextRenewTime\" ] && [ \"$(_time)\" -lt \"$Le_NextRenewTime\" ]; then _valid_to_saved=$(_readdomainconf Le_Valid_to) if [ \"$_valid_to_saved\" ] && ! _startswith \"$_valid_to_saved\" \"+\"; then _info \"The domain is set to be valid to: $_valid_to_saved\" _info \"It cannot be renewed automatically\" _info \"See: $_VALIDITY_WIKI\" return $RENEW_SKIP fi _saved_domain=$(_readdomainconf Le_Domain) _debug _saved_domain \"$_saved_domain\" _saved_alt=$(_readdomainconf Le_Alt) _debug _saved_alt \"$_saved_alt\" _normized_saved_domains=\"$(echo \"$_saved_domain,$_saved_alt\" | tr \",\" \"\\n\" | sort | tr '\\n' ',')\" _debug _normized_saved_domains \"$_normized_saved_domains\" _normized_domains=\"$(echo \"$_main_domain,$_alt_domains\" | tr \",\" \"\\n\" | sort | tr '\\n' ',')\" _debug _normized_domains \"$_normized_domains\" if [ \"$_normized_saved_domains\" = \"$_normized_domains\" ]; then _info \"Domains not changed.\" _info \"Skipping. Next renewal time is: $(__green \"$(_readdomainconf Le_NextRenewTimeStr)\")\" _info \"Add '$(__red '--force')' to force renewal.\" return $RENEW_SKIP else _info \"Domains have changed.\" fi fi fi _debug \"Using ACME_DIRECTORY: $ACME_DIRECTORY\" if ! _initAPI; then return 1 fi _savedomainconf \"Le_Domain\" \"$_main_domain\" _savedomainconf \"Le_Alt\" \"$_alt_domains\" _savedomainconf \"Le_Webroot\" \"$_web_roots\" _savedomainconf \"Le_PreHook\" \"$_pre_hook\" \"base64\" _savedomainconf \"Le_PostHook\" \"$_post_hook\" \"base64\" _savedomainconf \"Le_RenewHook\" \"$_renew_hook\" \"base64\" if [ \"$_local_addr\" ]; then _savedomainconf \"Le_LocalAddress\" \"$_local_addr\" else _cleardomainconf \"Le_LocalAddress\" fi if [ \"$_challenge_alias\" ]; then _savedomainconf \"Le_ChallengeAlias\" \"$_challenge_alias\" else _cleardomainconf \"Le_ChallengeAlias\" fi if [ \"$_preferred_chain\" ]; then _savedomainconf \"Le_Preferred_Chain\" \"$_preferred_chain\" \"base64\" else _cleardomainconf \"Le_Preferred_Chain\" fi Le_API=\"$ACME_DIRECTORY\" _savedomainconf \"Le_API\" \"$Le_API\" _info \"Using CA: $ACME_DIRECTORY\" if [ \"$_alt_domains\" = \"$NO_VALUE\" ]; then _alt_domains=\"\" fi if ! _on_before_issue \"$_web_roots\" \"$_main_domain\" \"$_alt_domains\" \"$_pre_hook\" \"$_local_addr\"; then _err \"_on_before_issue.\" return 1 fi _saved_account_key_hash=\"$(_readcaconf \"CA_KEY_HASH\")\" _debug2 _saved_account_key_hash \"$_saved_account_key_hash\" if [ -z \"$ACCOUNT_URL\" ] || [ -z \"$_saved_account_key_hash\" ] || [ \"$_saved_account_key_hash\" != \"$(__calcAccountKeyHash)\" ]; then if ! _regAccount \"$_accountkeylength\"; then _on_issue_err \"$_post_hook\" return 1 fi else _debug \"_saved_account_key_hash was not changed, skipping account registration.\" fi export Le_Next_Domain_Key=\"$CERT_KEY_PATH.next\" if [ -f \"$CSR_PATH\" ] && [ ! -f \"$CERT_KEY_PATH\" ]; then _info \"Signing from existing CSR.\" else # When renewing from an old version, the empty Le_Keylength means 2048. # Note, do not use DEFAULT_DOMAIN_KEY_LENGTH as that value may change over # time but an empty value implies 2048 specifically. _key=$(_readdomainconf Le_Keylength) if [ -z \"$_key\" ]; then _key=2048 fi _debug \"Read key length: $_key\" if [ ! -f \"$CERT_KEY_PATH\" ] || [ \"$_key_length\" != \"$_key\" ] || [ \"$Le_ForceNewDomainKey\" = \"1\" ]; then if [ \"$Le_ForceNewDomainKey\" = \"1\" ] && [ -f \"$Le_Next_Domain_Key\" ]; then _info \"Using pre-generated key: $Le_Next_Domain_Key\" cat \"$Le_Next_Domain_Key\" >\"$CERT_KEY_PATH\" echo \"\" >\"$Le_Next_Domain_Key\" else if ! createDomainKey \"$_main_domain\" \"$_key_length\"; then _err \"Error creating domain key.\" _clearup _on_issue_err \"$_post_hook\" return 1 fi fi fi if [ \"$Le_ForceNewDomainKey\" ]; then _info \"Generating next pre-generate key.\" if [ ! -e \"$Le_Next_Domain_Key\" ]; then touch \"$Le_Next_Domain_Key\" chmod 600 \"$Le_Next_Domain_Key\" fi if ! _createkey \"$_key_length\" \"$Le_Next_Domain_Key\"; then _err \"Cannot pre-generate domain key\" return 1 fi fi if ! _createcsr \"$_main_domain\" \"$_alt_domains\" \"$CERT_KEY_PATH\" \"$CSR_PATH\" \"$DOMAIN_SSL_CONF\"; then _err \"Error creating CSR.\" _clearup _on_issue_err \"$_post_hook\" return 1 fi fi _savedomainconf \"Le_Keylength\" \"$_key_length\" vlist=\"$Le_Vlist\" _cleardomainconf \"Le_Vlist\" _debug \"Getting domain auth token for each domain\" sep='#' dvsep=',' if [ -z \"$vlist\" ]; then #make new order request _identifiers=\"{\\\"type\\\":\\\"$(_getIdType \"$_main_domain\")\\\",\\\"value\\\":\\\"$(_idn \"$_main_domain\")\\\"}\" _w_index=1 while true; do d=\"$(echo \"$_alt_domains,\" | cut -d , -f \"$_w_index\")\" _w_index=\"$(_math \"$_w_index\" + 1)\" _debug d \"$d\" if [ -z \"$d\" ]; then break fi _identifiers=\"$_identifiers,{\\\"type\\\":\\\"$(_getIdType \"$d\")\\\",\\\"value\\\":\\\"$(_idn \"$d\")\\\"}\" done _debug2 _identifiers \"$_identifiers\" _notBefore=\"\" _notAfter=\"\" if [ \"$_valid_from\" ]; then _savedomainconf \"Le_Valid_From\" \"$_valid_from\" _debug2 \"_valid_from\" \"$_valid_from\" _notBefore=\"$(_convertValidaty \"\" \"$_valid_from\")\" if [ \"$?\" != \"0\" ]; then _err \"Cannot parse _valid_from: $_valid_from\" return 1 fi if [ \"$(_time)\" -gt \"$(_date2time \"$_notBefore\")\" ]; then _notBefore=\"\" fi else _cleardomainconf \"Le_Valid_From\" fi _debug2 _notBefore \"$_notBefore\" if [ \"$_valid_to\" ]; then _debug2 \"_valid_to\" \"$_valid_to\" _savedomainconf \"Le_Valid_To\" \"$_valid_to\" _notAfter=\"$(_convertValidaty \"$_notBefore\" \"$_valid_to\")\" if [ \"$?\" != \"0\" ]; then _err \"Cannot parse _valid_to: $_valid_to\" return 1 fi else _cleardomainconf \"Le_Valid_To\" fi _debug2 \"_notAfter\" \"$_notAfter\" _newOrderObj=\"{\\\"identifiers\\\": [$_identifiers]\" if [ \"$_notBefore\" ]; then _newOrderObj=\"$_newOrderObj,\\\"notBefore\\\": \\\"$_notBefore\\\"\" fi if [ \"$_notAfter\" ]; then _newOrderObj=\"$_newOrderObj,\\\"notAfter\\\": \\\"$_notAfter\\\"\" fi _debug \"STEP 1, Ordering a Certificate\" if ! _send_signed_request \"$ACME_NEW_ORDER\" \"$_newOrderObj}\"; then _err \"Error creating new order.\" _clearup _on_issue_err \"$_post_hook\" return 1 fi if _contains \"$response\" \"invalid\"; then if echo \"$response\" | _normalizeJson | grep '\"status\":\"invalid\"' >/dev/null 2>&1; then _err \"Create new order with invalid status.\" _err \"$response\" _clearup _on_issue_err \"$_post_hook\" return 1 fi fi Le_LinkOrder=\"$(echo \"$responseHeaders\" | grep -i '^Location.*$' | _tail_n 1 | tr -d \"\\r\\n \" | cut -d \":\" -f 2-)\" _debug Le_LinkOrder \"$Le_LinkOrder\" Le_OrderFinalize=\"$(echo \"$response\" | _egrep_o '\"finalize\" *: *\"[^\"]*\"' | cut -d '\"' -f 4)\" _debug Le_OrderFinalize \"$Le_OrderFinalize\" if [ -z \"$Le_OrderFinalize\" ]; then _err \"Error creating new order. Le_OrderFinalize not found. $response\" _clearup _on_issue_err \"$_post_hook\" return 1 fi #for dns manual mode _savedomainconf \"Le_OrderFinalize\" \"$Le_OrderFinalize\" _authorizations_seg=\"$(echo \"$response\" | _json_decode | _egrep_o '\"authorizations\" *: *\\[[^\\[]*\\]' | cut -d '[' -f 2 | tr -d ']' | tr -d '\"')\" _debug2 _authorizations_seg \"$_authorizations_seg\" if [ -z \"$_authorizations_seg\" ]; then _err \"_authorizations_seg not found.\" _clearup _on_issue_err \"$_post_hook\" return 1 fi _debug \"STEP 2, Get the authorizations of each domain\" #domain and authz map _authorizations_map=\"\" for _authz_url in $(echo \"$_authorizations_seg\" | tr ',' ' '); do _debug2 \"_authz_url\" \"$_authz_url\" if ! _send_signed_request \"$_authz_url\"; then _err \"Error getting authz.\" _err \"_authorizations_seg\" \"$_authorizations_seg\" _err \"_authz_url\" \"$_authz_url\" _err \"$response\" _clearup _on_issue_err \"$_post_hook\" return 1 fi response=\"$(echo \"$response\" | _normalizeJson)\" _debug2 response \"$response\" if echo \"$response\" | grep '\"status\":\"invalid\"' >/dev/null 2>&1; then _err \"get authz objec with invalid status, please try again later.\" _err \"_authorizations_seg\" \"$_authorizations_seg\" _err \"$response\" _clearup _on_issue_err \"$_post_hook\" return 1 fi _d=\"$(echo \"$response\" | _egrep_o '\"value\" *: *\"[^\"]*\"' | cut -d : -f 2- | tr -d ' \"')\" if _contains \"$response\" \"\\\"wildcard\\\" *: *true\"; then _d=\"*.$_d\" fi _debug2 _d \"$_d\" _authorizations_map=\"$_d,$response#$_authz_url $_authorizations_map\" done _debug2 _authorizations_map \"$_authorizations_map\" _index=0 _currentRoot=\"\" _w_index=1 while true; do d=\"$(echo \"$_main_domain,$_alt_domains,\" | cut -d , -f \"$_w_index\")\" _w_index=\"$(_math \"$_w_index\" + 1)\" _debug d \"$d\" if [ -z \"$d\" ]; then break fi _info \"Getting webroot for domain\" \"$d\" _index=$(_math $_index + 1) _w=\"$(echo $_web_roots | cut -d , -f $_index)\" _debug _w \"$_w\" if [ \"$_w\" ]; then _currentRoot=\"$_w\" fi _debug \"_currentRoot\" \"$_currentRoot\" vtype=\"$VTYPE_HTTP\" #todo, v2 wildcard force to use dns if _startswith \"$_currentRoot\" \"$W_DNS\"; then vtype=\"$VTYPE_DNS\" fi if [ \"$_currentRoot\" = \"$W_ALPN\" ]; then vtype=\"$VTYPE_ALPN\" fi _idn_d=\"$(_idn \"$d\")\" _candidates=\"$(echo \"$_authorizations_map\" | grep -i \"^$_idn_d,\")\" _debug2 _candidates \"$_candidates\" if [ \"$(echo \"$_candidates\" | wc -l)\" -gt 1 ]; then for _can in $_candidates; do if _startswith \"$(echo \"$_can\" | tr '.' '|')\" \"$(echo \"$_idn_d\" | tr '.' '|'),\"; then _candidates=\"$_can\" break fi done fi response=\"$(echo \"$_candidates\" | sed \"s/$_idn_d,//\")\" _debug2 \"response\" \"$response\" if [ -z \"$response\" ]; then _err \"Error getting authz.\" _err \"_authorizations_map\" \"$_authorizations_map\" _clearup _on_issue_err \"$_post_hook\" return 1 fi _authz_url=\"$(echo \"$_candidates\" | sed \"s/$_idn_d,//\" | _egrep_o \"#.*\" | sed \"s/^#//\")\" _debug _authz_url \"$_authz_url\" if [ -z \"$thumbprint\" ]; then thumbprint=\"$(__calc_account_thumbprint)\" fi keyauthorization=\"\" if echo \"$response\" | grep '\"status\":\"valid\"' >/dev/null 2>&1; then _debug \"$d is already valid.\" keyauthorization=\"$STATE_VERIFIED\" _debug keyauthorization \"$keyauthorization\" fi entry=\"$(echo \"$response\" | _egrep_o '[^\\{]*\"type\":\"'$vtype'\"[^\\}]*')\" _debug entry \"$entry\" if [ -z \"$keyauthorization\" -a -z \"$entry\" ]; then _err \"Cannot get domain token entry $d for $vtype\" _supported_vtypes=\"$(echo \"$response\" | _egrep_o \"\\\"challenges\\\":\\[[^]]*]\" | tr '{' \"\\n\" | grep type | cut -d '\"' -f 4 | tr \"\\n\" ' ')\" if [ \"$_supported_vtypes\" ]; then _err \"Supported validation types are: $_supported_vtypes, but you specified: $vtype\" fi _clearup _on_issue_err \"$_post_hook\" return 1 fi if [ -z \"$keyauthorization\" ]; then token=\"$(echo \"$entry\" | _egrep_o '\"token\":\"[^\"]*' | cut -d : -f 2 | tr -d '\"')\" _debug token \"$token\" if [ -z \"$token\" ]; then _err \"Cannot get domain token $entry\" _clearup _on_issue_err \"$_post_hook\" return 1 fi uri=\"$(echo \"$entry\" | _egrep_o '\"url\":\"[^\"]*' | cut -d '\"' -f 4 | _head_n 1)\" _debug uri \"$uri\" if [ -z \"$uri\" ]; then _err \"Cannot get domain URI $entry\" _clearup _on_issue_err \"$_post_hook\" return 1 fi keyauthorization=\"$token.$thumbprint\" _debug keyauthorization \"$keyauthorization\" fi dvlist=\"$d$sep$keyauthorization$sep$uri$sep$vtype$sep$_currentRoot$sep$_authz_url\" _debug dvlist \"$dvlist\" vlist=\"$vlist$dvlist$dvsep\" done _debug vlist \"$vlist\" #add entry dns_entries=\"\" dnsadded=\"\" ventries=$(echo \"$vlist\" | tr \"$dvsep\" ' ') _alias_index=1 for ventry in $ventries; do d=$(echo \"$ventry\" | cut -d \"$sep\" -f 1) keyauthorization=$(echo \"$ventry\" | cut -d \"$sep\" -f 2) vtype=$(echo \"$ventry\" | cut -d \"$sep\" -f 4) _currentRoot=$(echo \"$ventry\" | cut -d \"$sep\" -f 5) _authz_url=$(echo \"$ventry\" | cut -d \"$sep\" -f 6) _debug d \"$d\" if [ \"$keyauthorization\" = \"$STATE_VERIFIED\" ]; then _debug \"$d has already been verified, skipping $vtype.\" _alias_index=\"$(_math \"$_alias_index\" + 1)\" continue fi if [ \"$vtype\" = \"$VTYPE_DNS\" ]; then dnsadded='0' _dns_root_d=\"$d\" if _startswith \"$_dns_root_d\" \"*.\"; then _dns_root_d=\"$(echo \"$_dns_root_d\" | sed 's/*.//')\" fi _d_alias=\"$(_getfield \"$_challenge_alias\" \"$_alias_index\")\" test \"$_d_alias\" = \"$NO_VALUE\" && _d_alias=\"\" _alias_index=\"$(_math \"$_alias_index\" + 1)\" _debug \"_d_alias\" \"$_d_alias\" if [ \"$_d_alias\" ]; then if _startswith \"$_d_alias\" \"$DNS_ALIAS_PREFIX\"; then txtdomain=\"$(echo \"$_d_alias\" | sed \"s/$DNS_ALIAS_PREFIX//\")\" else txtdomain=\"_acme-challenge.$_d_alias\" fi dns_entry=\"${_dns_root_d}${dvsep}_acme-challenge.$_dns_root_d$dvsep$txtdomain$dvsep$_currentRoot\" else txtdomain=\"_acme-challenge.$_dns_root_d\" dns_entry=\"${_dns_root_d}${dvsep}_acme-challenge.$_dns_root_d$dvsep$dvsep$_currentRoot\" fi _debug txtdomain \"$txtdomain\" txt=\"$(printf \"%s\" \"$keyauthorization\" | _digest \"sha256\" | _url_replace)\" _debug txt \"$txt\" d_api=\"$(_findHook \"$_dns_root_d\" $_SUB_FOLDER_DNSAPI \"$_currentRoot\")\" _debug d_api \"$d_api\" dns_entry=\"$dns_entry$dvsep$txt${dvsep}$d_api\" _debug2 dns_entry \"$dns_entry\" if [ \"$d_api\" ]; then _debug \"Found domain API file: $d_api\" else if [ \"$_currentRoot\" != \"$W_DNS\" ]; then _err \"Cannot find DNS API hook for: $_currentRoot\" _info \"You need to add the TXT record manually.\" fi _info \"$(__red \"Add the following TXT record:\")\" _info \"$(__red \"Domain: '$(__green \"$txtdomain\")'\")\" _info \"$(__red \"TXT value: '$(__green \"$txt\")'\")\" _info \"$(__red \"Please make sure to prepend '_acme-challenge.' to your domain\")\" _info \"$(__red \"so that the resulting subdomain is: $txtdomain\")\" continue fi ( if ! . \"$d_api\"; then _err \"Error loading file $d_api. Please check your API file and try again.\" return 1 fi addcommand=\"${_currentRoot}_add\" if ! _exists \"$addcommand\"; then _err \"It seems that your API file is incorrect. Make sure it has a function named: $addcommand\" return 1 fi _info \"Adding TXT value: $txt for domain: $txtdomain\" if ! $addcommand \"$txtdomain\" \"$txt\"; then _err \"Error adding TXT record to domain: $txtdomain\" return 1 fi _info \"The TXT record has been successfully added.\" ) if [ \"$?\" != \"0\" ]; then _on_issue_err \"$_post_hook\" \"$vlist\" _clearup return 1 fi dns_entries=\"$dns_entries$dns_entry \" _debug2 \"$dns_entries\" dnsadded='1' fi done if [ \"$dnsadded\" = '0' ]; then _savedomainconf \"Le_Vlist\" \"$vlist\" _debug \"DNS record not yet added. Will save to $DOMAIN_CONF and exit.\" _err \"Please add the TXT records to the domains, and re-run with --renew.\" _on_issue_err \"$_post_hook\" _clearup # If asked to be in manual DNS mode, flag this exit with a separate # error so it can be distinguished from other failures. return $CODE_DNS_MANUAL fi fi if [ \"$dns_entries\" ]; then if [ -z \"$Le_DNSSleep\" ]; then _info \"Let's check each DNS record now. Sleeping for 20 seconds first.\" _sleep 20 if ! _check_dns_entries; then _err \"Error checking DNS.\" _on_issue_err \"$_post_hook\" _clearup return 1 fi else _savedomainconf \"Le_DNSSleep\" \"$Le_DNSSleep\" _info \"Sleeping for $(__green $Le_DNSSleep) seconds to wait for the the TXT records to take effect\" _sleep \"$Le_DNSSleep\" fi fi NGINX_RESTORE_VLIST=\"\" _debug \"OK, let's start verification\" _ncIndex=1 ventries=$(echo \"$vlist\" | tr \"$dvsep\" ' ') for ventry in $ventries; do d=$(echo \"$ventry\" | cut -d \"$sep\" -f 1) keyauthorization=$(echo \"$ventry\" | cut -d \"$sep\" -f 2) uri=$(echo \"$ventry\" | cut -d \"$sep\" -f 3) vtype=$(echo \"$ventry\" | cut -d \"$sep\" -f 4) _currentRoot=$(echo \"$ventry\" | cut -d \"$sep\" -f 5) _authz_url=$(echo \"$ventry\" | cut -d \"$sep\" -f 6) if [ \"$keyauthorization\" = \"$STATE_VERIFIED\" ]; then _info \"$d is already verified, skipping $vtype.\" continue fi _info \"Verifying: $d\" _debug \"d\" \"$d\" _debug \"keyauthorization\" \"$keyauthorization\" _debug \"uri\" \"$uri\" _debug \"_authz_url\" \"$_authz_url\" removelevel=\"\" token=\"$(printf \"%s\" \"$keyauthorization\" | cut -d '.' -f 1)\" _debug \"_currentRoot\" \"$_currentRoot\" if [ \"$vtype\" = \"$VTYPE_HTTP\" ]; then if [ \"$_currentRoot\" = \"$NO_VALUE\" ]; then _info \"Standalone mode server\" _ncaddr=\"$(_getfield \"$_local_addr\" \"$_ncIndex\")\" _ncIndex=\"$(_math $_ncIndex + 1)\" _startserver \"$keyauthorization\" \"$_ncaddr\" if [ \"$?\" != \"0\" ]; then _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi sleep 1 _debug serverproc \"$serverproc\" elif [ \"$_currentRoot\" = \"$MODE_STATELESS\" ]; then _info \"Stateless mode for domain: $d\" _sleep 1 elif _startswith \"$_currentRoot\" \"$NGINX\"; then _info \"Nginx mode for domain: $d\" #set up nginx server FOUND_REAL_NGINX_CONF=\"\" BACKUP_NGINX_CONF=\"\" if ! _setNginx \"$d\" \"$_currentRoot\" \"$thumbprint\"; then _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi if [ \"$FOUND_REAL_NGINX_CONF\" ]; then _realConf=\"$FOUND_REAL_NGINX_CONF\" _backup=\"$BACKUP_NGINX_CONF\" _debug _realConf \"$_realConf\" NGINX_RESTORE_VLIST=\"$d$sep$_realConf$sep$_backup$dvsep$NGINX_RESTORE_VLIST\" fi _sleep 1 else if [ \"$_currentRoot\" = \"apache\" ]; then wellknown_path=\"$ACME_DIR\" else wellknown_path=\"$_currentRoot/.well-known/acme-challenge\" if [ ! -d \"$_currentRoot/.well-known\" ]; then removelevel='1' elif [ ! -d \"$_currentRoot/.well-known/acme-challenge\" ]; then removelevel='2' else removelevel='3' fi fi _debug wellknown_path \"$wellknown_path\" _debug \"Writing token: $token to $wellknown_path/$token\" mkdir -p \"$wellknown_path\" if ! printf \"%s\" \"$keyauthorization\" >\"$wellknown_path/$token\"; then _err \"$d: Cannot write token to file: $wellknown_path/$token\" _clearupwebbroot \"$_currentRoot\" \"$removelevel\" \"$token\" _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi if ! chmod a+r \"$wellknown_path/$token\"; then _debug \"chmod failed, will just continue.\" fi fi elif [ \"$vtype\" = \"$VTYPE_ALPN\" ]; then acmevalidationv1=\"$(printf \"%s\" \"$keyauthorization\" | _digest \"sha256\" \"hex\")\" _debug acmevalidationv1 \"$acmevalidationv1\" if ! _starttlsserver \"$d\" \"\" \"$Le_TLSPort\" \"$keyauthorization\" \"$_ncaddr\" \"$acmevalidationv1\"; then _err \"Error starting TLS server.\" _clearupwebbroot \"$_currentRoot\" \"$removelevel\" \"$token\" _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi fi if ! __trigger_validation \"$uri\" \"$keyauthorization\" \"$vtype\"; then _err \"$d: Cannot get challenge: $response\" _clearupwebbroot \"$_currentRoot\" \"$removelevel\" \"$token\" _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi if [ \"$code\" ] && [ \"$code\" != '202' ]; then if [ \"$code\" = '200' ]; then _debug \"Trigger validation code: $code\" else _err \"$d: Challenge error: $response\" _clearupwebbroot \"$_currentRoot\" \"$removelevel\" \"$token\" _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi fi waittimes=0 if [ -z \"$MAX_RETRY_TIMES\" ]; then MAX_RETRY_TIMES=30 fi _debug \"Let's check the authz status\" while true; do waittimes=$(_math \"$waittimes\" + 1) if [ \"$waittimes\" -ge \"$MAX_RETRY_TIMES\" ]; then _err \"$d: Timeout\" _clearupwebbroot \"$_currentRoot\" \"$removelevel\" \"$token\" _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi _debug2 original \"$response\" response=\"$(echo \"$response\" | _normalizeJson)\" _debug2 response \"$response\" status=$(echo \"$response\" | _egrep_o '\"status\":\"[^\"]*' | cut -d : -f 2 | tr -d '\"') _debug2 status \"$status\" if _contains \"$status\" \"invalid\"; then error=\"$(echo \"$response\" | _egrep_o '\"error\":\\{[^\\}]*')\" _debug2 error \"$error\" errordetail=\"$(echo \"$error\" | _egrep_o '\"detail\": *\"[^\"]*' | cut -d '\"' -f 4)\" _debug2 errordetail \"$errordetail\" if [ \"$errordetail\" ]; then _err \"$d: Invalid status. Verification error details: $errordetail\" else _err \"$d: Invalid status, Verification error: $error\" fi if [ \"$DEBUG\" ]; then if [ \"$vtype\" = \"$VTYPE_HTTP\" ]; then _debug \"Debug: GET token URL.\" _get \"http://$d/.well-known/acme-challenge/$token\" \"\" 1 fi fi _clearupwebbroot \"$_currentRoot\" \"$removelevel\" \"$token\" _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi if _contains \"$status\" \"valid\"; then _info \"$(__green Success)\" _stopserver \"$serverproc\" serverproc=\"\" _clearupwebbroot \"$_currentRoot\" \"$removelevel\" \"$token\" break fi if _contains \"$status\" \"pending\"; then _info \"Pending. The CA is processing your order, please wait. ($waittimes/$MAX_RETRY_TIMES)\" elif _contains \"$status\" \"processing\"; then _info \"Processing. The CA is processing your order, please wait. ($waittimes/$MAX_RETRY_TIMES)\" else _err \"$d: Unknown status: $status. Verification error: $response\" _clearupwebbroot \"$_currentRoot\" \"$removelevel\" \"$token\" _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi _debug \"Sleep 2 seconds before verifying again\" _sleep 2 _debug \"Checking\" _send_signed_request \"$_authz_url\" if [ \"$?\" != \"0\" ]; then _err \"$d: Invalid code. Verification error: $response\" _clearupwebbroot \"$_currentRoot\" \"$removelevel\" \"$token\" _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi _retryafter=$(echo \"$responseHeaders\" | grep -i \"^Retry-After *: *[0-9]\\+ *\" | cut -d : -f 2 | tr -d ' ' | tr -d '\\r') _sleep_overload_retry_sec=$_retryafter if [ \"$_sleep_overload_retry_sec\" ]; then if [ $_sleep_overload_retry_sec -le 600 ]; then _sleep $_sleep_overload_retry_sec else _info \"The retryafter=$_retryafter value is too large (> 600), will not retry anymore.\" _clearupwebbroot \"$_currentRoot\" \"$removelevel\" \"$token\" _clearup _on_issue_err \"$_post_hook\" \"$vlist\" return 1 fi fi done done _clearup _info \"Verification finished, beginning signing.\" der=\"$(_getfile \"${CSR_PATH}\" \"${BEGIN_CSR}\" \"${END_CSR}\" | tr -d \"\\r\\n\" | _url_replace)\" _info \"Let's finalize the order.\" _info \"Le_OrderFinalize\" \"$Le_OrderFinalize\" if ! _send_signed_request \"${Le_OrderFinalize}\" \"{\\\"csr\\\": \\\"$der\\\"}\"; then _err \"Signing failed.\" _on_issue_err \"$_post_hook\" return 1 fi if [ \"$code\" != \"200\" ]; then _err \"Signing failed. Finalize code was not 200.\" _err \"$response\" _on_issue_err \"$_post_hook\" return 1 fi if [ -z \"$Le_LinkOrder\" ]; then Le_LinkOrder=\"$(echo \"$responseHeaders\" | grep -i '^Location.*$' | _tail_n 1 | tr -d \"\\r\\n \\t\" | cut -d \":\" -f 2-)\" fi _savedomainconf \"Le_LinkOrder\" \"$Le_LinkOrder\" _link_cert_retry=0 _MAX_CERT_RETRY=30 while [ \"$_link_cert_retry\" -lt \"$_MAX_CERT_RETRY\" ]; do if _contains \"$response\" \"\\\"status\\\":\\\"valid\\\"\"; then _debug \"Order status is valid.\" Le_LinkCert=\"$(echo \"$response\" | _egrep_o '\"certificate\" *: *\"[^\"]*\"' | cut -d '\"' -f 4)\" _debug Le_LinkCert \"$Le_LinkCert\" if [ -z \"$Le_LinkCert\" ]; then _err \"A signing error occurred: could not find Le_LinkCert\" _err \"$response\" _on_issue_err \"$_post_hook\" return 1 fi break elif _contains \"$response\" \"\\\"processing\\\"\"; then _info \"Order status is 'processing', let's sleep and retry.\" _retryafter=$(echo \"$responseHeaders\" | grep -i \"^Retry-After *:\" | cut -d : -f 2 | tr -d ' ' | tr -d '\\r') _debug \"_retryafter\" \"$_retryafter\" if [ \"$_retryafter\" ]; then _info \"Sleeping for $_retryafter seconds then retrying\" _sleep $_retryafter else _sleep 2 fi else _err \"Signing error: wrong status\" _err \"$response\" _on_issue_err \"$_post_hook\" return 1 fi #the order is processing, so we are going to poll order status if [ -z \"$Le_LinkOrder\" ]; then _err \"Signing error: could not get order link location header\" _err \"responseHeaders\" \"$responseHeaders\" _on_issue_err \"$_post_hook\" return 1 fi _info \"Polling order status: $Le_LinkOrder\" if ! _send_signed_request \"$Le_LinkOrder\"; then _err \"Signing failed. Could not make POST request to Le_LinkOrder for cert: $Le_LinkOrder.\" _err \"$response\" _on_issue_err \"$_post_hook\" return 1 fi _link_cert_retry=\"$(_math $_link_cert_retry + 1)\" done if [ -z \"$Le_LinkCert\" ]; then _err \"Signing failed. Could not get Le_LinkCert, and stopped retrying after reaching the retry limit.\" _err \"$response\" _on_issue_err \"$_post_hook\" return 1 fi _info \"Downloading cert.\" _info \"Le_LinkCert\" \"$Le_LinkCert\" if ! _send_signed_request \"$Le_LinkCert\"; then _err \"Signing failed. Could not download cert: $Le_LinkCert.\" _err \"$response\" _on_issue_err \"$_post_hook\" return 1 fi echo \"$response\" >\"$CERT_PATH\" _split_cert_chain \"$CERT_PATH\" \"$CERT_FULLCHAIN_PATH\" \"$CA_CERT_PATH\" if [ -z \"$_preferred_chain\" ]; then _preferred_chain=$(_readcaconf DEFAULT_PREFERRED_CHAIN) fi if [ \"$_preferred_chain\" ] && [ -f \"$CERT_FULLCHAIN_PATH\" ]; then if [ \"$DEBUG\" ]; then _debug \"Default chain issuers: \" \"$(_get_chain_issuers \"$CERT_FULLCHAIN_PATH\")\" fi if ! _match_issuer \"$CERT_FULLCHAIN_PATH\" \"$_preferred_chain\"; then rels=\"$(echo \"$responseHeaders\" | tr -d ' <>' | grep -i \"^link:\" | grep -i 'rel=\"alternate\"' | cut -d : -f 2- | cut -d ';' -f 1)\" _debug2 \"rels\" \"$rels\" for rel in $rels; do _info \"Trying rel: $rel\" if ! _send_signed_request \"$rel\"; then _err \"Signing failed, could not download cert: $rel\" _err \"$response\" continue fi _relcert=\"$CERT_PATH.alt\" _relfullchain=\"$CERT_FULLCHAIN_PATH.alt\" _relca=\"$CA_CERT_PATH.alt\" echo \"$response\" >\"$_relcert\" _split_cert_chain \"$_relcert\" \"$_relfullchain\" \"$_relca\" if [ \"$DEBUG\" ]; then _debug \"rel chain issuers: \" \"$(_get_chain_issuers \"$_relfullchain\")\" fi if _match_issuer \"$_relfullchain\" \"$_preferred_chain\"; then _info \"Matched issuer in: $rel\" cat $_relcert >\"$CERT_PATH\" cat $_relfullchain >\"$CERT_FULLCHAIN_PATH\" cat $_relca >\"$CA_CERT_PATH\" rm -f \"$_relcert\" rm -f \"$_relfullchain\" rm -f \"$_relca\" break fi rm -f \"$_relcert\" rm -f \"$_relfullchain\" rm -f \"$_relca\" done fi fi _debug \"Le_LinkCert\" \"$Le_LinkCert\" _savedomainconf \"Le_LinkCert\" \"$Le_LinkCert\" if [ -z \"$Le_LinkCert\" ] || ! _checkcert \"$CERT_PATH\"; then response=\"$(echo \"$response\" | _dbase64 \"multiline\" | tr -d '\\0' | _normalizeJson)\" _err \"Signing failed: $(echo \"$response\" | _egrep_o '\"detail\":\"[^\"]*\"')\" _on_issue_err \"$_post_hook\" return 1 fi if [ \"$Le_LinkCert\" ]; then _info \"$(__green \"Cert success.\")\" cat \"$CERT_PATH\" _info \"Your cert is in: $(__green \"$CERT_PATH\")\" if [ -f \"$CERT_KEY_PATH\" ]; then _info \"Your cert key is in: $(__green \"$CERT_KEY_PATH\")\" fi if [ ! \"$USER_PATH\" ] || [ ! \"$_ACME_IN_CRON\" ]; then USER_PATH=\"$PATH\" _saveaccountconf \"USER_PATH\" \"$USER_PATH\" fi fi [ -f \"$CA_CERT_PATH\" ] && _info \"The intermediate CA cert is in: $(__green \"$CA_CERT_PATH\")\" [ -f \"$CERT_FULLCHAIN_PATH\" ] && _info \"And the full-chain cert is in: $(__green \"$CERT_FULLCHAIN_PATH\")\" if [ \"$Le_ForceNewDomainKey\" ] && [ -e \"$Le_Next_Domain_Key\" ]; then _info \"Your pre-generated key for future cert key changes is in: $(__green \"$Le_Next_Domain_Key\")\" fi Le_CertCreateTime=$(_time) _savedomainconf \"Le_CertCreateTime\" \"$Le_CertCreateTime\" Le_CertCreateTimeStr=$(_time2str \"$Le_CertCreateTime\") _savedomainconf \"Le_CertCreateTimeStr\" \"$Le_CertCreateTimeStr\" if [ -z \"$Le_RenewalDays\" ] || [ \"$Le_RenewalDays\" -lt \"0\" ]; then Le_RenewalDays=\"$DEFAULT_RENEW\" else _savedomainconf \"Le_RenewalDays\" \"$Le_RenewalDays\" fi if [ \"$CA_BUNDLE\" ]; then _saveaccountconf CA_BUNDLE \"$CA_BUNDLE\" else _clearaccountconf \"CA_BUNDLE\" fi if [ \"$CA_PATH\" ]; then _saveaccountconf CA_PATH \"$CA_PATH\" else _clearaccountconf \"CA_PATH\" fi if [ \"$HTTPS_INSECURE\" ]; then _saveaccountconf HTTPS_INSECURE \"$HTTPS_INSECURE\" else _clearaccountconf \"HTTPS_INSECURE\" fi if [ \"$Le_Listen_V4\" ]; then _savedomainconf \"Le_Listen_V4\" \"$Le_Listen_V4\" _cleardomainconf Le_Listen_V6 elif [ \"$Le_Listen_V6\" ]; then _savedomainconf \"Le_Listen_V6\" \"$Le_Listen_V6\" _cleardomainconf Le_Listen_V4 fi if [ \"$Le_ForceNewDomainKey\" = \"1\" ]; then _savedomainconf \"Le_ForceNewDomainKey\" \"$Le_ForceNewDomainKey\" else _cleardomainconf Le_ForceNewDomainKey fi if [ \"$_notAfter\" ]; then Le_NextRenewTime=$(_date2time \"$_notAfter\") Le_NextRenewTimeStr=\"$_notAfter\" if [ \"$_valid_to\" ] && ! _startswith \"$_valid_to\" \"+\"; then _info \"The domain is set to be valid until: $_valid_to\" _info \"It cannot be renewed automatically\" _info \"See: $_VALIDITY_WIKI\" else _now=$(_time) _debug2 \"_now\" \"$_now\" _lifetime=$(_math $Le_NextRenewTime - $_now) _debug2 \"_lifetime\" \"$_lifetime\" if [ $_lifetime -gt 86400 ]; then #if lifetime is logner than one day, it will renew one day before Le_NextRenewTime=$(_math $Le_NextRenewTime - 86400) Le_NextRenewTimeStr=$(_time2str \"$Le_NextRenewTime\") else #if lifetime is less than 24 hours, it will renew one hour before Le_NextRenewTime=$(_math $Le_NextRenewTime - 3600) Le_NextRenewTimeStr=$(_time2str \"$Le_NextRenewTime\") fi fi else Le_NextRenewTime=$(_math \"$Le_CertCreateTime\" + \"$Le_RenewalDays\" \\* 24 \\* 60 \\* 60) Le_NextRenewTime=$(_math \"$Le_NextRenewTime\" - 86400) Le_NextRenewTimeStr=$(_time2str \"$Le_NextRenewTime\") fi _savedomainconf \"Le_NextRenewTimeStr\" \"$Le_NextRenewTimeStr\" _savedomainconf \"Le_NextRenewTime\" \"$Le_NextRenewTime\" #convert to pkcs12 if [ \"$Le_PFXPassword\" ]; then _toPkcs \"$CERT_PFX_PATH\" \"$CERT_KEY_PATH\" \"$CERT_PATH\" \"$CA_CERT_PATH\" \"$Le_PFXPassword\" fi export CERT_PFX_PATH if [ \"$_real_cert$_real_key$_real_ca$_reload_cmd$_real_fullchain\" ]; then _savedomainconf \"Le_RealCertPath\" \"$_real_cert\" _savedomainconf \"Le_RealCACertPath\" \"$_real_ca\" _savedomainconf \"Le_RealKeyPath\" \"$_real_key\" _savedomainconf \"Le_ReloadCmd\" \"$_reload_cmd\" \"base64\" _savedomainconf \"Le_RealFullChainPath\" \"$_real_fullchain\" if ! _installcert \"$_main_domain\" \"$_real_cert\" \"$_real_key\" \"$_real_ca\" \"$_real_fullchain\" \"$_reload_cmd\"; then return 1 fi fi if ! _on_issue_success \"$_post_hook\" \"$_renew_hook\"; then _err \"Error calling hook.\" return 1 fi } #in_out_cert out_fullchain out_ca _split_cert_chain() { _certf=\"$1\" _fullchainf=\"$2\" _caf=\"$3\" if [ \"$(grep -- \"$BEGIN_CERT\" \"$_certf\" | wc -l)\" -gt \"1\" ]; then _debug \"Found cert chain\" cat \"$_certf\" >\"$_fullchainf\" _end_n=\"$(grep -n -- \"$END_CERT\" \"$_fullchainf\" | _head_n 1 | cut -d : -f 1)\" _debug _end_n \"$_end_n\" sed -n \"1,${_end_n}p\" \"$_fullchainf\" >\"$_certf\" _end_n=\"$(_math $_end_n + 1)\" sed -n \"${_end_n},9999p\" \"$_fullchainf\" >\"$_caf\" fi } #domain [isEcc] [server] renew() { Le_Domain=\"$1\" if [ -z \"$Le_Domain\" ]; then _usage \"Usage: $PROJECT_ENTRY --renew --domain <domain.tld> [--ecc] [--server server]\" return 1 fi _isEcc=\"$2\" _renewServer=\"$3\" _debug \"_renewServer\" \"$_renewServer\" _initpath \"$Le_Domain\" \"$_isEcc\" _set_level=${NOTIFY_LEVEL:-$NOTIFY_LEVEL_DEFAULT} _info \"$(__green \"Renewing: '$Le_Domain'\")\" if [ ! -f \"$DOMAIN_CONF\" ]; then _info \"'$Le_Domain' is not an issued domain, skipping.\" return $RENEW_SKIP fi if [ \"$Le_RenewalDays\" ]; then _savedomainconf Le_RenewalDays \"$Le_RenewalDays\" fi . \"$DOMAIN_CONF\" _debug Le_API \"$Le_API\" case \"$Le_API\" in \"$CA_LETSENCRYPT_V2_TEST\") _info \"Switching back to $CA_LETSENCRYPT_V2\" Le_API=\"$CA_LETSENCRYPT_V2\" ;; \"$CA_BUYPASS_TEST\") _info \"Switching back to $CA_BUYPASS\" Le_API=\"$CA_BUYPASS\" ;; \"$CA_GOOGLE_TEST\") _info \"Switching back to $CA_GOOGLE\" Le_API=\"$CA_GOOGLE\" ;; esac if [ \"$_server\" ]; then Le_API=\"$_server\" fi _info \"Renewing using Le_API=$Le_API\" _clearAPI _clearCA export ACME_DIRECTORY=\"$Le_API\" #reload ca configs _debug2 \"initpath again.\" _initpath \"$Le_Domain\" \"$_isEcc\" if [ -z \"$FORCE\" ] && [ \"$Le_NextRenewTime\" ] && [ \"$(_time)\" -lt \"$Le_NextRenewTime\" ]; then _info \"Skipping. Next renewal time is: $(__green \"$Le_NextRenewTimeStr\")\" _info \"Add '$(__red '--force')' to force renewal.\" if [ -z \"$_ACME_IN_RENEWALL\" ]; then if [ $_set_level -ge $NOTIFY_LEVEL_SKIP ]; then _send_notify \"Renew $Le_Domain skipped\" \"Good, the cert is skipped.\" \"$NOTIFY_HOOK\" \"$RENEW_SKIP\" fi fi return \"$RENEW_SKIP\" fi if [ \"$_ACME_IN_CRON\" = \"1\" ] && [ -z \"$Le_CertCreateTime\" ]; then _info \"Skipping invalid cert for: $Le_Domain\" return $RENEW_SKIP fi _ACME_IS_RENEW=\"1\" Le_ReloadCmd=\"$(_readdomainconf Le_ReloadCmd)\" Le_PreHook=\"$(_readdomainconf Le_PreHook)\" Le_PostHook=\"$(_readdomainconf Le_PostHook)\" Le_RenewHook=\"$(_readdomainconf Le_RenewHook)\" Le_Preferred_Chain=\"$(_readdomainconf Le_Preferred_Chain)\" # When renewing from an old version, the empty Le_Keylength means 2048. # Note, do not use DEFAULT_DOMAIN_KEY_LENGTH as that value may change over # time but an empty value implies 2048 specifically. Le_Keylength=\"$(_readdomainconf Le_Keylength)\" if [ -z \"$Le_Keylength\" ]; then Le_Keylength=2048 fi issue \"$Le_Webroot\" \"$Le_Domain\" \"$Le_Alt\" \"$Le_Keylength\" \"$Le_RealCertPath\" \"$Le_RealKeyPath\" \"$Le_RealCACertPath\" \"$Le_ReloadCmd\" \"$Le_RealFullChainPath\" \"$Le_PreHook\" \"$Le_PostHook\" \"$Le_RenewHook\" \"$Le_LocalAddress\" \"$Le_ChallengeAlias\" \"$Le_Preferred_Chain\" \"$Le_Valid_From\" \"$Le_Valid_To\" res=\"$?\" if [ \"$res\" != \"0\" ]; then return \"$res\" fi if [ \"$Le_DeployHook\" ]; then _deploy \"$Le_Domain\" \"$Le_DeployHook\" res=\"$?\" fi _ACME_IS_RENEW=\"\" if [ -z \"$_ACME_IN_RENEWALL\" ]; then if [ \"$res\" = \"0\" ]; then if [ $_set_level -ge $NOTIFY_LEVEL_RENEW ]; then _send_notify \"Renew $d success\" \"Good, the cert is renewed.\" \"$NOTIFY_HOOK\" 0 fi else if [ $_set_level -ge $NOTIFY_LEVEL_ERROR ]; then _send_notify \"Renew $d error\" \"There is an error.\" \"$NOTIFY_HOOK\" 1 fi fi fi return \"$res\" } #renewAll [stopRenewOnError] [server] renewAll() { _initpath _clearCA _stopRenewOnError=\"$1\" _debug \"_stopRenewOnError\" \"$_stopRenewOnError\" _server=\"$2\" _debug \"_server\" \"$_server\" _ret=\"0\" _success_msg=\"\" _error_msg=\"\" _skipped_msg=\"\" _error_level=$NOTIFY_LEVEL_SKIP _notify_code=$RENEW_SKIP _set_level=${NOTIFY_LEVEL:-$NOTIFY_LEVEL_DEFAULT} _debug \"_set_level\" \"$_set_level\" export _ACME_IN_RENEWALL=1 for di in \"${CERT_HOME}\"/*.*/; do _debug di \"$di\" if ! [ -d \"$di\" ]; then _debug \"Not a directory, skipping: $di\" continue fi d=$(basename \"$di\") _debug d \"$d\" ( if _endswith \"$d\" \"$ECC_SUFFIX\"; then _isEcc=$(echo \"$d\" | cut -d \"$ECC_SEP\" -f 2) d=$(echo \"$d\" | cut -d \"$ECC_SEP\" -f 1) fi renew \"$d\" \"$_isEcc\" \"$_server\" ) rc=\"$?\" _debug \"Return code: $rc\" if [ \"$rc\" = \"0\" ]; then if [ $_error_level -gt $NOTIFY_LEVEL_RENEW ]; then _error_level=\"$NOTIFY_LEVEL_RENEW\" _notify_code=0 fi if [ $_set_level -ge $NOTIFY_LEVEL_RENEW ]; then if [ \"$NOTIFY_MODE\" = \"$NOTIFY_MODE_CERT\" ]; then _send_notify \"Renew $d success\" \"Good, the cert is renewed.\" \"$NOTIFY_HOOK\" 0 fi fi _success_msg=\"${_success_msg} $d \" elif [ \"$rc\" = \"$RENEW_SKIP\" ]; then if [ $_error_level -gt $NOTIFY_LEVEL_SKIP ]; then _error_level=\"$NOTIFY_LEVEL_SKIP\" _notify_code=$RENEW_SKIP fi if [ $_set_level -ge $NOTIFY_LEVEL_SKIP ]; then if [ \"$NOTIFY_MODE\" = \"$NOTIFY_MODE_CERT\" ]; then _send_notify \"Renew $d skipped\" \"Good, the cert is skipped.\" \"$NOTIFY_HOOK\" \"$RENEW_SKIP\" fi fi _info \"Skipped $d\" _skipped_msg=\"${_skipped_msg} $d \" else if [ $_error_level -gt $NOTIFY_LEVEL_ERROR ]; then _error_level=\"$NOTIFY_LEVEL_ERROR\" _notify_code=1 fi if [ $_set_level -ge $NOTIFY_LEVEL_ERROR ]; then if [ \"$NOTIFY_MODE\" = \"$NOTIFY_MODE_CERT\" ]; then _send_notify \"Renew $d error\" \"There is an error.\" \"$NOTIFY_HOOK\" 1 fi fi _error_msg=\"${_error_msg} $d \" if [ \"$_stopRenewOnError\" ]; then _err \"Error renewing $d, stopping.\" _ret=\"$rc\" break else _ret=\"$rc\" _err \"Error renewing $d.\" fi fi done _debug _error_level \"$_error_level\" _debug _set_level \"$_set_level\" if [ $_error_level -le $_set_level ]; then if [ -z \"$NOTIFY_MODE\" ] || [ \"$NOTIFY_MODE\" = \"$NOTIFY_MODE_BULK\" ]; then _msg_subject=\"Renew\" if [ \"$_error_msg\" ]; then _msg_subject=\"${_msg_subject} Error\" _msg_data=\"Errored certs: ${_error_msg} \" fi if [ \"$_success_msg\" ]; then _msg_subject=\"${_msg_subject} Success\" _msg_data=\"${_msg_data}Successful certs: ${_success_msg} \" fi if [ \"$_skipped_msg\" ]; then _msg_subject=\"${_msg_subject} Skipped\" _msg_data=\"${_msg_data}Skipped certs: ${_skipped_msg} \" fi _send_notify \"$_msg_subject\" \"$_msg_data\" \"$NOTIFY_HOOK\" \"$_notify_code\" fi fi return \"$_ret\" } #csr webroot signcsr() { _csrfile=\"$1\" _csrW=\"$2\" if [ -z \"$_csrfile\" ] || [ -z \"$_csrW\" ]; then _usage \"Usage: $PROJECT_ENTRY --sign-csr --csr <csr-file> --webroot <directory>\" return 1 fi _real_cert=\"$3\" _real_key=\"$4\" _real_ca=\"$5\" _reload_cmd=\"$6\" _real_fullchain=\"$7\" _pre_hook=\"${8}\" _post_hook=\"${9}\" _renew_hook=\"${10}\" _local_addr=\"${11}\" _challenge_alias=\"${12}\" _preferred_chain=\"${13}\" _csrsubj=$(_readSubjectFromCSR \"$_csrfile\") if [ \"$?\" != \"0\" ]; then _err \"Cannot read subject from CSR: $_csrfile\" return 1 fi _debug _csrsubj \"$_csrsubj\" if _contains \"$_csrsubj\" ' ' || ! _contains \"$_csrsubj\" '.'; then _info \"It seems that the subject $_csrsubj is not a valid domain name. Dropping it.\" _csrsubj=\"\" fi _csrdomainlist=$(_readSubjectAltNamesFromCSR \"$_csrfile\") if [ \"$?\" != \"0\" ]; then _err \"Cannot read domain list from CSR: $_csrfile\" return 1 fi _debug \"_csrdomainlist\" \"$_csrdomainlist\" if [ -z \"$_csrsubj\" ]; then _csrsubj=\"$(_getfield \"$_csrdomainlist\" 1)\" _debug _csrsubj \"$_csrsubj\" _csrdomainlist=\"$(echo \"$_csrdomainlist\" | cut -d , -f 2-)\" _debug \"_csrdomainlist\" \"$_csrdomainlist\" fi if [ -z \"$_csrsubj\" ]; then _err \"Cannot read subject from CSR: $_csrfile\" return 1 fi _csrkeylength=$(_readKeyLengthFromCSR \"$_csrfile\") if [ \"$?\" != \"0\" ] || [ -z \"$_csrkeylength\" ]; then _err \"Cannot read key length from CSR: $_csrfile\" return 1 fi _initpath \"$_csrsubj\" \"$_csrkeylength\" mkdir -p \"$DOMAIN_PATH\" _info \"Copying CSR to: $CSR_PATH\" cp \"$_csrfile\" \"$CSR_PATH\" issue \"$_csrW\" \"$_csrsubj\" \"$_csrdomainlist\" \"$_csrkeylength\" \"$_real_cert\" \"$_real_key\" \"$_real_ca\" \"$_reload_cmd\" \"$_real_fullchain\" \"$_pre_hook\" \"$_post_hook\" \"$_renew_hook\" \"$_local_addr\" \"$_challenge_alias\" \"$_preferred_chain\" } showcsr() { _csrfile=\"$1\" _csrd=\"$2\" if [ -z \"$_csrfile\" ] && [ -z \"$_csrd\" ]; then _usage \"Usage: $PROJECT_ENTRY --show-csr --csr <csr-file>\" return 1 fi _initpath _csrsubj=$(_readSubjectFromCSR \"$_csrfile\") if [ \"$?\" != \"0\" ]; then _err \"Cannot read subject from CSR: $_csrfile\" return 1 fi if [ -z \"$_csrsubj\" ]; then _info \"The subject is empty\" fi _info \"Subject=$_csrsubj\" _csrdomainlist=$(_readSubjectAltNamesFromCSR \"$_csrfile\") if [ \"$?\" != \"0\" ]; then _err \"Cannot read domain list from CSR: $_csrfile\" return 1 fi _debug \"_csrdomainlist\" \"$_csrdomainlist\" _info \"SubjectAltNames=$_csrdomainlist\" _csrkeylength=$(_readKeyLengthFromCSR \"$_csrfile\") if [ \"$?\" != \"0\" ] || [ -z \"$_csrkeylength\" ]; then _err \"Cannot read key length from CSR: $_csrfile\" return 1 fi _info \"KeyLength=$_csrkeylength\" } #listraw domain list() { _raw=\"$1\" _domain=\"$2\" _initpath _sep=\"|\" if [ \"$_raw\" ]; then if [ -z \"$_domain\" ]; then printf \"%s\\n\" \"Main_Domain${_sep}KeyLength${_sep}SAN_Domains${_sep}CA${_sep}Created${_sep}Renew\" fi for di in \"${CERT_HOME}\"/*.*/; do d=$(basename \"$di\") _debug d \"$d\" ( if _endswith \"$d\" \"$ECC_SUFFIX\"; then _isEcc=\"ecc\" d=$(echo \"$d\" | cut -d \"$ECC_SEP\" -f 1) fi DOMAIN_CONF=\"$di/$d.conf\" if [ -f \"$DOMAIN_CONF\" ]; then . \"$DOMAIN_CONF\" _ca=\"$(_getCAShortName \"$Le_API\")\" if [ -z \"$_domain\" ]; then printf \"%s\\n\" \"$Le_Domain${_sep}\\\"$Le_Keylength\\\"${_sep}$Le_Alt${_sep}$_ca${_sep}$Le_CertCreateTimeStr${_sep}$Le_NextRenewTimeStr\" else if [ \"$_domain\" = \"$d\" ]; then cat \"$DOMAIN_CONF\" fi fi fi ) done else if _exists column; then list \"raw\" \"$_domain\" | column -t -s \"$_sep\" else list \"raw\" \"$_domain\" | tr \"$_sep\" '\\t' fi fi } _deploy() { _d=\"$1\" _hooks=\"$2\" for _d_api in $(echo \"$_hooks\" | tr ',' \" \"); do _deployApi=\"$(_findHook \"$_d\" $_SUB_FOLDER_DEPLOY \"$_d_api\")\" if [ -z \"$_deployApi\" ]; then _err \"The deploy hook $_d_api was not found.\" return 1 fi _debug _deployApi \"$_deployApi\" if ! ( if ! . \"$_deployApi\"; then _err \"Error loading file $_deployApi. Please check your API file and try again.\" return 1 fi d_command=\"${_d_api}_deploy\" if ! _exists \"$d_command\"; then _err \"It seems that your API file is not correct. Make sure it has a function named: $d_command\" return 1 fi if ! $d_command \"$_d\" \"$CERT_KEY_PATH\" \"$CERT_PATH\" \"$CA_CERT_PATH\" \"$CERT_FULLCHAIN_PATH\"; then _err \"Error deploying for domain: $_d\" return 1 fi ); then _err \"Error encountered while deploying.\" return 1 else _info \"$(__green Success)\" fi done } #domain hooks deploy() { _d=\"$1\" _hooks=\"$2\" _isEcc=\"$3\" if [ -z \"$_hooks\" ]; then _usage \"Usage: $PROJECT_ENTRY --deploy --domain <domain.tld> --deploy-hook <hookname> [--ecc] \" return 1 fi _initpath \"$_d\" \"$_isEcc\" if [ ! -d \"$DOMAIN_PATH\" ]; then _err \"The domain '$_d' is not a cert name. You must use the cert name to specify the cert to install.\" _err \"Cannot find path: '$DOMAIN_PATH'\" return 1 fi _debug2 DOMAIN_CONF \"$DOMAIN_CONF\" . \"$DOMAIN_CONF\" _savedomainconf Le_DeployHook \"$_hooks\" _deploy \"$_d\" \"$_hooks\" } installcert() { _main_domain=\"$1\" if [ -z \"$_main_domain\" ]; then _usage \"Usage: $PROJECT_ENTRY --install-cert --domain <domain.tld> [--ecc] [--cert-file <file>] [--key-file <file>] [--ca-file <file>] [ --reloadcmd <command>] [--fullchain-file <file>]\" return 1 fi _real_cert=\"$2\" _real_key=\"$3\" _real_ca=\"$4\" _reload_cmd=\"$5\" _real_fullchain=\"$6\" _isEcc=\"$7\" _initpath \"$_main_domain\" \"$_isEcc\" if [ ! -d \"$DOMAIN_PATH\" ]; then _err \"The domain '$_main_domain' is not a cert name. You must use the cert name to specify the cert to install.\" _err \"Cannot find path: '$DOMAIN_PATH'\" return 1 fi _savedomainconf \"Le_RealCertPath\" \"$_real_cert\" _savedomainconf \"Le_RealCACertPath\" \"$_real_ca\" _savedomainconf \"Le_RealKeyPath\" \"$_real_key\" _savedomainconf \"Le_ReloadCmd\" \"$_reload_cmd\" \"base64\" _savedomainconf \"Le_RealFullChainPath\" \"$_real_fullchain\" export Le_ForceNewDomainKey=\"$(_readdomainconf Le_ForceNewDomainKey)\" export Le_Next_Domain_Key _installcert \"$_main_domain\" \"$_real_cert\" \"$_real_key\" \"$_real_ca\" \"$_real_fullchain\" \"$_reload_cmd\" } #domain cert key ca fullchain reloadcmd backup-prefix _installcert() { _main_domain=\"$1\" _real_cert=\"$2\" _real_key=\"$3\" _real_ca=\"$4\" _real_fullchain=\"$5\" _reload_cmd=\"$6\" _backup_prefix=\"$7\" if [ \"$_real_cert\" = \"$NO_VALUE\" ]; then _real_cert=\"\" fi if [ \"$_real_key\" = \"$NO_VALUE\" ]; then _real_key=\"\" fi if [ \"$_real_ca\" = \"$NO_VALUE\" ]; then _real_ca=\"\" fi if [ \"$_reload_cmd\" = \"$NO_VALUE\" ]; then _reload_cmd=\"\" fi if [ \"$_real_fullchain\" = \"$NO_VALUE\" ]; then _real_fullchain=\"\" fi _backup_path=\"$DOMAIN_BACKUP_PATH/$_backup_prefix\" mkdir -p \"$_backup_path\" if [ \"$_real_cert\" ]; then _info \"Installing cert to: $_real_cert\" if [ -f \"$_real_cert\" ] && [ ! \"$_ACME_IS_RENEW\" ]; then cp \"$_real_cert\" \"$_backup_path/cert.bak\" fi if [ \"$CERT_PATH\" != \"$_real_cert\" ]; then cat \"$CERT_PATH\" >\"$_real_cert\" || return 1 fi fi if [ \"$_real_ca\" ]; then _info \"Installing CA to: $_real_ca\" if [ \"$_real_ca\" = \"$_real_cert\" ]; then echo \"\" >>\"$_real_ca\" cat \"$CA_CERT_PATH\" >>\"$_real_ca\" || return 1 else if [ -f \"$_real_ca\" ] && [ ! \"$_ACME_IS_RENEW\" ]; then cp \"$_real_ca\" \"$_backup_path/ca.bak\" fi if [ \"$CA_CERT_PATH\" != \"$_real_ca\" ]; then cat \"$CA_CERT_PATH\" >\"$_real_ca\" || return 1 fi fi fi if [ \"$_real_key\" ]; then _info \"Installing key to: $_real_key\" if [ -f \"$_real_key\" ] && [ ! \"$_ACME_IS_RENEW\" ]; then cp \"$_real_key\" \"$_backup_path/key.bak\" fi if [ \"$CERT_KEY_PATH\" != \"$_real_key\" ]; then if [ -f \"$_real_key\" ]; then cat \"$CERT_KEY_PATH\" >\"$_real_key\" || return 1 else touch \"$_real_key\" || return 1 chmod 600 \"$_real_key\" cat \"$CERT_KEY_PATH\" >\"$_real_key\" || return 1 fi fi fi if [ \"$_real_fullchain\" ]; then _info \"Installing full chain to: $_real_fullchain\" if [ -f \"$_real_fullchain\" ] && [ ! \"$_ACME_IS_RENEW\" ]; then cp \"$_real_fullchain\" \"$_backup_path/fullchain.bak\" fi if [ \"$_real_fullchain\" != \"$CERT_FULLCHAIN_PATH\" ]; then cat \"$CERT_FULLCHAIN_PATH\" >\"$_real_fullchain\" || return 1 fi fi if [ \"$_reload_cmd\" ]; then _info \"Running reload cmd: $_reload_cmd\" if ( export CERT_PATH export CERT_KEY_PATH export CA_CERT_PATH export CERT_FULLCHAIN_PATH export Le_Domain=\"$_main_domain\" export Le_ForceNewDomainKey export Le_Next_Domain_Key cd \"$DOMAIN_PATH\" && eval \"$_reload_cmd\" ); then _info \"$(__green \"Reload successful\")\" else _err \"Reload error for: $Le_Domain\" fi fi } __read_password() { unset _pp prompt=\"Enter Password:\" while IFS= read -p \"$prompt\" -r -s -n 1 char; do if [ \"$char\" = $'\\0' ]; then break fi prompt='*' _pp=\"$_pp$char\" done echo \"$_pp\" } _install_win_taskscheduler() { _lesh=\"$1\" _centry=\"$2\" _randomminute=\"$3\" if ! _exists cygpath; then _err \"cygpath not found\" return 1 fi if ! _exists schtasks; then _err \"schtasks.exe was not found, are you on Windows?\" return 1 fi _winbash=\"$(cygpath -w $(which bash))\" _debug _winbash \"$_winbash\" if [ -z \"$_winbash\" ]; then _err \"Cannot find bash path\" return 1 fi _myname=\"$(whoami)\" _debug \"_myname\" \"$_myname\" if [ -z \"$_myname\" ]; then _err \"Can not find own username\" return 1 fi _debug \"_lesh\" \"$_lesh\" _info \"To install the scheduler task to your Windows account, you must input your Windows password.\" _info \"$PROJECT_NAME will not save your password.\" _info \"Please input your Windows password for: $(__green \"$_myname\")\" _password=\"$(__read_password)\" #SCHTASKS.exe '/create' '/SC' 'DAILY' '/TN' \"$_WINDOWS_SCHEDULER_NAME\" '/F' '/ST' \"00:$_randomminute\" '/RU' \"$_myname\" '/RP' \"$_password\" '/TR' \"$_winbash -l -c '$_lesh --cron --home \\\"$LE_WORKING_DIR\\\" $_centry'\" >/dev/null echo SCHTASKS.exe '/create' '/SC' 'DAILY' '/TN' \"$_WINDOWS_SCHEDULER_NAME\" '/F' '/ST' \"00:$_randomminute\" '/RU' \"$_myname\" '/RP' \"$_password\" '/TR' \"\\\"$_winbash -l -c '$_lesh --cron --home \\\"$LE_WORKING_DIR\\\" $_centry'\\\"\" | cmd.exe >/dev/null echo } _uninstall_win_taskscheduler() { if ! _exists schtasks; then _err \"schtasks.exe was not found, are you on Windows?\" return 1 fi if ! echo SCHTASKS /query /tn \"$_WINDOWS_SCHEDULER_NAME\" | cmd.exe >/dev/null; then _debug \"scheduler $_WINDOWS_SCHEDULER_NAME was not found.\" else _info \"Removing $_WINDOWS_SCHEDULER_NAME\" echo SCHTASKS /delete /f /tn \"$_WINDOWS_SCHEDULER_NAME\" | cmd.exe >/dev/null fi } #confighome installcronjob() { _c_home=\"$1\" _initpath _CRONTAB=\"crontab\" if [ -f \"$LE_WORKING_DIR/$PROJECT_ENTRY\" ]; then lesh=\"\\\"$LE_WORKING_DIR\\\"/$PROJECT_ENTRY\" else _debug \"_SCRIPT_\" \"$_SCRIPT_\" _script=\"$(_readlink \"$_SCRIPT_\")\" _debug _script \"$_script\" if [ -f \"$_script\" ]; then _info \"Usinging the current script from: $_script\" lesh=\"$_script\" else _err \"Cannot install cronjob, $PROJECT_ENTRY not found.\" return 1 fi fi if [ \"$_c_home\" ]; then _c_entry=\"--config-home \\\"$_c_home\\\" \" fi _t=$(_time) random_minute=$(_math $_t % 60) random_hour=$(_math $_t / 60 % 24) if ! _exists \"$_CRONTAB\" && _exists \"fcrontab\"; then _CRONTAB=\"fcrontab\" fi if ! _exists \"$_CRONTAB\"; then if _exists cygpath && _exists schtasks.exe; then _info \"It seems you are on Windows, let's install the Windows scheduler task.\" if _install_win_taskscheduler \"$lesh\" \"$_c_entry\" \"$random_minute\"; then _info \"Successfully installed Windows scheduler task.\" return 0 else _err \"Failed to install Windows scheduler task.\" return 1 fi fi _err \"crontab/fcrontab doesn't exist, so we cannot install cron jobs.\" _err \"Your certs will not be renewed automatically.\" _err \"You must add your own cron job to call '$PROJECT_ENTRY --cron' every day.\" return 1 fi _info \"Installing cron job\" if ! $_CRONTAB -l | grep \"$PROJECT_ENTRY --cron\"; then if _exists uname && uname -a | grep SunOS >/dev/null; then _CRONTAB_STDIN=\"$_CRONTAB --\" else _CRONTAB_STDIN=\"$_CRONTAB -\" fi $_CRONTAB -l | { cat echo \"$random_minute $random_hour * * * $lesh --cron --home \\\"$LE_WORKING_DIR\\\" $_c_entry> /dev/null\" } | $_CRONTAB_STDIN fi if [ \"$?\" != \"0\" ]; then _err \"Failed to install cron job. You need to manually renew your certs.\" _err \"Alternatively, you can add a cron job by yourself:\" _err \"$lesh --cron --home \\\"$LE_WORKING_DIR\\\" > /dev/null\" return 1 fi } uninstallcronjob() { _CRONTAB=\"crontab\" if ! _exists \"$_CRONTAB\" && _exists \"fcrontab\"; then _CRONTAB=\"fcrontab\" fi if ! _exists \"$_CRONTAB\"; then if _exists cygpath && _exists schtasks.exe; then _info \"It seems you are on Windows, let's uninstall the Windows scheduler task.\" if _uninstall_win_taskscheduler; then _info \"Successfully uninstalled Windows scheduler task.\" return 0 else _err \"Failed to uninstall Windows scheduler task.\" return 1 fi fi return fi _info \"Removing cron job\" cr=\"$($_CRONTAB -l | grep \"$PROJECT_ENTRY --cron\")\" if [ \"$cr\" ]; then if _exists uname && uname -a | grep SunOS >/dev/null; then $_CRONTAB -l | sed \"/$PROJECT_ENTRY --cron/d\" | $_CRONTAB -- else $_CRONTAB -l | sed \"/$PROJECT_ENTRY --cron/d\" | $_CRONTAB - fi LE_WORKING_DIR=\"$(echo \"$cr\" | cut -d ' ' -f 9 | tr -d '\"')\" _info LE_WORKING_DIR \"$LE_WORKING_DIR\" if _contains \"$cr\" \"--config-home\"; then LE_CONFIG_HOME=\"$(echo \"$cr\" | cut -d ' ' -f 11 | tr -d '\"')\" _debug LE_CONFIG_HOME \"$LE_CONFIG_HOME\" fi fi _initpath } #domain isECC revokeReason revoke() { Le_Domain=\"$1\" if [ -z \"$Le_Domain\" ]; then _usage \"Usage: $PROJECT_ENTRY --revoke --domain <domain.tld> [--ecc]\" return 1 fi _isEcc=\"$2\" _reason=\"$3\" if [ -z \"$_reason\" ]; then _reason=\"0\" fi _initpath \"$Le_Domain\" \"$_isEcc\" if [ ! -f \"$DOMAIN_CONF\" ]; then _err \"$Le_Domain is not an issued domain, skipping.\" return 1 fi if [ ! -f \"$CERT_PATH\" ]; then _err \"Cert for $Le_Domain $CERT_PATH was not found, skipping.\" return 1 fi . \"$DOMAIN_CONF\" _debug Le_API \"$Le_API\" if [ \"$Le_API\" ]; then if [ \"$Le_API\" != \"$ACME_DIRECTORY\" ]; then _clearAPI fi export ACME_DIRECTORY=\"$Le_API\" #reload ca configs ACCOUNT_KEY_PATH=\"\" ACCOUNT_JSON_PATH=\"\" CA_CONF=\"\" _debug3 \"initpath again.\" _initpath \"$Le_Domain\" \"$_isEcc\" _initAPI fi cert=\"$(_getfile \"${CERT_PATH}\" \"${BEGIN_CERT}\" \"${END_CERT}\" | tr -d \"\\r\\n\" | _url_replace)\" if [ -z \"$cert\" ]; then _err \"Cert for $Le_Domain is empty, skipping.\" return 1 fi _initAPI data=\"{\\\"certificate\\\": \\\"$cert\\\",\\\"reason\\\":$_reason}\" uri=\"${ACME_REVOKE_CERT}\" _info \"Trying account key first.\" if _send_signed_request \"$uri\" \"$data\" \"\" \"$ACCOUNT_KEY_PATH\"; then if [ -z \"$response\" ]; then _info \"Successfully revoked.\" rm -f \"$CERT_PATH\" cat \"$CERT_KEY_PATH\" >\"$CERT_KEY_PATH.revoked\" cat \"$CSR_PATH\" >\"$CSR_PATH.revoked\" return 0 else _err \"Error revoking.\" _debug \"$response\" fi fi if [ -f \"$CERT_KEY_PATH\" ]; then _info \"Trying domain key.\" if _send_signed_request \"$uri\" \"$data\" \"\" \"$CERT_KEY_PATH\"; then if [ -z \"$response\" ]; then _info \"Successfully revoked.\" rm -f \"$CERT_PATH\" cat \"$CERT_KEY_PATH\" >\"$CERT_KEY_PATH.revoked\" cat \"$CSR_PATH\" >\"$CSR_PATH.revoked\" return 0 else _err \"Error revoking using domain key.\" _err \"$response\" fi fi else _info \"Domain key file doesn't exist.\" fi return 1 } #domain ecc remove() { Le_Domain=\"$1\" if [ -z \"$Le_Domain\" ]; then _usage \"Usage: $PROJECT_ENTRY --remove --domain <domain.tld> [--ecc]\" return 1 fi _isEcc=\"$2\" _initpath \"$Le_Domain\" \"$_isEcc\" _removed_conf=\"$DOMAIN_CONF.removed\" if [ ! -f \"$DOMAIN_CONF\" ]; then if [ -f \"$_removed_conf\" ]; then _err \"$Le_Domain has already been removed. You can remove the folder by yourself: $DOMAIN_PATH\" else _err \"$Le_Domain is not an issued domain, skipping.\" fi return 1 fi if mv \"$DOMAIN_CONF\" \"$_removed_conf\"; then _info \"$Le_Domain has been removed. The key and cert files are in $(__green $DOMAIN_PATH)\" _info \"You can remove them by yourself.\" return 0 else _err \"Failed to remove $Le_Domain.\" return 1 fi } #domain vtype _deactivate() { _d_domain=\"$1\" _d_type=\"$2\" _initpath \"$_d_domain\" \"$_d_type\" . \"$DOMAIN_CONF\" _debug Le_API \"$Le_API\" if [ \"$Le_API\" ]; then if [ \"$Le_API\" != \"$ACME_DIRECTORY\" ]; then _clearAPI fi export ACME_DIRECTORY=\"$Le_API\" #reload ca configs ACCOUNT_KEY_PATH=\"\" ACCOUNT_JSON_PATH=\"\" CA_CONF=\"\" _debug3 \"initpath again.\" _initpath \"$Le_Domain\" \"$_d_type\" _initAPI fi _identifiers=\"{\\\"type\\\":\\\"$(_getIdType \"$_d_domain\")\\\",\\\"value\\\":\\\"$_d_domain\\\"}\" if ! _send_signed_request \"$ACME_NEW_ORDER\" \"{\\\"identifiers\\\": [$_identifiers]}\"; then _err \"Cannot get new order for domain.\" return 1 fi _authorizations_seg=\"$(echo \"$response\" | _egrep_o '\"authorizations\" *: *\\[[^\\]*\\]' | cut -d '[' -f 2 | tr -d ']' | tr -d '\"')\" _debug2 _authorizations_seg \"$_authorizations_seg\" if [ -z \"$_authorizations_seg\" ]; then _err \"_authorizations_seg not found.\" _clearup _on_issue_err \"$_post_hook\" return 1 fi authzUri=\"$_authorizations_seg\" _debug2 \"authzUri\" \"$authzUri\" if ! _send_signed_request \"$authzUri\"; then _err \"Error making GET request for authz.\" _err \"_authorizations_seg\" \"$_authorizations_seg\" _err \"authzUri\" \"$authzUri\" _clearup _on_issue_err \"$_post_hook\" return 1 fi response=\"$(echo \"$response\" | _normalizeJson)\" _debug2 response \"$response\" _URL_NAME=\"url\" entries=\"$(echo \"$response\" | tr '][' '==' | _egrep_o \"challenges\\\": *=[^=]*=\" | tr '}{' '\\n\\n' | grep \"\\\"status\\\": *\\\"valid\\\"\")\" if [ -z \"$entries\" ]; then _info \"No valid entries found.\" if [ -z \"$thumbprint\" ]; then thumbprint=\"$(__calc_account_thumbprint)\" fi _debug \"Trigger validation.\" vtype=\"$(_getIdType \"$_d_domain\")\" entry=\"$(echo \"$response\" | _egrep_o '[^\\{]*\"type\":\"'$vtype'\"[^\\}]*')\" _debug entry \"$entry\" if [ -z \"$entry\" ]; then _err \"$d: Cannot get domain token\" return 1 fi token=\"$(echo \"$entry\" | _egrep_o '\"token\":\"[^\"]*' | cut -d : -f 2 | tr -d '\"')\" _debug token \"$token\" uri=\"$(echo \"$entry\" | _egrep_o \"\\\"$_URL_NAME\\\":\\\"[^\\\"]*\" | cut -d : -f 2,3 | tr -d '\"')\" _debug uri \"$uri\" keyauthorization=\"$token.$thumbprint\" _debug keyauthorization \"$keyauthorization\" __trigger_validation \"$uri\" \"$keyauthorization\" fi _d_i=0 _d_max_retry=$(echo \"$entries\" | wc -l) while [ \"$_d_i\" -lt \"$_d_max_retry\" ]; do _info \"Deactivating $_d_domain\" _d_i=\"$(_math $_d_i + 1)\" entry=\"$(echo \"$entries\" | sed -n \"${_d_i}p\")\" _debug entry \"$entry\" if [ -z \"$entry\" ]; then _info \"No more valid entries found.\" break fi _vtype=\"$(echo \"$entry\" | _egrep_o '\"type\": *\"[^\"]*\"' | cut -d : -f 2 | tr -d '\"')\" _debug _vtype \"$_vtype\" _info \"Found $_vtype\" uri=\"$(echo \"$entry\" | _egrep_o \"\\\"$_URL_NAME\\\":\\\"[^\\\"]*\\\"\" | tr -d '\" ' | cut -d : -f 2-)\" _debug uri \"$uri\" if [ \"$_d_type\" ] && [ \"$_d_type\" != \"$_vtype\" ]; then _info \"Skipping $_vtype\" continue fi _info \"Deactivating $_vtype\" _djson=\"{\\\"status\\\":\\\"deactivated\\\"}\" if _send_signed_request \"$authzUri\" \"$_djson\" && _contains \"$response\" '\"deactivated\"'; then _info \"Successfully deactivated $_vtype.\" else _err \"Could not deactivate $_vtype.\" break fi done _debug \"$_d_i\" if [ \"$_d_i\" -eq \"$_d_max_retry\" ]; then _info \"Successfully deactivated!\" else _err \"Deactivation failed.\" fi } deactivate() { _d_domain_list=\"$1\" _d_type=\"$2\" _initpath _initAPI _debug _d_domain_list \"$_d_domain_list\" if [ -z \"$(echo $_d_domain_list | cut -d , -f 1)\" ]; then _usage \"Usage: $PROJECT_ENTRY --deactivate --domain <domain.tld> [--domain <domain2.tld> ...]\" return 1 fi for _d_dm in $(echo \"$_d_domain_list\" | tr ',' ' '); do if [ -z \"$_d_dm\" ] || [ \"$_d_dm\" = \"$NO_VALUE\" ]; then continue fi if ! _deactivate \"$_d_dm\" \"$_d_type\"; then return 1 fi done } # Detect profile file if not specified as environment variable _detect_profile() { if [ -n \"$PROFILE\" -a -f \"$PROFILE\" ]; then echo \"$PROFILE\" return fi DETECTED_PROFILE='' SHELLTYPE=\"$(basename \"/$SHELL\")\" if [ \"$SHELLTYPE\" = \"bash\" ]; then if [ -f \"$HOME/.bashrc\" ]; then DETECTED_PROFILE=\"$HOME/.bashrc\" elif [ -f \"$HOME/.bash_profile\" ]; then DETECTED_PROFILE=\"$HOME/.bash_profile\" fi elif [ \"$SHELLTYPE\" = \"zsh\" ]; then DETECTED_PROFILE=\"$HOME/.zshrc\" fi if [ -z \"$DETECTED_PROFILE\" ]; then if [ -f \"$HOME/.profile\" ]; then DETECTED_PROFILE=\"$HOME/.profile\" elif [ -f \"$HOME/.bashrc\" ]; then DETECTED_PROFILE=\"$HOME/.bashrc\" elif [ -f \"$HOME/.bash_profile\" ]; then DETECTED_PROFILE=\"$HOME/.bash_profile\" elif [ -f \"$HOME/.zshrc\" ]; then DETECTED_PROFILE=\"$HOME/.zshrc\" fi fi echo \"$DETECTED_PROFILE\" } _initconf() { _initpath if [ ! -f \"$ACCOUNT_CONF_PATH\" ]; then echo \" #LOG_FILE=\\\"$DEFAULT_LOG_FILE\\\" #LOG_LEVEL=1 #AUTO_UPGRADE=\\\"1\\\" #NO_TIMESTAMP=1 \" >\"$ACCOUNT_CONF_PATH\" fi } # nocron _precheck() { _nocron=\"$1\" if ! _exists \"curl\" && ! _exists \"wget\"; then _err \"Please install curl or wget first to enable access to HTTP resources.\" return 1 fi if [ -z \"$_nocron\" ]; then if ! _exists \"crontab\" && ! _exists \"fcrontab\"; then if _exists cygpath && _exists schtasks.exe; then _info \"It seems you are on Windows, we will install the Windows scheduler task.\" else _err \"It is recommended to install crontab first. Try to install 'cron', 'crontab', 'crontabs' or 'vixie-cron'.\" _err \"We need to set a cron job to renew the certs automatically.\" _err \"Otherwise, your certs will not be able to be renewed automatically.\" if [ -z \"$FORCE\" ]; then _err \"Please add '--force' and try install again to go without crontab.\" _err \"./$PROJECT_ENTRY --install --force\" return 1 fi fi fi fi if ! _exists \"${ACME_OPENSSL_BIN:-openssl}\"; then _err \"Please install openssl first. ACME_OPENSSL_BIN=$ACME_OPENSSL_BIN\" _err \"We need openssl to generate keys.\" return 1 fi if ! _exists \"socat\"; then _err \"It is recommended to install socat first.\" _err \"We use socat for the standalone server, which is used for standalone mode.\" _err \"If you don't want to use standalone mode, you may ignore this warning.\" fi return 0 } _setShebang() { _file=\"$1\" _shebang=\"$2\" if [ -z \"$_shebang\" ]; then _usage \"Usage: file shebang\" return 1 fi cp \"$_file\" \"$_file.tmp\" echo \"$_shebang\" >\"$_file\" sed -n 2,99999p \"$_file.tmp\" >>\"$_file\" rm -f \"$_file.tmp\" } #confighome _installalias() { _c_home=\"$1\" _initpath _envfile=\"$LE_WORKING_DIR/$PROJECT_ENTRY.env\" if [ \"$_upgrading\" ] && [ \"$_upgrading\" = \"1\" ]; then echo \"$(cat \"$_envfile\")\" | sed \"s|^LE_WORKING_DIR.*$||\" >\"$_envfile\" echo \"$(cat \"$_envfile\")\" | sed \"s|^alias le.*$||\" >\"$_envfile\" echo \"$(cat \"$_envfile\")\" | sed \"s|^alias le.sh.*$||\" >\"$_envfile\" fi if [ \"$_c_home\" ]; then _c_entry=\" --config-home '$_c_home'\" fi _setopt \"$_envfile\" \"export LE_WORKING_DIR\" \"=\" \"\\\"$LE_WORKING_DIR\\\"\" if [ \"$_c_home\" ]; then _setopt \"$_envfile\" \"export LE_CONFIG_HOME\" \"=\" \"\\\"$LE_CONFIG_HOME\\\"\" else _sed_i \"/^export LE_CONFIG_HOME/d\" \"$_envfile\" fi _setopt \"$_envfile\" \"alias $PROJECT_ENTRY\" \"=\" \"\\\"$LE_WORKING_DIR/$PROJECT_ENTRY$_c_entry\\\"\" _profile=\"$(_detect_profile)\" if [ \"$_profile\" ]; then _debug \"Found profile: $_profile\" _info \"Installing alias to '$_profile'\" _setopt \"$_profile\" \". \\\"$_envfile\\\"\" _info \"Close and reopen your terminal to start using $PROJECT_NAME\" else _info \"No profile has been found, you will need to change your working directory to $LE_WORKING_DIR to use $PROJECT_NAME\" fi #for csh _cshfile=\"$LE_WORKING_DIR/$PROJECT_ENTRY.csh\" _csh_profile=\"$HOME/.cshrc\" if [ -f \"$_csh_profile\" ]; then _info \"Installing alias to '$_csh_profile'\" _setopt \"$_cshfile\" \"setenv LE_WORKING_DIR\" \" \" \"\\\"$LE_WORKING_DIR\\\"\" if [ \"$_c_home\" ]; then _setopt \"$_cshfile\" \"setenv LE_CONFIG_HOME\" \" \" \"\\\"$LE_CONFIG_HOME\\\"\" else _sed_i \"/^setenv LE_CONFIG_HOME/d\" \"$_cshfile\" fi _setopt \"$_cshfile\" \"alias $PROJECT_ENTRY\" \" \" \"\\\"$LE_WORKING_DIR/$PROJECT_ENTRY$_c_entry\\\"\" _setopt \"$_csh_profile\" \"source \\\"$_cshfile\\\"\" fi #for tcsh _tcsh_profile=\"$HOME/.tcshrc\" if [ -f \"$_tcsh_profile\" ]; then _info \"Installing alias to '$_tcsh_profile'\" _setopt \"$_cshfile\" \"setenv LE_WORKING_DIR\" \" \" \"\\\"$LE_WORKING_DIR\\\"\" if [ \"$_c_home\" ]; then _setopt \"$_cshfile\" \"setenv LE_CONFIG_HOME\" \" \" \"\\\"$LE_CONFIG_HOME\\\"\" fi _setopt \"$_cshfile\" \"alias $PROJECT_ENTRY\" \" \" \"\\\"$LE_WORKING_DIR/$PROJECT_ENTRY$_c_entry\\\"\" _setopt \"$_tcsh_profile\" \"source \\\"$_cshfile\\\"\" fi } # nocron confighome noprofile accountemail install() { if [ -z \"$LE_WORKING_DIR\" ]; then LE_WORKING_DIR=\"$DEFAULT_INSTALL_HOME\" fi _nocron=\"$1\" _c_home=\"$2\" _noprofile=\"$3\" _accountemail=\"$4\" if ! _initpath; then _err \"Install failed.\" return 1 fi if [ \"$_nocron\" ]; then _debug \"Skipping cron job installation\" fi if [ \"$_ACME_IN_CRON\" != \"1\" ]; then if ! _precheck \"$_nocron\"; then _err \"Pre-check failed, cannot install.\" return 1 fi fi if [ -z \"$_c_home\" ] && [ \"$LE_CONFIG_HOME\" != \"$LE_WORKING_DIR\" ]; then _info \"Using config home: $LE_CONFIG_HOME\" _c_home=\"$LE_CONFIG_HOME\" fi #convert from le if [ -d \"$HOME/.le\" ]; then for envfile in \"le.env\" \"le.sh.env\"; do if [ -f \"$HOME/.le/$envfile\" ]; then if grep \"le.sh\" \"$HOME/.le/$envfile\" >/dev/null; then _upgrading=\"1\" _info \"You are upgrading from le.sh\" _info \"Renaming \\\"$HOME/.le\\\" to $LE_WORKING_DIR\" mv \"$HOME/.le\" \"$LE_WORKING_DIR\" mv \"$LE_WORKING_DIR/$envfile\" \"$LE_WORKING_DIR/$PROJECT_ENTRY.env\" break fi fi done fi _info \"Installing to $LE_WORKING_DIR\" if [ ! -d \"$LE_WORKING_DIR\" ]; then if ! mkdir -p \"$LE_WORKING_DIR\"; then _err \"Cannot create working dir: $LE_WORKING_DIR\" return 1 fi chmod 700 \"$LE_WORKING_DIR\" fi if [ ! -d \"$LE_CONFIG_HOME\" ]; then if ! mkdir -p \"$LE_CONFIG_HOME\"; then _err \"Cannot create config dir: $LE_CONFIG_HOME\" return 1 fi chmod 700 \"$LE_CONFIG_HOME\" fi cp \"$PROJECT_ENTRY\" \"$LE_WORKING_DIR/\" && chmod +x \"$LE_WORKING_DIR/$PROJECT_ENTRY\" if [ \"$?\" != \"0\" ]; then _err \"Installation failed, cannot copy $PROJECT_ENTRY\" return 1 fi _info \"Installed to $LE_WORKING_DIR/$PROJECT_ENTRY\" if [ \"$_ACME_IN_CRON\" != \"1\" ] && [ -z \"$_noprofile\" ]; then _installalias \"$_c_home\" fi for subf in $_SUB_FOLDERS; do if [ -d \"$subf\" ]; then mkdir -p \"$LE_WORKING_DIR/$subf\" cp \"$subf\"/* \"$LE_WORKING_DIR\"/\"$subf\"/ fi done if [ ! -f \"$ACCOUNT_CONF_PATH\" ]; then _initconf fi if [ \"$_DEFAULT_ACCOUNT_CONF_PATH\" != \"$ACCOUNT_CONF_PATH\" ]; then _setopt \"$_DEFAULT_ACCOUNT_CONF_PATH\" \"ACCOUNT_CONF_PATH\" \"=\" \"\\\"$ACCOUNT_CONF_PATH\\\"\" fi if [ \"$_DEFAULT_CERT_HOME\" != \"$CERT_HOME\" ]; then _saveaccountconf \"CERT_HOME\" \"$CERT_HOME\" fi if [ \"$_DEFAULT_ACCOUNT_KEY_PATH\" != \"$ACCOUNT_KEY_PATH\" ]; then _saveaccountconf \"ACCOUNT_KEY_PATH\" \"$ACCOUNT_KEY_PATH\" fi if [ -z \"$_nocron\" ]; then installcronjob \"$_c_home\" fi if [ -z \"$NO_DETECT_SH\" ]; then #Modify shebang if _exists bash; then _bash_path=\"$(bash -c \"command -v bash 2>/dev/null\")\" if [ -z \"$_bash_path\" ]; then _bash_path=\"$(bash -c 'echo $SHELL')\" fi fi if [ \"$_bash_path\" ]; then _info \"bash has been found. Changing the shebang to use bash as preferred.\" _shebang='#!'\"$_bash_path\" _setShebang \"$LE_WORKING_DIR/$PROJECT_ENTRY\" \"$_shebang\" for subf in $_SUB_FOLDERS; do if [ -d \"$LE_WORKING_DIR/$subf\" ]; then for _apifile in \"$LE_WORKING_DIR/$subf/\"*.sh; do _setShebang \"$_apifile\" \"$_shebang\" done fi done fi fi if [ \"$_accountemail\" ]; then _saveaccountconf \"ACCOUNT_EMAIL\" \"$_accountemail\" fi _saveaccountconf \"UPGRADE_HASH\" \"$(_getUpgradeHash)\" _info OK } # nocron uninstall() { _nocron=\"$1\" if [ -z \"$_nocron\" ]; then uninstallcronjob fi _initpath _uninstallalias rm -f \"$LE_WORKING_DIR/$PROJECT_ENTRY\" _info \"The keys and certs are in \\\"$(__green \"$LE_CONFIG_HOME\")\\\". You can remove them by yourself.\" } _uninstallalias() { _initpath _profile=\"$(_detect_profile)\" if [ \"$_profile\" ]; then _info \"Uninstalling alias from: '$_profile'\" text=\"$(cat \"$_profile\")\" echo \"$text\" | sed \"s|^.*\\\"$LE_WORKING_DIR/$PROJECT_NAME.env\\\"$||\" >\"$_profile\" fi _csh_profile=\"$HOME/.cshrc\" if [ -f \"$_csh_profile\" ]; then _info \"Uninstalling alias from: '$_csh_profile'\" text=\"$(cat \"$_csh_profile\")\" echo \"$text\" | sed \"s|^.*\\\"$LE_WORKING_DIR/$PROJECT_NAME.csh\\\"$||\" >\"$_csh_profile\" fi _tcsh_profile=\"$HOME/.tcshrc\" if [ -f \"$_tcsh_profile\" ]; then _info \"Uninstalling alias from: '$_csh_profile'\" text=\"$(cat \"$_tcsh_profile\")\" echo \"$text\" | sed \"s|^.*\\\"$LE_WORKING_DIR/$PROJECT_NAME.csh\\\"$||\" >\"$_tcsh_profile\" fi } cron() { export _ACME_IN_CRON=1 _initpath _info \"$(__green \"===Starting cron===\")\" if [ \"$AUTO_UPGRADE\" = \"1\" ]; then export LE_WORKING_DIR ( if ! upgrade; then _err \"Cron: Upgrade failed!\" return 1 fi ) . \"$LE_WORKING_DIR/$PROJECT_ENTRY\" >/dev/null if [ -t 1 ]; then __INTERACTIVE=\"1\" fi _info \"Automatically upgraded to: $VER\" fi renewAll _ret=\"$?\" _ACME_IN_CRON=\"\" _info \"$(__green \"===End cron===\")\" exit $_ret } version() { echo \"$PROJECT\" echo \"v$VER\" } # subject content hooks code _send_notify() { _nsubject=\"$1\" _ncontent=\"$2\" _nhooks=\"$3\" _nerror=\"$4\" if [ \"$NOTIFY_LEVEL\" = \"$NOTIFY_LEVEL_DISABLE\" ]; then _debug \"The NOTIFY_LEVEL is $NOTIFY_LEVEL, which means it's disabled, so will just return.\" return 0 fi if [ -z \"$_nhooks\" ]; then _debug \"The NOTIFY_HOOK is empty, will just return.\" return 0 fi _nsource=\"$NOTIFY_SOURCE\" if [ -z \"$_nsource\" ]; then _nsource=\"$(hostname)\" fi _nsubject=\"$_nsubject by $_nsource\" _send_err=0 for _n_hook in $(echo \"$_nhooks\" | tr ',' \" \"); do _n_hook_file=\"$(_findHook \"\" $_SUB_FOLDER_NOTIFY \"$_n_hook\")\" _info \"Sending via: $_n_hook\" _debug \"Found $_n_hook_file for $_n_hook\" if [ -z \"$_n_hook_file\" ]; then _err \"Cannot find the hook file for $_n_hook\" continue fi if ! ( if ! . \"$_n_hook_file\"; then _err \"Error loading file $_n_hook_file. Please check your API file and try again.\" return 1 fi d_command=\"${_n_hook}_send\" if ! _exists \"$d_command\"; then _err \"It seems that your API file is not correct. Make sure it has a function named: $d_command\" return 1 fi if ! $d_command \"$_nsubject\" \"$_ncontent\" \"$_nerror\"; then _err \"Error sending message using $d_command\" return 1 fi return 0 ); then _err \"Error setting $_n_hook_file.\" _send_err=1 else _info \"$_n_hook $(__green Success)\" fi done return $_send_err } # hook _set_notify_hook() { _nhooks=\"$1\" _test_subject=\"Hello, this is a notification from $PROJECT_NAME\" _test_content=\"If you receive this message, your notification works.\" _send_notify \"$_test_subject\" \"$_test_content\" \"$_nhooks\" 0 } #[hook] [level] [mode] setnotify() { _nhook=\"$1\" _nlevel=\"$2\" _nmode=\"$3\" _nsource=\"$4\" _initpath if [ -z \"$_nhook$_nlevel$_nmode$_nsource\" ]; then _usage \"Usage: $PROJECT_ENTRY --set-notify [--notify-hook <hookname>] [--notify-level <0|1|2|3>] [--notify-mode <0|1>] [--notify-source <hostname>]\" _usage \"$_NOTIFY_WIKI\" return 1 fi if [ \"$_nlevel\" ]; then _info \"Set notify level to: $_nlevel\" export \"NOTIFY_LEVEL=$_nlevel\" _saveaccountconf \"NOTIFY_LEVEL\" \"$NOTIFY_LEVEL\" fi if [ \"$_nmode\" ]; then _info \"Set notify mode to: $_nmode\" export \"NOTIFY_MODE=$_nmode\" _saveaccountconf \"NOTIFY_MODE\" \"$NOTIFY_MODE\" fi if [ \"$_nsource\" ]; then _info \"Set notify source to: $_nsource\" export \"NOTIFY_SOURCE=$_nsource\" _saveaccountconf \"NOTIFY_SOURCE\" \"$NOTIFY_SOURCE\" fi if [ \"$_nhook\" ]; then _info \"Set notify hook to: $_nhook\" if [ \"$_nhook\" = \"$NO_VALUE\" ]; then _info \"Clearing notify hook\" _clearaccountconf \"NOTIFY_HOOK\" else if _set_notify_hook \"$_nhook\"; then export NOTIFY_HOOK=\"$_nhook\" _saveaccountconf \"NOTIFY_HOOK\" \"$NOTIFY_HOOK\" return 0 else _err \"Cannot set notify hook to: $_nhook\" return 1 fi fi fi } showhelp() { _initpath version echo \"Usage: $PROJECT_ENTRY <command> ... [parameters ...] Commands: -h, --help Show this help message. -v, --version Show version info. --install Install $PROJECT_NAME to your system. --uninstall Uninstall $PROJECT_NAME, and uninstall the cron job. --upgrade Upgrade $PROJECT_NAME to the latest code from $PROJECT. --issue Issue a cert. --deploy Deploy the cert to your server. -i, --install-cert Install the issued cert to Apache/nginx or any other server. -r, --renew Renew a cert. --renew-all Renew all the certs. --revoke Revoke a cert. --remove Remove the cert from list of certs known to $PROJECT_NAME. --list List all the certs. --info Show the $PROJECT_NAME configs, or the configs for a domain with [-d domain] parameter. --to-pkcs12 Export the certificate and key to a pfx file. --to-pkcs8 Convert to pkcs8 format. --sign-csr Issue a cert from an existing csr. --show-csr Show the content of a csr. -ccr, --create-csr Create CSR, professional use. --create-domain-key Create an domain private key, professional use. --update-account Update account info. --register-account Register account key. --deactivate-account Deactivate the account. --create-account-key Create an account private key, professional use. --install-cronjob Install the cron job to renew certs, you don't need to call this. The 'install' command can automatically install the cron job. --uninstall-cronjob Uninstall the cron job. The 'uninstall' command can do this automatically. --cron Run cron job to renew all the certs. --set-notify Set the cron notification hook, level or mode. --deactivate Deactivate the domain authz, professional use. --set-default-ca Used with '--server', Set the default CA to use. See: $_SERVER_WIKI --set-default-chain Set the default preferred chain for a CA. See: $_PREFERRED_CHAIN_WIKI Parameters: -d, --domain <domain.tld> Specifies a domain, used to issue, renew or revoke etc. --challenge-alias <domain.tld> The challenge domain alias for DNS alias mode. See: $_DNS_ALIAS_WIKI --domain-alias <domain.tld> The domain alias for DNS alias mode. See: $_DNS_ALIAS_WIKI --preferred-chain <chain> If the CA offers multiple certificate chains, prefer the chain with an issuer matching this Subject Common Name. If no match, the default offered chain will be used. (default: empty) See: $_PREFERRED_CHAIN_WIKI --valid-to <date-time> Request the NotAfter field of the cert. See: $_VALIDITY_WIKI --valid-from <date-time> Request the NotBefore field of the cert. See: $_VALIDITY_WIKI -f, --force Force install, force cert renewal or override sudo restrictions. --staging, --test Use staging server, for testing. --debug [0|1|2|3] Output debug info. Defaults to $DEBUG_LEVEL_DEFAULT if argument is omitted. --output-insecure Output all the sensitive messages. By default all the credentials/sensitive messages are hidden from the output/debug/log for security. -w, --webroot <directory> Specifies the web root folder for web root mode. --standalone Use standalone mode. --alpn Use standalone alpn mode. --stateless Use stateless mode. See: $_STATELESS_WIKI --apache Use Apache mode. --dns [dns_hook] Use dns manual mode or dns api. Defaults to manual mode when argument is omitted. See: $_DNS_API_WIKI --dnssleep <seconds> The time in seconds to wait for all the txt records to propagate in dns api mode. It's not necessary to use this by default, $PROJECT_NAME polls dns status by DOH automatically. -k, --keylength <bits> Specifies the domain key length: 2048, 3072, 4096, 8192 or ec-256, ec-384, ec-521. -ak, --accountkeylength <bits> Specifies the account key length: 2048, 3072, 4096 --log [file] Specifies the log file. Defaults to \\\"$DEFAULT_LOG_FILE\\\" if argument is omitted. --log-level <1|2> Specifies the log level, default is $DEFAULT_LOG_LEVEL. --syslog <0|3|6|7> Syslog level, 0: disable syslog, 3: error, 6: info, 7: debug. --eab-kid <eab_key_id> Key Identifier for External Account Binding. --eab-hmac-key <eab_hmac_key> HMAC key for External Account Binding. These parameters are to install the cert to nginx/Apache or any other server after issue/renew a cert: --cert-file <file> Path to copy the cert file to after issue/renew. --key-file <file> Path to copy the key file to after issue/renew. --ca-file <file> Path to copy the intermediate cert file to after issue/renew. --fullchain-file <file> Path to copy the fullchain cert file to after issue/renew. --reloadcmd <command> Command to execute after issue/renew to reload the server. --server <server_uri> ACME Directory Resource URI. (default: $DEFAULT_CA) See: $_SERVER_WIKI --accountconf <file> Specifies a customized account config file. --home <directory> Specifies the home dir for $PROJECT_NAME. --cert-home <directory> Specifies the home dir to save all the certs, only valid for '--install' command. --config-home <directory> Specifies the home dir to save all the configurations. --useragent <string> Specifies the user agent string. it will be saved for future use too. -m, --email <email> Specifies the account email, only valid for the '--install' and '--update-account' command. --accountkey <file> Specifies the account key path, only valid for the '--install' command. --days <ndays> Specifies the days to renew the cert when using '--issue' command. The default value is $DEFAULT_RENEW days. --httpport <port> Specifies the standalone listening port. Only valid if the server is behind a reverse proxy or load balancer. --tlsport <port> Specifies the standalone tls listening port. Only valid if the server is behind a reverse proxy or load balancer. --local-address <ip> Specifies the standalone/tls server listening address, in case you have multiple ip addresses. --listraw Only used for '--list' command, list the certs in raw format. -se, --stop-renew-on-error Only valid for '--renew-all' command. Stop if one cert has error in renewal. --insecure Do not check the server certificate, in some devices, the api server's certificate may not be trusted. --ca-bundle <file> Specifies the path to the CA certificate bundle to verify api server's certificate. --ca-path <directory> Specifies directory containing CA certificates in PEM format, used by wget or curl. --no-cron Only valid for '--install' command, which means: do not install the default cron job. In this case, the certs will not be renewed automatically. --no-profile Only valid for '--install' command, which means: do not install aliases to user profile. --no-color Do not output color text. --force-color Force output of color text. Useful for non-interactive use with the aha tool for HTML E-Mails. --ecc Specifies use of the ECC cert. Only valid for '--install-cert', '--renew', '--remove ', '--revoke', '--deploy', '--to-pkcs8', '--to-pkcs12' and '--create-csr'. --csr <file> Specifies the input csr. --pre-hook <command> Command to be run before obtaining any certificates. --post-hook <command> Command to be run after attempting to obtain/renew certificates. Runs regardless of whether obtain/renew succeeded or failed. --renew-hook <command> Command to be run after each successfully renewed certificate. --deploy-hook <hookname> The hook file to deploy cert --extended-key-usage <string> Manually define the CSR extended key usage value. The default is serverAuth,clientAuth. --ocsp, --ocsp-must-staple Generate OCSP-Must-Staple extension. --always-force-new-domain-key Generate new domain key on renewal. Otherwise, the domain key is not changed by default. --auto-upgrade [0|1] Valid for '--upgrade' command, indicating whether to upgrade automatically in future. Defaults to 1 if argument is omitted. --listen-v4 Force standalone/tls server to listen at ipv4. --listen-v6 Force standalone/tls server to listen at ipv6. --openssl-bin <file> Specifies a custom openssl bin location. --use-wget Force to use wget, if you have both curl and wget installed. --yes-I-know-dns-manual-mode-enough-go-ahead-please Force use of dns manual mode. See: $_DNS_MANUAL_WIKI -b, --branch <branch> Only valid for '--upgrade' command, specifies the branch name to upgrade to. --notify-level <0|1|2|3> Set the notification level: Default value is $NOTIFY_LEVEL_DEFAULT. 0: disabled, no notification will be sent. 1: send notifications only when there is an error. 2: send notifications when a cert is successfully renewed, or there is an error. 3: send notifications when a cert is skipped, renewed, or error. --notify-mode <0|1> Set notification mode. Default value is $NOTIFY_MODE_DEFAULT. 0: Bulk mode. Send all the domain's notifications in one message(mail). 1: Cert mode. Send a message for every single cert. --notify-hook <hookname> Set the notify hook --notify-source <server name> Set the server name in the notification message --revoke-reason <0-10> The reason for revocation, can be used in conjunction with the '--revoke' command. See: $_REVOKE_WIKI --password <password> Add a password to exported pfx file. Use with --to-pkcs12. \" } installOnline() { _info \"Installing from online archive.\" _branch=\"$BRANCH\" if [ -z \"$_branch\" ]; then _branch=\"master\" fi target=\"$PROJECT/archive/$_branch.tar.gz\" _info \"Downloading $target\" localname=\"$_branch.tar.gz\" if ! _get \"$target\" >$localname; then _err \"Download error.\" return 1 fi ( _info \"Extracting $localname\" if ! (tar xzf $localname || gtar xzf $localname); then _err \"Extraction error.\" exit 1 fi cd \"$PROJECT_NAME-$_branch\" chmod +x $PROJECT_ENTRY if ./$PROJECT_ENTRY --install \"$@\"; then _info \"Install success!\" fi cd .. rm -rf \"$PROJECT_NAME-$_branch\" rm -f \"$localname\" ) } _getRepoHash() { _hash_path=$1 shift _hash_url=\"${PROJECT_API:-https://api.github.com/repos/acmesh-official}/$PROJECT_NAME/git/refs/$_hash_path\" _get \"$_hash_url\" \"\" 30 | tr -d \"\\r\\n\" | tr '{},' '\\n\\n\\n' | grep '\"sha\":' | cut -d '\"' -f 4 } _getUpgradeHash() { _b=\"$BRANCH\" if [ -z \"$_b\" ]; then _b=\"master\" fi _hash=$(_getRepoHash \"heads/$_b\") if [ -z \"$_hash\" ]; then _hash=$(_getRepoHash \"tags/$_b\"); fi echo $_hash } upgrade() { if ( _initpath [ -z \"$FORCE\" ] && [ \"$(_getUpgradeHash)\" = \"$(_readaccountconf \"UPGRADE_HASH\")\" ] && _info \"Already up to date!\" && exit 0 export LE_WORKING_DIR cd \"$LE_WORKING_DIR\" installOnline \"--nocron\" \"--noprofile\" ); then _info \"Upgrade successful!\" exit 0 else _err \"Upgrade failed!\" exit 1 fi } _processAccountConf() { if [ \"$_useragent\" ]; then _saveaccountconf \"USER_AGENT\" \"$_useragent\" elif [ \"$USER_AGENT\" ] && [ \"$USER_AGENT\" != \"$DEFAULT_USER_AGENT\" ]; then _saveaccountconf \"USER_AGENT\" \"$USER_AGENT\" fi if [ \"$_openssl_bin\" ]; then _saveaccountconf \"ACME_OPENSSL_BIN\" \"$_openssl_bin\" elif [ \"$ACME_OPENSSL_BIN\" ] && [ \"$ACME_OPENSSL_BIN\" != \"$DEFAULT_OPENSSL_BIN\" ]; then _saveaccountconf \"ACME_OPENSSL_BIN\" \"$ACME_OPENSSL_BIN\" fi if [ \"$_auto_upgrade\" ]; then _saveaccountconf \"AUTO_UPGRADE\" \"$_auto_upgrade\" elif [ \"$AUTO_UPGRADE\" ]; then _saveaccountconf \"AUTO_UPGRADE\" \"$AUTO_UPGRADE\" fi if [ \"$_use_wget\" ]; then _saveaccountconf \"ACME_USE_WGET\" \"$_use_wget\" elif [ \"$ACME_USE_WGET\" ]; then _saveaccountconf \"ACME_USE_WGET\" \"$ACME_USE_WGET\" fi } _checkSudo() { if [ -z \"$__INTERACTIVE\" ]; then #don't check if it's not in an interactive shell return 0 fi if [ \"$SUDO_GID\" ] && [ \"$SUDO_COMMAND\" ] && [ \"$SUDO_USER\" ] && [ \"$SUDO_UID\" ]; then if [ \"$SUDO_USER\" = \"root\" ] && [ \"$SUDO_UID\" = \"0\" ]; then #it's root using sudo, no matter it's using sudo or not, just fine return 0 fi if [ -n \"$SUDO_COMMAND\" ]; then #it's a normal user doing \"sudo su\", or `sudo -i` or `sudo -s`, or `sudo su acmeuser1` _endswith \"$SUDO_COMMAND\" /bin/su || _contains \"$SUDO_COMMAND\" \"/bin/su \" || grep \"^$SUDO_COMMAND\\$\" /etc/shells >/dev/null 2>&1 return $? fi #otherwise return 1 fi return 0 } #server #keylength _selectServer() { _server=\"$1\" _skeylength=\"$2\" _server_lower=\"$(echo \"$_server\" | _lower_case)\" _sindex=0 for snames in $CA_NAMES; do snames=\"$(echo \"$snames\" | _lower_case)\" _sindex=\"$(_math $_sindex + 1)\" _debug2 \"_selectServer try snames\" \"$snames\" for sname in $(echo \"$snames\" | tr ',' ' '); do if [ \"$_server_lower\" = \"$sname\" ]; then _debug2 \"_selectServer match $sname\" _serverdir=\"$(_getfield \"$CA_SERVERS\" $_sindex)\" if [ \"$_serverdir\" = \"$CA_SSLCOM_RSA\" ] && _isEccKey \"$_skeylength\"; then _serverdir=\"$CA_SSLCOM_ECC\" fi _debug \"Selected server: $_serverdir\" ACME_DIRECTORY=\"$_serverdir\" export ACME_DIRECTORY return fi done done ACME_DIRECTORY=\"$_server\" export ACME_DIRECTORY } #url _getCAShortName() { caurl=\"$1\" if [ -z \"$caurl\" ]; then #use letsencrypt as default value if the Le_API is empty #this case can only come from the old upgrading. caurl=\"$CA_LETSENCRYPT_V2\" fi if [ \"$CA_SSLCOM_ECC\" = \"$caurl\" ]; then caurl=\"$CA_SSLCOM_RSA\" #just hack to get the short name fi caurl_lower=\"$(echo $caurl | _lower_case)\" _sindex=0 for surl in $(echo \"$CA_SERVERS\" | _lower_case | tr , ' '); do _sindex=\"$(_math $_sindex + 1)\" if [ \"$caurl_lower\" = \"$surl\" ]; then _nindex=0 for snames in $CA_NAMES; do _nindex=\"$(_math $_nindex + 1)\" if [ $_nindex -ge $_sindex ]; then _getfield \"$snames\" 1 return fi done fi done echo \"$caurl\" } #set default ca to $ACME_DIRECTORY setdefaultca() { if [ -z \"$ACME_DIRECTORY\" ]; then _err \"Please provide a --server parameter.\" return 1 fi _saveaccountconf \"DEFAULT_ACME_SERVER\" \"$ACME_DIRECTORY\" _info \"Changed default CA to: $(__green \"$ACME_DIRECTORY\")\" } #preferred-chain setdefaultchain() { _initpath _preferred_chain=\"$1\" if [ -z \"$_preferred_chain\" ]; then _err \"Please provide a value for '--preferred-chain'.\" return 1 fi mkdir -p \"$CA_DIR\" _savecaconf \"DEFAULT_PREFERRED_CHAIN\" \"$_preferred_chain\" } #domain ecc info() { _domain=\"$1\" _ecc=\"$2\" _initpath if [ -z \"$_domain\" ]; then _debug \"Show global configs\" echo \"LE_WORKING_DIR=$LE_WORKING_DIR\" echo \"LE_CONFIG_HOME=$LE_CONFIG_HOME\" cat \"$ACCOUNT_CONF_PATH\" else _debug \"Show domain configs\" ( _initpath \"$_domain\" \"$_ecc\" echo \"DOMAIN_CONF=$DOMAIN_CONF\" for seg in $(cat $DOMAIN_CONF | cut -d = -f 1); do echo \"$seg=$(_readdomainconf \"$seg\")\" done ) fi } _process() { _CMD=\"\" _domain=\"\" _altdomains=\"$NO_VALUE\" _webroot=\"\" _challenge_alias=\"\" _keylength=\"$DEFAULT_DOMAIN_KEY_LENGTH\" _accountkeylength=\"$DEFAULT_ACCOUNT_KEY_LENGTH\" _cert_file=\"\" _key_file=\"\" _ca_file=\"\" _fullchain_file=\"\" _reloadcmd=\"\" _password=\"\" _accountconf=\"\" _useragent=\"\" _accountemail=\"\" _accountkey=\"\" _certhome=\"\" _confighome=\"\" _httpport=\"\" _tlsport=\"\" _dnssleep=\"\" _listraw=\"\" _stopRenewOnError=\"\" #_insecure=\"\" _ca_bundle=\"\" _ca_path=\"\" _nocron=\"\" _noprofile=\"\" _ecc=\"\" _csr=\"\" _pre_hook=\"\" _post_hook=\"\" _renew_hook=\"\" _deploy_hook=\"\" _logfile=\"\" _log=\"\" _local_address=\"\" _log_level=\"\" _auto_upgrade=\"\" _listen_v4=\"\" _listen_v6=\"\" _openssl_bin=\"\" _syslog=\"\" _use_wget=\"\" _server=\"\" _notify_hook=\"\" _notify_level=\"\" _notify_mode=\"\" _notify_source=\"\" _revoke_reason=\"\" _eab_kid=\"\" _eab_hmac_key=\"\" _preferred_chain=\"\" _valid_from=\"\" _valid_to=\"\" while [ ${#} -gt 0 ]; do case \"${1}\" in --help | -h) showhelp return ;; --version | -v) version return ;; --install) _CMD=\"install\" ;; --install-online) shift installOnline \"$@\" return ;; --uninstall) _CMD=\"uninstall\" ;; --upgrade) _CMD=\"upgrade\" ;; --issue) _CMD=\"issue\" ;; --deploy) _CMD=\"deploy\" ;; --sign-csr | --signcsr) _CMD=\"signcsr\" ;; --show-csr | --showcsr) _CMD=\"showcsr\" ;; -i | --install-cert | --installcert) _CMD=\"installcert\" ;; --renew | -r) _CMD=\"renew\" ;; --renew-all | --renewAll | --renewall) _CMD=\"renewAll\" ;; --revoke) _CMD=\"revoke\" ;; --remove) _CMD=\"remove\" ;; --list) _CMD=\"list\" ;; --info) _CMD=\"info\" ;; --install-cronjob | --installcronjob) _CMD=\"installcronjob\" ;; --uninstall-cronjob | --uninstallcronjob) _CMD=\"uninstallcronjob\" ;; --cron) _CMD=\"cron\" ;; --to-pkcs12 | --to-pkcs | --toPkcs) _CMD=\"toPkcs\" ;; --to-pkcs8 | --toPkcs8) _CMD=\"toPkcs8\" ;; --create-account-key | --createAccountKey | --createaccountkey | -cak) _CMD=\"createAccountKey\" ;; --create-domain-key | --createDomainKey | --createdomainkey | -cdk) _CMD=\"createDomainKey\" ;; -ccr | --create-csr | --createCSR | --createcsr) _CMD=\"createCSR\" ;; --deactivate) _CMD=\"deactivate\" ;; --update-account | --updateaccount) _CMD=\"updateaccount\" ;; --register-account | --registeraccount) _CMD=\"registeraccount\" ;; --deactivate-account) _CMD=\"deactivateaccount\" ;; --set-notify) _CMD=\"setnotify\" ;; --set-default-ca) _CMD=\"setdefaultca\" ;; --set-default-chain) _CMD=\"setdefaultchain\" ;; -d | --domain) _dvalue=\"$2\" if [ \"$_dvalue\" ]; then if _startswith \"$_dvalue\" \"-\"; then _err \"'$_dvalue' is not a valid domain for parameter '$1'\" return 1 fi if _is_idn \"$_dvalue\" && ! _exists idn; then _err \"It seems that $_dvalue is an IDN (Internationalized Domain Names), please install the 'idn' command first.\" return 1 fi if [ -z \"$_domain\" ]; then _domain=\"$_dvalue\" else if [ \"$_altdomains\" = \"$NO_VALUE\" ]; then _altdomains=\"$_dvalue\" else _altdomains=\"$_altdomains,$_dvalue\" fi fi fi shift ;; -f | --force) FORCE=\"1\" ;; --staging | --test) STAGE=\"1\" ;; --server) _server=\"$2\" shift ;; --debug) if [ -z \"$2\" ] || _startswith \"$2\" \"-\"; then DEBUG=\"$DEBUG_LEVEL_DEFAULT\" else DEBUG=\"$2\" shift fi ;; --output-insecure) export OUTPUT_INSECURE=1 ;; -w | --webroot) wvalue=\"$2\" if [ -z \"$_webroot\" ]; then _webroot=\"$wvalue\" else _webroot=\"$_webroot,$wvalue\" fi shift ;; --challenge-alias) cvalue=\"$2\" _challenge_alias=\"$_challenge_alias$cvalue,\" shift ;; --domain-alias) cvalue=\"$DNS_ALIAS_PREFIX$2\" _challenge_alias=\"$_challenge_alias$cvalue,\" shift ;; --standalone) wvalue=\"$NO_VALUE\" if [ -z \"$_webroot\" ]; then _webroot=\"$wvalue\" else _webroot=\"$_webroot,$wvalue\" fi ;; --alpn) wvalue=\"$W_ALPN\" if [ -z \"$_webroot\" ]; then _webroot=\"$wvalue\" else _webroot=\"$_webroot,$wvalue\" fi ;; --stateless) wvalue=\"$MODE_STATELESS\" if [ -z \"$_webroot\" ]; then _webroot=\"$wvalue\" else _webroot=\"$_webroot,$wvalue\" fi ;; --local-address) lvalue=\"$2\" _local_address=\"$_local_address$lvalue,\" shift ;; --apache) wvalue=\"apache\" if [ -z \"$_webroot\" ]; then _webroot=\"$wvalue\" else _webroot=\"$_webroot,$wvalue\" fi ;; --nginx) wvalue=\"$NGINX\" if [ \"$2\" ] && ! _startswith \"$2\" \"-\"; then wvalue=\"$NGINX$2\" shift fi if [ -z \"$_webroot\" ]; then _webroot=\"$wvalue\" else _webroot=\"$_webroot,$wvalue\" fi ;; --dns) wvalue=\"$W_DNS\" if [ \"$2\" ] && ! _startswith \"$2\" \"-\"; then wvalue=\"$2\" shift fi if [ -z \"$_webroot\" ]; then _webroot=\"$wvalue\" else _webroot=\"$_webroot,$wvalue\" fi ;; --dnssleep) _dnssleep=\"$2\" Le_DNSSleep=\"$_dnssleep\" shift ;; --keylength | -k) _keylength=\"$2\" shift if [ \"$_keylength\" ] && ! _isEccKey \"$_keylength\"; then export __SELECTED_RSA_KEY=1 fi ;; -ak | --accountkeylength) _accountkeylength=\"$2\" shift ;; --cert-file | --certpath) _cert_file=\"$2\" shift ;; --key-file | --keypath) _key_file=\"$2\" shift ;; --ca-file | --capath) _ca_file=\"$2\" shift ;; --fullchain-file | --fullchainpath) _fullchain_file=\"$2\" shift ;; --reloadcmd | --reloadCmd) _reloadcmd=\"$2\" shift ;; --password) _password=\"$2\" shift ;; --accountconf) _accountconf=\"$2\" ACCOUNT_CONF_PATH=\"$_accountconf\" shift ;; --home) export LE_WORKING_DIR=\"$(echo \"$2\" | sed 's|/$||')\" shift ;; --cert-home | --certhome) _certhome=\"$2\" export CERT_HOME=\"$_certhome\" shift ;; --config-home) _confighome=\"$2\" export LE_CONFIG_HOME=\"$_confighome\" shift ;; --useragent) _useragent=\"$2\" USER_AGENT=\"$_useragent\" shift ;; -m | --email | --accountemail) _accountemail=\"$2\" export ACCOUNT_EMAIL=\"$_accountemail\" shift ;; --accountkey) _accountkey=\"$2\" ACCOUNT_KEY_PATH=\"$_accountkey\" shift ;; --days) _days=\"$2\" Le_RenewalDays=\"$_days\" shift ;; --valid-from) _valid_from=\"$2\" shift ;; --valid-to) _valid_to=\"$2\" shift ;; --httpport) _httpport=\"$2\" Le_HTTPPort=\"$_httpport\" shift ;; --tlsport) _tlsport=\"$2\" Le_TLSPort=\"$_tlsport\" shift ;; --listraw) _listraw=\"raw\" ;; -se | --stop-renew-on-error | --stopRenewOnError | --stoprenewonerror) _stopRenewOnError=\"1\" ;; --insecure) #_insecure=\"1\" HTTPS_INSECURE=\"1\" ;; --ca-bundle) _ca_bundle=\"$(_readlink \"$2\")\" CA_BUNDLE=\"$_ca_bundle\" shift ;; --ca-path) _ca_path=\"$2\" CA_PATH=\"$_ca_path\" shift ;; --no-cron | --nocron) _nocron=\"1\" ;; --no-profile | --noprofile) _noprofile=\"1\" ;; --no-color) export ACME_NO_COLOR=1 ;; --force-color) export ACME_FORCE_COLOR=1 ;; --ecc) _ecc=\"isEcc\" ;; --csr) _csr=\"$2\" shift ;; --pre-hook) _pre_hook=\"$2\" shift ;; --post-hook) _post_hook=\"$2\" shift ;; --renew-hook) _renew_hook=\"$2\" shift ;; --deploy-hook) if [ -z \"$2\" ] || _startswith \"$2\" \"-\"; then _usage \"Please specify a value for '--deploy-hook'\" return 1 fi _deploy_hook=\"$_deploy_hook$2,\" shift ;; --extended-key-usage) Le_ExtKeyUse=\"$2\" shift ;; --ocsp-must-staple | --ocsp) Le_OCSP_Staple=\"1\" ;; --always-force-new-domain-key) if [ -z \"$2\" ] || _startswith \"$2\" \"-\"; then Le_ForceNewDomainKey=1 else Le_ForceNewDomainKey=\"$2\" shift fi ;; --yes-I-know-dns-manual-mode-enough-go-ahead-please) export FORCE_DNS_MANUAL=1 ;; --log | --logfile) _log=\"1\" _logfile=\"$2\" if _startswith \"$_logfile\" '-'; then _logfile=\"\" else shift fi LOG_FILE=\"$_logfile\" if [ -z \"$LOG_LEVEL\" ]; then LOG_LEVEL=\"$DEFAULT_LOG_LEVEL\" fi ;; --log-level) _log_level=\"$2\" LOG_LEVEL=\"$_log_level\" shift ;; --syslog) if ! _startswith \"$2\" '-'; then _syslog=\"$2\" shift fi if [ -z \"$_syslog\" ]; then _syslog=\"$SYSLOG_LEVEL_DEFAULT\" fi ;; --auto-upgrade) _auto_upgrade=\"$2\" if [ -z \"$_auto_upgrade\" ] || _startswith \"$_auto_upgrade\" '-'; then _auto_upgrade=\"1\" else shift fi AUTO_UPGRADE=\"$_auto_upgrade\" ;; --listen-v4) _listen_v4=\"1\" Le_Listen_V4=\"$_listen_v4\" ;; --listen-v6) _listen_v6=\"1\" Le_Listen_V6=\"$_listen_v6\" ;; --openssl-bin) _openssl_bin=\"$2\" ACME_OPENSSL_BIN=\"$_openssl_bin\" shift ;; --use-wget) _use_wget=\"1\" ACME_USE_WGET=\"1\" ;; --branch | -b) export BRANCH=\"$2\" shift ;; --notify-hook) _nhook=\"$2\" if _startswith \"$_nhook\" \"-\"; then _err \"'$_nhook' is not a hook name for '$1'\" return 1 fi if [ \"$_notify_hook\" ]; then _notify_hook=\"$_notify_hook,$_nhook\" else _notify_hook=\"$_nhook\" fi shift ;; --notify-level) _nlevel=\"$2\" if _startswith \"$_nlevel\" \"-\"; then _err \"'$_nlevel' is not an integer for '$1'\" return 1 fi _notify_level=\"$_nlevel\" shift ;; --notify-mode) _nmode=\"$2\" if _startswith \"$_nmode\" \"-\"; then _err \"'$_nmode' is not an integer for '$1'\" return 1 fi _notify_mode=\"$_nmode\" shift ;; --notify-source) _nsource=\"$2\" if _startswith \"$_nsource\" \"-\"; then _err \"'$_nsource' is not a valid host name for '$1'\" return 1 fi _notify_source=\"$_nsource\" shift ;; --revoke-reason) _revoke_reason=\"$2\" if _startswith \"$_revoke_reason\" \"-\"; then _err \"'$_revoke_reason' is not an integer for '$1'\" return 1 fi shift ;; --eab-kid) _eab_kid=\"$2\" shift ;; --eab-hmac-key) _eab_hmac_key=\"$2\" shift ;; --preferred-chain) _preferred_chain=\"$2\" shift ;; *) _err \"Unknown parameter: $1\" return 1 ;; esac shift 1 done if [ \"$_server\" ]; then _selectServer \"$_server\" \"${_ecc:-$_keylength}\" _server=\"$ACME_DIRECTORY\" fi if [ \"${_CMD}\" != \"install\" ]; then if [ \"$__INTERACTIVE\" ] && ! _checkSudo; then if [ -z \"$FORCE\" ]; then #Use \"echo\" here, instead of _info. it's too early echo \"It seems that you are using sudo, please read this page first:\" echo \"$_SUDO_WIKI\" return 1 fi fi __initHome if [ \"$_log\" ]; then if [ -z \"$_logfile\" ]; then _logfile=\"$DEFAULT_LOG_FILE\" fi fi if [ \"$_logfile\" ]; then _saveaccountconf \"LOG_FILE\" \"$_logfile\" LOG_FILE=\"$_logfile\" fi if [ \"$_log_level\" ]; then _saveaccountconf \"LOG_LEVEL\" \"$_log_level\" LOG_LEVEL=\"$_log_level\" fi if [ \"$_syslog\" ]; then if _exists logger; then if [ \"$_syslog\" = \"0\" ]; then _clearaccountconf \"SYS_LOG\" else _saveaccountconf \"SYS_LOG\" \"$_syslog\" fi SYS_LOG=\"$_syslog\" else _err \"The 'logger' command was not found, cannot enable syslog.\" _clearaccountconf \"SYS_LOG\" SYS_LOG=\"\" fi fi _processAccountConf fi _debug2 LE_WORKING_DIR \"$LE_WORKING_DIR\" if [ \"$DEBUG\" ]; then version if [ \"$_server\" ]; then _debug \"Using server: $_server\" fi fi _debug \"Running cmd: ${_CMD}\" case \"${_CMD}\" in install) install \"$_nocron\" \"$_confighome\" \"$_noprofile\" \"$_accountemail\" ;; uninstall) uninstall \"$_nocron\" ;; upgrade) upgrade ;; issue) issue \"$_webroot\" \"$_domain\" \"$_altdomains\" \"$_keylength\" \"$_cert_file\" \"$_key_file\" \"$_ca_file\" \"$_reloadcmd\" \"$_fullchain_file\" \"$_pre_hook\" \"$_post_hook\" \"$_renew_hook\" \"$_local_address\" \"$_challenge_alias\" \"$_preferred_chain\" \"$_valid_from\" \"$_valid_to\" ;; deploy) deploy \"$_domain\" \"$_deploy_hook\" \"$_ecc\" ;; signcsr) signcsr \"$_csr\" \"$_webroot\" \"$_cert_file\" \"$_key_file\" \"$_ca_file\" \"$_reloadcmd\" \"$_fullchain_file\" \"$_pre_hook\" \"$_post_hook\" \"$_renew_hook\" \"$_local_address\" \"$_challenge_alias\" \"$_preferred_chain\" ;; showcsr) showcsr \"$_csr\" \"$_domain\" ;; installcert) installcert \"$_domain\" \"$_cert_file\" \"$_key_file\" \"$_ca_file\" \"$_reloadcmd\" \"$_fullchain_file\" \"$_ecc\" ;; renew) renew \"$_domain\" \"$_ecc\" \"$_server\" ;; renewAll) renewAll \"$_stopRenewOnError\" \"$_server\" ;; revoke) revoke \"$_domain\" \"$_ecc\" \"$_revoke_reason\" ;; remove) remove \"$_domain\" \"$_ecc\" ;; deactivate) deactivate \"$_domain,$_altdomains\" ;; registeraccount) registeraccount \"$_accountkeylength\" \"$_eab_kid\" \"$_eab_hmac_key\" ;; updateaccount) updateaccount ;; deactivateaccount) deactivateaccount ;; list) list \"$_listraw\" \"$_domain\" ;; info) info \"$_domain\" \"$_ecc\" ;; installcronjob) installcronjob \"$_confighome\" ;; uninstallcronjob) uninstallcronjob ;; cron) cron ;; toPkcs) toPkcs \"$_domain\" \"$_password\" \"$_ecc\" ;; toPkcs8) toPkcs8 \"$_domain\" \"$_ecc\" ;; createAccountKey) createAccountKey \"$_accountkeylength\" ;; createDomainKey) createDomainKey \"$_domain\" \"$_keylength\" ;; createCSR) createCSR \"$_domain\" \"$_altdomains\" \"$_ecc\" ;; setnotify) setnotify \"$_notify_hook\" \"$_notify_level\" \"$_notify_mode\" \"$_notify_source\" ;; setdefaultca) setdefaultca ;; setdefaultchain) setdefaultchain \"$_preferred_chain\" ;; *) if [ \"$_CMD\" ]; then _err \"Invalid command: $_CMD\" fi showhelp return 1 ;; esac _ret=\"$?\" if [ \"$_ret\" != \"0\" ]; then return $_ret fi if [ \"${_CMD}\" = \"install\" ]; then if [ \"$_log\" ]; then if [ -z \"$LOG_FILE\" ]; then LOG_FILE=\"$DEFAULT_LOG_FILE\" fi _saveaccountconf \"LOG_FILE\" \"$LOG_FILE\" fi if [ \"$_log_level\" ]; then _saveaccountconf \"LOG_LEVEL\" \"$_log_level\" fi if [ \"$_syslog\" ]; then if _exists logger; then if [ \"$_syslog\" = \"0\" ]; then _clearaccountconf \"SYS_LOG\" else _saveaccountconf \"SYS_LOG\" \"$_syslog\" fi else _err \"The 'logger' command was not found, cannot enable syslog.\" _clearaccountconf \"SYS_LOG\" SYS_LOG=\"\" fi fi _processAccountConf fi } main() { [ -z \"$1\" ] && showhelp && return if _startswith \"$1\" '-'; then _process \"$@\"; else \"$@\"; fi } main \"$@\""
        },
        {
            "filename": "file_115.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_115.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034,SC2154 # Script to create certificate to Alibaba Cloud CDN # # Docs: https://github.com/acmesh-official/acme.sh/wiki/deployhooks#33-deploy-your-certificate-to-cdn-or-dcdn-of-alibaba-cloud-aliyun # # This deployment required following variables # export Ali_Key=\"ALIACCESSKEY\" # export Ali_Secret=\"ALISECRETKEY\" # The credentials are shared with all the Alibaba Cloud deploy hooks and dnsapi # # To specify the CDN domain that is different from the certificate CN, usually used for multi-domain or wildcard certificates # export DEPLOY_ALI_CDN_DOMAIN=\"cdn.example.com\" # If you have multiple CDN domains using the same certificate, just # export DEPLOY_ALI_CDN_DOMAIN=\"cdn1.example.com cdn2.example.com\" # # For DCDN, see ali_dcdn deploy hook Ali_CDN_API=\"https://cdn.aliyuncs.com/\" ali_cdn_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" # Load dnsapi/dns_ali.sh to reduce the duplicated codes # https://github.com/acmesh-official/acme.sh/pull/5205#issuecomment-2357867276 dnsapi_ali=\"$(_findHook \"$_cdomain\" \"$_SUB_FOLDER_DNSAPI\" dns_ali)\" # shellcheck source=/dev/null if ! . \"$dnsapi_ali\"; then _err \"Error loading file $dnsapi_ali. Please check your API file and try again.\" return 1 fi _prepare_ali_credentials || return 1 _getdeployconf DEPLOY_ALI_CDN_DOMAIN if [ \"$DEPLOY_ALI_CDN_DOMAIN\" ]; then _savedeployconf DEPLOY_ALI_CDN_DOMAIN \"$DEPLOY_ALI_CDN_DOMAIN\" else DEPLOY_ALI_CDN_DOMAIN=\"$_cdomain\" fi # read cert and key files and urlencode both _cert=$(_url_encode upper-hex <\"$_cfullchain\") _key=$(_url_encode upper-hex <\"$_ckey\") _debug2 _cert \"$_cert\" _debug2 _key \"$_key\" ## update domain ssl config for domain in $DEPLOY_ALI_CDN_DOMAIN; do _set_cdn_domain_ssl_certificate_query \"$domain\" \"$_cert\" \"$_key\" if _ali_rest \"Set CDN domain SSL certificate for $domain\" \"\" POST; then _info \"Domain $domain certificate has been deployed successfully\" fi done return 0 } # domain pub pri _set_cdn_domain_ssl_certificate_query() { endpoint=$Ali_CDN_API query='' query=$query'AccessKeyId='$Ali_Key query=$query'&Action=SetCdnDomainSSLCertificate' query=$query'&CertType=upload' query=$query'&DomainName='$1 query=$query'&Format=json' query=$query'&SSLPri='$3 query=$query'&SSLProtocol=on' query=$query'&SSLPub='$2 query=$query'&SignatureMethod=HMAC-SHA1' query=$query\"&SignatureNonce=$(_ali_nonce)\" query=$query'&SignatureVersion=1.0' query=$query'&Timestamp='$(_timestamp) query=$query'&Version=2018-05-10' }"
        },
        {
            "filename": "file_116.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_116.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034,SC2154 # Script to create certificate to Alibaba Cloud DCDN # # Docs: https://github.com/acmesh-official/acme.sh/wiki/deployhooks#33-deploy-your-certificate-to-cdn-or-dcdn-of-alibaba-cloud-aliyun # # This deployment required following variables # export Ali_Key=\"ALIACCESSKEY\" # export Ali_Secret=\"ALISECRETKEY\" # The credentials are shared with all the Alibaba Cloud deploy hooks and dnsapi # # To specify the DCDN domain that is different from the certificate CN, usually used for multi-domain or wildcard certificates # export DEPLOY_ALI_DCDN_DOMAIN=\"dcdn.example.com\" # If you have multiple CDN domains using the same certificate, just # export DEPLOY_ALI_DCDN_DOMAIN=\"dcdn1.example.com dcdn2.example.com\" # # For regular CDN, see ali_cdn deploy hook Ali_DCDN_API=\"https://dcdn.aliyuncs.com/\" ali_dcdn_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" # Load dnsapi/dns_ali.sh to reduce the duplicated codes # https://github.com/acmesh-official/acme.sh/pull/5205#issuecomment-2357867276 dnsapi_ali=\"$(_findHook \"$_cdomain\" \"$_SUB_FOLDER_DNSAPI\" dns_ali)\" # shellcheck source=/dev/null if ! . \"$dnsapi_ali\"; then _err \"Error loading file $dnsapi_ali. Please check your API file and try again.\" return 1 fi _prepare_ali_credentials || return 1 _getdeployconf DEPLOY_ALI_DCDN_DOMAIN if [ \"$DEPLOY_ALI_DCDN_DOMAIN\" ]; then _savedeployconf DEPLOY_ALI_DCDN_DOMAIN \"$DEPLOY_ALI_DCDN_DOMAIN\" else DEPLOY_ALI_DCDN_DOMAIN=\"$_cdomain\" fi # read cert and key files and urlencode both _cert=$(_url_encode upper-hex <\"$_cfullchain\") _key=$(_url_encode upper-hex <\"$_ckey\") _debug2 _cert \"$_cert\" _debug2 _key \"$_key\" ## update domain ssl config for domain in $DEPLOY_ALI_DCDN_DOMAIN; do _set_dcdn_domain_ssl_certificate_query \"$domain\" \"$_cert\" \"$_key\" if _ali_rest \"Set DCDN domain SSL certificate for $domain\" \"\" POST; then _info \"Domain $domain certificate has been deployed successfully\" fi done return 0 } # domain pub pri _set_dcdn_domain_ssl_certificate_query() { endpoint=$Ali_DCDN_API query='' query=$query'AccessKeyId='$Ali_Key query=$query'&Action=SetDcdnDomainSSLCertificate' query=$query'&CertType=upload' query=$query'&DomainName='$1 query=$query'&Format=json' query=$query'&SSLPri='$3 query=$query'&SSLProtocol=on' query=$query'&SSLPub='$2 query=$query'&SignatureMethod=HMAC-SHA1' query=$query\"&SignatureNonce=$(_ali_nonce)\" query=$query'&SignatureVersion=1.0' query=$query'&Timestamp='$(_timestamp) query=$query'&Version=2018-01-15' }"
        },
        {
            "filename": "file_117.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_117.sh",
            "content": "#!/usr/bin/env sh #Here is a script to deploy cert to apache server. #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain apache_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _err \"Deploy cert to apache server, Not implemented yet\" return 1 }"
        },
        {
            "filename": "file_118.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_118.sh",
            "content": "#!/usr/bin/env sh # Here is the script to deploy the cert to your CleverReach Account using the CleverReach REST API. # Your OAuth needs the right scope, please contact CleverReach support for that. # # Written by Jan-Philipp Benecke <github@bnck.me> # Public domain, 2020 # # Following environment variables must be set: # #export DEPLOY_CLEVERREACH_CLIENT_ID=myid #export DEPLOY_CLEVERREACH_CLIENT_SECRET=mysecret cleverreach_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _rest_endpoint=\"https://rest.cleverreach.com\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _getdeployconf DEPLOY_CLEVERREACH_CLIENT_ID _getdeployconf DEPLOY_CLEVERREACH_CLIENT_SECRET _getdeployconf DEPLOY_CLEVERREACH_SUBCLIENT_ID if [ -z \"${DEPLOY_CLEVERREACH_CLIENT_ID}\" ]; then _err \"CleverReach Client ID is not found, please define DEPLOY_CLEVERREACH_CLIENT_ID.\" return 1 fi if [ -z \"${DEPLOY_CLEVERREACH_CLIENT_SECRET}\" ]; then _err \"CleverReach client secret is not found, please define DEPLOY_CLEVERREACH_CLIENT_SECRET.\" return 1 fi _savedeployconf DEPLOY_CLEVERREACH_CLIENT_ID \"${DEPLOY_CLEVERREACH_CLIENT_ID}\" _savedeployconf DEPLOY_CLEVERREACH_CLIENT_SECRET \"${DEPLOY_CLEVERREACH_CLIENT_SECRET}\" _savedeployconf DEPLOY_CLEVERREACH_SUBCLIENT_ID \"${DEPLOY_CLEVERREACH_SUBCLIENT_ID}\" _info \"Obtaining a CleverReach access token\" _data=\"{\\\"grant_type\\\": \\\"client_credentials\\\", \\\"client_id\\\": \\\"${DEPLOY_CLEVERREACH_CLIENT_ID}\\\", \\\"client_secret\\\": \\\"${DEPLOY_CLEVERREACH_CLIENT_SECRET}\\\"}\" _auth_result=\"$(_post \"$_data\" \"$_rest_endpoint/oauth/token.php\" \"\" \"POST\" \"application/json\")\" _debug _data \"$_data\" _debug _auth_result \"$_auth_result\" _regex=\".*\\\"access_token\\\":\\\"\\([-._0-9A-Za-z]*\\)\\\".*$\" _debug _regex \"$_regex\" _access_token=$(echo \"$_auth_result\" | _json_decode | sed -n \"s/$_regex/\\1/p\") _debug _subclient \"${DEPLOY_CLEVERREACH_SUBCLIENT_ID}\" if [ -n \"${DEPLOY_CLEVERREACH_SUBCLIENT_ID}\" ]; then _info \"Obtaining token for sub-client ${DEPLOY_CLEVERREACH_SUBCLIENT_ID}\" export _H1=\"Authorization: Bearer ${_access_token}\" _subclient_token_result=\"$(_get \"$_rest_endpoint/v3/clients/$DEPLOY_CLEVERREACH_SUBCLIENT_ID/token\")\" _access_token=$(echo \"$_subclient_token_result\" | sed -n \"s/\\\"//p\") _debug _subclient_token_result \"$_access_token\" _info \"Destroying parent token at CleverReach, as it not needed anymore\" _destroy_result=\"$(_post \"\" \"$_rest_endpoint/v3/oauth/token.json\" \"\" \"DELETE\" \"application/json\")\" _debug _destroy_result \"$_destroy_result\" fi _info \"Uploading certificate and key to CleverReach\" _certData=\"{\\\"cert\\\":\\\"$(_json_encode <\"$_cfullchain\")\\\", \\\"key\\\":\\\"$(_json_encode <\"$_ckey\")\\\"}\" export _H1=\"Authorization: Bearer ${_access_token}\" _add_cert_result=\"$(_post \"$_certData\" \"$_rest_endpoint/v3/ssl\" \"\" \"POST\" \"application/json\")\" if [ -z \"${DEPLOY_CLEVERREACH_SUBCLIENT_ID}\" ]; then _info \"Destroying token at CleverReach, as it not needed anymore\" _destroy_result=\"$(_post \"\" \"$_rest_endpoint/v3/oauth/token.json\" \"\" \"DELETE\" \"application/json\")\" _debug _destroy_result \"$_destroy_result\" fi if ! echo \"$_add_cert_result\" | grep '\"error\":' >/dev/null; then _info \"Uploaded certificate successfully\" return 0 else _debug _add_cert_result \"$_add_cert_result\" _err \"Unable to update certificate\" return 1 fi }"
        },
        {
            "filename": "file_119.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_119.sh",
            "content": "#!/usr/bin/env sh # Here is a script to deploy cert to hashicorp consul using curl # (https://www.consul.io/) # # it requires following environment variables: # # CONSUL_PREFIX - this contains the prefix path in consul # CONSUL_HTTP_ADDR - consul requires this to find your consul server # # additionally, you need to ensure that CONSUL_HTTP_TOKEN is available # to access the consul server #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain consul_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" # validate required env vars _getdeployconf CONSUL_PREFIX if [ -z \"$CONSUL_PREFIX\" ]; then _err \"CONSUL_PREFIX needs to be defined (contains prefix path in vault)\" return 1 fi _savedeployconf CONSUL_PREFIX \"$CONSUL_PREFIX\" _getdeployconf CONSUL_HTTP_ADDR if [ -z \"$CONSUL_HTTP_ADDR\" ]; then _err \"CONSUL_HTTP_ADDR needs to be defined (contains consul connection address)\" return 1 fi _savedeployconf CONSUL_HTTP_ADDR \"$CONSUL_HTTP_ADDR\" CONSUL_CMD=$(command -v consul) # force CLI, but the binary does not exist => error if [ -n \"$USE_CLI\" ] && [ -z \"$CONSUL_CMD\" ]; then _err \"Cannot find the consul binary!\" return 1 fi # use the CLI first if [ -n \"$USE_CLI\" ] || [ -n \"$CONSUL_CMD\" ]; then _info \"Found consul binary, deploying with CLI\" consul_deploy_cli \"$CONSUL_CMD\" \"$CONSUL_PREFIX\" else _info \"Did not find consul binary, deploying with API\" consul_deploy_api \"$CONSUL_HTTP_ADDR\" \"$CONSUL_PREFIX\" \"$CONSUL_HTTP_TOKEN\" fi } consul_deploy_api() { CONSUL_HTTP_ADDR=\"$1\" CONSUL_PREFIX=\"$2\" CONSUL_HTTP_TOKEN=\"$3\" URL=\"$CONSUL_HTTP_ADDR/v1/kv/$CONSUL_PREFIX\" export _H1=\"X-Consul-Token: $CONSUL_HTTP_TOKEN\" if [ -n \"$FABIO\" ]; then _post \"$(cat \"$_cfullchain\")\" \"$URL/${_cdomain}-cert.pem\" '' \"PUT\" || return 1 _post \"$(cat \"$_ckey\")\" \"$URL/${_cdomain}-key.pem\" '' \"PUT\" || return 1 else _post \"$(cat \"$_ccert\")\" \"$URL/${_cdomain}/cert.pem\" '' \"PUT\" || return 1 _post \"$(cat \"$_ckey\")\" \"$URL/${_cdomain}/cert.key\" '' \"PUT\" || return 1 _post \"$(cat \"$_cca\")\" \"$URL/${_cdomain}/chain.pem\" '' \"PUT\" || return 1 _post \"$(cat \"$_cfullchain\")\" \"$URL/${_cdomain}/fullchain.pem\" '' \"PUT\" || return 1 fi } consul_deploy_cli() { CONSUL_CMD=\"$1\" CONSUL_PREFIX=\"$2\" if [ -n \"$FABIO\" ]; then $CONSUL_CMD kv put \"${CONSUL_PREFIX}/${_cdomain}-cert.pem\" @\"$_cfullchain\" || return 1 $CONSUL_CMD kv put \"${CONSUL_PREFIX}/${_cdomain}-key.pem\" @\"$_ckey\" || return 1 else $CONSUL_CMD kv put \"${CONSUL_PREFIX}/${_cdomain}/cert.pem\" value=@\"$_ccert\" || return 1 $CONSUL_CMD kv put \"${CONSUL_PREFIX}/${_cdomain}/cert.key\" value=@\"$_ckey\" || return 1 $CONSUL_CMD kv put \"${CONSUL_PREFIX}/${_cdomain}/chain.pem\" value=@\"$_cca\" || return 1 $CONSUL_CMD kv put \"${CONSUL_PREFIX}/${_cdomain}/fullchain.pem\" value=@\"$_cfullchain\" || return 1 fi }"
        },
        {
            "filename": "file_120.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_120.sh",
            "content": "#!/usr/bin/env sh # Here is the script to deploy the cert to your cpanel using the cpanel API. # Uses command line uapi. --user option is needed only if run as root. # Returns 0 when success. # # Configure DEPLOY_CPANEL_AUTO_<...> options to enable or restrict automatic # detection of deployment targets through UAPI (if not set, defaults below are used.) # - ENABLED : 'true' for multi-site / wildcard capability; otherwise single-site mode. # - NOMATCH : 'true' to allow deployment to sites that do not match the certificate. # - INCLUDE : Comma-separated list - sites must match this field. # - EXCLUDE : Comma-separated list - sites must NOT match this field. # INCLUDE/EXCLUDE both support non-lexical, glob-style matches using '*' # # Please note that I am no longer using Github. If you want to report an issue # or contact me, visit https://forum.webseodesigners.com/web-design-seo-and-hosting-f16/ # # Written by Santeri Kannisto <santeri.kannisto@webseodesigners.com> # Public domain, 2017-2018 # # export DEPLOY_CPANEL_USER=myusername # export DEPLOY_CPANEL_AUTO_ENABLED='true' # export DEPLOY_CPANEL_AUTO_NOMATCH='false' # export DEPLOY_CPANEL_AUTO_INCLUDE='*' # export DEPLOY_CPANEL_AUTO_EXCLUDE='' ######## Public functions ##################### #domain keyfile certfile cafile fullchain cpanel_uapi_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" # re-declare vars inherited from acme.sh but not passed to make ShellCheck happy : \"${Le_Alt:=\"\"}\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" if ! _exists uapi; then _err \"The command uapi is not found.\" return 1 fi # declare useful constants uapi_error_response='status: 0' # read cert and key files and urlencode both _cert=$(_url_encode <\"$_ccert\") _key=$(_url_encode <\"$_ckey\") _debug2 _cert \"$_cert\" _debug2 _key \"$_key\" if [ \"$(id -u)\" = 0 ]; then _getdeployconf DEPLOY_CPANEL_USER # fallback to _readdomainconf for old installs if [ -z \"${DEPLOY_CPANEL_USER:=$(_readdomainconf DEPLOY_CPANEL_USER)}\" ]; then _err \"It seems that you are root, please define the target user name: export DEPLOY_CPANEL_USER=username\" return 1 fi _debug DEPLOY_CPANEL_USER \"$DEPLOY_CPANEL_USER\" _savedeployconf DEPLOY_CPANEL_USER \"$DEPLOY_CPANEL_USER\" _uapi_user=\"$DEPLOY_CPANEL_USER\" fi # Load all AUTO envars and set defaults - see above for usage __cpanel_initautoparam ENABLED 'true' __cpanel_initautoparam NOMATCH 'false' __cpanel_initautoparam INCLUDE '*' __cpanel_initautoparam EXCLUDE '' # Auto mode if [ \"$DEPLOY_CPANEL_AUTO_ENABLED\" = \"true\" ]; then # call API for site config _response=$(uapi DomainInfo list_domains) # exit if error in response if [ -z \"$_response\" ] || [ \"${_response#*\"$uapi_error_response\"}\" != \"$_response\" ]; then _err \"Error in deploying certificate - cannot retrieve sitelist:\" _err \"\\n$_response\" return 1 fi # parse response to create site list sitelist=$(__cpanel_parse_response \"$_response\") _debug \"UAPI sites found: $sitelist\" # filter sitelist using configured domains # skip if NOMATCH is \"true\" if [ \"$DEPLOY_CPANEL_AUTO_NOMATCH\" = \"true\" ]; then _debug \"DEPLOY_CPANEL_AUTO_NOMATCH is true\" _info \"UAPI nomatch mode is enabled - Will not validate sites are valid for the certificate\" else _debug \"DEPLOY_CPANEL_AUTO_NOMATCH is false\" d=\"$(echo \"${Le_Alt},\" | sed -e \"s/^$_cdomain,//\" -e \"s/,$_cdomain,/,/\")\" d=\"$(echo \"$_cdomain,$d\" | tr ',' '\\n' | sed -e 's/\\./\\\\./g' -e 's/\\*/\\[\\^\\.\\]\\*/g')\" sitelist=\"$(echo \"$sitelist\" | grep -ix \"$d\")\" _debug2 \"Matched UAPI sites: $sitelist\" fi # filter sites that do not match $DEPLOY_CPANEL_AUTO_INCLUDE _info \"Applying sitelist filter DEPLOY_CPANEL_AUTO_INCLUDE: $DEPLOY_CPANEL_AUTO_INCLUDE\" sitelist=\"$(echo \"$sitelist\" | grep -ix \"$(echo \"$DEPLOY_CPANEL_AUTO_INCLUDE\" | tr ',' '\\n' | sed -e 's/\\./\\\\./g' -e 's/\\*/\\.\\*/g')\")\" _debug2 \"Remaining sites: $sitelist\" # filter sites that match $DEPLOY_CPANEL_AUTO_EXCLUDE _info \"Applying sitelist filter DEPLOY_CPANEL_AUTO_EXCLUDE: $DEPLOY_CPANEL_AUTO_EXCLUDE\" sitelist=\"$(echo \"$sitelist\" | grep -vix \"$(echo \"$DEPLOY_CPANEL_AUTO_EXCLUDE\" | tr ',' '\\n' | sed -e 's/\\./\\\\./g' -e 's/\\*/\\.\\*/g')\")\" _debug2 \"Remaining sites: $sitelist\" # counter for success / failure check successes=0 if [ -n \"$sitelist\" ]; then sitetotal=\"$(echo \"$sitelist\" | wc -l)\" _debug \"$sitetotal sites to deploy\" else sitetotal=0 _debug \"No sites to deploy\" fi # for each site: call uapi to publish cert and log result. Only return failure if all fail for site in $sitelist; do # call uapi to publish cert, check response for errors and log them. if [ -n \"$_uapi_user\" ]; then _response=$(uapi --user=\"$_uapi_user\" SSL install_ssl domain=\"$site\" cert=\"$_cert\" key=\"$_key\") else _response=$(uapi SSL install_ssl domain=\"$site\" cert=\"$_cert\" key=\"$_key\") fi if [ \"${_response#*\"$uapi_error_response\"}\" != \"$_response\" ]; then _err \"Error in deploying certificate to $site:\" _err \"$_response\" else successes=$((successes + 1)) _debug \"$_response\" _info \"Succcessfully deployed to $site\" fi done # Raise error if all updates fail if [ \"$sitetotal\" -gt 0 ] && [ \"$successes\" -eq 0 ]; then _err \"Could not deploy to any of $sitetotal sites via UAPI\" _debug \"successes: $successes, sitetotal: $sitetotal\" return 1 fi _info \"Successfully deployed certificate to $successes of $sitetotal sites via UAPI\" return 0 else # \"classic\" mode - will only try to deploy to the primary domain; will not check UAPI first if [ -n \"$_uapi_user\" ]; then _response=$(uapi --user=\"$_uapi_user\" SSL install_ssl domain=\"$_cdomain\" cert=\"$_cert\" key=\"$_key\") else _response=$(uapi SSL install_ssl domain=\"$_cdomain\" cert=\"$_cert\" key=\"$_key\") fi if [ \"${_response#*\"$uapi_error_response\"}\" != \"$_response\" ]; then _err \"Error in deploying certificate:\" _err \"$_response\" return 1 fi _debug response \"$_response\" _info \"Certificate successfully deployed\" return 0 fi } ######## Private functions ##################### # Internal utility to process YML from UAPI - looks at main_domain, sub_domains, addon domains and parked domains #[response] __cpanel_parse_response() { if [ $# -gt 0 ]; then resp=\"$*\"; else resp=\"$(cat)\"; fi echo \"$resp\" | sed -En \\ -e 's/\\r$//' \\ -e 's/^( *)([_.[:alnum:]]+) *: *(.*)/\\1,\\2,\\3/p' \\ -e 's/^( *)- (.*)/\\1,-,\\2/p' | awk -F, '{ level = length($1)/2; section[level] = $2; for (i in section) {if (i > level) {delete section[i]}} if (length($3) > 0) { prefix=\"\"; for (i=0; i < level; i++) { prefix = (prefix)(section[i])(\"/\") } printf(\"%s%s=%s\\n\", prefix, $2, $3); } }' | sed -En -e 's/^result\\/data\\/(main_domain|sub_domains\\/-|addon_domains\\/-|parked_domains\\/-)=(.*)$/\\2/p' } # Load parameter by prefix+name - fallback to default if not set, and save to config #pname pdefault __cpanel_initautoparam() { pname=\"$1\" pdefault=\"$2\" pkey=\"DEPLOY_CPANEL_AUTO_$pname\" _getdeployconf \"$pkey\" [ -n \"$(eval echo \"\\\"\\$$pkey\\\"\")\" ] || eval \"$pkey=\\\"$pdefault\\\"\" _debug2 \"$pkey\" \"$(eval echo \"\\\"\\$$pkey\\\"\")\" _savedeployconf \"$pkey\" \"$(eval echo \"\\\"\\$$pkey\\\"\")\" }"
        },
        {
            "filename": "file_121.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_121.sh",
            "content": "#!/usr/bin/env sh #DEPLOY_DOCKER_CONTAINER_LABEL=\"xxxxxxx\" #DEPLOY_DOCKER_CONTAINER_KEY_FILE=\"/path/to/key.pem\" #DEPLOY_DOCKER_CONTAINER_CERT_FILE=\"/path/to/cert.pem\" #DEPLOY_DOCKER_CONTAINER_CA_FILE=\"/path/to/ca.pem\" #DEPLOY_DOCKER_CONTAINER_FULLCHAIN_FILE=\"/path/to/fullchain.pem\" #DEPLOY_DOCKER_CONTAINER_RELOAD_CMD=\"service nginx force-reload\" _DEPLOY_DOCKER_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/deploy-to-docker-containers\" _DOCKER_HOST_DEFAULT=\"/var/run/docker.sock\" docker_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _getdeployconf DEPLOY_DOCKER_CONTAINER_LABEL _debug2 DEPLOY_DOCKER_CONTAINER_LABEL \"$DEPLOY_DOCKER_CONTAINER_LABEL\" if [ -z \"$DEPLOY_DOCKER_CONTAINER_LABEL\" ]; then _err \"The DEPLOY_DOCKER_CONTAINER_LABEL variable is not defined, we use this label to find the container.\" _err \"See: $_DEPLOY_DOCKER_WIKI\" fi _savedeployconf DEPLOY_DOCKER_CONTAINER_LABEL \"$DEPLOY_DOCKER_CONTAINER_LABEL\" if [ \"$DOCKER_HOST\" ]; then _saveaccountconf DOCKER_HOST \"$DOCKER_HOST\" fi if _exists docker && docker version | grep -i docker >/dev/null; then _info \"Using docker command\" export _USE_DOCKER_COMMAND=1 else export _USE_DOCKER_COMMAND= fi export _USE_UNIX_SOCKET= if [ -z \"$_USE_DOCKER_COMMAND\" ]; then export _USE_REST= if [ \"$DOCKER_HOST\" ]; then _debug \"Try use docker host: $DOCKER_HOST\" export _USE_REST=1 else export _DOCKER_SOCK=\"$_DOCKER_HOST_DEFAULT\" _debug \"Try use $_DOCKER_SOCK\" if [ ! -e \"$_DOCKER_SOCK\" ] || [ ! -w \"$_DOCKER_SOCK\" ]; then _err \"$_DOCKER_SOCK is not available\" return 1 fi export _USE_UNIX_SOCKET=1 if ! _exists \"curl\"; then _err \"Please install curl first.\" _err \"We need curl to work.\" return 1 fi if ! _check_curl_version; then return 1 fi fi fi _getdeployconf DEPLOY_DOCKER_CONTAINER_KEY_FILE _debug2 DEPLOY_DOCKER_CONTAINER_KEY_FILE \"$DEPLOY_DOCKER_CONTAINER_KEY_FILE\" if [ \"$DEPLOY_DOCKER_CONTAINER_KEY_FILE\" ]; then _savedeployconf DEPLOY_DOCKER_CONTAINER_KEY_FILE \"$DEPLOY_DOCKER_CONTAINER_KEY_FILE\" fi _getdeployconf DEPLOY_DOCKER_CONTAINER_CERT_FILE _debug2 DEPLOY_DOCKER_CONTAINER_CERT_FILE \"$DEPLOY_DOCKER_CONTAINER_CERT_FILE\" if [ \"$DEPLOY_DOCKER_CONTAINER_CERT_FILE\" ]; then _savedeployconf DEPLOY_DOCKER_CONTAINER_CERT_FILE \"$DEPLOY_DOCKER_CONTAINER_CERT_FILE\" fi _getdeployconf DEPLOY_DOCKER_CONTAINER_CA_FILE _debug2 DEPLOY_DOCKER_CONTAINER_CA_FILE \"$DEPLOY_DOCKER_CONTAINER_CA_FILE\" if [ \"$DEPLOY_DOCKER_CONTAINER_CA_FILE\" ]; then _savedeployconf DEPLOY_DOCKER_CONTAINER_CA_FILE \"$DEPLOY_DOCKER_CONTAINER_CA_FILE\" fi _getdeployconf DEPLOY_DOCKER_CONTAINER_FULLCHAIN_FILE _debug2 DEPLOY_DOCKER_CONTAINER_FULLCHAIN_FILE \"$DEPLOY_DOCKER_CONTAINER_FULLCHAIN_FILE\" if [ \"$DEPLOY_DOCKER_CONTAINER_FULLCHAIN_FILE\" ]; then _savedeployconf DEPLOY_DOCKER_CONTAINER_FULLCHAIN_FILE \"$DEPLOY_DOCKER_CONTAINER_FULLCHAIN_FILE\" fi _getdeployconf DEPLOY_DOCKER_CONTAINER_RELOAD_CMD _debug2 DEPLOY_DOCKER_CONTAINER_RELOAD_CMD \"$DEPLOY_DOCKER_CONTAINER_RELOAD_CMD\" if [ \"$DEPLOY_DOCKER_CONTAINER_RELOAD_CMD\" ]; then _savedeployconf DEPLOY_DOCKER_CONTAINER_RELOAD_CMD \"$DEPLOY_DOCKER_CONTAINER_RELOAD_CMD\" \"base64\" fi _cid=\"$(_get_id \"$DEPLOY_DOCKER_CONTAINER_LABEL\")\" _info \"Container id: $_cid\" if [ -z \"$_cid\" ]; then _err \"can not find container id\" return 1 fi if [ \"$DEPLOY_DOCKER_CONTAINER_KEY_FILE\" ]; then if ! _docker_cp \"$_cid\" \"$_ckey\" \"$DEPLOY_DOCKER_CONTAINER_KEY_FILE\"; then return 1 fi fi if [ \"$DEPLOY_DOCKER_CONTAINER_CERT_FILE\" ]; then if ! _docker_cp \"$_cid\" \"$_ccert\" \"$DEPLOY_DOCKER_CONTAINER_CERT_FILE\"; then return 1 fi fi if [ \"$DEPLOY_DOCKER_CONTAINER_CA_FILE\" ]; then if ! _docker_cp \"$_cid\" \"$_cca\" \"$DEPLOY_DOCKER_CONTAINER_CA_FILE\"; then return 1 fi fi if [ \"$DEPLOY_DOCKER_CONTAINER_FULLCHAIN_FILE\" ]; then if ! _docker_cp \"$_cid\" \"$_cfullchain\" \"$DEPLOY_DOCKER_CONTAINER_FULLCHAIN_FILE\"; then return 1 fi fi if [ \"$DEPLOY_DOCKER_CONTAINER_RELOAD_CMD\" ]; then _info \"Reloading: $DEPLOY_DOCKER_CONTAINER_RELOAD_CMD\" if ! _docker_exec \"$_cid\" \"$DEPLOY_DOCKER_CONTAINER_RELOAD_CMD\"; then return 1 fi fi return 0 } #label _get_id() { _label=\"$1\" if [ \"$_USE_DOCKER_COMMAND\" ]; then docker ps -f label=\"$_label\" --format \"{{.ID}}\" elif [ \"$_USE_REST\" ]; then _err \"Not implemented yet.\" return 1 elif [ \"$_USE_UNIX_SOCKET\" ]; then _req=\"{\\\"label\\\":[\\\"$_label\\\"]}\" _debug2 _req \"$_req\" _req=\"$(printf \"%s\" \"$_req\" | _url_encode)\" _debug2 _req \"$_req\" listjson=\"$(_curl_unix_sock \"${_DOCKER_SOCK:-$_DOCKER_HOST_DEFAULT}\" GET \"/containers/json?filters=$_req\")\" _debug2 \"listjson\" \"$listjson\" echo \"$listjson\" | tr '{,' '\\n' | grep -i '\"id\":' | _head_n 1 | cut -d '\"' -f 4 else _err \"Not implemented yet.\" return 1 fi } #id cmd _docker_exec() { _eargs=\"$*\" _debug2 \"_docker_exec $_eargs\" _dcid=\"$1\" shift if [ \"$_USE_DOCKER_COMMAND\" ]; then docker exec -i \"$_dcid\" sh -c \"$*\" elif [ \"$_USE_REST\" ]; then _err \"Not implemented yet.\" return 1 elif [ \"$_USE_UNIX_SOCKET\" ]; then _cmd=\"$*\" #_cmd=\"$(printf \"%s\" \"$_cmd\" | sed 's/ /\",\"/g')\" _debug2 _cmd \"$_cmd\" #create exec instance: cjson=\"$(_curl_unix_sock \"$_DOCKER_SOCK\" POST \"/containers/$_dcid/exec\" \"{\\\"Cmd\\\": [\\\"sh\\\", \\\"-c\\\", \\\"$_cmd\\\"]}\")\" _debug2 cjson \"$cjson\" execid=\"$(echo \"$cjson\" | cut -d '\"' -f 4)\" _debug execid \"$execid\" ejson=\"$(_curl_unix_sock \"$_DOCKER_SOCK\" POST \"/exec/$execid/start\" \"{\\\"Detach\\\": false,\\\"Tty\\\": false}\")\" _debug2 ejson \"$ejson\" if [ \"$ejson\" ]; then _err \"$ejson\" return 1 fi else _err \"Not implemented yet.\" return 1 fi } #id from to _docker_cp() { _dcid=\"$1\" _from=\"$2\" _to=\"$3\" _info \"Copying file from $_from to $_to\" _dir=\"$(dirname \"$_to\")\" _debug2 _dir \"$_dir\" if ! _docker_exec \"$_dcid\" mkdir -p \"$_dir\"; then _err \"Can not create dir: $_dir\" return 1 fi if [ \"$_USE_DOCKER_COMMAND\" ]; then if [ \"$DEBUG\" ] && [ \"$DEBUG\" -ge \"2\" ]; then _docker_exec \"$_dcid\" tee \"$_to\" <\"$_from\" else _docker_exec \"$_dcid\" tee \"$_to\" <\"$_from\" >/dev/null fi if [ \"$?\" = \"0\" ]; then _info \"Success\" return 0 else _info \"Error\" return 1 fi elif [ \"$_USE_REST\" ]; then _err \"Not implemented yet.\" return 1 elif [ \"$_USE_UNIX_SOCKET\" ]; then _frompath=\"$_from\" if _startswith \"$_frompath\" '/'; then _frompath=\"$(echo \"$_from\" | cut -b 2-)\" #remove the first '/' char fi _debug2 \"_frompath\" \"$_frompath\" _toname=\"$(basename \"$_to\")\" _debug2 \"_toname\" \"$_toname\" _debug2 \"_from\" \"$_from\" if ! tar --transform=\"s,$(printf \"%s\" \"$_frompath\" | tr '*' .),$_toname,\" -cz \"$_from\" 2>/dev/null | _curl_unix_sock \"$_DOCKER_SOCK\" PUT \"/containers/$_dcid/archive?noOverwriteDirNonDir=1&path=$(printf \"%s\" \"$_dir\" | _url_encode)\" '@-' \"Content-Type: application/octet-stream\"; then _err \"copy error\" return 1 fi return 0 else _err \"Not implemented yet.\" return 1 fi } #sock method endpoint data content-type _curl_unix_sock() { _socket=\"$1\" _method=\"$2\" _endpoint=\"$3\" _data=\"$4\" _ctype=\"$5\" if [ -z \"$_ctype\" ]; then _ctype=\"Content-Type: application/json\" fi _debug _data \"$_data\" _debug2 \"url\" \"http://localhost$_endpoint\" if [ \"$_CURL_NO_HOST\" ]; then _cux_url=\"http:$_endpoint\" else _cux_url=\"http://localhost$_endpoint\" fi if [ \"$DEBUG\" ] && [ \"$DEBUG\" -ge \"2\" ]; then curl -vvv --silent --unix-socket \"$_socket\" -X \"$_method\" --data-binary \"$_data\" --header \"$_ctype\" \"$_cux_url\" else curl --silent --unix-socket \"$_socket\" -X \"$_method\" --data-binary \"$_data\" --header \"$_ctype\" \"$_cux_url\" fi } _check_curl_version() { _cversion=\"$(curl -V | grep '^curl ' | cut -d ' ' -f 2)\" _debug2 \"_cversion\" \"$_cversion\" _major=\"$(_getfield \"$_cversion\" 1 '.')\" _debug2 \"_major\" \"$_major\" _minor=\"$(_getfield \"$_cversion\" 2 '.')\" _debug2 \"_minor\" \"$_minor\" if [ \"$_major\" -ge \"8\" ]; then #ok return 0 fi if [ \"$_major\" = \"7\" ]; then if [ \"$_minor\" -lt \"40\" ]; then _err \"curl v$_cversion doesn't support unit socket\" _err \"Please upgrade to curl 7.40 or later.\" return 1 fi if [ \"$_minor\" -lt \"50\" ]; then _debug \"Use short host name\" export _CURL_NO_HOST=1 else export _CURL_NO_HOST= fi return 0 else _err \"curl v$_cversion doesn't support unit socket\" _err \"Please upgrade to curl 7.40 or later.\" return 1 fi }"
        },
        {
            "filename": "file_122.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_122.sh",
            "content": "#!/usr/bin/env sh #Here is a script to deploy cert to dovecot server. #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain dovecot_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _err \"Not implemented yet\" return 1 }"
        },
        {
            "filename": "file_123.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_123.sh",
            "content": "#!/usr/bin/env sh #Here is a script to deploy cert to exim4 server. #returns 0 means success, otherwise error. #DEPLOY_EXIM4_CONF=\"/etc/exim/exim.conf\" #DEPLOY_EXIM4_RELOAD=\"service exim4 restart\" ######## Public functions ##################### #domain keyfile certfile cafile fullchain exim4_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _ssl_path=\"/etc/acme.sh/exim4\" if ! mkdir -p \"$_ssl_path\"; then _err \"Can not create folder:$_ssl_path\" return 1 fi _info \"Copying key and cert\" _real_key=\"$_ssl_path/exim4.key\" if ! cat \"$_ckey\" >\"$_real_key\"; then _err \"Error: write key file to: $_real_key\" return 1 fi _real_fullchain=\"$_ssl_path/exim4.pem\" if ! cat \"$_cfullchain\" >\"$_real_fullchain\"; then _err \"Error: write key file to: $_real_fullchain\" return 1 fi DEFAULT_EXIM4_RELOAD=\"service exim4 restart\" _reload=\"${DEPLOY_EXIM4_RELOAD:-$DEFAULT_EXIM4_RELOAD}\" if [ -z \"$IS_RENEW\" ]; then DEFAULT_EXIM4_CONF=\"/etc/exim/exim.conf\" if [ ! -f \"$DEFAULT_EXIM4_CONF\" ]; then DEFAULT_EXIM4_CONF=\"/etc/exim4/exim4.conf.template\" fi _exim4_conf=\"${DEPLOY_EXIM4_CONF:-$DEFAULT_EXIM4_CONF}\" _debug _exim4_conf \"$_exim4_conf\" if [ ! -f \"$_exim4_conf\" ]; then if [ -z \"$DEPLOY_EXIM4_CONF\" ]; then _err \"exim4 conf is not found, please define DEPLOY_EXIM4_CONF\" return 1 else _err \"It seems that the specified exim4 conf is not valid, please check.\" return 1 fi fi if [ ! -w \"$_exim4_conf\" ]; then _err \"The file $_exim4_conf is not writable, please change the permission.\" return 1 fi _backup_conf=\"$DOMAIN_BACKUP_PATH/exim4.conf.bak\" _info \"Backup $_exim4_conf to $_backup_conf\" cp \"$_exim4_conf\" \"$_backup_conf\" _info \"Modify exim4 conf: $_exim4_conf\" if _setopt \"$_exim4_conf\" \"tls_certificate\" \"=\" \"$_real_fullchain\" && _setopt \"$_exim4_conf\" \"tls_privatekey\" \"=\" \"$_real_key\"; then _info \"Set config success!\" else _err \"Config exim4 server error, please report bug to us.\" _info \"Restoring exim4 conf\" if cat \"$_backup_conf\" >\"$_exim4_conf\"; then _info \"Restore conf success\" eval \"$_reload\" else _err \"Oops, error restore exim4 conf, please report bug to us.\" fi return 1 fi fi _info \"Run reload: $_reload\" if eval \"$_reload\"; then _info \"Reload success!\" if [ \"$DEPLOY_EXIM4_CONF\" ]; then _savedomainconf DEPLOY_EXIM4_CONF \"$DEPLOY_EXIM4_CONF\" else _cleardomainconf DEPLOY_EXIM4_CONF fi if [ \"$DEPLOY_EXIM4_RELOAD\" ]; then _savedomainconf DEPLOY_EXIM4_RELOAD \"$DEPLOY_EXIM4_RELOAD\" else _cleardomainconf DEPLOY_EXIM4_RELOAD fi return 0 else _err \"Reload error, restoring\" if cat \"$_backup_conf\" >\"$_exim4_conf\"; then _info \"Restore conf success\" eval \"$_reload\" else _err \"Oops, error restore exim4 conf, please report bug to us.\" fi return 1 fi return 0 }"
        },
        {
            "filename": "file_124.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_124.sh",
            "content": "#!/usr/bin/env sh #Here is a script to deploy cert to an AVM FRITZ!Box router. #returns 0 means success, otherwise error. #DEPLOY_FRITZBOX_USERNAME=\"username\" #DEPLOY_FRITZBOX_PASSWORD=\"password\" #DEPLOY_FRITZBOX_URL=\"https://fritz.box\" # Kudos to wikrie at Github for his FRITZ!Box update script: # https://gist.github.com/wikrie/f1d5747a714e0a34d0582981f7cb4cfb ######## Public functions ##################### #domain keyfile certfile cafile fullchain fritzbox_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" if ! _exists iconv; then if ! _exists uconv; then if ! _exists perl; then _err \"iconv or uconv or perl not found\" return 1 fi fi fi # Clear traces of incorrectly stored values _clearaccountconf DEPLOY_FRITZBOX_USERNAME _clearaccountconf DEPLOY_FRITZBOX_PASSWORD _clearaccountconf DEPLOY_FRITZBOX_URL # Read config from saved values or env _getdeployconf DEPLOY_FRITZBOX_USERNAME _getdeployconf DEPLOY_FRITZBOX_PASSWORD _getdeployconf DEPLOY_FRITZBOX_URL _debug DEPLOY_FRITZBOX_URL \"$DEPLOY_FRITZBOX_URL\" _debug DEPLOY_FRITZBOX_USERNAME \"$DEPLOY_FRITZBOX_USERNAME\" _secure_debug DEPLOY_FRITZBOX_PASSWORD \"$DEPLOY_FRITZBOX_PASSWORD\" if [ -z \"$DEPLOY_FRITZBOX_USERNAME\" ]; then _err \"FRITZ!Box username is not found, please define DEPLOY_FRITZBOX_USERNAME.\" return 1 fi if [ -z \"$DEPLOY_FRITZBOX_PASSWORD\" ]; then _err \"FRITZ!Box password is not found, please define DEPLOY_FRITZBOX_PASSWORD.\" return 1 fi if [ -z \"$DEPLOY_FRITZBOX_URL\" ]; then _err \"FRITZ!Box url is not found, please define DEPLOY_FRITZBOX_URL.\" return 1 fi # Save current values _savedeployconf DEPLOY_FRITZBOX_USERNAME \"$DEPLOY_FRITZBOX_USERNAME\" _savedeployconf DEPLOY_FRITZBOX_PASSWORD \"$DEPLOY_FRITZBOX_PASSWORD\" _savedeployconf DEPLOY_FRITZBOX_URL \"$DEPLOY_FRITZBOX_URL\" # Do not check for a valid SSL certificate, because initially the cert is not valid, so it could not install the LE generated certificate export HTTPS_INSECURE=1 _info \"Log in to the FRITZ!Box\" _fritzbox_challenge=\"$(_get \"${DEPLOY_FRITZBOX_URL}/login_sid.lua\" | sed -e 's/^.*<Challenge>//' -e 's/<\\/Challenge>.*$//')\" if _exists iconv; then _fritzbox_hash=\"$(printf \"%s-%s\" \"${_fritzbox_challenge}\" \"${DEPLOY_FRITZBOX_PASSWORD}\" | iconv -f ASCII -t UTF16LE | _digest md5 hex)\" elif _exists uconv; then _fritzbox_hash=\"$(printf \"%s-%s\" \"${_fritzbox_challenge}\" \"${DEPLOY_FRITZBOX_PASSWORD}\" | uconv -f ASCII -t UTF16LE | _digest md5 hex)\" else _fritzbox_hash=\"$(printf \"%s-%s\" \"${_fritzbox_challenge}\" \"${DEPLOY_FRITZBOX_PASSWORD}\" | perl -p -e 'use Encode qw/encode/; print encode(\"UTF-16LE\",\"$_\"); $_=\"\";' | _digest md5 hex)\" fi _fritzbox_sid=\"$(_get \"${DEPLOY_FRITZBOX_URL}/login_sid.lua?sid=0000000000000000&username=${DEPLOY_FRITZBOX_USERNAME}&response=${_fritzbox_challenge}-${_fritzbox_hash}\" | sed -e 's/^.*<SID>//' -e 's/<\\/SID>.*$//')\" if [ -z \"${_fritzbox_sid}\" ] || [ \"${_fritzbox_sid}\" = \"0000000000000000\" ]; then _err \"Logging in to the FRITZ!Box failed. Please check username, password and URL.\" return 1 fi _info \"Generate form POST request\" _post_request=\"$(_mktemp)\" _post_boundary=\"---------------------------$(date +%Y%m%d%H%M%S)\" # _CERTPASSWORD_ is unset because Let's Encrypt certificates don't have a password. But if they ever do, here's the place to use it! _CERTPASSWORD_= { printf -- \"--\" printf -- \"%s\\r\\n\" \"${_post_boundary}\" printf \"Content-Disposition: form-data; name=\\\"sid\\\"\\r\\n\\r\\n%s\\r\\n\" \"${_fritzbox_sid}\" printf -- \"--\" printf -- \"%s\\r\\n\" \"${_post_boundary}\" printf \"Content-Disposition: form-data; name=\\\"BoxCertPassword\\\"\\r\\n\\r\\n%s\\r\\n\" \"${_CERTPASSWORD_}\" printf -- \"--\" printf -- \"%s\\r\\n\" \"${_post_boundary}\" printf \"Content-Disposition: form-data; name=\\\"BoxCertImportFile\\\"; filename=\\\"BoxCert.pem\\\"\\r\\n\" printf \"Content-Type: application/octet-stream\\r\\n\\r\\n\" cat \"${_ckey}\" \"${_cfullchain}\" printf \"\\r\\n\" printf -- \"--\" printf -- \"%s--\" \"${_post_boundary}\" } >>\"${_post_request}\" _info \"Upload certificate to the FRITZ!Box\" export _H1=\"Content-type: multipart/form-data boundary=${_post_boundary}\" _post \"$(cat \"${_post_request}\")\" \"${DEPLOY_FRITZBOX_URL}/cgi-bin/firmwarecfg\" | grep SSL retval=$? if [ $retval = 0 ]; then _info \"Upload successful\" else _err \"Upload failed\" fi rm \"${_post_request}\" return $retval }"
        },
        {
            "filename": "file_125.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_125.sh",
            "content": "#!/usr/bin/env sh # Here is the script to deploy the cert to G-Core CDN service (https://gcore.com/) using the G-Core Labs API (https://apidocs.gcore.com/cdn). # Returns 0 when success. # # Written by temoffey <temofffey@gmail.com> # Public domain, 2019 # Update by DreamOfIce <admin@dreamofice.cn> in 2023 #export DEPLOY_GCORE_CDN_USERNAME=myusername #export DEPLOY_GCORE_CDN_PASSWORD=mypassword ######## Public functions ##################### #domain keyfile certfile cafile fullchain gcore_cdn_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _fullchain=$(tr '\\r\\n' '*#' <\"$_cfullchain\" | sed 's/*#/#/g;s/##/#/g;s/#/\\\\n/g') _key=$(tr '\\r\\n' '*#' <\"$_ckey\" | sed 's/*#/#/g;s/#/\\\\n/g') _debug _fullchain \"$_fullchain\" _debug _key \"$_key\" if [ -z \"$DEPLOY_GCORE_CDN_USERNAME\" ]; then if [ -z \"$Le_Deploy_gcore_cdn_username\" ]; then _err \"Please define the target username: export DEPLOY_GCORE_CDN_USERNAME=username\" return 1 fi else Le_Deploy_gcore_cdn_username=\"$DEPLOY_GCORE_CDN_USERNAME\" _savedomainconf Le_Deploy_gcore_cdn_username \"$Le_Deploy_gcore_cdn_username\" fi if [ -z \"$DEPLOY_GCORE_CDN_PASSWORD\" ]; then if [ -z \"$Le_Deploy_gcore_cdn_password\" ]; then _err \"Please define the target password: export DEPLOY_GCORE_CDN_PASSWORD=password\" return 1 fi else Le_Deploy_gcore_cdn_password=\"$DEPLOY_GCORE_CDN_PASSWORD\" _savedomainconf Le_Deploy_gcore_cdn_password \"$Le_Deploy_gcore_cdn_password\" fi _info \"Get authorization token\" _request=\"{\\\"username\\\":\\\"$Le_Deploy_gcore_cdn_username\\\",\\\"password\\\":\\\"$Le_Deploy_gcore_cdn_password\\\"}\" _debug _request \"$_request\" export _H1=\"Content-Type:application/json\" _response=$(_post \"$_request\" \"https://api.gcore.com/auth/jwt/login\") _debug _response \"$_response\" _regex=\".*\\\"access\\\":\\\"\\([-._0-9A-Za-z]*\\)\\\".*$\" _debug _regex \"$_regex\" _token=$(echo \"$_response\" | sed -n \"s/$_regex/\\1/p\") _debug _token \"$_token\" if [ -z \"$_token\" ]; then _err \"Error G-Core Labs API authorization\" return 1 fi _info \"Find CDN resource with cname $_cdomain\" export _H2=\"Authorization:Bearer $_token\" _response=$(_get \"https://api.gcore.com/cdn/resources\") _debug _response \"$_response\" _regex=\"\\\"primary_resource\\\":null},\" _debug _regex \"$_regex\" _response=$(echo \"$_response\" | sed \"s/$_regex/$_regex\\n/g\") _debug _response \"$_response\" _regex=\"^.*\\\"cname\\\":\\\"$_cdomain\\\".*$\" _debug _regex \"$_regex\" _resource=$(echo \"$_response\" | _egrep_o \"$_regex\") _debug _resource \"$_resource\" _regex=\".*\\\"id\\\":\\([0-9]*\\).*$\" _debug _regex \"$_regex\" _resourceId=$(echo \"$_resource\" | sed -n \"s/$_regex/\\1/p\") _debug _resourceId \"$_resourceId\" _regex=\".*\\\"sslData\\\":\\([0-9]*\\).*$\" _debug _regex \"$_regex\" _sslDataOld=$(echo \"$_resource\" | sed -n \"s/$_regex/\\1/p\") _debug _sslDataOld \"$_sslDataOld\" _regex=\".*\\\"originGroup\\\":\\([0-9]*\\).*$\" _debug _regex \"$_regex\" _originGroup=$(echo \"$_resource\" | sed -n \"s/$_regex/\\1/p\") _debug _originGroup \"$_originGroup\" if [ -z \"$_resourceId\" ] || [ -z \"$_originGroup\" ]; then _err \"Not found CDN resource with cname $_cdomain\" return 1 fi _info \"Add new SSL certificate\" _date=$(date \"+%d.%m.%Y %H:%M:%S\") _request=\"{\\\"name\\\":\\\"$_cdomain ($_date)\\\",\\\"sslCertificate\\\":\\\"$_fullchain\\\",\\\"sslPrivateKey\\\":\\\"$_key\\\"}\" _debug _request \"$_request\" _response=$(_post \"$_request\" \"https://api.gcore.com/cdn/sslData\") _debug _response \"$_response\" _regex=\".*\\\"id\\\":\\([0-9]*\\).*$\" _debug _regex \"$_regex\" _sslDataAdd=$(echo \"$_response\" | sed -n \"s/$_regex/\\1/p\") _debug _sslDataAdd \"$_sslDataAdd\" if [ -z \"$_sslDataAdd\" ]; then _err \"Error new SSL certificate add\" return 1 fi _info \"Update CDN resource\" _request=\"{\\\"originGroup\\\":$_originGroup,\\\"sslData\\\":$_sslDataAdd}\" _debug _request \"$_request\" _response=$(_post \"$_request\" \"https://api.gcore.com/cdn/resources/$_resourceId\" '' \"PUT\") _debug _response \"$_response\" _regex=\".*\\\"sslData\\\":\\([0-9]*\\).*$\" _debug _regex \"$_regex\" _sslDataNew=$(echo \"$_response\" | sed -n \"s/$_regex/\\1/p\") _debug _sslDataNew \"$_sslDataNew\" if [ \"$_sslDataNew\" != \"$_sslDataAdd\" ]; then _err \"Error CDN resource update\" return 1 fi if [ -z \"$_sslDataOld\" ] || [ \"$_sslDataOld\" = \"null\" ]; then _info \"Not found old SSL certificate\" else _info \"Delete old SSL certificate\" _response=$(_post '' \"https://api.gcore.com/cdn/sslData/$_sslDataOld\" '' \"DELETE\") _debug _response \"$_response\" fi _info \"Certificate successfully deployed\" return 0 }"
        },
        {
            "filename": "file_126.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_126.sh",
            "content": "#!/usr/bin/env sh # Script to deploy certificate to a Gitlab hosted page # The following variables exported from environment will be used. # If not set then values previously saved in domain.conf file are used. # All the variables are required # export GITLAB_TOKEN=\"xxxxxxx\" # export GITLAB_PROJECT_ID=012345 # export GITLAB_DOMAIN=\"mydomain.com\" gitlab_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" if [ -z \"$GITLAB_TOKEN\" ]; then if [ -z \"$Le_Deploy_gitlab_token\" ]; then _err \"GITLAB_TOKEN not defined.\" return 1 fi else Le_Deploy_gitlab_token=\"$GITLAB_TOKEN\" _savedomainconf Le_Deploy_gitlab_token \"$Le_Deploy_gitlab_token\" fi if [ -z \"$GITLAB_PROJECT_ID\" ]; then if [ -z \"$Le_Deploy_gitlab_project_id\" ]; then _err \"GITLAB_PROJECT_ID not defined.\" return 1 fi else Le_Deploy_gitlab_project_id=\"$GITLAB_PROJECT_ID\" _savedomainconf Le_Deploy_gitlab_project_id \"$Le_Deploy_gitlab_project_id\" fi if [ -z \"$GITLAB_DOMAIN\" ]; then if [ -z \"$Le_Deploy_gitlab_domain\" ]; then _err \"GITLAB_DOMAIN not defined.\" return 1 fi else Le_Deploy_gitlab_domain=\"$GITLAB_DOMAIN\" _savedomainconf Le_Deploy_gitlab_domain \"$Le_Deploy_gitlab_domain\" fi string_fullchain=$(_url_encode <\"$_cfullchain\") string_key=$(_url_encode <\"$_ckey\") body=\"certificate=$string_fullchain&key=$string_key\" export _H1=\"PRIVATE-TOKEN: $Le_Deploy_gitlab_token\" gitlab_url=\"https://gitlab.com/api/v4/projects/$Le_Deploy_gitlab_project_id/pages/domains/$Le_Deploy_gitlab_domain\" _response=$(_post \"$body\" \"$gitlab_url\" 0 PUT | _dbase64 \"multiline\") error_response=\"error\" if test \"${_response#*\"$error_response\"}\" != \"$_response\"; then _err \"Error in deploying certificate:\" _err \"$_response\" return 1 fi _debug response \"$_response\" _info \"Certificate successfully deployed\" return 0 }"
        },
        {
            "filename": "file_127.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_127.sh",
            "content": "#!/usr/bin/env sh # Script for acme.sh to deploy certificates to haproxy # # The following variables can be exported: # # export DEPLOY_HAPROXY_PEM_NAME=\"${domain}.pem\" # # Defines the name of the PEM file. # Defaults to \"<domain>.pem\" # # export DEPLOY_HAPROXY_PEM_PATH=\"/etc/haproxy\" # # Defines location of PEM file for HAProxy. # Defaults to /etc/haproxy # # export DEPLOY_HAPROXY_RELOAD=\"systemctl reload haproxy\" # # OPTIONAL: Reload command used post deploy # This defaults to be a no-op (ie \"true\"). # It is strongly recommended to set this something that makes sense # for your distro. # # export DEPLOY_HAPROXY_ISSUER=\"no\" # # OPTIONAL: Places CA file as \"${DEPLOY_HAPROXY_PEM}.issuer\" # Note: Required for OCSP stapling to work # # export DEPLOY_HAPROXY_BUNDLE=\"no\" # # OPTIONAL: Deploy this certificate as part of a multi-cert bundle # This adds a suffix to the certificate based on the certificate type # eg RSA certificates will have .rsa as a suffix to the file name # HAProxy will load all certificates and provide one or the other # depending on client capabilities # Note: This functionality requires HAProxy was compiled against # a version of OpenSSL that supports this. # # export DEPLOY_HAPROXY_HOT_UPDATE=\"yes\" # export DEPLOY_HAPROXY_STATS_SOCKET=\"UNIX:/run/haproxy/admin.sock\" # # OPTIONAL: Deploy the certificate over the HAProxy stats socket without # needing to reload HAProxy. Default is \"no\". # # Require the socat binary. DEPLOY_HAPROXY_STATS_SOCKET variable uses the socat # address format. # # export DEPLOY_HAPROXY_MASTER_CLI=\"UNIX:/run/haproxy-master.sock\" # # OPTIONAL: To use the master CLI with DEPLOY_HAPROXY_HOT_UPDATE=\"yes\" instead # of a stats socket, use this variable. ######## Public functions ##################### #domain keyfile certfile cafile fullchain haproxy_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _cmdpfx=\"\" # Some defaults DEPLOY_HAPROXY_PEM_PATH_DEFAULT=\"/etc/haproxy\" DEPLOY_HAPROXY_PEM_NAME_DEFAULT=\"${_cdomain}.pem\" DEPLOY_HAPROXY_BUNDLE_DEFAULT=\"no\" DEPLOY_HAPROXY_ISSUER_DEFAULT=\"no\" DEPLOY_HAPROXY_RELOAD_DEFAULT=\"true\" DEPLOY_HAPROXY_HOT_UPDATE_DEFAULT=\"no\" DEPLOY_HAPROXY_STATS_SOCKET_DEFAULT=\"UNIX:/run/haproxy/admin.sock\" _debug _cdomain \"${_cdomain}\" _debug _ckey \"${_ckey}\" _debug _ccert \"${_ccert}\" _debug _cca \"${_cca}\" _debug _cfullchain \"${_cfullchain}\" # PEM_PATH is optional. If not provided then assume \"${DEPLOY_HAPROXY_PEM_PATH_DEFAULT}\" _getdeployconf DEPLOY_HAPROXY_PEM_PATH _debug2 DEPLOY_HAPROXY_PEM_PATH \"${DEPLOY_HAPROXY_PEM_PATH}\" if [ -n \"${DEPLOY_HAPROXY_PEM_PATH}\" ]; then Le_Deploy_haproxy_pem_path=\"${DEPLOY_HAPROXY_PEM_PATH}\" _savedomainconf Le_Deploy_haproxy_pem_path \"${Le_Deploy_haproxy_pem_path}\" elif [ -z \"${Le_Deploy_haproxy_pem_path}\" ]; then Le_Deploy_haproxy_pem_path=\"${DEPLOY_HAPROXY_PEM_PATH_DEFAULT}\" fi # Ensure PEM_PATH exists if [ -d \"${Le_Deploy_haproxy_pem_path}\" ]; then _debug \"PEM_PATH ${Le_Deploy_haproxy_pem_path} exists\" else _err \"PEM_PATH ${Le_Deploy_haproxy_pem_path} does not exist\" return 1 fi # PEM_NAME is optional. If not provided then assume \"${DEPLOY_HAPROXY_PEM_NAME_DEFAULT}\" _getdeployconf DEPLOY_HAPROXY_PEM_NAME _debug2 DEPLOY_HAPROXY_PEM_NAME \"${DEPLOY_HAPROXY_PEM_NAME}\" if [ -n \"${DEPLOY_HAPROXY_PEM_NAME}\" ]; then Le_Deploy_haproxy_pem_name=\"${DEPLOY_HAPROXY_PEM_NAME}\" _savedomainconf Le_Deploy_haproxy_pem_name \"${Le_Deploy_haproxy_pem_name}\" elif [ -z \"${Le_Deploy_haproxy_pem_name}\" ]; then Le_Deploy_haproxy_pem_name=\"${DEPLOY_HAPROXY_PEM_NAME_DEFAULT}\" # We better not have '*' as the first character if [ \"${Le_Deploy_haproxy_pem_name%%\"${Le_Deploy_haproxy_pem_name#?}\"}\" = '*' ]; then # removes the first characters and add a _ instead Le_Deploy_haproxy_pem_name=\"_${Le_Deploy_haproxy_pem_name#?}\" fi fi # BUNDLE is optional. If not provided then assume \"${DEPLOY_HAPROXY_BUNDLE_DEFAULT}\" _getdeployconf DEPLOY_HAPROXY_BUNDLE _debug2 DEPLOY_HAPROXY_BUNDLE \"${DEPLOY_HAPROXY_BUNDLE}\" if [ -n \"${DEPLOY_HAPROXY_BUNDLE}\" ]; then Le_Deploy_haproxy_bundle=\"${DEPLOY_HAPROXY_BUNDLE}\" _savedomainconf Le_Deploy_haproxy_bundle \"${Le_Deploy_haproxy_bundle}\" elif [ -z \"${Le_Deploy_haproxy_bundle}\" ]; then Le_Deploy_haproxy_bundle=\"${DEPLOY_HAPROXY_BUNDLE_DEFAULT}\" fi # ISSUER is optional. If not provided then assume \"${DEPLOY_HAPROXY_ISSUER_DEFAULT}\" _getdeployconf DEPLOY_HAPROXY_ISSUER _debug2 DEPLOY_HAPROXY_ISSUER \"${DEPLOY_HAPROXY_ISSUER}\" if [ -n \"${DEPLOY_HAPROXY_ISSUER}\" ]; then Le_Deploy_haproxy_issuer=\"${DEPLOY_HAPROXY_ISSUER}\" _savedomainconf Le_Deploy_haproxy_issuer \"${Le_Deploy_haproxy_issuer}\" elif [ -z \"${Le_Deploy_haproxy_issuer}\" ]; then Le_Deploy_haproxy_issuer=\"${DEPLOY_HAPROXY_ISSUER_DEFAULT}\" fi # RELOAD is optional. If not provided then assume \"${DEPLOY_HAPROXY_RELOAD_DEFAULT}\" _getdeployconf DEPLOY_HAPROXY_RELOAD _debug2 DEPLOY_HAPROXY_RELOAD \"${DEPLOY_HAPROXY_RELOAD}\" if [ -n \"${DEPLOY_HAPROXY_RELOAD}\" ]; then Le_Deploy_haproxy_reload=\"${DEPLOY_HAPROXY_RELOAD}\" _savedomainconf Le_Deploy_haproxy_reload \"${Le_Deploy_haproxy_reload}\" elif [ -z \"${Le_Deploy_haproxy_reload}\" ]; then Le_Deploy_haproxy_reload=\"${DEPLOY_HAPROXY_RELOAD_DEFAULT}\" fi # HOT_UPDATE is optional. If not provided then assume \"${DEPLOY_HAPROXY_HOT_UPDATE_DEFAULT}\" _getdeployconf DEPLOY_HAPROXY_HOT_UPDATE _debug2 DEPLOY_HAPROXY_HOT_UPDATE \"${DEPLOY_HAPROXY_HOT_UPDATE}\" if [ -n \"${DEPLOY_HAPROXY_HOT_UPDATE}\" ]; then Le_Deploy_haproxy_hot_update=\"${DEPLOY_HAPROXY_HOT_UPDATE}\" _savedomainconf Le_Deploy_haproxy_hot_update \"${Le_Deploy_haproxy_hot_update}\" elif [ -z \"${Le_Deploy_haproxy_hot_update}\" ]; then Le_Deploy_haproxy_hot_update=\"${DEPLOY_HAPROXY_HOT_UPDATE_DEFAULT}\" fi # STATS_SOCKET is optional. If not provided then assume \"${DEPLOY_HAPROXY_STATS_SOCKET_DEFAULT}\" _getdeployconf DEPLOY_HAPROXY_STATS_SOCKET _debug2 DEPLOY_HAPROXY_STATS_SOCKET \"${DEPLOY_HAPROXY_STATS_SOCKET}\" if [ -n \"${DEPLOY_HAPROXY_STATS_SOCKET}\" ]; then Le_Deploy_haproxy_stats_socket=\"${DEPLOY_HAPROXY_STATS_SOCKET}\" _savedomainconf Le_Deploy_haproxy_stats_socket \"${Le_Deploy_haproxy_stats_socket}\" elif [ -z \"${Le_Deploy_haproxy_stats_socket}\" ]; then Le_Deploy_haproxy_stats_socket=\"${DEPLOY_HAPROXY_STATS_SOCKET_DEFAULT}\" fi # MASTER_CLI is optional. No defaults are used. When the master CLI is used, # all commands are sent with a prefix. _getdeployconf DEPLOY_HAPROXY_MASTER_CLI _debug2 DEPLOY_HAPROXY_MASTER_CLI \"${DEPLOY_HAPROXY_MASTER_CLI}\" if [ -n \"${DEPLOY_HAPROXY_MASTER_CLI}\" ]; then Le_Deploy_haproxy_stats_socket=\"${DEPLOY_HAPROXY_MASTER_CLI}\" _savedomainconf Le_Deploy_haproxy_stats_socket \"${Le_Deploy_haproxy_stats_socket}\" _cmdpfx=\"@1 \" # command prefix used for master CLI only. fi # Set the suffix depending if we are creating a bundle or not if [ \"${Le_Deploy_haproxy_bundle}\" = \"yes\" ]; then _info \"Bundle creation requested\" # Initialise $Le_Keylength if its not already set if [ -z \"${Le_Keylength}\" ]; then Le_Keylength=\"\" fi if _isEccKey \"${Le_Keylength}\"; then _info \"ECC key type detected\" _suffix=\".ecdsa\" else _info \"RSA key type detected\" _suffix=\".rsa\" fi else _suffix=\"\" fi _debug _suffix \"${_suffix}\" # Set variables for later _pem=\"${Le_Deploy_haproxy_pem_path}/${Le_Deploy_haproxy_pem_name}${_suffix}\" _issuer=\"${_pem}.issuer\" _ocsp=\"${_pem}.ocsp\" _reload=\"${Le_Deploy_haproxy_reload}\" _statssock=\"${Le_Deploy_haproxy_stats_socket}\" _info \"Deploying PEM file\" # Create a temporary PEM file _temppem=\"$(_mktemp)\" _debug _temppem \"${_temppem}\" cat \"${_ccert}\" \"${_cca}\" \"${_ckey}\" | grep . >\"${_temppem}\" _ret=\"$?\" # Check that we could create the temporary file if [ \"${_ret}\" != \"0\" ]; then _err \"Error code ${_ret} returned during PEM file creation\" [ -f \"${_temppem}\" ] && rm -f \"${_temppem}\" return ${_ret} fi # Move PEM file into place _info \"Moving new certificate into place\" _debug _pem \"${_pem}\" cat \"${_temppem}\" >\"${_pem}\" _ret=$? # Clean up temp file [ -f \"${_temppem}\" ] && rm -f \"${_temppem}\" # Deal with any failure of moving PEM file into place if [ \"${_ret}\" != \"0\" ]; then _err \"Error code ${_ret} returned while moving new certificate into place\" return ${_ret} fi # Update .issuer file if requested if [ \"${Le_Deploy_haproxy_issuer}\" = \"yes\" ]; then _info \"Updating .issuer file\" _debug _issuer \"${_issuer}\" cat \"${_cca}\" >\"${_issuer}\" _ret=\"$?\" if [ \"${_ret}\" != \"0\" ]; then _err \"Error code ${_ret} returned while copying issuer/CA certificate into place\" return ${_ret} fi else [ -f \"${_issuer}\" ] && _err \"Issuer file update not requested but .issuer file exists\" fi # Update .ocsp file if certificate was requested with --ocsp/--ocsp-must-staple option if [ -z \"${Le_OCSP_Staple}\" ]; then Le_OCSP_Staple=\"0\" fi if [ \"${Le_OCSP_Staple}\" = \"1\" ]; then _info \"Updating OCSP stapling info\" _debug _ocsp \"${_ocsp}\" _info \"Extracting OCSP URL\" _ocsp_url=$(${ACME_OPENSSL_BIN:-openssl} x509 -noout -ocsp_uri -in \"${_pem}\") _debug _ocsp_url \"${_ocsp_url}\" # Only process OCSP if URL was present if [ \"${_ocsp_url}\" != \"\" ]; then # Extract the hostname from the OCSP URL _info \"Extracting OCSP URL\" _ocsp_host=$(echo \"${_ocsp_url}\" | cut -d/ -f3) _debug _ocsp_host \"${_ocsp_host}\" # Only process the certificate if we have a .issuer file if [ -r \"${_issuer}\" ]; then # Check if issuer cert is also a root CA cert _subjectdn=$(${ACME_OPENSSL_BIN:-openssl} x509 -in \"${_issuer}\" -subject -noout | cut -d'/' -f2,3,4,5,6,7,8,9,10) _debug _subjectdn \"${_subjectdn}\" _issuerdn=$(${ACME_OPENSSL_BIN:-openssl} x509 -in \"${_issuer}\" -issuer -noout | cut -d'/' -f2,3,4,5,6,7,8,9,10) _debug _issuerdn \"${_issuerdn}\" _info \"Requesting OCSP response\" # If the issuer is a CA cert then our command line has \"-CAfile\" added if [ \"${_subjectdn}\" = \"${_issuerdn}\" ]; then _cafile_argument=\"-CAfile \\\"${_issuer}\\\"\" else _cafile_argument=\"\" fi _debug _cafile_argument \"${_cafile_argument}\" # if OpenSSL/LibreSSL is v1.1 or above, the format for the -header option has changed _openssl_version=$(${ACME_OPENSSL_BIN:-openssl} version | cut -d' ' -f2) _debug _openssl_version \"${_openssl_version}\" _openssl_major=$(echo \"${_openssl_version}\" | cut -d '.' -f1) _openssl_minor=$(echo \"${_openssl_version}\" | cut -d '.' -f2) if [ \"${_openssl_major}\" -eq \"1\" ] && [ \"${_openssl_minor}\" -ge \"1\" ] || [ \"${_openssl_major}\" -ge \"2\" ]; then _header_sep=\"=\" else _header_sep=\" \" fi # Request the OCSP response from the issuer and store it _openssl_ocsp_cmd=\"${ACME_OPENSSL_BIN:-openssl} ocsp \\ -issuer \\\"${_issuer}\\\" \\ -cert \\\"${_pem}\\\" \\ -url \\\"${_ocsp_url}\\\" \\ -header Host${_header_sep}\\\"${_ocsp_host}\\\" \\ -respout \\\"${_ocsp}\\\" \\ -verify_other \\\"${_issuer}\\\" \\ ${_cafile_argument} \\ | grep -q \\\"${_pem}: good\\\"\" _debug _openssl_ocsp_cmd \"${_openssl_ocsp_cmd}\" eval \"${_openssl_ocsp_cmd}\" _ret=$? else # Non fatal: No issuer file was present so no OCSP stapling file created _err \"OCSP stapling in use but no .issuer file was present\" fi else # Non fatal: No OCSP url was found int the certificate _err \"OCSP update requested but no OCSP URL was found in certificate\" fi # Non fatal: Check return code of openssl command if [ \"${_ret}\" != \"0\" ]; then _err \"Updating OCSP stapling failed with return code ${_ret}\" fi else # An OCSP file was already present but certificate did not have OCSP extension if [ -f \"${_ocsp}\" ]; then _err \"OCSP was not requested but .ocsp file exists.\" # Could remove the file at this step, although HAProxy just ignores it in this case # rm -f \"${_ocsp}\" || _err \"Problem removing stale .ocsp file\" fi fi if [ \"${Le_Deploy_haproxy_hot_update}\" = \"yes\" ]; then # set the socket name for messages if [ -n \"${_cmdpfx}\" ]; then _socketname=\"master CLI\" else _socketname=\"stats socket\" fi # Update certificate over HAProxy stats socket or master CLI. if _exists socat; then # look for the certificate on the stats socket, to chose between updating or creating one _socat_cert_cmd=\"echo '${_cmdpfx}show ssl cert' | socat '${_statssock}' - | grep -q '^${_pem}$'\" _debug _socat_cert_cmd \"${_socat_cert_cmd}\" eval \"${_socat_cert_cmd}\" _ret=$? if [ \"${_ret}\" != \"0\" ]; then _newcert=\"1\" _info \"Creating new certificate '${_pem}' over HAProxy ${_socketname}.\" # certificate wasn't found, it's a new one. We should check if the crt-list exists and creates/inserts the certificate. _socat_crtlist_show_cmd=\"echo '${_cmdpfx}show ssl crt-list' | socat '${_statssock}' - | grep -q '^${Le_Deploy_haproxy_pem_path}$'\" _debug _socat_crtlist_show_cmd \"${_socat_crtlist_show_cmd}\" eval \"${_socat_crtlist_show_cmd}\" _ret=$? if [ \"${_ret}\" != \"0\" ]; then _err \"Couldn't find '${Le_Deploy_haproxy_pem_path}' in haproxy 'show ssl crt-list'\" return \"${_ret}\" fi # create a new certificate _socat_new_cmd=\"echo '${_cmdpfx}new ssl cert ${_pem}' | socat '${_statssock}' - | grep -q 'New empty'\" _debug _socat_new_cmd \"${_socat_new_cmd}\" eval \"${_socat_new_cmd}\" _ret=$? if [ \"${_ret}\" != \"0\" ]; then _err \"Couldn't create '${_pem}' in haproxy\" return \"${_ret}\" fi else _info \"Update existing certificate '${_pem}' over HAProxy ${_socketname}.\" fi _socat_cert_set_cmd=\"echo -e '${_cmdpfx}set ssl cert ${_pem} <<\\n$(cat \"${_pem}\")\\n' | socat '${_statssock}' - | grep -q 'Transaction created'\" _debug _socat_cert_set_cmd \"${_socat_cert_set_cmd}\" eval \"${_socat_cert_set_cmd}\" _ret=$? if [ \"${_ret}\" != \"0\" ]; then _err \"Can't update '${_pem}' in haproxy\" return \"${_ret}\" fi _socat_cert_commit_cmd=\"echo '${_cmdpfx}commit ssl cert ${_pem}' | socat '${_statssock}' - | grep -q '^Success!$'\" _debug _socat_cert_commit_cmd \"${_socat_cert_commit_cmd}\" eval \"${_socat_cert_commit_cmd}\" _ret=$? if [ \"${_ret}\" != \"0\" ]; then _err \"Can't commit '${_pem}' in haproxy\" return ${_ret} fi if [ \"${_newcert}\" = \"1\" ]; then # if this is a new certificate, it needs to be inserted into the crt-list` _socat_cert_add_cmd=\"echo '${_cmdpfx}add ssl crt-list ${Le_Deploy_haproxy_pem_path} ${_pem}' | socat '${_statssock}' - | grep -q 'Success!'\" _debug _socat_cert_add_cmd \"${_socat_cert_add_cmd}\" eval \"${_socat_cert_add_cmd}\" _ret=$? if [ \"${_ret}\" != \"0\" ]; then _err \"Can't update '${_pem}' in haproxy\" return \"${_ret}\" fi fi else _err \"'socat' is not available, couldn't update over ${_socketname}\" fi else # Reload HAProxy _debug _reload \"${_reload}\" eval \"${_reload}\" _ret=$? if [ \"${_ret}\" != \"0\" ]; then _err \"Error code ${_ret} during reload\" return ${_ret} else _info \"Reload successful\" fi fi return 0 }"
        },
        {
            "filename": "file_128.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_128.sh",
            "content": "#!/usr/bin/env sh ######## Public functions ##################### #domain keyfile certfile cafile fullchain keychain_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" /usr/bin/security import \"$_ckey\" -k \"/Library/Keychains/System.keychain\" /usr/bin/security import \"$_ccert\" -k \"/Library/Keychains/System.keychain\" /usr/bin/security import \"$_cca\" -k \"/Library/Keychains/System.keychain\" /usr/bin/security import \"$_cfullchain\" -k \"/Library/Keychains/System.keychain\" return 0 }"
        },
        {
            "filename": "file_129.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_129.sh",
            "content": "#!/usr/bin/env sh # If certificate already exists it will update only cert and key, not touching other parameters # If certificate doesn't exist it will only upload cert and key, and not set other parameters # Note that we deploy full chain # Written by Geoffroi Genot <ggenot@voxbone.com> ######## Public functions ##################### #domain keyfile certfile cafile fullchain kong_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _info \"Deploying certificate on Kong instance\" if [ -z \"$KONG_URL\" ]; then _debug \"KONG_URL Not set, using default http://localhost:8001\" KONG_URL=\"http://localhost:8001\" fi _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" #Get ssl_uuid linked to the domain ssl_uuid=$(_get \"$KONG_URL/certificates/$_cdomain\" | _normalizeJson | _egrep_o '[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}') if [ -z \"$ssl_uuid\" ]; then _debug \"Unable to get Kong ssl_uuid for domain $_cdomain\" _debug \"Make sure that KONG_URL is correctly configured\" _debug \"Make sure that a Kong certificate match the sni\" _debug \"Kong url: $KONG_URL\" _info \"No existing certificate, creating...\" #return 1 fi #Save kong url if it's succesful (First run case) _saveaccountconf KONG_URL \"$KONG_URL\" #Generate DEIM delim=\"-----MultipartDelimiter$(date \"+%s%N\")\" nl=\"\\015\\012\" #Set Header _H1=\"Content-Type: multipart/form-data; boundary=$delim\" #Generate data for request (Multipart/form-data with mixed content) if [ -z \"$ssl_uuid\" ]; then #set sni to domain content=\"--$delim${nl}Content-Disposition: form-data; name=\\\"snis[]\\\"${nl}${nl}$_cdomain\" fi #add key content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"key\\\"; filename=\\\"$(basename \"$_ckey\")\\\"${nl}Content-Type: application/octet-stream${nl}${nl}$(cat \"$_ckey\")\" #Add cert content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"cert\\\"; filename=\\\"$(basename \"$_cfullchain\")\\\"${nl}Content-Type: application/octet-stream${nl}${nl}$(cat \"$_cfullchain\")\" #Close multipart content=\"$content${nl}--$delim--${nl}\" #Convert CRLF content=$(printf %b \"$content\") #DEBUG _debug header \"$_H1\" _debug content \"$content\" #Check if sslcreated (if not => POST else => PATCH) if [ -z \"$ssl_uuid\" ]; then #Post certificate to Kong response=$(_post \"$content\" \"$KONG_URL/certificates\" \"\" \"POST\") else #patch response=$(_post \"$content\" \"$KONG_URL/certificates/$ssl_uuid\" \"\" \"PATCH\") fi if ! [ \"$(echo \"$response\" | _egrep_o \"created_at\")\" = \"created_at\" ]; then _err \"An error occurred with cert upload. Check response:\" _err \"$response\" return 1 fi _debug response \"$response\" _info \"Certificate successfully deployed\" }"
        },
        {
            "filename": "file_130.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_130.sh",
            "content": "#!/usr/bin/env sh # Script for acme.sh to deploy certificates to lighttpd # # The following variables can be exported: # # export DEPLOY_LIGHTTPD_PEM_NAME=\"${domain}.pem\" # # Defines the name of the PEM file. # Defaults to \"<domain>.pem\" # # export DEPLOY_LIGHTTPD_PEM_PATH=\"/etc/lighttpd\" # # Defines location of PEM file for Lighttpd. # Defaults to /etc/lighttpd # # export DEPLOY_LIGHTTPD_RELOAD=\"systemctl reload lighttpd\" # # OPTIONAL: Reload command used post deploy # This defaults to be a no-op (ie \"true\"). # It is strongly recommended to set this something that makes sense # for your distro. # # export DEPLOY_LIGHTTPD_ISSUER=\"yes\" # # OPTIONAL: Places CA file as \"${DEPLOY_LIGHTTPD_PEM}.issuer\" # Note: Required for OCSP stapling to work # # export DEPLOY_LIGHTTPD_BUNDLE=\"no\" # # OPTIONAL: Deploy this certificate as part of a multi-cert bundle # This adds a suffix to the certificate based on the certificate type # eg RSA certificates will have .rsa as a suffix to the file name # Lighttpd will load all certificates and provide one or the other # depending on client capabilities # Note: This functionality requires Lighttpd was compiled against # a version of OpenSSL that supports this. # ######## Public functions ##################### #domain keyfile certfile cafile fullchain lighttpd_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" # Some defaults DEPLOY_LIGHTTPD_PEM_PATH_DEFAULT=\"/etc/lighttpd\" DEPLOY_LIGHTTPD_PEM_NAME_DEFAULT=\"${_cdomain}.pem\" DEPLOY_LIGHTTPD_BUNDLE_DEFAULT=\"no\" DEPLOY_LIGHTTPD_ISSUER_DEFAULT=\"yes\" DEPLOY_LIGHTTPD_RELOAD_DEFAULT=\"true\" _debug _cdomain \"${_cdomain}\" _debug _ckey \"${_ckey}\" _debug _ccert \"${_ccert}\" _debug _cca \"${_cca}\" _debug _cfullchain \"${_cfullchain}\" # PEM_PATH is optional. If not provided then assume \"${DEPLOY_LIGHTTPD_PEM_PATH_DEFAULT}\" _getdeployconf DEPLOY_LIGHTTPD_PEM_PATH _debug2 DEPLOY_LIGHTTPD_PEM_PATH \"${DEPLOY_LIGHTTPD_PEM_PATH}\" if [ -n \"${DEPLOY_LIGHTTPD_PEM_PATH}\" ]; then Le_Deploy_lighttpd_pem_path=\"${DEPLOY_LIGHTTPD_PEM_PATH}\" _savedomainconf Le_Deploy_lighttpd_pem_path \"${Le_Deploy_lighttpd_pem_path}\" elif [ -z \"${Le_Deploy_lighttpd_pem_path}\" ]; then Le_Deploy_lighttpd_pem_path=\"${DEPLOY_LIGHTTPD_PEM_PATH_DEFAULT}\" fi # Ensure PEM_PATH exists if [ -d \"${Le_Deploy_lighttpd_pem_path}\" ]; then _debug \"PEM_PATH ${Le_Deploy_lighttpd_pem_path} exists\" else _err \"PEM_PATH ${Le_Deploy_lighttpd_pem_path} does not exist\" return 1 fi # PEM_NAME is optional. If not provided then assume \"${DEPLOY_LIGHTTPD_PEM_NAME_DEFAULT}\" _getdeployconf DEPLOY_LIGHTTPD_PEM_NAME _debug2 DEPLOY_LIGHTTPD_PEM_NAME \"${DEPLOY_LIGHTTPD_PEM_NAME}\" if [ -n \"${DEPLOY_LIGHTTPD_PEM_NAME}\" ]; then Le_Deploy_lighttpd_pem_name=\"${DEPLOY_LIGHTTPD_PEM_NAME}\" _savedomainconf Le_Deploy_lighttpd_pem_name \"${Le_Deploy_lighttpd_pem_name}\" elif [ -z \"${Le_Deploy_lighttpd_pem_name}\" ]; then Le_Deploy_lighttpd_pem_name=\"${DEPLOY_LIGHTTPD_PEM_NAME_DEFAULT}\" fi # BUNDLE is optional. If not provided then assume \"${DEPLOY_LIGHTTPD_BUNDLE_DEFAULT}\" _getdeployconf DEPLOY_LIGHTTPD_BUNDLE _debug2 DEPLOY_LIGHTTPD_BUNDLE \"${DEPLOY_LIGHTTPD_BUNDLE}\" if [ -n \"${DEPLOY_LIGHTTPD_BUNDLE}\" ]; then Le_Deploy_lighttpd_bundle=\"${DEPLOY_LIGHTTPD_BUNDLE}\" _savedomainconf Le_Deploy_lighttpd_bundle \"${Le_Deploy_lighttpd_bundle}\" elif [ -z \"${Le_Deploy_lighttpd_bundle}\" ]; then Le_Deploy_lighttpd_bundle=\"${DEPLOY_LIGHTTPD_BUNDLE_DEFAULT}\" fi # ISSUER is optional. If not provided then assume \"${DEPLOY_LIGHTTPD_ISSUER_DEFAULT}\" _getdeployconf DEPLOY_LIGHTTPD_ISSUER _debug2 DEPLOY_LIGHTTPD_ISSUER \"${DEPLOY_LIGHTTPD_ISSUER}\" if [ -n \"${DEPLOY_LIGHTTPD_ISSUER}\" ]; then Le_Deploy_lighttpd_issuer=\"${DEPLOY_LIGHTTPD_ISSUER}\" _savedomainconf Le_Deploy_lighttpd_issuer \"${Le_Deploy_lighttpd_issuer}\" elif [ -z \"${Le_Deploy_lighttpd_issuer}\" ]; then Le_Deploy_lighttpd_issuer=\"${DEPLOY_LIGHTTPD_ISSUER_DEFAULT}\" fi # RELOAD is optional. If not provided then assume \"${DEPLOY_LIGHTTPD_RELOAD_DEFAULT}\" _getdeployconf DEPLOY_LIGHTTPD_RELOAD _debug2 DEPLOY_LIGHTTPD_RELOAD \"${DEPLOY_LIGHTTPD_RELOAD}\" if [ -n \"${DEPLOY_LIGHTTPD_RELOAD}\" ]; then Le_Deploy_lighttpd_reload=\"${DEPLOY_LIGHTTPD_RELOAD}\" _savedomainconf Le_Deploy_lighttpd_reload \"${Le_Deploy_lighttpd_reload}\" elif [ -z \"${Le_Deploy_lighttpd_reload}\" ]; then Le_Deploy_lighttpd_reload=\"${DEPLOY_LIGHTTPD_RELOAD_DEFAULT}\" fi # Set the suffix depending if we are creating a bundle or not if [ \"${Le_Deploy_lighttpd_bundle}\" = \"yes\" ]; then _info \"Bundle creation requested\" # Initialise $Le_Keylength if its not already set if [ -z \"${Le_Keylength}\" ]; then Le_Keylength=\"\" fi if _isEccKey \"${Le_Keylength}\"; then _info \"ECC key type detected\" _suffix=\".ecdsa\" else _info \"RSA key type detected\" _suffix=\".rsa\" fi else _suffix=\"\" fi _debug _suffix \"${_suffix}\" # Set variables for later _pem=\"${Le_Deploy_lighttpd_pem_path}/${Le_Deploy_lighttpd_pem_name}${_suffix}\" _issuer=\"${_pem}.issuer\" _ocsp=\"${_pem}.ocsp\" _reload=\"${Le_Deploy_lighttpd_reload}\" _info \"Deploying PEM file\" # Create a temporary PEM file _temppem=\"$(_mktemp)\" _debug _temppem \"${_temppem}\" cat \"${_ckey}\" \"${_ccert}\" \"${_cca}\" >\"${_temppem}\" _ret=\"$?\" # Check that we could create the temporary file if [ \"${_ret}\" != \"0\" ]; then _err \"Error code ${_ret} returned during PEM file creation\" [ -f \"${_temppem}\" ] && rm -f \"${_temppem}\" return ${_ret} fi # Move PEM file into place _info \"Moving new certificate into place\" _debug _pem \"${_pem}\" cat \"${_temppem}\" >\"${_pem}\" _ret=$? # Clean up temp file [ -f \"${_temppem}\" ] && rm -f \"${_temppem}\" # Deal with any failure of moving PEM file into place if [ \"${_ret}\" != \"0\" ]; then _err \"Error code ${_ret} returned while moving new certificate into place\" return ${_ret} fi # Update .issuer file if requested if [ \"${Le_Deploy_lighttpd_issuer}\" = \"yes\" ]; then _info \"Updating .issuer file\" _debug _issuer \"${_issuer}\" cat \"${_cca}\" >\"${_issuer}\" _ret=\"$?\" if [ \"${_ret}\" != \"0\" ]; then _err \"Error code ${_ret} returned while copying issuer/CA certificate into place\" return ${_ret} fi else [ -f \"${_issuer}\" ] && _err \"Issuer file update not requested but .issuer file exists\" fi # Update .ocsp file if certificate was requested with --ocsp/--ocsp-must-staple option if [ -z \"${Le_OCSP_Staple}\" ]; then Le_OCSP_Staple=\"0\" fi if [ \"${Le_OCSP_Staple}\" = \"1\" ]; then _info \"Updating OCSP stapling info\" _debug _ocsp \"${_ocsp}\" _info \"Extracting OCSP URL\" _ocsp_url=$(${ACME_OPENSSL_BIN:-openssl} x509 -noout -ocsp_uri -in \"${_pem}\") _debug _ocsp_url \"${_ocsp_url}\" # Only process OCSP if URL was present if [ \"${_ocsp_url}\" != \"\" ]; then # Extract the hostname from the OCSP URL _info \"Extracting OCSP URL\" _ocsp_host=$(echo \"${_ocsp_url}\" | cut -d/ -f3) _debug _ocsp_host \"${_ocsp_host}\" # Only process the certificate if we have a .issuer file if [ -r \"${_issuer}\" ]; then # Check if issuer cert is also a root CA cert _subjectdn=$(${ACME_OPENSSL_BIN:-openssl} x509 -in \"${_issuer}\" -subject -noout | cut -d'/' -f2,3,4,5,6,7,8,9,10) _debug _subjectdn \"${_subjectdn}\" _issuerdn=$(${ACME_OPENSSL_BIN:-openssl} x509 -in \"${_issuer}\" -issuer -noout | cut -d'/' -f2,3,4,5,6,7,8,9,10) _debug _issuerdn \"${_issuerdn}\" _info \"Requesting OCSP response\" # If the issuer is a CA cert then our command line has \"-CAfile\" added if [ \"${_subjectdn}\" = \"${_issuerdn}\" ]; then _cafile_argument=\"-CAfile \\\"${_issuer}\\\"\" else _cafile_argument=\"\" fi _debug _cafile_argument \"${_cafile_argument}\" # if OpenSSL/LibreSSL is v1.1 or above, the format for the -header option has changed _openssl_version=$(${ACME_OPENSSL_BIN:-openssl} version | cut -d' ' -f2) _debug _openssl_version \"${_openssl_version}\" _openssl_major=$(echo \"${_openssl_version}\" | cut -d '.' -f1) _openssl_minor=$(echo \"${_openssl_version}\" | cut -d '.' -f2) if [ \"${_openssl_major}\" -eq \"1\" ] && [ \"${_openssl_minor}\" -ge \"1\" ] || [ \"${_openssl_major}\" -ge \"2\" ]; then _header_sep=\"=\" else _header_sep=\" \" fi # Request the OCSP response from the issuer and store it _openssl_ocsp_cmd=\"${ACME_OPENSSL_BIN:-openssl} ocsp \\ -issuer \\\"${_issuer}\\\" \\ -cert \\\"${_pem}\\\" \\ -url \\\"${_ocsp_url}\\\" \\ -header Host${_header_sep}\\\"${_ocsp_host}\\\" \\ -respout \\\"${_ocsp}\\\" \\ -verify_other \\\"${_issuer}\\\" \\ ${_cafile_argument} \\ | grep -q \\\"${_pem}: good\\\"\" _debug _openssl_ocsp_cmd \"${_openssl_ocsp_cmd}\" eval \"${_openssl_ocsp_cmd}\" _ret=$? else # Non fatal: No issuer file was present so no OCSP stapling file created _err \"OCSP stapling in use but no .issuer file was present\" fi else # Non fatal: No OCSP url was found int the certificate _err \"OCSP update requested but no OCSP URL was found in certificate\" fi # Non fatal: Check return code of openssl command if [ \"${_ret}\" != \"0\" ]; then _err \"Updating OCSP stapling failed with return code ${_ret}\" fi else # An OCSP file was already present but certificate did not have OCSP extension if [ -f \"${_ocsp}\" ]; then _err \"OCSP was not requested but .ocsp file exists.\" # Could remove the file at this step, although Lighttpd just ignores it in this case # rm -f \"${_ocsp}\" || _err \"Problem removing stale .ocsp file\" fi fi # Reload Lighttpd _debug _reload \"${_reload}\" eval \"${_reload}\" _ret=$? if [ \"${_ret}\" != \"0\" ]; then _err \"Error code ${_ret} during reload\" return ${_ret} else _info \"Reload successful\" fi return 0 }"
        },
        {
            "filename": "file_131.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_131.sh",
            "content": "#!/usr/bin/env sh #Here is a script to deploy cert to mailcow. #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain mailcow_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _getdeployconf DEPLOY_MAILCOW_PATH _getdeployconf DEPLOY_MAILCOW_RELOAD _debug DEPLOY_MAILCOW_PATH \"$DEPLOY_MAILCOW_PATH\" _debug DEPLOY_MAILCOW_RELOAD \"$DEPLOY_MAILCOW_RELOAD\" if [ -z \"$DEPLOY_MAILCOW_PATH\" ]; then _err \"Mailcow path is not found, please define DEPLOY_MAILCOW_PATH.\" return 1 fi _savedeployconf DEPLOY_MAILCOW_PATH \"$DEPLOY_MAILCOW_PATH\" [ -n \"$DEPLOY_MAILCOW_RELOAD\" ] && _savedeployconf DEPLOY_MAILCOW_RELOAD \"$DEPLOY_MAILCOW_RELOAD\" _ssl_path=\"$DEPLOY_MAILCOW_PATH\" if [ -f \"$DEPLOY_MAILCOW_PATH/generate_config.sh\" ]; then _ssl_path=\"$DEPLOY_MAILCOW_PATH/data/assets/ssl/\" fi if [ ! -d \"$_ssl_path\" ]; then _err \"Cannot find mailcow ssl path: $_ssl_path\" return 1 fi _info \"Copying key and cert\" _real_key=\"$_ssl_path/key.pem\" if ! cat \"$_ckey\" >\"$_real_key\"; then _err \"Error: write key file to: $_real_key\" return 1 fi _real_fullchain=\"$_ssl_path/cert.pem\" if ! cat \"$_cfullchain\" >\"$_real_fullchain\"; then _err \"Error: write cert file to: $_real_fullchain\" return 1 fi DEFAULT_MAILCOW_RELOAD=\"docker restart \\$(docker ps --quiet --filter name=nginx-mailcow --filter name=dovecot-mailcow --filter name=postfix-mailcow)\" _reload=\"${DEPLOY_MAILCOW_RELOAD:-$DEFAULT_MAILCOW_RELOAD}\" _info \"Run reload: $_reload\" if eval \"$_reload\"; then _info \"Reload success!\" fi return 0 }"
        },
        {
            "filename": "file_132.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_132.sh",
            "content": "#!/usr/bin/env sh #Here is a sample custom api script. #This file name is \"myapi.sh\" #So, here must be a method myapi_deploy() #Which will be called by acme.sh to deploy the cert #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain myapi_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _err \"Not implemented yet\" return 1 }"
        },
        {
            "filename": "file_133.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_133.sh",
            "content": "#!/usr/bin/env sh # MyDevil.net API (2019-02-03) # # MyDevil.net already supports automatic Let's Encrypt certificates, # except for wildcard domains. # # This script depends on `devil` command that MyDevil.net provides, # which means that it works only on server side. # # Author: Marcin Konicki <https://ahwayakchih.neoni.net> # ######## Public functions ##################### # Usage: mydevil_deploy domain keyfile certfile cafile fullchain mydevil_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" ip=\"\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" if ! _exists \"devil\"; then _err \"Could not find 'devil' command.\" return 1 fi ip=$(mydevil_get_ip \"$_cdomain\") if [ -z \"$ip\" ]; then _err \"Could not find IP for domain $_cdomain.\" return 1 fi # Delete old certificate first _info \"Removing old certificate for $_cdomain at $ip\" devil ssl www del \"$ip\" \"$_cdomain\" # Add new certificate _info \"Adding new certificate for $_cdomain at $ip\" devil ssl www add \"$ip\" \"$_cfullchain\" \"$_ckey\" \"$_cdomain\" || return 1 return 0 } #################### Private functions below ################################## # Usage: ip=$(mydevil_get_ip domain.com) # echo $ip mydevil_get_ip() { devil dns list \"$1\" | cut -w -s -f 3,7 | grep \"^A$(printf '\\t')\" | cut -w -s -f 2 || return 1 return 0 }"
        },
        {
            "filename": "file_134.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_134.sh",
            "content": "#!/usr/bin/env sh #Here is a script to deploy cert to mysqld server. #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain mysqld_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _err \"deploy cert to mysqld server, Not implemented yet\" return 1 }"
        },
        {
            "filename": "file_135.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_135.sh",
            "content": "#!/usr/bin/env sh #Here is a script to deploy cert to nginx server. #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain nginx_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _err \"deploy cert to nginx server, Not implemented yet\" return 1 }"
        },
        {
            "filename": "file_136.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_136.sh",
            "content": "#!/usr/bin/env sh # This deploy hook is tested on OpenMediaVault 5.x. It supports both local and remote deployment. # The way it works is that if a cert with the matching domain name is not found, it will firstly create a dummy cert to get its uuid, and then replace it with your cert. # # DEPLOY_OMV_WEBUI_ADMIN - This is OMV web gui admin account. Default value is admin. It's required as the user parameter (-u) for the omv-rpc command. # DEPLOY_OMV_HOST and DEPLOY_OMV_SSH_USER are optional. They are used for remote deployment through ssh (support public key authentication only). Per design, OMV web gui admin doesn't have ssh permission, so another account is needed for ssh. # # returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain openmediavault_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _getdeployconf DEPLOY_OMV_WEBUI_ADMIN if [ -z \"$DEPLOY_OMV_WEBUI_ADMIN\" ]; then DEPLOY_OMV_WEBUI_ADMIN=\"admin\" fi _savedeployconf DEPLOY_OMV_WEBUI_ADMIN \"$DEPLOY_OMV_WEBUI_ADMIN\" _getdeployconf DEPLOY_OMV_HOST _getdeployconf DEPLOY_OMV_SSH_USER if [ -n \"$DEPLOY_OMV_HOST\" ] && [ -n \"$DEPLOY_OMV_SSH_USER\" ]; then _info \"[OMV deploy-hook] Deploy certificate remotely through ssh.\" _savedeployconf DEPLOY_OMV_HOST \"$DEPLOY_OMV_HOST\" _savedeployconf DEPLOY_OMV_SSH_USER \"$DEPLOY_OMV_SSH_USER\" else _info \"[OMV deploy-hook] Deploy certificate locally.\" fi if [ -n \"$DEPLOY_OMV_HOST\" ] && [ -n \"$DEPLOY_OMV_SSH_USER\" ]; then _command=\"omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'CertificateMgmt' 'getList' '{\\\"start\\\": 0, \\\"limit\\\": -1}' | jq -r '.data[] | select(.name==\\\"/CN='$_cdomain'\\\") | .uuid'\" # shellcheck disable=SC2029 _uuid=$(ssh \"$DEPLOY_OMV_SSH_USER@$DEPLOY_OMV_HOST\" \"$_command\") _debug _command \"$_command\" if [ -z \"$_uuid\" ]; then _info \"[OMV deploy-hook] Domain $_cdomain has no certificate in openmediavault, creating it!\" _command=\"omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'CertificateMgmt' 'create' '{\\\"cn\\\": \\\"test.example.com\\\", \\\"size\\\": 4096, \\\"days\\\": 3650, \\\"c\\\": \\\"\\\", \\\"st\\\": \\\"\\\", \\\"l\\\": \\\"\\\", \\\"o\\\": \\\"\\\", \\\"ou\\\": \\\"\\\", \\\"email\\\": \\\"\\\"}' | jq -r '.uuid'\" # shellcheck disable=SC2029 _uuid=$(ssh \"$DEPLOY_OMV_SSH_USER@$DEPLOY_OMV_HOST\" \"$_command\") _debug _command \"$_command\" if [ -z \"$_uuid\" ]; then _err \"[OMV deploy-hook] An error occured while creating the certificate\" return 1 fi fi _info \"[OMV deploy-hook] Domain $_cdomain has uuid: $_uuid\" _fullchain=$(jq <\"$_cfullchain\" -aRs .) _key=$(jq <\"$_ckey\" -aRs .) _debug _fullchain \"$_fullchain\" _debug _key \"$_key\" _info \"[OMV deploy-hook] Updating key and certificate in openmediavault\" _command=\"omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'CertificateMgmt' 'set' '{\\\"uuid\\\":\\\"$_uuid\\\", \\\"certificate\\\":$_fullchain, \\\"privatekey\\\":$_key, \\\"comment\\\":\\\"acme.sh deployed $(date)\\\"}'\" # shellcheck disable=SC2029 _result=$(ssh \"$DEPLOY_OMV_SSH_USER@$DEPLOY_OMV_HOST\" \"$_command\") _debug _command \"$_command\" _debug _result \"$_result\" _command=\"omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'WebGui' 'setSettings' \\$(omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'WebGui' 'getSettings' | jq -c '.sslcertificateref=\\\"$_uuid\\\"')\" # shellcheck disable=SC2029 _result=$(ssh \"$DEPLOY_OMV_SSH_USER@$DEPLOY_OMV_HOST\" \"$_command\") _debug _command \"$_command\" _debug _result \"$_result\" _info \"[OMV deploy-hook] Asking openmediavault to apply changes... (this could take some time, hang in there)\" _command=\"omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'Config' 'applyChanges' '{\\\"modules\\\":[], \\\"force\\\": false}'\" # shellcheck disable=SC2029 _result=$(ssh \"$DEPLOY_OMV_SSH_USER@$DEPLOY_OMV_HOST\" \"$_command\") _debug _command \"$_command\" _debug _result \"$_result\" _info \"[OMV deploy-hook] Asking nginx to reload\" _command=\"nginx -s reload\" # shellcheck disable=SC2029 _result=$(ssh \"$DEPLOY_OMV_SSH_USER@$DEPLOY_OMV_HOST\" \"$_command\") _debug _command \"$_command\" _debug _result \"$_result\" else # shellcheck disable=SC2086 _uuid=$(omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'CertificateMgmt' 'getList' '{\"start\": 0, \"limit\": -1}' | jq -r '.data[] | select(.name==\"/CN='$_cdomain'\") | .uuid') if [ -z \"$_uuid\" ]; then _info \"[OMV deploy-hook] Domain $_cdomain has no certificate in openmediavault, creating it!\" # shellcheck disable=SC2086 _uuid=$(omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'CertificateMgmt' 'create' '{\"cn\": \"test.example.com\", \"size\": 4096, \"days\": 3650, \"c\": \"\", \"st\": \"\", \"l\": \"\", \"o\": \"\", \"ou\": \"\", \"email\": \"\"}' | jq -r '.uuid') if [ -z \"$_uuid\" ]; then _err \"[OMB deploy-hook] An error occured while creating the certificate\" return 1 fi fi _info \"[OMV deploy-hook] Domain $_cdomain has uuid: $_uuid\" _fullchain=$(jq <\"$_cfullchain\" -aRs .) _key=$(jq <\"$_ckey\" -aRs .) _debug _fullchain \"$_fullchain\" _debug _key \"$_key\" _info \"[OMV deploy-hook] Updating key and certificate in openmediavault\" _command=\"omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'CertificateMgmt' 'set' '{\\\"uuid\\\":\\\"$_uuid\\\", \\\"certificate\\\":$_fullchain, \\\"privatekey\\\":$_key, \\\"comment\\\":\\\"acme.sh deployed $(date)\\\"}'\" _result=$(eval \"$_command\") _debug _command \"$_command\" _debug _result \"$_result\" _command=\"omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'WebGui' 'setSettings' \\$(omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'WebGui' 'getSettings' | jq -c '.sslcertificateref=\\\"$_uuid\\\"')\" _result=$(eval \"$_command\") _debug _command \"$_command\" _debug _result \"$_result\" _info \"[OMV deploy-hook] Asking openmediavault to apply changes... (this could take some time, hang in there)\" _command=\"omv-rpc -u $DEPLOY_OMV_WEBUI_ADMIN 'Config' 'applyChanges' '{\\\"modules\\\":[], \\\"force\\\": false}'\" _result=$(eval \"$_command\") _debug _command \"$_command\" _debug _result \"$_result\" _info \"[OMV deploy-hook] Asking nginx to reload\" _command=\"nginx -s reload\" _result=$(eval \"$_command\") _debug _command \"$_command\" _debug _result \"$_result\" fi return 0 }"
        },
        {
            "filename": "file_137.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_137.sh",
            "content": "#!/usr/bin/env sh #Here is a script to deploy cert to opensshd server. #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain opensshd_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _err \"deploy cert to opensshd server, Not implemented yet\" return 1 }"
        },
        {
            "filename": "file_138.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_138.sh",
            "content": "#!/usr/bin/env sh # OpenStack Barbican deploy hook # # This requires you to have OpenStackClient and python-barbicanclient # installed. # # You will require Keystone V3 credentials loaded into your environment, which # could be either password or v3applicationcredential type. # # Author: Andy Botting <andy@andybotting.com> openstack_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" if ! _exists openstack; then _err \"OpenStack client not found\" return 1 fi _openstack_credentials || return $? _info \"Generate import pkcs12\" _import_pkcs12=\"$(_mktemp)\" if ! _openstack_to_pkcs \"$_import_pkcs12\" \"$_ckey\" \"$_ccert\" \"$_cca\"; then _err \"Error creating pkcs12 certificate\" return 1 fi _debug _import_pkcs12 \"$_import_pkcs12\" _base64_pkcs12=$(_base64 \"multiline\" <\"$_import_pkcs12\") secretHrefs=$(_openstack_get_secrets) _debug secretHrefs \"$secretHrefs\" _openstack_store_secret || return $? if [ -n \"$secretHrefs\" ]; then _info \"Cleaning up existing secret\" _openstack_delete_secrets || return $? fi _info \"Certificate successfully deployed\" return 0 } _openstack_store_secret() { if ! openstack secret store --name \"$_cdomain.\" -t 'application/octet-stream' -e base64 --payload \"$_base64_pkcs12\"; then _err \"Failed to create OpenStack secret\" return 1 fi return } _openstack_delete_secrets() { echo \"$secretHrefs\" | while read -r secretHref; do _info \"Deleting old secret $secretHref\" if ! openstack secret delete \"$secretHref\"; then _err \"Failed to delete OpenStack secret\" return 1 fi done return } _openstack_get_secrets() { if ! secretHrefs=$(openstack secret list -f value --name \"$_cdomain.\" | cut -d' ' -f1); then _err \"Failed to list secrets\" return 1 fi echo \"$secretHrefs\" } _openstack_to_pkcs() { # The existing _toPkcs command can't allow an empty password, due to sh # -z test, so copied here and forcing the empty password. _cpfx=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" ${ACME_OPENSSL_BIN:-openssl} pkcs12 -export -out \"$_cpfx\" -inkey \"$_ckey\" -in \"$_ccert\" -certfile \"$_cca\" -password \"pass:\" } _openstack_credentials() { _debug \"Check OpenStack credentials\" # If we have OS_AUTH_URL already set in the environment, then assume we want # to use those, otherwise use stored credentials if [ -n \"$OS_AUTH_URL\" ]; then _debug \"OS_AUTH_URL env var found, using environment\" else _debug \"OS_AUTH_URL not found, loading stored credentials\" OS_AUTH_URL=\"${OS_AUTH_URL:-$(_readaccountconf_mutable OS_AUTH_URL)}\" OS_IDENTITY_API_VERSION=\"${OS_IDENTITY_API_VERSION:-$(_readaccountconf_mutable OS_IDENTITY_API_VERSION)}\" OS_AUTH_TYPE=\"${OS_AUTH_TYPE:-$(_readaccountconf_mutable OS_AUTH_TYPE)}\" OS_APPLICATION_CREDENTIAL_ID=\"${OS_APPLICATION_CREDENTIAL_ID:-$(_readaccountconf_mutable OS_APPLICATION_CREDENTIAL_ID)}\" OS_APPLICATION_CREDENTIAL_SECRET=\"${OS_APPLICATION_CREDENTIAL_SECRET:-$(_readaccountconf_mutable OS_APPLICATION_CREDENTIAL_SECRET)}\" OS_USERNAME=\"${OS_USERNAME:-$(_readaccountconf_mutable OS_USERNAME)}\" OS_PASSWORD=\"${OS_PASSWORD:-$(_readaccountconf_mutable OS_PASSWORD)}\" OS_PROJECT_NAME=\"${OS_PROJECT_NAME:-$(_readaccountconf_mutable OS_PROJECT_NAME)}\" OS_PROJECT_ID=\"${OS_PROJECT_ID:-$(_readaccountconf_mutable OS_PROJECT_ID)}\" OS_USER_DOMAIN_NAME=\"${OS_USER_DOMAIN_NAME:-$(_readaccountconf_mutable OS_USER_DOMAIN_NAME)}\" OS_USER_DOMAIN_ID=\"${OS_USER_DOMAIN_ID:-$(_readaccountconf_mutable OS_USER_DOMAIN_ID)}\" OS_PROJECT_DOMAIN_NAME=\"${OS_PROJECT_DOMAIN_NAME:-$(_readaccountconf_mutable OS_PROJECT_DOMAIN_NAME)}\" OS_PROJECT_DOMAIN_ID=\"${OS_PROJECT_DOMAIN_ID:-$(_readaccountconf_mutable OS_PROJECT_DOMAIN_ID)}\" fi # Check each var and either save or clear it depending on whether its set. # The helps us clear out old vars in the case where a user may want # to switch between password and app creds _debug \"OS_AUTH_URL\" \"$OS_AUTH_URL\" if [ -n \"$OS_AUTH_URL\" ]; then export OS_AUTH_URL _saveaccountconf_mutable OS_AUTH_URL \"$OS_AUTH_URL\" else unset OS_AUTH_URL _clearaccountconf SAVED_OS_AUTH_URL fi _debug \"OS_IDENTITY_API_VERSION\" \"$OS_IDENTITY_API_VERSION\" if [ -n \"$OS_IDENTITY_API_VERSION\" ]; then export OS_IDENTITY_API_VERSION _saveaccountconf_mutable OS_IDENTITY_API_VERSION \"$OS_IDENTITY_API_VERSION\" else unset OS_IDENTITY_API_VERSION _clearaccountconf SAVED_OS_IDENTITY_API_VERSION fi _debug \"OS_AUTH_TYPE\" \"$OS_AUTH_TYPE\" if [ -n \"$OS_AUTH_TYPE\" ]; then export OS_AUTH_TYPE _saveaccountconf_mutable OS_AUTH_TYPE \"$OS_AUTH_TYPE\" else unset OS_AUTH_TYPE _clearaccountconf SAVED_OS_AUTH_TYPE fi _debug \"OS_APPLICATION_CREDENTIAL_ID\" \"$OS_APPLICATION_CREDENTIAL_ID\" if [ -n \"$OS_APPLICATION_CREDENTIAL_ID\" ]; then export OS_APPLICATION_CREDENTIAL_ID _saveaccountconf_mutable OS_APPLICATION_CREDENTIAL_ID \"$OS_APPLICATION_CREDENTIAL_ID\" else unset OS_APPLICATION_CREDENTIAL_ID _clearaccountconf SAVED_OS_APPLICATION_CREDENTIAL_ID fi _secure_debug \"OS_APPLICATION_CREDENTIAL_SECRET\" \"$OS_APPLICATION_CREDENTIAL_SECRET\" if [ -n \"$OS_APPLICATION_CREDENTIAL_SECRET\" ]; then export OS_APPLICATION_CREDENTIAL_SECRET _saveaccountconf_mutable OS_APPLICATION_CREDENTIAL_SECRET \"$OS_APPLICATION_CREDENTIAL_SECRET\" else unset OS_APPLICATION_CREDENTIAL_SECRET _clearaccountconf SAVED_OS_APPLICATION_CREDENTIAL_SECRET fi _debug \"OS_USERNAME\" \"$OS_USERNAME\" if [ -n \"$OS_USERNAME\" ]; then export OS_USERNAME _saveaccountconf_mutable OS_USERNAME \"$OS_USERNAME\" else unset OS_USERNAME _clearaccountconf SAVED_OS_USERNAME fi _secure_debug \"OS_PASSWORD\" \"$OS_PASSWORD\" if [ -n \"$OS_PASSWORD\" ]; then export OS_PASSWORD _saveaccountconf_mutable OS_PASSWORD \"$OS_PASSWORD\" else unset OS_PASSWORD _clearaccountconf SAVED_OS_PASSWORD fi _debug \"OS_PROJECT_NAME\" \"$OS_PROJECT_NAME\" if [ -n \"$OS_PROJECT_NAME\" ]; then export OS_PROJECT_NAME _saveaccountconf_mutable OS_PROJECT_NAME \"$OS_PROJECT_NAME\" else unset OS_PROJECT_NAME _clearaccountconf SAVED_OS_PROJECT_NAME fi _debug \"OS_PROJECT_ID\" \"$OS_PROJECT_ID\" if [ -n \"$OS_PROJECT_ID\" ]; then export OS_PROJECT_ID _saveaccountconf_mutable OS_PROJECT_ID \"$OS_PROJECT_ID\" else unset OS_PROJECT_ID _clearaccountconf SAVED_OS_PROJECT_ID fi _debug \"OS_USER_DOMAIN_NAME\" \"$OS_USER_DOMAIN_NAME\" if [ -n \"$OS_USER_DOMAIN_NAME\" ]; then export OS_USER_DOMAIN_NAME _saveaccountconf_mutable OS_USER_DOMAIN_NAME \"$OS_USER_DOMAIN_NAME\" else unset OS_USER_DOMAIN_NAME _clearaccountconf SAVED_OS_USER_DOMAIN_NAME fi _debug \"OS_USER_DOMAIN_ID\" \"$OS_USER_DOMAIN_ID\" if [ -n \"$OS_USER_DOMAIN_ID\" ]; then export OS_USER_DOMAIN_ID _saveaccountconf_mutable OS_USER_DOMAIN_ID \"$OS_USER_DOMAIN_ID\" else unset OS_USER_DOMAIN_ID _clearaccountconf SAVED_OS_USER_DOMAIN_ID fi _debug \"OS_PROJECT_DOMAIN_NAME\" \"$OS_PROJECT_DOMAIN_NAME\" if [ -n \"$OS_PROJECT_DOMAIN_NAME\" ]; then export OS_PROJECT_DOMAIN_NAME _saveaccountconf_mutable OS_PROJECT_DOMAIN_NAME \"$OS_PROJECT_DOMAIN_NAME\" else unset OS_PROJECT_DOMAIN_NAME _clearaccountconf SAVED_OS_PROJECT_DOMAIN_NAME fi _debug \"OS_PROJECT_DOMAIN_ID\" \"$OS_PROJECT_DOMAIN_ID\" if [ -n \"$OS_PROJECT_DOMAIN_ID\" ]; then export OS_PROJECT_DOMAIN_ID _saveaccountconf_mutable OS_PROJECT_DOMAIN_ID \"$OS_PROJECT_DOMAIN_ID\" else unset OS_PROJECT_DOMAIN_ID _clearaccountconf SAVED_OS_PROJECT_DOMAIN_ID fi if [ \"$OS_AUTH_TYPE\" = \"v3applicationcredential\" ]; then # Application Credential auth if [ -z \"$OS_APPLICATION_CREDENTIAL_ID\" ] || [ -z \"$OS_APPLICATION_CREDENTIAL_SECRET\" ]; then _err \"When using OpenStack application credentials, OS_APPLICATION_CREDENTIAL_ID\" _err \"and OS_APPLICATION_CREDENTIAL_SECRET must be set.\" _err \"Please check your credentials and try again.\" return 1 fi else # Password auth if [ -z \"$OS_USERNAME\" ] || [ -z \"$OS_PASSWORD\" ]; then _err \"OpenStack username or password not found.\" _err \"Please check your credentials and try again.\" return 1 fi if [ -z \"$OS_PROJECT_NAME\" ] && [ -z \"$OS_PROJECT_ID\" ]; then _err \"When using password authentication, OS_PROJECT_NAME or\" _err \"OS_PROJECT_ID must be set.\" _err \"Please check your credentials and try again.\" return 1 fi fi return 0 }"
        },
        {
            "filename": "file_139.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_139.sh",
            "content": "#!/usr/bin/env sh # Script to deploy certificates to Palo Alto Networks PANOS via API # Note PANOS API KEY and IP address needs to be set prior to running. # The following variables exported from environment will be used. # If not set then values previously saved in domain.conf file are used. # # Firewall admin with superuser and IP address is required. # # REQURED: # export PANOS_HOST=\"\" # export PANOS_USER=\"\" #User *MUST* have Commit and Import Permissions in XML API for Admin Role # export PANOS_PASS=\"\" # # OPTIONAL # export PANOS_TEMPLATE=\"\" #Template Name of panorama managed devices # # The script will automatically generate a new API key if # no key is found, or if a saved key has expired or is invalid. # This function is to parse the XML response from the firewall parse_response() { type=$2 if [ \"$type\" = 'keygen' ]; then status=$(echo \"$1\" | sed 's/^.*\\(['\\'']\\)\\([a-z]*\\)'\\''.*/\\2/g') if [ \"$status\" = \"success\" ]; then panos_key=$(echo \"$1\" | sed 's/^.*\\(<key>\\)\\(.*\\)<\\/key>.*/\\2/g') _panos_key=$panos_key else message=\"PAN-OS Key could not be set.\" fi else status=$(echo \"$1\" | tr -d '\\n' | sed 's/^.*\"\\([a-z]*\\)\".*/\\1/g') message=$(echo \"$1\" | tr -d '\\n' | sed 's/.*\\(<result>\\|<msg>\\|<line>\\)\\([^<]*\\).*/\\2/g') _debug \"Firewall message: $message\" if [ \"$type\" = 'keytest' ] && [ \"$status\" != \"success\" ]; then _debug \"**** API Key has EXPIRED or is INVALID ****\" unset _panos_key fi fi return 0 } #This function is used to deploy to the firewall deployer() { content=\"\" type=$1 # Types are keytest, keygen, cert, key, commit panos_url=\"https://$_panos_host/api/\" #Test API Key by performing a lookup if [ \"$type\" = 'keytest' ]; then _debug \"**** Testing saved API Key ****\" _H1=\"Content-Type: application/x-www-form-urlencoded\" # Get Version Info to test key content=\"type=version&key=$_panos_key\" ## Exclude all scopes for the empty commit #_exclude_scope=\"<policy-and-objects>exclude</policy-and-objects><device-and-network>exclude</device-and-network><shared-object>exclude</shared-object>\" #content=\"type=commit&action=partial&key=$_panos_key&cmd=<commit><partial>$_exclude_scope<admin><member>acmekeytest</member></admin></partial></commit>\" fi # Generate API Key if [ \"$type\" = 'keygen' ]; then _debug \"**** Generating new API Key ****\" _H1=\"Content-Type: application/x-www-form-urlencoded\" content=\"type=keygen&user=$_panos_user&password=$_panos_pass\" # content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; type=\\\"keygen\\\"; user=\\\"$_panos_user\\\"; password=\\\"$_panos_pass\\\"${nl}Content-Type: application/octet-stream${nl}${nl}\" fi # Deploy Cert or Key if [ \"$type\" = 'cert' ] || [ \"$type\" = 'key' ]; then _debug \"**** Deploying $type ****\" #Generate DELIM delim=\"-----MultipartDelimiter$(date \"+%s%N\")\" nl=\"\\015\\012\" #Set Header export _H1=\"Content-Type: multipart/form-data; boundary=$delim\" if [ \"$type\" = 'cert' ]; then panos_url=\"${panos_url}?type=import\" content=\"--$delim${nl}Content-Disposition: form-data; name=\\\"category\\\"\\r\\n\\r\\ncertificate\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"certificate-name\\\"\\r\\n\\r\\n$_cdomain\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"key\\\"\\r\\n\\r\\n$_panos_key\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"format\\\"\\r\\n\\r\\npem\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"file\\\"; filename=\\\"$(basename \"$_cfullchain\")\\\"${nl}Content-Type: application/octet-stream${nl}${nl}$(cat \"$_cfullchain\")\" if [ \"$_panos_template\" ]; then content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"target-tpl\\\"\\r\\n\\r\\n$_panos_template\" fi fi if [ \"$type\" = 'key' ]; then panos_url=\"${panos_url}?type=import\" content=\"--$delim${nl}Content-Disposition: form-data; name=\\\"category\\\"\\r\\n\\r\\nprivate-key\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"certificate-name\\\"\\r\\n\\r\\n$_cdomain\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"key\\\"\\r\\n\\r\\n$_panos_key\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"format\\\"\\r\\n\\r\\npem\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"passphrase\\\"\\r\\n\\r\\n123456\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"file\\\"; filename=\\\"$(basename \"$_cdomain.key\")\\\"${nl}Content-Type: application/octet-stream${nl}${nl}$(cat \"$_ckey\")\" if [ \"$_panos_template\" ]; then content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"target-tpl\\\"\\r\\n\\r\\n$_panos_template\" fi fi #Close multipart content=\"$content${nl}--$delim--${nl}${nl}\" #Convert CRLF content=$(printf %b \"$content\") fi # Commit changes if [ \"$type\" = 'commit' ]; then _debug \"**** Committing changes ****\" export _H1=\"Content-Type: application/x-www-form-urlencoded\" #Check for force commit - will commit ALL uncommited changes to the firewall. Use with caution! if [ \"$FORCE\" ]; then _debug \"Force switch detected. Committing ALL changes to the firewall.\" cmd=$(printf \"%s\" \"<commit><partial><force><admin><member>$_panos_user</member></admin></force></partial></commit>\" | _url_encode) else _exclude_scope=\"<policy-and-objects>exclude</policy-and-objects><device-and-network>exclude</device-and-network>\" cmd=$(printf \"%s\" \"<commit><partial>$_exclude_scope<admin><member>$_panos_user</member></admin></partial></commit>\" | _url_encode) fi content=\"type=commit&action=partial&key=$_panos_key&cmd=$cmd\" fi response=$(_post \"$content\" \"$panos_url\" \"\" \"POST\") parse_response \"$response\" \"$type\" # Saving response to variables response_status=$status _debug response_status \"$response_status\" if [ \"$response_status\" = \"success\" ]; then _debug \"Successfully deployed $type\" return 0 else _err \"Deploy of type $type failed. Try deploying with --debug to troubleshoot.\" _debug \"$message\" return 1 fi } # This is the main function that will call the other functions to deploy everything. panos_deploy() { _cdomain=$(echo \"$1\" | sed 's/*/WILDCARD_/g') #Wildcard Safe Filename _ckey=\"$2\" _cfullchain=\"$5\" # VALID FILE CHECK if [ ! -f \"$_ckey\" ] || [ ! -f \"$_cfullchain\" ]; then _err \"Unable to find a valid key and/or cert. If this is an ECDSA/ECC cert, use the --ecc flag when deploying.\" return 1 fi # PANOS_HOST if [ \"$PANOS_HOST\" ]; then _debug \"Detected ENV variable PANOS_HOST. Saving to file.\" _savedeployconf PANOS_HOST \"$PANOS_HOST\" 1 else _debug \"Attempting to load variable PANOS_HOST from file.\" _getdeployconf PANOS_HOST fi # PANOS USER if [ \"$PANOS_USER\" ]; then _debug \"Detected ENV variable PANOS_USER. Saving to file.\" _savedeployconf PANOS_USER \"$PANOS_USER\" 1 else _debug \"Attempting to load variable PANOS_USER from file.\" _getdeployconf PANOS_USER fi # PANOS_PASS if [ \"$PANOS_PASS\" ]; then _debug \"Detected ENV variable PANOS_PASS. Saving to file.\" _savedeployconf PANOS_PASS \"$PANOS_PASS\" 1 else _debug \"Attempting to load variable PANOS_PASS from file.\" _getdeployconf PANOS_PASS fi # PANOS_KEY _getdeployconf PANOS_KEY if [ \"$PANOS_KEY\" ]; then _debug \"Detected saved key.\" _panos_key=$PANOS_KEY else _debug \"No key detected\" unset _panos_key fi # PANOS_TEMPLATE if [ \"$PANOS_TEMPLATE\" ]; then _debug \"Detected ENV variable PANOS_TEMPLATE. Saving to file.\" _savedeployconf PANOS_TEMPLATE \"$PANOS_TEMPLATE\" 1 else _debug \"Attempting to load variable PANOS_TEMPLATE from file.\" _getdeployconf PANOS_TEMPLATE fi #Store variables _panos_host=$PANOS_HOST _panos_user=$PANOS_USER _panos_pass=$PANOS_PASS _panos_template=$PANOS_TEMPLATE #Test API Key if found. If the key is invalid, the variable _panos_key will be unset. if [ \"$_panos_host\" ] && [ \"$_panos_key\" ]; then _debug \"**** Testing API KEY ****\" deployer keytest fi # Check for valid variables if [ -z \"$_panos_host\" ]; then _err \"No host found. If this is your first time deploying, please set PANOS_HOST in ENV variables. You can delete it after you have successfully deployed the certs.\" return 1 elif [ -z \"$_panos_user\" ]; then _err \"No user found. If this is your first time deploying, please set PANOS_USER in ENV variables. You can delete it after you have successfully deployed the certs.\" return 1 elif [ -z \"$_panos_pass\" ]; then _err \"No password found. If this is your first time deploying, please set PANOS_PASS in ENV variables. You can delete it after you have successfully deployed the certs.\" return 1 else # Generate a new API key if no valid API key is found if [ -z \"$_panos_key\" ]; then _debug \"**** Generating new PANOS API KEY ****\" deployer keygen _savedeployconf PANOS_KEY \"$_panos_key\" 1 fi # Confirm that a valid key was generated if [ -z \"$_panos_key\" ]; then _err \"Unable to generate an API key. The user and pass may be invalid or not authorized to generate a new key. Please check the PANOS_USER and PANOS_PASS credentials and try again\" return 1 else deployer cert deployer key deployer commit fi fi }"
        },
        {
            "filename": "file_140.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_140.sh",
            "content": "#!/usr/bin/env sh # Script to deploy cert to Peplink Routers # # The following environment variables must be set: # # PEPLINK_Hostname - Peplink hostname # PEPLINK_Username - Peplink username to login # PEPLINK_Password - Peplink password to login # # The following environmental variables may be set if you don't like their # default values: # # PEPLINK_Certtype - Certificate type to target for replacement # defaults to \"webadmin\", can be one of: # * \"chub\" (ContentHub) # * \"openvpn\" (OpenVPN CA) # * \"portal\" (Captive Portal SSL) # * \"webadmin\" (Web Admin SSL) # * \"webproxy\" (Proxy Root CA) # * \"wwan_ca\" (Wi-Fi WAN CA) # * \"wwan_client\" (Wi-Fi WAN Client) # PEPLINK_Scheme - defaults to \"https\" # PEPLINK_Port - defaults to \"443\" # #returns 0 means success, otherwise error. ######## Public functions ##################### _peplink_get_cookie_data() { grep -i \"\\W$1=\" | grep -i \"^Set-Cookie:\" | _tail_n 1 | _egrep_o \"$1=[^;]*;\" | tr -d ';' } #domain keyfile certfile cafile fullchain peplink_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _cfullchain \"$_cfullchain\" _debug _ckey \"$_ckey\" # Get Hostname, Username and Password, but don't save until we successfully authenticate _getdeployconf PEPLINK_Hostname _getdeployconf PEPLINK_Username _getdeployconf PEPLINK_Password if [ -z \"${PEPLINK_Hostname:-}\" ] || [ -z \"${PEPLINK_Username:-}\" ] || [ -z \"${PEPLINK_Password:-}\" ]; then _err \"PEPLINK_Hostname & PEPLINK_Username & PEPLINK_Password must be set\" return 1 fi _debug2 PEPLINK_Hostname \"$PEPLINK_Hostname\" _debug2 PEPLINK_Username \"$PEPLINK_Username\" _secure_debug2 PEPLINK_Password \"$PEPLINK_Password\" # Optional certificate type, scheme, and port for Peplink _getdeployconf PEPLINK_Certtype _getdeployconf PEPLINK_Scheme _getdeployconf PEPLINK_Port # Don't save the certificate type until we verify it exists and is supported _savedeployconf PEPLINK_Scheme \"$PEPLINK_Scheme\" _savedeployconf PEPLINK_Port \"$PEPLINK_Port\" # Default vaules for certificate type, scheme, and port [ -n \"${PEPLINK_Certtype}\" ] || PEPLINK_Certtype=\"webadmin\" [ -n \"${PEPLINK_Scheme}\" ] || PEPLINK_Scheme=\"https\" [ -n \"${PEPLINK_Port}\" ] || PEPLINK_Port=\"443\" _debug2 PEPLINK_Certtype \"$PEPLINK_Certtype\" _debug2 PEPLINK_Scheme \"$PEPLINK_Scheme\" _debug2 PEPLINK_Port \"$PEPLINK_Port\" _base_url=\"$PEPLINK_Scheme://$PEPLINK_Hostname:$PEPLINK_Port\" _debug _base_url \"$_base_url\" # Login, get the auth token from the cookie _info \"Logging into $PEPLINK_Hostname:$PEPLINK_Port\" encoded_username=\"$(printf \"%s\" \"$PEPLINK_Username\" | _url_encode)\" encoded_password=\"$(printf \"%s\" \"$PEPLINK_Password\" | _url_encode)\" response=$(_post \"func=login&username=$encoded_username&password=$encoded_password\" \"$_base_url/cgi-bin/MANGA/api.cgi\") auth_token=$(_peplink_get_cookie_data \"bauth\" <\"$HTTP_HEADER\") _debug3 response \"$response\" _debug auth_token \"$auth_token\" if [ -z \"$auth_token\" ]; then _err \"Unable to authenticate to $PEPLINK_Hostname:$PEPLINK_Port using $PEPLINK_Scheme.\" _err \"Check your username and password.\" return 1 fi _H1=\"Cookie: $auth_token\" export _H1 _debug2 H1 \"${_H1}\" # Now that we know the hostnameusername and password are good, save them _savedeployconf PEPLINK_Hostname \"$PEPLINK_Hostname\" _savedeployconf PEPLINK_Username \"$PEPLINK_Username\" _savedeployconf PEPLINK_Password \"$PEPLINK_Password\" _info \"Generate form POST request\" encoded_key=\"$(_url_encode <\"$_ckey\")\" encoded_fullchain=\"$(_url_encode <\"$_cfullchain\")\" body=\"cert_type=$PEPLINK_Certtype&cert_uid=&section=CERT_modify&key_pem=$encoded_key&key_pem_passphrase=&key_pem_passphrase_confirm=&cert_pem=$encoded_fullchain\" _debug3 body \"$body\" _info \"Upload $PEPLINK_Certtype certificate to the Peplink\" response=$(_post \"$body\" \"$_base_url/cgi-bin/MANGA/admin.cgi\") _debug3 response \"$response\" if echo \"$response\" | grep 'Success' >/dev/null; then # We've verified this certificate type is valid, so save it _savedeployconf PEPLINK_Certtype \"$PEPLINK_Certtype\" _info \"Certificate was updated\" return 0 else _err \"Unable to update certificate, error code $response\" return 1 fi }"
        },
        {
            "filename": "file_141.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_141.sh",
            "content": "#!/usr/bin/env sh # Deploy certificates to a proxmox virtual environment node using the API. # # Environment variables that can be set are: # `DEPLOY_PROXMOXVE_SERVER`: The hostname of the proxmox ve node. Defaults to # _cdomain. # `DEPLOY_PROXMOXVE_SERVER_PORT`: The port number the management interface is on. # Defaults to 8006. # `DEPLOY_PROXMOXVE_NODE_NAME`: The name of the node we'll be connecting to. # Defaults to the host portion of the server # domain name. # `DEPLOY_PROXMOXVE_USER`: The user we'll connect as. Defaults to root. # `DEPLOY_PROXMOXVE_USER_REALM`: The authentication realm the user authenticates # with. Defaults to pam. # `DEPLOY_PROXMOXVE_API_TOKEN_NAME`: The name of the API token created for the # user account. Defaults to acme. # `DEPLOY_PROXMOXVE_API_TOKEN_KEY`: The API token. Required. proxmoxve_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug2 _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" # \"Sane\" defaults. _getdeployconf DEPLOY_PROXMOXVE_SERVER if [ -z \"$DEPLOY_PROXMOXVE_SERVER\" ]; then _target_hostname=\"$_cdomain\" else _target_hostname=\"$DEPLOY_PROXMOXVE_SERVER\" _savedeployconf DEPLOY_PROXMOXVE_SERVER \"$DEPLOY_PROXMOXVE_SERVER\" fi _debug2 DEPLOY_PROXMOXVE_SERVER \"$_target_hostname\" _getdeployconf DEPLOY_PROXMOXVE_SERVER_PORT if [ -z \"$DEPLOY_PROXMOXVE_SERVER_PORT\" ]; then _target_port=\"8006\" else _target_port=\"$DEPLOY_PROXMOXVE_SERVER_PORT\" _savedeployconf DEPLOY_PROXMOXVE_SERVER_PORT \"$DEPLOY_PROXMOXVE_SERVER_PORT\" fi _debug2 DEPLOY_PROXMOXVE_SERVER_PORT \"$_target_port\" _getdeployconf DEPLOY_PROXMOXVE_NODE_NAME if [ -z \"$DEPLOY_PROXMOXVE_NODE_NAME\" ]; then _node_name=$(echo \"$_target_hostname\" | cut -d. -f1) else _node_name=\"$DEPLOY_PROXMOXVE_NODE_NAME\" _savedeployconf DEPLOY_PROXMOXVE_NODE_NAME \"$DEPLOY_PROXMOXVE_NODE_NAME\" fi _debug2 DEPLOY_PROXMOXVE_NODE_NAME \"$_node_name\" # Complete URL. _target_url=\"https://${_target_hostname}:${_target_port}/api2/json/nodes/${_node_name}/certificates/custom\" _debug TARGET_URL \"$_target_url\" # More \"sane\" defaults. _getdeployconf DEPLOY_PROXMOXVE_USER if [ -z \"$DEPLOY_PROXMOXVE_USER\" ]; then _proxmoxve_user=\"root\" else _proxmoxve_user=\"$DEPLOY_PROXMOXVE_USER\" _savedeployconf DEPLOY_PROXMOXVE_USER \"$DEPLOY_PROXMOXVE_USER\" fi _debug2 DEPLOY_PROXMOXVE_USER \"$_proxmoxve_user\" _getdeployconf DEPLOY_PROXMOXVE_USER_REALM if [ -z \"$DEPLOY_PROXMOXVE_USER_REALM\" ]; then _proxmoxve_user_realm=\"pam\" else _proxmoxve_user_realm=\"$DEPLOY_PROXMOXVE_USER_REALM\" _savedeployconf DEPLOY_PROXMOXVE_USER_REALM \"$DEPLOY_PROXMOXVE_USER_REALM\" fi _debug2 DEPLOY_PROXMOXVE_USER_REALM \"$_proxmoxve_user_realm\" _getdeployconf DEPLOY_PROXMOXVE_API_TOKEN_NAME if [ -z \"$DEPLOY_PROXMOXVE_API_TOKEN_NAME\" ]; then _proxmoxve_api_token_name=\"acme\" else _proxmoxve_api_token_name=\"$DEPLOY_PROXMOXVE_API_TOKEN_NAME\" _savedeployconf DEPLOY_PROXMOXVE_API_TOKEN_NAME \"$DEPLOY_PROXMOXVE_API_TOKEN_NAME\" fi _debug2 DEPLOY_PROXMOXVE_API_TOKEN_NAME \"$_proxmoxve_api_token_name\" # This is required. _getdeployconf DEPLOY_PROXMOXVE_API_TOKEN_KEY if [ -z \"$DEPLOY_PROXMOXVE_API_TOKEN_KEY\" ]; then _err \"API key not provided.\" return 1 else _proxmoxve_api_token_key=\"$DEPLOY_PROXMOXVE_API_TOKEN_KEY\" _savedeployconf DEPLOY_PROXMOXVE_API_TOKEN_KEY \"$DEPLOY_PROXMOXVE_API_TOKEN_KEY\" fi _debug2 DEPLOY_PROXMOXVE_API_TOKEN_KEY \"$_proxmoxve_api_token_key\" # PVE API Token header value. Used in \"Authorization: PVEAPIToken\". _proxmoxve_header_api_token=\"${_proxmoxve_user}@${_proxmoxve_user_realm}!${_proxmoxve_api_token_name}=${_proxmoxve_api_token_key}\" _debug2 \"Auth Header\" \"$_proxmoxve_header_api_token\" # Ugly. I hate putting heredocs inside functions because heredocs don't # account for whitespace correctly but it _does_ work and is several times # cleaner than anything else I had here. # # This dumps the json payload to a variable that should be passable to the # _psot function. _json_payload=$( cat <<HEREDOC { \"certificates\": \"$(tr '\\n' ':' <\"$_cfullchain\" | sed 's/:/\\\\n/g')\", \"key\": \"$(tr '\\n' ':' <\"$_ckey\" | sed 's/:/\\\\n/g')\", \"node\":\"$_node_name\", \"restart\":\"1\", \"force\":\"1\" } HEREDOC ) _debug2 Payload \"$_json_payload\" _info \"Push certificates to server\" export HTTPS_INSECURE=1 export _H1=\"Authorization: PVEAPIToken=${_proxmoxve_header_api_token}\" _post \"$_json_payload\" \"$_target_url\" \"\" POST \"application/json\" }"
        },
        {
            "filename": "file_142.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_142.sh",
            "content": "#!/usr/bin/env sh #Here is a script to deploy cert to pureftpd server. #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain pureftpd_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _err \"deploy cert to pureftpd server, Not implemented yet\" return 1 }"
        },
        {
            "filename": "file_143.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_143.sh",
            "content": "#!/usr/bin/env sh # Script to create certificate to qiniu.com # # This deployment required following variables # export QINIU_AK=\"QINIUACCESSKEY\" # export QINIU_SK=\"QINIUSECRETKEY\" # export QINIU_CDN_DOMAIN=\"cdn.example.com\" # If you have more than one domain, just # export QINIU_CDN_DOMAIN=\"cdn1.example.com cdn2.example.com\" QINIU_API_BASE=\"https://api.qiniu.com\" qiniu_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" if [ -z \"$QINIU_AK\" ]; then _err \"QINIU_AK is not defined.\" return 1 else _savedomainconf QINIU_AK \"$QINIU_AK\" fi if [ -z \"$QINIU_SK\" ]; then _err \"QINIU_SK is not defined.\" return 1 else _savedomainconf QINIU_SK \"$QINIU_SK\" fi if [ \"$QINIU_CDN_DOMAIN\" ]; then _savedomainconf QINIU_CDN_DOMAIN \"$QINIU_CDN_DOMAIN\" else QINIU_CDN_DOMAIN=\"$_cdomain\" fi ## upload certificate string_fullchain=$(sed 's/$/\\\\n/' \"$_cfullchain\" | tr -d '\\n') string_key=$(sed 's/$/\\\\n/' \"$_ckey\" | tr -d '\\n') sslcert_path=\"/sslcert\" sslcerl_body=\"{\\\"name\\\":\\\"$_cdomain\\\",\\\"common_name\\\":\\\"$QINIU_CDN_DOMAIN\\\",\\\"ca\\\":\\\"$string_fullchain\\\",\\\"pri\\\":\\\"$string_key\\\"}\" sslcert_access_token=\"$(_make_access_token \"$sslcert_path\")\" _debug sslcert_access_token \"$sslcert_access_token\" export _H1=\"Authorization: QBox $sslcert_access_token\" sslcert_response=$(_post \"$sslcerl_body\" \"$QINIU_API_BASE$sslcert_path\" 0 \"POST\" \"application/json\" | _dbase64) if ! _contains \"$sslcert_response\" \"certID\"; then _err \"Error in creating certificate:\" _err \"$sslcert_response\" return 1 fi _debug sslcert_response \"$sslcert_response\" _info \"Certificate successfully uploaded, updating domain $_cdomain\" ## extract certId _certId=\"$(printf \"%s\" \"$sslcert_response\" | _normalizeJson | _egrep_o \"certID\\\": *\\\"[^\\\"]*\\\"\" | cut -d : -f 2)\" _debug certId \"$_certId\" ## update domain ssl config update_body=\"{\\\"certid\\\":$_certId,\\\"forceHttps\\\":false}\" for domain in $QINIU_CDN_DOMAIN; do update_path=\"/domain/$domain/httpsconf\" update_access_token=\"$(_make_access_token \"$update_path\")\" _debug update_access_token \"$update_access_token\" export _H1=\"Authorization: QBox $update_access_token\" update_response=$(_post \"$update_body\" \"$QINIU_API_BASE$update_path\" 0 \"PUT\" \"application/json\" | _dbase64) if _contains \"$update_response\" \"error\"; then _err \"Error in updating domain $domain httpsconf:\" _err \"$update_response\" return 1 fi _debug update_response \"$update_response\" _info \"Domain $domain certificate has been deployed successfully\" done return 0 } _make_access_token() { _token=\"$(printf \"%s\\n\" \"$1\" | _hmac \"sha1\" \"$(printf \"%s\" \"$QINIU_SK\" | _hex_dump | tr -d \" \")\" | _base64 | tr -- '+/' '-_')\" echo \"$QINIU_AK:$_token\" }"
        },
        {
            "filename": "file_144.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_144.sh",
            "content": "#!/usr/bin/env sh # Here is a script to deploy cert to routeros router. # Deploy the cert to remote routeros # # ```sh # acme.sh --deploy -d ftp.example.com --deploy-hook routeros # ``` # # Before you can deploy the certificate to router os, you need # to add the id_rsa.pub key to the routeros and assign a user # to that key. # # The user need to have access to ssh, ftp, read and write. # # There are no need to enable ftp service for the script to work, # as they are transmitted over SCP, however ftp is needed to store # the files on the router. # # Then you need to set the environment variables for the # deploy script to work. # # ```sh # export ROUTER_OS_USERNAME=certuser # export ROUTER_OS_HOST=router.example.com # export ROUTER_OS_PORT=22 # # acme.sh --deploy -d ftp.example.com --deploy-hook routeros # ``` # # The deploy script will remove previously deployed certificates, # and it does this with an assumption on how RouterOS names imported # certificates, adding a \"cer_0\" suffix at the end. This is true for # versions 6.32 -> 6.41.3, but it is not guaranteed that it will be # true for future versions when upgrading. # # If the router have other certificates with the same name as the one # beeing deployed, then this script will remove those certificates. # # At the end of the script, the services that use those certificates # could be updated. Currently only the www-ssl service is beeing # updated, but more services could be added. # # For instance: # ```sh # export ROUTER_OS_ADDITIONAL_SERVICES=\"/ip service set api-ssl certificate=$_cdomain.cer_0\" # ``` # # One optional thing to do as well is to create a script that updates # all the required services and run that script in a single command. # # To adopt parameters to `scp` and/or `ssh` set the optional # `ROUTER_OS_SSH_CMD` and `ROUTER_OS_SCP_CMD` variables accordingly, # see ssh(1) and scp(1) for parameters to those commands. # # Example: # ```ssh # export ROUTER_OS_SSH_CMD=\"ssh -i /acme.sh/.ssh/router.example.com -o UserKnownHostsFile=/acme.sh/.ssh/known_hosts\" # export ROUTER_OS_SCP_CMD=\"scp -i /acme.sh/.ssh/router.example.com -o UserKnownHostsFile=/acme.sh/.ssh/known_hosts\" # ```` # # returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain routeros_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _err_code=0 _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _getdeployconf ROUTER_OS_HOST if [ -z \"$ROUTER_OS_HOST\" ]; then _debug \"Using _cdomain as ROUTER_OS_HOST, please set if not correct.\" ROUTER_OS_HOST=\"$_cdomain\" fi _getdeployconf ROUTER_OS_USERNAME if [ -z \"$ROUTER_OS_USERNAME\" ]; then _err \"Need to set the env variable ROUTER_OS_USERNAME\" return 1 fi _getdeployconf ROUTER_OS_PORT if [ -z \"$ROUTER_OS_PORT\" ]; then _debug \"Using default port 22 as ROUTER_OS_PORT, please set if not correct.\" ROUTER_OS_PORT=22 fi _getdeployconf ROUTER_OS_SSH_CMD if [ -z \"$ROUTER_OS_SSH_CMD\" ]; then _debug \"Use default ssh setup.\" ROUTER_OS_SSH_CMD=\"ssh -p $ROUTER_OS_PORT\" fi _getdeployconf ROUTER_OS_SCP_CMD if [ -z \"$ROUTER_OS_SCP_CMD\" ]; then _debug \"USe default scp setup.\" ROUTER_OS_SCP_CMD=\"scp -P $ROUTER_OS_PORT\" fi _getdeployconf ROUTER_OS_ADDITIONAL_SERVICES if [ -z \"$ROUTER_OS_ADDITIONAL_SERVICES\" ]; then _debug \"Not enabling additional services\" ROUTER_OS_ADDITIONAL_SERVICES=\"\" fi _savedeployconf ROUTER_OS_HOST \"$ROUTER_OS_HOST\" _savedeployconf ROUTER_OS_USERNAME \"$ROUTER_OS_USERNAME\" _savedeployconf ROUTER_OS_PORT \"$ROUTER_OS_PORT\" _savedeployconf ROUTER_OS_SSH_CMD \"$ROUTER_OS_SSH_CMD\" _savedeployconf ROUTER_OS_SCP_CMD \"$ROUTER_OS_SCP_CMD\" _savedeployconf ROUTER_OS_ADDITIONAL_SERVICES \"$ROUTER_OS_ADDITIONAL_SERVICES\" # push key to routeros if ! _scp_certificate \"$_ckey\" \"$ROUTER_OS_USERNAME@$ROUTER_OS_HOST:$_cdomain.key\"; then return $_err_code fi # push certificate chain to routeros if ! _scp_certificate \"$_cfullchain\" \"$ROUTER_OS_USERNAME@$ROUTER_OS_HOST:$_cdomain.cer\"; then return $_err_code fi DEPLOY_SCRIPT_CMD=\":do {/system script remove \\\"LECertDeploy-$_cdomain\\\" } on-error={ }; \\ /system script add name=\\\"LECertDeploy-$_cdomain\\\" owner=$ROUTER_OS_USERNAME \\ comment=\\\"generated by routeros deploy script in acme.sh\\\" \\ source=\\\"/certificate remove [ find name=$_cdomain.cer_0 ];\\ \\n/certificate remove [ find name=$_cdomain.cer_1 ];\\ \\n/certificate remove [ find name=$_cdomain.cer_2 ];\\ \\ndelay 1;\\ \\n/certificate import file-name=$_cdomain.cer passphrase=\\\\\\\"\\\\\\\";\\ \\n/certificate import file-name=$_cdomain.key passphrase=\\\\\\\"\\\\\\\";\\ \\ndelay 1;\\ \\n:do {/file remove $_cdomain.cer; } on-error={ }\\ \\n:do {/file remove $_cdomain.key; } on-error={ }\\ \\ndelay 2;\\ \\n/ip service set www-ssl certificate=$_cdomain.cer_0;\\ \\n$ROUTER_OS_ADDITIONAL_SERVICES;\\ \\n\\\" \" if ! _ssh_remote_cmd \"$DEPLOY_SCRIPT_CMD\"; then return $_err_code fi if ! _ssh_remote_cmd \"/system script run \\\"LECertDeploy-$_cdomain\\\"\"; then return $_err_code fi if ! _ssh_remote_cmd \"/system script remove \\\"LECertDeploy-$_cdomain\\\"\"; then return $_err_code fi return 0 } # inspired by deploy/ssh.sh _ssh_remote_cmd() { _cmd=\"$1\" _secure_debug \"Remote commands to execute: $_cmd\" _info \"Submitting sequence of commands to routeros\" # quotations in bash cmd below intended. Squash travis spellcheck error # shellcheck disable=SC2029 $ROUTER_OS_SSH_CMD \"$ROUTER_OS_USERNAME@$ROUTER_OS_HOST\" \"$_cmd\" _err_code=\"$?\" if [ \"$_err_code\" != \"0\" ]; then _err \"Error code $_err_code returned from routeros\" fi return $_err_code } _scp_certificate() { _src=\"$1\" _dst=\"$2\" _secure_debug \"scp '$_src' to '$_dst'\" _info \"Push key '$_src' to routeros\" $ROUTER_OS_SCP_CMD \"$_src\" \"$_dst\" _err_code=\"$?\" if [ \"$_err_code\" != \"0\" ]; then _err \"Error code $_err_code returned from scp\" fi return $_err_code }"
        },
        {
            "filename": "file_145.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_145.sh",
            "content": "#!/usr/bin/env sh # Script to deploy certificates to remote server by SSH # Note that SSH must be able to login to remote host without a password... # SSH Keys must have been exchanged with the remote host. Validate and # test that you can login to USER@SERVER from the host running acme.sh before # using this script. # # The following variables exported from environment will be used. # If not set then values previously saved in domain.conf file are used. # # Only a username is required. All others are optional. # # The following examples are for QNAP NAS running QTS 4.2 # export DEPLOY_SSH_CMD=\"\" # defaults to \"ssh -T\" # export DEPLOY_SSH_USER=\"admin\" # required # export DEPLOY_SSH_SERVER=\"host1 host2:8022 192.168.0.1:9022\" # defaults to domain name, support multiple servers with optional port # export DEPLOY_SSH_KEYFILE=\"/etc/stunnel/stunnel.pem\" # export DEPLOY_SSH_CERTFILE=\"/etc/stunnel/stunnel.pem\" # export DEPLOY_SSH_CAFILE=\"/etc/stunnel/uca.pem\" # export DEPLOY_SSH_FULLCHAIN=\"\" # export DEPLOY_SSH_REMOTE_CMD=\"/etc/init.d/stunnel.sh restart\" # export DEPLOY_SSH_BACKUP=\"\" # yes or no, default to yes or previously saved value # export DEPLOY_SSH_BACKUP_PATH=\".acme_ssh_deploy\" # path on remote system. Defaults to .acme_ssh_deploy # export DEPLOY_SSH_MULTI_CALL=\"\" # yes or no, default to no or previously saved value # export DEPLOY_SSH_USE_SCP=\"\" yes or no, default to no # export DEPLOY_SSH_SCP_CMD=\"\" defaults to \"scp -q\" # ######## Public functions ##################### #domain keyfile certfile cafile fullchain ssh_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _deploy_ssh_servers=\"\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" # USER is required to login by SSH to remote host. _migratedeployconf Le_Deploy_ssh_user DEPLOY_SSH_USER _getdeployconf DEPLOY_SSH_USER _debug2 DEPLOY_SSH_USER \"$DEPLOY_SSH_USER\" if [ -z \"$DEPLOY_SSH_USER\" ]; then _err \"DEPLOY_SSH_USER not defined.\" return 1 fi _savedeployconf DEPLOY_SSH_USER \"$DEPLOY_SSH_USER\" # SERVER is optional. If not provided then use _cdomain _migratedeployconf Le_Deploy_ssh_server DEPLOY_SSH_SERVER _getdeployconf DEPLOY_SSH_SERVER _debug2 DEPLOY_SSH_SERVER \"$DEPLOY_SSH_SERVER\" if [ -z \"$DEPLOY_SSH_SERVER\" ]; then DEPLOY_SSH_SERVER=\"$_cdomain\" fi _savedeployconf DEPLOY_SSH_SERVER \"$DEPLOY_SSH_SERVER\" # CMD is optional. If not provided then use ssh _migratedeployconf Le_Deploy_ssh_cmd DEPLOY_SSH_CMD _getdeployconf DEPLOY_SSH_CMD _debug2 DEPLOY_SSH_CMD \"$DEPLOY_SSH_CMD\" if [ -z \"$DEPLOY_SSH_CMD\" ]; then DEPLOY_SSH_CMD=\"ssh -T\" fi _savedeployconf DEPLOY_SSH_CMD \"$DEPLOY_SSH_CMD\" # BACKUP is optional. If not provided then default to previously saved value or yes. _migratedeployconf Le_Deploy_ssh_backup DEPLOY_SSH_BACKUP _getdeployconf DEPLOY_SSH_BACKUP _debug2 DEPLOY_SSH_BACKUP \"$DEPLOY_SSH_BACKUP\" if [ -z \"$DEPLOY_SSH_BACKUP\" ]; then DEPLOY_SSH_BACKUP=\"yes\" fi _savedeployconf DEPLOY_SSH_BACKUP \"$DEPLOY_SSH_BACKUP\" # BACKUP_PATH is optional. If not provided then default to previously saved value or .acme_ssh_deploy _migratedeployconf Le_Deploy_ssh_backup_path DEPLOY_SSH_BACKUP_PATH _getdeployconf DEPLOY_SSH_BACKUP_PATH _debug2 DEPLOY_SSH_BACKUP_PATH \"$DEPLOY_SSH_BACKUP_PATH\" if [ -z \"$DEPLOY_SSH_BACKUP_PATH\" ]; then DEPLOY_SSH_BACKUP_PATH=\".acme_ssh_deploy\" fi _savedeployconf DEPLOY_SSH_BACKUP_PATH \"$DEPLOY_SSH_BACKUP_PATH\" # MULTI_CALL is optional. If not provided then default to previously saved # value (which may be undefined... equivalent to \"no\"). _migratedeployconf Le_Deploy_ssh_multi_call DEPLOY_SSH_MULTI_CALL _getdeployconf DEPLOY_SSH_MULTI_CALL _debug2 DEPLOY_SSH_MULTI_CALL \"$DEPLOY_SSH_MULTI_CALL\" if [ -z \"$DEPLOY_SSH_MULTI_CALL\" ]; then DEPLOY_SSH_MULTI_CALL=\"no\" fi _savedeployconf DEPLOY_SSH_MULTI_CALL \"$DEPLOY_SSH_MULTI_CALL\" # KEYFILE is optional. # If provided then private key will be copied to provided filename. _migratedeployconf Le_Deploy_ssh_keyfile DEPLOY_SSH_KEYFILE _getdeployconf DEPLOY_SSH_KEYFILE _debug2 DEPLOY_SSH_KEYFILE \"$DEPLOY_SSH_KEYFILE\" if [ -n \"$DEPLOY_SSH_KEYFILE\" ]; then _savedeployconf DEPLOY_SSH_KEYFILE \"$DEPLOY_SSH_KEYFILE\" fi # CERTFILE is optional. # If provided then certificate will be copied or appended to provided filename. _migratedeployconf Le_Deploy_ssh_certfile DEPLOY_SSH_CERTFILE _getdeployconf DEPLOY_SSH_CERTFILE _debug2 DEPLOY_SSH_CERTFILE \"$DEPLOY_SSH_CERTFILE\" if [ -n \"$DEPLOY_SSH_CERTFILE\" ]; then _savedeployconf DEPLOY_SSH_CERTFILE \"$DEPLOY_SSH_CERTFILE\" fi # CAFILE is optional. # If provided then CA intermediate certificate will be copied or appended to provided filename. _migratedeployconf Le_Deploy_ssh_cafile DEPLOY_SSH_CAFILE _getdeployconf DEPLOY_SSH_CAFILE _debug2 DEPLOY_SSH_CAFILE \"$DEPLOY_SSH_CAFILE\" if [ -n \"$DEPLOY_SSH_CAFILE\" ]; then _savedeployconf DEPLOY_SSH_CAFILE \"$DEPLOY_SSH_CAFILE\" fi # FULLCHAIN is optional. # If provided then fullchain certificate will be copied or appended to provided filename. _migratedeployconf Le_Deploy_ssh_fullchain DEPLOY_SSH_FULLCHAIN _getdeployconf DEPLOY_SSH_FULLCHAIN _debug2 DEPLOY_SSH_FULLCHAIN \"$DEPLOY_SSH_FULLCHAIN\" if [ -n \"$DEPLOY_SSH_FULLCHAIN\" ]; then _savedeployconf DEPLOY_SSH_FULLCHAIN \"$DEPLOY_SSH_FULLCHAIN\" fi # REMOTE_CMD is optional. # If provided then this command will be executed on remote host. _migratedeployconf Le_Deploy_ssh_remote_cmd DEPLOY_SSH_REMOTE_CMD _getdeployconf DEPLOY_SSH_REMOTE_CMD _debug2 DEPLOY_SSH_REMOTE_CMD \"$DEPLOY_SSH_REMOTE_CMD\" if [ -n \"$DEPLOY_SSH_REMOTE_CMD\" ]; then _savedeployconf DEPLOY_SSH_REMOTE_CMD \"$DEPLOY_SSH_REMOTE_CMD\" fi # USE_SCP is optional. If not provided then default to previously saved # value (which may be undefined... equivalent to \"no\"). _getdeployconf DEPLOY_SSH_USE_SCP _debug2 DEPLOY_SSH_USE_SCP \"$DEPLOY_SSH_USE_SCP\" if [ -z \"$DEPLOY_SSH_USE_SCP\" ]; then DEPLOY_SSH_USE_SCP=\"no\" fi _savedeployconf DEPLOY_SSH_USE_SCP \"$DEPLOY_SSH_USE_SCP\" # SCP_CMD is optional. If not provided then use scp _getdeployconf DEPLOY_SSH_SCP_CMD _debug2 DEPLOY_SSH_SCP_CMD \"$DEPLOY_SSH_SCP_CMD\" if [ -z \"$DEPLOY_SSH_SCP_CMD\" ]; then DEPLOY_SSH_SCP_CMD=\"scp -q\" fi _savedeployconf DEPLOY_SSH_SCP_CMD \"$DEPLOY_SSH_SCP_CMD\" if [ \"$DEPLOY_SSH_USE_SCP\" = \"yes\" ]; then DEPLOY_SSH_MULTI_CALL=\"yes\" _info \"Using scp as alternate method for copying files. Multicall Mode is implicit\" elif [ \"$DEPLOY_SSH_MULTI_CALL\" = \"yes\" ]; then _info \"Using MULTI_CALL mode... Required commands sent in multiple calls to remote host\" else _info \"Required commands batched and sent in single call to remote host\" fi _deploy_ssh_servers=\"$DEPLOY_SSH_SERVER\" for DEPLOY_SSH_SERVER in $_deploy_ssh_servers; do _ssh_deploy done } _ssh_deploy() { _err_code=0 _cmdstr=\"\" _backupprefix=\"\" _backupdir=\"\" _local_cert_file=\"\" _local_ca_file=\"\" _local_full_file=\"\" case $DEPLOY_SSH_SERVER in *:*) _host=${DEPLOY_SSH_SERVER%:*} _port=${DEPLOY_SSH_SERVER##*:} ;; *) _host=$DEPLOY_SSH_SERVER _port= ;; esac _info \"Deploy certificates to remote server $DEPLOY_SSH_USER@$_host:$_port\" if [ \"$DEPLOY_SSH_BACKUP\" = \"yes\" ]; then _backupprefix=\"$DEPLOY_SSH_BACKUP_PATH/$_cdomain-backup\" _backupdir=\"$_backupprefix-$(_utc_date | tr ' ' '-')\" # run cleanup on the backup directory, erase all older # than 180 days (15552000 seconds). _cmdstr=\"{ now=\\\"\\$(date -u +%s)\\\"; for fn in $_backupprefix*; \\ do if [ -d \\\"\\$fn\\\" ] && [ \\\"\\$(expr \\$now - \\$(date -ur \\$fn +%s) )\\\" -ge \\\"15552000\\\" ]; \\ then rm -rf \\\"\\$fn\\\"; echo \\\"Backup \\$fn deleted as older than 180 days\\\"; fi; done; }; $_cmdstr\" # Alternate version of above... _cmdstr=\"find $_backupprefix* -type d -mtime +180 2>/dev/null | xargs rm -rf; $_cmdstr\" # Create our backup directory for overwritten cert files. _cmdstr=\"mkdir -p $_backupdir; $_cmdstr\" _info \"Backup of old certificate files will be placed in remote directory $_backupdir\" _info \"Backup directories erased after 180 days.\" if [ \"$DEPLOY_SSH_MULTI_CALL\" = \"yes\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi _cmdstr=\"\" fi fi if [ -n \"$DEPLOY_SSH_KEYFILE\" ]; then if [ \"$DEPLOY_SSH_BACKUP\" = \"yes\" ]; then # backup file we are about to overwrite. _cmdstr=\"$_cmdstr cp $DEPLOY_SSH_KEYFILE $_backupdir >/dev/null;\" if [ \"$DEPLOY_SSH_MULTI_CALL\" = \"yes\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi _cmdstr=\"\" fi fi # copy new key into file. if [ \"$DEPLOY_SSH_USE_SCP\" = \"yes\" ]; then # scp the file if ! _scp_remote_cmd \"$_ckey\" \"$DEPLOY_SSH_KEYFILE\"; then return $_err_code fi else # ssh echo to the file _cmdstr=\"$_cmdstr echo \\\"$(cat \"$_ckey\")\\\" > $DEPLOY_SSH_KEYFILE;\" _info \"will copy private key to remote file $DEPLOY_SSH_KEYFILE\" if [ \"$DEPLOY_SSH_MULTI_CALL\" = \"yes\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi _cmdstr=\"\" fi fi fi if [ -n \"$DEPLOY_SSH_CERTFILE\" ]; then _pipe=\">\" if [ \"$DEPLOY_SSH_CERTFILE\" = \"$DEPLOY_SSH_KEYFILE\" ]; then # if filename is same as previous file then append. _pipe=\">>\" elif [ \"$DEPLOY_SSH_BACKUP\" = \"yes\" ]; then # backup file we are about to overwrite. _cmdstr=\"$_cmdstr cp $DEPLOY_SSH_CERTFILE $_backupdir >/dev/null;\" if [ \"$DEPLOY_SSH_MULTI_CALL\" = \"yes\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi _cmdstr=\"\" fi fi # copy new certificate into file. if [ \"$DEPLOY_SSH_USE_SCP\" = \"yes\" ]; then # scp the file _local_cert_file=$(_mktemp) if [ \"$DEPLOY_SSH_CERTFILE\" = \"$DEPLOY_SSH_KEYFILE\" ]; then cat \"$_ckey\" >>\"$_local_cert_file\" fi cat \"$_ccert\" >>\"$_local_cert_file\" if ! _scp_remote_cmd \"$_local_cert_file\" \"$DEPLOY_SSH_CERTFILE\"; then return $_err_code fi else # ssh echo to the file _cmdstr=\"$_cmdstr echo \\\"$(cat \"$_ccert\")\\\" $_pipe $DEPLOY_SSH_CERTFILE;\" _info \"will copy certificate to remote file $DEPLOY_SSH_CERTFILE\" if [ \"$DEPLOY_SSH_MULTI_CALL\" = \"yes\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi _cmdstr=\"\" fi fi fi if [ -n \"$DEPLOY_SSH_CAFILE\" ]; then _pipe=\">\" if [ \"$DEPLOY_SSH_CAFILE\" = \"$DEPLOY_SSH_KEYFILE\" ] || [ \"$DEPLOY_SSH_CAFILE\" = \"$DEPLOY_SSH_CERTFILE\" ]; then # if filename is same as previous file then append. _pipe=\">>\" elif [ \"$DEPLOY_SSH_BACKUP\" = \"yes\" ]; then # backup file we are about to overwrite. _cmdstr=\"$_cmdstr cp $DEPLOY_SSH_CAFILE $_backupdir >/dev/null;\" if [ \"$DEPLOY_SSH_MULTI_CALL\" = \"yes\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi _cmdstr=\"\" fi fi # copy new certificate into file. if [ \"$DEPLOY_SSH_USE_SCP\" = \"yes\" ]; then # scp the file _local_ca_file=$(_mktemp) if [ \"$DEPLOY_SSH_CAFILE\" = \"$DEPLOY_SSH_KEYFILE\" ]; then cat \"$_ckey\" >>\"$_local_ca_file\" fi if [ \"$DEPLOY_SSH_CAFILE\" = \"$DEPLOY_SSH_CERTFILE\" ]; then cat \"$_ccert\" >>\"$_local_ca_file\" fi cat \"$_cca\" >>\"$_local_ca_file\" if ! _scp_remote_cmd \"$_local_ca_file\" \"$DEPLOY_SSH_CAFILE\"; then return $_err_code fi else # ssh echo to the file _cmdstr=\"$_cmdstr echo \\\"$(cat \"$_cca\")\\\" $_pipe $DEPLOY_SSH_CAFILE;\" _info \"will copy CA file to remote file $DEPLOY_SSH_CAFILE\" if [ \"$DEPLOY_SSH_MULTI_CALL\" = \"yes\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi _cmdstr=\"\" fi fi fi if [ -n \"$DEPLOY_SSH_FULLCHAIN\" ]; then _pipe=\">\" if [ \"$DEPLOY_SSH_FULLCHAIN\" = \"$DEPLOY_SSH_KEYFILE\" ] || [ \"$DEPLOY_SSH_FULLCHAIN\" = \"$DEPLOY_SSH_CERTFILE\" ] || [ \"$DEPLOY_SSH_FULLCHAIN\" = \"$DEPLOY_SSH_CAFILE\" ]; then # if filename is same as previous file then append. _pipe=\">>\" elif [ \"$DEPLOY_SSH_BACKUP\" = \"yes\" ]; then # backup file we are about to overwrite. _cmdstr=\"$_cmdstr cp $DEPLOY_SSH_FULLCHAIN $_backupdir >/dev/null;\" if [ \"$DEPLOY_SSH_FULLCHAIN\" = \"yes\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi _cmdstr=\"\" fi fi # copy new certificate into file. if [ \"$DEPLOY_SSH_USE_SCP\" = \"yes\" ]; then # scp the file _local_full_file=$(_mktemp) if [ \"$DEPLOY_SSH_FULLCHAIN\" = \"$DEPLOY_SSH_KEYFILE\" ]; then cat \"$_ckey\" >>\"$_local_full_file\" fi if [ \"$DEPLOY_SSH_FULLCHAIN\" = \"$DEPLOY_SSH_CERTFILE\" ]; then cat \"$_ccert\" >>\"$_local_full_file\" fi if [ \"$DEPLOY_SSH_FULLCHAIN\" = \"$DEPLOY_SSH_CAFILE\" ]; then cat \"$_cca\" >>\"$_local_full_file\" fi cat \"$_cfullchain\" >>\"$_local_full_file\" if ! _scp_remote_cmd \"$_local_full_file\" \"$DEPLOY_SSH_FULLCHAIN\"; then return $_err_code fi else # ssh echo to the file _cmdstr=\"$_cmdstr echo \\\"$(cat \"$_cfullchain\")\\\" $_pipe $DEPLOY_SSH_FULLCHAIN;\" _info \"will copy fullchain to remote file $DEPLOY_SSH_FULLCHAIN\" if [ \"$DEPLOY_SSH_MULTI_CALL\" = \"yes\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi _cmdstr=\"\" fi fi fi # cleanup local files if any if [ -f \"$_local_cert_file\" ]; then rm -f \"$_local_cert_file\" fi if [ -f \"$_local_ca_file\" ]; then rm -f \"$_local_ca_file\" fi if [ -f \"$_local_full_file\" ]; then rm -f \"$_local_full_file\" fi if [ -n \"$DEPLOY_SSH_REMOTE_CMD\" ]; then _cmdstr=\"$_cmdstr $DEPLOY_SSH_REMOTE_CMD;\" _info \"Will execute remote command $DEPLOY_SSH_REMOTE_CMD\" if [ \"$DEPLOY_SSH_MULTI_CALL\" = \"yes\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi _cmdstr=\"\" fi fi # if commands not all sent in multiple calls then all commands sent in a single SSH call now... if [ -n \"$_cmdstr\" ]; then if ! _ssh_remote_cmd \"$_cmdstr\"; then return $_err_code fi fi # cleanup in case all is ok return 0 } #cmd _ssh_remote_cmd() { _cmd=\"$1\" _ssh_cmd=\"$DEPLOY_SSH_CMD\" if [ -n \"$_port\" ]; then _ssh_cmd=\"$_ssh_cmd -p $_port\" fi _secure_debug \"Remote commands to execute: $_cmd\" _info \"Submitting sequence of commands to remote server by $_ssh_cmd\" # quotations in bash cmd below intended. Squash travis spellcheck error # shellcheck disable=SC2029 $_ssh_cmd \"$DEPLOY_SSH_USER@$_host\" sh -c \"'$_cmd'\" _err_code=\"$?\" if [ \"$_err_code\" != \"0\" ]; then _err \"Error code $_err_code returned from ssh\" fi return $_err_code } # cmd scp _scp_remote_cmd() { _src=$1 _dest=$2 _scp_cmd=\"$DEPLOY_SSH_SCP_CMD\" if [ -n \"$_port\" ]; then _scp_cmd=\"$_scp_cmd -P $_port\" fi _secure_debug \"Remote copy source $_src to destination $_dest\" _info \"Submitting secure copy by $_scp_cmd\" $_scp_cmd \"$_src\" \"$DEPLOY_SSH_USER\"@\"$_host\":\"$_dest\" _err_code=\"$?\" if [ \"$_err_code\" != \"0\" ]; then _err \"Error code $_err_code returned from scp\" fi return $_err_code }"
        },
        {
            "filename": "file_146.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_146.sh",
            "content": "#!/usr/bin/env sh #Here is a sample custom api script. #This file name is \"myapi.sh\" #So, here must be a method myapi_deploy() #Which will be called by acme.sh to deploy the cert #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain strongswan_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _info \"Using strongswan\" if [ -x /usr/sbin/ipsec ]; then _ipsec=/usr/sbin/ipsec elif [ -x /usr/sbin/strongswan ]; then _ipsec=/usr/sbin/strongswan elif [ -x /usr/local/sbin/ipsec ]; then _ipsec=/usr/local/sbin/ipsec else _err \"no strongswan or ipsec command is detected\" return 1 fi _info _ipsec \"$_ipsec\" _confdir=$($_ipsec --confdir) if [ $? -ne 0 ] || [ -z \"$_confdir\" ]; then _err \"no strongswan --confdir is detected\" return 1 fi _info _confdir \"$_confdir\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" cat \"$_ckey\" >\"${_confdir}/ipsec.d/private/$(basename \"$_ckey\")\" cat \"$_ccert\" >\"${_confdir}/ipsec.d/certs/$(basename \"$_ccert\")\" cat \"$_cca\" >\"${_confdir}/ipsec.d/cacerts/$(basename \"$_cca\")\" cat \"$_cfullchain\" >\"${_confdir}/ipsec.d/cacerts/$(basename \"$_cfullchain\")\" $_ipsec reload }"
        },
        {
            "filename": "file_147.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_147.sh",
            "content": "#!/bin/bash ################################################################################ # ACME.sh 3rd party deploy plugin for Synology DSM ################################################################################ # Authors: Brian Hartvigsen (creator), https://github.com/tresni # Martin Arndt (contributor), https://troublezone.net/ # Updated: 2023-07-03 # Issues: https://github.com/acmesh-official/acme.sh/issues/2727 ################################################################################ # Usage (shown values are the examples): # 1. Set required environment variables: # - use automatically created temp admin user to authenticate # export SYNO_USE_TEMP_ADMIN=1 # - or provide your own admin user credential to authenticate # 1. export SYNO_USERNAME=\"adminUser\" # 2. export SYNO_PASSWORD=\"adminPassword\" # 2. Set optional environment variables # - common optional variables # - export SYNO_SCHEME=\"http\" - defaults to \"http\" # - export SYNO_HOSTNAME=\"localhost\" - defaults to \"localhost\" # - export SYNO_PORT=\"5000\" - defaults to \"5000\" # - export SYNO_CREATE=1 - to allow creating the cert if it doesn't exist # - export SYNO_CERTIFICATE=\"\" - to replace a specific cert by its # description # - temp admin optional variables # - export SYNO_LOCAL_HOSTNAME=1 - if set to 1, force to treat hostname is # targeting current local machine (since # this method only locally supported) # - exsiting admin 2FA-OTP optional variables # - export SYNO_OTP_CODE=\"XXXXXX\" - if set, script won't require to # interactive input the OTP code # - export SYNO_DEVICE_NAME=\"CertRenewal\" - if set, script won't require to # interactive input the device name # - export SYNO_DEVICE_ID=\"\" - (deprecated, auth with OTP code instead) # required for omitting 2FA-OTP # 3. Run command: # acme.sh --deploy --deploy-hook synology_dsm -d example.com ################################################################################ # Dependencies: # - curl # - synouser & synogroup & synosetkeyvalue (Required for SYNO_USE_TEMP_ADMIN=1) ################################################################################ # Return value: # 0 means success, otherwise error. ################################################################################ ########## Public functions #################################################### #domain keyfile certfile cafile fullchain synology_dsm_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _debug _cdomain \"$_cdomain\" # Get username and password, but don't save until we authenticated successfully _migratedeployconf SYNO_Username SYNO_USERNAME _migratedeployconf SYNO_Password SYNO_PASSWORD _migratedeployconf SYNO_Device_ID SYNO_DEVICE_ID _migratedeployconf SYNO_Device_Name SYNO_DEVICE_NAME _getdeployconf SYNO_USERNAME _getdeployconf SYNO_PASSWORD _getdeployconf SYNO_DEVICE_ID _getdeployconf SYNO_DEVICE_NAME # Prepare to use temp admin if SYNO_USE_TEMP_ADMIN is set _getdeployconf SYNO_USE_TEMP_ADMIN _check2cleardeployconfexp SYNO_USE_TEMP_ADMIN _debug2 SYNO_USE_TEMP_ADMIN \"$SYNO_USE_TEMP_ADMIN\" if [ -n \"$SYNO_USE_TEMP_ADMIN\" ]; then if ! _exists synouser || ! _exists synogroup || ! _exists synosetkeyvalue; then _err \"Missing required tools to creat temp admin user, please set SYNO_USERNAME and SYNO_PASSWORD instead.\" _err \"Notice: temp admin user authorization method only supports local deployment on DSM.\" return 1 fi if synouser --help 2>&1 | grep -q 'Permission denied'; then _err \"For creating temp admin user, the deploy script must be run as root.\" return 1 fi [ -n \"$SYNO_USERNAME\" ] || _savedeployconf SYNO_USERNAME \"\" [ -n \"$SYNO_PASSWORD\" ] || _savedeployconf SYNO_PASSWORD \"\" _debug \"Setting temp admin user credential...\" SYNO_USERNAME=sc-acmesh-tmp SYNO_PASSWORD=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 16) # Set 2FA-OTP settings to empty consider they won't be needed. SYNO_DEVICE_ID= SYNO_DEVICE_NAME= SYNO_OTP_CODE= else _debug2 SYNO_USERNAME \"$SYNO_USERNAME\" _secure_debug2 SYNO_PASSWORD \"$SYNO_PASSWORD\" _debug2 SYNO_DEVICE_NAME \"$SYNO_DEVICE_NAME\" _secure_debug2 SYNO_DEVICE_ID \"$SYNO_DEVICE_ID\" fi if [ -z \"$SYNO_USERNAME\" ] || [ -z \"$SYNO_PASSWORD\" ]; then _err \"You must set either SYNO_USE_TEMP_ADMIN, or set both SYNO_USERNAME and SYNO_PASSWORD.\" return 1 fi # Optional scheme, hostname and port for Synology DSM _migratedeployconf SYNO_Scheme SYNO_SCHEME _migratedeployconf SYNO_Hostname SYNO_HOSTNAME _migratedeployconf SYNO_Port SYNO_PORT _getdeployconf SYNO_SCHEME _getdeployconf SYNO_HOSTNAME _getdeployconf SYNO_PORT # Default values for scheme, hostname and port # Defaulting to localhost and http, because it's localhost\u2026 [ -n \"$SYNO_SCHEME\" ] || SYNO_SCHEME=http [ -n \"$SYNO_HOSTNAME\" ] || SYNO_HOSTNAME=localhost [ -n \"$SYNO_PORT\" ] || SYNO_PORT=5000 _savedeployconf SYNO_SCHEME \"$SYNO_SCHEME\" _savedeployconf SYNO_HOSTNAME \"$SYNO_HOSTNAME\" _savedeployconf SYNO_PORT \"$SYNO_PORT\" _debug2 SYNO_SCHEME \"$SYNO_SCHEME\" _debug2 SYNO_HOSTNAME \"$SYNO_HOSTNAME\" _debug2 SYNO_PORT \"$SYNO_PORT\" # Get the certificate description, but don't save it until we verify it's real _migratedeployconf SYNO_Certificate SYNO_CERTIFICATE \"base64\" _getdeployconf SYNO_CERTIFICATE _check2cleardeployconfexp SYNO_CERTIFICATE _debug SYNO_CERTIFICATE \"${SYNO_CERTIFICATE:-}\" # shellcheck disable=SC1003 # We are not trying to escape a single quote if printf \"%s\" \"$SYNO_CERTIFICATE\" | grep '\\\\'; then _err \"Do not use a backslash (\\) in your certificate description\" return 1 fi _debug \"Getting API version...\" _base_url=\"$SYNO_SCHEME://$SYNO_HOSTNAME:$SYNO_PORT\" _debug _base_url \"$_base_url\" response=$(_get \"$_base_url/webapi/query.cgi?api=SYNO.API.Info&version=1&method=query&query=SYNO.API.Auth\") api_path=$(echo \"$response\" | grep \"SYNO.API.Auth\" | sed -n 's/.*\"path\" *: *\"\\([^\"]*\\)\".*/\\1/p') api_version=$(echo \"$response\" | grep \"SYNO.API.Auth\" | sed -n 's/.*\"maxVersion\" *: *\\([0-9]*\\).*/\\1/p') _debug3 response \"$response\" _debug3 api_path \"$api_path\" _debug3 api_version \"$api_version\" # Login, get the session ID and SynoToken from JSON _info \"Logging into $SYNO_HOSTNAME:$SYNO_PORT...\" encoded_username=\"$(printf \"%s\" \"$SYNO_USERNAME\" | _url_encode)\" encoded_password=\"$(printf \"%s\" \"$SYNO_PASSWORD\" | _url_encode)\" # ## START ## - DEPRECATED, for backward compatibility _getdeployconf SYNO_TOTP_SECRET if [ -n \"$SYNO_TOTP_SECRET\" ]; then _info \"WARNING: Usage of SYNO_TOTP_SECRET is deprecated!\" _info \" See synology_dsm.sh script or ACME.sh Wiki page for details:\" _info \" https://github.com/acmesh-official/acme.sh/wiki/Synology-NAS-Guide\" if ! _exists oathtool; then _err \"oathtool could not be found, install oathtool to use SYNO_TOTP_SECRET\" return 1 fi DEPRECATED_otp_code=\"$(oathtool --base32 --totp \"$SYNO_TOTP_SECRET\" 2>/dev/null)\" if [ -z \"$SYNO_DEVICE_ID\" ]; then _getdeployconf SYNO_DID [ -n \"$SYNO_DID\" ] || SYNO_DEVICE_ID=\"$SYNO_DID\" fi if [ -n \"$SYNO_DEVICE_ID\" ]; then _H1=\"Cookie: did=$SYNO_DEVICE_ID\" export _H1 _debug3 H1 \"${_H1}\" fi response=$(_post \"method=login&account=$encoded_username&passwd=$encoded_password&api=SYNO.API.Auth&version=$api_version&enable_syno_token=yes&otp_code=$DEPRECATED_otp_code&device_name=certrenewal&device_id=$SYNO_DEVICE_ID\" \"$_base_url/webapi/$api_path?enable_syno_token=yes\") _debug3 response \"$response\" # ## END ## - DEPRECATED, for backward compatibility # If SYNO_DEVICE_ID or SYNO_OTP_CODE is set, we treat current account enabled 2FA-OTP. # Notice that if SYNO_USE_TEMP_ADMIN=1, both variables will be unset else if [ -n \"$SYNO_DEVICE_ID\" ] || [ -n \"$SYNO_OTP_CODE\" ]; then response='{\"error\":{\"code\":403}}' # Assume the current account disabled 2FA-OTP, try to log in right away. else if [ -n \"$SYNO_USE_TEMP_ADMIN\" ]; then _getdeployconf SYNO_LOCAL_HOSTNAME _debug SYNO_LOCAL_HOSTNAME \"${SYNO_LOCAL_HOSTNAME:-}\" if [ \"$SYNO_LOCAL_HOSTNAME\" != \"1\" ] && [ \"$SYNO_LOCAL_HOSTNAME\" == \"$SYNO_HOSTNAME\" ]; then if [ \"$SYNO_HOSTNAME\" != \"localhost\" ] && [ \"$SYNO_HOSTNAME\" != \"127.0.0.1\" ]; then _err \"SYNO_USE_TEMP_ADMIN=1 only support local deployment, though if you are sure that the hostname $SYNO_HOSTNAME is targeting to your **current local machine**, execute 'export SYNO_LOCAL_HOSTNAME=1' then rerun.\" return 1 fi fi _debug \"Creating temp admin user in Synology DSM...\" if synogroup --help | grep -q '\\-\\-memberadd '; then _temp_admin_create \"$SYNO_USERNAME\" \"$SYNO_PASSWORD\" synogroup --memberadd administrators \"$SYNO_USERNAME\" >/dev/null elif synogroup --help | grep -q '\\-\\-member '; then # For supporting DSM 6.x which only has `--member` parameter. cur_admins=$(synogroup --get administrators | awk -F '[][]' '/Group Members/,0{if(NF>1)printf \"%s \", $2}') if [ -n \"$cur_admins\" ]; then _temp_admin_create \"$SYNO_USERNAME\" \"$SYNO_PASSWORD\" _secure_debug3 admin_users \"$cur_admins$SYNO_USERNAME\" # shellcheck disable=SC2086 synogroup --member administrators $cur_admins $SYNO_USERNAME >/dev/null else _err \"The tool synogroup may be broken, please set SYNO_USERNAME and SYNO_PASSWORD instead.\" return 1 fi else _err \"Unsupported synogroup tool detected, please set SYNO_USERNAME and SYNO_PASSWORD instead.\" return 1 fi # havig a workaround to temporary disable enforce 2FA-OTP, will restore # it soon (after a single request), though if any accident occurs like # unexpected interruption, this setting can be easily reverted manually. otp_enforce_option=$(synogetkeyvalue /etc/synoinfo.conf otp_enforce_option) if [ -n \"$otp_enforce_option\" ] && [ \"${otp_enforce_option:-\"none\"}\" != \"none\" ]; then synosetkeyvalue /etc/synoinfo.conf otp_enforce_option none _info \"Enforcing 2FA-OTP has been disabled to complete temp admin authentication.\" _info \"Notice: it will be restored soon, if not, you can restore it manually via Control Panel.\" _info \"previous_otp_enforce_option\" \"$otp_enforce_option\" else otp_enforce_option=\"\" fi fi response=$(_get \"$_base_url/webapi/$api_path?api=SYNO.API.Auth&version=$api_version&method=login&format=sid&account=$encoded_username&passwd=$encoded_password&enable_syno_token=yes\") if [ -n \"$SYNO_USE_TEMP_ADMIN\" ] && [ -n \"$otp_enforce_option\" ]; then synosetkeyvalue /etc/synoinfo.conf otp_enforce_option \"$otp_enforce_option\" _info \"Restored previous enforce 2FA-OTP option.\" fi _debug3 response \"$response\" fi fi error_code=$(echo \"$response\" | grep '\"error\":' | grep -o '\"code\":[0-9]*' | grep -o '[0-9]*') _debug2 error_code \"$error_code\" # Account has 2FA-OTP enabled, since error 403 reported. # https://global.download.synology.com/download/Document/Software/DeveloperGuide/Os/DSM/All/enu/DSM_Login_Web_API_Guide_enu.pdf if [ \"$error_code\" == \"403\" ]; then if [ -z \"$SYNO_DEVICE_NAME\" ]; then printf \"Enter device name or leave empty for default (CertRenewal): \" read -r SYNO_DEVICE_NAME [ -n \"$SYNO_DEVICE_NAME\" ] || SYNO_DEVICE_NAME=\"CertRenewal\" fi if [ -n \"$SYNO_DEVICE_ID\" ]; then # Omit OTP code with SYNO_DEVICE_ID. response=$(_get \"$_base_url/webapi/$api_path?api=SYNO.API.Auth&version=$api_version&method=login&format=sid&account=$encoded_username&passwd=$encoded_password&enable_syno_token=yes&device_name=$SYNO_DEVICE_NAME&device_id=$SYNO_DEVICE_ID\") _secure_debug3 response \"$response\" else # Require the OTP code if still unset. if [ -z \"$SYNO_OTP_CODE\" ]; then printf \"Enter OTP code for user '%s': \" \"$SYNO_USERNAME\" read -r SYNO_OTP_CODE fi _secure_debug SYNO_OTP_CODE \"${SYNO_OTP_CODE:-}\" if [ -z \"$SYNO_OTP_CODE\" ]; then response='{\"error\":{\"code\":404}}' else response=$(_get \"$_base_url/webapi/$api_path?api=SYNO.API.Auth&version=$api_version&method=login&format=sid&account=$encoded_username&passwd=$encoded_password&enable_syno_token=yes&enable_device_token=yes&device_name=$SYNO_DEVICE_NAME&otp_code=$SYNO_OTP_CODE\") _secure_debug3 response \"$response\" id_property='device_id' [ \"${api_version}\" -gt '6' ] || id_property='did' SYNO_DEVICE_ID=$(echo \"$response\" | grep \"$id_property\" | sed -n 's/.*\"'$id_property'\" *: *\"\\([^\"]*\\).*/\\1/p') _secure_debug2 SYNO_DEVICE_ID \"$SYNO_DEVICE_ID\" fi fi error_code=$(echo \"$response\" | grep '\"error\":' | grep -o '\"code\":[0-9]*' | grep -o '[0-9]*') _debug2 error_code \"$error_code\" fi if [ -n \"$error_code\" ]; then if [ \"$error_code\" == \"403\" ] && [ -n \"$SYNO_DEVICE_ID\" ]; then _cleardeployconf SYNO_DEVICE_ID _err \"Failed to authenticate with SYNO_DEVICE_ID (may expired or invalid), please try again in a new terminal window.\" elif [ \"$error_code\" == \"404\" ]; then _err \"Failed to authenticate with provided 2FA-OTP code, please try again in a new terminal window.\" elif [ \"$error_code\" == \"406\" ]; then if [ -n \"$SYNO_USE_TEMP_ADMIN\" ]; then _err \"Failed with unexcepted error, please report this by providing full log with '--debug 3'.\" else _err \"Enforce auth with 2FA-OTP enabled, please configure the user to enable 2FA-OTP to continue.\" fi elif [ \"$error_code\" == \"400\" ]; then _err \"Failed to authenticate, no such account or incorrect password.\" elif [ \"$error_code\" == \"401\" ]; then _err \"Failed to authenticate with a non-existent account.\" elif [ \"$error_code\" == \"408\" ] || [ \"$error_code\" == \"409\" ] || [ \"$error_code\" == \"410\" ]; then _err \"Failed to authenticate, the account password has expired or must be changed.\" else _err \"Failed to authenticate with error: $error_code.\" fi _temp_admin_cleanup \"$SYNO_USE_TEMP_ADMIN\" \"$SYNO_USERNAME\" return 1 fi sid=$(echo \"$response\" | grep \"sid\" | sed -n 's/.*\"sid\" *: *\"\\([^\"]*\\).*/\\1/p') token=$(echo \"$response\" | grep \"synotoken\" | sed -n 's/.*\"synotoken\" *: *\"\\([^\"]*\\).*/\\1/p') _debug \"Session ID\" \"$sid\" _debug SynoToken \"$token\" if [ -z \"$sid\" ] || [ -z \"$token\" ]; then # Still can't get necessary info even got no errors, may Synology have API updated? _err \"Unable to authenticate to $_base_url, you may report this by providing full log with '--debug 3'.\" _temp_admin_cleanup \"$SYNO_USE_TEMP_ADMIN\" \"$SYNO_USERNAME\" return 1 fi _H1=\"X-SYNO-TOKEN: $token\" export _H1 _debug2 H1 \"${_H1}\" # Now that we know the username and password are good, save them if not in temp admin mode. if [ -n \"$SYNO_USE_TEMP_ADMIN\" ]; then _cleardeployconf SYNO_USERNAME _cleardeployconf SYNO_PASSWORD _cleardeployconf SYNO_DEVICE_ID _cleardeployconf SYNO_DEVICE_NAME _savedeployconf SYNO_USE_TEMP_ADMIN \"$SYNO_USE_TEMP_ADMIN\" _savedeployconf SYNO_LOCAL_HOSTNAME \"$SYNO_HOSTNAME\" else _savedeployconf SYNO_USERNAME \"$SYNO_USERNAME\" _savedeployconf SYNO_PASSWORD \"$SYNO_PASSWORD\" _savedeployconf SYNO_DEVICE_ID \"$SYNO_DEVICE_ID\" _savedeployconf SYNO_DEVICE_NAME \"$SYNO_DEVICE_NAME\" fi _info \"Getting certificates in Synology DSM...\" response=$(_post \"api=SYNO.Core.Certificate.CRT&method=list&version=1&_sid=$sid\" \"$_base_url/webapi/entry.cgi\") _debug3 response \"$response\" escaped_certificate=\"$(printf \"%s\" \"$SYNO_CERTIFICATE\" | sed 's/\\([].*^$[]\\)/\\\\\\1/g;s/\"/\\\\\\\\\"/g')\" _debug escaped_certificate \"$escaped_certificate\" id=$(echo \"$response\" | sed -n \"s/.*\\\"desc\\\":\\\"$escaped_certificate\\\",\\\"id\\\":\\\"\\([^\\\"]*\\).*/\\1/p\") _debug2 id \"$id\" error_code=$(echo \"$response\" | grep '\"error\":' | grep -o '\"code\":[0-9]*' | grep -o '[0-9]*') _debug2 error_code \"$error_code\" if [ -n \"$error_code\" ]; then if [ \"$error_code\" -eq 105 ]; then _err \"Current user is not administrator and does not have sufficient permission for deploying.\" else _err \"Failed to fetch certificate info: $error_code, please try again or contact Synology to learn more.\" fi _temp_admin_cleanup \"$SYNO_USE_TEMP_ADMIN\" \"$SYNO_USERNAME\" return 1 fi _migratedeployconf SYNO_Create SYNO_CREATE _getdeployconf SYNO_CREATE _debug2 SYNO_CREATE \"$SYNO_CREATE\" if [ -z \"$id\" ] && [ -z \"$SYNO_CREATE\" ]; then _err \"Unable to find certificate: $SYNO_CERTIFICATE and $SYNO_CREATE is not set.\" _temp_admin_cleanup \"$SYNO_USE_TEMP_ADMIN\" \"$SYNO_USERNAME\" return 1 fi # We've verified this certificate description is a thing, so save it _savedeployconf SYNO_CERTIFICATE \"$SYNO_CERTIFICATE\" \"base64\" _info \"Generating form POST request...\" nl=\"\\0015\\0012\" delim=\"--------------------------$(_utc_date | tr -d -- '-: ')\" content=\"--$delim${nl}Content-Disposition: form-data; name=\\\"key\\\"; filename=\\\"$(basename \"$_ckey\")\\\"${nl}Content-Type: application/octet-stream${nl}${nl}$(cat \"$_ckey\")\\0012\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"cert\\\"; filename=\\\"$(basename \"$_ccert\")\\\"${nl}Content-Type: application/octet-stream${nl}${nl}$(cat \"$_ccert\")\\0012\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"inter_cert\\\"; filename=\\\"$(basename \"$_cca\")\\\"${nl}Content-Type: application/octet-stream${nl}${nl}$(cat \"$_cca\")\\0012\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"id\\\"${nl}${nl}$id\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"desc\\\"${nl}${nl}${SYNO_CERTIFICATE}\" if echo \"$response\" | sed -n \"s/.*\\\"desc\\\":\\\"$escaped_certificate\\\",\\([^{]*\\).*/\\1/p\" | grep -- 'is_default\":true' >/dev/null; then _debug2 default \"This is the default certificate\" content=\"$content${nl}--$delim${nl}Content-Disposition: form-data; name=\\\"as_default\\\"${nl}${nl}true\" else _debug2 default \"This is NOT the default certificate\" fi content=\"$content${nl}--$delim--${nl}\" content=\"$(printf \"%b_\" \"$content\")\" content=\"${content%_}\" # protect trailing \\n _info \"Upload certificate to the Synology DSM.\" response=$(_post \"$content\" \"$_base_url/webapi/entry.cgi?api=SYNO.Core.Certificate&method=import&version=1&SynoToken=$token&_sid=$sid\" \"\" \"POST\" \"multipart/form-data; boundary=${delim}\") _debug3 response \"$response\" if ! echo \"$response\" | grep '\"error\":' >/dev/null; then if echo \"$response\" | grep '\"restart_httpd\":true' >/dev/null; then _info \"Restart HTTP services succeeded.\" else _info \"Restart HTTP services failed.\" fi _temp_admin_cleanup \"$SYNO_USE_TEMP_ADMIN\" \"$SYNO_USERNAME\" _logout return 0 else _temp_admin_cleanup \"$SYNO_USE_TEMP_ADMIN\" \"$SYNO_USERNAME\" _err \"Unable to update certificate, got error response: $response.\" _logout return 1 fi } #################### Private functions below ################################## _logout() { # Logout CERT user only to not occupy a permanent session, e.g. in DSM's \"Connected Users\" widget (based on previous variables) response=$(_get \"$_base_url/webapi/$api_path?api=SYNO.API.Auth&version=$api_version&method=logout&_sid=$sid\") _debug3 response \"$response\" } _temp_admin_create() { _username=\"$1\" _password=\"$2\" synouser --del \"$_username\" >/dev/null 2>/dev/null synouser --add \"$_username\" \"$_password\" \"\" 0 \"scruelt@hotmail.com\" 0 >/dev/null } _temp_admin_cleanup() { _flag=$1 _username=$2 if [ -n \"${_flag}\" ]; then _debug \"Cleanuping temp admin info...\" synouser --del \"$_username\" >/dev/null fi } #_cleardeployconf key _cleardeployconf() { _cleardomainconf \"SAVED_$1\" } # key _check2cleardeployconfexp() { _key=\"$1\" _clear_key=\"CLEAR_$_key\" # Clear saved settings if explicitly requested if [ -n \"$(eval echo \\$\"$_clear_key\")\" ]; then _debug2 \"$_key: value cleared from config, exported value will be ignored.\" _cleardeployconf \"$_key\" eval \"$_key\"= export \"$_key\"= eval SAVED_\"$_key\"= export SAVED_\"$_key\"= fi }"
        },
        {
            "filename": "file_148.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_148.sh",
            "content": "#!/usr/bin/env sh # Here is a scipt to deploy the cert to your TrueNAS using the REST API. # https://www.truenas.com/docs/hub/additional-topics/api/rest_api.html # # Written by Frank Plass github@f-plass.de # https://github.com/danb35/deploy-freenas/blob/master/deploy_freenas.py # Thanks to danb35 for your template! # # Following environment variables must be set: # # export DEPLOY_TRUENAS_APIKEY=\"<API_KEY_GENERATED_IN_THE_WEB_UI\" # # The following environmental variables may be set if you don't like their # default values: # # DEPLOY_TRUENAS_HOSTNAME - defaults to localhost # DEPLOY_TRUENAS_SCHEME - defaults to http, set alternatively to https # #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain truenas_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _getdeployconf DEPLOY_TRUENAS_APIKEY if [ -z \"$DEPLOY_TRUENAS_APIKEY\" ]; then _err \"TrueNAS API key not found, please set the DEPLOY_TRUENAS_APIKEY environment variable.\" return 1 fi _secure_debug2 DEPLOY_TRUENAS_APIKEY \"$DEPLOY_TRUENAS_APIKEY\" # Optional hostname, scheme for TrueNAS _getdeployconf DEPLOY_TRUENAS_HOSTNAME _getdeployconf DEPLOY_TRUENAS_SCHEME # default values for hostname and scheme [ -n \"${DEPLOY_TRUENAS_HOSTNAME}\" ] || DEPLOY_TRUENAS_HOSTNAME=\"localhost\" [ -n \"${DEPLOY_TRUENAS_SCHEME}\" ] || DEPLOY_TRUENAS_SCHEME=\"http\" _debug2 DEPLOY_TRUENAS_HOSTNAME \"$DEPLOY_TRUENAS_HOSTNAME\" _debug2 DEPLOY_TRUENAS_SCHEME \"$DEPLOY_TRUENAS_SCHEME\" _api_url=\"$DEPLOY_TRUENAS_SCHEME://$DEPLOY_TRUENAS_HOSTNAME/api/v2.0\" _debug _api_url \"$_api_url\" _H1=\"Authorization: Bearer $DEPLOY_TRUENAS_APIKEY\" _secure_debug3 _H1 \"$_H1\" _info \"Testing Connection TrueNAS\" _response=$(_get \"$_api_url/system/state\") _info \"TrueNAS system state: $_response.\" if [ -z \"$_response\" ]; then _err \"Unable to authenticate to $_api_url.\" _err 'Check your connection settings are correct, e.g.' _err 'DEPLOY_TRUENAS_HOSTNAME=\"192.168.x.y\" or DEPLOY_TRUENAS_HOSTNAME=\"truenas.example.com\".' _err 'DEPLOY_TRUENAS_SCHEME=\"https\" or DEPLOY_TRUENAS_SCHEME=\"http\".' _err \"Verify your TrueNAS API key is valid and set correctly, e.g. DEPLOY_TRUENAS_APIKEY=xxxx....\" return 1 fi _savedeployconf DEPLOY_TRUENAS_APIKEY \"$DEPLOY_TRUENAS_APIKEY\" _savedeployconf DEPLOY_TRUENAS_HOSTNAME \"$DEPLOY_TRUENAS_HOSTNAME\" _savedeployconf DEPLOY_TRUENAS_SCHEME \"$DEPLOY_TRUENAS_SCHEME\" _info \"Getting current active certificate from TrueNAS\" _response=$(_get \"$_api_url/system/general\") _active_cert_id=$(echo \"$_response\" | grep -B2 '\"name\":' | grep 'id' | tr -d -- '\"id: ,') _active_cert_name=$(echo \"$_response\" | grep '\"name\":' | sed -n 's/.*: \"\\(.\\{1,\\}\\)\",$/\\1/p') _param_httpsredirect=$(echo \"$_response\" | grep '\"ui_httpsredirect\":' | sed -n 's/.*\": \\(.\\{1,\\}\\),$/\\1/p') _debug Active_UI_Certificate_ID \"$_active_cert_id\" _debug Active_UI_Certificate_Name \"$_active_cert_name\" _debug Active_UI_http_redirect \"$_param_httpsredirect\" if [ \"$DEPLOY_TRUENAS_SCHEME\" = \"http\" ] && [ \"$_param_httpsredirect\" = \"true\" ]; then _info \"HTTP->HTTPS redirection is enabled\" _info \"Setting DEPLOY_TRUENAS_SCHEME to 'https'\" DEPLOY_TRUENAS_SCHEME=\"https\" _api_url=\"$DEPLOY_TRUENAS_SCHEME://$DEPLOY_TRUENAS_HOSTNAME/api/v2.0\" _savedeployconf DEPLOY_TRUENAS_SCHEME \"$DEPLOY_TRUENAS_SCHEME\" fi _info \"Uploading new certificate to TrueNAS\" _certname=\"Letsencrypt_$(_utc_date | tr ' ' '_' | tr -d -- ':')\" _debug3 _certname \"$_certname\" _certData=\"{\\\"create_type\\\": \\\"CERTIFICATE_CREATE_IMPORTED\\\", \\\"name\\\": \\\"${_certname}\\\", \\\"certificate\\\": \\\"$(_json_encode <\"$_cfullchain\")\\\", \\\"privatekey\\\": \\\"$(_json_encode <\"$_ckey\")\\\"}\" _add_cert_result=\"$(_post \"$_certData\" \"$_api_url/certificate\" \"\" \"POST\" \"application/json\")\" _debug3 _add_cert_result \"$_add_cert_result\" _info \"Fetching list of installed certificates\" _cert_list=$(_get \"$_api_url/system/general/ui_certificate_choices\") _cert_id=$(echo \"$_cert_list\" | grep \"$_certname\" | sed -n 's/.*\"\\([0-9]\\{1,\\}\\)\".*$/\\1/p') _debug3 _cert_id \"$_cert_id\" _info \"Current activate certificate ID: $_cert_id\" _activateData=\"{\\\"ui_certificate\\\": \\\"${_cert_id}\\\"}\" _activate_result=\"$(_post \"$_activateData\" \"$_api_url/system/general\" \"\" \"PUT\" \"application/json\")\" _debug3 _activate_result \"$_activate_result\" _info \"Checking if WebDAV certificate is the same as the TrueNAS web UI\" _webdav_list=$(_get \"$_api_url/webdav\") _webdav_cert_id=$(echo \"$_webdav_list\" | grep '\"certssl\":' | tr -d -- '\"certsl: ,') if [ \"$_webdav_cert_id\" = \"$_active_cert_id\" ]; then _info \"Updating the WebDAV certificate\" _debug _webdav_cert_id \"$_webdav_cert_id\" _webdav_data=\"{\\\"certssl\\\": \\\"${_cert_id}\\\"}\" _activate_webdav_cert=\"$(_post \"$_webdav_data\" \"$_api_url/webdav\" \"\" \"PUT\" \"application/json\")\" _webdav_new_cert_id=$(echo \"$_activate_webdav_cert\" | _json_decode | grep '\"certssl\":' | sed -n 's/.*: \\([0-9]\\{1,\\}\\),\\{0,1\\}$/\\1/p') if [ \"$_webdav_new_cert_id\" -eq \"$_cert_id\" ]; then _info \"WebDAV certificate updated successfully\" else _err \"Unable to set WebDAV certificate\" _debug3 _activate_webdav_cert \"$_activate_webdav_cert\" _debug3 _webdav_new_cert_id \"$_webdav_new_cert_id\" return 1 fi _debug3 _webdav_new_cert_id \"$_webdav_new_cert_id\" else _info \"WebDAV certificate is not configured or is not the same as TrueNAS web UI\" fi _info \"Checking if FTP certificate is the same as the TrueNAS web UI\" _ftp_list=$(_get \"$_api_url/ftp\") _ftp_cert_id=$(echo \"$_ftp_list\" | grep '\"ssltls_certificate\":' | tr -d -- '\"certislfa:_ ,') if [ \"$_ftp_cert_id\" = \"$_active_cert_id\" ]; then _info \"Updating the FTP certificate\" _debug _ftp_cert_id \"$_ftp_cert_id\" _ftp_data=\"{\\\"ssltls_certificate\\\": \\\"${_cert_id}\\\"}\" _activate_ftp_cert=\"$(_post \"$_ftp_data\" \"$_api_url/ftp\" \"\" \"PUT\" \"application/json\")\" _ftp_new_cert_id=$(echo \"$_activate_ftp_cert\" | _json_decode | grep '\"ssltls_certificate\":' | sed -n 's/.*: \\([0-9]\\{1,\\}\\),\\{0,1\\}$/\\1/p') if [ \"$_ftp_new_cert_id\" -eq \"$_cert_id\" ]; then _info \"FTP certificate updated successfully\" else _err \"Unable to set FTP certificate\" _debug3 _activate_ftp_cert \"$_activate_ftp_cert\" _debug3 _ftp_new_cert_id \"$_ftp_new_cert_id\" return 1 fi _debug3 _activate_ftp_cert \"$_activate_ftp_cert\" else _info \"FTP certificate is not configured or is not the same as TrueNAS web UI\" fi _info \"Checking if S3 certificate is the same as the TrueNAS web UI\" _s3_list=$(_get \"$_api_url/s3\") _s3_cert_id=$(echo \"$_s3_list\" | grep '\"certificate\":' | tr -d -- '\"certifa:_ ,') if [ \"$_s3_cert_id\" = \"$_active_cert_id\" ]; then _info \"Updating the S3 certificate\" _debug _s3_cert_id \"$_s3_cert_id\" _s3_data=\"{\\\"certificate\\\": \\\"${_cert_id}\\\"}\" _activate_s3_cert=\"$(_post \"$_s3_data\" \"$_api_url/s3\" \"\" \"PUT\" \"application/json\")\" _s3_new_cert_id=$(echo \"$_activate_s3_cert\" | _json_decode | grep '\"certificate\":' | sed -n 's/.*: \\([0-9]\\{1,\\}\\),\\{0,1\\}$/\\1/p') if [ \"$_s3_new_cert_id\" -eq \"$_cert_id\" ]; then _info \"S3 certificate updated successfully\" else _err \"Unable to set S3 certificate\" _debug3 _activate_s3_cert \"$_activate_s3_cert\" _debug3 _s3_new_cert_id \"$_s3_new_cert_id\" return 1 fi _debug3 _activate_s3_cert \"$_activate_s3_cert\" else _info \"S3 certificate is not configured or is not the same as TrueNAS web UI\" fi _info \"Checking if any chart release Apps is using the same certificate as TrueNAS web UI. Tool 'jq' is required\" if _exists jq; then _info \"Query all chart release\" _release_list=$(_get \"$_api_url/chart/release\") _related_name_list=$(printf \"%s\" \"$_release_list\" | jq -r \"[.[] | {name,certId: .config.ingress?.main.tls[]?.scaleCert} | select(.certId==$_active_cert_id) | .name ] | unique\") _release_length=$(printf \"%s\" \"$_related_name_list\" | jq -r \"length\") _info \"Found $_release_length related chart release in list: $_related_name_list\" for i in $(seq 0 $((_release_length - 1))); do _release_name=$(echo \"$_related_name_list\" | jq -r \".[$i]\") _info \"Updating certificate from $_active_cert_id to $_cert_id for chart release: $_release_name\" #Read the chart release configuration _chart_config=$(printf \"%s\" \"$_release_list\" | jq -r \".[] | select(.name==\\\"$_release_name\\\")\") #Replace the old certificate id with the new one in path .config.ingress.main.tls[].scaleCert. Then update .config.ingress _updated_chart_config=$(printf \"%s\" \"$_chart_config\" | jq \"(.config.ingress?.main.tls[]? | select(.scaleCert==$_active_cert_id) | .scaleCert ) |= $_cert_id | .config.ingress \") _update_chart_result=\"$(_post \"{\\\"values\\\" : { \\\"ingress\\\" : $_updated_chart_config } }\" \"$_api_url/chart/release/id/$_release_name\" \"\" \"PUT\" \"application/json\")\" _debug3 _update_chart_result \"$_update_chart_result\" done else _info \"Tool 'jq' does not exists, skip chart release checking\" fi _info \"Deleting old certificate\" _delete_result=\"$(_post \"\" \"$_api_url/certificate/id/$_active_cert_id\" \"\" \"DELETE\" \"application/json\")\" _debug3 _delete_result \"$_delete_result\" _info \"Reloading TrueNAS web UI\" _restart_UI=$(_get \"$_api_url/system/general/ui_restart\") _debug2 _restart_UI \"$_restart_UI\" if [ -n \"$_add_cert_result\" ] && [ -n \"$_activate_result\" ]; then return 0 else _err \"Certificate update was not succesful, please try again with --debug\" return 1 fi }"
        },
        {
            "filename": "file_149.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_149.sh",
            "content": "#!/usr/bin/env sh # Here is a script to deploy cert on a Unifi Controller or Cloud Key device. # It supports: # - self-hosted Unifi Controller # - Unifi Cloud Key (Gen1/2/2+) # - Unifi Cloud Key running UnifiOS (v2.0.0+, Gen2/2+ only) # - Unifi Dream Machine # This has not been tested on other \"all-in-one\" devices such as # UDM Pro or Unifi Express. # # OS Version v2.0.0+ # Network Application version 7.0.0+ # OS version ~3.1 removed java and keytool from the UnifiOS. # Using PKCS12 format keystore appears to work fine. # # Please report bugs to https://github.com/acmesh-official/acme.sh/issues/3359 #returns 0 means success, otherwise error. # The deploy-hook automatically detects standard Unifi installations # for each of the supported environments. Most users should not need # to set any of these variables, but if you are running a self-hosted # Controller with custom locations, set these as necessary before running # the deploy hook. (Defaults shown below.) # # Settings for Unifi Controller: # Location of Java keystore or unifi.keystore.jks file: #DEPLOY_UNIFI_KEYSTORE=\"/usr/lib/unifi/data/keystore\" # Keystore password (built into Unifi Controller, not a user-set password): #DEPLOY_UNIFI_KEYPASS=\"aircontrolenterprise\" # Command to restart Unifi Controller: #DEPLOY_UNIFI_RELOAD=\"service unifi restart\" # # Settings for Unifi Cloud Key Gen1 (nginx admin pages): # Directory where cloudkey.crt and cloudkey.key live: #DEPLOY_UNIFI_CLOUDKEY_CERTDIR=\"/etc/ssl/private\" # Command to restart maintenance pages and Controller # (same setting as above, default is updated when running on Cloud Key Gen1): #DEPLOY_UNIFI_RELOAD=\"service nginx restart && service unifi restart\" # # Settings for UnifiOS (Cloud Key Gen2): # Directory where unifi-core.crt and unifi-core.key live: #DEPLOY_UNIFI_CORE_CONFIG=\"/data/unifi-core/config/\" # Command to restart unifi-core: #DEPLOY_UNIFI_RELOAD=\"systemctl restart unifi-core\" # # At least one of DEPLOY_UNIFI_KEYSTORE, DEPLOY_UNIFI_CLOUDKEY_CERTDIR, # or DEPLOY_UNIFI_CORE_CONFIG must exist to receive the deployed certs. ######## Public functions ##################### #domain keyfile certfile cafile fullchain unifi_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _getdeployconf DEPLOY_UNIFI_KEYSTORE _getdeployconf DEPLOY_UNIFI_KEYPASS _getdeployconf DEPLOY_UNIFI_CLOUDKEY_CERTDIR _getdeployconf DEPLOY_UNIFI_CORE_CONFIG _getdeployconf DEPLOY_UNIFI_RELOAD _debug2 DEPLOY_UNIFI_KEYSTORE \"$DEPLOY_UNIFI_KEYSTORE\" _debug2 DEPLOY_UNIFI_KEYPASS \"$DEPLOY_UNIFI_KEYPASS\" _debug2 DEPLOY_UNIFI_CLOUDKEY_CERTDIR \"$DEPLOY_UNIFI_CLOUDKEY_CERTDIR\" _debug2 DEPLOY_UNIFI_CORE_CONFIG \"$DEPLOY_UNIFI_CORE_CONFIG\" _debug2 DEPLOY_UNIFI_RELOAD \"$DEPLOY_UNIFI_RELOAD\" # Space-separated list of environments detected and installed: _services_updated=\"\" # Default reload commands accumulated as we auto-detect environments: _reload_cmd=\"\" # Unifi Controller environment (self hosted or any Cloud Key) -- # auto-detect by file /usr/lib/unifi/data/keystore _unifi_keystore=\"${DEPLOY_UNIFI_KEYSTORE:-/usr/lib/unifi/data/keystore}\" if [ -f \"$_unifi_keystore\" ]; then _debug _unifi_keystore \"$_unifi_keystore\" if ! _exists keytool; then _do_keytool=0 _info \"Installing certificate for Unifi Controller (PKCS12 keystore).\" else _do_keytool=1 _info \"Installing certificate for Unifi Controller (Java keystore)\" fi if [ ! -w \"$_unifi_keystore\" ]; then _err \"The file $_unifi_keystore is not writable, please change the permission.\" return 1 fi _unifi_keypass=\"${DEPLOY_UNIFI_KEYPASS:-aircontrolenterprise}\" _debug \"Generate import pkcs12\" _import_pkcs12=\"$(_mktemp)\" _debug \"_toPkcs $_import_pkcs12 $_ckey $_ccert $_cca $_unifi_keypass unifi root\" _toPkcs \"$_import_pkcs12\" \"$_ckey\" \"$_ccert\" \"$_cca\" \"$_unifi_keypass\" unifi root # shellcheck disable=SC2181 if [ \"$?\" != \"0\" ]; then _err \"Error generating pkcs12. Please re-run with --debug and report a bug.\" return 1 fi # Save the existing keystore in case something goes wrong. mv -f \"${_unifi_keystore}\" \"${_unifi_keystore}\"_original _info \"Previous keystore saved to ${_unifi_keystore}_original.\" if [ \"$_do_keytool\" -eq 1 ]; then _debug \"Import into keystore: $_unifi_keystore\" if keytool -importkeystore \\ -deststorepass \"$_unifi_keypass\" -destkeypass \"$_unifi_keypass\" -destkeystore \"$_unifi_keystore\" \\ -srckeystore \"$_import_pkcs12\" -srcstoretype PKCS12 -srcstorepass \"$_unifi_keypass\" \\ -alias unifi -noprompt; then _debug \"Import keystore success!\" else _err \"Error importing into Unifi Java keystore.\" _err \"Please re-run with --debug and report a bug.\" _info \"Restoring original keystore.\" mv -f \"${_unifi_keystore}\"_original \"${_unifi_keystore}\" rm \"$_import_pkcs12\" return 1 fi else _debug \"Copying new keystore to $_unifi_keystore\" cp -f \"$_import_pkcs12\" \"$_unifi_keystore\" fi # Update unifi service for certificate cipher compatibility if ${ACME_OPENSSL_BIN:-openssl} pkcs12 \\ -in \"$_import_pkcs12\" \\ -password pass:aircontrolenterprise \\ -nokeys | ${ACME_OPENSSL_BIN:-openssl} x509 -text \\ -noout | grep -i \"signature\" | grep -iq ecdsa >/dev/null 2>&1; then cp -f /usr/lib/unifi/data/system.properties /usr/lib/unifi/data/system.properties_original _info \"Updating system configuration for cipher compatibility.\" _info \"Saved original system config to /usr/lib/unifi/data/system.properties_original\" sed -i '/unifi\\.https\\.ciphers/d' /usr/lib/unifi/data/system.properties echo \"unifi.https.ciphers=ECDHE-ECDSA-AES256-GCM-SHA384,ECDHE-RSA-AES128-GCM-SHA256\" >>/usr/lib/unifi/data/system.properties sed -i '/unifi\\.https\\.sslEnabledProtocols/d' /usr/lib/unifi/data/system.properties echo \"unifi.https.sslEnabledProtocols=TLSv1.3,TLSv1.2\" >>/usr/lib/unifi/data/system.properties _info \"System configuration updated.\" fi rm \"$_import_pkcs12\" # Restarting unifi-core will bring up unifi, doing it out of order results in # a certificate error, and breaks wifiman. # Restart if we aren't doing unifi-core, otherwise stop for later restart. if systemctl -q is-active unifi; then if [ ! -f \"${DEPLOY_UNIFI_CORE_CONFIG:-/data/unifi-core/config}/unifi-core.key\" ]; then _reload_cmd=\"${_reload_cmd:+$_reload_cmd && }systemctl restart unifi\" else _reload_cmd=\"${_reload_cmd:+$_reload_cmd && }systemctl stop unifi\" fi fi _services_updated=\"${_services_updated} unifi\" _info \"Install Unifi Controller certificate success!\" elif [ \"$DEPLOY_UNIFI_KEYSTORE\" ]; then _err \"The specified DEPLOY_UNIFI_KEYSTORE='$DEPLOY_UNIFI_KEYSTORE' is not valid, please check.\" return 1 fi # Cloud Key environment (non-UnifiOS -- nginx serves admin pages) -- # auto-detect by file /etc/ssl/private/cloudkey.key: _cloudkey_certdir=\"${DEPLOY_UNIFI_CLOUDKEY_CERTDIR:-/etc/ssl/private}\" if [ -f \"${_cloudkey_certdir}/cloudkey.key\" ]; then _info \"Installing certificate for Cloud Key Gen1 (nginx admin pages)\" _debug _cloudkey_certdir \"$_cloudkey_certdir\" if [ ! -w \"$_cloudkey_certdir\" ]; then _err \"The directory $_cloudkey_certdir is not writable; please check permissions.\" return 1 fi # Cloud Key expects to load the keystore from /etc/ssl/private/unifi.keystore.jks. # Normally /usr/lib/unifi/data/keystore is a symlink there (so the keystore was # updated above), but if not, we don't know how to handle this installation: if ! cmp -s \"$_unifi_keystore\" \"${_cloudkey_certdir}/unifi.keystore.jks\"; then _err \"Unsupported Cloud Key configuration: keystore not found at '${_cloudkey_certdir}/unifi.keystore.jks'\" return 1 fi cat \"$_cfullchain\" >\"${_cloudkey_certdir}/cloudkey.crt\" cat \"$_ckey\" >\"${_cloudkey_certdir}/cloudkey.key\" (cd \"$_cloudkey_certdir\" && tar -cf cert.tar cloudkey.crt cloudkey.key unifi.keystore.jks) if systemctl -q is-active nginx; then _reload_cmd=\"${_reload_cmd:+$_reload_cmd && }service nginx restart\" fi _info \"Install Cloud Key Gen1 certificate success!\" _services_updated=\"${_services_updated} nginx\" elif [ \"$DEPLOY_UNIFI_CLOUDKEY_CERTDIR\" ]; then _err \"The specified DEPLOY_UNIFI_CLOUDKEY_CERTDIR='$DEPLOY_UNIFI_CLOUDKEY_CERTDIR' is not valid, please check.\" return 1 fi # UnifiOS environment -- auto-detect by /data/unifi-core/config/unifi-core.key: _unifi_core_config=\"${DEPLOY_UNIFI_CORE_CONFIG:-/data/unifi-core/config}\" if [ -f \"${_unifi_core_config}/unifi-core.key\" ]; then _info \"Installing certificate for UnifiOS\" _debug _unifi_core_config \"$_unifi_core_config\" if [ ! -w \"$_unifi_core_config\" ]; then _err \"The directory $_unifi_core_config is not writable; please check permissions.\" return 1 fi # Save the existing certs in case something goes wrong. cp -f \"${_unifi_core_config}\"/unifi-core.crt \"${_unifi_core_config}\"/unifi-core_original.crt cp -f \"${_unifi_core_config}\"/unifi-core.key \"${_unifi_core_config}\"/unifi-core_original.key _info \"Previous certificate and key saved to ${_unifi_core_config}/unifi-core_original.crt/key.\" cat \"$_cfullchain\" >\"${_unifi_core_config}/unifi-core.crt\" cat \"$_ckey\" >\"${_unifi_core_config}/unifi-core.key\" if systemctl -q is-active unifi-core; then _reload_cmd=\"${_reload_cmd:+$_reload_cmd && }systemctl restart unifi-core\" fi _info \"Install UnifiOS certificate success!\" _services_updated=\"${_services_updated} unifi-core\" elif [ \"$DEPLOY_UNIFI_CORE_CONFIG\" ]; then _err \"The specified DEPLOY_UNIFI_CORE_CONFIG='$DEPLOY_UNIFI_CORE_CONFIG' is not valid, please check.\" return 1 fi if [ -z \"$_services_updated\" ]; then # None of the Unifi environments were auto-detected, so no deployment has occurred # (and none of DEPLOY_UNIFI_{KEYSTORE,CLOUDKEY_CERTDIR,CORE_CONFIG} were set). _err \"Unable to detect Unifi environment in standard location.\" _err \"(This deploy hook must be run on the Unifi device, not a remote machine.)\" _err \"For non-standard Unifi installations, set DEPLOY_UNIFI_KEYSTORE,\" _err \"DEPLOY_UNIFI_CLOUDKEY_CERTDIR, and/or DEPLOY_UNIFI_CORE_CONFIG as appropriate.\" return 1 fi _reload_cmd=\"${DEPLOY_UNIFI_RELOAD:-$_reload_cmd}\" if [ -z \"$_reload_cmd\" ]; then _err \"Certificates were installed for services:${_services_updated},\" _err \"but none appear to be active. Please set DEPLOY_UNIFI_RELOAD\" _err \"to a command that will restart the necessary services.\" return 1 fi _info \"Reload services (this may take some time): $_reload_cmd\" if eval \"$_reload_cmd\"; then _info \"Reload success!\" else _err \"Reload error\" return 1 fi # Successful, so save all (non-default) config: _savedeployconf DEPLOY_UNIFI_KEYSTORE \"$DEPLOY_UNIFI_KEYSTORE\" _savedeployconf DEPLOY_UNIFI_KEYPASS \"$DEPLOY_UNIFI_KEYPASS\" _savedeployconf DEPLOY_UNIFI_CLOUDKEY_CERTDIR \"$DEPLOY_UNIFI_CLOUDKEY_CERTDIR\" _savedeployconf DEPLOY_UNIFI_CORE_CONFIG \"$DEPLOY_UNIFI_CORE_CONFIG\" _savedeployconf DEPLOY_UNIFI_RELOAD \"$DEPLOY_UNIFI_RELOAD\" return 0 }"
        },
        {
            "filename": "file_150.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_150.sh",
            "content": "#!/usr/bin/env sh # Here is a script to deploy cert to hashicorp vault using curl # (https://www.vaultproject.io/) # # it requires following environment variables: # # VAULT_PREFIX - this contains the prefix path in vault # VAULT_ADDR - vault requires this to find your vault server # VAULT_SAVE_TOKEN - set to anything if you want to save the token # VAULT_RENEW_TOKEN - set to anything if you want to renew the token to default TTL before deploying # VAULT_KV_V2 - set to anything if you are using v2 of the kv engine # # additionally, you need to ensure that VAULT_TOKEN is avialable # to access the vault server #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain vault_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" # validate required env vars _getdeployconf VAULT_PREFIX if [ -z \"$VAULT_PREFIX\" ]; then _err \"VAULT_PREFIX needs to be defined (contains prefix path in vault)\" return 1 fi _savedeployconf VAULT_PREFIX \"$VAULT_PREFIX\" _getdeployconf VAULT_ADDR if [ -z \"$VAULT_ADDR\" ]; then _err \"VAULT_ADDR needs to be defined (contains vault connection address)\" return 1 fi _savedeployconf VAULT_ADDR \"$VAULT_ADDR\" _getdeployconf VAULT_SAVE_TOKEN _savedeployconf VAULT_SAVE_TOKEN \"$VAULT_SAVE_TOKEN\" _getdeployconf VAULT_RENEW_TOKEN _savedeployconf VAULT_RENEW_TOKEN \"$VAULT_RENEW_TOKEN\" _getdeployconf VAULT_KV_V2 _savedeployconf VAULT_KV_V2 \"$VAULT_KV_V2\" _getdeployconf VAULT_TOKEN if [ -z \"$VAULT_TOKEN\" ]; then _err \"VAULT_TOKEN needs to be defined\" return 1 fi if [ -n \"$VAULT_SAVE_TOKEN\" ]; then _savedeployconf VAULT_TOKEN \"$VAULT_TOKEN\" fi _migratedeployconf FABIO VAULT_FABIO_MODE # JSON does not allow multiline strings. # So replacing new-lines with \"\\n\" here _ckey=$(sed -e ':a' -e N -e '$ ! ba' -e 's/\\n/\\\\n/g' <\"$2\") _ccert=$(sed -e ':a' -e N -e '$ ! ba' -e 's/\\n/\\\\n/g' <\"$3\") _cca=$(sed -e ':a' -e N -e '$ ! ba' -e 's/\\n/\\\\n/g' <\"$4\") _cfullchain=$(sed -e ':a' -e N -e '$ ! ba' -e 's/\\n/\\\\n/g' <\"$5\") export _H1=\"X-Vault-Token: $VAULT_TOKEN\" if [ -n \"$VAULT_RENEW_TOKEN\" ]; then URL=\"$VAULT_ADDR/v1/auth/token/renew-self\" _info \"Renew the Vault token to default TTL\" if ! _post \"\" \"$URL\" >/dev/null; then _err \"Failed to renew the Vault token\" return 1 fi fi URL=\"$VAULT_ADDR/v1/$VAULT_PREFIX/$_cdomain\" if [ -n \"$VAULT_FABIO_MODE\" ]; then _info \"Writing certificate and key to $URL in Fabio mode\" if [ -n \"$VAULT_KV_V2\" ]; then _post \"{ \\\"data\\\": {\\\"cert\\\": \\\"$_cfullchain\\\", \\\"key\\\": \\\"$_ckey\\\"} }\" \"$URL\" >/dev/null || return 1 else _post \"{\\\"cert\\\": \\\"$_cfullchain\\\", \\\"key\\\": \\\"$_ckey\\\"}\" \"$URL\" >/dev/null || return 1 fi else if [ -n \"$VAULT_KV_V2\" ]; then _info \"Writing certificate to $URL/cert.pem\" _post \"{\\\"data\\\": {\\\"value\\\": \\\"$_ccert\\\"}}\" \"$URL/cert.pem\" >/dev/null || return 1 _info \"Writing key to $URL/cert.key\" _post \"{\\\"data\\\": {\\\"value\\\": \\\"$_ckey\\\"}}\" \"$URL/cert.key\" >/dev/null || return 1 _info \"Writing CA certificate to $URL/ca.pem\" _post \"{\\\"data\\\": {\\\"value\\\": \\\"$_cca\\\"}}\" \"$URL/ca.pem\" >/dev/null || return 1 _info \"Writing full-chain certificate to $URL/fullchain.pem\" _post \"{\\\"data\\\": {\\\"value\\\": \\\"$_cfullchain\\\"}}\" \"$URL/fullchain.pem\" >/dev/null || return 1 else _info \"Writing certificate to $URL/cert.pem\" _post \"{\\\"value\\\": \\\"$_ccert\\\"}\" \"$URL/cert.pem\" >/dev/null || return 1 _info \"Writing key to $URL/cert.key\" _post \"{\\\"value\\\": \\\"$_ckey\\\"}\" \"$URL/cert.key\" >/dev/null || return 1 _info \"Writing CA certificate to $URL/ca.pem\" _post \"{\\\"value\\\": \\\"$_cca\\\"}\" \"$URL/ca.pem\" >/dev/null || return 1 _info \"Writing full-chain certificate to $URL/fullchain.pem\" _post \"{\\\"value\\\": \\\"$_cfullchain\\\"}\" \"$URL/fullchain.pem\" >/dev/null || return 1 fi # To make it compatible with the wrong ca path `chain.pem` which was used in former versions if _contains \"$(_get \"$URL/chain.pem\")\" \"-----BEGIN CERTIFICATE-----\"; then _err \"The CA certificate has moved from chain.pem to ca.pem, if you don't depend on chain.pem anymore, you can delete it to avoid this warning\" _info \"Updating CA certificate to $URL/chain.pem for backward compatibility\" if [ -n \"$VAULT_KV_V2\" ]; then _post \"{\\\"data\\\": {\\\"value\\\": \\\"$_cca\\\"}}\" \"$URL/chain.pem\" >/dev/null || return 1 else _post \"{\\\"value\\\": \\\"$_cca\\\"}\" \"$URL/chain.pem\" >/dev/null || return 1 fi fi fi }"
        },
        {
            "filename": "file_151.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_151.sh",
            "content": "#!/usr/bin/env sh # Here is a script to deploy cert to hashicorp vault # (https://www.vaultproject.io/) # # it requires the vault binary to be available in PATH, and the following # environment variables: # # VAULT_PREFIX - this contains the prefix path in vault # VAULT_ADDR - vault requires this to find your vault server # VAULT_SAVE_TOKEN - set to anything if you want to save the token # VAULT_RENEW_TOKEN - set to anything if you want to renew the token to default TTL before deploying # # additionally, you need to ensure that VAULT_TOKEN is avialable or # `vault auth` has applied the appropriate authorization for the vault binary # to access the vault server #returns 0 means success, otherwise error. ######## Public functions ##################### #domain keyfile certfile cafile fullchain vault_cli_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" # validate required env vars _getdeployconf VAULT_PREFIX if [ -z \"$VAULT_PREFIX\" ]; then _err \"VAULT_PREFIX needs to be defined (contains prefix path in vault)\" return 1 fi _savedeployconf VAULT_PREFIX \"$VAULT_PREFIX\" _getdeployconf VAULT_ADDR if [ -z \"$VAULT_ADDR\" ]; then _err \"VAULT_ADDR needs to be defined (contains vault connection address)\" return 1 fi _savedeployconf VAULT_ADDR \"$VAULT_ADDR\" _getdeployconf VAULT_SAVE_TOKEN _savedeployconf VAULT_SAVE_TOKEN \"$VAULT_SAVE_TOKEN\" _getdeployconf VAULT_RENEW_TOKEN _savedeployconf VAULT_RENEW_TOKEN \"$VAULT_RENEW_TOKEN\" _getdeployconf VAULT_TOKEN if [ -z \"$VAULT_TOKEN\" ]; then _err \"VAULT_TOKEN needs to be defined\" return 1 fi if [ -n \"$VAULT_SAVE_TOKEN\" ]; then _savedeployconf VAULT_TOKEN \"$VAULT_TOKEN\" fi _migratedeployconf FABIO VAULT_FABIO_MODE VAULT_CMD=$(command -v vault) if [ ! $? ]; then _err \"cannot find vault binary!\" return 1 fi if [ -n \"$VAULT_RENEW_TOKEN\" ]; then _info \"Renew the Vault token to default TTL\" if ! $VAULT_CMD token renew; then _err \"Failed to renew the Vault token\" return 1 fi fi if [ -n \"$VAULT_FABIO_MODE\" ]; then _info \"Writing certificate and key to ${VAULT_PREFIX}/${_cdomain} in Fabio mode\" $VAULT_CMD kv put \"${VAULT_PREFIX}/${_cdomain}\" cert=@\"$_cfullchain\" key=@\"$_ckey\" || return 1 else _info \"Writing certificate to ${VAULT_PREFIX}/${_cdomain}/cert.pem\" $VAULT_CMD kv put \"${VAULT_PREFIX}/${_cdomain}/cert.pem\" value=@\"$_ccert\" || return 1 _info \"Writing key to ${VAULT_PREFIX}/${_cdomain}/cert.key\" $VAULT_CMD kv put \"${VAULT_PREFIX}/${_cdomain}/cert.key\" value=@\"$_ckey\" || return 1 _info \"Writing CA certificate to ${VAULT_PREFIX}/${_cdomain}/ca.pem\" $VAULT_CMD kv put \"${VAULT_PREFIX}/${_cdomain}/ca.pem\" value=@\"$_cca\" || return 1 _info \"Writing full-chain certificate to ${VAULT_PREFIX}/${_cdomain}/fullchain.pem\" $VAULT_CMD kv put \"${VAULT_PREFIX}/${_cdomain}/fullchain.pem\" value=@\"$_cfullchain\" || return 1 # To make it compatible with the wrong ca path `chain.pem` which was used in former versions if $VAULT_CMD kv get \"${VAULT_PREFIX}/${_cdomain}/chain.pem\" >/dev/null; then _err \"The CA certificate has moved from chain.pem to ca.pem, if you don't depend on chain.pem anymore, you can delete it to avoid this warning\" _info \"Updating CA certificate to ${VAULT_PREFIX}/${_cdomain}/chain.pem for backward compatibility\" $VAULT_CMD kv put \"${VAULT_PREFIX}/${_cdomain}/chain.pem\" value=@\"$_cca\" || return 1 fi fi }"
        },
        {
            "filename": "file_152.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\deploy\\file_152.sh",
            "content": "#!/usr/bin/env sh #Here is a script to deploy cert to vsftpd server. #returns 0 means success, otherwise error. #DEPLOY_VSFTPD_CONF=\"/etc/vsftpd.conf\" #DEPLOY_VSFTPD_RELOAD=\"service vsftpd restart\" ######## Public functions ##################### #domain keyfile certfile cafile fullchain vsftpd_deploy() { _cdomain=\"$1\" _ckey=\"$2\" _ccert=\"$3\" _cca=\"$4\" _cfullchain=\"$5\" _debug _cdomain \"$_cdomain\" _debug _ckey \"$_ckey\" _debug _ccert \"$_ccert\" _debug _cca \"$_cca\" _debug _cfullchain \"$_cfullchain\" _ssl_path=\"/etc/acme.sh/vsftpd\" if ! mkdir -p \"$_ssl_path\"; then _err \"Can not create folder:$_ssl_path\" return 1 fi _info \"Copying key and cert\" _real_key=\"$_ssl_path/vsftpd.key\" if ! cat \"$_ckey\" >\"$_real_key\"; then _err \"Error: write key file to: $_real_key\" return 1 fi _real_fullchain=\"$_ssl_path/vsftpd.chain.pem\" if ! cat \"$_cfullchain\" >\"$_real_fullchain\"; then _err \"Error: write key file to: $_real_fullchain\" return 1 fi DEFAULT_VSFTPD_RELOAD=\"service vsftpd restart\" _reload=\"${DEPLOY_VSFTPD_RELOAD:-$DEFAULT_VSFTPD_RELOAD}\" if [ -z \"$IS_RENEW\" ]; then DEFAULT_VSFTPD_CONF=\"/etc/vsftpd.conf\" _vsftpd_conf=\"${DEPLOY_VSFTPD_CONF:-$DEFAULT_VSFTPD_CONF}\" if [ ! -f \"$_vsftpd_conf\" ]; then if [ -z \"$DEPLOY_VSFTPD_CONF\" ]; then _err \"vsftpd conf is not found, please define DEPLOY_VSFTPD_CONF\" return 1 else _err \"It seems that the specified vsftpd conf is not valid, please check.\" return 1 fi fi if [ ! -w \"$_vsftpd_conf\" ]; then _err \"The file $_vsftpd_conf is not writable, please change the permission.\" return 1 fi _backup_conf=\"$DOMAIN_BACKUP_PATH/vsftpd.conf.bak\" _info \"Backup $_vsftpd_conf to $_backup_conf\" cp \"$_vsftpd_conf\" \"$_backup_conf\" _info \"Modify vsftpd conf: $_vsftpd_conf\" if _setopt \"$_vsftpd_conf\" \"rsa_cert_file\" \"=\" \"$_real_fullchain\" && _setopt \"$_vsftpd_conf\" \"rsa_private_key_file\" \"=\" \"$_real_key\" && _setopt \"$_vsftpd_conf\" \"ssl_enable\" \"=\" \"YES\"; then _info \"Set config success!\" else _err \"Config vsftpd server error, please report bug to us.\" _info \"Restoring vsftpd conf\" if cat \"$_backup_conf\" >\"$_vsftpd_conf\"; then _info \"Restore conf success\" eval \"$_reload\" else _err \"Oops, error restore vsftpd conf, please report bug to us.\" fi return 1 fi fi _info \"Run reload: $_reload\" if eval \"$_reload\"; then _info \"Reload success!\" if [ \"$DEPLOY_VSFTPD_CONF\" ]; then _savedomainconf DEPLOY_VSFTPD_CONF \"$DEPLOY_VSFTPD_CONF\" else _cleardomainconf DEPLOY_VSFTPD_CONF fi if [ \"$DEPLOY_VSFTPD_RELOAD\" ]; then _savedomainconf DEPLOY_VSFTPD_RELOAD \"$DEPLOY_VSFTPD_RELOAD\" else _cleardomainconf DEPLOY_VSFTPD_RELOAD fi return 0 else _err \"Reload error, restoring\" if cat \"$_backup_conf\" >\"$_vsftpd_conf\"; then _info \"Restore conf success\" eval \"$_reload\" else _err \"Oops, error restore vsftpd conf, please report bug to us.\" fi return 1 fi return 0 }"
        },
        {
            "filename": "file_153.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_153.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_1984hosting_info='1984.hosting Domains: 1984.is Site: 1984.hosting Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_1984hosting Options: One984HOSTING_Username Username One984HOSTING_Password Password Issues: github.com/acmesh-official/acme.sh/issues/2851 Author: Adrian Fedoreanu ' ######## Public functions ##################### # Usage: dns_1984hosting_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Add a text record. dns_1984hosting_add() { fulldomain=$1 txtvalue=$2 _info \"Add TXT record using 1984Hosting.\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" if ! _1984hosting_login; then _err \"1984Hosting login failed for user $One984HOSTING_Username. Check $HTTP_HEADER file.\" return 1 fi _debug \"First detect the root zone.\" if ! _get_root \"$fulldomain\"; then _err \"Invalid domain '$fulldomain'.\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Add TXT record $fulldomain with value '$txtvalue'.\" value=\"$(printf '%s' \"$txtvalue\" | _url_encode)\" url=\"https://1984.hosting/domains/entry/\" postdata=\"entry=new\" postdata=\"$postdata&type=TXT\" postdata=\"$postdata&ttl=900\" postdata=\"$postdata&zone=$_domain\" postdata=\"$postdata&host=$_sub_domain\" postdata=\"$postdata&rdata=%22$value%22\" _debug2 postdata \"$postdata\" _authpost \"$postdata\" \"$url\" if _contains \"$_response\" '\"haserrors\": true'; then _err \"1984Hosting failed to add TXT record for $_sub_domain bad RC from _post.\" return 1 elif _contains \"$_response\" \"html>\"; then _err \"1984Hosting failed to add TXT record for $_sub_domain. Check $HTTP_HEADER file.\" return 1 elif _contains \"$_response\" '\"auth\": false'; then _err \"1984Hosting failed to add TXT record for $_sub_domain. Invalid or expired cookie.\" return 1 fi _info \"Added acme challenge TXT record for $fulldomain at 1984Hosting.\" return 0 } # Usage: fulldomain txtvalue # Remove the txt record after validation. dns_1984hosting_rm() { fulldomain=$1 txtvalue=$2 _info \"Delete TXT record using 1984Hosting.\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" if ! _1984hosting_login; then _err \"1984Hosting login failed for user $One984HOSTING_Username. Check $HTTP_HEADER file.\" return 1 fi _debug \"First detect the root zone.\" if ! _get_root \"$fulldomain\"; then _err \"Invalid domain '$fulldomain'.\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Delete $fulldomain TXT record.\" url=\"https://1984.hosting/domains\" if ! _get_zone_id \"$url\" \"$_domain\"; then _err \"Invalid zone '$_domain'.\" return 1 fi _htmlget \"$url/$_zone_id\" \"$txtvalue\" entry_id=\"$(echo \"$_response\" | _egrep_o 'entry_[0-9]+' | sed 's/entry_//')\" _debug2 entry_id \"$entry_id\" if [ -z \"$entry_id\" ]; then _err \"Error getting TXT entry_id for $1.\" return 1 fi _authpost \"entry=$entry_id\" \"$url/delentry/\" if ! _contains \"$_response\" '\"ok\": true'; then _err \"1984Hosting failed to delete TXT record for $entry_id bad RC from _post.\" return 1 fi _info \"Deleted acme challenge TXT record for $fulldomain at 1984Hosting.\" return 0 } #################### Private functions below ################################## _1984hosting_login() { if ! _check_credentials; then return 1; fi if _check_cookies; then _debug \"Already logged in.\" return 0 fi _debug \"Login to 1984Hosting as user $One984HOSTING_Username.\" username=$(printf '%s' \"$One984HOSTING_Username\" | _url_encode) password=$(printf '%s' \"$One984HOSTING_Password\" | _url_encode) url=\"https://1984.hosting/api/auth/\" _get \"https://1984.hosting/accounts/login/\" | grep \"csrfmiddlewaretoken\" csrftoken=\"$(grep -i '^set-cookie:' \"$HTTP_HEADER\" | _egrep_o 'csrftoken=[^;]*;' | tr -d ';')\" sessionid=\"$(grep -i '^set-cookie:' \"$HTTP_HEADER\" | _egrep_o 'sessionid=[^;]*;' | tr -d ';')\" if [ -z \"$csrftoken\" ] || [ -z \"$sessionid\" ]; then _err \"One or more cookies are empty: '$csrftoken', '$sessionid'.\" return 1 fi export _H1=\"Cookie: $csrftoken; $sessionid\" export _H2=\"Referer: https://1984.hosting/accounts/login/\" csrf_header=$(echo \"$csrftoken\" | sed 's/csrftoken=//' | _head_n 1) export _H3=\"X-CSRFToken: $csrf_header\" response=\"$(_post \"username=$username&password=$password&otpkey=\" $url)\" response=\"$(echo \"$response\" | _normalizeJson)\" _debug2 response \"$response\" if _contains \"$response\" '\"loggedin\": true'; then One984HOSTING_SESSIONID_COOKIE=\"$(grep -i '^set-cookie:' \"$HTTP_HEADER\" | _egrep_o 'sessionid=[^;]*;' | tr -d ';')\" One984HOSTING_CSRFTOKEN_COOKIE=\"$(grep -i '^set-cookie:' \"$HTTP_HEADER\" | _egrep_o 'csrftoken=[^;]*;' | tr -d ';')\" export One984HOSTING_SESSIONID_COOKIE export One984HOSTING_CSRFTOKEN_COOKIE _saveaccountconf_mutable One984HOSTING_Username \"$One984HOSTING_Username\" _saveaccountconf_mutable One984HOSTING_Password \"$One984HOSTING_Password\" _saveaccountconf_mutable One984HOSTING_SESSIONID_COOKIE \"$One984HOSTING_SESSIONID_COOKIE\" _saveaccountconf_mutable One984HOSTING_CSRFTOKEN_COOKIE \"$One984HOSTING_CSRFTOKEN_COOKIE\" return 0 fi return 1 } _check_credentials() { One984HOSTING_Username=\"${One984HOSTING_Username:-$(_readaccountconf_mutable One984HOSTING_Username)}\" One984HOSTING_Password=\"${One984HOSTING_Password:-$(_readaccountconf_mutable One984HOSTING_Password)}\" if [ -z \"$One984HOSTING_Username\" ] || [ -z \"$One984HOSTING_Password\" ]; then One984HOSTING_Username=\"\" One984HOSTING_Password=\"\" _clearaccountconf_mutable One984HOSTING_Username _clearaccountconf_mutable One984HOSTING_Password _err \"You haven't specified 1984Hosting username or password yet.\" _err \"Please export as One984HOSTING_Username / One984HOSTING_Password and try again.\" return 1 fi return 0 } _check_cookies() { One984HOSTING_SESSIONID_COOKIE=\"${One984HOSTING_SESSIONID_COOKIE:-$(_readaccountconf_mutable One984HOSTING_SESSIONID_COOKIE)}\" One984HOSTING_CSRFTOKEN_COOKIE=\"${One984HOSTING_CSRFTOKEN_COOKIE:-$(_readaccountconf_mutable One984HOSTING_CSRFTOKEN_COOKIE)}\" if [ -z \"$One984HOSTING_SESSIONID_COOKIE\" ] || [ -z \"$One984HOSTING_CSRFTOKEN_COOKIE\" ]; then _debug \"No cached cookie(s) found.\" return 1 fi _authget \"https://1984.hosting/api/auth/\" if _contains \"$_response\" '\"ok\": true'; then _debug \"Cached cookies still valid.\" return 0 fi _debug \"Cached cookies no longer valid. Clearing cookies.\" One984HOSTING_SESSIONID_COOKIE=\"\" One984HOSTING_CSRFTOKEN_COOKIE=\"\" _clearaccountconf_mutable One984HOSTING_SESSIONID_COOKIE _clearaccountconf_mutable One984HOSTING_CSRFTOKEN_COOKIE return 1 } # _acme-challenge.www.domain.com # Returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=\"$1\" i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f \"$i\"-100) # not valid if [ -z \"$h\" ]; then return 1 fi _authget \"https://1984.hosting/domains/zonestatus/$h/?cached=no\" if _contains \"$_response\" '\"ok\": true'; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-\"$p\") _domain=\"$h\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } # Usage: _get_zone_id url domain.com # Returns zone id for domain.com _get_zone_id() { url=$1 domain=$2 _htmlget \"$url\" \"$domain\" _zone_id=\"$(echo \"$_response\" | _egrep_o 'zone\\/[0-9]+' | _head_n 1)\" _debug2 _zone_id \"$_zone_id\" if [ -z \"$_zone_id\" ]; then _err \"Error getting _zone_id for $2.\" return 1 fi return 0 } # Add extra headers to request _authget() { export _H1=\"Cookie: $One984HOSTING_CSRFTOKEN_COOKIE; $One984HOSTING_SESSIONID_COOKIE\" _response=$(_get \"$1\" | _normalizeJson) _debug2 _response \"$_response\" } # Truncate huge HTML response _htmlget() { export _H1=\"Cookie: $One984HOSTING_CSRFTOKEN_COOKIE; $One984HOSTING_SESSIONID_COOKIE\" _response=$(_get \"$1\" | grep \"$2\") if _contains \"$_response\" \"@$2\"; then _response=$(echo \"$_response\" | grep -v \"[@]\" | _head_n 1) fi _debug2 _response \"$_response\" } # Add extra headers to request _authpost() { url=\"https://1984.hosting/domains\" _get_zone_id \"$url\" \"$_domain\" csrf_header=\"$(echo \"$One984HOSTING_CSRFTOKEN_COOKIE\" | _egrep_o \"=[^=][0-9a-zA-Z]*\" | tr -d \"=\")\" export _H1=\"Cookie: $One984HOSTING_CSRFTOKEN_COOKIE; $One984HOSTING_SESSIONID_COOKIE\" export _H2=\"Referer: https://1984.hosting/domains/$_zone_id\" export _H3=\"X-CSRFToken: $csrf_header\" _response=\"$(_post \"$1\" \"$2\" | _normalizeJson)\" _debug2 _response \"$_response\" }"
        },
        {
            "filename": "file_154.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_154.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_acmedns_info='acme-dns Server API The acme-dns is a limited DNS server with RESTful API to handle ACME DNS challenges. Site: github.com/joohoi/acme-dns Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_acmedns Options: ACMEDNS_USERNAME Username. Optional. ACMEDNS_PASSWORD Password. Optional. ACMEDNS_SUBDOMAIN Subdomain. Optional. ACMEDNS_BASE_URL API endpoint. Default: \"https://auth.acme-dns.io\". Issues: github.com/dampfklon/acme.sh Author: Wolfgang Ebner, Sven Neubuaer ' ######## Public functions ##################### #Usage: dns_acmedns_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record dns_acmedns_add() { fulldomain=$1 txtvalue=$2 _info \"Using acme-dns\" _debug \"fulldomain $fulldomain\" _debug \"txtvalue $txtvalue\" #for compatiblity from account conf ACMEDNS_USERNAME=\"${ACMEDNS_USERNAME:-$(_readaccountconf_mutable ACMEDNS_USERNAME)}\" _clearaccountconf_mutable ACMEDNS_USERNAME ACMEDNS_PASSWORD=\"${ACMEDNS_PASSWORD:-$(_readaccountconf_mutable ACMEDNS_PASSWORD)}\" _clearaccountconf_mutable ACMEDNS_PASSWORD ACMEDNS_SUBDOMAIN=\"${ACMEDNS_SUBDOMAIN:-$(_readaccountconf_mutable ACMEDNS_SUBDOMAIN)}\" _clearaccountconf_mutable ACMEDNS_SUBDOMAIN ACMEDNS_BASE_URL=\"${ACMEDNS_BASE_URL:-$(_readdomainconf ACMEDNS_BASE_URL)}\" ACMEDNS_USERNAME=\"${ACMEDNS_USERNAME:-$(_readdomainconf ACMEDNS_USERNAME)}\" ACMEDNS_PASSWORD=\"${ACMEDNS_PASSWORD:-$(_readdomainconf ACMEDNS_PASSWORD)}\" ACMEDNS_SUBDOMAIN=\"${ACMEDNS_SUBDOMAIN:-$(_readdomainconf ACMEDNS_SUBDOMAIN)}\" if [ \"$ACMEDNS_BASE_URL\" = \"\" ]; then ACMEDNS_BASE_URL=\"https://auth.acme-dns.io\" fi ACMEDNS_UPDATE_URL=\"$ACMEDNS_BASE_URL/update\" ACMEDNS_REGISTER_URL=\"$ACMEDNS_BASE_URL/register\" if [ -z \"$ACMEDNS_USERNAME\" ] || [ -z \"$ACMEDNS_PASSWORD\" ]; then response=\"$(_post \"\" \"$ACMEDNS_REGISTER_URL\" \"\" \"POST\")\" _debug response \"$response\" ACMEDNS_USERNAME=$(echo \"$response\" | sed -n 's/^{.*\\\"username\\\":[ ]*\\\"\\([^\\\"]*\\)\\\".*}/\\1/p') _debug \"received username: $ACMEDNS_USERNAME\" ACMEDNS_PASSWORD=$(echo \"$response\" | sed -n 's/^{.*\\\"password\\\":[ ]*\\\"\\([^\\\"]*\\)\\\".*}/\\1/p') _debug \"received password: $ACMEDNS_PASSWORD\" ACMEDNS_SUBDOMAIN=$(echo \"$response\" | sed -n 's/^{.*\\\"subdomain\\\":[ ]*\\\"\\([^\\\"]*\\)\\\".*}/\\1/p') _debug \"received subdomain: $ACMEDNS_SUBDOMAIN\" ACMEDNS_FULLDOMAIN=$(echo \"$response\" | sed -n 's/^{.*\\\"fulldomain\\\":[ ]*\\\"\\([^\\\"]*\\)\\\".*}/\\1/p') _info \"##########################################################\" _info \"# Create $fulldomain CNAME $ACMEDNS_FULLDOMAIN DNS entry #\" _info \"##########################################################\" _info \"Press enter to continue... \" read -r _ fi _savedomainconf ACMEDNS_BASE_URL \"$ACMEDNS_BASE_URL\" _savedomainconf ACMEDNS_USERNAME \"$ACMEDNS_USERNAME\" _savedomainconf ACMEDNS_PASSWORD \"$ACMEDNS_PASSWORD\" _savedomainconf ACMEDNS_SUBDOMAIN \"$ACMEDNS_SUBDOMAIN\" export _H1=\"X-Api-User: $ACMEDNS_USERNAME\" export _H2=\"X-Api-Key: $ACMEDNS_PASSWORD\" data=\"{\\\"subdomain\\\":\\\"$ACMEDNS_SUBDOMAIN\\\", \\\"txt\\\": \\\"$txtvalue\\\"}\" _debug data \"$data\" response=\"$(_post \"$data\" \"$ACMEDNS_UPDATE_URL\" \"\" \"POST\")\" _debug response \"$response\" if ! echo \"$response\" | grep \"\\\"$txtvalue\\\"\" >/dev/null; then _err \"invalid response of acme-dns\" return 1 fi } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_acmedns_rm() { fulldomain=$1 txtvalue=$2 _info \"Using acme-dns\" _debug \"fulldomain $fulldomain\" _debug \"txtvalue $txtvalue\" } #################### Private functions below ##################################"
        },
        {
            "filename": "file_155.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_155.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_acmeproxy_info='AcmeProxy Server API AcmeProxy can be used to as a single host in your network to request certificates through a DNS API. Clients can connect with the one AcmeProxy host so you do not need to store DNS API credentials on every single host. Site: github.com/mdbraber/acmeproxy Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_acmeproxy Options: ACMEPROXY_ENDPOINT API Endpoint ACMEPROXY_USERNAME Username ACMEPROXY_PASSWORD Password Issues: github.com/acmesh-official/acme.sh/issues/2251 Author: Maarten den Braber ' dns_acmeproxy_add() { fulldomain=\"${1}\" txtvalue=\"${2}\" action=\"present\" _debug \"Calling: _acmeproxy_request() '${fulldomain}' '${txtvalue}' '${action}'\" _acmeproxy_request \"$fulldomain\" \"$txtvalue\" \"$action\" } dns_acmeproxy_rm() { fulldomain=\"${1}\" txtvalue=\"${2}\" action=\"cleanup\" _debug \"Calling: _acmeproxy_request() '${fulldomain}' '${txtvalue}' '${action}'\" _acmeproxy_request \"$fulldomain\" \"$txtvalue\" \"$action\" } _acmeproxy_request() { ## Nothing to see here, just some housekeeping fulldomain=$1 txtvalue=$2 action=$3 _info \"Using acmeproxy\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" ACMEPROXY_ENDPOINT=\"${ACMEPROXY_ENDPOINT:-$(_readaccountconf_mutable ACMEPROXY_ENDPOINT)}\" ACMEPROXY_USERNAME=\"${ACMEPROXY_USERNAME:-$(_readaccountconf_mutable ACMEPROXY_USERNAME)}\" ACMEPROXY_PASSWORD=\"${ACMEPROXY_PASSWORD:-$(_readaccountconf_mutable ACMEPROXY_PASSWORD)}\" ## Check for the endpoint if [ -z \"$ACMEPROXY_ENDPOINT\" ]; then ACMEPROXY_ENDPOINT=\"\" _err \"You didn't specify the endpoint\" _err \"Please set them via 'export ACMEPROXY_ENDPOINT=https://ip:port' and try again.\" return 1 fi ## Save the credentials to the account file _saveaccountconf_mutable ACMEPROXY_ENDPOINT \"$ACMEPROXY_ENDPOINT\" _saveaccountconf_mutable ACMEPROXY_USERNAME \"$ACMEPROXY_USERNAME\" _saveaccountconf_mutable ACMEPROXY_PASSWORD \"$ACMEPROXY_PASSWORD\" if [ -z \"$ACMEPROXY_USERNAME\" ] || [ -z \"$ACMEPROXY_PASSWORD\" ]; then _info \"ACMEPROXY_USERNAME and/or ACMEPROXY_PASSWORD not set - using without client authentication! Make sure you're using server authentication (e.g. IP-based)\" export _H1=\"Accept: application/json\" export _H2=\"Content-Type: application/json\" else ## Base64 encode the credentials credentials=$(printf \"%b\" \"$ACMEPROXY_USERNAME:$ACMEPROXY_PASSWORD\" | _base64) ## Construct the HTTP Authorization header export _H1=\"Authorization: Basic $credentials\" export _H2=\"Accept: application/json\" export _H3=\"Content-Type: application/json\" fi ## Add the challenge record to the acmeproxy grid member response=\"$(_post \"{\\\"fqdn\\\": \\\"$fulldomain.\\\", \\\"value\\\": \\\"$txtvalue\\\"}\" \"$ACMEPROXY_ENDPOINT/$action\" \"\" \"POST\")\" ## Let's see if we get something intelligible back from the unit if echo \"$response\" | grep \"\\\"$txtvalue\\\"\" >/dev/null; then _info \"Successfully updated the txt record\" return 0 else _err \"Error encountered during record addition\" _err \"$response\" return 1 fi } #################### Private functions below ##################################"
        },
        {
            "filename": "file_156.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_156.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_active24_info='Active24.com Site: Active24.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_active24 Options: ACTIVE24_Token API Token Issues: github.com/acmesh-official/acme.sh/issues/2059 Author: Milan P\u00e1la ' ACTIVE24_Api=\"https://api.active24.com\" ######## Public functions ##################### # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record dns_active24_add() { fulldomain=$1 txtvalue=$2 _active24_init _info \"Adding txt record\" if _active24_rest POST \"dns/$_domain/txt/v1\" \"{\\\"name\\\":\\\"$_sub_domain\\\",\\\"text\\\":\\\"$txtvalue\\\",\\\"ttl\\\":0}\"; then if _contains \"$response\" \"errors\"; then _err \"Add txt record error.\" return 1 else _info \"Added, OK\" return 0 fi fi _err \"Add txt record error.\" return 1 } # Usage: fulldomain txtvalue # Used to remove the txt record after validation dns_active24_rm() { fulldomain=$1 txtvalue=$2 _active24_init _debug \"Getting txt records\" _active24_rest GET \"dns/$_domain/records/v1\" if _contains \"$response\" \"errors\"; then _err \"Error\" return 1 fi hash_ids=$(echo \"$response\" | _egrep_o \"[^{]+${txtvalue}[^}]+\" | _egrep_o \"hashId\\\":\\\"[^\\\"]+\" | cut -c10-) for hash_id in $hash_ids; do _debug \"Removing hash_id\" \"$hash_id\" if _active24_rest DELETE \"dns/$_domain/$hash_id/v1\" \"\"; then if _contains \"$response\" \"errors\"; then _err \"Unable to remove txt record.\" return 1 else _info \"Removed txt record.\" return 0 fi fi done _err \"No txt records found.\" return 1 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 if ! _active24_rest GET \"dns/domains/v1\"; then return 1 fi i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug \"h\" \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"\\\"$h\\\"\" >/dev/null; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _active24_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Authorization: Bearer $ACTIVE24_Token\" if [ \"$m\" != \"GET\" ]; then _debug \"data\" \"$data\" response=\"$(_post \"$data\" \"$ACTIVE24_Api/$ep\" \"\" \"$m\" \"application/json\")\" else response=\"$(_get \"$ACTIVE24_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 } _active24_init() { ACTIVE24_Token=\"${ACTIVE24_Token:-$(_readaccountconf_mutable ACTIVE24_Token)}\" if [ -z \"$ACTIVE24_Token\" ]; then ACTIVE24_Token=\"\" _err \"You didn't specify a Active24 api token yet.\" _err \"Please create the token and try again.\" return 1 fi _saveaccountconf_mutable ACTIVE24_Token \"$ACTIVE24_Token\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" }"
        },
        {
            "filename": "file_157.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_157.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_ad_info='AlwaysData.com Site: AlwaysData.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_ad Options: AD_API_KEY API Key Issues: github.com/acmesh-official/acme.sh/pull/503 Author: Paul Koppen ' AD_API_URL=\"https://$AD_API_KEY:@api.alwaysdata.com/v1\" ######## Public functions ##################### #Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_ad_add() { fulldomain=$1 txtvalue=$2 if [ -z \"$AD_API_KEY\" ]; then AD_API_KEY=\"\" _err \"You didn't specify the AD api key yet.\" _err \"Please create you key and try again.\" return 1 fi _saveaccountconf AD_API_KEY \"$AD_API_KEY\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _ad_tmpl_json=\"{\\\"domain\\\":$_domain_id,\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"value\\\":\\\"$txtvalue\\\"}\" if _ad_rest POST \"record/\" \"$_ad_tmpl_json\" && [ -z \"$response\" ]; then _info \"txt record updated success.\" return 0 fi return 1 } #fulldomain txtvalue dns_ad_rm() { fulldomain=$1 txtvalue=$2 _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _ad_rest GET \"record/?domain=$_domain_id&name=$_sub_domain\" if [ -n \"$response\" ]; then record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":\\s*[0-9]+\" | cut -d : -f 2 | tr -d \" \" | _head_n 1) _debug record_id \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if _ad_rest DELETE \"record/$record_id/\" && [ -z \"$response\" ]; then _info \"txt record deleted success.\" return 0 fi _debug response \"$response\" return 1 fi return 1 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=12345 _get_root() { domain=$1 i=2 p=1 if _ad_rest GET \"domain/\"; then response=\"$(echo \"$response\" | tr -d \"\\n\" | sed 's/{/\\n&/g')\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi hostedzone=\"$(echo \"$response\" | _egrep_o \"{.*\\\"name\\\":\\s*\\\"$h\\\".*}\")\" if [ \"$hostedzone\" ]; then _domain_id=$(printf \"%s\\n\" \"$hostedzone\" | _egrep_o \"\\\"id\\\":\\s*[0-9]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\ ) if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done fi return 1 } #method uri qstr data _ad_rest() { mtd=\"$1\" ep=\"$2\" data=\"$3\" _debug mtd \"$mtd\" _debug ep \"$ep\" export _H1=\"Accept: application/json\" export _H2=\"Content-Type: application/json\" if [ \"$mtd\" != \"GET\" ]; then # both POST and DELETE. _debug data \"$data\" response=\"$(_post \"$data\" \"$AD_API_URL/$ep\" \"\" \"$mtd\")\" else response=\"$(_get \"$AD_API_URL/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_158.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_158.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_ali_info='AlibabaCloud.com Domains: Aliyun.com Site: AlibabaCloud.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_ali Options: Ali_Key API Key Ali_Secret API Secret ' # NOTICE: # This file is referenced by Alibaba Cloud Services deploy hooks # https://github.com/acmesh-official/acme.sh/pull/5205#issuecomment-2357867276 # Be careful when modifying this file, especially when making breaking changes for common functions Ali_DNS_API=\"https://alidns.aliyuncs.com/\" #Usage: dns_ali_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_ali_add() { fulldomain=$1 txtvalue=$2 _prepare_ali_credentials || return 1 _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then return 1 fi _debug \"Add record\" _add_record_query \"$_domain\" \"$_sub_domain\" \"$txtvalue\" && _ali_rest \"Add record\" } dns_ali_rm() { fulldomain=$1 txtvalue=$2 Ali_Key=\"${Ali_Key:-$(_readaccountconf_mutable Ali_Key)}\" Ali_Secret=\"${Ali_Secret:-$(_readaccountconf_mutable Ali_Secret)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then return 1 fi _clean } #################### Alibaba Cloud common functions below #################### _prepare_ali_credentials() { Ali_Key=\"${Ali_Key:-$(_readaccountconf_mutable Ali_Key)}\" Ali_Secret=\"${Ali_Secret:-$(_readaccountconf_mutable Ali_Secret)}\" if [ -z \"$Ali_Key\" ] || [ -z \"$Ali_Secret\" ]; then Ali_Key=\"\" Ali_Secret=\"\" _err \"You don't specify aliyun api key and secret yet.\" return 1 fi #save the api key and secret to the account conf file. _saveaccountconf_mutable Ali_Key \"$Ali_Key\" _saveaccountconf_mutable Ali_Secret \"$Ali_Secret\" } # act ign mtd _ali_rest() { act=\"$1\" ign=\"$2\" mtd=\"${3:-GET}\" signature=$(printf \"%s\" \"$mtd&%2F&$(printf \"%s\" \"$query\" | _url_encode upper-hex)\" | _hmac \"sha1\" \"$(printf \"%s\" \"$Ali_Secret&\" | _hex_dump | tr -d \" \")\" | _base64) signature=$(printf \"%s\" \"$signature\" | _url_encode upper-hex) url=\"$endpoint?Signature=$signature\" if [ \"$mtd\" = \"GET\" ]; then url=\"$url&$query\" response=\"$(_get \"$url\")\" else response=\"$(_post \"$query\" \"$url\" \"\" \"$mtd\" \"application/x-www-form-urlencoded\")\" fi _ret=\"$?\" _debug2 response \"$response\" if [ \"$_ret\" != \"0\" ]; then _err \"Error <$act>\" return 1 fi if [ -z \"$ign\" ]; then message=\"$(echo \"$response\" | _egrep_o \"\\\"Message\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\")\" if [ \"$message\" ]; then _err \"$message\" return 1 fi fi } _ali_nonce() { #_head_n 1 </dev/urandom | _digest \"sha256\" hex | cut -c 1-31 #Not so good... date +\"%s%N\" | sed 's/%N//g' } _timestamp() { date -u +\"%Y-%m-%dT%H%%3A%M%%3A%SZ\" } #################### Private functions below #################### _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi _describe_records_query \"$h\" if ! _ali_rest \"Get root\" \"ignore\"; then return 1 fi if _contains \"$response\" \"PageNumber\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _debug _sub_domain \"$_sub_domain\" _domain=\"$h\" _debug _domain \"$_domain\" return 0 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } _check_exist_query() { _qdomain=\"$1\" _qsubdomain=\"$2\" endpoint=$Ali_DNS_API query='' query=$query'AccessKeyId='$Ali_Key query=$query'&Action=DescribeDomainRecords' query=$query'&DomainName='$_qdomain query=$query'&Format=json' query=$query'&RRKeyWord='$_qsubdomain query=$query'&SignatureMethod=HMAC-SHA1' query=$query\"&SignatureNonce=$(_ali_nonce)\" query=$query'&SignatureVersion=1.0' query=$query'&Timestamp='$(_timestamp) query=$query'&TypeKeyWord=TXT' query=$query'&Version=2015-01-09' } _add_record_query() { endpoint=$Ali_DNS_API query='' query=$query'AccessKeyId='$Ali_Key query=$query'&Action=AddDomainRecord' query=$query'&DomainName='$1 query=$query'&Format=json' query=$query'&RR='$2 query=$query'&SignatureMethod=HMAC-SHA1' query=$query\"&SignatureNonce=$(_ali_nonce)\" query=$query'&SignatureVersion=1.0' query=$query'&Timestamp='$(_timestamp) query=$query'&Type=TXT' query=$query'&Value='$3 query=$query'&Version=2015-01-09' } _delete_record_query() { endpoint=$Ali_DNS_API query='' query=$query'AccessKeyId='$Ali_Key query=$query'&Action=DeleteDomainRecord' query=$query'&Format=json' query=$query'&RecordId='$1 query=$query'&SignatureMethod=HMAC-SHA1' query=$query\"&SignatureNonce=$(_ali_nonce)\" query=$query'&SignatureVersion=1.0' query=$query'&Timestamp='$(_timestamp) query=$query'&Version=2015-01-09' } _describe_records_query() { endpoint=$Ali_DNS_API query='' query=$query'AccessKeyId='$Ali_Key query=$query'&Action=DescribeDomainRecords' query=$query'&DomainName='$1 query=$query'&Format=json' query=$query'&SignatureMethod=HMAC-SHA1' query=$query\"&SignatureNonce=$(_ali_nonce)\" query=$query'&SignatureVersion=1.0' query=$query'&Timestamp='$(_timestamp) query=$query'&Version=2015-01-09' } _clean() { _check_exist_query \"$_domain\" \"$_sub_domain\" # do not correct grammar here if ! _ali_rest \"Check exist records\" \"ignore\"; then return 1 fi record_id=\"$(echo \"$response\" | tr '{' \"\\n\" | grep \"$_sub_domain\" | grep -- \"$txtvalue\" | tr \",\" \"\\n\" | grep RecordId | cut -d '\"' -f 4)\" _debug2 record_id \"$record_id\" if [ -z \"$record_id\" ]; then _debug \"record not found, skip\" else _delete_record_query \"$record_id\" _ali_rest \"Delete record $record_id\" \"ignore\" fi }"
        },
        {
            "filename": "file_159.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_159.sh",
            "content": "#!/usr/bin/env sh # Alviy domain api # # Get API key and secret from https://cloud.alviy.com/token # # Alviy_token=\"some-secret-key\" # # Ex.: acme.sh --issue --staging --dns dns_alviy -d \"*.s.example.com\" -d \"s.example.com\" Alviy_Api=\"https://cloud.alviy.com/api/v1\" ######## Public functions ##################### #Usage: dns_alviy_add _acme-challenge.www.domain.com \"content\" dns_alviy_add() { fulldomain=$1 txtvalue=$2 Alviy_token=\"${Alviy_token:-$(_readaccountconf_mutable Alviy_token)}\" if [ -z \"$Alviy_token\" ]; then Alviy_token=\"\" _err \"Please specify Alviy token.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable Alviy_token \"$Alviy_token\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting existing records\" if _alviy_txt_exists \"$_domain\" \"$fulldomain\" \"$txtvalue\"; then _info \"This record already exists, skipping\" return 0 fi _add_data=\"{\\\"content\\\":\\\"$txtvalue\\\",\\\"type\\\":\\\"TXT\\\"}\" _debug2 _add_data \"$_add_data\" _info \"Adding record\" if _alviy_rest POST \"zone/$_domain/domain/$fulldomain/\" \"$_add_data\"; then _debug \"Checking updated records of '${fulldomain}'\" if ! _alviy_txt_exists \"$_domain\" \"$fulldomain\" \"$txtvalue\"; then _err \"TXT record '${txtvalue}' for '${fulldomain}', value wasn't set!\" return 1 fi else _err \"Add txt record error, value '${txtvalue}' for '${fulldomain}' was not set.\" return 1 fi _sleep 10 _info \"Added TXT record '${txtvalue}' for '${fulldomain}'.\" return 0 } #fulldomain dns_alviy_rm() { fulldomain=$1 txtvalue=$2 Alviy_token=\"${Alviy_token:-$(_readaccountconf_mutable Alviy_token)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" if ! _alviy_txt_exists \"$_domain\" \"$fulldomain\" \"$txtvalue\"; then _info \"The record does not exist, skip\" return 0 fi _add_data=\"\" uuid=$(echo \"$response\" | tr \"{\" \"\\n\" | grep \"$txtvalue\" | tr \",\" \"\\n\" | grep uuid | cut -d \\\" -f4) # delete record _debug \"Delete TXT record for '${fulldomain}'\" if ! _alviy_rest DELETE \"zone/$_domain/record/$uuid\" \"{\\\"confirm\\\":1}\"; then _err \"Cannot delete empty TXT record for '$fulldomain'\" return 1 fi _info \"The record '$fulldomain'='$txtvalue' deleted\" } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=3 a=\"init\" while [ -n \"$a\" ]; do a=$(printf \"%s\" \"$domain\" | cut -d . -f $i-) i=$((i + 1)) done n=$((i - 3)) h=$(printf \"%s\" \"$domain\" | cut -d . -f $n-) if [ -z \"$h\" ]; then #not valid _alviy_rest GET \"zone/$domain/\" _debug \"can't get host from $domain\" return 1 fi if ! _alviy_rest GET \"zone/$h/\"; then return 1 fi if _contains \"$response\" '\"code\":\"NOT_FOUND\"'; then _debug \"$h not found\" else s=$((n - 1)) _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f -$s) _domain=\"$h\" return 0 fi return 1 } _alviy_txt_exists() { zone=$1 domain=$2 content_data=$3 _debug \"Getting existing records\" if ! _alviy_rest GET \"zone/$zone/domain/$domain/TXT/\"; then _info \"The record does not exist\" return 1 fi if ! _contains \"$response\" \"$3\"; then _info \"The record has other value\" return 1 fi # GOOD code return - TRUE function return 0 } _alviy_rest() { method=$1 path=\"$2\" content_data=\"$3\" _debug \"$path\" export _H1=\"Authorization: Bearer $Alviy_token\" export _H2=\"Content-Type: application/json\" if [ \"$content_data\" ] || [ \"$method\" = \"DELETE\" ]; then _debug \"data ($method): \" \"$content_data\" response=\"$(_post \"$content_data\" \"$Alviy_Api/$path\" \"\" \"$method\")\" else response=\"$(_get \"$Alviy_Api/$path\")\" fi _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" if [ \"$_code\" = \"401\" ]; then _err \"It seems that your api key or secret is not correct.\" return 1 fi if [ \"$_code\" != \"200\" ]; then _err \"API call error ($method): $path Response code $_code\" fi if [ \"$?\" != \"0\" ]; then _err \"error on rest call ($method): $path. Response:\" _err \"$response\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_160.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_160.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_anx_info='Anexia.com CloudDNS Site: Anexia.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_anx Options: ANX_Token API Token Issues: github.com/acmesh-official/acme.sh/issues/3238 ' ANX_API='https://engine.anexia-it.com/api/clouddns/v1' ######## Public functions ##################### dns_anx_add() { fulldomain=$1 txtvalue=$2 _info \"Using ANX CDNS API\" ANX_Token=\"${ANX_Token:-$(_readaccountconf_mutable ANX_Token)}\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" if [ \"$ANX_Token\" ]; then _saveaccountconf_mutable ANX_Token \"$ANX_Token\" else _err \"You didn't specify a ANEXIA Engine API token.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi # Always add records, wildcard need two records with the same name _anx_rest POST \"zone.json/${_domain}/records\" \"{\\\"name\\\":\\\"$_sub_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"rdata\\\":\\\"$txtvalue\\\"}\" if _contains \"$response\" \"$txtvalue\"; then return 0 else return 1 fi } dns_anx_rm() { fulldomain=$1 txtvalue=$2 _info \"Using ANX CDNS API\" ANX_Token=\"${ANX_Token:-$(_readaccountconf_mutable ANX_Token)}\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _get_record_id if _is_uuid \"$_record_id\"; then if ! _anx_rest DELETE \"zone.json/${_domain}/records/$_record_id\"; then _err \"Delete record\" return 1 fi else _info \"No record found.\" fi echo \"$response\" | tr -d \" \" | grep \\\"status\\\":\\\"OK\\\" >/dev/null } #################### Private functions below ################################## _is_uuid() { pattern='^\\{?[A-Z0-9a-z]{8}-[A-Z0-9a-z]{4}-[A-Z0-9a-z]{4}-[A-Z0-9a-z]{4}-[A-Z0-9a-z]{12}\\}?$' if echo \"$1\" | _egrep_o \"$pattern\" >/dev/null; then return 0 fi return 1 } _get_record_id() { _debug subdomain \"$_sub_domain\" _debug domain \"$_domain\" if _anx_rest GET \"zone.json/${_domain}/records?name=$_sub_domain&type=TXT\"; then _debug response \"$response\" if _contains \"$response\" \"\\\"name\\\":\\\"$_sub_domain\\\"\" >/dev/null; then _record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\[.\\\"identifier\\\":\\\"[^\\\"]*\\\"\" | head -n 1 | cut -d : -f 2 | tr -d \\\") else _record_id='' fi else _err \"Search existing record\" fi } _anx_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: Token $ANX_Token\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"${ANX_API}/$ep\" \"\" \"$m\")\" else response=\"$(_get \"${ANX_API}/$ep\")\" fi # shellcheck disable=SC2181 if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug response \"$response\" return 0 } _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi _anx_rest GET \"zone.json/${h}\" if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 }"
        },
        {
            "filename": "file_161.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_161.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_artfiles_info='ArtFiles.de Site: ArtFiles.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_artfiles Options: AF_API_USERNAME API Username AF_API_PASSWORD API Password Issues: github.com/acmesh-official/acme.sh/issues/4718 Author: Martin Arndt <https://troublezone.net/> ' ########## API configuration ################################################### AF_API_SUCCESS='status\":\"OK' AF_URL_DCP='https://dcp.c.artfiles.de/api/' AF_URL_DNS=${AF_URL_DCP}'dns/{*}_dns.html?domain=' AF_URL_DOMAINS=${AF_URL_DCP}'domain/get_domains.html' ########## Public functions #################################################### # Adds a new TXT record for given ACME challenge value & domain. # Usage: dns_artfiles_add _acme-challenge.www.example.com \"ACME challenge value\" dns_artfiles_add() { domain=\"$1\" txtValue=\"$2\" _info 'Using ArtFiles.de DNS addition API\u2026' _debug 'Domain' \"$domain\" _debug 'txtValue' \"$txtValue\" _set_credentials _saveaccountconf_mutable 'AF_API_USERNAME' \"$AF_API_USERNAME\" _saveaccountconf_mutable 'AF_API_PASSWORD' \"$AF_API_PASSWORD\" _set_headers _get_zone \"$domain\" _dns 'GET' if ! _contains \"$response\" 'TXT'; then _err 'Retrieving TXT records failed.' return 1 fi _clean_records _dns 'SET' \"$(printf -- '%s\\n_acme-challenge \"%s\"' \"$response\" \"$txtValue\")\" if ! _contains \"$response\" \"$AF_API_SUCCESS\"; then _err 'Adding ACME challenge value failed.' return 1 fi } # Removes the existing TXT record for given ACME challenge value & domain. # Usage: dns_artfiles_rm _acme-challenge.www.example.com \"ACME challenge value\" dns_artfiles_rm() { domain=\"$1\" txtValue=\"$2\" _info 'Using ArtFiles.de DNS removal API\u2026' _debug 'Domain' \"$domain\" _debug 'txtValue' \"$txtValue\" _set_credentials _set_headers _get_zone \"$domain\" if ! _dns 'GET'; then return 1 fi if ! _contains \"$response\" \"$txtValue\"; then _err 'Retrieved TXT records are missing given ACME challenge value.' return 1 fi _clean_records response=\"$(printf -- '%s' \"$response\" | sed '/_acme-challenge \"'\"$txtValue\"'\"/d')\" _dns 'SET' \"$response\" if ! _contains \"$response\" \"$AF_API_SUCCESS\"; then _err 'Removing ACME challenge value failed.' return 1 fi } ########## Private functions ################################################### # Cleans awful TXT records response of ArtFiles's API & pretty prints it. # Usage: _clean_records _clean_records() { _info 'Cleaning TXT records\u2026' # Extract TXT part, strip trailing quote sign (ACME.sh API guidelines forbid # usage of SED's GNU extensions, hence couldn't omit it via regex), strip '\\' # from '\\\"' & turn '\\n' into real LF characters. # Yup, awful API to use - but that's all we got to get this working, so\u2026 ;) _debug2 'Raw ' \"$response\" response=\"$(printf -- '%s' \"$response\" | sed 's/^.*TXT\":\"\\([^}]*\\).*$/\\1/;s/,\".*$//;s/.$//;s/\\\\\"/\"/g;s/\\\\n/\\n/g')\" _debug2 'Clean' \"$response\" } # Executes an HTTP GET or POST request for getting or setting DNS records, # containing given payload upon POST. # Usage: _dns [GET | SET] [payload] _dns() { _info 'Executing HTTP request\u2026' action=\"$1\" payload=\"$(printf -- '%s' \"$2\" | _url_encode)\" url=\"$(printf -- '%s%s' \"$AF_URL_DNS\" \"$domain\" | sed 's/{\\*}/'\"$(printf -- '%s' \"$action\" | _lower_case)\"'/')\" if [ \"$action\" = 'SET' ]; then _debug2 'Payload' \"$payload\" response=\"$(_post '' \"$url&TXT=$payload\" '' 'POST' 'application/x-www-form-urlencoded')\" else response=\"$(_get \"$url\" '' 10)\" fi if ! _contains \"$response\" \"$AF_API_SUCCESS\"; then _err \"DNS API error: $response\" return 1 fi _debug 'Response' \"$response\" return 0 } # Gets the root domain zone for given domain. # Usage: _get_zone _acme-challenge.www.example.com _get_zone() { fqdn=\"$1\" domains=\"$(_get \"$AF_URL_DOMAINS\" '' 10)\" _info 'Getting domain zone\u2026' _debug2 'FQDN' \"$fqdn\" _debug2 'Domains' \"$domains\" while _contains \"$fqdn\" \".\"; do if _contains \"$domains\" \"$fqdn\"; then domain=\"$fqdn\" _info \"Found root domain zone: $domain\" break else fqdn=\"${fqdn#*.}\" _debug2 'FQDN' \"$fqdn\" fi done if [ \"$domain\" = \"$fqdn\" ]; then return 0 fi _err 'Couldn'\\''t find root domain zone.' return 1 } # Sets the credentials for accessing ArtFiles's API # Usage: _set_credentials _set_credentials() { _info 'Setting credentials\u2026' AF_API_USERNAME=\"${AF_API_USERNAME:-$(_readaccountconf_mutable AF_API_USERNAME)}\" AF_API_PASSWORD=\"${AF_API_PASSWORD:-$(_readaccountconf_mutable AF_API_PASSWORD)}\" if [ -z \"$AF_API_USERNAME\" ] || [ -z \"$AF_API_PASSWORD\" ]; then _err 'Missing ArtFiles.de username and/or password.' _err 'Please ensure both are set via export command & try again.' return 1 fi } # Adds the HTTP Authorization & Content-Type headers to a follow-up request. # Usage: _set_headers _set_headers() { _info 'Setting headers\u2026' encoded=\"$(printf -- '%s:%s' \"$AF_API_USERNAME\" \"$AF_API_PASSWORD\" | _base64)\" export _H1=\"Authorization: Basic $encoded\" export _H2='Content-Type: application/json' }"
        },
        {
            "filename": "file_162.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_162.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_arvan_info='ArvanCloud.ir Site: ArvanCloud.ir Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_arvan Options: Arvan_Token API Token Issues: github.com/acmesh-official/acme.sh/issues/2796 Author: Vahid Fardi ' ARVAN_API_URL=\"https://napi.arvancloud.ir/cdn/4.0/domains\" ######## Public functions ##################### #Usage: dns_arvan_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_arvan_add() { fulldomain=$1 txtvalue=$2 _info \"Using Arvan\" Arvan_Token=\"${Arvan_Token:-$(_readaccountconf_mutable Arvan_Token)}\" if [ -z \"$Arvan_Token\" ]; then _err \"You didn't specify \\\"Arvan_Token\\\" token yet.\" _err \"You can get yours from here https://npanel.arvancloud.ir/profile/api-keys\" return 1 fi #save the api token to the account conf file. _saveaccountconf_mutable Arvan_Token \"$Arvan_Token\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if _arvan_rest POST \"$_domain/dns-records\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"value\\\":{\\\"text\\\":\\\"$txtvalue\\\"},\\\"ttl\\\":120}\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"response id is $response\" _info \"Added, OK\" return 0 elif _contains \"$response\" \"Record Data is duplicate\"; then _info \"Already exists, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 0 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_arvan_rm() { fulldomain=$1 txtvalue=$2 _info \"Using Arvan\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" Arvan_Token=\"${Arvan_Token:-$(_readaccountconf_mutable Arvan_Token)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _arvan_rest GET \"${_domain}/dns-records\" if ! printf \"%s\" \"$response\" | grep \\\"current_page\\\":1 >/dev/null; then _err \"Error on Arvan Api\" _err \"Please create a github issue with debbug log\" return 1 fi _record_id=$(echo \"$response\" | _egrep_o \".\\\"id\\\":\\\"[^\\\"]*\\\",\\\"type\\\":\\\"txt\\\",\\\"name\\\":\\\"_acme-challenge\\\",\\\"value\\\":{\\\"text\\\":\\\"$txtvalue\\\"}\" | cut -d : -f 2 | cut -d , -f 1 | tr -d \\\") if ! _arvan_rest \"DELETE\" \"${_domain}/dns-records/${_record_id}\"; then _err \"Error on Arvan Api\" return 1 fi _debug \"$response\" _contains \"$response\" 'dns record deleted' return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _arvan_rest GET \"$h\"; then return 1 fi if _contains \"$response\" \"\\\"domain\\\":\\\"$h\\\"\"; then _domain_id=$(echo \"$response\" | cut -d : -f 3 | cut -d , -f 1 | tr -d \\\") if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _arvan_rest() { mtd=\"$1\" ep=\"$2\" data=\"$3\" token_trimmed=$(echo \"$Arvan_Token\" | tr -d '\"') export _H1=\"Authorization: $token_trimmed\" if [ \"$mtd\" = \"DELETE\" ]; then #DELETE Request shouldn't have Content-Type _debug data \"$data\" response=\"$(_post \"$data\" \"$ARVAN_API_URL/$ep\" \"\" \"$mtd\")\" elif [ \"$mtd\" = \"POST\" ]; then export _H2=\"Content-Type: application/json\" export _H3=\"Accept: application/json\" _debug data \"$data\" response=\"$(_post \"$data\" \"$ARVAN_API_URL/$ep\" \"\" \"$mtd\")\" else response=\"$(_get \"$ARVAN_API_URL/$ep$data\")\" fi return 0 }"
        },
        {
            "filename": "file_163.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_163.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_aurora_info='versio.nl AuroraDNS Domains: pcextreme.nl Site: versio.nl Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_aurora Options: AURORA_Key API Key AURORA_Secret API Secret Issues: github.com/acmesh-official/acme.sh/issues/3459 Author: Jasper Zonneveld ' AURORA_Api=\"https://api.auroradns.eu\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_aurora_add() { fulldomain=$1 txtvalue=$2 AURORA_Key=\"${AURORA_Key:-$(_readaccountconf_mutable AURORA_Key)}\" AURORA_Secret=\"${AURORA_Secret:-$(_readaccountconf_mutable AURORA_Secret)}\" if [ -z \"$AURORA_Key\" ] || [ -z \"$AURORA_Secret\" ]; then AURORA_Key=\"\" AURORA_Secret=\"\" _err \"You didn't specify an Aurora api key and secret yet.\" _err \"You can get yours from here https://cp.pcextreme.nl/auroradns/users.\" return 1 fi #save the api key and secret to the account conf file. _saveaccountconf_mutable AURORA_Key \"$AURORA_Key\" _saveaccountconf_mutable AURORA_Secret \"$AURORA_Secret\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if _aurora_rest POST \"zones/$_domain_id/records\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":300}\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"Added, OK\" return 0 elif _contains \"$response\" \"RecordExistsError\"; then _info \"Already exists, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_aurora_rm() { fulldomain=$1 txtvalue=$2 AURORA_Key=\"${AURORA_Key:-$(_readaccountconf_mutable AURORA_Key)}\" AURORA_Secret=\"${AURORA_Secret:-$(_readaccountconf_mutable AURORA_Secret)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting records\" _aurora_rest GET \"zones/${_domain_id}/records\" if ! _contains \"$response\" \"$txtvalue\"; then _info \"Don't need to remove.\" else records=$(echo \"$response\" | _normalizeJson | tr -d \"[]\" | sed \"s/},{/}|{/g\" | tr \"|\" \"\\n\") if [ \"$(echo \"$records\" | wc -l)\" -le 2 ]; then _err \"Can not parse records.\" return 1 fi record_id=$(echo \"$records\" | grep \"\\\"type\\\": *\\\"TXT\\\"\" | grep \"\\\"name\\\": *\\\"$_sub_domain\\\"\" | grep \"\\\"content\\\": *\\\"$txtvalue\\\"\" | _egrep_o \"\\\"id\\\": *\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\" | _head_n 1 | tr -d \" \") _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _aurora_rest DELETE \"zones/$_domain_id/records/$record_id\"; then _err \"Delete record error.\" return 1 fi fi return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _aurora_rest GET \"zones/$h\"; then return 1 fi if _contains \"$response\" \"\\\"name\\\": \\\"$h\\\"\"; then _domain_id=$(echo \"$response\" | _normalizeJson | tr -d \"{}\" | tr \",\" \"\\n\" | grep \"\\\"id\\\": *\\\"\" | cut -d : -f 2 | tr -d \\\" | _head_n 1 | tr -d \" \") _debug _domain_id \"$_domain_id\" if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _aurora_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" key_trimmed=$(echo \"$AURORA_Key\" | tr -d '\"') secret_trimmed=$(echo \"$AURORA_Secret\" | tr -d '\"') timestamp=$(date -u +\"%Y%m%dT%H%M%SZ\") signature=$(printf \"%s/%s%s\" \"$m\" \"$ep\" \"$timestamp\" | _hmac sha256 \"$(printf \"%s\" \"$secret_trimmed\" | _hex_dump | tr -d \" \")\" | _base64) authorization=$(printf \"AuroraDNSv1 %s\" \"$(printf \"%s:%s\" \"$key_trimmed\" \"$signature\" | _base64)\") export _H1=\"Content-Type: application/json; charset=UTF-8\" export _H2=\"X-AuroraDNS-Date: $timestamp\" export _H3=\"Authorization: $authorization\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$AURORA_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$AURORA_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_164.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_164.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_autodns_info='InternetX autoDNS InternetX autoDNS XML API Site: InternetX.com/autodns/ Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_autodns Options: AUTODNS_USER Username AUTODNS_PASSWORD Password AUTODNS_CONTEXT Context Author: <auerswald@gmail.com> ' AUTODNS_API=\"https://gateway.autodns.com\" # Arguments: # txtdomain # txt dns_autodns_add() { fulldomain=\"$1\" txtvalue=\"$2\" AUTODNS_USER=\"${AUTODNS_USER:-$(_readaccountconf_mutable AUTODNS_USER)}\" AUTODNS_PASSWORD=\"${AUTODNS_PASSWORD:-$(_readaccountconf_mutable AUTODNS_PASSWORD)}\" AUTODNS_CONTEXT=\"${AUTODNS_CONTEXT:-$(_readaccountconf_mutable AUTODNS_CONTEXT)}\" if [ -z \"$AUTODNS_USER\" ] || [ -z \"$AUTODNS_CONTEXT\" ] || [ -z \"$AUTODNS_PASSWORD\" ]; then _err \"You don't specify autodns user, password and context.\" return 1 fi _saveaccountconf_mutable AUTODNS_USER \"$AUTODNS_USER\" _saveaccountconf_mutable AUTODNS_PASSWORD \"$AUTODNS_PASSWORD\" _saveaccountconf_mutable AUTODNS_CONTEXT \"$AUTODNS_CONTEXT\" _debug \"First detect the root zone\" if ! _get_autodns_zone \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _zone \"$_zone\" _debug _system_ns \"$_system_ns\" _info \"Adding TXT record\" autodns_response=\"$(_autodns_zone_update \"$_zone\" \"$_sub_domain\" \"$txtvalue\" \"$_system_ns\")\" if [ \"$?\" -eq \"0\" ]; then _info \"Added, OK\" return 0 fi return 1 } # Arguments: # txtdomain # txt dns_autodns_rm() { fulldomain=\"$1\" txtvalue=\"$2\" AUTODNS_USER=\"${AUTODNS_USER:-$(_readaccountconf_mutable AUTODNS_USER)}\" AUTODNS_PASSWORD=\"${AUTODNS_PASSWORD:-$(_readaccountconf_mutable AUTODNS_PASSWORD)}\" AUTODNS_CONTEXT=\"${AUTODNS_CONTEXT:-$(_readaccountconf_mutable AUTODNS_CONTEXT)}\" if [ -z \"$AUTODNS_USER\" ] || [ -z \"$AUTODNS_CONTEXT\" ] || [ -z \"$AUTODNS_PASSWORD\" ]; then _err \"You don't specify autodns user, password and context.\" return 1 fi _debug \"First detect the root zone\" if ! _get_autodns_zone \"$fulldomain\"; then _err \"zone not found\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _zone \"$_zone\" _debug _system_ns \"$_system_ns\" _info \"Delete TXT record\" autodns_response=\"$(_autodns_zone_cleanup \"$_zone\" \"$_sub_domain\" \"$txtvalue\" \"$_system_ns\")\" if [ \"$?\" -eq \"0\" ]; then _info \"Deleted, OK\" return 0 fi return 1 } #################### Private functions below ################################## # Arguments: # fulldomain # Returns: # _sub_domain=_acme-challenge.www # _zone=domain.com # _system_ns _get_autodns_zone() { domain=\"$1\" i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then # not valid return 1 fi autodns_response=\"$(_autodns_zone_inquire \"$h\")\" if [ \"$?\" -ne \"0\" ]; then _err \"invalid domain\" return 1 fi if _contains \"$autodns_response\" \"<summary>1</summary>\" >/dev/null; then _zone=\"$(echo \"$autodns_response\" | _egrep_o '<name>[^<]*</name>' | cut -d '>' -f 2 | cut -d '<' -f 1)\" _system_ns=\"$(echo \"$autodns_response\" | _egrep_o '<system_ns>[^<]*</system_ns>' | cut -d '>' -f 2 | cut -d '<' -f 1)\" _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _build_request_auth_xml() { printf \"<auth> <user>%s</user> <password>%s</password> <context>%s</context> </auth>\" \"$AUTODNS_USER\" \"$AUTODNS_PASSWORD\" \"$AUTODNS_CONTEXT\" } # Arguments: # zone _build_zone_inquire_xml() { printf \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?> <request> %s <task> <code>0205</code> <view> <children>1</children> <limit>1</limit> </view> <where> <key>name</key> <operator>eq</operator> <value>%s</value> </where> </task> </request>\" \"$(_build_request_auth_xml)\" \"$1\" } # Arguments: # zone # subdomain # txtvalue # system_ns _build_zone_update_xml() { printf \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?> <request> %s <task> <code>0202001</code> <default> <rr_add> <name>%s</name> <ttl>600</ttl> <type>TXT</type> <value>%s</value> </rr_add> </default> <zone> <name>%s</name> <system_ns>%s</system_ns> </zone> </task> </request>\" \"$(_build_request_auth_xml)\" \"$2\" \"$3\" \"$1\" \"$4\" } # Arguments: # zone _autodns_zone_inquire() { request_data=\"$(_build_zone_inquire_xml \"$1\")\" autodns_response=\"$(_autodns_api_call \"$request_data\")\" ret=\"$?\" printf \"%s\" \"$autodns_response\" return \"$ret\" } # Arguments: # zone # subdomain # txtvalue # system_ns _autodns_zone_update() { request_data=\"$(_build_zone_update_xml \"$1\" \"$2\" \"$3\" \"$4\")\" autodns_response=\"$(_autodns_api_call \"$request_data\")\" ret=\"$?\" printf \"%s\" \"$autodns_response\" return \"$ret\" } # Arguments: # zone # subdomain # txtvalue # system_ns _autodns_zone_cleanup() { request_data=\"$(_build_zone_update_xml \"$1\" \"$2\" \"$3\" \"$4\")\" # replace 'rr_add>' with 'rr_rem>' in request_data request_data=\"$(printf -- \"%s\" \"$request_data\" | sed 's/rr_add>/rr_rem>/g')\" autodns_response=\"$(_autodns_api_call \"$request_data\")\" ret=\"$?\" printf \"%s\" \"$autodns_response\" return \"$ret\" } # Arguments: # request_data _autodns_api_call() { request_data=\"$1\" _debug request_data \"$request_data\" autodns_response=\"$(_post \"$request_data\" \"$AUTODNS_API\")\" ret=\"$?\" _debug autodns_response \"$autodns_response\" if [ \"$ret\" -ne \"0\" ]; then _err \"error\" return 1 fi if _contains \"$autodns_response\" \"<type>success</type>\" >/dev/null; then _info \"success\" printf \"%s\" \"$autodns_response\" return 0 fi return 1 }"
        },
        {
            "filename": "file_165.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_165.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_aws_info='Amazon AWS Route53 domain API Site: docs.aws.amazon.com/route53/ Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_aws Options: AWS_ACCESS_KEY_ID API Key ID AWS_SECRET_ACCESS_KEY API Secret ' # All `_sleep` commands are included to avoid Route53 throttling, see # https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/DNSLimitations.html#limits-api-requests AWS_HOST=\"route53.amazonaws.com\" AWS_URL=\"https://$AWS_HOST\" AWS_WIKI=\"https://github.com/acmesh-official/acme.sh/wiki/How-to-use-Amazon-Route53-API\" ######## Public functions ##################### #Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_aws_add() { fulldomain=$1 txtvalue=$2 AWS_ACCESS_KEY_ID=\"${AWS_ACCESS_KEY_ID:-$(_readaccountconf_mutable AWS_ACCESS_KEY_ID)}\" AWS_SECRET_ACCESS_KEY=\"${AWS_SECRET_ACCESS_KEY:-$(_readaccountconf_mutable AWS_SECRET_ACCESS_KEY)}\" AWS_DNS_SLOWRATE=\"${AWS_DNS_SLOWRATE:-$(_readaccountconf_mutable AWS_DNS_SLOWRATE)}\" if [ -z \"$AWS_ACCESS_KEY_ID\" ] || [ -z \"$AWS_SECRET_ACCESS_KEY\" ]; then _use_container_role || _use_instance_role fi if [ -z \"$AWS_ACCESS_KEY_ID\" ] || [ -z \"$AWS_SECRET_ACCESS_KEY\" ]; then AWS_ACCESS_KEY_ID=\"\" AWS_SECRET_ACCESS_KEY=\"\" _err \"You haven't specified the aws route53 api key id and and api key secret yet.\" _err \"Please create your key and try again. see $(__green $AWS_WIKI)\" return 1 fi #save for future use, unless using a role which will be fetched as needed if [ -z \"$_using_role\" ]; then _saveaccountconf_mutable AWS_ACCESS_KEY_ID \"$AWS_ACCESS_KEY_ID\" _saveaccountconf_mutable AWS_SECRET_ACCESS_KEY \"$AWS_SECRET_ACCESS_KEY\" _saveaccountconf_mutable AWS_DNS_SLOWRATE \"$AWS_DNS_SLOWRATE\" fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" _sleep 1 return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Getting existing records for $fulldomain\" if ! aws_rest GET \"2013-04-01$_domain_id/rrset\" \"name=$fulldomain&type=TXT\"; then _sleep 1 return 1 fi if _contains \"$response\" \"<Name>$fulldomain.</Name>\"; then _resource_record=\"$(echo \"$response\" | sed 's/<ResourceRecordSet>/\"/g' | tr '\"' \"\\n\" | grep \"<Name>$fulldomain.</Name>\" | _egrep_o \"<ResourceRecords.*</ResourceRecords>\" | sed \"s/<ResourceRecords>//\" | sed \"s#</ResourceRecords>##\")\" _debug \"_resource_record\" \"$_resource_record\" else _debug \"single new add\" fi if [ \"$_resource_record\" ] && _contains \"$response\" \"$txtvalue\"; then _info \"The TXT record already exists. Skipping.\" _sleep 1 return 0 fi _debug \"Adding records\" _aws_tmpl_xml=\"<ChangeResourceRecordSetsRequest xmlns=\\\"https://route53.amazonaws.com/doc/2013-04-01/\\\"><ChangeBatch><Changes><Change><Action>UPSERT</Action><ResourceRecordSet><Name>$fulldomain</Name><Type>TXT</Type><TTL>300</TTL><ResourceRecords>$_resource_record<ResourceRecord><Value>\\\"$txtvalue\\\"</Value></ResourceRecord></ResourceRecords></ResourceRecordSet></Change></Changes></ChangeBatch></ChangeResourceRecordSetsRequest>\" if aws_rest POST \"2013-04-01$_domain_id/rrset/\" \"\" \"$_aws_tmpl_xml\" && _contains \"$response\" \"ChangeResourceRecordSetsResponse\"; then _info \"TXT record updated successfully.\" if [ -n \"$AWS_DNS_SLOWRATE\" ]; then _info \"Slow rate activated: sleeping for $AWS_DNS_SLOWRATE seconds\" _sleep \"$AWS_DNS_SLOWRATE\" else _sleep 1 fi return 0 fi _sleep 1 return 1 } #fulldomain txtvalue dns_aws_rm() { fulldomain=$1 txtvalue=$2 AWS_ACCESS_KEY_ID=\"${AWS_ACCESS_KEY_ID:-$(_readaccountconf_mutable AWS_ACCESS_KEY_ID)}\" AWS_SECRET_ACCESS_KEY=\"${AWS_SECRET_ACCESS_KEY:-$(_readaccountconf_mutable AWS_SECRET_ACCESS_KEY)}\" AWS_DNS_SLOWRATE=\"${AWS_DNS_SLOWRATE:-$(_readaccountconf_mutable AWS_DNS_SLOWRATE)}\" if [ -z \"$AWS_ACCESS_KEY_ID\" ] || [ -z \"$AWS_SECRET_ACCESS_KEY\" ]; then _use_container_role || _use_instance_role fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" _sleep 1 return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Getting existing records for $fulldomain\" if ! aws_rest GET \"2013-04-01$_domain_id/rrset\" \"name=$fulldomain&type=TXT\"; then _sleep 1 return 1 fi if _contains \"$response\" \"<Name>$fulldomain.</Name>\"; then _resource_record=\"$(echo \"$response\" | sed 's/<ResourceRecordSet>/\"/g' | tr '\"' \"\\n\" | grep \"<Name>$fulldomain.</Name>\" | _egrep_o \"<ResourceRecords.*</ResourceRecords>\" | sed \"s/<ResourceRecords>//\" | sed \"s#</ResourceRecords>##\")\" _debug \"_resource_record\" \"$_resource_record\" else _debug \"no records exist, skip\" _sleep 1 return 0 fi _aws_tmpl_xml=\"<ChangeResourceRecordSetsRequest xmlns=\\\"https://route53.amazonaws.com/doc/2013-04-01/\\\"><ChangeBatch><Changes><Change><Action>DELETE</Action><ResourceRecordSet><ResourceRecords>$_resource_record</ResourceRecords><Name>$fulldomain.</Name><Type>TXT</Type><TTL>300</TTL></ResourceRecordSet></Change></Changes></ChangeBatch></ChangeResourceRecordSetsRequest>\" if aws_rest POST \"2013-04-01$_domain_id/rrset/\" \"\" \"$_aws_tmpl_xml\" && _contains \"$response\" \"ChangeResourceRecordSetsResponse\"; then _info \"TXT record deleted successfully.\" if [ -n \"$AWS_DNS_SLOWRATE\" ]; then _info \"Slow rate activated: sleeping for $AWS_DNS_SLOWRATE seconds\" _sleep \"$AWS_DNS_SLOWRATE\" else _sleep 1 fi return 0 fi _sleep 1 return 1 } #################### Private functions below ################################## _get_root() { domain=$1 i=1 p=1 # iterate over names (a.b.c.d -> b.c.d -> c.d -> d) while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100 | sed 's/\\./\\\\./g') _debug \"Checking domain: $h\" if [ -z \"$h\" ]; then _error \"invalid domain\" return 1 fi # iterate over paginated result for list_hosted_zones aws_rest GET \"2013-04-01/hostedzone\" while true; do if _contains \"$response\" \"<Name>$h.</Name>\"; then hostedzone=\"$(echo \"$response\" | tr -d '\\n' | sed 's/<HostedZone>/#&/g' | tr '#' '\\n' | _egrep_o \"<HostedZone><Id>[^<]*<.Id><Name>$h.<.Name>.*<PrivateZone>false<.PrivateZone>.*<.HostedZone>\")\" _debug hostedzone \"$hostedzone\" if [ \"$hostedzone\" ]; then _domain_id=$(printf \"%s\\n\" \"$hostedzone\" | _egrep_o \"<Id>.*<.Id>\" | head -n 1 | _egrep_o \">.*<\" | tr -d \"<>\") if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi _err \"Can't find domain with id: $h\" return 1 fi fi if _contains \"$response\" \"<IsTruncated>true</IsTruncated>\" && _contains \"$response\" \"<NextMarker>\"; then _debug \"IsTruncated\" _nextMarker=\"$(echo \"$response\" | _egrep_o \"<NextMarker>.*</NextMarker>\" | cut -d '>' -f 2 | cut -d '<' -f 1)\" _debug \"NextMarker\" \"$_nextMarker\" else break fi _debug \"Checking domain: $h - Next Page \" aws_rest GET \"2013-04-01/hostedzone\" \"marker=$_nextMarker\" done p=$i i=$(_math \"$i\" + 1) done return 1 } _use_container_role() { # automatically set if running inside ECS if [ -z \"$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI\" ]; then _debug \"No ECS environment variable detected\" return 1 fi _use_metadata \"169.254.170.2$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI\" } _use_instance_role() { _instance_role_name_url=\"http://169.254.169.254/latest/meta-data/iam/security-credentials/\" if _get \"$_instance_role_name_url\" true 1 | _head_n 1 | grep -Fq 401; then _debug \"Using IMDSv2\" _token_url=\"http://169.254.169.254/latest/api/token\" export _H1=\"X-aws-ec2-metadata-token-ttl-seconds: 21600\" _token=\"$(_post \"\" \"$_token_url\" \"\" \"PUT\")\" _secure_debug3 \"_token\" \"$_token\" if [ -z \"$_token\" ]; then _debug \"Unable to fetch IMDSv2 token from instance metadata\" return 1 fi export _H1=\"X-aws-ec2-metadata-token: $_token\" fi if ! _get \"$_instance_role_name_url\" true 1 | _head_n 1 | grep -Fq 200; then _debug \"Unable to fetch IAM role from instance metadata\" return 1 fi _instance_role_name=$(_get \"$_instance_role_name_url\" \"\" 1) _debug \"_instance_role_name\" \"$_instance_role_name\" _use_metadata \"$_instance_role_name_url$_instance_role_name\" \"$_token\" } _use_metadata() { export _H1=\"X-aws-ec2-metadata-token: $2\" _aws_creds=\"$( _get \"$1\" \"\" 1 | _normalizeJson | tr '{,}' '\\n' | while read -r _line; do _key=\"$(echo \"${_line%%:*}\" | tr -d '\\\"')\" _value=\"${_line#*:}\" _debug3 \"_key\" \"$_key\" _secure_debug3 \"_value\" \"$_value\" case \"$_key\" in AccessKeyId) echo \"AWS_ACCESS_KEY_ID=$_value\" ;; SecretAccessKey) echo \"AWS_SECRET_ACCESS_KEY=$_value\" ;; Token) echo \"AWS_SESSION_TOKEN=$_value\" ;; esac done | paste -sd' ' - )\" _secure_debug \"_aws_creds\" \"$_aws_creds\" if [ -z \"$_aws_creds\" ]; then return 1 fi eval \"$_aws_creds\" _using_role=true } #method uri qstr data aws_rest() { mtd=\"$1\" ep=\"$2\" qsr=\"$3\" data=\"$4\" _debug mtd \"$mtd\" _debug ep \"$ep\" _debug qsr \"$qsr\" _debug data \"$data\" CanonicalURI=\"/$ep\" _debug2 CanonicalURI \"$CanonicalURI\" CanonicalQueryString=\"$qsr\" _debug2 CanonicalQueryString \"$CanonicalQueryString\" RequestDate=\"$(date -u +\"%Y%m%dT%H%M%SZ\")\" _debug2 RequestDate \"$RequestDate\" #RequestDate=\"20161120T141056Z\" ############## export _H1=\"x-amz-date: $RequestDate\" aws_host=\"$AWS_HOST\" CanonicalHeaders=\"host:$aws_host\\nx-amz-date:$RequestDate\\n\" SignedHeaders=\"host;x-amz-date\" if [ -n \"$AWS_SESSION_TOKEN\" ]; then export _H3=\"x-amz-security-token: $AWS_SESSION_TOKEN\" CanonicalHeaders=\"${CanonicalHeaders}x-amz-security-token:$AWS_SESSION_TOKEN\\n\" SignedHeaders=\"${SignedHeaders};x-amz-security-token\" fi _debug2 CanonicalHeaders \"$CanonicalHeaders\" _debug2 SignedHeaders \"$SignedHeaders\" RequestPayload=\"$data\" _debug2 RequestPayload \"$RequestPayload\" Hash=\"sha256\" CanonicalRequest=\"$mtd\\n$CanonicalURI\\n$CanonicalQueryString\\n$CanonicalHeaders\\n$SignedHeaders\\n$(printf \"%s\" \"$RequestPayload\" | _digest \"$Hash\" hex)\" _debug2 CanonicalRequest \"$CanonicalRequest\" HashedCanonicalRequest=\"$(printf \"$CanonicalRequest%s\" | _digest \"$Hash\" hex)\" _debug2 HashedCanonicalRequest \"$HashedCanonicalRequest\" Algorithm=\"AWS4-HMAC-SHA256\" _debug2 Algorithm \"$Algorithm\" RequestDateOnly=\"$(echo \"$RequestDate\" | cut -c 1-8)\" _debug2 RequestDateOnly \"$RequestDateOnly\" Region=\"us-east-1\" Service=\"route53\" CredentialScope=\"$RequestDateOnly/$Region/$Service/aws4_request\" _debug2 CredentialScope \"$CredentialScope\" StringToSign=\"$Algorithm\\n$RequestDate\\n$CredentialScope\\n$HashedCanonicalRequest\" _debug2 StringToSign \"$StringToSign\" kSecret=\"AWS4$AWS_SECRET_ACCESS_KEY\" #kSecret=\"wJalrXUtnFEMI/K7MDENG+bPxRfiCYEXAMPLEKEY\" ############################ _secure_debug2 kSecret \"$kSecret\" kSecretH=\"$(printf \"%s\" \"$kSecret\" | _hex_dump | tr -d \" \")\" _secure_debug2 kSecretH \"$kSecretH\" kDateH=\"$(printf \"$RequestDateOnly%s\" | _hmac \"$Hash\" \"$kSecretH\" hex)\" _debug2 kDateH \"$kDateH\" kRegionH=\"$(printf \"$Region%s\" | _hmac \"$Hash\" \"$kDateH\" hex)\" _debug2 kRegionH \"$kRegionH\" kServiceH=\"$(printf \"$Service%s\" | _hmac \"$Hash\" \"$kRegionH\" hex)\" _debug2 kServiceH \"$kServiceH\" kSigningH=\"$(printf \"%s\" \"aws4_request\" | _hmac \"$Hash\" \"$kServiceH\" hex)\" _debug2 kSigningH \"$kSigningH\" signature=\"$(printf \"$StringToSign%s\" | _hmac \"$Hash\" \"$kSigningH\" hex)\" _debug2 signature \"$signature\" Authorization=\"$Algorithm Credential=$AWS_ACCESS_KEY_ID/$CredentialScope, SignedHeaders=$SignedHeaders, Signature=$signature\" _debug2 Authorization \"$Authorization\" _H2=\"Authorization: $Authorization\" _debug _H2 \"$_H2\" url=\"$AWS_URL/$ep\" if [ \"$qsr\" ]; then url=\"$AWS_URL/$ep?$qsr\" fi if [ \"$mtd\" = \"GET\" ]; then response=\"$(_get \"$url\")\" else response=\"$(_post \"$data\" \"$url\")\" fi _ret=\"$?\" _debug2 response \"$response\" if [ \"$_ret\" = \"0\" ]; then if _contains \"$response\" \"<ErrorResponse\"; then _err \"Response error:$response\" return 1 fi fi return \"$_ret\" }"
        },
        {
            "filename": "file_166.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_166.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_azion_info='Azion.om Site: Azion.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_azion Options: AZION_Email Email AZION_Password Password Issues: github.com/acmesh-official/acme.sh/issues/3555 ' AZION_Api=\"https://api.azionapi.net\" ######## Public functions ######## # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record dns_azion_add() { fulldomain=$1 txtvalue=$2 _debug \"Detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"Domain not found\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug _domain_id \"$_domain_id\" _info \"Add or update record\" _get_record \"$_domain_id\" \"$_sub_domain\" if [ \"$record_id\" ]; then _payload=\"{\\\"record_type\\\": \\\"TXT\\\", \\\"entry\\\": \\\"$_sub_domain\\\", \\\"answers_list\\\": [$answers_list, \\\"$txtvalue\\\"], \\\"ttl\\\": 20}\" if _azion_rest PUT \"intelligent_dns/$_domain_id/records/$record_id\" \"$_payload\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"Record updated.\" return 0 fi fi else _payload=\"{\\\"record_type\\\": \\\"TXT\\\", \\\"entry\\\": \\\"$_sub_domain\\\", \\\"answers_list\\\": [\\\"$txtvalue\\\"], \\\"ttl\\\": 20}\" if _azion_rest POST \"intelligent_dns/$_domain_id/records\" \"$_payload\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"Record added.\" return 0 fi fi fi _err \"Failed to add or update record.\" return 1 } # Usage: fulldomain txtvalue # Used to remove the txt record after validation dns_azion_rm() { fulldomain=$1 txtvalue=$2 _debug \"Detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"Domain not found\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug _domain_id \"$_domain_id\" _info \"Removing record\" _get_record \"$_domain_id\" \"$_sub_domain\" if [ \"$record_id\" ]; then if _azion_rest DELETE \"intelligent_dns/$_domain_id/records/$record_id\"; then _info \"Record removed.\" return 0 else _err \"Failed to remove record.\" return 1 fi else _info \"Record not found or already removed.\" return 0 fi } #################### Private functions below ################################## # Usage: _acme-challenge.www.domain.com # returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=1 p=1 if ! _azion_rest GET \"intelligent_dns\"; then return 1 fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then # not valid return 1 fi if _contains \"$response\" \"\\\"domain\\\":\\\"$h\\\"\"; then _domain_id=$(echo \"$response\" | tr '{' \"\\n\" | grep \"\\\"domain\\\":\\\"$h\\\"\" | _egrep_o \"\\\"id\\\":[0-9]*\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") _debug _domain_id \"$_domain_id\" if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _get_record() { _domain_id=$1 _record=$2 if ! _azion_rest GET \"intelligent_dns/$_domain_id/records\"; then return 1 fi if _contains \"$response\" \"\\\"entry\\\":\\\"$_record\\\"\"; then _json_record=$(echo \"$response\" | tr '{' \"\\n\" | grep \"\\\"entry\\\":\\\"$_record\\\"\") if [ \"$_json_record\" ]; then record_id=$(echo \"$_json_record\" | _egrep_o \"\\\"record_id\\\":[0-9]*\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") answers_list=$(echo \"$_json_record\" | _egrep_o \"\\\"answers_list\\\":\\[.*\\]\" | _head_n 1 | cut -d : -f 2 | tr -d \\[\\]) return 0 fi return 1 fi return 1 } _get_token() { AZION_Email=\"${AZION_Email:-$(_readaccountconf_mutable AZION_Email)}\" AZION_Password=\"${AZION_Password:-$(_readaccountconf_mutable AZION_Password)}\" if ! _contains \"$AZION_Email\" \"@\"; then _err \"It seems that the AZION_Email is not a valid email address. Revalidate your environments.\" return 1 fi if [ -z \"$AZION_Email\" ] || [ -z \"$AZION_Password\" ]; then _err \"You didn't specified a AZION_Email/AZION_Password to generate Azion token.\" return 1 fi _saveaccountconf_mutable AZION_Email \"$AZION_Email\" _saveaccountconf_mutable AZION_Password \"$AZION_Password\" _basic_auth=$(printf \"%s:%s\" \"$AZION_Email\" \"$AZION_Password\" | _base64) _debug _basic_auth \"$_basic_auth\" export _H1=\"Accept: application/json; version=3\" export _H2=\"Content-Type: application/json\" export _H3=\"Authorization: Basic $_basic_auth\" response=\"$(_post \"\" \"$AZION_Api/tokens\" \"\" \"POST\")\" if _contains \"$response\" \"\\\"token\\\":\\\"\" >/dev/null; then _azion_token=$(echo \"$response\" | _egrep_o \"\\\"token\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\") export AZION_Token=\"$_azion_token\" else _err \"Failed to generate Azion token\" return 1 fi } _azion_rest() { _method=$1 _uri=\"$2\" _data=\"$3\" if [ -z \"$AZION_Token\" ]; then _get_token fi _debug2 token \"$AZION_Token\" export _H1=\"Accept: application/json; version=3\" export _H2=\"Content-Type: application/json\" export _H3=\"Authorization: token $AZION_Token\" if [ \"$_method\" != \"GET\" ]; then _debug _data \"$_data\" response=\"$(_post \"$_data\" \"$AZION_Api/$_uri\" \"\" \"$_method\")\" else response=\"$(_get \"$AZION_Api/$_uri\")\" fi _debug2 response \"$response\" if [ \"$?\" != \"0\" ]; then _err \"error $_method $_uri $_data\" return 1 fi return 0 }"
        },
        {
            "filename": "file_167.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_167.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_azure_info='Azure Site: Azure.microsoft.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_azure Options: AZUREDNS_SUBSCRIPTIONID Subscription ID AZUREDNS_TENANTID Tenant ID AZUREDNS_APPID App ID. App ID of the service principal AZUREDNS_CLIENTSECRET Client Secret. Secret from creating the service principal AZUREDNS_MANAGEDIDENTITY Use Managed Identity. Use Managed Identity assigned to a resource instead of a service principal. \"true\"/\"false\" ' ######## Public functions ##################### # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record # # Ref: https://docs.microsoft.com/en-us/rest/api/dns/recordsets/createorupdate # dns_azure_add() { fulldomain=$1 txtvalue=$2 AZUREDNS_SUBSCRIPTIONID=\"${AZUREDNS_SUBSCRIPTIONID:-$(_readaccountconf_mutable AZUREDNS_SUBSCRIPTIONID)}\" if [ -z \"$AZUREDNS_SUBSCRIPTIONID\" ]; then AZUREDNS_SUBSCRIPTIONID=\"\" AZUREDNS_TENANTID=\"\" AZUREDNS_APPID=\"\" AZUREDNS_CLIENTSECRET=\"\" _err \"You didn't specify the Azure Subscription ID\" return 1 fi #save subscription id to account conf file. _saveaccountconf_mutable AZUREDNS_SUBSCRIPTIONID \"$AZUREDNS_SUBSCRIPTIONID\" AZUREDNS_MANAGEDIDENTITY=\"${AZUREDNS_MANAGEDIDENTITY:-$(_readaccountconf_mutable AZUREDNS_MANAGEDIDENTITY)}\" if [ \"$AZUREDNS_MANAGEDIDENTITY\" = true ]; then _info \"Using Azure managed identity\" #save managed identity as preferred authentication method, clear service principal credentials from conf file. _saveaccountconf_mutable AZUREDNS_MANAGEDIDENTITY \"$AZUREDNS_MANAGEDIDENTITY\" _saveaccountconf_mutable AZUREDNS_TENANTID \"\" _saveaccountconf_mutable AZUREDNS_APPID \"\" _saveaccountconf_mutable AZUREDNS_CLIENTSECRET \"\" else _info \"You didn't ask to use Azure managed identity, checking service principal credentials\" AZUREDNS_TENANTID=\"${AZUREDNS_TENANTID:-$(_readaccountconf_mutable AZUREDNS_TENANTID)}\" AZUREDNS_APPID=\"${AZUREDNS_APPID:-$(_readaccountconf_mutable AZUREDNS_APPID)}\" AZUREDNS_CLIENTSECRET=\"${AZUREDNS_CLIENTSECRET:-$(_readaccountconf_mutable AZUREDNS_CLIENTSECRET)}\" if [ -z \"$AZUREDNS_TENANTID\" ]; then AZUREDNS_SUBSCRIPTIONID=\"\" AZUREDNS_TENANTID=\"\" AZUREDNS_APPID=\"\" AZUREDNS_CLIENTSECRET=\"\" _err \"You didn't specify the Azure Tenant ID \" return 1 fi if [ -z \"$AZUREDNS_APPID\" ]; then AZUREDNS_SUBSCRIPTIONID=\"\" AZUREDNS_TENANTID=\"\" AZUREDNS_APPID=\"\" AZUREDNS_CLIENTSECRET=\"\" _err \"You didn't specify the Azure App ID\" return 1 fi if [ -z \"$AZUREDNS_CLIENTSECRET\" ]; then AZUREDNS_SUBSCRIPTIONID=\"\" AZUREDNS_TENANTID=\"\" AZUREDNS_APPID=\"\" AZUREDNS_CLIENTSECRET=\"\" _err \"You didn't specify the Azure Client Secret\" return 1 fi #save account details to account conf file, don't opt in for azure manages identity check. _saveaccountconf_mutable AZUREDNS_MANAGEDIDENTITY \"false\" _saveaccountconf_mutable AZUREDNS_TENANTID \"$AZUREDNS_TENANTID\" _saveaccountconf_mutable AZUREDNS_APPID \"$AZUREDNS_APPID\" _saveaccountconf_mutable AZUREDNS_CLIENTSECRET \"$AZUREDNS_CLIENTSECRET\" fi accesstoken=$(_azure_getaccess_token \"$AZUREDNS_MANAGEDIDENTITY\" \"$AZUREDNS_TENANTID\" \"$AZUREDNS_APPID\" \"$AZUREDNS_CLIENTSECRET\") if ! _get_root \"$fulldomain\" \"$AZUREDNS_SUBSCRIPTIONID\" \"$accesstoken\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" acmeRecordURI=\"https://management.azure.com$(printf '%s' \"$_domain_id\" | sed 's/\\\\//g')/TXT/$_sub_domain?api-version=2017-09-01\" _debug \"$acmeRecordURI\" # Get existing TXT record _azure_rest GET \"$acmeRecordURI\" \"\" \"$accesstoken\" values=\"{\\\"value\\\":[\\\"$txtvalue\\\"]}\" timestamp=\"$(_time)\" if [ \"$_code\" = \"200\" ]; then vlist=\"$(echo \"$response\" | _egrep_o \"\\\"value\\\"\\\\s*:\\\\s*\\\\[\\\\s*\\\"[^\\\"]*\\\"\\\\s*]\" | cut -d : -f 2 | tr -d \"[]\\\"\")\" _debug \"existing TXT found\" _debug \"$vlist\" existingts=\"$(echo \"$response\" | _egrep_o \"\\\"acmetscheck\\\"\\\\s*:\\\\s*\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \"\\\"\")\" if [ -z \"$existingts\" ]; then # the record was not created by acme.sh. Copy the exisiting entires existingts=$timestamp fi _diff=\"$(_math \"$timestamp - $existingts\")\" _debug \"existing txt age: $_diff\" # only use recently added records and discard if older than 2 hours because they are probably orphaned if [ \"$_diff\" -lt 7200 ]; then _debug \"existing txt value: $vlist\" for v in $vlist; do values=\"$values ,{\\\"value\\\":[\\\"$v\\\"]}\" done fi fi # Add the txtvalue TXT Record body=\"{\\\"properties\\\":{\\\"metadata\\\":{\\\"acmetscheck\\\":\\\"$timestamp\\\"},\\\"TTL\\\":10, \\\"TXTRecords\\\":[$values]}}\" _azure_rest PUT \"$acmeRecordURI\" \"$body\" \"$accesstoken\" if [ \"$_code\" = \"200\" ] || [ \"$_code\" = '201' ]; then _info \"validation value added\" return 0 else _err \"error adding validation value ($_code)\" return 1 fi } # Usage: fulldomain txtvalue # Used to remove the txt record after validation # # Ref: https://docs.microsoft.com/en-us/rest/api/dns/recordsets/delete # dns_azure_rm() { fulldomain=$1 txtvalue=$2 AZUREDNS_SUBSCRIPTIONID=\"${AZUREDNS_SUBSCRIPTIONID:-$(_readaccountconf_mutable AZUREDNS_SUBSCRIPTIONID)}\" if [ -z \"$AZUREDNS_SUBSCRIPTIONID\" ]; then AZUREDNS_SUBSCRIPTIONID=\"\" AZUREDNS_TENANTID=\"\" AZUREDNS_APPID=\"\" AZUREDNS_CLIENTSECRET=\"\" _err \"You didn't specify the Azure Subscription ID \" return 1 fi AZUREDNS_MANAGEDIDENTITY=\"${AZUREDNS_MANAGEDIDENTITY:-$(_readaccountconf_mutable AZUREDNS_MANAGEDIDENTITY)}\" if [ \"$AZUREDNS_MANAGEDIDENTITY\" = true ]; then _info \"Using Azure managed identity\" else _info \"You didn't ask to use Azure managed identity, checking service principal credentials\" AZUREDNS_TENANTID=\"${AZUREDNS_TENANTID:-$(_readaccountconf_mutable AZUREDNS_TENANTID)}\" AZUREDNS_APPID=\"${AZUREDNS_APPID:-$(_readaccountconf_mutable AZUREDNS_APPID)}\" AZUREDNS_CLIENTSECRET=\"${AZUREDNS_CLIENTSECRET:-$(_readaccountconf_mutable AZUREDNS_CLIENTSECRET)}\" if [ -z \"$AZUREDNS_TENANTID\" ]; then AZUREDNS_SUBSCRIPTIONID=\"\" AZUREDNS_TENANTID=\"\" AZUREDNS_APPID=\"\" AZUREDNS_CLIENTSECRET=\"\" _err \"You didn't specify the Azure Tenant ID \" return 1 fi if [ -z \"$AZUREDNS_APPID\" ]; then AZUREDNS_SUBSCRIPTIONID=\"\" AZUREDNS_TENANTID=\"\" AZUREDNS_APPID=\"\" AZUREDNS_CLIENTSECRET=\"\" _err \"You didn't specify the Azure App ID\" return 1 fi if [ -z \"$AZUREDNS_CLIENTSECRET\" ]; then AZUREDNS_SUBSCRIPTIONID=\"\" AZUREDNS_TENANTID=\"\" AZUREDNS_APPID=\"\" AZUREDNS_CLIENTSECRET=\"\" _err \"You didn't specify the Azure Client Secret\" return 1 fi fi accesstoken=$(_azure_getaccess_token \"$AZUREDNS_MANAGEDIDENTITY\" \"$AZUREDNS_TENANTID\" \"$AZUREDNS_APPID\" \"$AZUREDNS_CLIENTSECRET\") if ! _get_root \"$fulldomain\" \"$AZUREDNS_SUBSCRIPTIONID\" \"$accesstoken\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" acmeRecordURI=\"https://management.azure.com$(printf '%s' \"$_domain_id\" | sed 's/\\\\//g')/TXT/$_sub_domain?api-version=2017-09-01\" _debug \"$acmeRecordURI\" # Get existing TXT record _azure_rest GET \"$acmeRecordURI\" \"\" \"$accesstoken\" timestamp=\"$(_time)\" if [ \"$_code\" = \"200\" ]; then vlist=\"$(echo \"$response\" | _egrep_o \"\\\"value\\\"\\\\s*:\\\\s*\\\\[\\\\s*\\\"[^\\\"]*\\\"\\\\s*]\" | cut -d : -f 2 | tr -d \"[]\\\"\" | grep -v -- \"$txtvalue\")\" values=\"\" comma=\"\" for v in $vlist; do values=\"$values$comma{\\\"value\\\":[\\\"$v\\\"]}\" comma=\",\" done if [ -z \"$values\" ]; then # No values left remove record _debug \"removing validation record completely $acmeRecordURI\" _azure_rest DELETE \"$acmeRecordURI\" \"\" \"$accesstoken\" if [ \"$_code\" = \"200\" ] || [ \"$_code\" = '204' ]; then _info \"validation record removed\" else _err \"error removing validation record ($_code)\" return 1 fi else # Remove only txtvalue from the TXT Record body=\"{\\\"properties\\\":{\\\"metadata\\\":{\\\"acmetscheck\\\":\\\"$timestamp\\\"},\\\"TTL\\\":10, \\\"TXTRecords\\\":[$values]}}\" _azure_rest PUT \"$acmeRecordURI\" \"$body\" \"$accesstoken\" if [ \"$_code\" = \"200\" ] || [ \"$_code\" = '201' ]; then _info \"validation value removed\" return 0 else _err \"error removing validation value ($_code)\" return 1 fi fi fi } ################### Private functions below ################################## _azure_rest() { m=$1 ep=\"$2\" data=\"$3\" accesstoken=\"$4\" MAX_REQUEST_RETRY_TIMES=5 _request_retry_times=0 while [ \"${_request_retry_times}\" -lt \"$MAX_REQUEST_RETRY_TIMES\" ]; do _debug3 _request_retry_times \"$_request_retry_times\" export _H1=\"authorization: Bearer $accesstoken\" export _H2=\"accept: application/json\" export _H3=\"Content-Type: application/json\" # clear headers from previous request to avoid getting wrong http code on timeouts : >\"$HTTP_HEADER\" _debug \"$ep\" if [ \"$m\" != \"GET\" ]; then _secure_debug2 \"data $data\" response=\"$(_post \"$data\" \"$ep\" \"\" \"$m\")\" else response=\"$(_get \"$ep\")\" fi _ret=\"$?\" _secure_debug2 \"response $response\" _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" _debug \"http response code $_code\" if [ \"$_code\" = \"401\" ]; then # we have an invalid access token set to expired _saveaccountconf_mutable AZUREDNS_TOKENVALIDTO \"0\" _err \"access denied make sure your Azure settings are correct. See $WIKI\" return 1 fi # See https://docs.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#general-rest-and-retry-guidelines for retryable HTTP codes if [ \"$_ret\" != \"0\" ] || [ -z \"$_code\" ] || [ \"$_code\" = \"408\" ] || [ \"$_code\" = \"500\" ] || [ \"$_code\" = \"503\" ] || [ \"$_code\" = \"504\" ]; then _request_retry_times=\"$(_math \"$_request_retry_times\" + 1)\" _info \"REST call error $_code retrying $ep in $_request_retry_times s\" _sleep \"$_request_retry_times\" continue fi break done if [ \"$_request_retry_times\" = \"$MAX_REQUEST_RETRY_TIMES\" ]; then _err \"Error Azure REST called was retried $MAX_REQUEST_RETRY_TIMES times.\" _err \"Calling $ep failed.\" return 1 fi response=\"$(echo \"$response\" | _normalizeJson)\" return 0 } ## Ref: https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-protocols-oauth-service-to-service#request-an-access-token _azure_getaccess_token() { managedIdentity=$1 tenantID=$2 clientID=$3 clientSecret=$4 accesstoken=\"${AZUREDNS_BEARERTOKEN:-$(_readaccountconf_mutable AZUREDNS_BEARERTOKEN)}\" expires_on=\"${AZUREDNS_TOKENVALIDTO:-$(_readaccountconf_mutable AZUREDNS_TOKENVALIDTO)}\" # can we reuse the bearer token? if [ -n \"$accesstoken\" ] && [ -n \"$expires_on\" ]; then if [ \"$(_time)\" -lt \"$expires_on\" ]; then # brearer token is still valid - reuse it _debug \"reusing bearer token\" printf \"%s\" \"$accesstoken\" return 0 else _debug \"bearer token expired\" fi fi _debug \"getting new bearer token\" if [ \"$managedIdentity\" = true ]; then # https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/how-to-use-vm-token#get-a-token-using-http export _H1=\"Metadata: true\" response=\"$(_get http://169.254.169.254/metadata/identity/oauth2/token\\?api-version=2018-02-01\\&resource=https://management.azure.com/)\" response=\"$(echo \"$response\" | _normalizeJson)\" accesstoken=$(echo \"$response\" | _egrep_o \"\\\"access_token\\\":\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") expires_on=$(echo \"$response\" | _egrep_o \"\\\"expires_on\\\":\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") else export _H1=\"accept: application/json\" export _H2=\"Content-Type: application/x-www-form-urlencoded\" body=\"resource=$(printf \"%s\" 'https://management.core.windows.net/' | _url_encode)&client_id=$(printf \"%s\" \"$clientID\" | _url_encode)&client_secret=$(printf \"%s\" \"$clientSecret\" | _url_encode)&grant_type=client_credentials\" _secure_debug2 \"data $body\" response=\"$(_post \"$body\" \"https://login.microsoftonline.com/$tenantID/oauth2/token\" \"\" \"POST\")\" _ret=\"$?\" _secure_debug2 \"response $response\" response=\"$(echo \"$response\" | _normalizeJson)\" accesstoken=$(echo \"$response\" | _egrep_o \"\\\"access_token\\\":\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") expires_on=$(echo \"$response\" | _egrep_o \"\\\"expires_on\\\":\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") fi if [ -z \"$accesstoken\" ]; then _err \"no acccess token received. Check your Azure settings see $WIKI\" return 1 fi if [ \"$_ret\" != \"0\" ]; then _err \"error $response\" return 1 fi _saveaccountconf_mutable AZUREDNS_BEARERTOKEN \"$accesstoken\" _saveaccountconf_mutable AZUREDNS_TOKENVALIDTO \"$expires_on\" printf \"%s\" \"$accesstoken\" return 0 } _get_root() { domain=$1 subscriptionId=$2 accesstoken=$3 i=1 p=1 ## Ref: https://docs.microsoft.com/en-us/rest/api/dns/zones/list ## returns up to 100 zones in one response therefore handling more results is not not implemented ## (ZoneListResult with continuation token for the next page of results) ## Per https://docs.microsoft.com/en-us/azure/azure-subscription-service-limits#dns-limits you are limited to 100 Zone/subscriptions anyways ## _azure_rest GET \"https://management.azure.com/subscriptions/$subscriptionId/providers/Microsoft.Network/dnszones?\\$top=500&api-version=2017-09-01\" \"\" \"$accesstoken\" # Find matching domain name in Json response while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug2 \"Checking domain: $h\" if [ -z \"$h\" ]; then #not valid _err \"Invalid domain\" return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" >/dev/null; then _domain_id=$(echo \"$response\" | _egrep_o \"\\\\{\\\"id\\\":\\\"[^\\\"]*\\\\/$h\\\"\" | head -n 1 | cut -d : -f 2 | tr -d \\\") if [ \"$_domain_id\" ]; then if [ \"$i\" = 1 ]; then #create the record at the domain apex (@) if only the domain name was provided as --domain-alias _sub_domain=\"@\" else _sub_domain=$(echo \"$domain\" | cut -d . -f 1-$p) fi _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 }"
        },
        {
            "filename": "file_168.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_168.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_bookmyname_info='BookMyName.com Site: BookMyName.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_bookmyname Options: BOOKMYNAME_USERNAME Username BOOKMYNAME_PASSWORD Password Issues: github.com/acmesh-official/acme.sh/issues/3209 Author: Neilpang ' ######## Public functions ##################### # BookMyName urls: # https://BOOKMYNAME_USERNAME:BOOKMYNAME_PASSWORD@www.bookmyname.com/dyndns/?hostname=_acme-challenge.domain.tld&type=txt&ttl=300&do=add&value=\"XXXXXXXX\"' # https://BOOKMYNAME_USERNAME:BOOKMYNAME_PASSWORD@www.bookmyname.com/dyndns/?hostname=_acme-challenge.domain.tld&type=txt&ttl=300&do=remove&value=\"XXXXXXXX\"' # Output: #good: update done, cid 123456, domain id 456789, type txt, ip XXXXXXXX #good: remove done 1, cid 123456, domain id 456789, ttl 300, type txt, ip XXXXXXXX # Be careful, BMN DNS servers can be slow to pick up changes; using dnssleep is thus advised. # Usage: # export BOOKMYNAME_USERNAME=\"ABCDE-FREE\" # export BOOKMYNAME_PASSWORD=\"MyPassword\" # /usr/local/ssl/acme.sh/acme.sh --dns dns_bookmyname --dnssleep 600 --issue -d domain.tld #Usage: dns_bookmyname_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_bookmyname_add() { fulldomain=$1 txtvalue=$2 _info \"Using bookmyname\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" BOOKMYNAME_USERNAME=\"${BOOKMYNAME_USERNAME:-$(_readaccountconf_mutable BOOKMYNAME_USERNAME)}\" BOOKMYNAME_PASSWORD=\"${BOOKMYNAME_PASSWORD:-$(_readaccountconf_mutable BOOKMYNAME_PASSWORD)}\" if [ -z \"$BOOKMYNAME_USERNAME\" ] || [ -z \"$BOOKMYNAME_PASSWORD\" ]; then BOOKMYNAME_USERNAME=\"\" BOOKMYNAME_PASSWORD=\"\" _err \"You didn't specify BookMyName username and password yet.\" _err \"Please specify them and try again.\" return 1 fi #save the credentials to the account conf file. _saveaccountconf_mutable BOOKMYNAME_USERNAME \"$BOOKMYNAME_USERNAME\" _saveaccountconf_mutable BOOKMYNAME_PASSWORD \"$BOOKMYNAME_PASSWORD\" uri=\"https://${BOOKMYNAME_USERNAME}:${BOOKMYNAME_PASSWORD}@www.bookmyname.com/dyndns/\" data=\"?hostname=${fulldomain}&type=TXT&ttl=300&do=add&value=${txtvalue}\" result=\"$(_get \"${uri}${data}\")\" _debug \"Result: $result\" if ! _startswith \"$result\" 'good: update done, cid '; then _err \"Can't add $fulldomain\" return 1 fi } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_bookmyname_rm() { fulldomain=$1 txtvalue=$2 _info \"Using bookmyname\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" BOOKMYNAME_USERNAME=\"${BOOKMYNAME_USERNAME:-$(_readaccountconf_mutable BOOKMYNAME_USERNAME)}\" BOOKMYNAME_PASSWORD=\"${BOOKMYNAME_PASSWORD:-$(_readaccountconf_mutable BOOKMYNAME_PASSWORD)}\" uri=\"https://${BOOKMYNAME_USERNAME}:${BOOKMYNAME_PASSWORD}@www.bookmyname.com/dyndns/\" data=\"?hostname=${fulldomain}&type=TXT&ttl=300&do=remove&value=${txtvalue}\" result=\"$(_get \"${uri}${data}\")\" _debug \"Result: $result\" if ! _startswith \"$result\" 'good: remove done 1, cid '; then _info \"Can't remove $fulldomain\" fi } #################### Private functions below ##################################"
        },
        {
            "filename": "file_169.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_169.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_bunny_info='Bunny.net Site: Bunny.net/dns/ Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_bunny Options: BUNNY_API_KEY API Key Issues: github.com/acmesh-official/acme.sh/issues/4296 Author: <nosilver4u@ewww.io> ' ##################### Public functions ##################### ## Create the text record for validation. ## Usage: fulldomain txtvalue ## EG: \"_acme-challenge.www.other.domain.com\" \"XKrxpRBosdq0HG9i01zxXp5CPBs\" dns_bunny_add() { fulldomain=\"$(echo \"$1\" | _lower_case)\" txtvalue=$2 BUNNY_API_KEY=\"${BUNNY_API_KEY:-$(_readaccountconf_mutable BUNNY_API_KEY)}\" # Check if API Key is set if [ -z \"$BUNNY_API_KEY\" ]; then BUNNY_API_KEY=\"\" _err \"You did not specify Bunny.net API key.\" _err \"Please export BUNNY_API_KEY and try again.\" return 1 fi _info \"Using Bunny.net dns validation - add record\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" ## save the env vars (key and domain split location) for later automated use _saveaccountconf_mutable BUNNY_API_KEY \"$BUNNY_API_KEY\" ## split the domain for Bunny API if ! _get_base_domain \"$fulldomain\"; then _err \"domain not found in your account for addition\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug _domain_id \"$_domain_id\" ## Set the header with our post type and auth key export _H1=\"Accept: application/json\" export _H2=\"AccessKey: $BUNNY_API_KEY\" export _H3=\"Content-Type: application/json\" PURL=\"https://api.bunny.net/dnszone/$_domain_id/records\" PBODY='{\"Id\":'$_domain_id',\"Type\":3,\"Name\":\"'$_sub_domain'\",\"Value\":\"'$txtvalue'\",\"ttl\":120}' _debug PURL \"$PURL\" _debug PBODY \"$PBODY\" ## the create request - POST ## args: BODY, URL, [need64, httpmethod] response=\"$(_post \"$PBODY\" \"$PURL\" \"\" \"PUT\")\" ## check response if [ \"$?\" != \"0\" ]; then _err \"error in response: $response\" return 1 fi _debug2 response \"$response\" ## finished correctly return 0 } ## Remove the txt record after validation. ## Usage: fulldomain txtvalue ## EG: \"_acme-challenge.www.other.domain.com\" \"XKrxpRBosdq0HG9i01zxXp5CPBs\" dns_bunny_rm() { fulldomain=\"$(echo \"$1\" | _lower_case)\" txtvalue=$2 BUNNY_API_KEY=\"${BUNNY_API_KEY:-$(_readaccountconf_mutable BUNNY_API_KEY)}\" # Check if API Key Exists if [ -z \"$BUNNY_API_KEY\" ]; then BUNNY_API_KEY=\"\" _err \"You did not specify Bunny.net API key.\" _err \"Please export BUNNY_API_KEY and try again.\" return 1 fi _info \"Using Bunny.net dns validation - remove record\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" ## split the domain for Bunny API if ! _get_base_domain \"$fulldomain\"; then _err \"Domain not found in your account for TXT record removal\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug _domain_id \"$_domain_id\" ## Set the header with our post type and key auth key export _H1=\"Accept: application/json\" export _H2=\"AccessKey: $BUNNY_API_KEY\" ## get URL for the list of DNS records GURL=\"https://api.bunny.net/dnszone/$_domain_id\" ## 1) Get the domain/zone records ## the fetch request - GET ## args: URL, [onlyheader, timeout] domain_list=\"$(_get \"$GURL\")\" ## check response if [ \"$?\" != \"0\" ]; then _err \"error in domain_list response: $domain_list\" return 1 fi _debug2 domain_list \"$domain_list\" ## 2) search through records ## check for what we are looking for: \"Type\":3,\"Value\":\"$txtvalue\",\"Name\":\"$_sub_domain\" record=\"$(echo \"$domain_list\" | _egrep_o \"\\\"Id\\\"\\s*\\:\\s*\\\"*[0-9]+\\\"*,\\s*\\\"Type\\\"[^}]*\\\"Value\\\"\\s*\\:\\s*\\\"$txtvalue\\\"[^}]*\\\"Name\\\"\\s*\\:\\s*\\\"$_sub_domain\\\"\")\" if [ -n \"$record\" ]; then ## We found records rec_ids=\"$(echo \"$record\" | _egrep_o \"Id\\\"\\s*\\:\\s*\\\"*[0-9]+\" | _egrep_o \"[0-9]+\")\" _debug rec_ids \"$rec_ids\" if [ -n \"$rec_ids\" ]; then echo \"$rec_ids\" | while IFS= read -r rec_id; do ## delete the record ## delete URL for removing the one we dont want DURL=\"https://api.bunny.net/dnszone/$_domain_id/records/$rec_id\" ## the removal request - DELETE ## args: BODY, URL, [need64, httpmethod] response=\"$(_post \"\" \"$DURL\" \"\" \"DELETE\")\" ## check response (sort of) if [ \"$?\" != \"0\" ]; then _err \"error in remove response: $response\" return 1 fi _debug2 response \"$response\" done fi fi ## finished correctly return 0 } ##################### Private functions below ##################### ## Split the domain provided into the \"base domain\" and the \"start prefix\". ## This function searches for the longest subdomain in your account ## for the full domain given and splits it into the base domain (zone) ## and the prefix/record to be added/removed ## USAGE: fulldomain ## EG: \"_acme-challenge.two.three.four.domain.com\" ## returns ## _sub_domain=\"_acme-challenge.two\" ## _domain=\"three.four.domain.com\" *IF* zone \"three.four.domain.com\" exists ## _domain_id=234 ## if only \"domain.com\" exists it will return ## _sub_domain=\"_acme-challenge.two.three.four\" ## _domain=\"domain.com\" ## _domain_id=234 _get_base_domain() { # args fulldomain=\"$(echo \"$1\" | _lower_case)\" _debug fulldomain \"$fulldomain\" # domain max legal length = 253 MAX_DOM=255 page=1 ## get a list of domains for the account to check thru ## Set the headers export _H1=\"Accept: application/json\" export _H2=\"AccessKey: $BUNNY_API_KEY\" _debug BUNNY_API_KEY \"$BUNNY_API_KEY\" ## get URL for the list of domains ## may get: \"links\":{\"pages\":{\"last\":\".../v2/domains/DOM/records?page=2\",\"next\":\".../v2/domains/DOM/records?page=2\"}} DOMURL=\"https://api.bunny.net/dnszone\" ## while we dont have a matching domain we keep going while [ -z \"$found\" ]; do ## get the domain list (current page) domain_list=\"$(_get \"$DOMURL\")\" ## check response if [ \"$?\" != \"0\" ]; then _err \"error in domain_list response: $domain_list\" return 1 fi _debug2 domain_list \"$domain_list\" i=1 while [ $i -gt 0 ]; do ## get next longest domain _domain=$(printf \"%s\" \"$fulldomain\" | cut -d . -f \"$i\"-\"$MAX_DOM\") ## check we got something back from our cut (or are we at the end) if [ -z \"$_domain\" ]; then break fi ## we got part of a domain back - grep it out found=\"$(echo \"$domain_list\" | _egrep_o \"\\\"Id\\\"\\s*:\\s*\\\"*[0-9]+\\\"*,\\s*\\\"Domain\\\"\\s*\\:\\s*\\\"$_domain\\\"\")\" ## check if it exists if [ -n \"$found\" ]; then ## exists - exit loop returning the parts sub_point=$(_math $i - 1) _sub_domain=$(printf \"%s\" \"$fulldomain\" | cut -d . -f 1-\"$sub_point\") _domain_id=\"$(echo \"$found\" | _egrep_o \"Id\\\"\\s*\\:\\s*\\\"*[0-9]+\" | _egrep_o \"[0-9]+\")\" _debug _domain_id \"$_domain_id\" _debug _domain \"$_domain\" _debug _sub_domain \"$_sub_domain\" found=\"\" return 0 fi ## increment cut point $i i=$(_math $i + 1) done if [ -z \"$found\" ]; then page=$(_math $page + 1) nextpage=\"https://api.bunny.net/dnszone?page=$page\" ## Find the next page if we don't have a match. hasnextpage=\"$(echo \"$domain_list\" | _egrep_o \"\\\"HasMoreItems\\\"\\s*:\\s*true\")\" if [ -z \"$hasnextpage\" ]; then _err \"No record and no nextpage in Bunny.net domain search.\" found=\"\" return 1 fi _debug2 nextpage \"$nextpage\" DOMURL=\"$nextpage\" fi done ## We went through the entire domain zone list and didn't find one that matched. ## If we ever get here, something is broken in the code... _err \"Domain not found in Bunny.net account, but we should never get here!\" found=\"\" return 1 }"
        },
        {
            "filename": "file_170.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_170.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_cf_info='CloudFlare Site: CloudFlare.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_cf Options: CF_Key API Key CF_Email Your account email OptionsAlt: CF_Token API Token CF_Account_ID Account ID CF_Zone_ID Zone ID. Optional. ' CF_Api=\"https://api.cloudflare.com/client/v4\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_cf_add() { fulldomain=$1 txtvalue=$2 CF_Token=\"${CF_Token:-$(_readaccountconf_mutable CF_Token)}\" CF_Account_ID=\"${CF_Account_ID:-$(_readaccountconf_mutable CF_Account_ID)}\" CF_Zone_ID=\"${CF_Zone_ID:-$(_readaccountconf_mutable CF_Zone_ID)}\" CF_Key=\"${CF_Key:-$(_readaccountconf_mutable CF_Key)}\" CF_Email=\"${CF_Email:-$(_readaccountconf_mutable CF_Email)}\" if [ \"$CF_Token\" ]; then if [ \"$CF_Zone_ID\" ]; then _savedomainconf CF_Token \"$CF_Token\" _savedomainconf CF_Account_ID \"$CF_Account_ID\" _savedomainconf CF_Zone_ID \"$CF_Zone_ID\" else _saveaccountconf_mutable CF_Token \"$CF_Token\" _saveaccountconf_mutable CF_Account_ID \"$CF_Account_ID\" _clearaccountconf_mutable CF_Zone_ID _clearaccountconf CF_Zone_ID fi else if [ -z \"$CF_Key\" ] || [ -z \"$CF_Email\" ]; then CF_Key=\"\" CF_Email=\"\" _err \"You didn't specify a Cloudflare api key and email yet.\" _err \"You can get yours from here https://dash.cloudflare.com/profile.\" return 1 fi if ! _contains \"$CF_Email\" \"@\"; then _err \"It seems that the CF_Email=$CF_Email is not a valid email address.\" _err \"Please check and retry.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable CF_Key \"$CF_Key\" _saveaccountconf_mutable CF_Email \"$CF_Email\" _clearaccountconf_mutable CF_Token _clearaccountconf_mutable CF_Account_ID _clearaccountconf_mutable CF_Zone_ID _clearaccountconf CF_Token _clearaccountconf CF_Account_ID _clearaccountconf CF_Zone_ID fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _cf_rest GET \"zones/${_domain_id}/dns_records?type=TXT&name=$fulldomain\" if ! echo \"$response\" | tr -d \" \" | grep \\\"success\\\":true >/dev/null; then _err \"Error\" return 1 fi # For wildcard cert, the main root domain and the wildcard domain have the same txt subdomain name, so # we can not use updating anymore. # count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"count\\\":[^,]*\" | cut -d : -f 2) # _debug count \"$count\" # if [ \"$count\" = \"0\" ]; then _info \"Adding record\" if _cf_rest POST \"zones/$_domain_id/dns_records\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$fulldomain\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":120}\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"Added, OK\" return 0 elif _contains \"$response\" \"The record already exists\"; then _info \"Already exists, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_cf_rm() { fulldomain=$1 txtvalue=$2 CF_Token=\"${CF_Token:-$(_readaccountconf_mutable CF_Token)}\" CF_Account_ID=\"${CF_Account_ID:-$(_readaccountconf_mutable CF_Account_ID)}\" CF_Zone_ID=\"${CF_Zone_ID:-$(_readaccountconf_mutable CF_Zone_ID)}\" CF_Key=\"${CF_Key:-$(_readaccountconf_mutable CF_Key)}\" CF_Email=\"${CF_Email:-$(_readaccountconf_mutable CF_Email)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _cf_rest GET \"zones/${_domain_id}/dns_records?type=TXT&name=$fulldomain&content=$txtvalue\" if ! echo \"$response\" | tr -d \" \" | grep \\\"success\\\":true >/dev/null; then _err \"Error: $response\" return 1 fi count=$(echo \"$response\" | _egrep_o \"\\\"count\\\": *[^,]*\" | cut -d : -f 2 | tr -d \" \") _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else record_id=$(echo \"$response\" | _egrep_o \"\\\"id\\\": *\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\" | _head_n 1 | tr -d \" \") _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _cf_rest DELETE \"zones/$_domain_id/dns_records/$record_id\"; then _err \"Delete record error.\" return 1 fi echo \"$response\" | tr -d \" \" | grep \\\"success\\\":true >/dev/null fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=1 p=1 # Use Zone ID directly if provided if [ \"$CF_Zone_ID\" ]; then if ! _cf_rest GET \"zones/$CF_Zone_ID\"; then return 1 else if echo \"$response\" | tr -d \" \" | grep \\\"success\\\":true >/dev/null; then _domain=$(echo \"$response\" | _egrep_o \"\\\"name\\\": *\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\" | _head_n 1 | tr -d \" \") if [ \"$_domain\" ]; then _cutlength=$((${#domain} - ${#_domain} - 1)) _sub_domain=$(printf \"%s\" \"$domain\" | cut -c \"1-$_cutlength\") _domain_id=$CF_Zone_ID return 0 else return 1 fi else return 1 fi fi fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if [ \"$CF_Account_ID\" ]; then if ! _cf_rest GET \"zones?name=$h&account.id=$CF_Account_ID\"; then return 1 fi else if ! _cf_rest GET \"zones?name=$h\"; then return 1 fi fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" || _contains \"$response\" '\"total_count\":1'; then _domain_id=$(echo \"$response\" | _egrep_o \"\\[.\\\"id\\\": *\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \\\" | tr -d \" \") if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _cf_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" email_trimmed=$(echo \"$CF_Email\" | tr -d '\"') key_trimmed=$(echo \"$CF_Key\" | tr -d '\"') token_trimmed=$(echo \"$CF_Token\" | tr -d '\"') export _H1=\"Content-Type: application/json\" if [ \"$token_trimmed\" ]; then export _H2=\"Authorization: Bearer $token_trimmed\" else export _H2=\"X-Auth-Email: $email_trimmed\" export _H3=\"X-Auth-Key: $key_trimmed\" fi if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$CF_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$CF_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_171.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_171.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_clouddns_info='vshosting.cz CloudDNS Site: github.com/vshosting/clouddns Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_clouddns Options: CLOUDDNS_EMAIL Email CLOUDDNS_PASSWORD Password CLOUDDNS_CLIENT_ID Client ID Issues: github.com/acmesh-official/acme.sh/issues/2699 Author: Radek Sprta <sprta@vshosting.cz> ' CLOUDDNS_API='https://admin.vshosting.cloud/clouddns' CLOUDDNS_LOGIN_API='https://admin.vshosting.cloud/api/public/auth/login' ######## Public functions ##################### # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_clouddns_add() { fulldomain=$1 txtvalue=$2 _debug \"fulldomain\" \"$fulldomain\" CLOUDDNS_CLIENT_ID=\"${CLOUDDNS_CLIENT_ID:-$(_readaccountconf_mutable CLOUDDNS_CLIENT_ID)}\" CLOUDDNS_EMAIL=\"${CLOUDDNS_EMAIL:-$(_readaccountconf_mutable CLOUDDNS_EMAIL)}\" CLOUDDNS_PASSWORD=\"${CLOUDDNS_PASSWORD:-$(_readaccountconf_mutable CLOUDDNS_PASSWORD)}\" if [ -z \"$CLOUDDNS_PASSWORD\" ] || [ -z \"$CLOUDDNS_EMAIL\" ] || [ -z \"$CLOUDDNS_CLIENT_ID\" ]; then CLOUDDNS_CLIENT_ID=\"\" CLOUDDNS_EMAIL=\"\" CLOUDDNS_PASSWORD=\"\" _err \"You didn't specify a CloudDNS password, email and client ID yet.\" return 1 fi if ! _contains \"$CLOUDDNS_EMAIL\" \"@\"; then _err \"It seems that the CLOUDDNS_EMAIL=$CLOUDDNS_EMAIL is not a valid email address.\" _err \"Please check and retry.\" return 1 fi # Save CloudDNS client id, email and password to config file _saveaccountconf_mutable CLOUDDNS_CLIENT_ID \"$CLOUDDNS_CLIENT_ID\" _saveaccountconf_mutable CLOUDDNS_EMAIL \"$CLOUDDNS_EMAIL\" _saveaccountconf_mutable CLOUDDNS_PASSWORD \"$CLOUDDNS_PASSWORD\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # Add TXT record data=\"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$fulldomain.\\\",\\\"value\\\":\\\"$txtvalue\\\",\\\"domainId\\\":\\\"$_domain_id\\\"}\" if _clouddns_api POST \"record-txt\" \"$data\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"Added, OK\" elif _contains \"$response\" '\"code\":4136'; then _info \"Already exists, OK\" else _err \"Add TXT record error.\" return 1 fi fi _debug \"Publishing record changes\" _clouddns_api PUT \"domain/$_domain_id/publish\" \"{\\\"soaTtl\\\":300}\" } # Usage: rm _acme-challenge.www.domain.com dns_clouddns_rm() { fulldomain=$1 _debug \"fulldomain\" \"$fulldomain\" CLOUDDNS_CLIENT_ID=\"${CLOUDDNS_CLIENT_ID:-$(_readaccountconf_mutable CLOUDDNS_CLIENT_ID)}\" CLOUDDNS_EMAIL=\"${CLOUDDNS_EMAIL:-$(_readaccountconf_mutable CLOUDDNS_EMAIL)}\" CLOUDDNS_PASSWORD=\"${CLOUDDNS_PASSWORD:-$(_readaccountconf_mutable CLOUDDNS_PASSWORD)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # Get record ID _clouddns_api GET \"domain/$_domain_id\" if _contains \"$response\" \"lastDomainRecordList\"; then re=\"\\\"lastDomainRecordList\\\".*\\\"id\\\":\\\"([^\\\"}]*)\\\"[^}]*\\\"name\\\":\\\"$fulldomain.\\\",\" _last_domains=$(echo \"$response\" | _egrep_o \"$re\") re2=\"\\\"id\\\":\\\"([^\\\"}]*)\\\"[^}]*\\\"name\\\":\\\"$fulldomain.\\\",\" _record_id=$(echo \"$_last_domains\" | _egrep_o \"$re2\" | _head_n 1 | cut -d : -f 2 | cut -d , -f 1 | tr -d \"\\\"\") _debug _record_id \"$_record_id\" else _err \"Could not retrieve record ID\" return 1 fi _info \"Removing record\" if _clouddns_api DELETE \"record/$_record_id\"; then if _contains \"$response\" \"\\\"error\\\":\"; then _err \"Could not remove record\" return 1 fi fi _debug \"Publishing record changes\" _clouddns_api PUT \"domain/$_domain_id/publish\" \"{\\\"soaTtl\\\":300}\" } #################### Private functions below ################################## # Usage: _get_root _acme-challenge.www.domain.com # Returns: # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 # Get domain root data=\"{\\\"search\\\": [{\\\"name\\\": \\\"clientId\\\", \\\"operator\\\": \\\"eq\\\", \\\"value\\\": \\\"$CLOUDDNS_CLIENT_ID\\\"}]}\" _clouddns_api \"POST\" \"domain/search\" \"$data\" domain_slice=\"$domain\" while [ -z \"$domain_root\" ]; do if _contains \"$response\" \"\\\"domainName\\\":\\\"$domain_slice\\.\\\"\"; then domain_root=\"$domain_slice\" _debug domain_root \"$domain_root\" fi domain_slice=\"$(echo \"$domain_slice\" | cut -d . -f 2-)\" done # Get domain id data=\"{\\\"search\\\": [{\\\"name\\\": \\\"clientId\\\", \\\"operator\\\": \\\"eq\\\", \\\"value\\\": \\\"$CLOUDDNS_CLIENT_ID\\\"}, \\ {\\\"name\\\": \\\"domainName\\\", \\\"operator\\\": \\\"eq\\\", \\\"value\\\": \\\"$domain_root.\\\"}]}\" _clouddns_api \"POST\" \"domain/search\" \"$data\" if _contains \"$response\" \"\\\"id\\\":\\\"\"; then re='domainType\\\":\\\"[^\\\"]*\\\",\\\"id\\\":\\\"([^\\\"]*)\\\",' # Match domain id _domain_id=$(echo \"$response\" | _egrep_o \"$re\" | _head_n 1 | cut -d : -f 3 | tr -d \"\\\",\") if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | sed \"s/.$domain_root//\") _domain=\"$domain_root\" return 0 fi _err 'Domain name not found on your CloudDNS account' return 1 fi return 1 } # Usage: _clouddns_api GET domain/search '{\"data\": \"value\"}' # Returns: # response='{\"message\": \"api response\"}' _clouddns_api() { method=$1 endpoint=\"$2\" data=\"$3\" _debug endpoint \"$endpoint\" if [ -z \"$CLOUDDNS_TOKEN\" ]; then _clouddns_login fi _debug CLOUDDNS_TOKEN \"$CLOUDDNS_TOKEN\" export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: Bearer $CLOUDDNS_TOKEN\" if [ \"$method\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$CLOUDDNS_API/$endpoint\" \"\" \"$method\" | tr -d '\\t\\r\\n ')\" else response=\"$(_get \"$CLOUDDNS_API/$endpoint\" | tr -d '\\t\\r\\n ')\" fi # shellcheck disable=SC2181 if [ \"$?\" != \"0\" ]; then _err \"Error $endpoint\" return 1 fi _debug2 response \"$response\" return 0 } # Returns: # CLOUDDNS_TOKEN=dslfje2rj23l _clouddns_login() { login_data=\"{\\\"email\\\": \\\"$CLOUDDNS_EMAIL\\\", \\\"password\\\": \\\"$CLOUDDNS_PASSWORD\\\"}\" response=\"$(_post \"$login_data\" \"$CLOUDDNS_LOGIN_API\" \"\" \"POST\" \"Content-Type: application/json\")\" if _contains \"$response\" \"\\\"accessToken\\\":\\\"\"; then CLOUDDNS_TOKEN=$(echo \"$response\" | _egrep_o \"\\\"accessToken\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\") export CLOUDDNS_TOKEN else echo 'Could not get CloudDNS access token; check your credentials' return 1 fi return 0 }"
        },
        {
            "filename": "file_172.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_172.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_cloudns_info='ClouDNS.net Site: ClouDNS.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_cloudns Options: CLOUDNS_AUTH_ID Regular auth ID CLOUDNS_SUB_AUTH_ID Sub auth ID CLOUDNS_AUTH_PASSWORD Auth Password Author: Boyan Peychev <boyan@cloudns.net> ' CLOUDNS_API=\"https://api.cloudns.net\" DOMAIN_TYPE= DOMAIN_MASTER= ######## Public functions ##################### #Usage: dns_cloudns_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_cloudns_add() { _info \"Using cloudns\" if ! _dns_cloudns_init_check; then return 1 fi zone=\"$(_dns_cloudns_get_zone_name \"$1\")\" if [ -z \"$zone\" ]; then _err \"Missing DNS zone at ClouDNS. Please log into your control panel and create the required DNS zone for the initial setup.\" return 1 fi host=\"$(echo \"$1\" | sed \"s/\\.$zone\\$//\")\" record=$2 _debug zone \"$zone\" _debug host \"$host\" _debug record \"$record\" _info \"Adding the TXT record for $1\" _dns_cloudns_http_api_call \"dns/add-record.json\" \"domain-name=$zone&record-type=TXT&host=$host&record=$record&ttl=60\" if ! _contains \"$response\" \"\\\"status\\\":\\\"Success\\\"\"; then _err \"Record cannot be added.\" return 1 fi _info \"Added.\" return 0 } #Usage: dns_cloudns_rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_cloudns_rm() { _info \"Using cloudns\" if ! _dns_cloudns_init_check; then return 1 fi if [ -z \"$zone\" ]; then zone=\"$(_dns_cloudns_get_zone_name \"$1\")\" if [ -z \"$zone\" ]; then _err \"Missing DNS zone at ClouDNS. Please log into your control panel and create the required DNS zone for the initial setup.\" return 1 fi fi host=\"$(echo \"$1\" | sed \"s/\\.$zone\\$//\")\" record=$2 _dns_cloudns_get_zone_info \"$zone\" _debug \"Type\" \"$DOMAIN_TYPE\" _debug \"Cloud Master\" \"$DOMAIN_MASTER\" if _contains \"$DOMAIN_TYPE\" \"cloud\"; then zone=$DOMAIN_MASTER fi _debug \"ZONE\" \"$zone\" _dns_cloudns_http_api_call \"dns/records.json\" \"domain-name=$zone&host=$host&type=TXT\" if ! _contains \"$response\" \"\\\"id\\\":\"; then return 1 fi for i in $(echo \"$response\" | tr '{' \"\\n\" | grep -- \"$record\"); do record_id=$(echo \"$i\" | tr ',' \"\\n\" | grep -E '^\"id\"' | sed -re 's/^\\\"id\\\"\\:\\\"([0-9]+)\\\"$/\\1/g') if [ -n \"$record_id\" ]; then _debug zone \"$zone\" _debug host \"$host\" _debug record \"$record\" _debug record_id \"$record_id\" _info \"Deleting the TXT record for $1\" _dns_cloudns_http_api_call \"dns/delete-record.json\" \"domain-name=$zone&record-id=$record_id\" if ! _contains \"$response\" \"\\\"status\\\":\\\"Success\\\"\"; then _err \"The TXT record for $1 cannot be deleted.\" else _info \"Deleted.\" fi fi done return 0 } #################### Private functions below ################################## _dns_cloudns_init_check() { if [ -n \"$CLOUDNS_INIT_CHECK_COMPLETED\" ]; then return 0 fi CLOUDNS_AUTH_ID=\"${CLOUDNS_AUTH_ID:-$(_readaccountconf_mutable CLOUDNS_AUTH_ID)}\" CLOUDNS_SUB_AUTH_ID=\"${CLOUDNS_SUB_AUTH_ID:-$(_readaccountconf_mutable CLOUDNS_SUB_AUTH_ID)}\" CLOUDNS_AUTH_PASSWORD=\"${CLOUDNS_AUTH_PASSWORD:-$(_readaccountconf_mutable CLOUDNS_AUTH_PASSWORD)}\" if [ -z \"$CLOUDNS_AUTH_ID$CLOUDNS_SUB_AUTH_ID\" ] || [ -z \"$CLOUDNS_AUTH_PASSWORD\" ]; then CLOUDNS_AUTH_ID=\"\" CLOUDNS_SUB_AUTH_ID=\"\" CLOUDNS_AUTH_PASSWORD=\"\" _err \"You don't specify cloudns api id and password yet.\" _err \"Please create you id and password and try again.\" return 1 fi if [ -z \"$CLOUDNS_AUTH_ID\" ] && [ -z \"$CLOUDNS_SUB_AUTH_ID\" ]; then _err \"CLOUDNS_AUTH_ID or CLOUDNS_SUB_AUTH_ID is not configured\" return 1 fi if [ -z \"$CLOUDNS_AUTH_PASSWORD\" ]; then _err \"CLOUDNS_AUTH_PASSWORD is not configured\" return 1 fi _dns_cloudns_http_api_call \"dns/login.json\" \"\" if ! _contains \"$response\" \"\\\"status\\\":\\\"Success\\\"\"; then _err \"Invalid CLOUDNS_AUTH_ID or CLOUDNS_AUTH_PASSWORD. Please check your login credentials.\" return 1 fi # save the api id and password to the account conf file. _saveaccountconf_mutable CLOUDNS_AUTH_ID \"$CLOUDNS_AUTH_ID\" _saveaccountconf_mutable CLOUDNS_SUB_AUTH_ID \"$CLOUDNS_SUB_AUTH_ID\" _saveaccountconf_mutable CLOUDNS_AUTH_PASSWORD \"$CLOUDNS_AUTH_PASSWORD\" CLOUDNS_INIT_CHECK_COMPLETED=1 return 0 } _dns_cloudns_get_zone_info() { zone=$1 _dns_cloudns_http_api_call \"dns/get-zone-info.json\" \"domain-name=$zone\" if ! _contains \"$response\" \"\\\"status\\\":\\\"Failed\\\"\"; then DOMAIN_TYPE=$(echo \"$response\" | _egrep_o '\"type\":\"[^\"]*\"' | cut -d : -f 2 | tr -d '\"') if _contains \"$DOMAIN_TYPE\" \"cloud\"; then DOMAIN_MASTER=$(echo \"$response\" | _egrep_o '\"cloud-master\":\"[^\"]*\"' | cut -d : -f 2 | tr -d '\"') fi fi return 0 } _dns_cloudns_get_zone_name() { i=2 while true; do zoneForCheck=$(printf \"%s\" \"$1\" | cut -d . -f $i-100) if [ -z \"$zoneForCheck\" ]; then return 1 fi _debug zoneForCheck \"$zoneForCheck\" _dns_cloudns_http_api_call \"dns/get-zone-info.json\" \"domain-name=$zoneForCheck\" if ! _contains \"$response\" \"\\\"status\\\":\\\"Failed\\\"\"; then echo \"$zoneForCheck\" return 0 fi i=$(_math \"$i\" + 1) done return 1 } _dns_cloudns_http_api_call() { method=$1 _debug CLOUDNS_AUTH_ID \"$CLOUDNS_AUTH_ID\" _debug CLOUDNS_SUB_AUTH_ID \"$CLOUDNS_SUB_AUTH_ID\" _debug CLOUDNS_AUTH_PASSWORD \"$CLOUDNS_AUTH_PASSWORD\" if [ -n \"$CLOUDNS_SUB_AUTH_ID\" ]; then auth_user=\"sub-auth-id=$CLOUDNS_SUB_AUTH_ID\" else auth_user=\"auth-id=$CLOUDNS_AUTH_ID\" fi if [ -z \"$2\" ]; then data=\"$auth_user&auth-password=$CLOUDNS_AUTH_PASSWORD\" else data=\"$auth_user&auth-password=$CLOUDNS_AUTH_PASSWORD&$2\" fi response=\"$(_get \"$CLOUDNS_API/$method?$data\")\" _debug response \"$response\" return 0 }"
        },
        {
            "filename": "file_173.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_173.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_cn_info='Core-Networks.de Site: beta.api.Core-Networks.de/doc/ Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_cn Options: CN_User User CN_Password Password Issues: github.com/acmesh-official/acme.sh/issues/2142 Author: 5ll, francis ' CN_API=\"https://beta.api.core-networks.de\" ######## Public functions ##################### dns_cn_add() { fulldomain=$1 txtvalue=$2 if ! _cn_login; then _err \"login failed\" return 1 fi _debug \"First detect the root zone\" if ! _cn_get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug \"_sub_domain $_sub_domain\" _debug \"_domain $_domain\" _info \"Adding record\" curData=\"{\\\"name\\\":\\\"$_sub_domain\\\",\\\"ttl\\\":120,\\\"type\\\":\\\"TXT\\\",\\\"data\\\":\\\"$txtvalue\\\"}\" curResult=\"$(_post \"${curData}\" \"${CN_API}/dnszones/${_domain}/records/\")\" _debug \"curData $curData\" _debug \"curResult $curResult\" if _contains \"$curResult\" \"\"; then _info \"Added, OK\" if ! _cn_commit; then _err \"commiting changes failed\" return 1 fi return 0 else _err \"Add txt record error.\" _debug \"curData is $curData\" _debug \"curResult is $curResult\" _err \"error adding text record, response was $curResult\" return 1 fi } dns_cn_rm() { fulldomain=$1 txtvalue=$2 if ! _cn_login; then _err \"login failed\" return 1 fi _debug \"First detect the root zone\" if ! _cn_get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _info \"Deleting record\" curData=\"{\\\"name\\\":\\\"$_sub_domain\\\",\\\"data\\\":\\\"$txtvalue\\\"}\" curResult=\"$(_post \"${curData}\" \"${CN_API}/dnszones/${_domain}/records/delete\")\" _debug curData is \"$curData\" _info \"commiting changes\" if ! _cn_commit; then _err \"commiting changes failed\" return 1 fi _info \"Deletet txt record\" return 0 } ################### Private functions below ################################## _cn_login() { CN_User=\"${CN_User:-$(_readaccountconf_mutable CN_User)}\" CN_Password=\"${CN_Password:-$(_readaccountconf_mutable CN_Password)}\" if [ -z \"$CN_User\" ] || [ -z \"$CN_Password\" ]; then CN_User=\"\" CN_Password=\"\" _err \"You must export variables: CN_User and CN_Password\" return 1 fi #save the config variables to the account conf file. _saveaccountconf_mutable CN_User \"$CN_User\" _saveaccountconf_mutable CN_Password \"$CN_Password\" _info \"Getting an AUTH-Token\" curData=\"{\\\"login\\\":\\\"${CN_User}\\\",\\\"password\\\":\\\"${CN_Password}\\\"}\" curResult=\"$(_post \"${curData}\" \"${CN_API}/auth/token\")\" _debug \"Calling _CN_login: '${curData}' '${CN_API}/auth/token'\" if _contains \"${curResult}\" '\"token\":\"'; then authToken=$(echo \"${curResult}\" | cut -d \":\" -f2 | cut -d \",\" -f1 | sed 's/^.\\(.*\\).$/\\1/') export _H1=\"Authorization: Bearer $authToken\" _info \"Successfully acquired AUTH-Token\" _debug \"AUTH-Token: '${authToken}'\" _debug \"_H1 '${_H1}'\" else _err \"Couldn't acquire an AUTH-Token\" return 1 fi } # Commit changes _cn_commit() { _info \"Commiting changes\" _post \"\" \"${CN_API}/dnszones/$h/records/commit\" } _cn_get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" _debug _H1 \"${_H1}\" if [ -z \"$h\" ]; then #not valid return 1 fi _cn_zonelist=\"$(_get ${CN_API}/dnszones/)\" _debug _cn_zonelist \"${_cn_zonelist}\" if [ \"$?\" != \"0\" ]; then _err \"something went wrong while getting the zone list\" return 1 fi if _contains \"$_cn_zonelist\" \"\\\"name\\\":\\\"$h\\\"\" >/dev/null; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 else _debug \"Zonelist does not contain domain - iterating \" fi p=$i i=$(_math \"$i\" + 1) done _err \"Zonelist does not contain domain - exiting\" return 1 }"
        },
        {
            "filename": "file_174.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_174.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_conoha_info='ConoHa.jp Domains: ConoHa.io Site: ConoHa.jp Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_conoha Options: CONOHA_Username Username CONOHA_Password Password CONOHA_TenantId TenantId CONOHA_IdentityServiceApi Identity Service API. E.g. \"https://identity.xxxx.conoha.io/v2.0\" ' CONOHA_DNS_EP_PREFIX_REGEXP=\"https://dns-service\\.\" ######## Public functions ##################### #Usage: dns_conoha_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_conoha_add() { fulldomain=$1 txtvalue=$2 _info \"Using conoha\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug \"Check uesrname and password\" CONOHA_Username=\"${CONOHA_Username:-$(_readaccountconf_mutable CONOHA_Username)}\" CONOHA_Password=\"${CONOHA_Password:-$(_readaccountconf_mutable CONOHA_Password)}\" CONOHA_TenantId=\"${CONOHA_TenantId:-$(_readaccountconf_mutable CONOHA_TenantId)}\" CONOHA_IdentityServiceApi=\"${CONOHA_IdentityServiceApi:-$(_readaccountconf_mutable CONOHA_IdentityServiceApi)}\" if [ -z \"$CONOHA_Username\" ] || [ -z \"$CONOHA_Password\" ] || [ -z \"$CONOHA_TenantId\" ] || [ -z \"$CONOHA_IdentityServiceApi\" ]; then CONOHA_Username=\"\" CONOHA_Password=\"\" CONOHA_TenantId=\"\" CONOHA_IdentityServiceApi=\"\" _err \"You didn't specify a conoha api username and password yet.\" _err \"Please create the user and try again.\" return 1 fi _saveaccountconf_mutable CONOHA_Username \"$CONOHA_Username\" _saveaccountconf_mutable CONOHA_Password \"$CONOHA_Password\" _saveaccountconf_mutable CONOHA_TenantId \"$CONOHA_TenantId\" _saveaccountconf_mutable CONOHA_IdentityServiceApi \"$CONOHA_IdentityServiceApi\" if token=\"$(_conoha_get_accesstoken \"$CONOHA_IdentityServiceApi/tokens\" \"$CONOHA_Username\" \"$CONOHA_Password\" \"$CONOHA_TenantId\")\"; then accesstoken=\"$(printf \"%s\" \"$token\" | sed -n 1p)\" CONOHA_Api=\"$(printf \"%s\" \"$token\" | sed -n 2p)\" else return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\" \"$CONOHA_Api\" \"$accesstoken\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" body=\"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$fulldomain.\\\",\\\"data\\\":\\\"$txtvalue\\\",\\\"ttl\\\":60}\" if _conoha_rest POST \"$CONOHA_Api/v1/domains/$_domain_id/records\" \"$body\" \"$accesstoken\"; then if _contains \"$response\" '\"data\":\"'\"$txtvalue\"'\"'; then _info \"Added, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_conoha_rm() { fulldomain=$1 txtvalue=$2 _info \"Using conoha\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug \"Check uesrname and password\" CONOHA_Username=\"${CONOHA_Username:-$(_readaccountconf_mutable CONOHA_Username)}\" CONOHA_Password=\"${CONOHA_Password:-$(_readaccountconf_mutable CONOHA_Password)}\" CONOHA_TenantId=\"${CONOHA_TenantId:-$(_readaccountconf_mutable CONOHA_TenantId)}\" CONOHA_IdentityServiceApi=\"${CONOHA_IdentityServiceApi:-$(_readaccountconf_mutable CONOHA_IdentityServiceApi)}\" if [ -z \"$CONOHA_Username\" ] || [ -z \"$CONOHA_Password\" ] || [ -z \"$CONOHA_TenantId\" ] || [ -z \"$CONOHA_IdentityServiceApi\" ]; then CONOHA_Username=\"\" CONOHA_Password=\"\" CONOHA_TenantId=\"\" CONOHA_IdentityServiceApi=\"\" _err \"You didn't specify a conoha api username and password yet.\" _err \"Please create the user and try again.\" return 1 fi _saveaccountconf_mutable CONOHA_Username \"$CONOHA_Username\" _saveaccountconf_mutable CONOHA_Password \"$CONOHA_Password\" _saveaccountconf_mutable CONOHA_TenantId \"$CONOHA_TenantId\" _saveaccountconf_mutable CONOHA_IdentityServiceApi \"$CONOHA_IdentityServiceApi\" if token=\"$(_conoha_get_accesstoken \"$CONOHA_IdentityServiceApi/tokens\" \"$CONOHA_Username\" \"$CONOHA_Password\" \"$CONOHA_TenantId\")\"; then accesstoken=\"$(printf \"%s\" \"$token\" | sed -n 1p)\" CONOHA_Api=\"$(printf \"%s\" \"$token\" | sed -n 2p)\" else return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\" \"$CONOHA_Api\" \"$accesstoken\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" if ! _conoha_rest GET \"$CONOHA_Api/v1/domains/$_domain_id/records\" \"\" \"$accesstoken\"; then _err \"Error\" return 1 fi record_id=$(printf \"%s\" \"$response\" | _egrep_o '{[^}]*}' | grep '\"type\":\"TXT\"' | grep \"\\\"data\\\":\\\"$txtvalue\\\"\" | _egrep_o \"\\\"id\\\":\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi _debug record_id \"$record_id\" _info \"Removing the txt record\" if ! _conoha_rest DELETE \"$CONOHA_Api/v1/domains/$_domain_id/records/$record_id\" \"\" \"$accesstoken\"; then _err \"Delete record error.\" return 1 fi return 0 } #################### Private functions below ################################## _conoha_rest() { m=\"$1\" ep=\"$2\" data=\"$3\" accesstoken=\"$4\" export _H1=\"Accept: application/json\" export _H2=\"Content-Type: application/json\" if [ -n \"$accesstoken\" ]; then export _H3=\"X-Auth-Token: $accesstoken\" fi _debug \"$ep\" if [ \"$m\" != \"GET\" ]; then _secure_debug2 data \"$data\" response=\"$(_post \"$data\" \"$ep\" \"\" \"$m\")\" else response=\"$(_get \"$ep\")\" fi _ret=\"$?\" _secure_debug2 response \"$response\" if [ \"$_ret\" != \"0\" ]; then _err \"error $ep\" return 1 fi response=\"$(printf \"%s\" \"$response\" | _normalizeJson)\" return 0 } _conoha_get_accesstoken() { ep=\"$1\" username=\"$2\" password=\"$3\" tenantId=\"$4\" accesstoken=\"$(_readaccountconf_mutable conoha_accesstoken)\" expires=\"$(_readaccountconf_mutable conoha_tokenvalidto)\" CONOHA_Api=\"$(_readaccountconf_mutable conoha_dns_ep)\" # can we reuse the access token? if [ -n \"$accesstoken\" ] && [ -n \"$expires\" ] && [ -n \"$CONOHA_Api\" ]; then utc_date=\"$(_utc_date | sed \"s/ /T/\")\" if expr \"$utc_date\" \"<\" \"$expires\" >/dev/null; then # access token is still valid - reuse it _debug \"reusing access token\" printf \"%s\\n%s\\n\" \"$accesstoken\" \"$CONOHA_Api\" return 0 else _debug \"access token expired\" fi fi _debug \"getting new access token\" body=\"$(printf '{\"auth\":{\"passwordCredentials\":{\"username\":\"%s\",\"password\":\"%s\"},\"tenantId\":\"%s\"}}' \"$username\" \"$password\" \"$tenantId\")\" if ! _conoha_rest POST \"$ep\" \"$body\" \"\"; then _err error \"$response\" return 1 fi accesstoken=$(printf \"%s\" \"$response\" | _egrep_o \"\\\"id\\\":\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") expires=$(printf \"%s\" \"$response\" | _egrep_o \"\\\"expires\\\":\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2-4 | tr -d \\\" | tr -d Z) #expect UTC if [ -z \"$accesstoken\" ] || [ -z \"$expires\" ]; then _err \"no acccess token received. Check your Conoha settings see $WIKI\" return 1 fi _saveaccountconf_mutable conoha_accesstoken \"$accesstoken\" _saveaccountconf_mutable conoha_tokenvalidto \"$expires\" CONOHA_Api=$(printf \"%s\" \"$response\" | _egrep_o 'publicURL\":\"'\"$CONOHA_DNS_EP_PREFIX_REGEXP\"'[^\"]*\"' | _head_n 1 | cut -d : -f 2-3 | tr -d \\\") if [ -z \"$CONOHA_Api\" ]; then _err \"failed to get conoha dns endpoint url\" return 1 fi _saveaccountconf_mutable conoha_dns_ep \"$CONOHA_Api\" printf \"%s\\n%s\\n\" \"$accesstoken\" \"$CONOHA_Api\" return 0 } #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=\"$1\" ep=\"$2\" accesstoken=\"$3\" i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100). _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _conoha_rest GET \"$ep/v1/domains?name=$h\" \"\" \"$accesstoken\"; then return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" >/dev/null; then _domain_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":\\\"[^\\\"]*\\\"\" | head -n 1 | cut -d : -f 2 | tr -d \\\") if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 }"
        },
        {
            "filename": "file_175.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_175.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_constellix_info='Constellix.com Site: Constellix.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_constellix Options: CONSTELLIX_Key API Key CONSTELLIX_Secret API Secret Issues: github.com/acmesh-official/acme.sh/issues/2724 Author: Wout Decre <wout@canodus.be> ' CONSTELLIX_Api=\"https://api.dns.constellix.com/v1\" ######## Public functions ##################### # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record dns_constellix_add() { fulldomain=$1 txtvalue=$2 CONSTELLIX_Key=\"${CONSTELLIX_Key:-$(_readaccountconf_mutable CONSTELLIX_Key)}\" CONSTELLIX_Secret=\"${CONSTELLIX_Secret:-$(_readaccountconf_mutable CONSTELLIX_Secret)}\" if [ -z \"$CONSTELLIX_Key\" ] || [ -z \"$CONSTELLIX_Secret\" ]; then _err \"You did not specify the Contellix API key and secret yet.\" return 1 fi _saveaccountconf_mutable CONSTELLIX_Key \"$CONSTELLIX_Key\" _saveaccountconf_mutable CONSTELLIX_Secret \"$CONSTELLIX_Secret\" if ! _get_root \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi # The TXT record might already exist when working with wildcard certificates. In that case, update the record by adding the new value. _debug \"Search TXT record\" if _constellix_rest GET \"domains/${_domain_id}/records/TXT/search?exact=${_sub_domain}\"; then if printf -- \"%s\" \"$response\" | grep \"{\\\"errors\\\":\\[\\\"Requested record was not found\\\"\\]}\" >/dev/null; then _info \"Adding TXT record\" if _constellix_rest POST \"domains/${_domain_id}/records\" \"[{\\\"type\\\":\\\"txt\\\",\\\"add\\\":true,\\\"set\\\":{\\\"name\\\":\\\"${_sub_domain}\\\",\\\"ttl\\\":60,\\\"roundRobin\\\":[{\\\"value\\\":\\\"${txtvalue}\\\"}]}}]\"; then if printf -- \"%s\" \"$response\" | grep \"{\\\"success\\\":\\\"1 record(s) added, 0 record(s) updated, 0 record(s) deleted\\\"}\" >/dev/null; then _info \"Added\" return 0 else _err \"Error adding TXT record\" fi fi else _record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":[0-9]*\" | cut -d ':' -f 2) if _constellix_rest GET \"domains/${_domain_id}/records/TXT/${_record_id}\"; then _new_rr_values=$(printf \"%s\\n\" \"$response\" | _egrep_o '\"roundRobin\":\\[[^]]*\\]' | sed \"s/\\]$/,{\\\"value\\\":\\\"${txtvalue}\\\"}]/\") _debug _new_rr_values \"$_new_rr_values\" _info \"Updating TXT record\" if _constellix_rest PUT \"domains/${_domain_id}/records/TXT/${_record_id}\" \"{\\\"name\\\":\\\"${_sub_domain}\\\",\\\"ttl\\\":60,${_new_rr_values}}\"; then if printf -- \"%s\" \"$response\" | grep \"{\\\"success\\\":\\\"Record.*updated successfully\\\"}\" >/dev/null; then _info \"Updated\" return 0 elif printf -- \"%s\" \"$response\" | grep \"{\\\"errors\\\":\\[\\\"Contents are identical\\\"\\]}\" >/dev/null; then _info \"Already exists, no need to update\" return 0 else _err \"Error updating TXT record\" fi fi fi fi fi return 1 } # Usage: fulldomain txtvalue # Used to remove the txt record after validation dns_constellix_rm() { fulldomain=$1 txtvalue=$2 CONSTELLIX_Key=\"${CONSTELLIX_Key:-$(_readaccountconf_mutable CONSTELLIX_Key)}\" CONSTELLIX_Secret=\"${CONSTELLIX_Secret:-$(_readaccountconf_mutable CONSTELLIX_Secret)}\" if [ -z \"$CONSTELLIX_Key\" ] || [ -z \"$CONSTELLIX_Secret\" ]; then _err \"You did not specify the Contellix API key and secret yet.\" return 1 fi if ! _get_root \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi # The TXT record might have been removed already when working with some wildcard certificates. _debug \"Search TXT record\" if _constellix_rest GET \"domains/${_domain_id}/records/TXT/search?exact=${_sub_domain}\"; then if printf -- \"%s\" \"$response\" | grep \"{\\\"errors\\\":\\[\\\"Requested record was not found\\\"\\]}\" >/dev/null; then _info \"Removed\" return 0 else _info \"Removing TXT record\" if _constellix_rest POST \"domains/${_domain_id}/records\" \"[{\\\"type\\\":\\\"txt\\\",\\\"delete\\\":true,\\\"filter\\\":{\\\"field\\\":\\\"name\\\",\\\"op\\\":\\\"eq\\\",\\\"value\\\":\\\"${_sub_domain}\\\"}}]\"; then if printf -- \"%s\" \"$response\" | grep \"{\\\"success\\\":\\\"0 record(s) added, 0 record(s) updated, 1 record(s) deleted\\\"}\" >/dev/null; then _info \"Removed\" return 0 else _err \"Error removing TXT record\" fi fi fi fi return 1 } #################### Private functions below ################################## _get_root() { domain=$1 i=2 p=1 _debug \"Detecting root zone\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then return 1 fi if ! _constellix_rest GET \"domains/search?exact=$h\"; then return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\"; then _domain_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":[0-9]*\" | cut -d ':' -f 2) if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d '.' -f 1-$p) _domain=\"$h\" _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _constellix_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" rdate=$(date +\"%s\")\"000\" hmac=$(printf \"%s\" \"$rdate\" | _hmac sha1 \"$(printf \"%s\" \"$CONSTELLIX_Secret\" | _hex_dump | tr -d ' ')\" | _base64) export _H1=\"x-cnsdns-apiKey: $CONSTELLIX_Key\" export _H2=\"x-cnsdns-requestDate: $rdate\" export _H3=\"x-cnsdns-hmac: $hmac\" export _H4=\"Accept: application/json\" export _H5=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$CONSTELLIX_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$CONSTELLIX_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"Error $ep\" return 1 fi _debug response \"$response\" return 0 }"
        },
        {
            "filename": "file_176.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_176.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_cpanel_info='cPanel Server API Manage DNS via cPanel Dashboard. Site: cPanel.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_cpanel Options: cPanel_Username Username cPanel_Apitoken API Token cPanel_Hostname Server URL. E.g. \"https://hostname:port\" Issues: github.com/acmesh-official/acme.sh/issues/3732 Author: Bjarne Saltbaek ' ######## Public functions ##################### # Used to add txt record dns_cpanel_add() { fulldomain=$1 txtvalue=$2 _info \"Adding TXT record to cPanel based system\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug cPanel_Username \"$cPanel_Username\" _debug cPanel_Apitoken \"$cPanel_Apitoken\" _debug cPanel_Hostname \"$cPanel_Hostname\" if ! _cpanel_login; then _err \"cPanel Login failed for user $cPanel_Username. Check $HTTP_HEADER file\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"No matching root domain for $fulldomain found\" return 1 fi # adding entry _info \"Adding the entry\" stripped_fulldomain=$(echo \"$fulldomain\" | sed \"s/.$_domain//\") _debug \"Adding $stripped_fulldomain to $_domain zone\" _myget \"json-api/cpanel?cpanel_jsonapi_apiversion=2&cpanel_jsonapi_module=ZoneEdit&cpanel_jsonapi_func=add_zone_record&domain=$_domain&name=$stripped_fulldomain&type=TXT&txtdata=$txtvalue&ttl=1\" if _successful_update; then return 0; fi _err \"Couldn't create entry!\" return 1 } # Usage: fulldomain txtvalue # Used to remove the txt record after validation dns_cpanel_rm() { fulldomain=$1 txtvalue=$2 _info \"Using cPanel based system\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" if ! _cpanel_login; then _err \"cPanel Login failed for user $cPanel_Username. Check $HTTP_HEADER file\" return 1 fi if ! _get_root; then _err \"No matching root domain for $fulldomain found\" return 1 fi _findentry \"$fulldomain\" \"$txtvalue\" if [ -z \"$_id\" ]; then _info \"Entry doesn't exist, nothing to delete\" return 0 fi _debug \"Deleting record...\" _myget \"json-api/cpanel?cpanel_jsonapi_apiversion=2&cpanel_jsonapi_module=ZoneEdit&cpanel_jsonapi_func=remove_zone_record&domain=$_domain&line=$_id\" # removing entry _debug \"_result is: $_result\" if _successful_update; then return 0; fi _err \"Couldn't delete entry!\" return 1 } #################### Private functions below ################################## _checkcredentials() { cPanel_Username=\"${cPanel_Username:-$(_readaccountconf_mutable cPanel_Username)}\" cPanel_Apitoken=\"${cPanel_Apitoken:-$(_readaccountconf_mutable cPanel_Apitoken)}\" cPanel_Hostname=\"${cPanel_Hostname:-$(_readaccountconf_mutable cPanel_Hostname)}\" if [ -z \"$cPanel_Username\" ] || [ -z \"$cPanel_Apitoken\" ] || [ -z \"$cPanel_Hostname\" ]; then cPanel_Username=\"\" cPanel_Apitoken=\"\" cPanel_Hostname=\"\" _err \"You haven't specified cPanel username, apitoken and hostname yet.\" _err \"Please add credentials and try again.\" return 1 fi #save the credentials to the account conf file. _saveaccountconf_mutable cPanel_Username \"$cPanel_Username\" _saveaccountconf_mutable cPanel_Apitoken \"$cPanel_Apitoken\" _saveaccountconf_mutable cPanel_Hostname \"$cPanel_Hostname\" return 0 } _cpanel_login() { if ! _checkcredentials; then return 1; fi if ! _myget \"json-api/cpanel?cpanel_jsonapi_apiversion=2&cpanel_jsonapi_module=CustInfo&cpanel_jsonapi_func=displaycontactinfo\"; then _err \"cPanel login failed for user $cPanel_Username.\" return 1 fi return 0 } _myget() { #Adds auth header to request export _H1=\"Authorization: cpanel $cPanel_Username:$cPanel_Apitoken\" _result=$(_get \"$cPanel_Hostname/$1\") } _get_root() { _myget 'json-api/cpanel?cpanel_jsonapi_apiversion=2&cpanel_jsonapi_module=ZoneEdit&cpanel_jsonapi_func=fetchzones' _domains=$(echo \"$_result\" | _egrep_o '\"[a-z0-9\\.\\-]*\":\\[\"; cPanel first' | cut -d':' -f1 | sed 's/\"//g' | sed 's/{//g') _debug \"_result is: $_result\" _debug \"_domains is: $_domains\" if [ -z \"$_domains\" ]; then _err \"Primary domain list not found!\" return 1 fi for _domain in $_domains; do _debug \"Checking if $fulldomain ends with $_domain\" if (_endswith \"$fulldomain\" \"$_domain\"); then _debug \"Root domain: $_domain\" return 0 fi done return 1 } _successful_update() { if (echo \"$_result\" | _egrep_o 'data\":\\[[^]]*]' | grep -q '\"newserial\":null'); then return 1; fi return 0 } _findentry() { _debug \"In _findentry\" #returns id of dns entry, if it exists _myget \"json-api/cpanel?cpanel_jsonapi_apiversion=2&cpanel_jsonapi_module=ZoneEdit&cpanel_jsonapi_func=fetchzone_records&domain=$_domain\" _id=$(echo \"$_result\" | sed -e \"s/},{/},\\n{/g\" | grep \"$fulldomain\" | grep \"$txtvalue\" | _egrep_o 'line\":[0-9]+' | cut -d ':' -f 2) _debug \"_result is: $_result\" _debug \"fulldomain. is $fulldomain.\" _debug \"txtvalue is $txtvalue\" _debug \"_id is: $_id\" if [ -n \"$_id\" ]; then _debug \"Entry found with _id=$_id\" return 0 fi return 1 }"
        },
        {
            "filename": "file_177.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_177.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_curanet_info='Curanet.dk Domains: scannet.dk wannafind.dk dandomain.dk Site: Curanet.dk Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_curanet Options: CURANET_AUTHCLIENTID Auth ClientID. Requires scope dns CURANET_AUTHSECRET Auth Secret Issues: github.com/acmesh-official/acme.sh/issues/3933 Author: Peter L. Hansen <peter@r12.dk> ' CURANET_REST_URL=\"https://api.curanet.dk/dns/v1/Domains\" CURANET_AUTH_URL=\"https://apiauth.dk.team.blue/auth/realms/Curanet/protocol/openid-connect/token\" CURANET_ACCESS_TOKEN=\"\" ######## Public functions ##################### #Usage: dns_curanet_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_curanet_add() { fulldomain=$1 txtvalue=$2 _info \"Using curanet\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" CURANET_AUTHCLIENTID=\"${CURANET_AUTHCLIENTID:-$(_readaccountconf_mutable CURANET_AUTHCLIENTID)}\" CURANET_AUTHSECRET=\"${CURANET_AUTHSECRET:-$(_readaccountconf_mutable CURANET_AUTHSECRET)}\" if [ -z \"$CURANET_AUTHCLIENTID\" ] || [ -z \"$CURANET_AUTHSECRET\" ]; then CURANET_AUTHCLIENTID=\"\" CURANET_AUTHSECRET=\"\" _err \"You don't specify curanet api client and secret.\" _err \"Please create your auth info and try again.\" return 1 fi #save the credentials to the account conf file. _saveaccountconf_mutable CURANET_AUTHCLIENTID \"$CURANET_AUTHCLIENTID\" _saveaccountconf_mutable CURANET_AUTHSECRET \"$CURANET_AUTHSECRET\" if ! _get_token; then _err \"Unable to get token\" return 1 fi if ! _get_root \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi export _H1=\"Content-Type: application/json-patch+json\" export _H2=\"Accept: application/json\" export _H3=\"Authorization: Bearer $CURANET_ACCESS_TOKEN\" data=\"{\\\"name\\\": \\\"$fulldomain\\\",\\\"type\\\": \\\"TXT\\\",\\\"ttl\\\": 60,\\\"priority\\\": 0,\\\"data\\\": \\\"$txtvalue\\\"}\" response=\"$(_post \"$data\" \"$CURANET_REST_URL/${_domain}/Records\" \"\" \"\")\" if _contains \"$response\" \"$txtvalue\"; then _debug \"TXT record added OK\" else _err \"Unable to add TXT record\" return 1 fi return 0 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_curanet_rm() { fulldomain=$1 txtvalue=$2 _info \"Using curanet\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" CURANET_AUTHCLIENTID=\"${CURANET_AUTHCLIENTID:-$(_readaccountconf_mutable CURANET_AUTHCLIENTID)}\" CURANET_AUTHSECRET=\"${CURANET_AUTHSECRET:-$(_readaccountconf_mutable CURANET_AUTHSECRET)}\" if ! _get_token; then _err \"Unable to get token\" return 1 fi if ! _get_root \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi _debug \"Getting current record list to identify TXT to delete\" export _H1=\"Content-Type: application/json\" export _H2=\"Accept: application/json\" export _H3=\"Authorization: Bearer $CURANET_ACCESS_TOKEN\" response=\"$(_get \"$CURANET_REST_URL/${_domain}/Records\" \"\" \"\")\" if ! _contains \"$response\" \"$txtvalue\"; then _err \"Unable to delete record (does not contain $txtvalue )\" return 1 fi recordid=$(echo \"$response\" | _egrep_o \"{\\\"id\\\":[0-9]+,\\\"name\\\":\\\"$fulldomain\\\",\\\"type\\\":\\\"TXT\\\",\\\"ttl\\\":60,\\\"priority\\\":0,\\\"data\\\":\\\"..$txtvalue\" | _egrep_o \"id\\\":[0-9]+\" | cut -c 5-) if [ -z \"$recordid\" ]; then _err \"Unable to get recordid\" _debug \"regex {\\\"id\\\":[0-9]+,\\\"name\\\":\\\"$fulldomain\\\",\\\"type\\\":\\\"TXT\\\",\\\"ttl\\\":60,\\\"priority\\\":0,\\\"data\\\":\\\"..$txtvalue\" _debug \"response $response\" return 1 fi _debug \"Deleting recordID $recordid\" response=\"$(_post \"\" \"$CURANET_REST_URL/${_domain}/Records/$recordid\" \"\" \"DELETE\")\" return 0 } #################### Private functions below ################################## _get_token() { response=\"$(_post \"grant_type=client_credentials&client_id=$CURANET_AUTHCLIENTID&client_secret=$CURANET_AUTHSECRET&scope=dns\" \"$CURANET_AUTH_URL\" \"\" \"\")\" if ! _contains \"$response\" \"access_token\"; then _err \"Unable get access token\" return 1 fi CURANET_ACCESS_TOKEN=$(echo \"$response\" | _egrep_o \"\\\"access_token\\\":\\\"[^\\\"]+\" | cut -c 17-) if [ -z \"$CURANET_ACCESS_TOKEN\" ]; then _err \"Unable to get token\" return 1 fi return 0 } #_acme-challenge.www.domain.com #returns # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi export _H1=\"Content-Type: application/json\" export _H2=\"Accept: application/json\" export _H3=\"Authorization: Bearer $CURANET_ACCESS_TOKEN\" response=\"$(_get \"$CURANET_REST_URL/$h/Records\" \"\" \"\")\" if [ ! \"$(echo \"$response\" | _egrep_o \"Entity not found\")\" ]; then _domain=$h return 0 fi i=$(_math \"$i\" + 1) done return 1 }"
        },
        {
            "filename": "file_178.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_178.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_cyon_info='cyon.ch Site: cyon.ch Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_cyon Options: CY_Username Username CY_Password API Token CY_OTP_Secret OTP token. Only required if using 2FA Issues: github.com/noplanman/cyon-api/issues Author: Armando L\u00fcscher <armando@noplanman.ch> ' dns_cyon_add() { _cyon_load_credentials && _cyon_load_parameters \"$@\" && _cyon_print_header \"add\" && _cyon_login && _cyon_change_domain_env && _cyon_add_txt && _cyon_logout } dns_cyon_rm() { _cyon_load_credentials && _cyon_load_parameters \"$@\" && _cyon_print_header \"delete\" && _cyon_login && _cyon_change_domain_env && _cyon_delete_txt && _cyon_logout } ######################### ### PRIVATE FUNCTIONS ### ######################### _cyon_load_credentials() { # Convert loaded password to/from base64 as needed. if [ \"${CY_Password_B64}\" ]; then CY_Password=\"$(printf \"%s\" \"${CY_Password_B64}\" | _dbase64)\" elif [ \"${CY_Password}\" ]; then CY_Password_B64=\"$(printf \"%s\" \"${CY_Password}\" | _base64)\" fi if [ -z \"${CY_Username}\" ] || [ -z \"${CY_Password}\" ]; then # Dummy entries to satisfy script checker. CY_Username=\"\" CY_Password=\"\" CY_OTP_Secret=\"\" _err \"\" _err \"You haven't set your cyon.ch login credentials yet.\" _err \"Please set the required cyon environment variables.\" _err \"\" return 1 fi # Save the login credentials to the account.conf file. _debug \"Save credentials to account.conf\" _saveaccountconf CY_Username \"${CY_Username}\" _saveaccountconf CY_Password_B64 \"$CY_Password_B64\" if [ -n \"${CY_OTP_Secret}\" ]; then _saveaccountconf CY_OTP_Secret \"$CY_OTP_Secret\" else _clearaccountconf CY_OTP_Secret fi } _cyon_is_idn() { _idn_temp=\"$(printf \"%s\" \"${1}\" | tr -d \"0-9a-zA-Z.,-_\")\" _idn_temp2=\"$(printf \"%s\" \"${1}\" | grep -o \"xn--\")\" [ \"$_idn_temp\" ] || [ \"$_idn_temp2\" ] } _cyon_load_parameters() { # Read the required parameters to add the TXT entry. # shellcheck disable=SC2018,SC2019 fulldomain=\"$(printf \"%s\" \"${1}\" | tr \"A-Z\" \"a-z\")\" fulldomain_idn=\"${fulldomain}\" # Special case for IDNs, as cyon needs a domain environment change, # which uses the \"pretty\" instead of the punycode version. if _cyon_is_idn \"${fulldomain}\"; then if ! _exists idn; then _err \"Please install idn to process IDN names.\" _err \"\" return 1 fi fulldomain=\"$(idn -u \"${fulldomain}\")\" fulldomain_idn=\"$(idn -a \"${fulldomain}\")\" fi _debug fulldomain \"${fulldomain}\" _debug fulldomain_idn \"${fulldomain_idn}\" txtvalue=\"${2}\" _debug txtvalue \"${txtvalue}\" # This header is required for curl calls. _H1=\"X-Requested-With: XMLHttpRequest\" export _H1 } _cyon_print_header() { if [ \"${1}\" = \"add\" ]; then _info \"\" _info \"+---------------------------------------------+\" _info \"| Adding DNS TXT entry to your cyon.ch domain |\" _info \"+---------------------------------------------+\" _info \"\" _info \" * Full Domain: ${fulldomain}\" _info \" * TXT Value: ${txtvalue}\" _info \"\" elif [ \"${1}\" = \"delete\" ]; then _info \"\" _info \"+-------------------------------------------------+\" _info \"| Deleting DNS TXT entry from your cyon.ch domain |\" _info \"+-------------------------------------------------+\" _info \"\" _info \" * Full Domain: ${fulldomain}\" _info \"\" fi } _cyon_get_cookie_header() { printf \"Cookie: %s\" \"$(grep \"cyon=\" \"$HTTP_HEADER\" | grep \"^Set-Cookie:\" | _tail_n 1 | _egrep_o 'cyon=[^;]*;' | tr -d ';')\" } _cyon_login() { _info \" - Logging in...\" username_encoded=\"$(printf \"%s\" \"${CY_Username}\" | _url_encode)\" password_encoded=\"$(printf \"%s\" \"${CY_Password}\" | _url_encode)\" login_url=\"https://my.cyon.ch/auth/index/dologin-async\" login_data=\"$(printf \"%s\" \"username=${username_encoded}&password=${password_encoded}&pathname=%2F\")\" login_response=\"$(_post \"$login_data\" \"$login_url\")\" _debug login_response \"${login_response}\" # Bail if login fails. if [ \"$(printf \"%s\" \"${login_response}\" | _cyon_get_response_success)\" != \"success\" ]; then _err \" $(printf \"%s\" \"${login_response}\" | _cyon_get_response_message)\" _err \"\" return 1 fi _info \" success\" # NECESSARY!! Load the main page after login, to get the new cookie. _H2=\"$(_cyon_get_cookie_header)\" export _H2 _get \"https://my.cyon.ch/\" >/dev/null # todo: instead of just checking if the env variable is defined, check if we actually need to do a 2FA auth request. # 2FA authentication with OTP? if [ -n \"${CY_OTP_Secret}\" ]; then _info \" - Authorising with OTP code...\" if ! _exists oathtool; then _err \"Please install oathtool to use 2 Factor Authentication.\" _err \"\" return 1 fi # Get OTP code with the defined secret. otp_code=\"$(oathtool --base32 --totp \"${CY_OTP_Secret}\" 2>/dev/null)\" login_otp_url=\"https://my.cyon.ch/auth/multi-factor/domultifactorauth-async\" login_otp_data=\"totpcode=${otp_code}&pathname=%2F&rememberme=0\" login_otp_response=\"$(_post \"$login_otp_data\" \"$login_otp_url\")\" _debug login_otp_response \"${login_otp_response}\" # Bail if OTP authentication fails. if [ \"$(printf \"%s\" \"${login_otp_response}\" | _cyon_get_response_success)\" != \"success\" ]; then _err \" $(printf \"%s\" \"${login_otp_response}\" | _cyon_get_response_message)\" _err \"\" return 1 fi _info \" success\" fi _info \"\" } _cyon_logout() { _info \" - Logging out...\" _get \"https://my.cyon.ch/auth/index/dologout\" >/dev/null _info \" success\" _info \"\" } _cyon_change_domain_env() { _info \" - Changing domain environment...\" # Get the \"example.com\" part of the full domain name. domain_env=\"$(printf \"%s\" \"${fulldomain}\" | sed -E -e 's/.*\\.(.*\\..*)$/\\1/')\" _debug \"Changing domain environment to ${domain_env}\" gloo_item_key=\"$(_get \"https://my.cyon.ch/domain/\" | tr '\\n' ' ' | sed -E -e \"s/.*data-domain=\\\"${domain_env}\\\"[^<]*data-itemkey=\\\"([^\\\"]*).*/\\1/\")\" _debug gloo_item_key \"${gloo_item_key}\" domain_env_url=\"https://my.cyon.ch/user/environment/setdomain/d/${domain_env}/gik/${gloo_item_key}\" domain_env_response=\"$(_get \"${domain_env_url}\")\" _debug domain_env_response \"${domain_env_response}\" if ! _cyon_check_if_2fa_missed \"${domain_env_response}\"; then return 1; fi domain_env_success=\"$(printf \"%s\" \"${domain_env_response}\" | _egrep_o '\"authenticated\":\\w*' | cut -d : -f 2)\" # Bail if domain environment change fails. if [ \"${domain_env_success}\" != \"true\" ]; then _err \" $(printf \"%s\" \"${domain_env_response}\" | _cyon_get_response_message)\" _err \"\" return 1 fi _info \" success\" _info \"\" } _cyon_add_txt() { _info \" - Adding DNS TXT entry...\" add_txt_url=\"https://my.cyon.ch/domain/dnseditor/add-record-async\" add_txt_data=\"zone=${fulldomain_idn}.&ttl=900&type=TXT&value=${txtvalue}\" add_txt_response=\"$(_post \"$add_txt_data\" \"$add_txt_url\")\" _debug add_txt_response \"${add_txt_response}\" if ! _cyon_check_if_2fa_missed \"${add_txt_response}\"; then return 1; fi add_txt_message=\"$(printf \"%s\" \"${add_txt_response}\" | _cyon_get_response_message)\" add_txt_status=\"$(printf \"%s\" \"${add_txt_response}\" | _cyon_get_response_status)\" # Bail if adding TXT entry fails. if [ \"${add_txt_status}\" != \"true\" ]; then _err \" ${add_txt_message}\" _err \"\" return 1 fi _info \" success (TXT|${fulldomain_idn}.|${txtvalue})\" _info \"\" } _cyon_delete_txt() { _info \" - Deleting DNS TXT entry...\" list_txt_url=\"https://my.cyon.ch/domain/dnseditor/list-async\" list_txt_response=\"$(_get \"${list_txt_url}\" | sed -e 's/data-hash/\\\\ndata-hash/g')\" _debug list_txt_response \"${list_txt_response}\" if ! _cyon_check_if_2fa_missed \"${list_txt_response}\"; then return 1; fi # Find and delete all acme challenge entries for the $fulldomain. _dns_entries=\"$(printf \"%b\\n\" \"${list_txt_response}\" | sed -n 's/data-hash=\\\\\"\\([^\"]*\\)\\\\\" data-identifier=\\\\\"\\([^\"]*\\)\\\\\".*/\\1 \\2/p')\" printf \"%s\" \"${_dns_entries}\" | while read -r _hash _identifier; do dns_type=\"$(printf \"%s\" \"$_identifier\" | cut -d'|' -f1)\" dns_domain=\"$(printf \"%s\" \"$_identifier\" | cut -d'|' -f2)\" if [ \"${dns_type}\" != \"TXT\" ] || [ \"${dns_domain}\" != \"${fulldomain_idn}.\" ]; then continue fi hash_encoded=\"$(printf \"%s\" \"${_hash}\" | _url_encode)\" identifier_encoded=\"$(printf \"%s\" \"${_identifier}\" | _url_encode)\" delete_txt_url=\"https://my.cyon.ch/domain/dnseditor/delete-record-async\" delete_txt_data=\"$(printf \"%s\" \"hash=${hash_encoded}&identifier=${identifier_encoded}\")\" delete_txt_response=\"$(_post \"$delete_txt_data\" \"$delete_txt_url\")\" _debug delete_txt_response \"${delete_txt_response}\" if ! _cyon_check_if_2fa_missed \"${delete_txt_response}\"; then return 1; fi delete_txt_message=\"$(printf \"%s\" \"${delete_txt_response}\" | _cyon_get_response_message)\" delete_txt_status=\"$(printf \"%s\" \"${delete_txt_response}\" | _cyon_get_response_status)\" # Skip if deleting TXT entry fails. if [ \"${delete_txt_status}\" != \"true\" ]; then _err \" ${delete_txt_message} (${_identifier})\" else _info \" success (${_identifier})\" fi done _info \" done\" _info \"\" } _cyon_get_response_message() { _egrep_o '\"message\":\"[^\"]*\"' | cut -d : -f 2 | tr -d '\"' } _cyon_get_response_status() { _egrep_o '\"status\":\\w*' | cut -d : -f 2 } _cyon_get_response_success() { _egrep_o '\"onSuccess\":\"[^\"]*\"' | cut -d : -f 2 | tr -d '\"' } _cyon_check_if_2fa_missed() { # Did we miss the 2FA? if test \"${1#*multi_factor_form}\" != \"${1}\"; then _err \" Missed OTP authentication!\" _err \"\" return 1 fi }"
        },
        {
            "filename": "file_179.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_179.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_da_info='DirectAdmin Server API Site: DirectAdmin.com/api.php Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_da Options: DA_Api API Server URL. E.g. \"https://remoteUser:remotePassword@da.domain.tld:8443\" DA_Api_Insecure Insecure TLS. 0: check for cert validity, 1: always accept Issues: github.com/TigerP/acme.sh/issues ' ######## Public functions ##################### # Usage: dns_myapi_add _acme-challenge.www.example.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record dns_da_add() { fulldomain=\"${1}\" txtvalue=\"${2}\" _debug \"Calling: dns_da_add() '${fulldomain}' '${txtvalue}'\" _DA_credentials && _DA_getDomainInfo && _DA_addTxt } # Usage: dns_da_rm _acme-challenge.www.example.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to remove the txt record after validation dns_da_rm() { fulldomain=\"${1}\" txtvalue=\"${2}\" _debug \"Calling: dns_da_rm() '${fulldomain}' '${txtvalue}'\" _DA_credentials && _DA_getDomainInfo && _DA_rmTxt } #################### Private functions below ################################## # Usage: _DA_credentials # It will check if the needed settings are available _DA_credentials() { DA_Api=\"${DA_Api:-$(_readaccountconf_mutable DA_Api)}\" DA_Api_Insecure=\"${DA_Api_Insecure:-$(_readaccountconf_mutable DA_Api_Insecure)}\" if [ -z \"${DA_Api}\" ] || [ -z \"${DA_Api_Insecure}\" ]; then DA_Api=\"\" DA_Api_Insecure=\"\" _err \"You haven't specified the DirectAdmin Login data, URL and whether you want check the DirectAdmin SSL cert. Please try again.\" return 1 else _saveaccountconf_mutable DA_Api \"${DA_Api}\" _saveaccountconf_mutable DA_Api_Insecure \"${DA_Api_Insecure}\" # Set whether curl should use secure or insecure mode export HTTPS_INSECURE=\"${DA_Api_Insecure}\" fi } # Usage: _get_root _acme-challenge.www.example.com # Split the full domain to a domain and subdomain #returns # _sub_domain=_acme-challenge.www # _domain=example.com _get_root() { domain=$1 i=2 p=1 # Get a list of all the domains # response will contain \"list[]=example.com&list[]=example.org\" _da_api CMD_API_SHOW_DOMAINS \"\" \"${domain}\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then # not valid _debug \"The given domain $h is not valid\" return 1 fi if _contains \"$response\" \"$h\" >/dev/null; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi p=$i i=$(_math \"$i\" + 1) done _debug \"Stop on 100\" return 1 } # Usage: _da_api CMD_API_* data example.com # Use the DirectAdmin API and check the result # returns # response=\"error=0&text=Result text&details=\" _da_api() { cmd=$1 data=$2 domain=$3 _debug \"$domain; $data\" response=\"$(_post \"$data\" \"$DA_Api/$cmd\" \"\" \"POST\")\" if [ \"$?\" != \"0\" ]; then _err \"error $cmd\" return 1 fi _debug response \"$response\" case \"${cmd}\" in CMD_API_DNS_CONTROL) # Parse the result in general # error=0&text=Records Deleted&details= # error=1&text=Cannot View Dns Record&details=No domain provided err_field=\"$(_getfield \"$response\" 1 '&')\" txt_field=\"$(_getfield \"$response\" 2 '&')\" details_field=\"$(_getfield \"$response\" 3 '&')\" error=\"$(_getfield \"$err_field\" 2 '=')\" text=\"$(_getfield \"$txt_field\" 2 '=')\" details=\"$(_getfield \"$details_field\" 2 '=')\" _debug \"error: ${error}, text: ${text}, details: ${details}\" if [ \"$error\" != \"0\" ]; then _err \"error $response\" return 1 fi ;; CMD_API_SHOW_DOMAINS) ;; esac return 0 } # Usage: _DA_getDomainInfo # Get the root zone if possible _DA_getDomainInfo() { _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 else _debug \"The root domain: $_domain\" _debug \"The sub domain: $_sub_domain\" fi return 0 } # Usage: _DA_addTxt # Use the API to add a record _DA_addTxt() { curData=\"domain=${_domain}&action=add&type=TXT&name=${_sub_domain}&value=\\\"${txtvalue}\\\"\" _debug \"Calling _DA_addTxt: '${curData}' '${DA_Api}/CMD_API_DNS_CONTROL'\" _da_api CMD_API_DNS_CONTROL \"${curData}\" \"${_domain}\" _debug \"Result of _DA_addTxt: '$response'\" if _contains \"${response}\" 'error=0'; then _debug \"Add TXT succeeded\" return 0 fi _debug \"Add TXT failed\" return 1 } # Usage: _DA_rmTxt # Use the API to remove a record _DA_rmTxt() { curData=\"domain=${_domain}&action=select&txtrecs0=name=${_sub_domain}&amp;value=\\\"${txtvalue}\\\"\" _debug \"Calling _DA_rmTxt: '${curData}' '${DA_Api}/CMD_API_DNS_CONTROL'\" if _da_api CMD_API_DNS_CONTROL \"${curData}\" \"${_domain}\"; then _debug \"Result of _DA_rmTxt: '$response'\" else _err \"Result of _DA_rmTxt: '$response'\" fi if _contains \"${response}\" 'error=0'; then _debug \"RM TXT succeeded\" return 0 fi _debug \"RM TXT failed\" return 1 }"
        },
        {
            "filename": "file_180.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_180.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_ddnss_info='DDNSS.de Site: DDNSS.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_ddnss Options: DDNSS_Token API Token Issues: github.com/acmesh-official/acme.sh/issues/2230 Author: RaidenII, helbgd, mod242 ' DDNSS_DNS_API=\"https://ddnss.de/upd.php\" ######## Public functions ##################### #Usage: dns_ddnss_add _acme-challenge.domain.ddnss.de \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_ddnss_add() { fulldomain=$1 txtvalue=$2 DDNSS_Token=\"${DDNSS_Token:-$(_readaccountconf_mutable DDNSS_Token)}\" if [ -z \"$DDNSS_Token\" ]; then _err \"You must export variable: DDNSS_Token\" _err \"The token for your DDNSS account is necessary.\" _err \"You can look it up in your DDNSS account.\" return 1 fi # Now save the credentials. _saveaccountconf_mutable DDNSS_Token \"$DDNSS_Token\" # Unfortunately, DDNSS does not seems to support lookup domain through API # So I assume your credentials (which are your domain and token) are correct # If something goes wrong, we will get a KO response from DDNSS if ! _ddnss_get_domain; then return 1 fi # Now add the TXT record to DDNSS DNS _info \"Trying to add TXT record\" if _ddnss_rest GET \"key=$DDNSS_Token&host=$_ddnss_domain&txtm=1&txt=$txtvalue\"; then if [ \"$response\" = \"Updated 1 hostname.\" ]; then _info \"TXT record has been successfully added to your DDNSS domain.\" _info \"Note that all subdomains under this domain uses the same TXT record.\" return 0 else _err \"Errors happened during adding the TXT record, response=$response\" return 1 fi else _err \"Errors happened during adding the TXT record.\" return 1 fi } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_ddnss_rm() { fulldomain=$1 txtvalue=$2 DDNSS_Token=\"${DDNSS_Token:-$(_readaccountconf_mutable DDNSS_Token)}\" if [ -z \"$DDNSS_Token\" ]; then _err \"You must export variable: DDNSS_Token\" _err \"The token for your DDNSS account is necessary.\" _err \"You can look it up in your DDNSS account.\" return 1 fi if ! _ddnss_get_domain; then return 1 fi # Now remove the TXT record from DDNS DNS _info \"Trying to remove TXT record\" if _ddnss_rest GET \"key=$DDNSS_Token&host=$_ddnss_domain&txtm=2\"; then if [ \"$response\" = \"Updated 1 hostname.\" ]; then _info \"TXT record has been successfully removed from your DDNSS domain.\" return 0 else _err \"Errors happened during removing the TXT record, response=$response\" return 1 fi else _err \"Errors happened during removing the TXT record.\" return 1 fi } #################### Private functions below ################################## #fulldomain=_acme-challenge.domain.ddnss.de #returns # _ddnss_domain=domain _ddnss_get_domain() { # We'll extract the domain/username from full domain _ddnss_domain=\"$(echo \"$fulldomain\" | _lower_case | _egrep_o '[.][^.][^.]*[.](ddnss|dyn-ip24|dyndns|dyn|dyndns1|home-webserver|myhome-server|dynip)\\..*' | cut -d . -f 2-)\" if [ -z \"$_ddnss_domain\" ]; then _err \"Error extracting the domain.\" return 1 fi return 0 } #Usage: method URI _ddnss_rest() { method=$1 param=\"$2\" _debug param \"$param\" url=\"$DDNSS_DNS_API?$param\" _debug url \"$url\" # DDNSS uses GET to update domain info if [ \"$method\" = \"GET\" ]; then response=\"$(_get \"$url\" | sed 's/<[a-zA-Z\\/][^>]*>//g' | tr -s \"\\n\" | _tail_n 1)\" else _err \"Unsupported method\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_181.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_181.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_desec_info='deSEC.io Site: desec.readthedocs.io/en/latest/ Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_desec Options: DDNSS_Token API Token Issues: github.com/acmesh-official/acme.sh/issues/2180 Author: Zheng Qian ' REST_API=\"https://desec.io/api/v1/domains\" ######## Public functions ##################### #Usage: dns_desec_add _acme-challenge.foobar.dedyn.io \"d41d8cd98f00b204e9800998ecf8427e\" dns_desec_add() { fulldomain=$1 txtvalue=$2 _info \"Using desec.io api\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" DEDYN_TOKEN=\"${DEDYN_TOKEN:-$(_readaccountconf_mutable DEDYN_TOKEN)}\" if [ -z \"$DEDYN_TOKEN\" ]; then DEDYN_TOKEN=\"\" _err \"You did not specify DEDYN_TOKEN yet.\" _err \"Please create your key and try again.\" _err \"e.g.\" _err \"export DEDYN_TOKEN=d41d8cd98f00b204e9800998ecf8427e\" return 1 fi #save the api token to the account conf file. _saveaccountconf_mutable DEDYN_TOKEN \"$DEDYN_TOKEN\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\" \"$REST_API/\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # Get existing TXT record _debug \"Getting txt records\" txtvalues=\"\\\"\\\\\\\"$txtvalue\\\\\\\"\\\"\" _desec_rest GET \"$REST_API/$_domain/rrsets/$_sub_domain/TXT/\" if [ \"$_code\" = \"200\" ]; then oldtxtvalues=\"$(echo \"$response\" | _egrep_o \"\\\"records\\\":\\\\[\\\"\\\\S*\\\"\\\\]\" | cut -d : -f 2 | tr -d \"[]\\\\\\\\\\\"\" | sed \"s/,/ /g\")\" _debug \"existing TXT found\" _debug oldtxtvalues \"$oldtxtvalues\" if [ -n \"$oldtxtvalues\" ]; then for oldtxtvalue in $oldtxtvalues; do txtvalues=\"$txtvalues, \\\"\\\\\\\"$oldtxtvalue\\\\\\\"\\\"\" done fi fi _debug txtvalues \"$txtvalues\" _info \"Adding record\" body=\"[{\\\"subname\\\":\\\"$_sub_domain\\\", \\\"type\\\":\\\"TXT\\\", \\\"records\\\":[$txtvalues], \\\"ttl\\\":3600}]\" if _desec_rest PUT \"$REST_API/$_domain/rrsets/\" \"$body\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"Added, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_desec_rm() { fulldomain=$1 txtvalue=$2 _info \"Using desec.io api\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" DEDYN_TOKEN=\"${DEDYN_TOKEN:-$(_readaccountconf_mutable DEDYN_TOKEN)}\" if [ -z \"$DEDYN_TOKEN\" ]; then DEDYN_TOKEN=\"\" _err \"You did not specify DEDYN_TOKEN yet.\" _err \"Please create your key and try again.\" _err \"e.g.\" _err \"export DEDYN_TOKEN=d41d8cd98f00b204e9800998ecf8427e\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\" \"$REST_API/\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # Get existing TXT record _debug \"Getting txt records\" txtvalues=\"\" _desec_rest GET \"$REST_API/$_domain/rrsets/$_sub_domain/TXT/\" if [ \"$_code\" = \"200\" ]; then oldtxtvalues=\"$(echo \"$response\" | _egrep_o \"\\\"records\\\":\\\\[\\\"\\\\S*\\\"\\\\]\" | cut -d : -f 2 | tr -d \"[]\\\\\\\\\\\"\" | sed \"s/,/ /g\")\" _debug \"existing TXT found\" _debug oldtxtvalues \"$oldtxtvalues\" if [ -n \"$oldtxtvalues\" ]; then for oldtxtvalue in $oldtxtvalues; do if [ \"$txtvalue\" != \"$oldtxtvalue\" ]; then txtvalues=\"$txtvalues, \\\"\\\\\\\"$oldtxtvalue\\\\\\\"\\\"\" fi done fi fi txtvalues=\"$(echo \"$txtvalues\" | cut -c3-)\" _debug txtvalues \"$txtvalues\" _info \"Deleting record\" body=\"[{\\\"subname\\\":\\\"$_sub_domain\\\", \\\"type\\\":\\\"TXT\\\", \\\"records\\\":[$txtvalues], \\\"ttl\\\":3600}]\" _desec_rest PUT \"$REST_API/$_domain/rrsets/\" \"$body\" if [ \"$_code\" = \"200\" ]; then _info \"Deleted, OK\" return 0 fi _err \"Delete txt record error.\" return 1 } #################### Private functions below ################################## _desec_rest() { m=\"$1\" ep=\"$2\" data=\"$3\" export _H1=\"Authorization: Token $DEDYN_TOKEN\" export _H2=\"Accept: application/json\" export _H3=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then _secure_debug2 data \"$data\" response=\"$(_post \"$data\" \"$ep\" \"\" \"$m\")\" else response=\"$(_get \"$ep\")\" fi _ret=\"$?\" _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" _debug \"http response code $_code\" _secure_debug2 response \"$response\" if [ \"$_ret\" != \"0\" ]; then _err \"error $ep\" return 1 fi response=\"$(printf \"%s\" \"$response\" | _normalizeJson)\" return 0 } #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=\"$1\" ep=\"$2\" i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _desec_rest GET \"$ep\"; then return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" >/dev/null; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 }"
        },
        {
            "filename": "file_182.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_182.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_df_info='DynDnsFree.de Domains: dynup.de Site: DynDnsFree.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_df Options: DF_user Username DF_password Password Issues: github.com/acmesh-official/acme.sh/issues/2897 Author: Thilo Gass <thilo.gass@gmail.com> ' dyndnsfree_api=\"https://dynup.de/acme.php\" dns_df_add() { fulldomain=$1 txt_value=$2 _info \"Using DNS-01 dyndnsfree.de hook\" DF_user=\"${DF_user:-$(_readaccountconf_mutable DF_user)}\" DF_password=\"${DF_password:-$(_readaccountconf_mutable DF_password)}\" if [ -z \"$DF_user\" ] || [ -z \"$DF_password\" ]; then DF_user=\"\" DF_password=\"\" _err \"No auth details provided. Please set user credentials using the \\$DF_user and \\$DF_password environment variables.\" return 1 fi #save the api user and password to the account conf file. _debug \"Save user and password\" _saveaccountconf_mutable DF_user \"$DF_user\" _saveaccountconf_mutable DF_password \"$DF_password\" domain=\"$(printf \"%s\" \"$fulldomain\" | cut -d\".\" -f2-)\" get=\"$dyndnsfree_api?username=$DF_user&password=$DF_password&hostname=$domain&add_hostname=$fulldomain&txt=$txt_value\" if ! erg=\"$(_get \"$get\")\"; then _err \"error Adding $fulldomain TXT: $txt_value\" return 1 fi if _contains \"$erg\" \"success\"; then _info \"Success, TXT Added, OK\" else _err \"error Adding $fulldomain TXT: $txt_value erg: $erg\" return 1 fi _debug \"ok Auto $fulldomain TXT: $txt_value erg: $erg\" return 0 } dns_df_rm() { fulldomain=$1 txtvalue=$2 _info \"TXT enrty in $fulldomain is deleted automatically\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" }"
        },
        {
            "filename": "file_183.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_183.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dgon_info='DigitalOcean.com Site: DigitalOcean.com/help/api/ Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_dgon Options: DO_API_KEY API Key Author: <github@thewer.com> ' ##################### Public functions ##################### ## Create the text record for validation. ## Usage: fulldomain txtvalue ## EG: \"_acme-challenge.www.other.domain.com\" \"XKrxpRBosdq0HG9i01zxXp5CPBs\" dns_dgon_add() { fulldomain=\"$(echo \"$1\" | _lower_case)\" txtvalue=$2 DO_API_KEY=\"${DO_API_KEY:-$(_readaccountconf_mutable DO_API_KEY)}\" # Check if API Key Exists if [ -z \"$DO_API_KEY\" ]; then DO_API_KEY=\"\" _err \"You did not specify DigitalOcean API key.\" _err \"Please export DO_API_KEY and try again.\" return 1 fi _info \"Using digitalocean dns validation - add record\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" ## save the env vars (key and domain split location) for later automated use _saveaccountconf_mutable DO_API_KEY \"$DO_API_KEY\" ## split the domain for DO API if ! _get_base_domain \"$fulldomain\"; then _err \"domain not found in your account for addition\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" ## Set the header with our post type and key auth key export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: Bearer $DO_API_KEY\" PURL='https://api.digitalocean.com/v2/domains/'$_domain'/records' PBODY='{\"type\":\"TXT\",\"name\":\"'$_sub_domain'\",\"data\":\"'$txtvalue'\",\"ttl\":120}' _debug PURL \"$PURL\" _debug PBODY \"$PBODY\" ## the create request - post ## args: BODY, URL, [need64, httpmethod] response=\"$(_post \"$PBODY\" \"$PURL\")\" ## check response if [ \"$?\" != \"0\" ]; then _err \"error in response: $response\" return 1 fi _debug2 response \"$response\" ## finished correctly return 0 } ## Remove the txt record after validation. ## Usage: fulldomain txtvalue ## EG: \"_acme-challenge.www.other.domain.com\" \"XKrxpRBosdq0HG9i01zxXp5CPBs\" dns_dgon_rm() { fulldomain=\"$(echo \"$1\" | _lower_case)\" txtvalue=$2 DO_API_KEY=\"${DO_API_KEY:-$(_readaccountconf_mutable DO_API_KEY)}\" # Check if API Key Exists if [ -z \"$DO_API_KEY\" ]; then DO_API_KEY=\"\" _err \"You did not specify DigitalOcean API key.\" _err \"Please export DO_API_KEY and try again.\" return 1 fi _info \"Using digitalocean dns validation - remove record\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" ## split the domain for DO API if ! _get_base_domain \"$fulldomain\"; then _err \"domain not found in your account for removal\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" ## Set the header with our post type and key auth key export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: Bearer $DO_API_KEY\" ## get URL for the list of domains ## may get: \"links\":{\"pages\":{\"last\":\".../v2/domains/DOM/records?page=2\",\"next\":\".../v2/domains/DOM/records?page=2\"}} GURL=\"https://api.digitalocean.com/v2/domains/$_domain/records\" ## Get all the matching records while true; do ## 1) get the URL ## the create request - get ## args: URL, [onlyheader, timeout] domain_list=\"$(_get \"$GURL\")\" ## check response if [ \"$?\" != \"0\" ]; then _err \"error in domain_list response: $domain_list\" return 1 fi _debug2 domain_list \"$domain_list\" ## 2) find records ## check for what we are looking for: \"type\":\"A\",\"name\":\"$_sub_domain\" record=\"$(echo \"$domain_list\" | _egrep_o \"\\\"id\\\"\\s*\\:\\s*\\\"*[0-9]+\\\"*[^}]*\\\"name\\\"\\s*\\:\\s*\\\"$_sub_domain\\\"[^}]*\\\"data\\\"\\s*\\:\\s*\\\"$txtvalue\\\"\")\" if [ -n \"$record\" ]; then ## we found records rec_ids=\"$(echo \"$record\" | _egrep_o \"id\\\"\\s*\\:\\s*\\\"*[0-9]+\" | _egrep_o \"[0-9]+\")\" _debug rec_ids \"$rec_ids\" if [ -n \"$rec_ids\" ]; then echo \"$rec_ids\" | while IFS= read -r rec_id; do ## delete the record ## delete URL for removing the one we dont want DURL=\"https://api.digitalocean.com/v2/domains/$_domain/records/$rec_id\" ## the create request - delete ## args: BODY, URL, [need64, httpmethod] response=\"$(_post \"\" \"$DURL\" \"\" \"DELETE\")\" ## check response (sort of) if [ \"$?\" != \"0\" ]; then _err \"error in remove response: $response\" return 1 fi _debug2 response \"$response\" done fi fi ## 3) find the next page nextpage=\"$(echo \"$domain_list\" | _egrep_o \"\\\"links\\\".*\" | _egrep_o \"\\\"next\\\".*\" | _egrep_o \"http.*page\\=[0-9]+\")\" if [ -z \"$nextpage\" ]; then break fi _debug2 nextpage \"$nextpage\" GURL=\"$nextpage\" done ## finished correctly return 0 } ##################### Private functions below ##################### ## Split the domain provided into the \"bade domain\" and the \"start prefix\". ## This function searches for the longest subdomain in your account ## for the full domain given and splits it into the base domain (zone) ## and the prefix/record to be added/removed ## USAGE: fulldomain ## EG: \"_acme-challenge.two.three.four.domain.com\" ## returns ## _sub_domain=\"_acme-challenge.two\" ## _domain=\"three.four.domain.com\" *IF* zone \"three.four.domain.com\" exists ## if only \"domain.com\" exists it will return ## _sub_domain=\"_acme-challenge.two.three.four\" ## _domain=\"domain.com\" _get_base_domain() { # args fulldomain=\"$(echo \"$1\" | _lower_case)\" _debug fulldomain \"$fulldomain\" # domain max legal length = 253 MAX_DOM=255 ## get a list of domains for the account to check thru ## Set the headers export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: Bearer $DO_API_KEY\" _debug DO_API_KEY \"$DO_API_KEY\" ## get URL for the list of domains ## may get: \"links\":{\"pages\":{\"last\":\".../v2/domains/DOM/records?page=2\",\"next\":\".../v2/domains/DOM/records?page=2\"}} DOMURL=\"https://api.digitalocean.com/v2/domains\" found=\"\" ## while we dont have a matching domain we keep going while [ -z \"$found\" ]; do ## get the domain list (current page) domain_list=\"$(_get \"$DOMURL\")\" ## check response if [ \"$?\" != \"0\" ]; then _err \"error in domain_list response: $domain_list\" return 1 fi _debug2 domain_list \"$domain_list\" i=1 while [ $i -gt 0 ]; do ## get next longest domain _domain=$(printf \"%s\" \"$fulldomain\" | cut -d . -f \"$i\"-\"$MAX_DOM\") ## check we got something back from our cut (or are we at the end) if [ -z \"$_domain\" ]; then break fi ## we got part of a domain back - grep it out found=\"$(echo \"$domain_list\" | _egrep_o \"\\\"name\\\"\\s*\\:\\s*\\\"$_domain\\\"\")\" ## check if it exists if [ -n \"$found\" ]; then ## exists - exit loop returning the parts sub_point=$(_math $i - 1) _sub_domain=$(printf \"%s\" \"$fulldomain\" | cut -d . -f 1-\"$sub_point\") _debug _domain \"$_domain\" _debug _sub_domain \"$_sub_domain\" return 0 fi ## increment cut point $i i=$(_math $i + 1) done if [ -z \"$found\" ]; then ## find the next page if we dont have a match nextpage=\"$(echo \"$domain_list\" | _egrep_o \"\\\"links\\\".*\" | _egrep_o \"\\\"next\\\".*\" | _egrep_o \"http.*page\\=[0-9]+\")\" if [ -z \"$nextpage\" ]; then _err \"no record and no nextpage in digital ocean DNS removal\" return 1 fi _debug2 nextpage \"$nextpage\" DOMURL=\"$nextpage\" fi done ## we went through the entire domain zone list and dint find one that matched ## doesnt look like we can add in the record _err \"domain not found in DigitalOcean account, but we should never get here\" return 1 }"
        },
        {
            "filename": "file_184.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_184.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dnsexit_info='DNSExit.com Site: DNSExit.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_dnsexit Options: DNSEXIT_API_KEY API Key DNSEXIT_AUTH_USER Username DNSEXIT_AUTH_PASS Password Issues: github.com/acmesh-official/acme.sh/issues/4719 Author: Samuel Jimenez ' DNSEXIT_API_URL=\"https://api.dnsexit.com/dns/\" DNSEXIT_HOSTS_URL=\"https://update.dnsexit.com/ipupdate/hosts.jsp\" ######## Public functions ##################### #Usage: dns_dnsexit_add _acme-challenge.*.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_dnsexit_add() { fulldomain=$1 txtvalue=$2 _info \"Using DNSExit.com\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug 'Load account auth' if ! get_account_info; then return 1 fi _debug 'First detect the root zone' if ! _get_root \"$fulldomain\"; then return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" if ! _dnsexit_rest \"{\\\"domain\\\":\\\"$_domain\\\",\\\"add\\\":{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":0,\\\"overwrite\\\":false}}\"; then _err \"$response\" return 1 fi _debug2 _response \"$response\" return 0 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_dnsexit_rm() { fulldomain=$1 txtvalue=$2 _info \"Using DNSExit.com\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug 'Load account auth' if ! get_account_info; then return 1 fi _debug 'First detect the root zone' if ! _get_root \"$fulldomain\"; then _err \"$response\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" if ! _dnsexit_rest \"{\\\"domain\\\":\\\"$_domain\\\",\\\"delete\\\":{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"content\\\":\\\"$txtvalue\\\"}}\"; then _err \"$response\" return 1 fi _debug2 _response \"$response\" return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=1 while true; do _domain=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$_domain\" if [ -z \"$_domain\" ]; then return 1 fi _debug login \"$DNSEXIT_AUTH_USER\" _debug password \"$DNSEXIT_AUTH_PASS\" _debug domain \"$_domain\" _dnsexit_http \"login=$DNSEXIT_AUTH_USER&password=$DNSEXIT_AUTH_PASS&domain=$_domain\" if _contains \"$response\" \"0=$_domain\"; then _sub_domain=\"$(echo \"$fulldomain\" | sed \"s/\\\\.$_domain\\$//\")\" return 0 else _debug \"Go to next level of $_domain\" fi i=$(_math \"$i\" + 1) done return 1 } _dnsexit_rest() { m=POST ep=\"\" data=\"$1\" _debug _dnsexit_rest \"$ep\" _debug data \"$data\" api_key_trimmed=$(echo \"$DNSEXIT_API_KEY\" | tr -d '\"') export _H1=\"apikey: $api_key_trimmed\" export _H2='Content-Type: application/json' if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$DNSEXIT_API_URL/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$DNSEXIT_API_URL/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"Error $ep\" return 1 fi _debug2 response \"$response\" return 0 } _dnsexit_http() { m=GET param=\"$1\" _debug param \"$param\" _debug get \"$DNSEXIT_HOSTS_URL?$param\" response=\"$(_get \"$DNSEXIT_HOSTS_URL?$param\")\" _debug response \"$response\" if [ \"$?\" != \"0\" ]; then _err \"Error $param\" return 1 fi _debug2 response \"$response\" return 0 } get_account_info() { DNSEXIT_API_KEY=\"${DNSEXIT_API_KEY:-$(_readaccountconf_mutable DNSEXIT_API_KEY)}\" if test -z \"$DNSEXIT_API_KEY\"; then DNSEXIT_API_KEY='' _err 'DNSEXIT_API_KEY was not exported' return 1 fi _saveaccountconf_mutable DNSEXIT_API_KEY \"$DNSEXIT_API_KEY\" DNSEXIT_AUTH_USER=\"${DNSEXIT_AUTH_USER:-$(_readaccountconf_mutable DNSEXIT_AUTH_USER)}\" if test -z \"$DNSEXIT_AUTH_USER\"; then DNSEXIT_AUTH_USER=\"\" _err 'DNSEXIT_AUTH_USER was not exported' return 1 fi _saveaccountconf_mutable DNSEXIT_AUTH_USER \"$DNSEXIT_AUTH_USER\" DNSEXIT_AUTH_PASS=\"${DNSEXIT_AUTH_PASS:-$(_readaccountconf_mutable DNSEXIT_AUTH_PASS)}\" if test -z \"$DNSEXIT_AUTH_PASS\"; then DNSEXIT_AUTH_PASS=\"\" _err 'DNSEXIT_AUTH_PASS was not exported' return 1 fi _saveaccountconf_mutable DNSEXIT_AUTH_PASS \"$DNSEXIT_AUTH_PASS\" return 0 }"
        },
        {
            "filename": "file_185.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_185.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dnshome_info='dnsHome.de Site: dnsHome.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_dnshome Options: DNSHOME_Subdomain Subdomain DNSHOME_SubdomainPassword Subdomain Password Issues: github.com/acmesh-official/acme.sh/issues/3819 Author: dnsHome.de https://github.com/dnsHome-de ' # Usage: add subdomain.ddnsdomain.tld \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record dns_dnshome_add() { txtvalue=$2 DNSHOME_Subdomain=\"${DNSHOME_Subdomain:-$(_readdomainconf DNSHOME_Subdomain)}\" DNSHOME_SubdomainPassword=\"${DNSHOME_SubdomainPassword:-$(_readdomainconf DNSHOME_SubdomainPassword)}\" if [ -z \"$DNSHOME_Subdomain\" ] || [ -z \"$DNSHOME_SubdomainPassword\" ]; then DNSHOME_Subdomain=\"\" DNSHOME_SubdomainPassword=\"\" _err \"Please specify/export your dnsHome.de Subdomain and Password\" return 1 fi #save the credentials to the account conf file. _savedomainconf DNSHOME_Subdomain \"$DNSHOME_Subdomain\" _savedomainconf DNSHOME_SubdomainPassword \"$DNSHOME_SubdomainPassword\" DNSHOME_Api=\"https://$DNSHOME_Subdomain:$DNSHOME_SubdomainPassword@www.dnshome.de/dyndns.php\" _DNSHOME_rest POST \"acme=add&txt=$txtvalue\" if ! echo \"$response\" | grep 'successfully' >/dev/null; then _err \"Error\" _err \"$response\" return 1 fi return 0 } # Usage: txtvalue # Used to remove the txt record after validation dns_dnshome_rm() { txtvalue=$2 DNSHOME_Subdomain=\"${DNSHOME_Subdomain:-$(_readdomainconf DNSHOME_Subdomain)}\" DNSHOME_SubdomainPassword=\"${DNSHOME_SubdomainPassword:-$(_readdomainconf DNSHOME_SubdomainPassword)}\" DNSHOME_Api=\"https://$DNSHOME_Subdomain:$DNSHOME_SubdomainPassword@www.dnshome.de/dyndns.php\" if [ -z \"$DNSHOME_Subdomain\" ] || [ -z \"$DNSHOME_SubdomainPassword\" ]; then DNSHOME_Subdomain=\"\" DNSHOME_SubdomainPassword=\"\" _err \"Please specify/export your dnsHome.de Subdomain and Password\" return 1 fi _DNSHOME_rest POST \"acme=rm&txt=$txtvalue\" if ! echo \"$response\" | grep 'successfully' >/dev/null; then _err \"Error\" _err \"$response\" return 1 fi return 0 } #################### Private functions below ################################## _DNSHOME_rest() { method=$1 data=\"$2\" _debug \"$data\" _debug data \"$data\" response=\"$(_post \"$data\" \"$DNSHOME_Api\" \"\" \"$method\")\" if [ \"$?\" != \"0\" ]; then _err \"error $data\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_186.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_186.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dnsimple_info='DNSimple.com Site: DNSimple.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_dnsimple Options: DNSimple_OAUTH_TOKEN OAuth Token Issues: github.com/pho3nixf1re/acme.sh/issues ' DNSimple_API=\"https://api.dnsimple.com/v2\" ######## Public functions ##################### # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_dnsimple_add() { fulldomain=$1 txtvalue=$2 if [ -z \"$DNSimple_OAUTH_TOKEN\" ]; then DNSimple_OAUTH_TOKEN=\"\" _err \"You have not set the dnsimple oauth token yet.\" _err \"Please visit https://dnsimple.com/user to generate it.\" return 1 fi # save the oauth token for later _saveaccountconf DNSimple_OAUTH_TOKEN \"$DNSimple_OAUTH_TOKEN\" if ! _get_account_id; then _err \"failed to retrive account id\" return 1 fi if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _get_records \"$_account_id\" \"$_domain\" \"$_sub_domain\" _info \"Adding record\" if _dnsimple_rest POST \"$_account_id/zones/$_domain/records\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":120}\"; then if printf -- \"%s\" \"$response\" | grep \"\\\"name\\\":\\\"$_sub_domain\\\"\" >/dev/null; then _info \"Added\" return 0 else _err \"Unexpected response while adding text record.\" return 1 fi fi _err \"Add txt record error.\" } # fulldomain dns_dnsimple_rm() { fulldomain=$1 if ! _get_account_id; then _err \"failed to retrive account id\" return 1 fi if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _get_records \"$_account_id\" \"$_domain\" \"$_sub_domain\" _extract_record_id \"$_records\" \"$_sub_domain\" if [ \"$_record_id\" ]; then echo \"$_record_id\" | while read -r item; do if _dnsimple_rest DELETE \"$_account_id/zones/$_domain/records/$item\"; then _info \"removed record\" \"$item\" return 0 else _err \"failed to remove record\" \"$item\" return 1 fi done fi } #################### Private functions bellow ################################## # _acme-challenge.www.domain.com # returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=2 previous=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then # not valid return 1 fi if ! _dnsimple_rest GET \"$_account_id/zones/$h\"; then return 1 fi if _contains \"$response\" 'not found'; then _debug \"$h not found\" else _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$previous) _domain=\"$h\" _debug _domain \"$_domain\" _debug _sub_domain \"$_sub_domain\" return 0 fi previous=\"$i\" i=$(_math \"$i\" + 1) done return 1 } # returns _account_id _get_account_id() { _debug \"retrive account id\" if ! _dnsimple_rest GET \"whoami\"; then return 1 fi if _contains \"$response\" \"\\\"account\\\":null\"; then _err \"no account associated with this token\" return 1 fi if _contains \"$response\" \"timeout\"; then _err \"timeout retrieving account id\" return 1 fi _account_id=$(printf \"%s\" \"$response\" | _egrep_o \"\\\"id\\\":[^,]*,\\\"email\\\":\" | cut -d: -f2 | cut -d, -f1) _debug _account_id \"$_account_id\" return 0 } # returns # _records # _records_count _get_records() { account_id=$1 domain=$2 sub_domain=$3 _debug \"fetching txt records\" _dnsimple_rest GET \"$account_id/zones/$domain/records?per_page=5000&sort=id:desc\" if ! _contains \"$response\" \"\\\"id\\\":\"; then _err \"failed to retrieve records\" return 1 fi _records_count=$(printf \"%s\" \"$response\" | _egrep_o \"\\\"name\\\":\\\"$sub_domain\\\"\" | wc -l | _egrep_o \"[0-9]+\") _records=$response _debug _records_count \"$_records_count\" } # returns _record_id _extract_record_id() { _record_id=$(printf \"%s\" \"$_records\" | _egrep_o \"\\\"id\\\":[^,]*,\\\"zone_id\\\":\\\"[^,]*\\\",\\\"parent_id\\\":null,\\\"name\\\":\\\"$_sub_domain\\\"\" | cut -d: -f2 | cut -d, -f1) _debug \"_record_id\" \"$_record_id\" } # returns response _dnsimple_rest() { method=$1 path=\"$2\" data=\"$3\" request_url=\"$DNSimple_API/$path\" _debug \"$path\" export _H1=\"Accept: application/json\" export _H2=\"Authorization: Bearer $DNSimple_OAUTH_TOKEN\" if [ \"$data\" ] || [ \"$method\" = \"DELETE\" ]; then _H1=\"Content-Type: application/json\" _debug data \"$data\" response=\"$(_post \"$data\" \"$request_url\" \"\" \"$method\")\" else response=\"$(_get \"$request_url\" \"\" \"\" \"$method\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $request_url\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_187.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_187.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dnsservices_info='DNS.Services Site: DNS.Services Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_dnsservices Options: DnsServices_Username Username DnsServices_Password Password Issues: github.com/acmesh-official/acme.sh/issues/4152 Author: Bjarke Bruun <bbruun@gmail.com> ' DNSServices_API=https://dns.services/api ######## Public functions ##################### #Usage: dns_dnsservices_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_dnsservices_add() { fulldomain=\"$1\" txtvalue=\"$2\" _info \"Using dns.services to create ACME DNS challenge\" _debug2 add_fulldomain \"$fulldomain\" _debug2 add_txtvalue \"$txtvalue\" # Read username/password from environment or .acme.sh/accounts.conf DnsServices_Username=\"${DnsServices_Username:-$(_readaccountconf_mutable DnsServices_Username)}\" DnsServices_Password=\"${DnsServices_Password:-$(_readaccountconf_mutable DnsServices_Password)}\" if [ -z \"$DnsServices_Username\" ] || [ -z \"$DnsServices_Password\" ]; then DnsServices_Username=\"\" DnsServices_Password=\"\" _err \"You didn't specify dns.services api username and password yet.\" _err \"Set environment variables DnsServices_Username and DnsServices_Password\" return 1 fi # Setup GET/POST/DELETE headers _setup_headers #save the credentials to the account conf file. _saveaccountconf_mutable DnsServices_Username \"$DnsServices_Username\" _saveaccountconf_mutable DnsServices_Password \"$DnsServices_Password\" if ! _contains \"$DnsServices_Username\" \"@\"; then _err \"It seems that the username variable DnsServices_Username has not been set/left blank\" _err \"or is not a valid email. Please correct and try again.\" return 1 fi if ! _get_root \"${fulldomain}\"; then _err \"Invalid domain ${fulldomain}\" return 1 fi if ! createRecord \"$fulldomain\" \"${txtvalue}\"; then _err \"Error creating TXT record in domain $fulldomain in $rootZoneName\" return 1 fi _debug2 challenge-created \"Created $fulldomain\" return 0 } #Usage: fulldomain txtvalue #Description: Remove the txt record after validation. dns_dnsservices_rm() { fulldomain=\"$1\" txtvalue=\"$2\" _info \"Using dns.services to remove DNS record $fulldomain TXT $txtvalue\" _debug rm_fulldomain \"$fulldomain\" _debug rm_txtvalue \"$txtvalue\" # Read username/password from environment or .acme.sh/accounts.conf DnsServices_Username=\"${DnsServices_Username:-$(_readaccountconf_mutable DnsServices_Username)}\" DnsServices_Password=\"${DnsServices_Password:-$(_readaccountconf_mutable DnsServices_Password)}\" if [ -z \"$DnsServices_Username\" ] || [ -z \"$DnsServices_Password\" ]; then DnsServices_Username=\"\" DnsServices_Password=\"\" _err \"You didn't specify dns.services api username and password yet.\" _err \"Set environment variables DnsServices_Username and DnsServices_Password\" return 1 fi # Setup GET/POST/DELETE headers _setup_headers if ! _get_root \"${fulldomain}\"; then _err \"Invalid domain ${fulldomain}\" return 1 fi _debug2 rm_rootDomainInfo \"found root domain $rootZoneName for $fulldomain\" if ! deleteRecord \"${fulldomain}\" \"${txtvalue}\"; then _err \"Error removing record: $fulldomain TXT ${txtvalue}\" return 1 fi return 0 } #################### Private functions below ################################## _setup_headers() { # Set up API Headers for _get() and _post() # The <function>_add or <function>_rm must have been called before to work if [ -z \"$DnsServices_Username\" ] || [ -z \"$DnsServices_Password\" ]; then _err \"Could not setup BASIC authentication headers, they are missing\" return 1 fi DnsServiceCredentials=\"$(printf \"%s\" \"$DnsServices_Username:$DnsServices_Password\" | _base64)\" export _H1=\"Authorization: Basic $DnsServiceCredentials\" export _H2=\"Content-Type: application/json\" # Just return if headers are set return 0 } _get_root() { domain=\"$1\" _debug2 _get_root \"Get the root domain of ${domain} for DNS API\" # Setup _get() and _post() headers #_setup_headers result=$(_H1=\"$_H1\" _H2=\"$_H2\" _get \"$DNSServices_API/dns\") result2=\"$(printf \"%s\\n\" \"$result\" | tr '[' '\\n' | grep '\"name\"')\" result3=\"$(printf \"%s\\n\" \"$result2\" | tr '}' '\\n' | grep '\"name\"' | sed \"s,^\\,,,g\" | sed \"s,$,},g\")\" useResult=\"\" _debug2 _get_root \"Got the following root domain(s) $result\" _debug2 _get_root \"- JSON: $result\" if [ \"$(printf \"%s\\n\" \"$result\" | tr '}' '\\n' | grep -c '\"name\"')\" -gt \"1\" ]; then checkMultiZones=\"true\" _debug2 _get_root \"- multiple zones found\" else checkMultiZones=\"false\" _debug2 _get_root \"- single zone found\" fi # Find/isolate the root zone to work with in createRecord() and deleteRecord() rootZone=\"\" if [ \"$checkMultiZones\" = \"true\" ]; then #rootZone=$(for x in $(printf \"%s\" \"${result3}\" | tr ',' '\\n' | sed -n 's/.*\"name\":\"\\(.*\\)\",.*/\\1/p'); do if [ \"$(echo \"$domain\" | grep \"$x\")\" != \"\" ]; then echo \"$x\"; fi; done) rootZone=$(for x in $(printf \"%s\\n\" \"${result3}\" | tr ',' '\\n' | grep name | cut -d'\"' -f4); do if [ \"$(echo \"$domain\" | grep \"$x\")\" != \"\" ]; then echo \"$x\"; fi; done) if [ \"$rootZone\" != \"\" ]; then _debug2 _rootZone \"- root zone for $domain is $rootZone\" else _err \"Could not find root zone for $domain, is it correctly typed?\" return 1 fi else rootZone=$(echo \"$result\" | tr '}' '\\n' | _egrep_o '\"name\":\"[^\"]*' | cut -d'\"' -f4) _debug2 _get_root \"- only found 1 domain in API: $rootZone\" fi if [ -z \"$rootZone\" ]; then _err \"Could not find root domain for $domain - is it correctly typed?\" return 1 fi # Make sure we use the correct API zone data useResult=\"$(printf \"%s\\n\" \"${result3}\" tr ',' '\\n' | grep \"$rootZone\")\" _debug2 _useResult \"useResult=$useResult\" # Setup variables used by other functions to communicate with DNS.Services API #zoneInfo=$(printf \"%s\\n\" \"$useResult\" | sed -E 's,.*(zones)(.*),\\1\\2,g' | sed -E 's,^(.*\"name\":\")([^\"]*)\"(.*)$,\\2,g') zoneInfo=$(printf \"%s\\n\" \"$useResult\" | tr ',' '\\n' | grep '\"name\"' | cut -d'\"' -f4) rootZoneName=\"$rootZone\" subDomainName=\"$(printf \"%s\\n\" \"$domain\" | sed \"s,\\.$rootZone,,g\")\" subDomainNameClean=\"$(printf \"%s\\n\" \"$domain\" | sed \"s,_acme-challenge.,,g\")\" rootZoneDomainID=$(printf \"%s\\n\" \"$useResult\" | tr ',' '\\n' | grep domain_id | cut -d'\"' -f4) rootZoneServiceID=$(printf \"%s\\n\" \"$useResult\" | tr ',' '\\n' | grep service_id | cut -d'\"' -f4) _debug2 _zoneInfo \"Zone info from API : $zoneInfo\" _debug2 _get_root \"Root zone name : $rootZoneName\" _debug2 _get_root \"Root zone domain ID : $rootZoneDomainID\" _debug2 _get_root \"Root zone service ID: $rootZoneServiceID\" _debug2 _get_root \"Sub domain : $subDomainName\" _debug _get_root \"Found valid root domain $rootZone for $subDomainNameClean\" return 0 } createRecord() { fulldomain=\"$1\" txtvalue=\"$2\" # Get root domain information - needed for DNS.Services API communication if [ -z \"$rootZoneName\" ] || [ -z \"$rootZoneDomainID\" ] || [ -z \"$rootZoneServiceID\" ]; then _get_root \"$fulldomain\" fi if [ -z \"$rootZoneName\" ] || [ -z \"$rootZoneDomainID\" ] || [ -z \"$rootZoneServiceID\" ]; then _err \"Something happend - could not get the API zone information\" return 1 fi _debug2 createRecord \"CNAME TXT value is: $txtvalue\" # Prepare data to send to API data=\"{\\\"name\\\":\\\"${fulldomain}\\\",\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"${txtvalue}\\\", \\\"ttl\\\":\\\"10\\\"}\" _debug2 createRecord \"data to API: $data\" result=$(_post \"$data\" \"$DNSServices_API/service/$rootZoneServiceID/dns/$rootZoneDomainID/records\" \"\" \"POST\") _debug2 createRecord \"result from API: $result\" if [ \"$(echo \"$result\" | _egrep_o \"\\\"success\\\":true\")\" = \"\" ]; then _err \"Failed to create TXT record $fulldomain with content $txtvalue in zone $rootZoneName\" _err \"$result\" return 1 fi _info \"Record \\\"$fulldomain TXT $txtvalue\\\" has been created\" return 0 } deleteRecord() { fulldomain=\"$1\" txtvalue=\"$2\" _log deleteRecord \"Deleting $fulldomain TXT $txtvalue record\" if [ -z \"$rootZoneName\" ] || [ -z \"$rootZoneDomainID\" ] || [ -z \"$rootZoneServiceID\" ]; then _get_root \"$fulldomain\" fi result=\"$(_H1=\"$_H1\" _H2=\"$_H2\" _get \"$DNSServices_API/service/$rootZoneServiceID/dns/$rootZoneDomainID\")\" #recordInfo=\"$(echo \"$result\" | sed -e 's/:{/:{\\n/g' -e 's/},/\\n},\\n/g' | grep \"${txtvalue}\")\" #recordID=\"$(echo \"$recordInfo\" | sed -e 's/:{/:{\\n/g' -e 's/},/\\n},\\n/g' | grep \"${txtvalue}\" | sed -E 's,.*(zones)(.*),\\1\\2,g' | sed -E 's,^(.*\"id\":\")([^\"]*)\"(.*)$,\\2,g')\" recordID=\"$(printf \"%s\\n\" \"$result\" | tr '}' '\\n' | grep -- \"$txtvalue\" | tr ',' '\\n' | grep '\"id\"' | cut -d'\"' -f4)\" _debug2 _recordID \"recordID used for deletion of record: $recordID\" if [ -z \"$recordID\" ]; then _info \"Record $fulldomain TXT $txtvalue not found or already deleted\" return 0 else _debug2 deleteRecord \"Found recordID=$recordID\" fi _debug2 deleteRecord \"DELETE request $DNSServices_API/service/$rootZoneServiceID/dns/$rootZoneDomainID/records/$recordID\" _log \"curl DELETE request $DNSServices_API/service/$rootZoneServiceID/dns/$rootZoneDomainID/records/$recordID\" result=\"$(_H1=\"$_H1\" _H2=\"$_H2\" _post \"\" \"$DNSServices_API/service/$rootZoneServiceID/dns/$rootZoneDomainID/records/$recordID\" \"\" \"DELETE\")\" _debug2 deleteRecord \"API Delete result \\\"$result\\\"\" _log \"curl API Delete result \\\"$result\\\"\" # Return OK regardless return 0 }"
        },
        {
            "filename": "file_188.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_188.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_doapi_info='Domain-Offensive do.de Official LetsEncrypt API for do.de / Domain-Offensive. This API is also available to private customers/individuals. Site: do.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_doapi Options: DO_LETOKEN LetsEncrypt Token Issues: github.com/acmesh-official/acme.sh/issues/2057 ' DO_API=\"https://my.do.de/api/letsencrypt\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_doapi_add() { fulldomain=$1 txtvalue=$2 DO_LETOKEN=\"${DO_LETOKEN:-$(_readaccountconf_mutable DO_LETOKEN)}\" if [ -z \"$DO_LETOKEN\" ]; then DO_LETOKEN=\"\" _err \"You didn't configure a do.de API token yet.\" _err \"Please set DO_LETOKEN and try again.\" return 1 fi _saveaccountconf_mutable DO_LETOKEN \"$DO_LETOKEN\" _info \"Adding TXT record to ${fulldomain}\" response=\"$(_get \"$DO_API?token=$DO_LETOKEN&domain=${fulldomain}&value=${txtvalue}\")\" if _contains \"${response}\" 'success'; then return 0 fi _err \"Could not create resource record, check logs\" _err \"${response}\" return 1 } dns_doapi_rm() { fulldomain=$1 DO_LETOKEN=\"${DO_LETOKEN:-$(_readaccountconf_mutable DO_LETOKEN)}\" if [ -z \"$DO_LETOKEN\" ]; then DO_LETOKEN=\"\" _err \"You didn't configure a do.de API token yet.\" _err \"Please set DO_LETOKEN and try again.\" return 1 fi _saveaccountconf_mutable DO_LETOKEN \"$DO_LETOKEN\" _info \"Deleting resource record $fulldomain\" response=\"$(_get \"$DO_API?token=$DO_LETOKEN&domain=${fulldomain}&action=delete\")\" if _contains \"${response}\" 'success'; then return 0 fi _err \"Could not delete resource record, check logs\" _err \"${response}\" return 1 }"
        },
        {
            "filename": "file_189.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_189.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_domeneshop_info='DomeneShop.no Site: DomeneShop.no Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_domeneshop Options: DOMENESHOP_Token Token DOMENESHOP_Secret Secret Issues: github.com/acmesh-official/acme.sh/issues/2457 ' DOMENESHOP_Api_Endpoint=\"https://api.domeneshop.no/v0\" ##################### Public functions ##################### # Usage: dns_domeneshop_add <full domain> <txt record> # Example: dns_domeneshop_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_domeneshop_add() { fulldomain=$1 txtvalue=$2 # Get token and secret DOMENESHOP_Token=\"${DOMENESHOP_Token:-$(_readaccountconf_mutable DOMENESHOP_Token)}\" DOMENESHOP_Secret=\"${DOMENESHOP_Secret:-$(_readaccountconf_mutable DOMENESHOP_Secret)}\" if [ -z \"$DOMENESHOP_Token\" ] || [ -z \"$DOMENESHOP_Secret\" ]; then DOMENESHOP_Token=\"\" DOMENESHOP_Secret=\"\" _err \"You need to spesify a Domeneshop/Domainnameshop API Token and Secret.\" return 1 fi # Save the api token and secret. _saveaccountconf_mutable DOMENESHOP_Token \"$DOMENESHOP_Token\" _saveaccountconf_mutable DOMENESHOP_Secret \"$DOMENESHOP_Secret\" # Get the domain name id if ! _get_domainid \"$fulldomain\"; then _err \"Did not find domainname\" return 1 fi # Create record _domeneshop_rest POST \"domains/$_domainid/dns\" \"{\\\"type\\\":\\\"TXT\\\",\\\"host\\\":\\\"$_sub_domain\\\",\\\"data\\\":\\\"$txtvalue\\\",\\\"ttl\\\":120}\" } # Usage: dns_domeneshop_rm <full domain> <txt record> # Example: dns_domeneshop_rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_domeneshop_rm() { fulldomain=$1 txtvalue=$2 # Get token and secret DOMENESHOP_Token=\"${DOMENESHOP_Token:-$(_readaccountconf_mutable DOMENESHOP_Token)}\" DOMENESHOP_Secret=\"${DOMENESHOP_Secret:-$(_readaccountconf_mutable DOMENESHOP_Secret)}\" if [ -z \"$DOMENESHOP_Token\" ] || [ -z \"$DOMENESHOP_Secret\" ]; then DOMENESHOP_Token=\"\" DOMENESHOP_Secret=\"\" _err \"You need to spesify a Domeneshop/Domainnameshop API Token and Secret.\" return 1 fi # Get the domain name id if ! _get_domainid \"$fulldomain\"; then _err \"Did not find domainname\" return 1 fi # Find record if ! _get_recordid \"$_domainid\" \"$_sub_domain\" \"$txtvalue\"; then _err \"Did not find dns record\" return 1 fi # Remove record _domeneshop_rest DELETE \"domains/$_domainid/dns/$_recordid\" } ##################### Private functions ##################### _get_domainid() { domain=$1 # Get domains _domeneshop_rest GET \"domains\" if ! _contains \"$response\" \"\\\"id\\\":\"; then _err \"failed to get domain names\" return 1 fi i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug \"h\" \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"\\\"$h\\\"\" >/dev/null; then # We have found the domain name. _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h _domainid=$(printf \"%s\" \"$response\" | _egrep_o \"[^{]*\\\"domain\\\":\\\"$_domain\\\"[^}]*\" | _egrep_o \"\\\"id\\\":[0-9]+\" | cut -d : -f 2) return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _get_recordid() { domainid=$1 subdomain=$2 txtvalue=$3 # Get all dns records for the domainname _domeneshop_rest GET \"domains/$domainid/dns\" if ! _contains \"$response\" \"\\\"id\\\":\"; then _debug \"No records in dns\" return 1 fi if ! _contains \"$response\" \"\\\"host\\\":\\\"$subdomain\\\"\"; then _debug \"Record does not exist\" return 1 fi # Get the id of the record in question _recordid=$(printf \"%s\" \"$response\" | _egrep_o \"[^{]*\\\"host\\\":\\\"$subdomain\\\"[^}]*\" | _egrep_o \"[^{]*\\\"data\\\":\\\"$txtvalue\\\"[^}]*\" | _egrep_o \"\\\"id\\\":[0-9]+\" | cut -d : -f 2) if [ -z \"$_recordid\" ]; then return 1 fi return 0 } _domeneshop_rest() { method=$1 endpoint=$2 data=$3 credentials=$(printf \"%b\" \"$DOMENESHOP_Token:$DOMENESHOP_Secret\" | _base64) export _H1=\"Authorization: Basic $credentials\" export _H2=\"Content-Type: application/json\" if [ \"$method\" != \"GET\" ]; then response=\"$(_post \"$data\" \"$DOMENESHOP_Api_Endpoint/$endpoint\" \"\" \"$method\")\" else response=\"$(_get \"$DOMENESHOP_Api_Endpoint/$endpoint\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $endpoint\" return 1 fi return 0 }"
        },
        {
            "filename": "file_190.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_190.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dp_info='DNSPod.cn Site: DNSPod.cn Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_dp Options: DP_Id Id DP_Key Key ' REST_API=\"https://dnsapi.cn\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_dp_add() { fulldomain=$1 txtvalue=$2 DP_Id=\"${DP_Id:-$(_readaccountconf_mutable DP_Id)}\" DP_Key=\"${DP_Key:-$(_readaccountconf_mutable DP_Key)}\" if [ -z \"$DP_Id\" ] || [ -z \"$DP_Key\" ]; then DP_Id=\"\" DP_Key=\"\" _err \"You don't specify dnspod api key and key id yet.\" _err \"Please create you key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable DP_Id \"$DP_Id\" _saveaccountconf_mutable DP_Key \"$DP_Key\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi add_record \"$_domain\" \"$_sub_domain\" \"$txtvalue\" } #fulldomain txtvalue dns_dp_rm() { fulldomain=$1 txtvalue=$2 DP_Id=\"${DP_Id:-$(_readaccountconf_mutable DP_Id)}\" DP_Key=\"${DP_Key:-$(_readaccountconf_mutable DP_Key)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi if ! _rest POST \"Record.List\" \"login_token=$DP_Id,$DP_Key&format=json&lang=en&domain_id=$_domain_id&sub_domain=$_sub_domain\"; then _err \"Record.Lis error.\" return 1 fi if _contains \"$response\" 'No records'; then _info \"Don't need to remove.\" return 0 fi record_id=$(echo \"$response\" | tr \"{\" \"\\n\" | grep -- \"$txtvalue\" | grep '^\"id\"' | cut -d : -f 2 | cut -d '\"' -f 2) _debug record_id \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id.\" return 1 fi if ! _rest POST \"Record.Remove\" \"login_token=$DP_Id,$DP_Key&format=json&lang=en&domain_id=$_domain_id&record_id=$record_id\"; then _err \"Record.Remove error.\" return 1 fi _contains \"$response\" \"successful\" } #add the txt record. #usage: root sub txtvalue add_record() { root=$1 sub=$2 txtvalue=$3 fulldomain=\"$sub.$root\" _info \"Adding record\" if ! _rest POST \"Record.Create\" \"login_token=$DP_Id,$DP_Key&format=json&lang=en&domain_id=$_domain_id&sub_domain=$_sub_domain&record_type=TXT&value=$txtvalue&record_line=%E9%BB%98%E8%AE%A4\"; then return 1 fi _contains \"$response\" \"successful\" || _contains \"$response\" \"Domain record already exists\" } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi if ! _rest POST \"Domain.Info\" \"login_token=$DP_Id,$DP_Key&format=json&lang=en&domain=$h\"; then return 1 fi if _contains \"$response\" \"successful\"; then _domain_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\") _debug _domain_id \"$_domain_id\" if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _debug _sub_domain \"$_sub_domain\" _domain=\"$h\" _debug _domain \"$_domain\" return 0 fi return 1 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } #Usage: method URI data _rest() { m=\"$1\" ep=\"$2\" data=\"$3\" _debug \"$ep\" url=\"$REST_API/$ep\" _debug url \"$url\" if [ \"$m\" = \"GET\" ]; then response=\"$(_get \"$url\" | tr -d '\\r')\" else _debug2 data \"$data\" response=\"$(_post \"$data\" \"$url\" | tr -d '\\r')\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_191.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_191.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dpi_info='DNSPod.com Site: DNSPod.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_dpi Options: DPI_Id Id DPI_Key Key ' REST_API=\"https://api.dnspod.com\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_dpi_add() { fulldomain=$1 txtvalue=$2 DPI_Id=\"${DPI_Id:-$(_readaccountconf_mutable DPI_Id)}\" DPI_Key=\"${DPI_Key:-$(_readaccountconf_mutable DPI_Key)}\" if [ -z \"$DPI_Id\" ] || [ -z \"$DPI_Key\" ]; then DPI_Id=\"\" DPI_Key=\"\" _err \"You don't specify dnspod api key and key id yet.\" _err \"Please create you key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable DPI_Id \"$DPI_Id\" _saveaccountconf_mutable DPI_Key \"$DPI_Key\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi add_record \"$_domain\" \"$_sub_domain\" \"$txtvalue\" } #fulldomain txtvalue dns_dpi_rm() { fulldomain=$1 txtvalue=$2 DPI_Id=\"${DPI_Id:-$(_readaccountconf_mutable DPI_Id)}\" DPI_Key=\"${DPI_Key:-$(_readaccountconf_mutable DPI_Key)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi if ! _rest POST \"Record.List\" \"login_token=$DPI_Id,$DPI_Key&format=json&domain_id=$_domain_id&sub_domain=$_sub_domain\"; then _err \"Record.Lis error.\" return 1 fi if _contains \"$response\" 'No records'; then _info \"Don't need to remove.\" return 0 fi record_id=$(echo \"$response\" | tr \"{\" \"\\n\" | grep -- \"$txtvalue\" | grep '^\"id\"' | cut -d : -f 2 | cut -d '\"' -f 2) _debug record_id \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id.\" return 1 fi if ! _rest POST \"Record.Remove\" \"login_token=$DPI_Id,$DPI_Key&format=json&domain_id=$_domain_id&record_id=$record_id\"; then _err \"Record.Remove error.\" return 1 fi _contains \"$response\" \"Operation successful\" } #add the txt record. #usage: root sub txtvalue add_record() { root=$1 sub=$2 txtvalue=$3 fulldomain=\"$sub.$root\" _info \"Adding record\" if ! _rest POST \"Record.Create\" \"login_token=$DPI_Id,$DPI_Key&format=json&domain_id=$_domain_id&sub_domain=$_sub_domain&record_type=TXT&value=$txtvalue&record_line=default\"; then return 1 fi _contains \"$response\" \"Operation successful\" || _contains \"$response\" \"Domain record already exists\" } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi if ! _rest POST \"Domain.Info\" \"login_token=$DPI_Id,$DPI_Key&format=json&domain=$h\"; then return 1 fi if _contains \"$response\" \"Operation successful\"; then _domain_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\") _debug _domain_id \"$_domain_id\" if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _debug _sub_domain \"$_sub_domain\" _domain=\"$h\" _debug _domain \"$_domain\" return 0 fi return 1 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } #Usage: method URI data _rest() { m=\"$1\" ep=\"$2\" data=\"$3\" _debug \"$ep\" url=\"$REST_API/$ep\" _debug url \"$url\" if [ \"$m\" = \"GET\" ]; then response=\"$(_get \"$url\" | tr -d '\\r')\" else _debug2 data \"$data\" response=\"$(_post \"$data\" \"$url\" | tr -d '\\r')\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_192.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_192.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dreamhost_info='DreamHost.com Site: DreamHost.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_dreamhost Options: DH_API_KEY API Key Issues: github.com/RhinoLance/acme.sh Author: RhinoLance ' DH_API_ENDPOINT=\"https://api.dreamhost.com/\" querystring=\"\" ######## Public functions ##################### #Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_dreamhost_add() { fulldomain=$1 txtvalue=$2 if ! validate \"$fulldomain\" \"$txtvalue\"; then return 1 fi querystring=\"key=$DH_API_KEY&cmd=dns-add_record&record=$fulldomain&type=TXT&value=$txtvalue\" if ! submit \"$querystring\"; then return 1 fi return 0 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_dreamhost_rm() { fulldomain=$1 txtvalue=$2 if ! validate \"$fulldomain\" \"$txtvalue\"; then return 1 fi querystring=\"key=$DH_API_KEY&cmd=dns-remove_record&record=$fulldomain&type=TXT&value=$txtvalue\" if ! submit \"$querystring\"; then return 1 fi return 0 } #################### Private functions below ################################## #send the command to the api endpoint. submit() { querystring=$1 url=\"$DH_API_ENDPOINT?$querystring\" _debug url \"$url\" if ! response=\"$(_get \"$url\")\"; then _err \"Error <$1>\" return 1 fi if [ -z \"$2\" ]; then message=\"$(echo \"$response\" | _egrep_o \"\\\"Message\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\")\" if [ -n \"$message\" ]; then _err \"$message\" return 1 fi fi _debug response \"$response\" return 0 } #check that we have a valid API Key validate() { fulldomain=$1 txtvalue=$2 _info \"Using dreamhost\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" #retrieve the API key from the environment variable if it exists, otherwise look for a saved key. DH_API_KEY=\"${DH_API_KEY:-$(_readaccountconf_mutable DH_API_KEY)}\" if [ -z \"$DH_API_KEY\" ]; then DH_API_KEY=\"\" _err \"You didn't specify the DreamHost api key yet (export DH_API_KEY=\\\"<api key>\\\")\" _err \"Please login to your control panel, create a key and try again.\" return 1 fi #save the api key to the account conf file. _saveaccountconf_mutable DH_API_KEY \"$DH_API_KEY\" }"
        },
        {
            "filename": "file_193.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_193.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_duckdns_info='DuckDNS.org Site: www.DuckDNS.org Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_duckdns Options: DuckDNS_Token API Token Author: RaidenII ' DuckDNS_API=\"https://www.duckdns.org/update\" ######## Public functions ###################### #Usage: dns_duckdns_add _acme-challenge.domain.duckdns.org \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_duckdns_add() { fulldomain=$1 txtvalue=$2 DuckDNS_Token=\"${DuckDNS_Token:-$(_readaccountconf_mutable DuckDNS_Token)}\" if [ -z \"$DuckDNS_Token\" ]; then _err \"You must export variable: DuckDNS_Token\" _err \"The token for your DuckDNS account is necessary.\" _err \"You can look it up in your DuckDNS account.\" return 1 fi # Now save the credentials. _saveaccountconf_mutable DuckDNS_Token \"$DuckDNS_Token\" # Unfortunately, DuckDNS does not seems to support lookup domain through API # So I assume your credentials (which are your domain and token) are correct # If something goes wrong, we will get a KO response from DuckDNS if ! _duckdns_get_domain; then return 1 fi # Now add the TXT record to DuckDNS _info \"Trying to add TXT record\" if _duckdns_rest GET \"domains=$_duckdns_domain&token=$DuckDNS_Token&txt=$txtvalue\"; then if [ \"$response\" = \"OK\" ]; then _info \"TXT record has been successfully added to your DuckDNS domain.\" _info \"Note that all subdomains under this domain uses the same TXT record.\" return 0 else _err \"Errors happened during adding the TXT record, response=$response\" return 1 fi else _err \"Errors happened during adding the TXT record.\" return 1 fi } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_duckdns_rm() { fulldomain=$1 txtvalue=$2 DuckDNS_Token=\"${DuckDNS_Token:-$(_readaccountconf_mutable DuckDNS_Token)}\" if [ -z \"$DuckDNS_Token\" ]; then _err \"You must export variable: DuckDNS_Token\" _err \"The token for your DuckDNS account is necessary.\" _err \"You can look it up in your DuckDNS account.\" return 1 fi if ! _duckdns_get_domain; then return 1 fi # Now remove the TXT record from DuckDNS _info \"Trying to remove TXT record\" if _duckdns_rest GET \"domains=$_duckdns_domain&token=$DuckDNS_Token&txt=&clear=true\"; then if [ \"$response\" = \"OK\" ]; then _info \"TXT record has been successfully removed from your DuckDNS domain.\" return 0 else _err \"Errors happened during removing the TXT record, response=$response\" return 1 fi else _err \"Errors happened during removing the TXT record.\" return 1 fi } #################### Private functions below ################################## # fulldomain may be 'domain.duckdns.org' (if using --domain-alias) or '_acme-challenge.domain.duckdns.org' # either way, return 'domain'. (duckdns does not allow further subdomains and restricts domains to [a-z0-9-].) _duckdns_get_domain() { # We'll extract the domain/username from full domain _duckdns_domain=\"$(printf \"%s\" \"$fulldomain\" | _lower_case | _egrep_o '^(_acme-challenge\\.)?([a-z0-9-]+\\.)+duckdns\\.org' | sed -n 's/^\\([^.]\\{1,\\}\\.\\)*\\([a-z0-9-]\\{1,\\}\\)\\.duckdns\\.org$/\\2/p;')\" if [ -z \"$_duckdns_domain\" ]; then _err \"Error extracting the domain.\" return 1 fi return 0 } #Usage: method URI _duckdns_rest() { method=$1 param=\"$2\" _debug param \"$param\" url=\"$DuckDNS_API?$param\" if [ -n \"$DEBUG\" ] && [ \"$DEBUG\" -gt 0 ]; then url=\"$url&verbose=true\" fi _debug url \"$url\" # DuckDNS uses GET to update domain info if [ \"$method\" = \"GET\" ]; then response=\"$(_get \"$url\")\" _debug2 response \"$response\" if [ -n \"$DEBUG\" ] && [ \"$DEBUG\" -gt 0 ] && _contains \"$response\" \"UPDATED\" && _contains \"$response\" \"OK\"; then response=\"OK\" fi else _err \"Unsupported method\" return 1 fi return 0 }"
        },
        {
            "filename": "file_194.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_194.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_durabledns_info='DurableDNS.com Site: DurableDNS.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_durabledns Options: DD_API_User API User DD_API_Key API Key Issues: github.com/acmesh-official/acme.sh/issues/2281 ' _DD_BASE=\"https://durabledns.com/services/dns\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_durabledns_add() { fulldomain=$1 txtvalue=$2 DD_API_User=\"${DD_API_User:-$(_readaccountconf_mutable DD_API_User)}\" DD_API_Key=\"${DD_API_Key:-$(_readaccountconf_mutable DD_API_Key)}\" if [ -z \"$DD_API_User\" ] || [ -z \"$DD_API_Key\" ]; then DD_API_User=\"\" DD_API_Key=\"\" _err \"You didn't specify a durabledns api user or key yet.\" _err \"You can get yours from here https://durabledns.com/dashboard/index.php\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable DD_API_User \"$DD_API_User\" _saveaccountconf_mutable DD_API_Key \"$DD_API_Key\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _dd_soap createRecord string zonename \"$_domain.\" string name \"$_sub_domain\" string type \"TXT\" string data \"$txtvalue\" int aux 0 int ttl 10 string ddns_enabled N _contains \"$response\" \"createRecordResponse\" } dns_durabledns_rm() { fulldomain=$1 txtvalue=$2 DD_API_User=\"${DD_API_User:-$(_readaccountconf_mutable DD_API_User)}\" DD_API_Key=\"${DD_API_Key:-$(_readaccountconf_mutable DD_API_Key)}\" if [ -z \"$DD_API_User\" ] || [ -z \"$DD_API_Key\" ]; then DD_API_User=\"\" DD_API_Key=\"\" _err \"You didn't specify a durabledns api user or key yet.\" _err \"You can get yours from here https://durabledns.com/dashboard/index.php\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Find record id\" if ! _dd_soap listRecords string zonename \"$_domain.\"; then _err \"can not listRecords\" return 1 fi subtxt=\"$(echo \"$txtvalue\" | cut -c 1-30)\" record=\"$(echo \"$response\" | sed 's/<item\\>/#<item>/g' | tr '#' '\\n' | grep \">$subtxt\")\" _debug record \"$record\" if [ -z \"$record\" ]; then _err \"can not find record for txtvalue\" \"$txtvalue\" _err \"$response\" return 1 fi recordid=\"$(echo \"$record\" | _egrep_o '<id xsi:type=\"xsd:int\">[0-9]*</id>' | cut -d '>' -f 2 | cut -d '<' -f 1)\" _debug recordid \"$recordid\" if [ -z \"$recordid\" ]; then _err \"can not find record id\" return 1 fi if ! _dd_soap deleteRecord string zonename \"$_domain.\" int id \"$recordid\"; then _err \"delete error\" return 1 fi _contains \"$response\" \"Success\" } #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 if ! _dd_soap \"listZones\"; then return 1 fi i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \">$h.</origin>\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } #method _dd_soap() { _method=\"$1\" shift _urn=\"${_method}wsdl\" # put the parameters to xml body=\"<tns:$_method> <apiuser xsi:type=\\\"xsd:string\\\">$DD_API_User</apiuser> <apikey xsi:type=\\\"xsd:string\\\">$DD_API_Key</apikey> \" while [ \"$1\" ]; do _t=\"$1\" shift _k=\"$1\" shift _v=\"$1\" shift body=\"$body<$_k xsi:type=\\\"xsd:$_t\\\">$_v</$_k>\" done body=\"$body</tns:$_method>\" _debug2 \"SOAP request ${body}\" # build SOAP XML _xml='<?xml version=\"1.0\" encoding=\"utf-8\"?> <soap:Envelope xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:tns=\"urn:'$_urn'\" xmlns:types=\"urn:'$_urn'/encodedTypes\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"> <soap:Body soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\">'\"$body\"'</soap:Body> </soap:Envelope>' _debug2 _xml \"$_xml\" # set SOAP headers _action=\"SOAPAction: \\\"urn:$_urn#$_method\\\"\" _debug2 \"_action\" \"$_action\" export _H1=\"$_action\" export _H2=\"Content-Type: text/xml; charset=utf-8\" _url=\"$_DD_BASE/$_method.php\" _debug \"_url\" \"$_url\" if ! response=\"$(_post \"${_xml}\" \"${_url}\")\"; then _err \"Error <$1>\" return 1 fi _debug2 \"response\" \"$response\" response=\"$(echo \"$response\" | tr -d \"\\r\\n\" | _egrep_o \":${_method}Response .*:${_method}Response><\")\" _debug2 \"response\" \"$response\" return 0 }"
        },
        {
            "filename": "file_195.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_195.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dyn_info='Dyn.com Domains: dynect.net Site: Dyn.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_dyn Options: DYN_Customer Customer DYN_Username API Username DYN_Password Secret Author: Gerd Naschenweng <https://github.com/magicdude4eva> ' # Dyn Managed DNS API # https://help.dyn.com/dns-api-knowledge-base/ # # It is recommended to add a \"Dyn Managed DNS\" user specific for API access. # The \"Zones & Records Permissions\" required by this script are: # -- # RecordAdd # RecordUpdate # RecordDelete # RecordGet # ZoneGet # ZoneAddNode # ZoneRemoveNode # ZonePublish # -- DYN_API=\"https://api.dynect.net/REST\" #REST_API ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"Challenge-code\" dns_dyn_add() { fulldomain=\"$1\" txtvalue=\"$2\" DYN_Customer=\"${DYN_Customer:-$(_readaccountconf_mutable DYN_Customer)}\" DYN_Username=\"${DYN_Username:-$(_readaccountconf_mutable DYN_Username)}\" DYN_Password=\"${DYN_Password:-$(_readaccountconf_mutable DYN_Password)}\" if [ -z \"$DYN_Customer\" ] || [ -z \"$DYN_Username\" ] || [ -z \"$DYN_Password\" ]; then DYN_Customer=\"\" DYN_Username=\"\" DYN_Password=\"\" _err \"You must export variables: DYN_Customer, DYN_Username and DYN_Password\" return 1 fi #save the config variables to the account conf file. _saveaccountconf_mutable DYN_Customer \"$DYN_Customer\" _saveaccountconf_mutable DYN_Username \"$DYN_Username\" _saveaccountconf_mutable DYN_Password \"$DYN_Password\" if ! _dyn_get_authtoken; then return 1 fi if [ -z \"$_dyn_authtoken\" ]; then _dyn_end_session return 1 fi if ! _dyn_get_zone; then _dyn_end_session return 1 fi if ! _dyn_add_record; then _dyn_end_session return 1 fi if ! _dyn_publish_zone; then _dyn_end_session return 1 fi _dyn_end_session return 0 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_dyn_rm() { fulldomain=\"$1\" txtvalue=\"$2\" DYN_Customer=\"${DYN_Customer:-$(_readaccountconf_mutable DYN_Customer)}\" DYN_Username=\"${DYN_Username:-$(_readaccountconf_mutable DYN_Username)}\" DYN_Password=\"${DYN_Password:-$(_readaccountconf_mutable DYN_Password)}\" if [ -z \"$DYN_Customer\" ] || [ -z \"$DYN_Username\" ] || [ -z \"$DYN_Password\" ]; then DYN_Customer=\"\" DYN_Username=\"\" DYN_Password=\"\" _err \"You must export variables: DYN_Customer, DYN_Username and DYN_Password\" return 1 fi if ! _dyn_get_authtoken; then return 1 fi if [ -z \"$_dyn_authtoken\" ]; then _dyn_end_session return 1 fi if ! _dyn_get_zone; then _dyn_end_session return 1 fi if ! _dyn_get_record_id; then _dyn_end_session return 1 fi if [ -z \"$_dyn_record_id\" ]; then _dyn_end_session return 1 fi if ! _dyn_rm_record; then _dyn_end_session return 1 fi if ! _dyn_publish_zone; then _dyn_end_session return 1 fi _dyn_end_session return 0 } #################### Private functions below ################################## #get Auth-Token _dyn_get_authtoken() { _info \"Start Dyn API Session\" data=\"{\\\"customer_name\\\":\\\"$DYN_Customer\\\", \\\"user_name\\\":\\\"$DYN_Username\\\", \\\"password\\\":\\\"$DYN_Password\\\"}\" dyn_url=\"$DYN_API/Session/\" method=\"POST\" _debug data \"$data\" _debug dyn_url \"$dyn_url\" export _H1=\"Content-Type: application/json\" response=\"$(_post \"$data\" \"$dyn_url\" \"\" \"$method\")\" sessionstatus=\"$(printf \"%s\\n\" \"$response\" | _egrep_o '\"status\" *: *\"[^\"]*' | _head_n 1 | sed 's#^\"status\" *: *\"##')\" _debug response \"$response\" _debug sessionstatus \"$sessionstatus\" if [ \"$sessionstatus\" = \"success\" ]; then _dyn_authtoken=\"$(printf \"%s\\n\" \"$response\" | _egrep_o '\"token\" *: *\"[^\"]*' | _head_n 1 | sed 's#^\"token\" *: *\"##')\" _info \"Token received\" _debug _dyn_authtoken \"$_dyn_authtoken\" return 0 fi _dyn_authtoken=\"\" _err \"get token failed\" return 1 } #fulldomain=_acme-challenge.www.domain.com #returns # _dyn_zone=domain.com _dyn_get_zone() { i=2 while true; do domain=\"$(printf \"%s\" \"$fulldomain\" | cut -d . -f \"$i-100\")\" if [ -z \"$domain\" ]; then break fi dyn_url=\"$DYN_API/Zone/$domain/\" export _H1=\"Auth-Token: $_dyn_authtoken\" export _H2=\"Content-Type: application/json\" response=\"$(_get \"$dyn_url\" \"\" \"\")\" sessionstatus=\"$(printf \"%s\\n\" \"$response\" | _egrep_o '\"status\" *: *\"[^\"]*' | _head_n 1 | sed 's#^\"status\" *: *\"##')\" _debug dyn_url \"$dyn_url\" _debug response \"$response\" _debug sessionstatus \"$sessionstatus\" if [ \"$sessionstatus\" = \"success\" ]; then _dyn_zone=\"$domain\" return 0 fi i=$(_math \"$i\" + 1) done _dyn_zone=\"\" _err \"get zone failed\" return 1 } #add TXT record _dyn_add_record() { _info \"Adding TXT record\" data=\"{\\\"rdata\\\":{\\\"txtdata\\\":\\\"$txtvalue\\\"},\\\"ttl\\\":\\\"300\\\"}\" dyn_url=\"$DYN_API/TXTRecord/$_dyn_zone/$fulldomain/\" method=\"POST\" export _H1=\"Auth-Token: $_dyn_authtoken\" export _H2=\"Content-Type: application/json\" response=\"$(_post \"$data\" \"$dyn_url\" \"\" \"$method\")\" sessionstatus=\"$(printf \"%s\\n\" \"$response\" | _egrep_o '\"status\" *: *\"[^\"]*' | _head_n 1 | sed 's#^\"status\" *: *\"##')\" _debug response \"$response\" _debug sessionstatus \"$sessionstatus\" if [ \"$sessionstatus\" = \"success\" ]; then _info \"TXT Record successfully added\" return 0 fi _err \"add TXT record failed\" return 1 } #publish the zone _dyn_publish_zone() { _info \"Publishing zone\" data=\"{\\\"publish\\\":\\\"true\\\"}\" dyn_url=\"$DYN_API/Zone/$_dyn_zone/\" method=\"PUT\" export _H1=\"Auth-Token: $_dyn_authtoken\" export _H2=\"Content-Type: application/json\" response=\"$(_post \"$data\" \"$dyn_url\" \"\" \"$method\")\" sessionstatus=\"$(printf \"%s\\n\" \"$response\" | _egrep_o '\"status\" *: *\"[^\"]*' | _head_n 1 | sed 's#^\"status\" *: *\"##')\" _debug response \"$response\" _debug sessionstatus \"$sessionstatus\" if [ \"$sessionstatus\" = \"success\" ]; then _info \"Zone published\" return 0 fi _err \"publish zone failed\" return 1 } #get record_id of TXT record so we can delete the record _dyn_get_record_id() { _info \"Getting record_id of TXT record\" dyn_url=\"$DYN_API/TXTRecord/$_dyn_zone/$fulldomain/\" export _H1=\"Auth-Token: $_dyn_authtoken\" export _H2=\"Content-Type: application/json\" response=\"$(_get \"$dyn_url\" \"\" \"\")\" sessionstatus=\"$(printf \"%s\\n\" \"$response\" | _egrep_o '\"status\" *: *\"[^\"]*' | _head_n 1 | sed 's#^\"status\" *: *\"##')\" _debug response \"$response\" _debug sessionstatus \"$sessionstatus\" if [ \"$sessionstatus\" = \"success\" ]; then _dyn_record_id=\"$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"data\\\" *: *\\[\\\"/REST/TXTRecord/$_dyn_zone/$fulldomain/[^\\\"]*\" | _head_n 1 | sed \"s#^\\\"data\\\" *: *\\[\\\"/REST/TXTRecord/$_dyn_zone/$fulldomain/##\")\" _debug _dyn_record_id \"$_dyn_record_id\" return 0 fi _dyn_record_id=\"\" _err \"getting record_id failed\" return 1 } #delete TXT record _dyn_rm_record() { _info \"Deleting TXT record\" dyn_url=\"$DYN_API/TXTRecord/$_dyn_zone/$fulldomain/$_dyn_record_id/\" method=\"DELETE\" _debug dyn_url \"$dyn_url\" export _H1=\"Auth-Token: $_dyn_authtoken\" export _H2=\"Content-Type: application/json\" response=\"$(_post \"\" \"$dyn_url\" \"\" \"$method\")\" sessionstatus=\"$(printf \"%s\\n\" \"$response\" | _egrep_o '\"status\" *: *\"[^\"]*' | _head_n 1 | sed 's#^\"status\" *: *\"##')\" _debug response \"$response\" _debug sessionstatus \"$sessionstatus\" if [ \"$sessionstatus\" = \"success\" ]; then _info \"TXT record successfully deleted\" return 0 fi _err \"delete TXT record failed\" return 1 } #logout _dyn_end_session() { _info \"End Dyn API Session\" dyn_url=\"$DYN_API/Session/\" method=\"DELETE\" _debug dyn_url \"$dyn_url\" export _H1=\"Auth-Token: $_dyn_authtoken\" export _H2=\"Content-Type: application/json\" response=\"$(_post \"\" \"$dyn_url\" \"\" \"$method\")\" _debug response \"$response\" _dyn_authtoken=\"\" return 0 }"
        },
        {
            "filename": "file_196.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_196.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dynu_info='Dynu.com Site: Dynu.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_dynu Options: Dynu_ClientId Client ID Dynu_Secret Secret Issues: github.com/shar0119/acme.sh Author: Dynu Systems Inc ' #Token Dynu_Token=\"\" # #Endpoint Dynu_EndPoint=\"https://api.dynu.com/v2\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_dynu_add() { fulldomain=$1 txtvalue=$2 if [ -z \"$Dynu_ClientId\" ] || [ -z \"$Dynu_Secret\" ]; then Dynu_ClientId=\"\" Dynu_Secret=\"\" _err \"Dynu client id and secret is not specified.\" _err \"Please create you API client id and secret and try again.\" return 1 fi #save the client id and secret to the account conf file. _saveaccountconf Dynu_ClientId \"$Dynu_ClientId\" _saveaccountconf Dynu_Secret \"$Dynu_Secret\" if [ -z \"$Dynu_Token\" ]; then _info \"Getting Dynu token.\" if ! _dynu_authentication; then _err \"Can not get token.\" fi fi _debug \"Detect root zone\" if ! _get_root \"$fulldomain\"; then _err \"Invalid domain.\" return 1 fi _debug _node \"$_node\" _debug _domain_name \"$_domain_name\" _info \"Creating TXT record.\" if ! _dynu_rest POST \"dns/$dnsId/record\" \"{\\\"domainId\\\":\\\"$dnsId\\\",\\\"nodeName\\\":\\\"$_node\\\",\\\"recordType\\\":\\\"TXT\\\",\\\"textData\\\":\\\"$txtvalue\\\",\\\"state\\\":true,\\\"ttl\\\":90}\"; then return 1 fi if ! _contains \"$response\" \"200\"; then _err \"Could not add TXT record.\" return 1 fi return 0 } #Usage: rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_dynu_rm() { fulldomain=$1 txtvalue=$2 if [ -z \"$Dynu_ClientId\" ] || [ -z \"$Dynu_Secret\" ]; then Dynu_ClientId=\"\" Dynu_Secret=\"\" _err \"Dynu client id and secret is not specified.\" _err \"Please create you API client id and secret and try again.\" return 1 fi #save the client id and secret to the account conf file. _saveaccountconf Dynu_ClientId \"$Dynu_ClientId\" _saveaccountconf Dynu_Secret \"$Dynu_Secret\" if [ -z \"$Dynu_Token\" ]; then _info \"Getting Dynu token.\" if ! _dynu_authentication; then _err \"Can not get token.\" fi fi _debug \"Detect root zone.\" if ! _get_root \"$fulldomain\"; then _err \"Invalid domain.\" return 1 fi _debug _node \"$_node\" _debug _domain_name \"$_domain_name\" _info \"Checking for TXT record.\" if ! _get_recordid \"$fulldomain\" \"$txtvalue\"; then _err \"Could not get TXT record id.\" return 1 fi if [ \"$_dns_record_id\" = \"\" ]; then _err \"TXT record not found.\" return 1 fi _info \"Removing TXT record.\" if ! _delete_txt_record \"$_dns_record_id\"; then _err \"Could not remove TXT record $_dns_record_id.\" fi return 0 } ######## Private functions below ################################## #_acme-challenge.www.domain.com #returns # _node=_acme-challenge.www # _domain_name=domain.com _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _dynu_rest GET \"dns/getroot/$h\"; then return 1 fi if _contains \"$response\" \"\\\"domainName\\\":\\\"$h\\\"\" >/dev/null; then dnsId=$(printf \"%s\" \"$response\" | tr -d \"{}\" | cut -d , -f 2 | cut -d : -f 2) _domain_name=$h _node=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _get_recordid() { fulldomain=$1 txtvalue=$2 if ! _dynu_rest GET \"dns/$dnsId/record\"; then return 1 fi if ! _contains \"$response\" \"$txtvalue\"; then _dns_record_id=0 return 0 fi _dns_record_id=$(printf \"%s\" \"$response\" | sed -e 's/[^{]*\\({[^}]*}\\)[^{]*/\\1\\n/g' | grep \"\\\"textData\\\":\\\"$txtvalue\\\"\" | sed -e 's/.*\"id\":\\([^,]*\\).*/\\1/') return 0 } _delete_txt_record() { _dns_record_id=$1 if ! _dynu_rest DELETE \"dns/$dnsId/record/$_dns_record_id\"; then return 1 fi if ! _contains \"$response\" \"200\"; then return 1 fi return 0 } _dynu_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Authorization: Bearer $Dynu_Token\" export _H2=\"Content-Type: application/json\" if [ \"$data\" ] || [ \"$m\" = \"DELETE\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$Dynu_EndPoint/$ep\" \"\" \"$m\")\" else _info \"Getting $Dynu_EndPoint/$ep\" response=\"$(_get \"$Dynu_EndPoint/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 } _dynu_authentication() { realm=\"$(printf \"%s\" \"$Dynu_ClientId:$Dynu_Secret\" | _base64)\" export _H1=\"Authorization: Basic $realm\" export _H2=\"Content-Type: application/json\" response=\"$(_get \"$Dynu_EndPoint/oauth2/token\")\" if [ \"$?\" != \"0\" ]; then _err \"Authentication failed.\" return 1 fi if _contains \"$response\" \"Authentication Exception\"; then _err \"Authentication failed.\" return 1 fi if _contains \"$response\" \"access_token\"; then Dynu_Token=$(printf \"%s\" \"$response\" | tr -d \"{}\" | cut -d , -f 1 | cut -d : -f 2 | cut -d '\"' -f 2) fi if _contains \"$Dynu_Token\" \"null\"; then Dynu_Token=\"\" fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_197.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_197.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_dynv6_info='DynV6.com Site: DynV6.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_dynv6 Options: DYNV6_TOKEN REST API token. Get from https://DynV6.com/keys OptionsAlt: KEY Path to SSH private key file. E.g. \"/root/.ssh/dynv6\" Issues: github.com/acmesh-official/acme.sh/issues/2702 Author: StefanAbl ' dynv6_api=\"https://dynv6.com/api/v2\" ######## Public functions ##################### # Please Read this guide first: https://github.com/Neilpang/acme.sh/wiki/DNS-API-Dev-Guide #Usage: dns_dynv6_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_dynv6_add() { fulldomain=\"$(echo \"$1\" | _lower_case)\" txtvalue=\"$2\" _info \"Using dynv6 api\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _get_authentication if [ \"$dynv6_token\" ]; then _dns_dynv6_add_http return $? else _info \"using key file $dynv6_keyfile\" _your_hosts=\"$(ssh -i \"$dynv6_keyfile\" api@dynv6.com hosts)\" if ! _get_domain \"$fulldomain\" \"$_your_hosts\"; then _err \"Host not found on your account\" return 1 fi _debug \"found host on your account\" returnval=\"$(ssh -i \"$dynv6_keyfile\" api@dynv6.com hosts \\\"\"$_host\"\\\" records set \\\"\"$_record\"\\\" txt data \\\"\"$txtvalue\"\\\")\" _debug \"Dynv6 returned this after record was added: $returnval\" if _contains \"$returnval\" \"created\"; then return 0 elif _contains \"$returnval\" \"updated\"; then return 0 else _err \"Something went wrong! it does not seem like the record was added successfully\" return 1 fi return 1 fi return 1 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_dynv6_rm() { fulldomain=\"$(echo \"$1\" | _lower_case)\" txtvalue=\"$2\" _info \"Using dynv6 API\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _get_authentication if [ \"$dynv6_token\" ]; then _dns_dynv6_rm_http return $? else _info \"using key file $dynv6_keyfile\" _your_hosts=\"$(ssh -i \"$dynv6_keyfile\" api@dynv6.com hosts)\" if ! _get_domain \"$fulldomain\" \"$_your_hosts\"; then _err \"Host not found on your account\" return 1 fi _debug \"found host on your account\" _info \"$(ssh -i \"$dynv6_keyfile\" api@dynv6.com hosts \"\\\"$_host\\\"\" records del \"\\\"$_record\\\"\" txt)\" return 0 fi } #################### Private functions below ################################## #Usage: No Input required #returns #dynv6_keyfile the path to the new key file that has been generated _generate_new_key() { dynv6_keyfile=\"$(eval echo ~\"$USER\")/.ssh/dynv6\" _info \"Path to key file used: $dynv6_keyfile\" if [ ! -f \"$dynv6_keyfile\" ] && [ ! -f \"$dynv6_keyfile.pub\" ]; then _debug \"generating key in $dynv6_keyfile and $dynv6_keyfile.pub\" ssh-keygen -f \"$dynv6_keyfile\" -t ssh-ed25519 -N '' else _err \"There is already a file in $dynv6_keyfile or $dynv6_keyfile.pub\" return 1 fi } #Usage: _acme-challenge.www.example.dynv6.net \"$_your_hosts\" #where _your_hosts is the output of ssh -i ~/.ssh/dynv6.pub api@dynv6.com hosts #returns #_host= example.dynv6.net #_record=_acme-challenge.www #aborts if not a valid domain _get_domain() { #_your_hosts=\"$(ssh -i ~/.ssh/dynv6.pub api@dynv6.com hosts)\" _full_domain=\"$1\" _your_hosts=\"$2\" _your_hosts=\"$(echo \"$_your_hosts\" | awk '/\\./ {print $1}')\" for l in $_your_hosts; do #echo \"host: $l\" if test \"${_full_domain#*\"$l\"}\" != \"$_full_domain\"; then _record=${_full_domain%.\"$l\"} _host=$l _debug \"The host is $_host and the record $_record\" return 0 fi done _err \"Either their is no such host on your dnyv6 account or it cannot be accessed with this key\" return 1 } # Usage: No input required #returns #dynv6_keyfile path to the key that will be used _get_authentication() { dynv6_token=\"${DYNV6_TOKEN:-$(_readaccountconf_mutable dynv6_token)}\" if [ \"$dynv6_token\" ]; then _debug \"Found HTTP Token. Going to use the HTTP API and not the SSH API\" if [ \"$DYNV6_TOKEN\" ]; then _saveaccountconf_mutable dynv6_token \"$dynv6_token\" fi else _debug \"no HTTP token found. Looking for an SSH key\" dynv6_keyfile=\"${dynv6_keyfile:-$(_readaccountconf_mutable dynv6_keyfile)}\" _debug \"Your key is $dynv6_keyfile\" if [ -z \"$dynv6_keyfile\" ]; then if [ -z \"$KEY\" ]; then _err \"You did not specify a key to use with dynv6\" _info \"Creating new dynv6 API key to add to dynv6.com\" _generate_new_key _info \"Please add this key to dynv6.com $(cat \"$dynv6_keyfile.pub\")\" _info \"Hit Enter to continue\" read -r _ #save the credentials to the account conf file. else dynv6_keyfile=\"$KEY\" fi _saveaccountconf_mutable dynv6_keyfile \"$dynv6_keyfile\" fi fi } _dns_dynv6_add_http() { _debug \"Got HTTP token form _get_authentication method. Going to use the HTTP API\" if ! _get_zone_id \"$fulldomain\"; then _err \"Could not find a matching zone for $fulldomain. Maybe your HTTP Token is not authorized to access the zone\" return 1 fi _get_zone_name \"$_zone_id\" record=${fulldomain%%.\"$_zone_name\"} _set_record TXT \"$record\" \"$txtvalue\" if _contains \"$response\" \"$txtvalue\"; then _info \"Successfully added record\" return 0 else _err \"Something went wrong while adding the record\" return 1 fi } _dns_dynv6_rm_http() { _debug \"Got HTTP token form _get_authentication method. Going to use the HTTP API\" if ! _get_zone_id \"$fulldomain\"; then _err \"Could not find a matching zone for $fulldomain. Maybe your HTTP Token is not authorized to access the zone\" return 1 fi _get_zone_name \"$_zone_id\" record=${fulldomain%%.\"$_zone_name\"} _get_record_id \"$_zone_id\" \"$record\" \"$txtvalue\" _del_record \"$_zone_id\" \"$_record_id\" if [ -z \"$response\" ]; then _info \"Successfully deleted record\" return 0 else _err \"Something went wrong while deleting the record\" return 1 fi } #get the zoneid for a specifc record or zone #usage: _get_zone_id \u00a7record #where $record is the record to get the id for #returns _zone_id the id of the zone _get_zone_id() { record=\"$1\" _debug \"getting zone id for $record\" _dynv6_rest GET zones zones=\"$(echo \"$response\" | tr '}' '\\n' | tr ',' '\\n' | grep name | sed 's/\\[//g' | tr -d '{' | tr -d '\"')\" #echo $zones selected=\"\" for z in $zones; do z=\"${z#name:}\" _debug zone: \"$z\" if _contains \"$record\" \"$z\"; then _debug \"$z found in $record\" selected=\"$z\" fi done if [ -z \"$selected\" ]; then _err \"no zone found\" return 1 fi zone_id=\"$(echo \"$response\" | tr '}' '\\n' | grep \"$selected\" | tr ',' '\\n' | grep '\"id\":' | tr -d '\"')\" _zone_id=\"${zone_id#id:}\" _debug \"zone id: $_zone_id\" } _get_zone_name() { _zone_id=\"$1\" _dynv6_rest GET zones/\"$_zone_id\" _zone_name=\"$(echo \"$response\" | tr ',' '\\n' | tr -d '{' | grep name | tr -d '\"')\" _zone_name=\"${_zone_name#name:}\" } #usaage _get_record_id $zone_id $record # where zone_id is thevalue returned by _get_zone_id # and record ist in the form _acme.www for an fqdn of _acme.www.example.com # returns _record_id _get_record_id() { _zone_id=\"$1\" record=\"$2\" value=\"$3\" _dynv6_rest GET \"zones/$_zone_id/records\" if ! _get_record_id_from_response \"$response\"; then _err \"no such record $record found in zone $_zone_id\" return 1 fi } _get_record_id_from_response() { response=\"$1\" _record_id=\"$(echo \"$response\" | tr '}' '\\n' | grep \"\\\"name\\\":\\\"$record\\\"\" | grep \"\\\"data\\\":\\\"$value\\\"\" | tr ',' '\\n' | grep id | tr -d '\"' | tr -d 'id:')\" #_record_id=\"${_record_id#id:}\" if [ -z \"$_record_id\" ]; then _err \"no such record: $record found in zone $_zone_id\" return 1 fi _debug \"record id: $_record_id\" return 0 } #usage: _set_record TXT _acme_challenge.www longvalue 12345678 #zone id is optional can also be set as vairable bevor calling this method _set_record() { type=\"$1\" record=\"$2\" value=\"$3\" if [ \"$4\" ]; then _zone_id=\"$4\" fi data=\"{\\\"name\\\": \\\"$record\\\", \\\"data\\\": \\\"$value\\\", \\\"type\\\": \\\"$type\\\"}\" #data='{ \"name\": \"acme.test.thorn.dynv6.net\", \"type\": \"A\", \"data\": \"192.168.0.1\"}' echo \"$data\" #\"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$fulldomain\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":120}\" _dynv6_rest POST \"zones/$_zone_id/records\" \"$data\" } _del_record() { _zone_id=$1 _record_id=$2 _dynv6_rest DELETE zones/\"$_zone_id\"/records/\"$_record_id\" } _dynv6_rest() { m=$1 #method GET,POST,DELETE or PUT ep=\"$2\" #the endpoint data=\"$3\" _debug \"$ep\" token_trimmed=$(echo \"$dynv6_token\" | tr -d '\"') export _H1=\"Authorization: Bearer $token_trimmed\" export _H2=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$dynv6_api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$dynv6_api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_198.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_198.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_easydns_info='easyDNS.net Site: easyDNS.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_easydns Options: EASYDNS_Token API Token EASYDNS_Key API Key Issues: github.com/acmesh-official/acme.sh/issues/2647 Author: Neilpang, wurzelpanzer <wurzelpanzer@maximolider.net> ' # API Documentation: https://sandbox.rest.easydns.net:3001/ #################### Public functions ################# #EASYDNS_Key=\"xxxxxxxxxxxxxxxxxxxxxxxx\" #EASYDNS_Token=\"xxxxxxxxxxxxxxxxxxxxxxxx\" EASYDNS_Api=\"https://rest.easydns.net\" #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_easydns_add() { fulldomain=$1 txtvalue=$2 EASYDNS_Token=\"${EASYDNS_Token:-$(_readaccountconf_mutable EASYDNS_Token)}\" EASYDNS_Key=\"${EASYDNS_Key:-$(_readaccountconf_mutable EASYDNS_Key)}\" if [ -z \"$EASYDNS_Token\" ] || [ -z \"$EASYDNS_Key\" ]; then _err \"You didn't specify an easydns.net token or api key. Signup at https://cp.easydns.com/manage/security/api/signup.php\" return 1 else _saveaccountconf_mutable EASYDNS_Token \"$EASYDNS_Token\" _saveaccountconf_mutable EASYDNS_Key \"$EASYDNS_Key\" fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _EASYDNS_rest GET \"zones/records/all/${_domain}/search/${_sub_domain}\" if ! printf \"%s\" \"$response\" | grep \\\"status\\\":200 >/dev/null; then _err \"Error\" return 1 fi _info \"Adding record\" if _EASYDNS_rest PUT \"zones/records/add/$_domain/TXT\" \"{\\\"host\\\":\\\"$_sub_domain\\\",\\\"rdata\\\":\\\"$txtvalue\\\"}\"; then if _contains \"$response\" \"\\\"status\\\":201\"; then _info \"Added, OK\" return 0 elif _contains \"$response\" \"Record already exists\"; then _info \"Already exists, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } dns_easydns_rm() { fulldomain=$1 txtvalue=$2 EASYDNS_Token=\"${EASYDNS_Token:-$(_readaccountconf_mutable EASYDNS_Token)}\" EASYDNS_Key=\"${EASYDNS_Key:-$(_readaccountconf_mutable EASYDNS_Key)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _EASYDNS_rest GET \"zones/records/all/${_domain}/search/${_sub_domain}\" if ! printf \"%s\" \"$response\" | grep \\\"status\\\":200 >/dev/null; then _err \"Error\" return 1 fi count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"count\\\":[^,]*\" | cut -d : -f 2) _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\" | head -n 1) _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _EASYDNS_rest DELETE \"zones/records/$_domain/$record_id\"; then _err \"Delete record error.\" return 1 fi _contains \"$response\" \"\\\"status\\\":200\" fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _EASYDNS_rest GET \"zones/records/all/$h\"; then return 1 fi if _contains \"$response\" \"\\\"status\\\":200\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _EASYDNS_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" basicauth=$(printf \"%s\" \"$EASYDNS_Token\":\"$EASYDNS_Key\" | _base64) export _H1=\"accept: application/json\" if [ \"$basicauth\" ]; then export _H2=\"Authorization: Basic $basicauth\" fi if [ \"$m\" != \"GET\" ]; then export _H3=\"Content-Type: application/json\" _debug data \"$data\" response=\"$(_post \"$data\" \"$EASYDNS_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$EASYDNS_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_199.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_199.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_edgedns_info='Akamai.com Edge DNS Site: techdocs.Akamai.com/edge-dns/reference/edge-dns-api Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_edgedns Options: Specify individual credentials AKAMAI_HOST Host AKAMAI_ACCESS_TOKEN Access token AKAMAI_CLIENT_TOKEN Client token AKAMAI_CLIENT_SECRET Client secret Issues: github.com/acmesh-official/acme.sh/issues/3157 ' # Akamai Edge DNS v2 API # User must provide Open Edgegrid API credentials to the EdgeDNS installation. The remote user in EdgeDNS must have CRUD access to # Edge DNS Zones and Recordsets, e.g. DNS\u2014Zone Record Management authorization # Report bugs to https://control.akamai.com/apps/support-ui/#/contact-support # *** TBD. NOT IMPLEMENTED YET *** # Specify Edgegrid credentials file and section. # AKAMAI_EDGERC Edge RC. Full file path # AKAMAI_EDGERC_SECTION Edge RC Section. E.g. \"default\" ACME_EDGEDNS_VERSION=\"0.1.0\" ######## Public functions ##################### # Usage: dns_edgedns_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record # dns_edgedns_add() { fulldomain=$1 txtvalue=$2 _debug \"ENTERING DNS_EDGEDNS_ADD\" _debug2 \"fulldomain\" \"$fulldomain\" _debug2 \"txtvalue\" \"$txtvalue\" if ! _EDGEDNS_credentials; then _err \"$@\" return 1 fi if ! _EDGEDNS_getZoneInfo \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi _debug2 \"Add: zone\" \"$zone\" acmeRecordURI=$(printf \"%s/%s/names/%s/types/TXT\" \"$edge_endpoint\" \"$zone\" \"$fulldomain\") _debug3 \"Add URL\" \"$acmeRecordURI\" # Get existing TXT record _edge_result=$(_edgedns_rest GET \"$acmeRecordURI\") _api_status=\"$?\" _debug3 \"_edge_result\" \"$_edge_result\" if [ \"$_api_status\" -ne 0 ]; then if [ \"$curResult\" = \"FATAL\" ]; then _err \"$(printf \"Fatal error: acme API function call : %s\" \"$retVal\")\" fi if [ \"$_edge_result\" != \"404\" ]; then _err \"$(printf \"Failure accessing Akamai Edge DNS API Server. Error: %s\" \"$_edge_result\")\" return 1 fi fi rdata=\"\\\"${txtvalue}\\\"\" record_op=\"POST\" if [ \"$_api_status\" -eq 0 ]; then # record already exists. Get existing record data and update record_op=\"PUT\" rdlist=\"${_edge_result#*\\\"rdata\\\":[}\" rdlist=\"${rdlist%%]*}\" rdlist=$(echo \"$rdlist\" | tr -d '\"' | tr -d \"\\\\\\\\\") _debug3 \"existing TXT found\" _debug3 \"record data\" \"$rdlist\" # value already there? if _contains \"$rdlist\" \"$txtvalue\"; then return 0 fi _txt_val=\"\" while [ \"$_txt_val\" != \"$rdlist\" ] && [ \"${rdlist}\" ]; do _txt_val=\"${rdlist%%,*}\" rdlist=\"${rdlist#*,}\" rdata=\"${rdata},\\\"${_txt_val}\\\"\" done fi # Add the txtvalue TXT Record body=\"{\\\"name\\\":\\\"$fulldomain\\\",\\\"type\\\":\\\"TXT\\\",\\\"ttl\\\":600, \\\"rdata\\\":\"[${rdata}]\"}\" _debug3 \"Add body '${body}'\" _edge_result=$(_edgedns_rest \"$record_op\" \"$acmeRecordURI\" \"$body\") _api_status=\"$?\" if [ \"$_api_status\" -eq 0 ]; then _log \"$(printf \"Text value %s added to recordset %s\" \"$txtvalue\" \"$fulldomain\")\" return 0 else _err \"$(printf \"error adding TXT record for validation. Error: %s\" \"$_edge_result\")\" return 1 fi } # Usage: dns_edgedns_rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to delete txt record # dns_edgedns_rm() { fulldomain=$1 txtvalue=$2 _debug \"ENTERING DNS_EDGEDNS_RM\" _debug2 \"fulldomain\" \"$fulldomain\" _debug2 \"txtvalue\" \"$txtvalue\" if ! _EDGEDNS_credentials; then _err \"$@\" return 1 fi if ! _EDGEDNS_getZoneInfo \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi _debug2 \"RM: zone\" \"${zone}\" acmeRecordURI=$(printf \"%s/%s/names/%s/types/TXT\" \"${edge_endpoint}\" \"$zone\" \"$fulldomain\") _debug3 \"RM URL\" \"$acmeRecordURI\" # Get existing TXT record _edge_result=$(_edgedns_rest GET \"$acmeRecordURI\") _api_status=\"$?\" if [ \"$_api_status\" -ne 0 ]; then if [ \"$curResult\" = \"FATAL\" ]; then _err \"$(printf \"Fatal error: acme API function call : %s\" \"$retVal\")\" fi if [ \"$_edge_result\" != \"404\" ]; then _err \"$(printf \"Failure accessing Akamai Edge DNS API Server. Error: %s\" \"$_edge_result\")\" return 1 fi fi _debug3 \"_edge_result\" \"$_edge_result\" record_op=\"DELETE\" body=\"\" if [ \"$_api_status\" -eq 0 ]; then # record already exists. Get existing record data and update rdlist=\"${_edge_result#*\\\"rdata\\\":[}\" rdlist=\"${rdlist%%]*}\" rdlist=$(echo \"$rdlist\" | tr -d '\"' | tr -d \"\\\\\\\\\") _debug3 \"rdlist\" \"$rdlist\" if [ -n \"$rdlist\" ]; then record_op=\"PUT\" comma=\"\" rdata=\"\" _txt_val=\"\" while [ \"$_txt_val\" != \"$rdlist\" ] && [ \"$rdlist\" ]; do _txt_val=\"${rdlist%%,*}\" rdlist=\"${rdlist#*,}\" _debug3 \"_txt_val\" \"$_txt_val\" _debug3 \"txtvalue\" \"$txtvalue\" if ! _contains \"$_txt_val\" \"$txtvalue\"; then rdata=\"${rdata}${comma}\\\"${_txt_val}\\\"\" comma=\",\" fi done if [ -z \"$rdata\" ]; then record_op=\"DELETE\" else # Recreate the txtvalue TXT Record body=\"{\\\"name\\\":\\\"$fulldomain\\\",\\\"type\\\":\\\"TXT\\\",\\\"ttl\\\":600, \\\"rdata\\\":\"[${rdata}]\"}\" _debug3 \"body\" \"$body\" fi fi fi _edge_result=$(_edgedns_rest \"$record_op\" \"$acmeRecordURI\" \"$body\") _api_status=\"$?\" if [ \"$_api_status\" -eq 0 ]; then _log \"$(printf \"Text value %s removed from recordset %s\" \"$txtvalue\" \"$fulldomain\")\" return 0 else _err \"$(printf \"error removing TXT record for validation. Error: %s\" \"$_edge_result\")\" return 1 fi } #################### Private functions below ################################## _EDGEDNS_credentials() { _debug \"GettingEdge DNS credentials\" _log \"$(printf \"ACME DNSAPI Edge DNS version %s\" ${ACME_EDGEDNS_VERSION})\" args_missing=0 AKAMAI_ACCESS_TOKEN=\"${AKAMAI_ACCESS_TOKEN:-$(_readaccountconf_mutable AKAMAI_ACCESS_TOKEN)}\" if [ -z \"$AKAMAI_ACCESS_TOKEN\" ]; then AKAMAI_ACCESS_TOKEN=\"\" AKAMAI_CLIENT_TOKEN=\"\" AKAMAI_HOST=\"\" AKAMAI_CLIENT_SECRET=\"\" _err \"AKAMAI_ACCESS_TOKEN is missing\" args_missing=1 fi AKAMAI_CLIENT_TOKEN=\"${AKAMAI_CLIENT_TOKEN:-$(_readaccountconf_mutable AKAMAI_CLIENT_TOKEN)}\" if [ -z \"$AKAMAI_CLIENT_TOKEN\" ]; then AKAMAI_ACCESS_TOKEN=\"\" AKAMAI_CLIENT_TOKEN=\"\" AKAMAI_HOST=\"\" AKAMAI_CLIENT_SECRET=\"\" _err \"AKAMAI_CLIENT_TOKEN is missing\" args_missing=1 fi AKAMAI_HOST=\"${AKAMAI_HOST:-$(_readaccountconf_mutable AKAMAI_HOST)}\" if [ -z \"$AKAMAI_HOST\" ]; then AKAMAI_ACCESS_TOKEN=\"\" AKAMAI_CLIENT_TOKEN=\"\" AKAMAI_HOST=\"\" AKAMAI_CLIENT_SECRET=\"\" _err \"AKAMAI_HOST is missing\" args_missing=1 fi AKAMAI_CLIENT_SECRET=\"${AKAMAI_CLIENT_SECRET:-$(_readaccountconf_mutable AKAMAI_CLIENT_SECRET)}\" if [ -z \"$AKAMAI_CLIENT_SECRET\" ]; then AKAMAI_ACCESS_TOKEN=\"\" AKAMAI_CLIENT_TOKEN=\"\" AKAMAI_HOST=\"\" AKAMAI_CLIENT_SECRET=\"\" _err \"AKAMAI_CLIENT_SECRET is missing\" args_missing=1 fi if [ \"$args_missing\" = 1 ]; then _err \"You have not properly specified the EdgeDNS Open Edgegrid API credentials. Please try again.\" return 1 else _saveaccountconf_mutable AKAMAI_ACCESS_TOKEN \"$AKAMAI_ACCESS_TOKEN\" _saveaccountconf_mutable AKAMAI_CLIENT_TOKEN \"$AKAMAI_CLIENT_TOKEN\" _saveaccountconf_mutable AKAMAI_HOST \"$AKAMAI_HOST\" _saveaccountconf_mutable AKAMAI_CLIENT_SECRET \"$AKAMAI_CLIENT_SECRET\" # Set whether curl should use secure or insecure mode fi export HTTPS_INSECURE=0 # All Edgegrid API calls are secure edge_endpoint=$(printf \"https://%s/config-dns/v2/zones\" \"$AKAMAI_HOST\") _debug3 \"Edge API Endpoint:\" \"$edge_endpoint\" } _EDGEDNS_getZoneInfo() { _debug \"Getting Zoneinfo\" zoneEnd=false curZone=$1 while [ -n \"$zoneEnd\" ]; do # we can strip the first part of the fulldomain, since its just the _acme-challenge string curZone=\"${curZone#*.}\" # suffix . needed for zone -> domain.tld. # create zone get url get_zone_url=$(printf \"%s/%s\" \"$edge_endpoint\" \"$curZone\") _debug3 \"Zone Get: \" \"${get_zone_url}\" curResult=$(_edgedns_rest GET \"$get_zone_url\") retVal=$? if [ \"$retVal\" -ne 0 ]; then if [ \"$curResult\" = \"FATAL\" ]; then _err \"$(printf \"Fatal error: acme API function call : %s\" \"$retVal\")\" fi if [ \"$curResult\" != \"404\" ]; then _err \"$(printf \"Managed zone validation failed. Error response: %s\" \"$retVal\")\" return 1 fi fi if _contains \"$curResult\" \"\\\"zone\\\":\"; then _debug2 \"Zone data\" \"${curResult}\" zone=$(echo \"${curResult}\" | _egrep_o \"\\\"zone\\\"\\\\s*:\\\\s*\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \"\\\"\") _debug3 \"Zone\" \"${zone}\" zoneEnd=\"\" return 0 fi if [ \"${curZone#*.}\" != \"$curZone\" ]; then _debug3 \"$(printf \"%s still contains a '.' - so we can check next higher level\" \"$curZone\")\" else zoneEnd=true _err \"Couldn't retrieve zone data.\" return 1 fi done _err \"Failed to retrieve zone data.\" return 2 } _edgedns_headers=\"\" _edgedns_rest() { _debug \"Handling API Request\" m=$1 # Assume endpoint is complete path, including query args if applicable ep=$2 body_data=$3 _edgedns_content_type=\"\" _request_url_path=\"$ep\" _request_body=\"$body_data\" _request_method=\"$m\" _edgedns_headers=\"\" tab=\"\" _edgedns_headers=\"${_edgedns_headers}${tab}Host: ${AKAMAI_HOST}\" tab=\"\\t\" # Set in acme.sh _post/_get #_edgedns_headers=\"${_edgedns_headers}${tab}User-Agent:ACME DNSAPI Edge DNS version ${ACME_EDGEDNS_VERSION}\" _edgedns_headers=\"${_edgedns_headers}${tab}Accept: application/json,*/*\" if [ \"$m\" != \"GET\" ] && [ \"$m\" != \"DELETE\" ]; then _edgedns_content_type=\"application/json\" _debug3 \"_request_body\" \"$_request_body\" _body_len=$(echo \"$_request_body\" | tr -d \"\\n\\r\" | awk '{print length}') _edgedns_headers=\"${_edgedns_headers}${tab}Content-Length: ${_body_len}\" fi _edgedns_make_auth_header _edgedns_headers=\"${_edgedns_headers}${tab}Authorization: ${_signed_auth_header}\" _secure_debug2 \"Made Auth Header\" \"$_signed_auth_header\" hdr_indx=1 work_header=\"${_edgedns_headers}${tab}\" _debug3 \"work_header\" \"$work_header\" while [ \"$work_header\" ]; do entry=\"${work_header%%\\\\t*}\" work_header=\"${work_header#*\\\\t}\" export \"$(printf \"_H%s=%s\" \"$hdr_indx\" \"$entry\")\" _debug2 \"Request Header \" \"$entry\" hdr_indx=$((hdr_indx + 1)) done # clear headers from previous request to avoid getting wrong http code on timeouts : >\"$HTTP_HEADER\" _debug2 \"$ep\" if [ \"$m\" != \"GET\" ]; then _debug3 \"Method data\" \"$data\" # body url [needbase64] [POST|PUT|DELETE] [ContentType] response=$(_post \"$_request_body\" \"$ep\" false \"$m\" \"$_edgedns_content_type\") else response=$(_get \"$ep\") fi _ret=\"$?\" if [ \"$_ret\" -ne 0 ]; then _err \"$(printf \"acme.sh API function call failed. Error: %s\" \"$_ret\")\" echo \"FATAL\" return \"$_ret\" fi _debug2 \"response\" \"${response}\" _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" _debug2 \"http response code\" \"$_code\" if [ \"$_code\" = \"200\" ] || [ \"$_code\" = \"201\" ]; then # All good response=\"$(echo \"${response}\" | _normalizeJson)\" echo \"$response\" return 0 fi if [ \"$_code\" = \"204\" ]; then # Success, no body echo \"$_code\" return 0 fi if [ \"$_code\" = \"400\" ]; then _err \"Bad request presented\" _log \"$(printf \"Headers: %s\" \"$_edgedns_headers\")\" _log \"$(printf \"Method: %s\" \"$_request_method\")\" _log \"$(printf \"URL: %s\" \"$ep\")\" _log \"$(printf \"Data: %s\" \"$data\")\" fi if [ \"$_code\" = \"403\" ]; then _err \"access denied make sure your Edgegrid cedentials are correct.\" fi echo \"$_code\" return 1 } _edgedns_eg_timestamp() { _debug \"Generating signature Timestamp\" _debug3 \"Retriving ntp time\" _timeheaders=\"$(_get \"https://www.ntp.org\" \"onlyheader\")\" _debug3 \"_timeheaders\" \"$_timeheaders\" _ntpdate=\"$(echo \"$_timeheaders\" | grep -i \"Date:\" | _head_n 1 | cut -d ':' -f 2- | tr -d \"\\r\\n\")\" _debug3 \"_ntpdate\" \"$_ntpdate\" _ntpdate=\"$(echo \"${_ntpdate}\" | sed -e 's/^[[:space:]]*//')\" _debug3 \"_NTPDATE\" \"$_ntpdate\" _ntptime=\"$(echo \"${_ntpdate}\" | _head_n 1 | cut -d \" \" -f 5 | tr -d \"\\r\\n\")\" _debug3 \"_ntptime\" \"$_ntptime\" _eg_timestamp=$(date -u \"+%Y%m%dT\") _eg_timestamp=\"$(printf \"%s%s+0000\" \"$_eg_timestamp\" \"$_ntptime\")\" _debug \"_eg_timestamp\" \"$_eg_timestamp\" } _edgedns_new_nonce() { _debug \"Generating Nonce\" _nonce=$(echo \"EDGEDNS$(_time)\" | _digest sha1 hex | cut -c 1-32) _debug3 \"_nonce\" \"$_nonce\" } _edgedns_make_auth_header() { _debug \"Constructing Auth Header\" _edgedns_new_nonce _edgedns_eg_timestamp # \"Unsigned authorization header: 'EG1-HMAC-SHA256 client_token=block;access_token=block;timestamp=20200806T14:16:33+0000;nonce=72cde72c-82d9-4721-9854-2ba057929d67;'\" _auth_header=\"$(printf \"EG1-HMAC-SHA256 client_token=%s;access_token=%s;timestamp=%s;nonce=%s;\" \"$AKAMAI_CLIENT_TOKEN\" \"$AKAMAI_ACCESS_TOKEN\" \"$_eg_timestamp\" \"$_nonce\")\" _secure_debug2 \"Unsigned Auth Header: \" \"$_auth_header\" _edgedns_sign_request _signed_auth_header=\"$(printf \"%ssignature=%s\" \"$_auth_header\" \"$_signed_req\")\" _secure_debug2 \"Signed Auth Header: \" \"${_signed_auth_header}\" } _edgedns_sign_request() { _debug2 \"Signing http request\" _edgedns_make_data_to_sign \"$_auth_header\" _secure_debug2 \"Returned signed data\" \"$_mdata\" _edgedns_make_signing_key \"$_eg_timestamp\" _edgedns_base64_hmac_sha256 \"$_mdata\" \"$_signing_key\" _signed_req=\"$_hmac_out\" _secure_debug2 \"Signed Request\" \"$_signed_req\" } _edgedns_make_signing_key() { _debug2 \"Creating sigining key\" ts=$1 _edgedns_base64_hmac_sha256 \"$ts\" \"$AKAMAI_CLIENT_SECRET\" _signing_key=\"$_hmac_out\" _secure_debug2 \"Signing Key\" \"$_signing_key\" } _edgedns_make_data_to_sign() { _debug2 \"Processing data to sign\" hdr=$1 _secure_debug2 \"hdr\" \"$hdr\" _edgedns_make_content_hash path=\"$(echo \"$_request_url_path\" | tr -d \"\\n\\r\" | sed 's/https\\?:\\/\\///')\" path=${path#*\"$AKAMAI_HOST\"} _debug \"hier path\" \"$path\" # dont expose headers to sign so use MT string _mdata=\"$(printf \"%s\\thttps\\t%s\\t%s\\t%s\\t%s\\t%s\" \"$_request_method\" \"$AKAMAI_HOST\" \"$path\" \"\" \"$_hash\" \"$hdr\")\" _secure_debug2 \"Data to Sign\" \"$_mdata\" } _edgedns_make_content_hash() { _debug2 \"Generating content hash\" _hash=\"\" _debug2 \"Request method\" \"${_request_method}\" if [ \"$_request_method\" != \"POST\" ] || [ -z \"$_request_body\" ]; then return 0 fi _debug2 \"Req body\" \"$_request_body\" _edgedns_base64_sha256 \"$_request_body\" _hash=\"$_sha256_out\" _debug2 \"Content hash\" \"$_hash\" } _edgedns_base64_hmac_sha256() { _debug2 \"Generating hmac\" data=$1 key=$2 encoded_data=\"$(echo \"$data\" | iconv -t utf-8)\" encoded_key=\"$(echo \"$key\" | iconv -t utf-8)\" _secure_debug2 \"encoded data\" \"$encoded_data\" _secure_debug2 \"encoded key\" \"$encoded_key\" encoded_key_hex=$(printf \"%s\" \"$encoded_key\" | _hex_dump | tr -d ' ') data_sig=\"$(echo \"$encoded_data\" | tr -d \"\\n\\r\" | _hmac sha256 \"$encoded_key_hex\" | _base64)\" _secure_debug2 \"data_sig:\" \"$data_sig\" _hmac_out=\"$(echo \"$data_sig\" | tr -d \"\\n\\r\" | iconv -f utf-8)\" _secure_debug2 \"hmac\" \"$_hmac_out\" } _edgedns_base64_sha256() { _debug2 \"Creating sha256 digest\" trg=$1 _secure_debug2 \"digest data\" \"$trg\" digest=\"$(echo \"$trg\" | tr -d \"\\n\\r\" | _digest \"sha256\")\" _sha256_out=\"$(echo \"$digest\" | tr -d \"\\n\\r\" | iconv -f utf-8)\" _secure_debug2 \"digest decode\" \"$_sha256_out\" } #_edgedns_parse_edgerc() { # filepath=$1 # section=$2 #}"
        },
        {
            "filename": "file_200.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_200.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_euserv_info='EUserv.com Domains: EUserv.eu Site: EUserv.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_euserv Options: EUSERV_Username Username EUSERV_Password Password Author: Michael Brueckner ' EUSERV_Api=\"https://api.euserv.net\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_euserv_add() { fulldomain=\"$(echo \"$1\" | _lower_case)\" txtvalue=$2 EUSERV_Username=\"${EUSERV_Username:-$(_readaccountconf_mutable EUSERV_Username)}\" EUSERV_Password=\"${EUSERV_Password:-$(_readaccountconf_mutable EUSERV_Password)}\" if [ -z \"$EUSERV_Username\" ] || [ -z \"$EUSERV_Password\" ]; then EUSERV_Username=\"\" EUSERV_Password=\"\" _err \"You don't specify euserv user and password yet.\" _err \"Please create your key and try again.\" return 1 fi #save the user and email to the account conf file. _saveaccountconf_mutable EUSERV_Username \"$EUSERV_Username\" _saveaccountconf_mutable EUSERV_Password \"$EUSERV_Password\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug \"_sub_domain\" \"$_sub_domain\" _debug \"_domain\" \"$_domain\" _info \"Adding record\" if ! _euserv_add_record \"$_domain\" \"$_sub_domain\" \"$txtvalue\"; then return 1 fi } #fulldomain txtvalue dns_euserv_rm() { fulldomain=\"$(echo \"$1\" | _lower_case)\" txtvalue=$2 EUSERV_Username=\"${EUSERV_Username:-$(_readaccountconf_mutable EUSERV_Username)}\" EUSERV_Password=\"${EUSERV_Password:-$(_readaccountconf_mutable EUSERV_Password)}\" if [ -z \"$EUSERV_Username\" ] || [ -z \"$EUSERV_Password\" ]; then EUSERV_Username=\"\" EUSERV_Password=\"\" _err \"You don't specify euserv user and password yet.\" _err \"Please create your key and try again.\" return 1 fi #save the user and email to the account conf file. _saveaccountconf_mutable EUSERV_Username \"$EUSERV_Username\" _saveaccountconf_mutable EUSERV_Password \"$EUSERV_Password\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug \"_sub_domain\" \"$_sub_domain\" _debug \"_domain\" \"$_domain\" _debug \"Getting txt records\" xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>domain.dns_get_active_records</methodName> <params> <param> <value> <struct> <member> <name>login</name> <value> <string>%s</string> </value> </member> <member> <name>password</name> <value> <string>%s</string> </value> </member> <member> <name>domain_id</name> <value> <int>%s</int> </value> </member> </struct> </value> </param> </params> </methodCall>' \"$EUSERV_Username\" \"$EUSERV_Password\" \"$_euserv_domain_id\") export _H1=\"Content-Type: text/xml\" response=\"$(_post \"$xml_content\" \"$EUSERV_Api\" \"\" \"POST\")\" if ! _contains \"$response\" \"<member><name>status</name><value><i4>100</i4></value></member>\"; then _err \"Error could not get txt records\" _debug \"xml_content\" \"$xml_content\" _debug \"response\" \"$response\" return 1 fi if ! echo \"$response\" | grep '>dns_record_content<.*>'\"$txtvalue\"'<' >/dev/null; then _info \"Do not need to delete record\" else # find XML block where txtvalue is in. The record_id is allways prior this line! _endLine=$(echo \"$response\" | grep -n '>dns_record_content<.*>'\"$txtvalue\"'<' | cut -d ':' -f 1) # record_id is the last <name> Tag with a number before the row _endLine, identified by </name><value><struct> _record_id=$(echo \"$response\" | sed -n '1,'\"$_endLine\"'p' | grep '</name><value><struct>' | _tail_n 1 | sed 's/.*<name>\\([0-9]*\\)<\\/name>.*/\\1/') _info \"Deleting record\" _euserv_delete_record \"$_record_id\" fi } #################### Private functions below ################################## _get_root() { domain=$1 _debug \"get root\" # Just to read the domain_orders once domain=$1 i=2 p=1 if ! _euserv_get_domain_orders; then return 1 fi # Get saved response with domain_orders response=\"$_euserv_domain_orders\" while true; do h=$(echo \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"$h\"; then _sub_domain=$(echo \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" if ! _euserv_get_domain_id \"$_domain\"; then _err \"invalid domain\" return 1 fi return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _euserv_get_domain_orders() { # returns: _euserv_domain_orders _debug \"get domain_orders\" xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>domain.get_domain_orders</methodName> <params> <param> <value> <struct> <member> <name>login</name> <value><string>%s</string></value> </member> <member> <name>password</name> <value><string>%s</string></value> </member> </struct> </value> </param> </params> </methodCall>' \"$EUSERV_Username\" \"$EUSERV_Password\") export _H1=\"Content-Type: text/xml\" response=\"$(_post \"$xml_content\" \"$EUSERV_Api\" \"\" \"POST\")\" if ! _contains \"$response\" \"<member><name>status</name><value><i4>100</i4></value></member>\"; then _err \"Error could not get domain orders\" _debug \"xml_content\" \"$xml_content\" _debug \"response\" \"$response\" return 1 fi # save response to reduce API calls _euserv_domain_orders=\"$response\" return 0 } _euserv_get_domain_id() { # returns: _euserv_domain_id domain=$1 _debug \"get domain_id\" # find line where the domain name is within the $response _startLine=$(echo \"$_euserv_domain_orders\" | grep -n '>domain_name<.*>'\"$domain\"'<' | cut -d ':' -f 1) # next occurency of domain_id after the domain_name is the correct one _euserv_domain_id=$(echo \"$_euserv_domain_orders\" | sed -n \"$_startLine\"',$p' | grep '>domain_id<' | _head_n 1 | sed 's/.*<i4>\\([0-9]*\\)<\\/i4>.*/\\1/') if [ -z \"$_euserv_domain_id\" ]; then _err \"Could not find domain_id for domain $domain\" _debug \"_euserv_domain_orders\" \"$_euserv_domain_orders\" return 1 fi return 0 } _euserv_delete_record() { record_id=$1 xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>domain.dns_delete_record</methodName> <params> <param> <value> <struct> <member> <name>login</name> <value> <string>%s</string> </value> </member> <member> <name>password</name> <value> <string>%s</string> </value> </member> <member> <name>dns_record_id</name> <value> <int>%s</int> </value> </member> </struct> </value> </param> </params> </methodCall>' \"$EUSERV_Username\" \"$EUSERV_Password\" \"$record_id\") export _H1=\"Content-Type: text/xml\" response=\"$(_post \"$xml_content\" \"$EUSERV_Api\" \"\" \"POST\")\" if ! _contains \"$response\" \"<member><name>status</name><value><i4>100</i4></value></member>\"; then _err \"Error deleting record\" _debug \"xml_content\" \"$xml_content\" _debug \"response\" \"$response\" return 1 fi return 0 } _euserv_add_record() { domain=$1 sub_domain=$2 txtval=$3 xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>domain.dns_create_record</methodName> <params> <param> <value> <struct> <member> <name>login</name> <value> <string>%s</string> </value> </member> <member> <name>password</name> <value> <string>%s</string></value> </member> <member> <name>domain_id</name> <value> <int>%s</int> </value> </member> <member> <name>dns_record_subdomain</name> <value> <string>%s</string> </value> </member> <member> <name>dns_record_type</name> <value> <string>TXT</string> </value> </member> <member> <name>dns_record_value</name> <value> <string>%s</string> </value> </member> <member> <name>dns_record_ttl</name> <value> <int>300</int> </value> </member> </struct> </value> </param> </params> </methodCall>' \"$EUSERV_Username\" \"$EUSERV_Password\" \"$_euserv_domain_id\" \"$sub_domain\" \"$txtval\") export _H1=\"Content-Type: text/xml\" response=\"$(_post \"$xml_content\" \"$EUSERV_Api\" \"\" \"POST\")\" if ! _contains \"$response\" \"<member><name>status</name><value><i4>100</i4></value></member>\"; then _err \"Error could not create record\" _debug \"xml_content\" \"$xml_content\" _debug \"response\" \"$response\" return 1 fi return 0 }"
        },
        {
            "filename": "file_201.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_201.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_exoscale_info='Exoscale.com Site: Exoscale.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_exoscale Options: EXOSCALE_API_KEY API Key EXOSCALE_SECRET_KEY API Secret key ' EXOSCALE_API=https://api.exoscale.com/dns/v1 ######## Public functions ##################### # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record dns_exoscale_add() { fulldomain=$1 txtvalue=$2 if ! _checkAuth; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if _exoscale_rest POST \"domains/$_domain_id/records\" \"{\\\"record\\\":{\\\"name\\\":\\\"$_sub_domain\\\",\\\"record_type\\\":\\\"TXT\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":120}}\" \"$_domain_token\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"Added, OK\" return 0 fi fi _err \"Add txt record error.\" return 1 } # Usage: fulldomain txtvalue # Used to remove the txt record after validation dns_exoscale_rm() { fulldomain=$1 txtvalue=$2 if ! _checkAuth; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _exoscale_rest GET \"domains/${_domain_id}/records?type=TXT&name=$_sub_domain\" \"\" \"$_domain_token\" if _contains \"$response\" \"\\\"name\\\":\\\"$_sub_domain\\\"\" >/dev/null; then _record_id=$(echo \"$response\" | tr '{' \"\\n\" | grep \"\\\"content\\\":\\\"$txtvalue\\\"\" | _egrep_o \"\\\"id\\\":[^,]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") fi if [ -z \"$_record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi _debug \"Deleting record $_record_id\" if ! _exoscale_rest DELETE \"domains/$_domain_id/records/$_record_id\" \"\" \"$_domain_token\"; then _err \"Delete record error.\" return 1 fi return 0 } #################### Private functions below ################################## _checkAuth() { EXOSCALE_API_KEY=\"${EXOSCALE_API_KEY:-$(_readaccountconf_mutable EXOSCALE_API_KEY)}\" EXOSCALE_SECRET_KEY=\"${EXOSCALE_SECRET_KEY:-$(_readaccountconf_mutable EXOSCALE_SECRET_KEY)}\" if [ -z \"$EXOSCALE_API_KEY\" ] || [ -z \"$EXOSCALE_SECRET_KEY\" ]; then EXOSCALE_API_KEY=\"\" EXOSCALE_SECRET_KEY=\"\" _err \"You don't specify Exoscale application key and application secret yet.\" _err \"Please create you key and try again.\" return 1 fi _saveaccountconf_mutable EXOSCALE_API_KEY \"$EXOSCALE_API_KEY\" _saveaccountconf_mutable EXOSCALE_SECRET_KEY \"$EXOSCALE_SECRET_KEY\" return 0 } #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg # _domain_token=sdjkglgdfewsdfg _get_root() { if ! _exoscale_rest GET \"domains\"; then return 1 fi domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" >/dev/null; then _domain_id=$(echo \"$response\" | tr '{' \"\\n\" | grep \"\\\"name\\\":\\\"$h\\\"\" | _egrep_o \"\\\"id\\\":[^,]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") _domain_token=$(echo \"$response\" | tr '{' \"\\n\" | grep \"\\\"name\\\":\\\"$h\\\"\" | _egrep_o \"\\\"token\\\":\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") if [ \"$_domain_token\" ] && [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } # returns response _exoscale_rest() { method=$1 path=\"$2\" data=\"$3\" token=\"$4\" request_url=\"$EXOSCALE_API/$path\" _debug \"$path\" export _H1=\"Accept: application/json\" if [ \"$token\" ]; then export _H2=\"X-DNS-Domain-Token: $token\" else export _H2=\"X-DNS-Token: $EXOSCALE_API_KEY:$EXOSCALE_SECRET_KEY\" fi if [ \"$data\" ] || [ \"$method\" = \"DELETE\" ]; then export _H3=\"Content-Type: application/json\" _debug data \"$data\" response=\"$(_post \"$data\" \"$request_url\" \"\" \"$method\")\" else response=\"$(_get \"$request_url\" \"\" \"\" \"$method\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $request_url\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_202.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_202.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_fornex_info='Fornex.com Site: Fornex.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_fornex Options: FORNEX_API_KEY API Key Issues: github.com/acmesh-official/acme.sh/issues/3998 Author: Timur Umarov <inbox@tumarov.com> ' FORNEX_API_URL=\"https://fornex.com/api/dns/v0.1\" ######## Public functions ##################### #Usage: dns_fornex_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_fornex_add() { fulldomain=$1 txtvalue=$2 if ! _Fornex_API; then return 1 fi if ! _get_root \"$fulldomain\"; then _err \"Unable to determine root domain\" return 1 else _debug _domain \"$_domain\" fi _info \"Adding record\" if _rest POST \"$_domain/entry_set/add/\" \"host=$fulldomain&type=TXT&value=$txtvalue&apikey=$FORNEX_API_KEY\"; then _debug _response \"$response\" if _contains \"$response\" '\"ok\": true' || _contains \"$response\" '\u0422\u0430\u043a\u0430\u044f \u0437\u0430\u043f\u0438\u0441\u044c \u0443\u0436\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442.'; then _info \"Added, OK\" return 0 fi fi _err \"Add txt record error.\" return 1 } #Usage: dns_fornex_rm _acme-challenge.www.domain.com dns_fornex_rm() { fulldomain=$1 txtvalue=$2 if ! _Fornex_API; then return 1 fi if ! _get_root \"$fulldomain\"; then _err \"Unable to determine root domain\" return 1 else _debug _domain \"$_domain\" fi _debug \"Getting txt records\" _rest GET \"$_domain/entry_set.json?apikey=$FORNEX_API_KEY\" if ! _contains \"$response\" \"$txtvalue\"; then _err \"Txt record not found\" return 1 fi _record_id=\"$(echo \"$response\" | _egrep_o \"{[^{]*\\\"value\\\"*:*\\\"$txtvalue\\\"[^}]*}\" | sed -n -e 's#.*\"id\": \\([0-9]*\\).*#\\1#p')\" _debug \"_record_id\" \"$_record_id\" if [ -z \"$_record_id\" ]; then _err \"can not find _record_id\" return 1 fi if ! _rest POST \"$_domain/entry_set/$_record_id/delete/\" \"apikey=$FORNEX_API_KEY\"; then _err \"Delete record error.\" return 1 fi return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _rest GET \"domain_list.json?q=$h&apikey=$FORNEX_API_KEY\"; then return 1 fi if _contains \"$response\" \"\\\"$h\\\"\" >/dev/null; then _domain=$h return 0 else _debug \"$h not found\" fi i=$(_math \"$i\" + 1) done return 1 } _Fornex_API() { FORNEX_API_KEY=\"${FORNEX_API_KEY:-$(_readaccountconf_mutable FORNEX_API_KEY)}\" if [ -z \"$FORNEX_API_KEY\" ]; then FORNEX_API_KEY=\"\" _err \"You didn't specify the Fornex API key yet.\" _err \"Please create your key and try again.\" return 1 fi _saveaccountconf_mutable FORNEX_API_KEY \"$FORNEX_API_KEY\" } #method method action data _rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Accept: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$FORNEX_API_URL/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$FORNEX_API_URL/$ep\" | _normalizeJson)\" fi _ret=\"$?\" if [ \"$_ret\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_203.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_203.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_freedns_info='FreeDNS Site: FreeDNS.afraid.org Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_freedns Options: FREEDNS_User Username FREEDNS_Password Password Issues: github.com/acmesh-official/acme.sh/issues/2305 Author: David Kerr <https://github.com/dkerr64> ' ######## Public functions ##################### # Export FreeDNS userid and password in following variables... # FREEDNS_User=username # FREEDNS_Password=password # login cookie is saved in acme account config file so userid / pw # need to be set only when changed. #Usage: dns_freedns_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_freedns_add() { fulldomain=\"$1\" txtvalue=\"$2\" _info \"Add TXT record using FreeDNS\" _debug \"fulldomain: $fulldomain\" _debug \"txtvalue: $txtvalue\" if [ -z \"$FREEDNS_User\" ] || [ -z \"$FREEDNS_Password\" ]; then FREEDNS_User=\"\" FREEDNS_Password=\"\" if [ -z \"$FREEDNS_COOKIE\" ]; then _err \"You did not specify the FreeDNS username and password yet.\" _err \"Please export as FREEDNS_User / FREEDNS_Password and try again.\" return 1 fi using_cached_cookies=\"true\" else FREEDNS_COOKIE=\"$(_freedns_login \"$FREEDNS_User\" \"$FREEDNS_Password\")\" if [ -z \"$FREEDNS_COOKIE\" ]; then return 1 fi using_cached_cookies=\"false\" fi _debug \"FreeDNS login cookies: $FREEDNS_COOKIE (cached = $using_cached_cookies)\" _saveaccountconf FREEDNS_COOKIE \"$FREEDNS_COOKIE\" # We may have to cycle through the domain name to find the # TLD that we own... i=1 wmax=\"$(echo \"$fulldomain\" | tr '.' ' ' | wc -w)\" while [ \"$i\" -lt \"$wmax\" ]; do # split our full domain name into two parts... sub_domain=\"$(echo \"$fulldomain\" | cut -d. -f -\"$i\")\" i=\"$(_math \"$i\" + 1)\" top_domain=\"$(echo \"$fulldomain\" | cut -d. -f \"$i\"-100)\" _debug \"sub_domain: $sub_domain\" _debug \"top_domain: $top_domain\" DNSdomainid=\"$(_freedns_domain_id \"$top_domain\")\" if [ \"$?\" = \"0\" ]; then _info \"Domain $top_domain found at FreeDNS, domain_id $DNSdomainid\" break else _info \"Domain $top_domain not found at FreeDNS, try with next level of TLD\" fi done if [ -z \"$DNSdomainid\" ]; then # If domain ID is empty then something went wrong (top level # domain not found at FreeDNS). _err \"Domain $top_domain not found at FreeDNS\" return 1 fi # Add in new TXT record with the value provided _debug \"Adding TXT record for $fulldomain, $txtvalue\" _freedns_add_txt_record \"$FREEDNS_COOKIE\" \"$DNSdomainid\" \"$sub_domain\" \"$txtvalue\" return $? } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_freedns_rm() { fulldomain=\"$1\" txtvalue=\"$2\" _info \"Delete TXT record using FreeDNS\" _debug \"fulldomain: $fulldomain\" _debug \"txtvalue: $txtvalue\" # Need to read cookie from conf file again in case new value set # during login to FreeDNS when TXT record was created. FREEDNS_COOKIE=\"$(_readaccountconf \"FREEDNS_COOKIE\")\" _debug \"FreeDNS login cookies: $FREEDNS_COOKIE\" TXTdataid=\"$(_freedns_data_id \"$fulldomain\" \"TXT\")\" if [ \"$?\" != \"0\" ]; then _info \"Cannot delete TXT record for $fulldomain, record does not exist at FreeDNS\" return 1 fi _debug \"Data ID's found, $TXTdataid\" # now we have one (or more) TXT record data ID's. Load the page # for that record and search for the record txt value. If match # then we can delete it. lines=\"$(echo \"$TXTdataid\" | wc -l)\" _debug \"Found $lines TXT data records for $fulldomain\" i=0 while [ \"$i\" -lt \"$lines\" ]; do i=\"$(_math \"$i\" + 1)\" dataid=\"$(echo \"$TXTdataid\" | sed -n \"${i}p\")\" _debug \"$dataid\" htmlpage=\"$(_freedns_retrieve_data_page \"$FREEDNS_COOKIE\" \"$dataid\")\" if [ \"$?\" != \"0\" ]; then if [ \"$using_cached_cookies\" = \"true\" ]; then _err \"Has your FreeDNS username and password changed? If so...\" _err \"Please export as FREEDNS_User / FREEDNS_Password and try again.\" fi return 1 fi echo \"$htmlpage\" | grep \"value=\\\"&quot;$txtvalue&quot;\\\"\" >/dev/null if [ \"$?\" = \"0\" ]; then # Found a match... delete the record and return _info \"Deleting TXT record for $fulldomain, $txtvalue\" _freedns_delete_txt_record \"$FREEDNS_COOKIE\" \"$dataid\" return $? fi done # If we get this far we did not find a match # Not necessarily an error, but log anyway. _info \"Cannot delete TXT record for $fulldomain, $txtvalue. Does not exist at FreeDNS\" return 0 } #################### Private functions below ################################## # usage: _freedns_login username password # print string \"cookie=value\" etc. # returns 0 success _freedns_login() { export _H1=\"Accept-Language:en-US\" username=\"$1\" password=\"$2\" url=\"https://freedns.afraid.org/zc.php?step=2\" _debug \"Login to FreeDNS as user $username\" htmlpage=\"$(_post \"username=$(printf '%s' \"$username\" | _url_encode)&password=$(printf '%s' \"$password\" | _url_encode)&submit=Login&action=auth\" \"$url\")\" if [ \"$?\" != \"0\" ]; then _err \"FreeDNS login failed for user $username bad RC from _post\" return 1 fi cookies=\"$(grep -i '^Set-Cookie.*dns_cookie.*$' \"$HTTP_HEADER\" | _head_n 1 | tr -d \"\\r\\n\" | cut -d \" \" -f 2)\" # if cookies is not empty then logon successful if [ -z \"$cookies\" ]; then _debug3 \"htmlpage: $htmlpage\" _err \"FreeDNS login failed for user $username. Check $HTTP_HEADER file\" return 1 fi printf \"%s\" \"$cookies\" return 0 } # usage _freedns_retrieve_subdomain_page login_cookies # echo page retrieved (html) # returns 0 success _freedns_retrieve_subdomain_page() { export _H1=\"Cookie:$1\" export _H2=\"Accept-Language:en-US\" url=\"https://freedns.afraid.org/subdomain/\" _debug \"Retrieve subdomain page from FreeDNS\" htmlpage=\"$(_get \"$url\")\" if [ \"$?\" != \"0\" ]; then _err \"FreeDNS retrieve subdomains failed bad RC from _get\" return 1 elif [ -z \"$htmlpage\" ]; then _err \"FreeDNS returned empty subdomain page\" return 1 fi _debug3 \"htmlpage: $htmlpage\" printf \"%s\" \"$htmlpage\" return 0 } # usage _freedns_retrieve_data_page login_cookies data_id # echo page retrieved (html) # returns 0 success _freedns_retrieve_data_page() { export _H1=\"Cookie:$1\" export _H2=\"Accept-Language:en-US\" data_id=\"$2\" url=\"https://freedns.afraid.org/subdomain/edit.php?data_id=$2\" _debug \"Retrieve data page for ID $data_id from FreeDNS\" htmlpage=\"$(_get \"$url\")\" if [ \"$?\" != \"0\" ]; then _err \"FreeDNS retrieve data page failed bad RC from _get\" return 1 elif [ -z \"$htmlpage\" ]; then _err \"FreeDNS returned empty data page\" return 1 fi _debug3 \"htmlpage: $htmlpage\" printf \"%s\" \"$htmlpage\" return 0 } # usage _freedns_add_txt_record login_cookies domain_id subdomain value # returns 0 success _freedns_add_txt_record() { export _H1=\"Cookie:$1\" export _H2=\"Accept-Language:en-US\" domain_id=\"$2\" subdomain=\"$3\" value=\"$(printf '%s' \"$4\" | _url_encode)\" url=\"https://freedns.afraid.org/subdomain/save.php?step=2\" htmlpage=\"$(_post \"type=TXT&domain_id=$domain_id&subdomain=$subdomain&address=%22$value%22&send=Save%21\" \"$url\")\" if [ \"$?\" != \"0\" ]; then _err \"FreeDNS failed to add TXT record for $subdomain bad RC from _post\" return 1 elif ! grep \"200 OK\" \"$HTTP_HEADER\" >/dev/null; then _debug3 \"htmlpage: $htmlpage\" _err \"FreeDNS failed to add TXT record for $subdomain. Check $HTTP_HEADER file\" return 1 elif _contains \"$htmlpage\" \"security code was incorrect\"; then _debug3 \"htmlpage: $htmlpage\" _err \"FreeDNS failed to add TXT record for $subdomain as FreeDNS requested security code\" _err \"Note that you cannot use automatic DNS validation for FreeDNS public domains\" return 1 fi _debug3 \"htmlpage: $htmlpage\" _info \"Added acme challenge TXT record for $fulldomain at FreeDNS\" return 0 } # usage _freedns_delete_txt_record login_cookies data_id # returns 0 success _freedns_delete_txt_record() { export _H1=\"Cookie:$1\" export _H2=\"Accept-Language:en-US\" data_id=\"$2\" url=\"https://freedns.afraid.org/subdomain/delete2.php\" htmlheader=\"$(_get \"$url?data_id%5B%5D=$data_id&submit=delete+selected\" \"onlyheader\")\" if [ \"$?\" != \"0\" ]; then _err \"FreeDNS failed to delete TXT record for $data_id bad RC from _get\" return 1 elif ! _contains \"$htmlheader\" \"200 OK\"; then _debug2 \"htmlheader: $htmlheader\" _err \"FreeDNS failed to delete TXT record $data_id\" return 1 fi _info \"Deleted acme challenge TXT record for $fulldomain at FreeDNS\" return 0 } # usage _freedns_domain_id domain_name # echo the domain_id if found # return 0 success _freedns_domain_id() { # Start by escaping the dots in the domain name search_domain=\"$(echo \"$1\" | sed 's/\\./\\\\./g')\" # Sometimes FreeDNS does not return the subdomain page but rather # returns a page regarding becoming a premium member. This usually # happens after a period of inactivity. Immediately trying again # returns the correct subdomain page. So, we will try twice to # load the page and obtain our domain ID attempts=2 while [ \"$attempts\" -gt \"0\" ]; do attempts=\"$(_math \"$attempts\" - 1)\" htmlpage=\"$(_freedns_retrieve_subdomain_page \"$FREEDNS_COOKIE\")\" if [ \"$?\" != \"0\" ]; then if [ \"$using_cached_cookies\" = \"true\" ]; then _err \"Has your FreeDNS username and password changed? If so...\" _err \"Please export as FREEDNS_User / FREEDNS_Password and try again.\" fi return 1 fi domain_id=\"$(echo \"$htmlpage\" | tr -d \" \\t\\r\\n\\v\\f\" | sed 's/<tr>/@<tr>/g' | tr '@' '\\n' | grep \"<td>$search_domain</td>\\|<td>$search_domain(.*)</td>\" | sed -n 's/.*\\(edit\\.php?edit_domain_id=[0-9a-zA-Z]*\\).*/\\1/p' | cut -d = -f 2)\" # The above beauty extracts domain ID from the html page... # strip out all blank space and new lines. Then insert newlines # before each table row <tr> # search for the domain within each row (which may or may not have # a text string in brackets (.*) after it. # And finally extract the domain ID. if [ -n \"$domain_id\" ]; then printf \"%s\" \"$domain_id\" return 0 fi _debug \"Domain $search_domain not found. Retry loading subdomain page ($attempts attempts remaining)\" done _debug \"Domain $search_domain not found after retry\" return 1 } # usage _freedns_data_id domain_name record_type # echo the data_id(s) if found # return 0 success _freedns_data_id() { # Start by escaping the dots in the domain name search_domain=\"$(echo \"$1\" | sed 's/\\./\\\\./g')\" record_type=\"$2\" # Sometimes FreeDNS does not return the subdomain page but rather # returns a page regarding becoming a premium member. This usually # happens after a period of inactivity. Immediately trying again # returns the correct subdomain page. So, we will try twice to # load the page and obtain our domain ID attempts=2 while [ \"$attempts\" -gt \"0\" ]; do attempts=\"$(_math \"$attempts\" - 1)\" htmlpage=\"$(_freedns_retrieve_subdomain_page \"$FREEDNS_COOKIE\")\" if [ \"$?\" != \"0\" ]; then if [ \"$using_cached_cookies\" = \"true\" ]; then _err \"Has your FreeDNS username and password changed? If so...\" _err \"Please export as FREEDNS_User / FREEDNS_Password and try again.\" fi return 1 fi data_id=\"$(echo \"$htmlpage\" | tr -d \" \\t\\r\\n\\v\\f\" | sed 's/<tr>/@<tr>/g' | tr '@' '\\n' | grep \"<td[a-zA-Z=#]*>$record_type</td>\" | grep \"<ahref.*>$search_domain</a>\" | sed -n 's/.*\\(edit\\.php?data_id=[0-9a-zA-Z]*\\).*/\\1/p' | cut -d = -f 2)\" # The above beauty extracts data ID from the html page... # strip out all blank space and new lines. Then insert newlines # before each table row <tr> # search for the record type withing each row (e.g. TXT) # search for the domain within each row (which is within a <a..> # </a> anchor. And finally extract the domain ID. if [ -n \"$data_id\" ]; then printf \"%s\" \"$data_id\" return 0 fi _debug \"Domain $search_domain not found. Retry loading subdomain page ($attempts attempts remaining)\" done _debug \"Domain $search_domain not found after retry\" return 1 }"
        },
        {
            "filename": "file_204.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_204.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_gandi_livedns_info='Gandi.net LiveDNS Site: Gandi.net/domain/dns Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_gandi_livedns Options: GANDI_LIVEDNS_KEY API Key Issues: github.com/fcrozat/acme.sh Author: Fr\u00e9d\u00e9ric Crozat <fcrozat@suse.com>, Dominik R\u00f6ttsches <drott@google.com> ' # Gandi LiveDNS v5 API # https://api.gandi.net/docs/livedns/ # https://api.gandi.net/docs/authentication/ for token + apikey (deprecated) authentication # currently under beta ######## Public functions ##################### GANDI_LIVEDNS_API=\"https://api.gandi.net/v5/livedns\" #Usage: dns_gandi_livedns_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_gandi_livedns_add() { fulldomain=$1 txtvalue=$2 if [ -z \"$GANDI_LIVEDNS_KEY\" ] && [ -z \"$GANDI_LIVEDNS_TOKEN\" ]; then _err \"No Token or API key (deprecated) specified for Gandi LiveDNS.\" _err \"Create your token or key and export it as GANDI_LIVEDNS_KEY or GANDI_LIVEDNS_TOKEN respectively\" return 1 fi # Keep only one secret in configuration if [ -n \"$GANDI_LIVEDNS_TOKEN\" ]; then _saveaccountconf GANDI_LIVEDNS_TOKEN \"$GANDI_LIVEDNS_TOKEN\" _clearaccountconf GANDI_LIVEDNS_KEY elif [ -n \"$GANDI_LIVEDNS_KEY\" ]; then _saveaccountconf GANDI_LIVEDNS_KEY \"$GANDI_LIVEDNS_KEY\" _clearaccountconf GANDI_LIVEDNS_TOKEN fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug domain \"$_domain\" _debug sub_domain \"$_sub_domain\" _dns_gandi_append_record \"$_domain\" \"$_sub_domain\" \"$txtvalue\" } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_gandi_livedns_rm() { fulldomain=$1 txtvalue=$2 _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug fulldomain \"$fulldomain\" _debug domain \"$_domain\" _debug sub_domain \"$_sub_domain\" _debug txtvalue \"$txtvalue\" if ! _dns_gandi_existing_rrset_values \"$_domain\" \"$_sub_domain\"; then return 1 fi _new_rrset_values=$(echo \"$_rrset_values\" | sed \"s/...$txtvalue...//g\") # Cleanup dangling commata. _new_rrset_values=$(echo \"$_new_rrset_values\" | sed \"s/, ,/ ,/g\") _new_rrset_values=$(echo \"$_new_rrset_values\" | sed \"s/, *\\]/\\]/g\") _new_rrset_values=$(echo \"$_new_rrset_values\" | sed \"s/\\[ *,/\\[/g\") _debug \"New rrset_values\" \"$_new_rrset_values\" _gandi_livedns_rest PUT \\ \"domains/$_domain/records/$_sub_domain/TXT\" \\ \"{\\\"rrset_ttl\\\": 300, \\\"rrset_values\\\": $_new_rrset_values}\" && _contains \"$response\" '{\"message\":\"DNS Record Created\"}' && _info \"Removing record $(__green \"success\")\" } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _gandi_livedns_rest GET \"domains/$h\"; then return 1 fi if _contains \"$response\" '\"code\": 401'; then _err \"$response\" return 1 elif _contains \"$response\" '\"code\": 404'; then _debug \"$h not found\" else _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } _dns_gandi_append_record() { domain=$1 sub_domain=$2 txtvalue=$3 if _dns_gandi_existing_rrset_values \"$domain\" \"$sub_domain\"; then _debug \"Appending new value\" _rrset_values=$(echo \"$_rrset_values\" | sed \"s/\\\"]/\\\",\\\"$txtvalue\\\"]/\") else _debug \"Creating new record\" \"$_rrset_values\" _rrset_values=\"[\\\"$txtvalue\\\"]\" fi _debug new_rrset_values \"$_rrset_values\" _gandi_livedns_rest PUT \"domains/$_domain/records/$sub_domain/TXT\" \\ \"{\\\"rrset_ttl\\\": 300, \\\"rrset_values\\\": $_rrset_values}\" && _contains \"$response\" '{\"message\":\"DNS Record Created\"}' && _info \"Adding record $(__green \"success\")\" } _dns_gandi_existing_rrset_values() { domain=$1 sub_domain=$2 if ! _gandi_livedns_rest GET \"domains/$domain/records/$sub_domain\"; then return 1 fi if ! _contains \"$response\" '\"rrset_type\":\"TXT\"'; then _debug \"Does not have a _acme-challenge TXT record yet.\" return 1 fi if _contains \"$response\" '\"rrset_values\":\\[\\]'; then _debug \"Empty rrset_values for TXT record, no previous TXT record.\" return 1 fi _debug \"Already has TXT record.\" _rrset_values=$(echo \"$response\" | _egrep_o 'rrset_values.*\\[.*\\]' | _egrep_o '\\[\".*\\\"]') return 0 } _gandi_livedns_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Content-Type: application/json\" if [ -n \"$GANDI_LIVEDNS_TOKEN\" ]; then export _H2=\"Authorization: Bearer $GANDI_LIVEDNS_TOKEN\" else export _H2=\"Authorization: Apikey $GANDI_LIVEDNS_KEY\" fi if [ \"$m\" = \"GET\" ]; then response=\"$(_get \"$GANDI_LIVEDNS_API/$ep\")\" else _debug data \"$data\" response=\"$(_post \"$data\" \"$GANDI_LIVEDNS_API/$ep\" \"\" \"$m\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_205.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_205.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_gcloud_info='Google Cloud DNS Site: Cloud.Google.com/dns Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_gcloud Options: CLOUDSDK_ACTIVE_CONFIG_NAME Active config name. E.g. \"default\" Author: Janos Lenart <janos@lenart.io> ' ######## Public functions ##################### # Usage: dns_gcloud_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_gcloud_add() { fulldomain=$1 txtvalue=$2 _info \"Using gcloud\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _dns_gcloud_find_zone || return $? # Add an extra RR _dns_gcloud_start_tr || return $? _dns_gcloud_get_rrdatas || return $? echo \"$rrdatas\" | _dns_gcloud_remove_rrs || return $? printf \"%s\\n%s\\n\" \"$rrdatas\" \"\\\"$txtvalue\\\"\" | grep -v '^$' | _dns_gcloud_add_rrs || return $? _dns_gcloud_execute_tr || return $? _info \"$fulldomain record added\" } # Usage: dns_gcloud_rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Remove the txt record after validation. dns_gcloud_rm() { fulldomain=$1 txtvalue=$2 _info \"Using gcloud\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _dns_gcloud_find_zone || return $? # Remove one RR _dns_gcloud_start_tr || return $? _dns_gcloud_get_rrdatas || return $? echo \"$rrdatas\" | _dns_gcloud_remove_rrs || return $? echo \"$rrdatas\" | grep -F -v -- \"\\\"$txtvalue\\\"\" | _dns_gcloud_add_rrs || return $? _dns_gcloud_execute_tr || return $? _info \"$fulldomain record removed\" } #################### Private functions below ################################## _dns_gcloud_start_tr() { if ! trd=$(mktemp -d); then _err \"_dns_gcloud_start_tr: failed to create temporary directory\" return 1 fi tr=\"$trd/tr.yaml\" _debug tr \"$tr\" if ! gcloud dns record-sets transaction start \\ --transaction-file=\"$tr\" \\ --zone=\"$managedZone\"; then rm -r \"$trd\" _err \"_dns_gcloud_start_tr: failed to execute transaction\" return 1 fi } _dns_gcloud_execute_tr() { if ! gcloud dns record-sets transaction execute \\ --transaction-file=\"$tr\" \\ --zone=\"$managedZone\"; then _debug tr \"$(cat \"$tr\")\" rm -r \"$trd\" _err \"_dns_gcloud_execute_tr: failed to execute transaction\" return 1 fi rm -r \"$trd\" for i in $(seq 1 120); do if gcloud dns record-sets changes list \\ --zone=\"$managedZone\" \\ --filter='status != done' | grep -q '^.*'; then _info \"_dns_gcloud_execute_tr: waiting for transaction to be comitted ($i/120)...\" sleep 5 else return 0 fi done _err \"_dns_gcloud_execute_tr: transaction is still pending after 10 minutes\" rm -r \"$trd\" return 1 } _dns_gcloud_remove_rrs() { if ! xargs -r gcloud dns record-sets transaction remove \\ --name=\"$fulldomain.\" \\ --ttl=\"$ttl\" \\ --type=TXT \\ --zone=\"$managedZone\" \\ --transaction-file=\"$tr\" --; then _debug tr \"$(cat \"$tr\")\" rm -r \"$trd\" _err \"_dns_gcloud_remove_rrs: failed to remove RRs\" return 1 fi } _dns_gcloud_add_rrs() { ttl=60 if ! xargs -r gcloud dns record-sets transaction add \\ --name=\"$fulldomain.\" \\ --ttl=\"$ttl\" \\ --type=TXT \\ --zone=\"$managedZone\" \\ --transaction-file=\"$tr\" --; then _debug tr \"$(cat \"$tr\")\" rm -r \"$trd\" _err \"_dns_gcloud_add_rrs: failed to add RRs\" return 1 fi } _dns_gcloud_find_zone() { # Prepare a filter that matches zones that are suiteable for this entry. # For example, _acme-challenge.something.domain.com might need to go into something.domain.com or domain.com; # this function finds the longest postfix that has a managed zone. part=\"$fulldomain\" filter=\"dnsName=( \" while [ \"$part\" != \"\" ]; do filter=\"$filter$part. \" part=\"$(echo \"$part\" | sed 's/[^.]*\\.*//')\" done filter=\"$filter) AND visibility=public\" _debug filter \"$filter\" # List domains and find the zone with the deepest sub-domain (in case of some levels of delegation) if ! match=$(gcloud dns managed-zones list \\ --format=\"value(name, dnsName)\" \\ --filter=\"$filter\" | while read -r dnsName name; do printf \"%s\\t%s\\t%s\\n\" \"$(echo \"$name\" | awk -F\".\" '{print NF-1}')\" \"$dnsName\" \"$name\" done | sort -n -r | _head_n 1 | cut -f2,3 | grep '^.*'); then _err \"_dns_gcloud_find_zone: Can't find a matching managed zone! Perhaps wrong project or gcloud credentials?\" return 1 fi dnsName=$(echo \"$match\" | cut -f2) _debug dnsName \"$dnsName\" managedZone=$(echo \"$match\" | cut -f1) _debug managedZone \"$managedZone\" } _dns_gcloud_get_rrdatas() { if ! rrdatas=$(gcloud dns record-sets list \\ --zone=\"$managedZone\" \\ --name=\"$fulldomain.\" \\ --type=TXT \\ --format=\"value(ttl,rrdatas)\"); then _err \"_dns_gcloud_get_rrdatas: Failed to list record-sets\" rm -r \"$trd\" return 1 fi ttl=$(echo \"$rrdatas\" | cut -f1) # starting with version 353.0.0 gcloud seems to # separate records with a semicolon instead of commas # see also https://cloud.google.com/sdk/docs/release-notes#35300_2021-08-17 rrdatas=$(echo \"$rrdatas\" | cut -f2 | sed 's/\"[,;]\"/\"\\n\"/g') }"
        },
        {
            "filename": "file_206.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_206.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_gcore_info='Gcore.com Site: Gcore.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_gcore Options: GCORE_Key API Key Issues: github.com/acmesh-official/acme.sh/issues/4460 ' GCORE_Api=\"https://api.gcore.com/dns/v2\" GCORE_Doc=\"https://api.gcore.com/docs/dns\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_gcore_add() { fulldomain=$1 txtvalue=$2 GCORE_Key=\"${GCORE_Key:-$(_readaccountconf_mutable GCORE_Key)}\" if [ -z \"$GCORE_Key\" ]; then GCORE_Key=\"\" _err \"You didn't specify a Gcore api key yet.\" _err \"You can get yours from here $GCORE_Doc\" return 1 fi #save the api key to the account conf file. _saveaccountconf_mutable GCORE_Key \"$GCORE_Key\" \"base64\" _debug \"First detect the zone name\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _zone_name \"$_zone_name\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _gcore_rest GET \"zones/$_zone_name/$fulldomain/TXT\" payload=\"\" if echo \"$response\" | grep \"record is not found\" >/dev/null; then _info \"Record doesn't exists\" payload=\"{\\\"resource_records\\\":[{\\\"content\\\":[\\\"$txtvalue\\\"],\\\"enabled\\\":true}],\\\"ttl\\\":120}\" elif echo \"$response\" | grep \"$txtvalue\" >/dev/null; then _info \"Already exists, OK\" return 0 elif echo \"$response\" | tr -d \" \" | grep \\\"name\\\":\\\"\"$fulldomain\"\\\",\\\"type\\\":\\\"TXT\\\" >/dev/null; then _info \"Record with mismatch txtvalue, try update it\" payload=$(echo \"$response\" | tr -d \" \" | sed 's/\"updated_at\":[0-9]\\+,//g' | sed 's/\"meta\":{}}]}/\"meta\":{}},{\"content\":['\\\"\"$txtvalue\"\\\"'],\"enabled\":true}]}/') fi # For wildcard cert, the main root domain and the wildcard domain have the same txt subdomain name, so # we can not use updating anymore. # count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"count\\\":[^,]*\" | cut -d : -f 2) # _debug count \"$count\" # if [ \"$count\" = \"0\" ]; then _info \"Adding record\" if _gcore_rest PUT \"zones/$_zone_name/$fulldomain/TXT\" \"$payload\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"Added, OK\" return 0 elif _contains \"$response\" \"rrset is already exists\"; then _info \"Already exists, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_gcore_rm() { fulldomain=$1 txtvalue=$2 GCORE_Key=\"${GCORE_Key:-$(_readaccountconf_mutable GCORE_Key)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _zone_name \"$_zone_name\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _gcore_rest GET \"zones/$_zone_name/$fulldomain/TXT\" if echo \"$response\" | grep \"record is not found\" >/dev/null; then _info \"No such txt recrod\" return 0 fi if ! echo \"$response\" | tr -d \" \" | grep \\\"name\\\":\\\"\"$fulldomain\"\\\",\\\"type\\\":\\\"TXT\\\" >/dev/null; then _err \"Error: $response\" return 1 fi if ! echo \"$response\" | tr -d \" \" | grep \\\"\"$txtvalue\"\\\" >/dev/null; then _info \"No such txt recrod\" return 0 fi count=\"$(echo \"$response\" | grep -o \"content\" | wc -l)\" if [ \"$count\" = \"1\" ]; then if ! _gcore_rest DELETE \"zones/$_zone_name/$fulldomain/TXT\"; then _err \"Delete record error. $response\" return 1 fi return 0 fi payload=\"$(echo \"$response\" | tr -d \" \" | sed 's/\"updated_at\":[0-9]\\+,//g' | sed 's/{\"id\":[0-9]\\+,\"content\":\\[\"'\"$txtvalue\"'\"\\],\"enabled\":true,\"meta\":{}}//' | sed 's/\\[,/\\[/' | sed 's/,,/,/' | sed 's/,\\]/\\]/')\" if ! _gcore_rest PUT \"zones/$_zone_name/$fulldomain/TXT\" \"$payload\"; then _err \"Delete record error. $response\" fi } #################### Private functions below ################################## #_acme-challenge.sub.domain.com #returns # _sub_domain=_acme-challenge.sub or _acme-challenge # _domain=domain.com # _zone_name=domain.com or sub.domain.com _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _gcore_rest GET \"zones/$h\"; then return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\"; then _zone_name=$h if [ \"$_zone_name\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _gcore_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" key_trimmed=$(echo \"$GCORE_Key\" | tr -d '\"') export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: APIKey $key_trimmed\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$GCORE_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$GCORE_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_207.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_207.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_gd_info='GoDaddy.com Site: GoDaddy.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_gd Options: GD_Key API Key GD_Secret API Secret ' GD_Api=\"https://api.godaddy.com/v1\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_gd_add() { fulldomain=$1 txtvalue=$2 GD_Key=\"${GD_Key:-$(_readaccountconf_mutable GD_Key)}\" GD_Secret=\"${GD_Secret:-$(_readaccountconf_mutable GD_Secret)}\" if [ -z \"$GD_Key\" ] || [ -z \"$GD_Secret\" ]; then GD_Key=\"\" GD_Secret=\"\" _err \"You didn't specify godaddy api key and secret yet.\" _err \"Please create your key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable GD_Key \"$GD_Key\" _saveaccountconf_mutable GD_Secret \"$GD_Secret\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting existing records\" if ! _gd_rest GET \"domains/$_domain/records/TXT/$_sub_domain\"; then return 1 fi if _contains \"$response\" \"$txtvalue\"; then _info \"This record already exists, skipping\" return 0 fi _add_data=\"{\\\"data\\\":\\\"$txtvalue\\\"}\" for t in $(echo \"$response\" | tr '{' \"\\n\" | grep \"\\\"name\\\":\\\"$_sub_domain\\\"\" | tr ',' \"\\n\" | grep '\"data\"' | cut -d : -f 2); do _debug2 t \"$t\" # ignore empty (previously removed) records, to prevent useless _acme-challenge TXT entries if [ \"$t\" ] && [ \"$t\" != '\"\"' ]; then _add_data=\"$_add_data,{\\\"data\\\":$t}\" fi done _debug2 _add_data \"$_add_data\" _info \"Adding record\" if _gd_rest PUT \"domains/$_domain/records/TXT/$_sub_domain\" \"[$_add_data]\"; then _debug \"Checking updated records of '${fulldomain}'\" if ! _gd_rest GET \"domains/$_domain/records/TXT/$_sub_domain\"; then _err \"Validating TXT record for '${fulldomain}' with rest error [$?].\" \"$response\" return 1 fi if ! _contains \"$response\" \"$txtvalue\"; then _err \"TXT record '${txtvalue}' for '${fulldomain}', value wasn't set!\" return 1 fi else _err \"Add txt record error, value '${txtvalue}' for '${fulldomain}' was not set.\" return 1 fi _sleep 10 _info \"Added TXT record '${txtvalue}' for '${fulldomain}'.\" return 0 } #fulldomain dns_gd_rm() { fulldomain=$1 txtvalue=$2 GD_Key=\"${GD_Key:-$(_readaccountconf_mutable GD_Key)}\" GD_Secret=\"${GD_Secret:-$(_readaccountconf_mutable GD_Secret)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting existing records\" if ! _gd_rest GET \"domains/$_domain/records/TXT/$_sub_domain\"; then return 1 fi if ! _contains \"$response\" \"$txtvalue\"; then _info \"The record does not exist, skip\" return 0 fi _add_data=\"\" for t in $(echo \"$response\" | tr '{' \"\\n\" | grep \"\\\"name\\\":\\\"$_sub_domain\\\"\" | tr ',' \"\\n\" | grep '\"data\"' | cut -d : -f 2); do _debug2 t \"$t\" if [ \"$t\" ] && [ \"$t\" != \"\\\"$txtvalue\\\"\" ]; then if [ \"$_add_data\" ]; then _add_data=\"$_add_data,{\\\"data\\\":$t}\" else _add_data=\"{\\\"data\\\":$t}\" fi fi done if [ -z \"$_add_data\" ]; then # delete empty record _debug \"Delete last record for '${fulldomain}'\" if ! _gd_rest DELETE \"domains/$_domain/records/TXT/$_sub_domain\"; then _err \"Cannot delete empty TXT record for '$fulldomain'\" return 1 fi else # remove specific TXT value, keeping other entries _debug2 _add_data \"$_add_data\" if ! _gd_rest PUT \"domains/$_domain/records/TXT/$_sub_domain\" \"[$_add_data]\"; then _err \"Cannot update TXT record for '$fulldomain'\" return 1 fi fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi if ! _gd_rest GET \"domains/$h\"; then return 1 fi if _contains \"$response\" '\"code\":\"NOT_FOUND\"'; then _debug \"$h not found\" else _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } _gd_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Authorization: sso-key $GD_Key:$GD_Secret\" export _H2=\"Content-Type: application/json\" if [ \"$data\" ] || [ \"$m\" = \"DELETE\" ]; then _debug \"data ($m): \" \"$data\" response=\"$(_post \"$data\" \"$GD_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$GD_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error on rest call ($m): $ep\" return 1 fi _debug2 response \"$response\" if _contains \"$response\" \"UNABLE_TO_AUTHENTICATE\"; then _err \"It seems that your api key or secret is not correct.\" return 1 fi return 0 }"
        },
        {
            "filename": "file_208.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_208.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_geoscaling_info='GeoScaling.com Site: GeoScaling.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_geoscaling Options: GEOSCALING_Username Username. This is usually NOT an email address GEOSCALING_Password Password ' #-- dns_geoscaling_add() - Add TXT record -------------------------------------- # Usage: dns_geoscaling_add _acme-challenge.subdomain.domain.com \"XyZ123...\" dns_geoscaling_add() { full_domain=$1 txt_value=$2 _info \"Using DNS-01 Geoscaling DNS2 hook\" GEOSCALING_Username=\"${GEOSCALING_Username:-$(_readaccountconf_mutable GEOSCALING_Username)}\" GEOSCALING_Password=\"${GEOSCALING_Password:-$(_readaccountconf_mutable GEOSCALING_Password)}\" if [ -z \"$GEOSCALING_Username\" ] || [ -z \"$GEOSCALING_Password\" ]; then GEOSCALING_Username= GEOSCALING_Password= _err \"No auth details provided. Please set user credentials using the \\$GEOSCALING_Username and \\$GEOSCALING_Password environment variables.\" return 1 fi _saveaccountconf_mutable GEOSCALING_Username \"${GEOSCALING_Username}\" _saveaccountconf_mutable GEOSCALING_Password \"${GEOSCALING_Password}\" # Fills in the $zone_id and $zone_name find_zone \"${full_domain}\" || return 1 _debug \"Zone id '${zone_id}' will be used.\" # We're logged in here # we should add ${full_domain} minus the trailing ${zone_name} prefix=$(echo \"${full_domain}\" | sed \"s|\\\\.${zone_name}\\$||\") body=\"id=${zone_id}&name=${prefix}&type=TXT&content=${txt_value}&ttl=300&prio=0\" do_post \"$body\" \"https://www.geoscaling.com/dns2/ajax/add_record.php\" exit_code=\"$?\" if [ \"${exit_code}\" -eq 0 ]; then _info \"TXT record added successfully.\" else _err \"Couldn't add the TXT record.\" fi do_logout return \"${exit_code}\" } #-- dns_geoscaling_rm() - Remove TXT record ------------------------------------ # Usage: dns_geoscaling_rm _acme-challenge.subdomain.domain.com \"XyZ123...\" dns_geoscaling_rm() { full_domain=$1 txt_value=$2 _info \"Cleaning up after DNS-01 Geoscaling DNS2 hook\" GEOSCALING_Username=\"${GEOSCALING_Username:-$(_readaccountconf_mutable GEOSCALING_Username)}\" GEOSCALING_Password=\"${GEOSCALING_Password:-$(_readaccountconf_mutable GEOSCALING_Password)}\" if [ -z \"$GEOSCALING_Username\" ] || [ -z \"$GEOSCALING_Password\" ]; then GEOSCALING_Username= GEOSCALING_Password= _err \"No auth details provided. Please set user credentials using the \\$GEOSCALING_Username and \\$GEOSCALING_Password environment variables.\" return 1 fi _saveaccountconf_mutable GEOSCALING_Username \"${GEOSCALING_Username}\" _saveaccountconf_mutable GEOSCALING_Password \"${GEOSCALING_Password}\" # fills in the $zone_id find_zone \"${full_domain}\" || return 1 _debug \"Zone id '${zone_id}' will be used.\" # Here we're logged in # Find the record id to clean # get the domain response=$(do_get \"https://www.geoscaling.com/dns2/index.php?module=domain&id=${zone_id}\") _debug2 \"response\" \"$response\" table=\"$(echo \"${response}\" | tr -d '\\n' | sed 's|.*<div class=\"box\"><div class=\"boxtitle\">Basic Records</div><div class=\"boxtext\"><table|<table|; s|</table>.*|</table>|')\" _debug2 table \"${table}\" names=$(echo \"${table}\" | _egrep_o 'id=\"[0-9]+\\.name\">[^<]*</td>' | sed 's|</td>||; s|.*>||') ids=$(echo \"${table}\" | _egrep_o 'id=\"[0-9]+\\.name\">[^<]*</td>' | sed 's|\\.name\">.*||; s|id=\"||') types=$(echo \"${table}\" | _egrep_o 'id=\"[0-9]+\\.type\">[^<]*</td>' | sed 's|</td>||; s|.*>||') values=$(echo \"${table}\" | _egrep_o 'id=\"[0-9]+\\.content\">[^<]*</td>' | sed 's|</td>||; s|.*>||') _debug2 names \"${names}\" _debug2 ids \"${ids}\" _debug2 types \"${types}\" _debug2 values \"${values}\" # look for line whose name is ${full_domain}, whose type is TXT, and whose value is ${txt_value} line_num=\"$(echo \"${values}\" | grep -F -n -- \"${txt_value}\" | _head_n 1 | cut -d ':' -f 1)\" _debug2 line_num \"${line_num}\" found_id= if [ -n \"$line_num\" ]; then type=$(echo \"${types}\" | sed -n \"${line_num}p\") name=$(echo \"${names}\" | sed -n \"${line_num}p\") id=$(echo \"${ids}\" | sed -n \"${line_num}p\") _debug2 type \"$type\" _debug2 name \"$name\" _debug2 id \"$id\" _debug2 full_domain \"$full_domain\" if [ \"${type}\" = \"TXT\" ] && [ \"${name}\" = \"${full_domain}\" ]; then found_id=${id} fi fi if [ \"${found_id}\" = \"\" ]; then _err \"Can not find record id.\" return 0 fi # Remove the record body=\"id=${zone_id}&record_id=${found_id}\" response=$(do_post \"$body\" \"https://www.geoscaling.com/dns2/ajax/delete_record.php\") exit_code=\"$?\" if [ \"$exit_code\" -eq 0 ]; then _info \"Record removed successfully.\" else _err \"Could not clean (remove) up the record. Please go to Geoscaling administration interface and clean it by hand.\" fi do_logout return \"${exit_code}\" } ########################## PRIVATE FUNCTIONS ########################### do_get() { _url=$1 export _H1=\"Cookie: $geoscaling_phpsessid_cookie\" _get \"${_url}\" } do_post() { _body=$1 _url=$2 export _H1=\"Cookie: $geoscaling_phpsessid_cookie\" _post \"${_body}\" \"${_url}\" } do_login() { _info \"Logging in...\" username_encoded=\"$(printf \"%s\" \"${GEOSCALING_Username}\" | _url_encode)\" password_encoded=\"$(printf \"%s\" \"${GEOSCALING_Password}\" | _url_encode)\" body=\"username=${username_encoded}&password=${password_encoded}\" response=$(_post \"$body\" \"https://www.geoscaling.com/dns2/index.php?module=auth\") _debug2 response \"${response}\" #retcode=$(grep '^HTTP[^ ]*' \"${HTTP_HEADER}\" | _head_n 1 | _egrep_o '[0-9]+$') retcode=$(grep '^HTTP[^ ]*' \"${HTTP_HEADER}\" | _head_n 1 | cut -d ' ' -f 2) if [ \"$retcode\" != \"302\" ]; then _err \"Geoscaling login failed for user ${GEOSCALING_Username}. Check ${HTTP_HEADER} file\" return 1 fi geoscaling_phpsessid_cookie=\"$(grep -i '^set-cookie:' \"${HTTP_HEADER}\" | _egrep_o 'PHPSESSID=[^;]*;' | tr -d ';')\" return 0 } do_logout() { _info \"Logging out.\" response=\"$(do_get \"https://www.geoscaling.com/dns2/index.php?module=auth\")\" _debug2 response \"$response\" return 0 } find_zone() { domain=\"$1\" # do login do_login || return 1 # get zones response=\"$(do_get \"https://www.geoscaling.com/dns2/index.php?module=domains\")\" table=\"$(echo \"${response}\" | tr -d '\\n' | sed 's|.*<div class=\"box\"><div class=\"boxtitle\">Your domains</div><div class=\"boxtext\"><table|<table|; s|</table>.*|</table>|')\" _debug2 table \"${table}\" zone_names=\"$(echo \"${table}\" | _egrep_o '<b>[^<]*</b>' | sed 's|<b>||;s|</b>||')\" _debug2 _matches \"${zone_names}\" # Zone names and zone IDs are in same order zone_ids=$(echo \"${table}\" | _egrep_o '<a href=.index\\.php\\?module=domain&id=[0-9]+. onclick=\"javascript:show_loader\\(\\);\">' | sed 's|.*id=||;s|. .*||') _debug2 \"These are the zones on this Geoscaling account:\" _debug2 \"zone_names\" \"${zone_names}\" _debug2 \"And these are their respective IDs:\" _debug2 \"zone_ids\" \"${zone_ids}\" if [ -z \"${zone_names}\" ] || [ -z \"${zone_ids}\" ]; then _err \"Can not get zone names or IDs.\" return 1 fi # Walk through all possible zone names strip_counter=1 while true; do attempted_zone=$(echo \"${domain}\" | cut -d . -f ${strip_counter}-) # All possible zone names have been tried if [ -z \"${attempted_zone}\" ]; then _err \"No zone for domain '${domain}' found.\" return 1 fi _debug \"Looking for zone '${attempted_zone}'\" line_num=\"$(echo \"${zone_names}\" | grep -n \"^${attempted_zone}\\$\" | _head_n 1 | cut -d : -f 1)\" _debug2 line_num \"${line_num}\" if [ \"$line_num\" ]; then zone_id=$(echo \"${zone_ids}\" | sed -n \"${line_num}p\") zone_name=$(echo \"${zone_names}\" | sed -n \"${line_num}p\") if [ -z \"${zone_id}\" ]; then _err \"Can not find zone id.\" return 1 fi _debug \"Found relevant zone '${attempted_zone}' with id '${zone_id}' - will be used for domain '${domain}'.\" return 0 fi _debug \"Zone '${attempted_zone}' doesn't exist, let's try a less specific zone.\" strip_counter=$(_math \"${strip_counter}\" + 1) done } # vim: et:ts=2:sw=2:"
        },
        {
            "filename": "file_209.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_209.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_googledomains_info='Google Domains Site: Domains.Google.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_googledomains Options: GOOGLEDOMAINS_ACCESS_TOKEN API Access Token GOOGLEDOMAINS_ZONE Zone Issues: github.com/acmesh-official/acme.sh/issues/4545 Author: Alex Leigh <leigh@alexleigh.me> ' GOOGLEDOMAINS_API=\"https://acmedns.googleapis.com/v1/acmeChallengeSets\" ######## Public functions ######## #Usage: dns_googledomains_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_googledomains_add() { fulldomain=$1 txtvalue=$2 _info \"Invoking Google Domains ACME DNS API.\" if ! _dns_googledomains_setup; then return 1 fi zone=\"$(_dns_googledomains_get_zone \"$fulldomain\")\" if [ -z \"$zone\" ]; then _err \"Could not find a Google Domains-managed zone containing the requested domain.\" return 1 fi _debug zone \"$zone\" _debug txtvalue \"$txtvalue\" _info \"Adding TXT record for $fulldomain.\" if _dns_googledomains_api \"$zone\" \":rotateChallenges\" \"{\\\"accessToken\\\":\\\"$GOOGLEDOMAINS_ACCESS_TOKEN\\\",\\\"recordsToAdd\\\":[{\\\"fqdn\\\":\\\"$fulldomain\\\",\\\"digest\\\":\\\"$txtvalue\\\"}],\\\"keepExpiredRecords\\\":true}\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"TXT record added.\" return 0 else _err \"Error adding TXT record.\" return 1 fi fi _err \"Error adding TXT record.\" return 1 } #Usage: dns_googledomains_rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_googledomains_rm() { fulldomain=$1 txtvalue=$2 _info \"Invoking Google Domains ACME DNS API.\" if ! _dns_googledomains_setup; then return 1 fi zone=\"$(_dns_googledomains_get_zone \"$fulldomain\")\" if [ -z \"$zone\" ]; then _err \"Could not find a Google Domains-managed domain based on request.\" return 1 fi _debug zone \"$zone\" _debug txtvalue \"$txtvalue\" _info \"Removing TXT record for $fulldomain.\" if _dns_googledomains_api \"$zone\" \":rotateChallenges\" \"{\\\"accessToken\\\":\\\"$GOOGLEDOMAINS_ACCESS_TOKEN\\\",\\\"recordsToRemove\\\":[{\\\"fqdn\\\":\\\"$fulldomain\\\",\\\"digest\\\":\\\"$txtvalue\\\"}],\\\"keepExpiredRecords\\\":true}\"; then if _contains \"$response\" \"$txtvalue\"; then _err \"Error removing TXT record.\" return 1 else _info \"TXT record removed.\" return 0 fi fi _err \"Error removing TXT record.\" return 1 } ######## Private functions ######## _dns_googledomains_setup() { if [ -n \"$GOOGLEDOMAINS_SETUP_COMPLETED\" ]; then return 0 fi GOOGLEDOMAINS_ACCESS_TOKEN=\"${GOOGLEDOMAINS_ACCESS_TOKEN:-$(_readaccountconf_mutable GOOGLEDOMAINS_ACCESS_TOKEN)}\" GOOGLEDOMAINS_ZONE=\"${GOOGLEDOMAINS_ZONE:-$(_readaccountconf_mutable GOOGLEDOMAINS_ZONE)}\" if [ -z \"$GOOGLEDOMAINS_ACCESS_TOKEN\" ]; then GOOGLEDOMAINS_ACCESS_TOKEN=\"\" _err \"Google Domains access token was not specified.\" _err \"Please visit Google Domains Security settings to provision an ACME DNS API access token.\" return 1 fi if [ \"$GOOGLEDOMAINS_ZONE\" ]; then _savedomainconf GOOGLEDOMAINS_ACCESS_TOKEN \"$GOOGLEDOMAINS_ACCESS_TOKEN\" _savedomainconf GOOGLEDOMAINS_ZONE \"$GOOGLEDOMAINS_ZONE\" else _saveaccountconf_mutable GOOGLEDOMAINS_ACCESS_TOKEN \"$GOOGLEDOMAINS_ACCESS_TOKEN\" _clearaccountconf_mutable GOOGLEDOMAINS_ZONE _clearaccountconf GOOGLEDOMAINS_ZONE fi _debug GOOGLEDOMAINS_ACCESS_TOKEN \"$GOOGLEDOMAINS_ACCESS_TOKEN\" _debug GOOGLEDOMAINS_ZONE \"$GOOGLEDOMAINS_ZONE\" GOOGLEDOMAINS_SETUP_COMPLETED=1 return 0 } _dns_googledomains_get_zone() { domain=$1 # Use zone directly if provided if [ \"$GOOGLEDOMAINS_ZONE\" ]; then if ! _dns_googledomains_api \"$GOOGLEDOMAINS_ZONE\"; then return 1 fi echo \"$GOOGLEDOMAINS_ZONE\" return 0 fi i=2 while true; do curr=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug curr \"$curr\" if [ -z \"$curr\" ]; then return 1 fi if _dns_googledomains_api \"$curr\"; then echo \"$curr\" return 0 fi i=$(_math \"$i\" + 1) done return 1 } _dns_googledomains_api() { zone=$1 apimethod=$2 data=\"$3\" if [ -z \"$data\" ]; then response=\"$(_get \"$GOOGLEDOMAINS_API/$zone$apimethod\")\" else _debug data \"$data\" export _H1=\"Content-Type: application/json\" response=\"$(_post \"$data\" \"$GOOGLEDOMAINS_API/$zone$apimethod\")\" fi _debug response \"$response\" if [ \"$?\" != \"0\" ]; then _err \"Error\" return 1 fi if _contains \"$response\" \"\\\"error\\\": {\"; then return 1 fi return 0 }"
        },
        {
            "filename": "file_210.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_210.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_he_info='Hurricane Electric HE.net Site: dns.he.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_he Options: HE_Username Username HE_Password Password Issues: github.com/angel333/acme.sh/issues/ Author: Ondrej Simek <me@ondrejsimek.com> ' #-- dns_he_add() - Add TXT record -------------------------------------- # Usage: dns_he_add _acme-challenge.subdomain.domain.com \"XyZ123...\" dns_he_add() { _full_domain=$1 _txt_value=$2 _info \"Using DNS-01 Hurricane Electric hook\" HE_Username=\"${HE_Username:-$(_readaccountconf_mutable HE_Username)}\" HE_Password=\"${HE_Password:-$(_readaccountconf_mutable HE_Password)}\" if [ -z \"$HE_Username\" ] || [ -z \"$HE_Password\" ]; then HE_Username= HE_Password= _err \"No auth details provided. Please set user credentials using the \\$HE_Username and \\$HE_Password environment variables.\" return 1 fi _saveaccountconf_mutable HE_Username \"$HE_Username\" _saveaccountconf_mutable HE_Password \"$HE_Password\" # Fills in the $_zone_id _find_zone \"$_full_domain\" || return 1 _debug \"Zone id \\\"$_zone_id\\\" will be used.\" username_encoded=\"$(printf \"%s\" \"${HE_Username}\" | _url_encode)\" password_encoded=\"$(printf \"%s\" \"${HE_Password}\" | _url_encode)\" body=\"email=${username_encoded}&pass=${password_encoded}\" body=\"$body&account=\" body=\"$body&menu=edit_zone\" body=\"$body&Type=TXT\" body=\"$body&hosted_dns_zoneid=$_zone_id\" body=\"$body&hosted_dns_recordid=\" body=\"$body&hosted_dns_editzone=1\" body=\"$body&Priority=\" body=\"$body&Name=$_full_domain\" body=\"$body&Content=$_txt_value\" body=\"$body&TTL=300\" body=\"$body&hosted_dns_editrecord=Submit\" response=\"$(_post \"$body\" \"https://dns.he.net/\")\" exit_code=\"$?\" if [ \"$exit_code\" -eq 0 ]; then _info \"TXT record added successfully.\" else _err \"Couldn't add the TXT record.\" fi _debug2 response \"$response\" return \"$exit_code\" } #-- dns_he_rm() - Remove TXT record ------------------------------------ # Usage: dns_he_rm _acme-challenge.subdomain.domain.com \"XyZ123...\" dns_he_rm() { _full_domain=$1 _txt_value=$2 _info \"Cleaning up after DNS-01 Hurricane Electric hook\" HE_Username=\"${HE_Username:-$(_readaccountconf_mutable HE_Username)}\" HE_Password=\"${HE_Password:-$(_readaccountconf_mutable HE_Password)}\" # fills in the $_zone_id _find_zone \"$_full_domain\" || return 1 _debug \"Zone id \\\"$_zone_id\\\" will be used.\" # Find the record id to clean username_encoded=\"$(printf \"%s\" \"${HE_Username}\" | _url_encode)\" password_encoded=\"$(printf \"%s\" \"${HE_Password}\" | _url_encode)\" body=\"email=${username_encoded}&pass=${password_encoded}\" body=\"$body&hosted_dns_zoneid=$_zone_id\" body=\"$body&menu=edit_zone\" body=\"$body&hosted_dns_editzone=\" response=\"$(_post \"$body\" \"https://dns.he.net/\")\" _debug2 \"response\" \"$response\" if ! _contains \"$response\" \"$_txt_value\"; then _debug \"The txt record is not found, just skip\" return 0 fi _record_id=\"$(echo \"$response\" | tr -d \"#\" | sed \"s/<tr/#<tr/g\" | tr -d \"\\n\" | tr \"#\" \"\\n\" | grep \"$_full_domain\" | grep '\"dns_tr\"' | grep -- \"$_txt_value\" | cut -d '\"' -f 4)\" _debug2 _record_id \"$_record_id\" if [ -z \"$_record_id\" ]; then _err \"Can not find record id\" return 1 fi # Remove the record username_encoded=\"$(printf \"%s\" \"${HE_Username}\" | _url_encode)\" password_encoded=\"$(printf \"%s\" \"${HE_Password}\" | _url_encode)\" body=\"email=${username_encoded}&pass=${password_encoded}\" body=\"$body&menu=edit_zone\" body=\"$body&hosted_dns_zoneid=$_zone_id\" body=\"$body&hosted_dns_recordid=$_record_id\" body=\"$body&hosted_dns_editzone=1\" body=\"$body&hosted_dns_delrecord=1\" body=\"$body&hosted_dns_delconfirm=delete\" _post \"$body\" \"https://dns.he.net/\" | grep '<div id=\"dns_status\" onClick=\"hideThis(this);\">Successfully removed record.</div>' \\ >/dev/null exit_code=\"$?\" if [ \"$exit_code\" -eq 0 ]; then _info \"Record removed successfully.\" else _err \"Could not clean (remove) up the record. Please go to HE administration interface and clean it by hand.\" return \"$exit_code\" fi } ########################## PRIVATE FUNCTIONS ########################### _find_zone() { _domain=\"$1\" username_encoded=\"$(printf \"%s\" \"${HE_Username}\" | _url_encode)\" password_encoded=\"$(printf \"%s\" \"${HE_Password}\" | _url_encode)\" body=\"email=${username_encoded}&pass=${password_encoded}\" response=\"$(_post \"$body\" \"https://dns.he.net/\")\" _debug2 response \"$response\" if _contains \"$response\" '>Incorrect<'; then _err \"Unable to login to dns.he.net please check username and password\" return 1 fi _table=\"$(echo \"$response\" | tr -d \"#\" | sed \"s/<table/#<table/g\" | tr -d \"\\n\" | tr \"#\" \"\\n\" | grep 'id=\"domains_table\"')\" _debug2 _table \"$_table\" _matches=\"$(echo \"$_table\" | sed \"s/<tr/#<tr/g\" | tr \"#\" \"\\n\" | grep 'alt=\"edit\"' | tr -d \" \" | sed \"s/<td/#<td/g\" | tr \"#\" \"\\n\" | grep 'hosted_dns_zoneid')\" _debug2 _matches \"$_matches\" # Zone names and zone IDs are in same order _zone_ids=$(echo \"$_matches\" | _egrep_o \"hosted_dns_zoneid=[0-9]*&\" | cut -d = -f 2 | tr -d '&') _zone_names=$(echo \"$_matches\" | _egrep_o \"name=.*onclick\" | cut -d '\"' -f 2) _debug2 \"These are the zones on this HE account:\" _debug2 \"_zone_names\" \"$_zone_names\" _debug2 \"And these are their respective IDs:\" _debug2 \"_zone_ids\" \"$_zone_ids\" if [ -z \"$_zone_names\" ] || [ -z \"$_zone_ids\" ]; then _err \"Can not get zone names.\" return 1 fi # Walk through all possible zone names _strip_counter=1 while true; do _attempted_zone=$(echo \"$_domain\" | cut -d . -f ${_strip_counter}-) # All possible zone names have been tried if [ -z \"$_attempted_zone\" ]; then _err \"No zone for domain \\\"$_domain\\\" found.\" return 1 fi _debug \"Looking for zone \\\"${_attempted_zone}\\\"\" line_num=\"$(echo \"$_zone_names\" | grep -n \"^$_attempted_zone\\$\" | _head_n 1 | cut -d : -f 1)\" _debug2 line_num \"$line_num\" if [ \"$line_num\" ]; then _zone_id=$(echo \"$_zone_ids\" | sed -n \"${line_num}p\") if [ -z \"$_zone_id\" ]; then _err \"Can not find zone id.\" return 1 fi _debug \"Found relevant zone \\\"$_attempted_zone\\\" with id \\\"$_zone_id\\\" - will be used for domain \\\"$_domain\\\".\" return 0 fi _debug \"Zone \\\"$_attempted_zone\\\" doesn't exist, let's try a less specific zone.\" _strip_counter=$(_math \"$_strip_counter\" + 1) done } # vim: et:ts=2:sw=2:"
        },
        {
            "filename": "file_211.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_211.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_hetzner_info='Hetzner.com Site: Hetzner.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_hetzner Options: HETZNER_Token API Token Issues: github.com/acmesh-official/acme.sh/issues/2943 ' HETZNER_Api=\"https://dns.hetzner.com/api/v1\" ######## Public functions ##################### # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record # Ref: https://dns.hetzner.com/api-docs/ dns_hetzner_add() { full_domain=$1 txt_value=$2 HETZNER_Token=\"${HETZNER_Token:-$(_readaccountconf_mutable HETZNER_Token)}\" if [ -z \"$HETZNER_Token\" ]; then HETZNER_Token=\"\" _err \"You didn't specify a Hetzner api token.\" _err \"You can get yours from here https://dns.hetzner.com/settings/api-token.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable HETZNER_Token \"$HETZNER_Token\" _debug \"First detect the root zone\" if ! _get_root \"$full_domain\"; then _err \"Invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting TXT records\" if ! _find_record \"$_sub_domain\" \"$txt_value\"; then return 1 fi if [ -z \"$_record_id\" ]; then _info \"Adding record\" if _hetzner_rest POST \"records\" \"{\\\"zone_id\\\":\\\"${HETZNER_Zone_ID}\\\",\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"value\\\":\\\"$txt_value\\\",\\\"ttl\\\":120}\"; then if _contains \"$response\" \"$txt_value\"; then _info \"Record added, OK\" _sleep 2 return 0 fi fi _err \"Add txt record error${_response_error}\" return 1 else _info \"Found record id: $_record_id.\" _info \"Record found, do nothing.\" return 0 # we could modify a record, if the names for txt records for *.example.com and example.com would be not the same #if _hetzner_rest PUT \"records/${_record_id}\" \"{\\\"zone_id\\\":\\\"${HETZNER_Zone_ID}\\\",\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$full_domain\\\",\\\"value\\\":\\\"$txt_value\\\",\\\"ttl\\\":120}\"; then # if _contains \"$response\" \"$txt_value\"; then # _info \"Modified, OK\" # return 0 # fi #fi #_err \"Add txt record error (modify).\" #return 1 fi } # Usage: full_domain txt_value # Used to remove the txt record after validation dns_hetzner_rm() { full_domain=$1 txt_value=$2 HETZNER_Token=\"${HETZNER_Token:-$(_readaccountconf_mutable HETZNER_Token)}\" _debug \"First detect the root zone\" if ! _get_root \"$full_domain\"; then _err \"Invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting TXT records\" if ! _find_record \"$_sub_domain\" \"$txt_value\"; then return 1 fi if [ -z \"$_record_id\" ]; then _info \"Remove not needed. Record not found.\" else if ! _hetzner_rest DELETE \"records/$_record_id\"; then _err \"Delete record error${_response_error}\" return 1 fi _sleep 2 _info \"Record deleted\" fi } #################### Private functions below ################################## #returns # _record_id=a8d58f22d6931bf830eaa0ec6464bf81 if found; or 1 if error _find_record() { unset _record_id _record_name=$1 _record_value=$2 if [ -z \"$_record_value\" ]; then _record_value='[^\"]*' fi _debug \"Getting all records\" _hetzner_rest GET \"records?zone_id=${_domain_id}\" if _response_has_error; then _err \"Error${_response_error}\" return 1 else _record_id=$( echo \"$response\" | grep -o \"{[^\\{\\}]*\\\"name\\\":\\\"$_record_name\\\"[^\\}]*}\" | grep \"\\\"value\\\":\\\"$_record_value\\\"\" | while read -r record; do # test for type and if [ -n \"$(echo \"$record\" | _egrep_o '\"type\":\"TXT\"')\" ]; then echo \"$record\" | _egrep_o '\"id\":\"[^\"]*\"' | cut -d : -f 2 | tr -d \\\" break fi done ) fi } #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=1 p=1 domain_without_acme=$(echo \"$domain\" | cut -d . -f 2-) domain_param_name=$(echo \"HETZNER_Zone_ID_for_${domain_without_acme}\" | sed 's/[\\.\\-]/_/g') _debug \"Reading zone_id for '$domain_without_acme' from config...\" HETZNER_Zone_ID=$(_readdomainconf \"$domain_param_name\") if [ \"$HETZNER_Zone_ID\" ]; then _debug \"Found, using: $HETZNER_Zone_ID\" if ! _hetzner_rest GET \"zones/${HETZNER_Zone_ID}\"; then _debug \"Zone with id '$HETZNER_Zone_ID' does not exist.\" _cleardomainconf \"$domain_param_name\" unset HETZNER_Zone_ID else if _contains \"$response\" \"\\\"id\\\":\\\"$HETZNER_Zone_ID\\\"\"; then _domain=$(printf \"%s\\n\" \"$response\" | _egrep_o '\"name\":\"[^\"]*\"' | cut -d : -f 2 | tr -d \\\" | head -n 1) if [ \"$_domain\" ]; then _cut_length=$((${#domain} - ${#_domain} - 1)) _sub_domain=$(printf \"%s\" \"$domain\" | cut -c \"1-$_cut_length\") _domain_id=\"$HETZNER_Zone_ID\" return 0 else return 1 fi else return 1 fi fi fi _debug \"Trying to get zone id by domain name for '$domain_without_acme'.\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi _debug h \"$h\" _hetzner_rest GET \"zones?name=$h\" if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" || _contains \"$response\" '\"total_entries\":1'; then _domain_id=$(echo \"$response\" | _egrep_o \"\\[.\\\"id\\\":\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \\\") if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h HETZNER_Zone_ID=$_domain_id _savedomainconf \"$domain_param_name\" \"$HETZNER_Zone_ID\" return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } #returns # _response_error _response_has_error() { unset _response_error err_part=\"$(echo \"$response\" | _egrep_o '\"error\":{[^}]*}')\" if [ -n \"$err_part\" ]; then err_code=$(echo \"$err_part\" | _egrep_o '\"code\":[0-9]+' | cut -d : -f 2) err_message=$(echo \"$err_part\" | _egrep_o '\"message\":\"[^\"]+\"' | cut -d : -f 2 | tr -d \\\") if [ -n \"$err_code\" ] && [ -n \"$err_message\" ]; then _response_error=\" - message: ${err_message}, code: ${err_code}\" return 0 fi fi return 1 } #returns # response _hetzner_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" key_trimmed=$(echo \"$HETZNER_Token\" | tr -d \\\") export _H1=\"Content-TType: application/json\" export _H2=\"Auth-API-Token: $key_trimmed\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$HETZNER_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$HETZNER_Api/$ep\")\" fi if [ \"$?\" != \"0\" ] || _response_has_error; then _debug \"Error$_response_error\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_212.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_212.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_hexonet_info='Hexonet.com Site: Hexonet.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_hexonet Options: Hexonet_Login Login. E.g. \"username!roleId\" Hexonet_Password Role Password Issues: github.com/acmesh-official/acme.sh/issues/2389 ' Hexonet_Api=\"https://coreapi.1api.net/api/call.cgi\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_hexonet_add() { fulldomain=$1 txtvalue=$2 Hexonet_Login=\"${Hexonet_Login:-$(_readaccountconf_mutable Hexonet_Login)}\" Hexonet_Password=\"${Hexonet_Password:-$(_readaccountconf_mutable Hexonet_Password)}\" if [ -z \"$Hexonet_Login\" ] || [ -z \"$Hexonet_Password\" ]; then Hexonet_Login=\"\" Hexonet_Password=\"\" _err \"You must export variables: Hexonet_Login and Hexonet_Password\" return 1 fi if ! _contains \"$Hexonet_Login\" \"!\"; then _err \"It seems that the Hexonet_Login=$Hexonet_Login is not a restrivteed user.\" _err \"Please check and retry.\" return 1 fi #save the username and password to the account conf file. _saveaccountconf_mutable Hexonet_Login \"$Hexonet_Login\" _saveaccountconf_mutable Hexonet_Password \"$Hexonet_Password\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _hexonet_rest \"command=QueryDNSZoneRRList&dnszone=${h}.&RRTYPE=TXT\" if ! _contains \"$response\" \"CODE=200\"; then _err \"Error\" return 1 fi _info \"Adding record\" if _hexonet_rest \"command=UpdateDNSZone&dnszone=${_domain}.&addrr0=${_sub_domain}%20IN%20TXT%20${txtvalue}\"; then if _contains \"$response\" \"CODE=200\"; then _info \"Added, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_hexonet_rm() { fulldomain=$1 txtvalue=$2 Hexonet_Login=\"${Hexonet_Login:-$(_readaccountconf_mutable Hexonet_Login)}\" Hexonet_Password=\"${Hexonet_Password:-$(_readaccountconf_mutable Hexonet_Password)}\" if [ -z \"$Hexonet_Login\" ] || [ -z \"$Hexonet_Password\" ]; then Hexonet_Login=\"\" Hexonet_Password=\"\" _err \"You must export variables: Hexonet_Login and Hexonet_Password\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _hexonet_rest \"command=QueryDNSZoneRRList&dnszone=${h}.&RRTYPE=TXT&RR=${_sub_domain}%20IN%20TXT%20\\\"${txtvalue}\\\"\" if ! _contains \"$response\" \"CODE=200\"; then _err \"Error\" return 1 fi count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"PROPERTY[TOTAL][0]=\" | cut -d = -f 2) _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else if ! _hexonet_rest \"command=UpdateDNSZone&dnszone=${_domain}.&delrr0=${_sub_domain}%20IN%20TXT%20\\\"${txtvalue}\\\"\"; then _err \"Delete record error.\" return 1 fi _contains \"$response\" \"CODE=200\" fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _hexonet_rest \"command=QueryDNSZoneRRList&dnszone=${h}.\"; then return 1 fi if _contains \"$response\" \"CODE=200\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _hexonet_rest() { query_params=\"$1\" _debug \"$query_params\" response=\"$(_get \"${Hexonet_Api}?s_login=${Hexonet_Login}&s_pw=${Hexonet_Password}&${query_params}\")\" if [ \"$?\" != \"0\" ]; then _err \"error $query_params\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_213.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_213.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_hostingde_info='Hosting.de Site: Hosting.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_hostingde Options: HOSTINGDE_ENDPOINT Endpoint. E.g. \"https://secure.hosting.de\" HOSTINGDE_APIKEY API Key Issues: github.com/acmesh-official/acme.sh/issues/2058 ' ######## Public functions ##################### dns_hostingde_add() { fulldomain=\"${1}\" txtvalue=\"${2}\" _debug \"Calling: _hostingde_addRecord() '${fulldomain}' '${txtvalue}'\" _hostingde_apiKey && _hostingde_getZoneConfig && _hostingde_addRecord return $? } dns_hostingde_rm() { fulldomain=\"${1}\" txtvalue=\"${2}\" _debug \"Calling: _hostingde_removeRecord() '${fulldomain}' '${txtvalue}'\" _hostingde_apiKey && _hostingde_getZoneConfig && _hostingde_removeRecord return $? } #################### own Private functions below ################################## _hostingde_apiKey() { HOSTINGDE_APIKEY=\"${HOSTINGDE_APIKEY:-$(_readaccountconf_mutable HOSTINGDE_APIKEY)}\" HOSTINGDE_ENDPOINT=\"${HOSTINGDE_ENDPOINT:-$(_readaccountconf_mutable HOSTINGDE_ENDPOINT)}\" if [ -z \"$HOSTINGDE_APIKEY\" ] || [ -z \"$HOSTINGDE_ENDPOINT\" ]; then HOSTINGDE_APIKEY=\"\" HOSTINGDE_ENDPOINT=\"\" _err \"You haven't specified hosting.de API key or endpoint yet.\" _err \"Please create your key and try again.\" return 1 fi _saveaccountconf_mutable HOSTINGDE_APIKEY \"$HOSTINGDE_APIKEY\" _saveaccountconf_mutable HOSTINGDE_ENDPOINT \"$HOSTINGDE_ENDPOINT\" } _hostingde_parse() { find=\"${1}\" if [ \"${2}\" ]; then notfind=\"${2}\" fi if [ \"${notfind}\" ]; then _egrep_o \\\"\"${find}\\\":.*\" | grep -v \"${notfind}\" | cut -d ':' -f 2 | cut -d ',' -f 1 | tr -d ' ' else _egrep_o \\\"\"${find}\\\":.*\" | cut -d ':' -f 2 | cut -d ',' -f 1 | tr -d ' ' fi } _hostingde_getZoneConfig() { _info \"Getting ZoneConfig\" curZone=\"${fulldomain#*.}\" returnCode=1 while _contains \"${curZone}\" \"\\\\.\"; do curData=\"{\\\"filter\\\":{\\\"field\\\":\\\"zoneName\\\",\\\"value\\\":\\\"${curZone}\\\"},\\\"limit\\\":1,\\\"authToken\\\":\\\"${HOSTINGDE_APIKEY}\\\"}\" curResult=\"$(_post \"${curData}\" \"${HOSTINGDE_ENDPOINT}/api/dns/v1/json/zoneConfigsFind\")\" _debug \"Calling zoneConfigsFind: '${curData}' '${HOSTINGDE_ENDPOINT}/api/dns/v1/json/zoneConfigsFind'\" _debug \"Result of zoneConfigsFind: '$curResult'\" if _contains \"${curResult}\" '\"status\": \"error\"'; then if _contains \"${curResult}\" '\"code\": 10109'; then _err \"The API-Key is invalid or could not be found\" else _err \"UNKNOWN API ERROR\" fi returnCode=1 break fi if _contains \"${curResult}\" '\"totalEntries\": 1'; then _info \"Retrieved zone data.\" _debug \"Zone data: '${curResult}'\" zoneConfigId=$(echo \"${curResult}\" | _hostingde_parse \"id\") zoneConfigName=$(echo \"${curResult}\" | _hostingde_parse \"name\") zoneConfigType=$(echo \"${curResult}\" | _hostingde_parse \"type\" \"FindZoneConfigsResult\") zoneConfigExpire=$(echo \"${curResult}\" | _hostingde_parse \"expire\") zoneConfigNegativeTtl=$(echo \"${curResult}\" | _hostingde_parse \"negativeTtl\") zoneConfigRefresh=$(echo \"${curResult}\" | _hostingde_parse \"refresh\") zoneConfigRetry=$(echo \"${curResult}\" | _hostingde_parse \"retry\") zoneConfigTtl=$(echo \"${curResult}\" | _hostingde_parse \"ttl\") zoneConfigDnsServerGroupId=$(echo \"${curResult}\" | _hostingde_parse \"dnsServerGroupId\") zoneConfigEmailAddress=$(echo \"${curResult}\" | _hostingde_parse \"emailAddress\") zoneConfigDnsSecMode=$(echo \"${curResult}\" | _hostingde_parse \"dnsSecMode\") zoneConfigTemplateValues=$(echo \"${curResult}\" | _hostingde_parse \"templateValues\") if [ \"$zoneConfigTemplateValues\" != \"null\" ]; then _debug \"Zone is tied to a template.\" zoneConfigTemplateValuesTemplateId=$(echo \"${curResult}\" | _hostingde_parse \"templateId\") zoneConfigTemplateValuesTemplateName=$(echo \"${curResult}\" | _hostingde_parse \"templateName\") zoneConfigTemplateValuesTemplateReplacementsIPv4=$(echo \"${curResult}\" | _hostingde_parse \"ipv4Replacement\") zoneConfigTemplateValuesTemplateReplacementsIPv6=$(echo \"${curResult}\" | _hostingde_parse \"ipv6Replacement\") zoneConfigTemplateValuesTemplateReplacementsMailIPv4=$(echo \"${curResult}\" | _hostingde_parse \"mailIpv4Replacement\") zoneConfigTemplateValuesTemplateReplacementsMailIPv6=$(echo \"${curResult}\" | _hostingde_parse \"mailIpv6Replacement\") zoneConfigTemplateValuesTemplateTieToTemplate=$(echo \"${curResult}\" | _hostingde_parse \"tieToTemplate\") zoneConfigTemplateValues=\"{\\\"templateId\\\":${zoneConfigTemplateValuesTemplateId},\\\"templateName\\\":${zoneConfigTemplateValuesTemplateName},\\\"templateReplacements\\\":{\\\"ipv4Replacement\\\":${zoneConfigTemplateValuesTemplateReplacementsIPv4},\\\"ipv6Replacement\\\":${zoneConfigTemplateValuesTemplateReplacementsIPv6},\\\"mailIpv4Replacement\\\":${zoneConfigTemplateValuesTemplateReplacementsMailIPv4},\\\"mailIpv6Replacement\\\":${zoneConfigTemplateValuesTemplateReplacementsMailIPv6}},\\\"tieToTemplate\\\":${zoneConfigTemplateValuesTemplateTieToTemplate}}\" _debug \"Template values: '{$zoneConfigTemplateValues}'\" fi if [ \"${zoneConfigType}\" != \"\\\"NATIVE\\\"\" ]; then _err \"Zone is not native\" returnCode=1 break fi _debug \"zoneConfigId '${zoneConfigId}'\" returnCode=0 break fi curZone=\"${curZone#*.}\" done if [ $returnCode -ne 0 ]; then _info \"ZoneEnd reached, Zone ${curZone} not found in hosting.de API\" fi return $returnCode } _hostingde_getZoneStatus() { _debug \"Checking Zone status\" curData=\"{\\\"filter\\\":{\\\"field\\\":\\\"zoneConfigId\\\",\\\"value\\\":${zoneConfigId}},\\\"limit\\\":1,\\\"authToken\\\":\\\"${HOSTINGDE_APIKEY}\\\"}\" curResult=\"$(_post \"${curData}\" \"${HOSTINGDE_ENDPOINT}/api/dns/v1/json/zonesFind\")\" _debug \"Calling zonesFind '${curData}' '${HOSTINGDE_ENDPOINT}/api/dns/v1/json/zonesFind'\" _debug \"Result of zonesFind '$curResult'\" zoneStatus=$(echo \"${curResult}\" | _hostingde_parse \"status\" \"success\") _debug \"zoneStatus '${zoneStatus}'\" return 0 } _hostingde_addRecord() { _info \"Adding record to zone\" _hostingde_getZoneStatus _debug \"Result of zoneStatus: '${zoneStatus}'\" while [ \"${zoneStatus}\" != \"\\\"active\\\"\" ]; do _sleep 5 _hostingde_getZoneStatus _debug \"Result of zoneStatus: '${zoneStatus}'\" done curData=\"{\\\"authToken\\\":\\\"${HOSTINGDE_APIKEY}\\\",\\\"zoneConfig\\\":{\\\"id\\\":${zoneConfigId},\\\"name\\\":${zoneConfigName},\\\"type\\\":${zoneConfigType},\\\"dnsServerGroupId\\\":${zoneConfigDnsServerGroupId},\\\"dnsSecMode\\\":${zoneConfigDnsSecMode},\\\"emailAddress\\\":${zoneConfigEmailAddress},\\\"soaValues\\\":{\\\"expire\\\":${zoneConfigExpire},\\\"negativeTtl\\\":${zoneConfigNegativeTtl},\\\"refresh\\\":${zoneConfigRefresh},\\\"retry\\\":${zoneConfigRetry},\\\"ttl\\\":${zoneConfigTtl}},\\\"templateValues\\\":${zoneConfigTemplateValues}},\\\"recordsToAdd\\\":[{\\\"name\\\":\\\"${fulldomain}\\\",\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"\\\\\\\"${txtvalue}\\\\\\\"\\\",\\\"ttl\\\":3600}]}\" curResult=\"$(_post \"${curData}\" \"${HOSTINGDE_ENDPOINT}/api/dns/v1/json/zoneUpdate\")\" _debug \"Calling zoneUpdate: '${curData}' '${HOSTINGDE_ENDPOINT}/api/dns/v1/json/zoneUpdate'\" _debug \"Result of zoneUpdate: '$curResult'\" if _contains \"${curResult}\" '\"status\": \"error\"'; then if _contains \"${curResult}\" '\"code\": 10109'; then _err \"The API-Key is invalid or could not be found\" else _err \"UNKNOWN API ERROR\" fi return 1 fi return 0 } _hostingde_removeRecord() { _info \"Removing record from zone\" _hostingde_getZoneStatus _debug \"Result of zoneStatus: '$zoneStatus'\" while [ \"$zoneStatus\" != \"\\\"active\\\"\" ]; do _sleep 5 _hostingde_getZoneStatus _debug \"Result of zoneStatus: '$zoneStatus'\" done curData=\"{\\\"authToken\\\":\\\"${HOSTINGDE_APIKEY}\\\",\\\"zoneConfig\\\":{\\\"id\\\":${zoneConfigId},\\\"name\\\":${zoneConfigName},\\\"type\\\":${zoneConfigType},\\\"dnsServerGroupId\\\":${zoneConfigDnsServerGroupId},\\\"dnsSecMode\\\":${zoneConfigDnsSecMode},\\\"emailAddress\\\":${zoneConfigEmailAddress},\\\"soaValues\\\":{\\\"expire\\\":${zoneConfigExpire},\\\"negativeTtl\\\":${zoneConfigNegativeTtl},\\\"refresh\\\":${zoneConfigRefresh},\\\"retry\\\":${zoneConfigRetry},\\\"ttl\\\":${zoneConfigTtl}},\\\"templateValues\\\":${zoneConfigTemplateValues}},\\\"recordsToDelete\\\":[{\\\"name\\\":\\\"${fulldomain}\\\",\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"\\\\\\\"${txtvalue}\\\\\\\"\\\"}]}\" curResult=\"$(_post \"${curData}\" \"${HOSTINGDE_ENDPOINT}/api/dns/v1/json/zoneUpdate\")\" _debug \"Calling zoneUpdate: '${curData}' '${HOSTINGDE_ENDPOINT}/api/dns/v1/json/zoneUpdate'\" _debug \"Result of zoneUpdate: '$curResult'\" if _contains \"${curResult}\" '\"status\": \"error\"'; then if _contains \"${curResult}\" '\"code\": 10109'; then _err \"The API-Key is invalid or could not be found\" else _err \"UNKNOWN API ERROR\" fi return 1 fi return 0 }"
        },
        {
            "filename": "file_214.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_214.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_huaweicloud_info='HuaweiCloud.com Site: HuaweiCloud.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_huaweicloud Options: HUAWEICLOUD_Username Username HUAWEICLOUD_Password Password HUAWEICLOUD_DomainName DomainName Issues: github.com/acmesh-official/acme.sh/issues/3265 ' iam_api=\"https://iam.myhuaweicloud.com\" dns_api=\"https://dns.ap-southeast-1.myhuaweicloud.com\" # Should work ######## Public functions ##################### # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record # # Ref: https://support.huaweicloud.com/intl/zh-cn/api-dns/zh-cn_topic_0132421999.html # # About \"DomainName\" parameters see: https://support.huaweicloud.com/api-iam/iam_01_0006.html # dns_huaweicloud_add() { fulldomain=$1 txtvalue=$2 HUAWEICLOUD_Username=\"${HUAWEICLOUD_Username:-$(_readaccountconf_mutable HUAWEICLOUD_Username)}\" HUAWEICLOUD_Password=\"${HUAWEICLOUD_Password:-$(_readaccountconf_mutable HUAWEICLOUD_Password)}\" HUAWEICLOUD_DomainName=\"${HUAWEICLOUD_DomainName:-$(_readaccountconf_mutable HUAWEICLOUD_DomainName)}\" # Check information if [ -z \"${HUAWEICLOUD_Username}\" ] || [ -z \"${HUAWEICLOUD_Password}\" ] || [ -z \"${HUAWEICLOUD_DomainName}\" ]; then _err \"Not enough information provided to dns_huaweicloud!\" return 1 fi unset token # Clear token token=\"$(_get_token \"${HUAWEICLOUD_Username}\" \"${HUAWEICLOUD_Password}\" \"${HUAWEICLOUD_DomainName}\")\" if [ -z \"${token}\" ]; then # Check token _err \"dns_api(dns_huaweicloud): Error getting token.\" return 1 fi _secure_debug \"Access token is:\" \"${token}\" unset zoneid zoneid=\"$(_get_zoneid \"${token}\" \"${fulldomain}\")\" if [ -z \"${zoneid}\" ]; then _err \"dns_api(dns_huaweicloud): Error getting zone id.\" return 1 fi _debug \"Zone ID is:\" \"${zoneid}\" _debug \"Adding Record\" _add_record \"${token}\" \"${fulldomain}\" \"${txtvalue}\" ret=\"$?\" if [ \"${ret}\" != \"0\" ]; then _err \"dns_api(dns_huaweicloud): Error adding record.\" return 1 fi # Do saving work if all succeeded _saveaccountconf_mutable HUAWEICLOUD_Username \"${HUAWEICLOUD_Username}\" _saveaccountconf_mutable HUAWEICLOUD_Password \"${HUAWEICLOUD_Password}\" _saveaccountconf_mutable HUAWEICLOUD_DomainName \"${HUAWEICLOUD_DomainName}\" return 0 } # Usage: fulldomain txtvalue # Used to remove the txt record after validation # # Ref: https://support.huaweicloud.com/intl/zh-cn/api-dns/dns_api_64005.html # dns_huaweicloud_rm() { fulldomain=$1 txtvalue=$2 HUAWEICLOUD_Username=\"${HUAWEICLOUD_Username:-$(_readaccountconf_mutable HUAWEICLOUD_Username)}\" HUAWEICLOUD_Password=\"${HUAWEICLOUD_Password:-$(_readaccountconf_mutable HUAWEICLOUD_Password)}\" HUAWEICLOUD_DomainName=\"${HUAWEICLOUD_DomainName:-$(_readaccountconf_mutable HUAWEICLOUD_DomainName)}\" # Check information if [ -z \"${HUAWEICLOUD_Username}\" ] || [ -z \"${HUAWEICLOUD_Password}\" ] || [ -z \"${HUAWEICLOUD_DomainName}\" ]; then _err \"Not enough information provided to dns_huaweicloud!\" return 1 fi unset token # Clear token token=\"$(_get_token \"${HUAWEICLOUD_Username}\" \"${HUAWEICLOUD_Password}\" \"${HUAWEICLOUD_DomainName}\")\" if [ -z \"${token}\" ]; then # Check token _err \"dns_api(dns_huaweicloud): Error getting token.\" return 1 fi _secure_debug \"Access token is:\" \"${token}\" unset zoneid zoneid=\"$(_get_zoneid \"${token}\" \"${fulldomain}\")\" if [ -z \"${zoneid}\" ]; then _err \"dns_api(dns_huaweicloud): Error getting zone id.\" return 1 fi _debug \"Zone ID is:\" \"${zoneid}\" record_id=\"$(_get_recordset_id \"${token}\" \"${fulldomain}\" \"${zoneid}\")\" _recursive_rm_record \"${token}\" \"${fulldomain}\" \"${zoneid}\" \"${record_id}\" ret=\"$?\" if [ \"${ret}\" != \"0\" ]; then _err \"dns_api(dns_huaweicloud): Error removing record.\" return 1 fi return 0 } ################### Private functions below ################################## # _recursive_rm_record # remove all records from the record set # # _token=$1 # _domain=$2 # _zoneid=$3 # _record_id=$4 # # Returns 0 on success _recursive_rm_record() { _token=$1 _domain=$2 _zoneid=$3 _record_id=$4 # Most likely to have problems will huaweicloud side if more than 50 attempts but still cannot fully remove the record set # Maybe can be removed manually in the dashboard _retry_cnt=50 # Remove all records # Therotically HuaweiCloud does not allow more than one record set # But remove them recurringly to increase robusty while [ \"${_record_id}\" != \"0\" ] && [ \"${_retry_cnt}\" != \"0\" ]; do _debug \"Removing Record\" _retry_cnt=$((_retry_cnt - 1)) _rm_record \"${_token}\" \"${_zoneid}\" \"${_record_id}\" _record_id=\"$(_get_recordset_id \"${_token}\" \"${_domain}\" \"${_zoneid}\")\" _debug2 \"Checking record exists: record_id=${_record_id}\" done # Check if retry count is reached if [ \"${_retry_cnt}\" = \"0\" ]; then _debug \"Failed to remove record after 50 attempts, please try removing it manually in the dashboard\" return 1 fi return 0 } # _get_zoneid # # _token=$1 # _domain_string=$2 # # printf \"%s\" \"${_zoneid}\" _get_zoneid() { _token=$1 _domain_string=$2 export _H1=\"X-Auth-Token: ${_token}\" i=1 while true; do h=$(printf \"%s\" \"${_domain_string}\" | cut -d . -f \"$i\"-100) if [ -z \"$h\" ]; then #not valid return 1 fi _debug \"$h\" response=$(_get \"${dns_api}/v2/zones?name=${h}\") _debug2 \"$response\" if _contains \"${response}\" '\"id\"'; then zoneidlist=$(echo \"${response}\" | _egrep_o \"\\\"id\\\": *\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\" | tr -d \" \") zonenamelist=$(echo \"${response}\" | _egrep_o \"\\\"name\\\": *\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\" | tr -d \" \") _debug2 \"Returned Zone ID(s):\" \"${zoneidlist}\" _debug2 \"Returned Zone Name(s):\" \"${zonenamelist}\" zoneidnum=0 zoneidcount=$(echo \"${zoneidlist}\" | grep -c '^') _debug \"Returned Zone ID(s) Count:\" \"${zoneidcount}\" while [ \"${zoneidnum}\" -lt \"${zoneidcount}\" ]; do zoneidnum=$(_math \"$zoneidnum\" + 1) _zoneid=$(echo \"${zoneidlist}\" | sed -n \"${zoneidnum}p\") zonename=$(echo \"${zonenamelist}\" | sed -n \"${zoneidnum}p\") _debug \"Check Zone Name\" \"${zonename}\" if [ \"${zonename}\" = \"${h}.\" ]; then _debug \"Get Zone ID Success.\" _debug \"ZoneID:\" \"${_zoneid}\" printf \"%s\" \"${_zoneid}\" return 0 fi done fi i=$(_math \"$i\" + 1) done return 1 } _get_recordset_id() { _token=$1 _domain=$2 _zoneid=$3 export _H1=\"X-Auth-Token: ${_token}\" response=$(_get \"${dns_api}/v2/zones/${_zoneid}/recordsets?name=${_domain}&status=ACTIVE\") if _contains \"${response}\" '\"id\"'; then _id=\"$(echo \"${response}\" | _egrep_o \"\\\"id\\\": *\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\" | tr -d \" \")\" printf \"%s\" \"${_id}\" return 0 fi printf \"%s\" \"0\" return 1 } _add_record() { _token=$1 _domain=$2 _txtvalue=$3 # Get Existing Records export _H1=\"X-Auth-Token: ${_token}\" response=$(_get \"${dns_api}/v2/zones/${zoneid}/recordsets?name=${_domain}&status=ACTIVE\") _debug2 \"${response}\" _exist_record=$(echo \"${response}\" | _egrep_o '\"records\":[^]]*' | sed 's/\\\"records\\\"\\:\\[//g') _debug \"${_exist_record}\" # Check if record exist # Generate body data if [ -z \"${_exist_record}\" ]; then _post_body=\"{ \\\"name\\\": \\\"${_domain}.\\\", \\\"description\\\": \\\"ACME Challenge\\\", \\\"type\\\": \\\"TXT\\\", \\\"ttl\\\": 1, \\\"records\\\": [ \\\"\\\\\\\"${_txtvalue}\\\\\\\"\\\" ] }\" else _post_body=\"{ \\\"name\\\": \\\"${_domain}.\\\", \\\"description\\\": \\\"ACME Challenge\\\", \\\"type\\\": \\\"TXT\\\", \\\"ttl\\\": 1, \\\"records\\\": [ ${_exist_record},\\\"\\\\\\\"${_txtvalue}\\\\\\\"\\\" ] }\" fi _record_id=\"$(_get_recordset_id \"${_token}\" \"${_domain}\" \"${zoneid}\")\" _debug \"Record Set ID is:\" \"${_record_id}\" # Add brand new records with all old and new records export _H2=\"Content-Type: application/json\" export _H1=\"X-Auth-Token: ${_token}\" _debug2 \"${_post_body}\" if [ -z \"${_exist_record}\" ]; then _post \"${_post_body}\" \"${dns_api}/v2/zones/${zoneid}/recordsets\" >/dev/null else _post \"${_post_body}\" \"${dns_api}/v2/zones/${zoneid}/recordsets/${_record_id}\" false \"PUT\" >/dev/null fi _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" if [ \"$_code\" != \"202\" ]; then _err \"dns_huaweicloud: http code ${_code}\" return 1 fi return 0 } # _rm_record $token $zoneid $recordid # assume ${dns_api} exist # no output # return 0 _rm_record() { _token=$1 _zone_id=$2 _record_id=$3 export _H2=\"Content-Type: application/json\" export _H1=\"X-Auth-Token: ${_token}\" _post \"\" \"${dns_api}/v2/zones/${_zone_id}/recordsets/${_record_id}\" false \"DELETE\" >/dev/null return $? } _get_token() { _username=$1 _password=$2 _domain_name=$3 _debug \"Getting Token\" body=\"{ \\\"auth\\\": { \\\"identity\\\": { \\\"methods\\\": [ \\\"password\\\" ], \\\"password\\\": { \\\"user\\\": { \\\"name\\\": \\\"${_username}\\\", \\\"password\\\": \\\"${_password}\\\", \\\"domain\\\": { \\\"name\\\": \\\"${_domain_name}\\\" } } } }, \\\"scope\\\": { \\\"project\\\": { \\\"name\\\": \\\"ap-southeast-1\\\" } } } }\" export _H1=\"Content-Type: application/json;charset=utf8\" _post \"${body}\" \"${iam_api}/v3/auth/tokens\" >/dev/null _code=$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\") _token=$(grep \"^X-Subject-Token\" \"$HTTP_HEADER\" | cut -d \" \" -f 2-) _secure_debug \"${_code}\" printf \"%s\" \"${_token}\" return 0 }"
        },
        {
            "filename": "file_215.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_215.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_infoblox_info='Infoblox.com Site: Infoblox.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_infoblox Options: Infoblox_Creds Credentials. E.g. \"username:password\" Infoblox_Server Server hostname. IP or FQDN of infoblox appliance Issues: github.com/jasonkeller/acme.sh Author: Jason Keller, Elijah Tenai ' dns_infoblox_add() { ## Nothing to see here, just some housekeeping fulldomain=$1 txtvalue=$2 _info \"Using Infoblox API\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" ## Check for the credentials if [ -z \"$Infoblox_Creds\" ] || [ -z \"$Infoblox_Server\" ]; then Infoblox_Creds=\"\" Infoblox_Server=\"\" _err \"You didn't specify the Infoblox credentials or server (Infoblox_Creds; Infoblox_Server).\" _err \"Please set them via EXPORT Infoblox_Creds=username:password or EXPORT Infoblox_server=ip/hostname and try again.\" return 1 fi if [ -z \"$Infoblox_View\" ]; then _info \"No Infoblox_View set, using fallback value 'default'\" Infoblox_View=\"default\" fi ## Save the credentials to the account file _saveaccountconf Infoblox_Creds \"$Infoblox_Creds\" _saveaccountconf Infoblox_Server \"$Infoblox_Server\" _saveaccountconf Infoblox_View \"$Infoblox_View\" ## URLencode Infoblox View to deal with e.g. spaces Infoblox_ViewEncoded=$(printf \"%b\" \"$Infoblox_View\" | _url_encode) ## Base64 encode the credentials Infoblox_CredsEncoded=$(printf \"%b\" \"$Infoblox_Creds\" | _base64) ## Construct the HTTP Authorization header export _H1=\"Accept-Language:en-US\" export _H2=\"Authorization: Basic $Infoblox_CredsEncoded\" ## Construct the request URL baseurlnObject=\"https://$Infoblox_Server/wapi/v2.2.2/record:txt?name=$fulldomain&text=$txtvalue&view=${Infoblox_ViewEncoded}\" ## Add the challenge record to the Infoblox grid member result=\"$(_post \"\" \"$baseurlnObject\" \"\" \"POST\")\" ## Let's see if we get something intelligible back from the unit if [ \"$(echo \"$result\" | _egrep_o \"record:txt/.*:.*/${Infoblox_ViewEncoded}\")\" ]; then _info \"Successfully created the txt record\" return 0 else _err \"Error encountered during record addition\" _err \"$result\" return 1 fi } dns_infoblox_rm() { ## Nothing to see here, just some housekeeping fulldomain=$1 txtvalue=$2 _info \"Using Infoblox API\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" ## URLencode Infoblox View to deal with e.g. spaces Infoblox_ViewEncoded=$(printf \"%b\" \"$Infoblox_View\" | _url_encode) ## Base64 encode the credentials Infoblox_CredsEncoded=\"$(printf \"%b\" \"$Infoblox_Creds\" | _base64)\" ## Construct the HTTP Authorization header export _H1=\"Accept-Language:en-US\" export _H2=\"Authorization: Basic $Infoblox_CredsEncoded\" ## Does the record exist? Let's check. baseurlnObject=\"https://$Infoblox_Server/wapi/v2.2.2/record:txt?name=$fulldomain&text=$txtvalue&view=${Infoblox_ViewEncoded}&_return_type=xml-pretty\" result=\"$(_get \"$baseurlnObject\")\" ## Let's see if we get something intelligible back from the grid if [ \"$(echo \"$result\" | _egrep_o \"record:txt/.*:.*/${Infoblox_ViewEncoded}\")\" ]; then ## Extract the object reference objRef=\"$(printf \"%b\" \"$result\" | _egrep_o \"record:txt/.*:.*/${Infoblox_ViewEncoded}\")\" objRmUrl=\"https://$Infoblox_Server/wapi/v2.2.2/$objRef\" ## Delete them! All the stale records! rmResult=\"$(_post \"\" \"$objRmUrl\" \"\" \"DELETE\")\" ## Let's see if that worked if [ \"$(echo \"$rmResult\" | _egrep_o \"record:txt/.*:.*/${Infoblox_ViewEncoded}\")\" ]; then _info \"Successfully deleted $objRef\" return 0 else _err \"Error occurred during txt record delete\" _err \"$rmResult\" return 1 fi else _err \"Record to delete didn't match an existing record\" _err \"$result\" return 1 fi } #################### Private functions below ##################################"
        },
        {
            "filename": "file_216.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_216.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_infomaniak_info='Infomaniak.com Site: Infomaniak.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_infomaniak Options: INFOMANIAK_API_TOKEN API Token Issues: github.com/acmesh-official/acme.sh/issues/3188 ' # To use this API you need visit the API dashboard of your account # once logged into https://manager.infomaniak.com add /api/dashboard to the URL # # Note: the URL looks like this: # https://manager.infomaniak.com/v3/<account_id>/api/dashboard # Then generate a token with the scope Domain # this is given as an environment variable INFOMANIAK_API_TOKEN # base variables DEFAULT_INFOMANIAK_API_URL=\"https://api.infomaniak.com\" DEFAULT_INFOMANIAK_TTL=300 ######## Public functions ##################### #Usage: dns_infomaniak_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_infomaniak_add() { INFOMANIAK_API_TOKEN=\"${INFOMANIAK_API_TOKEN:-$(_readaccountconf_mutable INFOMANIAK_API_TOKEN)}\" INFOMANIAK_API_URL=\"${INFOMANIAK_API_URL:-$(_readaccountconf_mutable INFOMANIAK_API_URL)}\" INFOMANIAK_TTL=\"${INFOMANIAK_TTL:-$(_readaccountconf_mutable INFOMANIAK_TTL)}\" if [ -z \"$INFOMANIAK_API_TOKEN\" ]; then INFOMANIAK_API_TOKEN=\"\" _err \"Please provide a valid Infomaniak API token in variable INFOMANIAK_API_TOKEN\" return 1 fi if [ -z \"$INFOMANIAK_API_URL\" ]; then INFOMANIAK_API_URL=\"$DEFAULT_INFOMANIAK_API_URL\" fi if [ -z \"$INFOMANIAK_TTL\" ]; then INFOMANIAK_TTL=\"$DEFAULT_INFOMANIAK_TTL\" fi #save the token to the account conf file. _saveaccountconf_mutable INFOMANIAK_API_TOKEN \"$INFOMANIAK_API_TOKEN\" if [ \"$INFOMANIAK_API_URL\" != \"$DEFAULT_INFOMANIAK_API_URL\" ]; then _saveaccountconf_mutable INFOMANIAK_API_URL \"$INFOMANIAK_API_URL\" fi if [ \"$INFOMANIAK_TTL\" != \"$DEFAULT_INFOMANIAK_TTL\" ]; then _saveaccountconf_mutable INFOMANIAK_TTL \"$INFOMANIAK_TTL\" fi export _H1=\"Authorization: Bearer $INFOMANIAK_API_TOKEN\" export _H2=\"Content-Type: application/json\" fulldomain=\"$1\" txtvalue=\"$2\" _info \"Infomaniak DNS API\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" fqdn=${fulldomain#_acme-challenge.} # guess which base domain to add record to zone_and_id=$(_find_zone \"$fqdn\") if [ -z \"$zone_and_id\" ]; then _err \"cannot find zone to modify\" return 1 fi zone=${zone_and_id% *} domain_id=${zone_and_id#* } # extract first part of domain key=${fulldomain%.\"$zone\"} _debug \"zone:$zone id:$domain_id key:$key\" # payload data=\"{\\\"type\\\": \\\"TXT\\\", \\\"source\\\": \\\"$key\\\", \\\"target\\\": \\\"$txtvalue\\\", \\\"ttl\\\": $INFOMANIAK_TTL}\" # API call response=$(_post \"$data\" \"${INFOMANIAK_API_URL}/1/domain/$domain_id/dns/record\") if [ -n \"$response\" ] && echo \"$response\" | _contains '\"result\":\"success\"'; then _info \"Record added\" _debug \"Response: $response\" return 0 fi _err \"could not create record\" _debug \"Response: $response\" return 1 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_infomaniak_rm() { INFOMANIAK_API_TOKEN=\"${INFOMANIAK_API_TOKEN:-$(_readaccountconf_mutable INFOMANIAK_API_TOKEN)}\" INFOMANIAK_API_URL=\"${INFOMANIAK_API_URL:-$(_readaccountconf_mutable INFOMANIAK_API_URL)}\" INFOMANIAK_TTL=\"${INFOMANIAK_TTL:-$(_readaccountconf_mutable INFOMANIAK_TTL)}\" if [ -z \"$INFOMANIAK_API_TOKEN\" ]; then INFOMANIAK_API_TOKEN=\"\" _err \"Please provide a valid Infomaniak API token in variable INFOMANIAK_API_TOKEN\" return 1 fi if [ -z \"$INFOMANIAK_API_URL\" ]; then INFOMANIAK_API_URL=\"$DEFAULT_INFOMANIAK_API_URL\" fi if [ -z \"$INFOMANIAK_TTL\" ]; then INFOMANIAK_TTL=\"$DEFAULT_INFOMANIAK_TTL\" fi #save the token to the account conf file. _saveaccountconf_mutable INFOMANIAK_API_TOKEN \"$INFOMANIAK_API_TOKEN\" if [ \"$INFOMANIAK_API_URL\" != \"$DEFAULT_INFOMANIAK_API_URL\" ]; then _saveaccountconf_mutable INFOMANIAK_API_URL \"$INFOMANIAK_API_URL\" fi if [ \"$INFOMANIAK_TTL\" != \"$DEFAULT_INFOMANIAK_TTL\" ]; then _saveaccountconf_mutable INFOMANIAK_TTL \"$INFOMANIAK_TTL\" fi export _H1=\"Authorization: Bearer $INFOMANIAK_API_TOKEN\" export _H2=\"ContentType: application/json\" fulldomain=$1 txtvalue=$2 _info \"Infomaniak DNS API\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" fqdn=${fulldomain#_acme-challenge.} # guess which base domain to add record to zone_and_id=$(_find_zone \"$fqdn\") if [ -z \"$zone_and_id\" ]; then _err \"cannot find zone to modify\" return 1 fi zone=${zone_and_id% *} domain_id=${zone_and_id#* } # extract first part of domain key=${fulldomain%.\"$zone\"} _debug \"zone:$zone id:$domain_id key:$key\" # find previous record # shellcheck disable=SC1004 record_id=$(_get \"${INFOMANIAK_API_URL}/1/domain/$domain_id/dns/record\" | sed 's/.*\"data\":\\[\\(.*\\)\\]}/\\1/; s/},{/}\\ {/g' | sed -n 's/.*\"id\":\"*\\([0-9]*\\)\"*.*\"source_idn\":\"'\"$fulldomain\"'\".*\"target_idn\":\"'\"$txtvalue\"'\".*/\\1/p') if [ -z \"$record_id\" ]; then _err \"could not find record to delete\" return 1 fi _debug \"record_id: $record_id\" # API call response=$(_post \"\" \"${INFOMANIAK_API_URL}/1/domain/$domain_id/dns/record/$record_id\" \"\" DELETE) if [ -n \"$response\" ] && echo \"$response\" | _contains '\"result\":\"success\"'; then _info \"Record deleted\" return 0 fi _err \"could not delete record\" return 1 } #################### Private functions below ################################## _get_domain_id() { domain=\"$1\" # shellcheck disable=SC1004 _get \"${INFOMANIAK_API_URL}/1/product?service_name=domain&customer_name=$domain\" | sed 's/.*\"data\":\\[{\\(.*\\)}\\]}/\\1/; s/,/\\ /g' | sed -n 's/^\"id\":\\(.*\\)/\\1/p' } _find_zone() { zone=\"$1\" # find domain in list, removing . parts sequentialy while _contains \"$zone\" '\\.'; do _debug \"testing $zone\" id=$(_get_domain_id \"$zone\") if [ -n \"$id\" ]; then echo \"$zone $id\" return fi zone=${zone#*.} done }"
        },
        {
            "filename": "file_217.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_217.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_internetbs_info='InternetBS.net Site: InternetBS.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_internetbs Options: INTERNETBS_API_KEY API Key INTERNETBS_API_PASSWORD API Password Issues: github.com/acmesh-official/acme.sh/issues/2261 Author: Ne-Lexa <alexey@nelexa.ru> ' INTERNETBS_API_URL=\"https://api.internet.bs\" ######## Public functions ##################### #Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_internetbs_add() { fulldomain=$1 txtvalue=$2 INTERNETBS_API_KEY=\"${INTERNETBS_API_KEY:-$(_readaccountconf_mutable INTERNETBS_API_KEY)}\" INTERNETBS_API_PASSWORD=\"${INTERNETBS_API_PASSWORD:-$(_readaccountconf_mutable INTERNETBS_API_PASSWORD)}\" if [ -z \"$INTERNETBS_API_KEY\" ] || [ -z \"$INTERNETBS_API_PASSWORD\" ]; then INTERNETBS_API_KEY=\"\" INTERNETBS_API_PASSWORD=\"\" _err \"You didn't specify the INTERNET.BS api key and password yet.\" _err \"Please create you key and try again.\" return 1 fi _saveaccountconf_mutable INTERNETBS_API_KEY \"$INTERNETBS_API_KEY\" _saveaccountconf_mutable INTERNETBS_API_PASSWORD \"$INTERNETBS_API_PASSWORD\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # https://testapi.internet.bs/Domain/DnsRecord/Add?ApiKey=testapi&Password=testpass&FullRecordName=w3.test-api-domain7.net&Type=CNAME&Value=www.internet.bs%&ResponseFormat=json if _internetbs_rest POST \"Domain/DnsRecord/Add\" \"FullRecordName=${_sub_domain}.${_domain}&Type=TXT&Value=${txtvalue}&ResponseFormat=json\"; then if ! _contains \"$response\" \"\\\"status\\\":\\\"SUCCESS\\\"\"; then _err \"ERROR add TXT record\" _err \"$response\" return 1 fi _info \"txt record add success.\" return 0 fi return 1 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_internetbs_rm() { fulldomain=$1 txtvalue=$2 INTERNETBS_API_KEY=\"${INTERNETBS_API_KEY:-$(_readaccountconf_mutable INTERNETBS_API_KEY)}\" INTERNETBS_API_PASSWORD=\"${INTERNETBS_API_PASSWORD:-$(_readaccountconf_mutable INTERNETBS_API_PASSWORD)}\" if [ -z \"$INTERNETBS_API_KEY\" ] || [ -z \"$INTERNETBS_API_PASSWORD\" ]; then INTERNETBS_API_KEY=\"\" INTERNETBS_API_PASSWORD=\"\" _err \"You didn't specify the INTERNET.BS api key and password yet.\" _err \"Please create you key and try again.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" # https://testapi.internet.bs/Domain/DnsRecord/List?ApiKey=testapi&Password=testpass&Domain=test-api-domain7.net&FilterType=CNAME&ResponseFormat=json _internetbs_rest POST \"Domain/DnsRecord/List\" \"Domain=$_domain&FilterType=TXT&ResponseFormat=json\" if ! _contains \"$response\" \"\\\"status\\\":\\\"SUCCESS\\\"\"; then _err \"ERROR list dns records\" _err \"$response\" return 1 fi if _contains \"$response\" \"\\name\\\":\\\"${_sub_domain}.${_domain}\\\"\"; then _info \"txt record find.\" # https://testapi.internet.bs/Domain/DnsRecord/Remove?ApiKey=testapi&Password=testpass&FullRecordName=www.test-api-domain7.net&Type=cname&ResponseFormat=json _internetbs_rest POST \"Domain/DnsRecord/Remove\" \"FullRecordName=${_sub_domain}.${_domain}&Type=TXT&ResponseFormat=json\" if ! _contains \"$response\" \"\\\"status\\\":\\\"SUCCESS\\\"\"; then _err \"ERROR remove dns record\" _err \"$response\" return 1 fi _info \"txt record deleted success.\" return 0 fi return 1 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=12345 _get_root() { domain=$1 i=2 p=1 # https://testapi.internet.bs/Domain/List?ApiKey=testapi&Password=testpass&CompactList=yes&ResponseFormat=json if _internetbs_rest POST \"Domain/List\" \"CompactList=yes&ResponseFormat=json\"; then if ! _contains \"$response\" \"\\\"status\\\":\\\"SUCCESS\\\"\"; then _err \"ERROR fetch domain list\" _err \"$response\" return 1 fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f ${i}-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"\\\"$h\\\"\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-${p}) _domain=${h} return 0 fi p=${i} i=$(_math \"$i\" + 1) done fi return 1 } #Usage: method URI data _internetbs_rest() { m=\"$1\" ep=\"$2\" data=\"$3\" url=\"${INTERNETBS_API_URL}/${ep}\" _debug url \"$url\" apiKey=\"$(printf \"%s\" \"${INTERNETBS_API_KEY}\" | _url_encode)\" password=\"$(printf \"%s\" \"${INTERNETBS_API_PASSWORD}\" | _url_encode)\" if [ \"$m\" = \"GET\" ]; then response=\"$(_get \"${url}?ApiKey=${apiKey}&Password=${password}&${data}\" | tr -d '\\r')\" else _debug2 data \"$data\" response=\"$(_post \"$data\" \"${url}?ApiKey=${apiKey}&Password=${password}\" | tr -d '\\r')\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_218.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_218.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_inwx_info='INWX.de Site: INWX.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_inwx Options: INWX_User Username INWX_Password Password ' # Dependencies: # ------------- # - oathtool (When using 2 Factor Authentication) INWX_Api=\"https://api.domrobot.com/xmlrpc/\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_inwx_add() { fulldomain=$1 txtvalue=$2 INWX_User=\"${INWX_User:-$(_readaccountconf_mutable INWX_User)}\" INWX_Password=\"${INWX_Password:-$(_readaccountconf_mutable INWX_Password)}\" INWX_Shared_Secret=\"${INWX_Shared_Secret:-$(_readaccountconf_mutable INWX_Shared_Secret)}\" if [ -z \"$INWX_User\" ] || [ -z \"$INWX_Password\" ]; then INWX_User=\"\" INWX_Password=\"\" _err \"You don't specify inwx user and password yet.\" _err \"Please create you key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable INWX_User \"$INWX_User\" _saveaccountconf_mutable INWX_Password \"$INWX_Password\" _saveaccountconf_mutable INWX_Shared_Secret \"$INWX_Shared_Secret\" if ! _inwx_login; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" _inwx_add_record \"$_domain\" \"$_sub_domain\" \"$txtvalue\" } #fulldomain txtvalue dns_inwx_rm() { fulldomain=$1 txtvalue=$2 INWX_User=\"${INWX_User:-$(_readaccountconf_mutable INWX_User)}\" INWX_Password=\"${INWX_Password:-$(_readaccountconf_mutable INWX_Password)}\" INWX_Shared_Secret=\"${INWX_Shared_Secret:-$(_readaccountconf_mutable INWX_Shared_Secret)}\" if [ -z \"$INWX_User\" ] || [ -z \"$INWX_Password\" ]; then INWX_User=\"\" INWX_Password=\"\" _err \"You don't specify inwx user and password yet.\" _err \"Please create you key and try again.\" return 1 fi if ! _inwx_login; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>nameserver.info</methodName> <params> <param> <value> <struct> <member> <name>domain</name> <value> <string>%s</string> </value> </member> <member> <name>type</name> <value> <string>TXT</string> </value> </member> <member> <name>name</name> <value> <string>%s</string> </value> </member> </struct> </value> </param> </params> </methodCall>' \"$_domain\" \"$_sub_domain\") response=\"$(_post \"$xml_content\" \"$INWX_Api\" \"\" \"POST\")\" if ! _contains \"$response\" \"Command completed successfully\"; then _err \"Error could not get txt records\" return 1 fi if ! printf \"%s\" \"$response\" | grep \"count\" >/dev/null; then _info \"Do not need to delete record\" else _record_id=$(printf '%s' \"$response\" | _egrep_o '.*(<member><name>record){1}(.*)([0-9]+){1}' | _egrep_o '<name>id<\\/name><value><int>[0-9]+' | _egrep_o '[0-9]+') _info \"Deleting record\" _inwx_delete_record \"$_record_id\" fi } #################### Private functions below ################################## _inwx_check_cookie() { INWX_Cookie=\"${INWX_Cookie:-$(_readaccountconf_mutable INWX_Cookie)}\" if [ -z \"$INWX_Cookie\" ]; then _debug \"No cached cookie found\" return 1 fi _H1=\"$INWX_Cookie\" export _H1 xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>account.info</methodName> </methodCall>') response=\"$(_post \"$xml_content\" \"$INWX_Api\" \"\" \"POST\")\" if _contains \"$response\" \"<member><name>code</name><value><int>1000</int></value></member>\"; then _debug \"Cached cookie still valid\" return 0 fi _debug \"Cached cookie no longer valid\" _H1=\"\" export _H1 INWX_Cookie=\"\" _saveaccountconf_mutable INWX_Cookie \"$INWX_Cookie\" return 1 } _htmlEscape() { _s=\"$1\" _s=$(echo \"$_s\" | sed \"s/&/&amp;/g\") _s=$(echo \"$_s\" | sed \"s/</\\&lt;/g\") _s=$(echo \"$_s\" | sed \"s/>/\\&gt;/g\") _s=$(echo \"$_s\" | sed 's/\"/\\&quot;/g') printf -- %s \"$_s\" } _inwx_login() { if _inwx_check_cookie; then _debug \"Already logged in\" return 0 fi XML_PASS=$(_htmlEscape \"$INWX_Password\") xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>account.login</methodName> <params> <param> <value> <struct> <member> <name>user</name> <value> <string>%s</string> </value> </member> <member> <name>pass</name> <value> <string>%s</string> </value> </member> </struct> </value> </param> </params> </methodCall>' \"$INWX_User\" \"$XML_PASS\") response=\"$(_post \"$xml_content\" \"$INWX_Api\" \"\" \"POST\")\" INWX_Cookie=$(printf \"Cookie: %s\" \"$(grep \"domrobot=\" \"$HTTP_HEADER\" | grep -i \"^Set-Cookie:\" | _tail_n 1 | _egrep_o 'domrobot=[^;]*;' | tr -d ';')\") _H1=$INWX_Cookie export _H1 export INWX_Cookie _saveaccountconf_mutable INWX_Cookie \"$INWX_Cookie\" if ! _contains \"$response\" \"<member><name>code</name><value><int>1000</int></value></member>\"; then _err \"INWX API: Authentication error (username/password correct?)\" return 1 fi #https://github.com/inwx/php-client/blob/master/INWX/Domrobot.php#L71 if _contains \"$response\" \"<member><name>tfa</name><value><string>GOOGLE-AUTH</string></value></member>\"; then if [ -z \"$INWX_Shared_Secret\" ]; then _err \"INWX API: Mobile TAN detected.\" _err \"Please define a shared secret.\" return 1 fi if ! _exists oathtool; then _err \"Please install oathtool to use 2 Factor Authentication.\" _err \"\" return 1 fi tan=\"$(oathtool --base32 --totp \"${INWX_Shared_Secret}\" 2>/dev/null)\" xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>account.unlock</methodName> <params> <param> <value> <struct> <member> <name>tan</name> <value> <string>%s</string> </value> </member> </struct> </value> </param> </params> </methodCall>' \"$tan\") response=\"$(_post \"$xml_content\" \"$INWX_Api\" \"\" \"POST\")\" if ! _contains \"$response\" \"<member><name>code</name><value><int>1000</int></value></member>\"; then _err \"INWX API: Mobile TAN not correct.\" return 1 fi fi } _get_root() { domain=$1 _debug \"get root\" domain=$1 i=2 p=1 xml_content='<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>nameserver.list</methodName> <params> <param> <value> <struct> <member> <name>pagelimit</name> <value> <int>9999</int> </value> </member> </struct> </value> </param> </params> </methodCall>' response=\"$(_post \"$xml_content\" \"$INWX_Api\" \"\" \"POST\")\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"$h\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _inwx_delete_record() { record_id=$1 xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>nameserver.deleteRecord</methodName> <params> <param> <value> <struct> <member> <name>id</name> <value> <int>%s</int> </value> </member> </struct> </value> </param> </params> </methodCall>' \"$record_id\") response=\"$(_post \"$xml_content\" \"$INWX_Api\" \"\" \"POST\")\" if ! printf \"%s\" \"$response\" | grep \"Command completed successfully\" >/dev/null; then _err \"Error\" return 1 fi return 0 } _inwx_update_record() { record_id=$1 txtval=$2 xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>nameserver.updateRecord</methodName> <params> <param> <value> <struct> <member> <name>content</name> <value> <string>%s</string> </value> </member> <member> <name>id</name> <value> <int>%s</int> </value> </member> </struct> </value> </param> </params> </methodCall>' \"$txtval\" \"$record_id\") response=\"$(_post \"$xml_content\" \"$INWX_Api\" \"\" \"POST\")\" if ! printf \"%s\" \"$response\" | grep \"Command completed successfully\" >/dev/null; then _err \"Error\" return 1 fi return 0 } _inwx_add_record() { domain=$1 sub_domain=$2 txtval=$3 xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>nameserver.createRecord</methodName> <params> <param> <value> <struct> <member> <name>domain</name> <value> <string>%s</string> </value> </member> <member> <name>type</name> <value> <string>TXT</string> </value> </member> <member> <name>content</name> <value> <string>%s</string> </value> </member> <member> <name>name</name> <value> <string>%s</string> </value> </member> </struct> </value> </param> </params> </methodCall>' \"$domain\" \"$txtval\" \"$sub_domain\") response=\"$(_post \"$xml_content\" \"$INWX_Api\" \"\" \"POST\")\" if ! printf \"%s\" \"$response\" | grep \"Command completed successfully\" >/dev/null; then _err \"Error\" return 1 fi return 0 }"
        },
        {
            "filename": "file_219.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_219.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_ionos_info='IONOS.de Site: IONOS.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_ionos Options: IONOS_PREFIX Prefix IONOS_SECRET Secret Issues: github.com/acmesh-official/acme.sh/issues/3379 ' IONOS_API=\"https://api.hosting.ionos.com/dns\" IONOS_ROUTE_ZONES=\"/v1/zones\" IONOS_TXT_TTL=60 # minimum accepted by API IONOS_TXT_PRIO=10 dns_ionos_add() { fulldomain=$1 txtvalue=$2 if ! _ionos_init; then return 1 fi _body=\"[{\\\"name\\\":\\\"$_sub_domain.$_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":$IONOS_TXT_TTL,\\\"prio\\\":$IONOS_TXT_PRIO,\\\"disabled\\\":false}]\" if _ionos_rest POST \"$IONOS_ROUTE_ZONES/$_zone_id/records\" \"$_body\" && [ \"$_code\" = \"201\" ]; then _info \"TXT record has been created successfully.\" return 0 fi return 1 } dns_ionos_rm() { fulldomain=$1 txtvalue=$2 if ! _ionos_init; then return 1 fi if ! _ionos_get_record \"$fulldomain\" \"$_zone_id\" \"$txtvalue\"; then _err \"Could not find _acme-challenge TXT record.\" return 1 fi if _ionos_rest DELETE \"$IONOS_ROUTE_ZONES/$_zone_id/records/$_record_id\" && [ \"$_code\" = \"200\" ]; then _info \"TXT record has been deleted successfully.\" return 0 fi return 1 } _ionos_init() { IONOS_PREFIX=\"${IONOS_PREFIX:-$(_readaccountconf_mutable IONOS_PREFIX)}\" IONOS_SECRET=\"${IONOS_SECRET:-$(_readaccountconf_mutable IONOS_SECRET)}\" if [ -z \"$IONOS_PREFIX\" ] || [ -z \"$IONOS_SECRET\" ]; then _err \"You didn't specify an IONOS api prefix and secret yet.\" _err \"Read https://beta.developer.hosting.ionos.de/docs/getstarted to learn how to get a prefix and secret.\" _err \"\" _err \"Then set them before calling acme.sh:\" _err \"\\$ export IONOS_PREFIX=\\\"...\\\"\" _err \"\\$ export IONOS_SECRET=\\\"...\\\"\" _err \"\\$ acme.sh --issue -d ... --dns dns_ionos\" return 1 fi _saveaccountconf_mutable IONOS_PREFIX \"$IONOS_PREFIX\" _saveaccountconf_mutable IONOS_SECRET \"$IONOS_SECRET\" if ! _get_root \"$fulldomain\"; then _err \"Cannot find this domain in your IONOS account.\" return 1 fi } _get_root() { domain=$1 i=1 p=1 if _ionos_rest GET \"$IONOS_ROUTE_ZONES\"; then _response=\"$(echo \"$_response\" | tr -d \"\\n\")\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then return 1 fi _zone=\"$(echo \"$_response\" | _egrep_o \"\\\"name\\\":\\\"$h\\\".*\\}\")\" if [ \"$_zone\" ]; then _zone_id=$(printf \"%s\\n\" \"$_zone\" | _egrep_o \"\\\"id\\\":\\\"[a-fA-F0-9\\-]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d '\\\"') if [ \"$_zone_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done fi return 1 } _ionos_get_record() { fulldomain=$1 zone_id=$2 txtrecord=$3 if _ionos_rest GET \"$IONOS_ROUTE_ZONES/$zone_id?recordName=$fulldomain&recordType=TXT\"; then _response=\"$(echo \"$_response\" | tr -d \"\\n\")\" _record=\"$(echo \"$_response\" | _egrep_o \"\\\"name\\\":\\\"$fulldomain\\\"[^\\}]*\\\"type\\\":\\\"TXT\\\"[^\\}]*\\\"content\\\":\\\"\\\\\\\\\\\"$txtrecord\\\\\\\\\\\"\\\".*\\}\")\" if [ \"$_record\" ]; then _record_id=$(printf \"%s\\n\" \"$_record\" | _egrep_o \"\\\"id\\\":\\\"[a-fA-F0-9\\-]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d '\\\"') return 0 fi fi return 1 } _ionos_rest() { method=\"$1\" route=\"$2\" data=\"$3\" IONOS_API_KEY=\"$(printf \"%s.%s\" \"$IONOS_PREFIX\" \"$IONOS_SECRET\")\" export _H1=\"X-API-Key: $IONOS_API_KEY\" # clear headers : >\"$HTTP_HEADER\" if [ \"$method\" != \"GET\" ]; then export _H2=\"Accept: application/json\" export _H3=\"Content-Type: application/json\" _response=\"$(_post \"$data\" \"$IONOS_API$route\" \"\" \"$method\" \"application/json\")\" else export _H2=\"Accept: */*\" export _H3= _response=\"$(_get \"$IONOS_API$route\")\" fi _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" if [ \"$?\" != \"0\" ]; then _err \"Error $route: $_response\" return 1 fi _debug2 \"_response\" \"$_response\" _debug2 \"_code\" \"$_code\" return 0 }"
        },
        {
            "filename": "file_220.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_220.sh",
            "content": "#!/usr/bin/env sh # Supports IONOS Cloud DNS API v1.15.4 # # Usage: # Export IONOS_TOKEN before calling acme.sh: # $ export IONOS_TOKEN=\"...\" # # $ acme.sh --issue --dns dns_ionos_cloud ... IONOS_CLOUD_API=\"https://dns.de-fra.ionos.com\" IONOS_CLOUD_ROUTE_ZONES=\"/zones\" dns_ionos_cloud_add() { fulldomain=$1 txtvalue=$2 if ! _ionos_init; then return 1 fi _record_name=$(printf \"%s\" \"$fulldomain\" | cut -d . -f 1) _body=\"{\\\"properties\\\":{\\\"name\\\":\\\"$_record_name\\\", \\\"type\\\":\\\"TXT\\\", \\\"content\\\":\\\"$txtvalue\\\"}}\" if _ionos_cloud_rest POST \"$IONOS_CLOUD_ROUTE_ZONES/$_zone_id/records\" \"$_body\" && [ \"$_code\" = \"202\" ]; then _info \"TXT record has been created successfully.\" return 0 fi return 1 } dns_ionos_cloud_rm() { fulldomain=$1 txtvalue=$2 if ! _ionos_init; then return 1 fi if ! _ionos_cloud_get_record \"$_zone_id\" \"$txtvalue\" \"$fulldomain\"; then _err \"Could not find _acme-challenge TXT record.\" return 1 fi if _ionos_cloud_rest DELETE \"$IONOS_CLOUD_ROUTE_ZONES/$_zone_id/records/$_record_id\" && [ \"$_code\" = \"202\" ]; then _info \"TXT record has been deleted successfully.\" return 0 fi return 1 } _ionos_init() { IONOS_TOKEN=\"${IONOS_TOKEN:-$(_readaccountconf_mutable IONOS_TOKEN)}\" if [ -z \"$IONOS_TOKEN\" ]; then _err \"You didn't specify an IONOS token yet.\" _err \"Read https://api.ionos.com/docs/authentication/v1/#tag/tokens/operation/tokensGenerate to learn how to get a token.\" _err \"You need to set it before calling acme.sh:\" _err \"\\$ export IONOS_TOKEN=\\\"...\\\"\" _err \"\\$ acme.sh --issue -d ... --dns dns_ionos_cloud\" return 1 fi _saveaccountconf_mutable IONOS_TOKEN \"$IONOS_TOKEN\" if ! _get_cloud_zone \"$fulldomain\"; then _err \"Cannot find zone $zone in your IONOS account.\" return 1 fi return 0 } _get_cloud_zone() { domain=$1 zone=$(printf \"%s\" \"$domain\" | cut -d . -f 2-) if _ionos_cloud_rest GET \"$IONOS_CLOUD_ROUTE_ZONES?filter.zoneName=$zone\"; then _response=\"$(echo \"$_response\" | tr -d \"\\n\")\" _zone_list_items=$(echo \"$_response\" | _egrep_o \"\\\"items\\\":.*\") _zone_id=$(printf \"%s\\n\" \"$_zone_list_items\" | _egrep_o \"\\\"id\\\":\\\"[a-fA-F0-9\\-]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d '\\\"') if [ \"$_zone_id\" ]; then return 0 fi fi return 1 } _ionos_cloud_get_record() { zone_id=$1 txtrecord=$2 # this is to transform the domain to lower case fulldomain=$(printf \"%s\" \"$3\" | _lower_case) # this is to transform record name to lower case # IONOS Cloud API transforms all record names to lower case _record_name=$(printf \"%s\" \"$fulldomain\" | cut -d . -f 1 | _lower_case) if _ionos_cloud_rest GET \"$IONOS_CLOUD_ROUTE_ZONES/$zone_id/records\"; then _response=\"$(echo \"$_response\" | tr -d \"\\n\")\" pattern=\"\\{\\\"id\\\":\\\"[a-fA-F0-9\\-]*\\\",\\\"type\\\":\\\"record\\\",\\\"href\\\":\\\"/zones/$zone_id/records/[a-fA-F0-9\\-]*\\\",\\\"metadata\\\":\\{\\\"createdDate\\\":\\\"[A-Z0-9\\:\\.\\-]*\\\",\\\"lastModifiedDate\\\":\\\"[A-Z0-9\\:\\.\\-]*\\\",\\\"fqdn\\\":\\\"$fulldomain\\\",\\\"state\\\":\\\"AVAILABLE\\\",\\\"zoneId\\\":\\\"$zone_id\\\"\\},\\\"properties\\\":\\{\\\"content\\\":\\\"$txtrecord\\\",\\\"enabled\\\":true,\\\"name\\\":\\\"$_record_name\\\",\\\"priority\\\":[0-9]*,\\\"ttl\\\":[0-9]*,\\\"type\\\":\\\"TXT\\\"\\}\\}\" _record=\"$(echo \"$_response\" | _egrep_o \"$pattern\")\" if [ \"$_record\" ]; then _record_id=$(printf \"%s\\n\" \"$_record\" | _egrep_o \"\\\"id\\\":\\\"[a-fA-F0-9\\-]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d '\\\"') return 0 fi fi return 1 } _ionos_cloud_rest() { method=\"$1\" route=\"$2\" data=\"$3\" export _H1=\"Authorization: Bearer $IONOS_TOKEN\" # clear headers : >\"$HTTP_HEADER\" if [ \"$method\" != \"GET\" ]; then _response=\"$(_post \"$data\" \"$IONOS_CLOUD_API$route\" \"\" \"$method\" \"application/json\")\" else _response=\"$(_get \"$IONOS_CLOUD_API$route\")\" fi _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" if [ \"$?\" != \"0\" ]; then _err \"Error $route: $_response\" return 1 fi _debug2 \"_response\" \"$_response\" _debug2 \"_code\" \"$_code\" return 0 }"
        },
        {
            "filename": "file_221.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_221.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_ipv64_info='IPv64.net Site: IPv64.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_ipv64 Options: IPv64_Token API Token Issues: github.com/acmesh-official/acme.sh/issues/4419 Author: Roman Lumetsberger ' IPv64_API=\"https://ipv64.net/api\" ######## Public functions ###################### #Usage: dns_ipv64_add _acme-challenge.domain.ipv64.net \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_ipv64_add() { fulldomain=$1 txtvalue=$2 IPv64_Token=\"${IPv64_Token:-$(_readaccountconf_mutable IPv64_Token)}\" if [ -z \"$IPv64_Token\" ]; then _err \"You must export variable: IPv64_Token\" _err \"The API Key for your IPv64 account is necessary.\" _err \"You can look it up in your IPv64 account.\" return 1 fi # Now save the credentials. _saveaccountconf_mutable IPv64_Token \"$IPv64_Token\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" \"$fulldomain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # convert to lower case _domain=\"$(echo \"$_domain\" | _lower_case)\" _sub_domain=\"$(echo \"$_sub_domain\" | _lower_case)\" # Now add the TXT record _info \"Trying to add TXT record\" if _ipv64_rest \"POST\" \"add_record=$_domain&praefix=$_sub_domain&type=TXT&content=$txtvalue\"; then _info \"TXT record has been successfully added.\" return 0 else _err \"Errors happened during adding the TXT record, response=$_response\" return 1 fi } #Usage: fulldomain txtvalue #Usage: dns_ipv64_rm _acme-challenge.domain.ipv64.net \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" #Remove the txt record after validation. dns_ipv64_rm() { fulldomain=$1 txtvalue=$2 IPv64_Token=\"${IPv64_Token:-$(_readaccountconf_mutable IPv64_Token)}\" if [ -z \"$IPv64_Token\" ]; then _err \"You must export variable: IPv64_Token\" _err \"The API Key for your IPv64 account is necessary.\" _err \"You can look it up in your IPv64 account.\" return 1 fi if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" \"$fulldomain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # convert to lower case _domain=\"$(echo \"$_domain\" | _lower_case)\" _sub_domain=\"$(echo \"$_sub_domain\" | _lower_case)\" # Now delete the TXT record _info \"Trying to delete TXT record\" if _ipv64_rest \"DELETE\" \"del_record=$_domain&praefix=$_sub_domain&type=TXT&content=$txtvalue\"; then _info \"TXT record has been successfully deleted.\" return 0 else _err \"Errors happened during deleting the TXT record, response=$_response\" return 1 fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=\"$1\" i=1 p=1 _ipv64_get \"get_domains\" domain_data=$_response while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f \"$i\"-100) if [ -z \"$h\" ]; then #not valid return 1 fi #if _contains \"$domain_data\" \"\\\"\"$h\"\\\"\\:\"; then if _contains \"$domain_data\" \"\\\"\"\"$h\"\"\\\"\\:\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-\"$p\") _domain=\"$h\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } #send get request to api # $1 has to set the api-function _ipv64_get() { url=\"$IPv64_API?$1\" export _H1=\"Authorization: Bearer $IPv64_Token\" _response=$(_get \"$url\") _response=\"$(echo \"$_response\" | _normalizeJson)\" if _contains \"$_response\" \"429 Too Many Requests\"; then _info \"API throttled, sleeping to reset the limit\" _sleep 10 _response=$(_get \"$url\") _response=\"$(echo \"$_response\" | _normalizeJson)\" fi } _ipv64_rest() { url=\"$IPv64_API\" export _H1=\"Authorization: Bearer $IPv64_Token\" export _H2=\"Content-Type: application/x-www-form-urlencoded\" _response=$(_post \"$2\" \"$url\" \"\" \"$1\") if _contains \"$_response\" \"429 Too Many Requests\"; then _info \"API throttled, sleeping to reset the limit\" _sleep 10 _response=$(_post \"$2\" \"$url\" \"\" \"$1\") fi if ! _contains \"$_response\" \"\\\"info\\\":\\\"success\\\"\"; then return 1 fi _debug2 response \"$_response\" return 0 }"
        },
        {
            "filename": "file_222.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_222.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_ispconfig_info='ISPConfig Server API Site: ISPConfig.org Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_ispconfig Options: ISPC_User Remote User ISPC_Password Remote Password ISPC_Api API URL. E.g. \"https://ispc.domain.tld:8080/remote/json.php\" ISPC_Api_Insecure Insecure TLS. 0: check for cert validity, 1: always accept ' # ISPConfig 3.1 API # User must provide login data and URL to the ISPConfig installation incl. port. # The remote user in ISPConfig must have access to: # - DNS txt Functions # - DNS zone functions # - Client functions ######## Public functions ##################### #Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_ispconfig_add() { fulldomain=\"${1}\" txtvalue=\"${2}\" _debug \"Calling: dns_ispconfig_add() '${fulldomain}' '${txtvalue}'\" _ISPC_credentials && _ISPC_login && _ISPC_getZoneInfo && _ISPC_addTxt } #Usage: dns_myapi_rm _acme-challenge.www.domain.com dns_ispconfig_rm() { fulldomain=\"${1}\" _debug \"Calling: dns_ispconfig_rm() '${fulldomain}'\" _ISPC_credentials && _ISPC_login && _ISPC_rmTxt } #################### Private functions below ################################## _ISPC_credentials() { ISPC_User=\"${ISPC_User:-$(_readaccountconf_mutable ISPC_User)}\" ISPC_Password=\"${ISPC_Password:-$(_readaccountconf_mutable ISPC_Password)}\" ISPC_Api=\"${ISPC_Api:-$(_readaccountconf_mutable ISPC_Api)}\" ISPC_Api_Insecure=\"${ISPC_Api_Insecure:-$(_readaccountconf_mutable ISPC_Api_Insecure)}\" if [ -z \"${ISPC_User}\" ] || [ -z \"${ISPC_Password}\" ] || [ -z \"${ISPC_Api}\" ] || [ -z \"${ISPC_Api_Insecure}\" ]; then ISPC_User=\"\" ISPC_Password=\"\" ISPC_Api=\"\" ISPC_Api_Insecure=\"\" _err \"You haven't specified the ISPConfig Login data, URL and whether you want check the ISPC SSL cert. Please try again.\" return 1 else _saveaccountconf_mutable ISPC_User \"${ISPC_User}\" _saveaccountconf_mutable ISPC_Password \"${ISPC_Password}\" _saveaccountconf_mutable ISPC_Api \"${ISPC_Api}\" _saveaccountconf_mutable ISPC_Api_Insecure \"${ISPC_Api_Insecure}\" # Set whether curl should use secure or insecure mode export HTTPS_INSECURE=\"${ISPC_Api_Insecure}\" fi } _ISPC_login() { _info \"Getting Session ID\" curData=\"{\\\"username\\\":\\\"${ISPC_User}\\\",\\\"password\\\":\\\"${ISPC_Password}\\\",\\\"client_login\\\":false}\" curResult=\"$(_post \"${curData}\" \"${ISPC_Api}?login\")\" _debug \"Calling _ISPC_login: '${curData}' '${ISPC_Api}?login'\" _debug \"Result of _ISPC_login: '$curResult'\" if _contains \"${curResult}\" '\"code\":\"ok\"'; then sessionID=$(echo \"${curResult}\" | _egrep_o \"response.*\" | cut -d ':' -f 2 | cut -d '\"' -f 2) _info \"Retrieved Session ID.\" _debug \"Session ID: '${sessionID}'\" else _err \"Couldn't retrieve the Session ID.\" return 1 fi } _ISPC_getZoneInfo() { _info \"Getting Zoneinfo\" zoneEnd=false curZone=\"${fulldomain}\" while [ \"${zoneEnd}\" = false ]; do # we can strip the first part of the fulldomain, since it's just the _acme-challenge string curZone=\"${curZone#*.}\" # suffix . needed for zone -> domain.tld. curData=\"{\\\"session_id\\\":\\\"${sessionID}\\\",\\\"primary_id\\\":{\\\"origin\\\":\\\"${curZone}.\\\"}}\" curResult=\"$(_post \"${curData}\" \"${ISPC_Api}?dns_zone_get\")\" _debug \"Calling _ISPC_getZoneInfo: '${curData}' '${ISPC_Api}?dns_zone_get'\" _debug \"Result of _ISPC_getZoneInfo: '$curResult'\" if _contains \"${curResult}\" '\"id\":\"'; then zoneFound=true zoneEnd=true _info \"Retrieved zone data.\" _debug \"Zone data: '${curResult}'\" fi if [ \"${curZone#*.}\" != \"$curZone\" ]; then _debug2 \"$curZone still contains a '.' - so we can check next higher level\" else zoneEnd=true _err \"Couldn't retrieve zone data.\" return 1 fi done if [ \"${zoneFound}\" ]; then server_id=$(echo \"${curResult}\" | _egrep_o \"server_id.*\" | cut -d ':' -f 2 | cut -d '\"' -f 2) _debug \"Server ID: '${server_id}'\" case \"${server_id}\" in '' | *[!0-9]*) _err \"Server ID is not numeric.\" return 1 ;; *) _info \"Retrieved Server ID\" ;; esac zone=$(echo \"${curResult}\" | _egrep_o \"\\\"id.*\" | cut -d ':' -f 2 | cut -d '\"' -f 2) _debug \"Zone: '${zone}'\" case \"${zone}\" in '' | *[!0-9]*) _err \"Zone ID is not numeric.\" return 1 ;; *) _info \"Retrieved Zone ID\" ;; esac sys_userid=$(echo \"${curResult}\" | _egrep_o \"sys_userid.*\" | cut -d ':' -f 2 | cut -d '\"' -f 2) _debug \"SYS User ID: '${sys_userid}'\" case \"${sys_userid}\" in '' | *[!0-9]*) _err \"SYS User ID is not numeric.\" return 1 ;; *) _info \"Retrieved SYS User ID.\" ;; esac zoneFound=\"\" zoneEnd=\"\" fi # Need to get client_id as it is different from sys_userid curData=\"{\\\"session_id\\\":\\\"${sessionID}\\\",\\\"sys_userid\\\":\\\"${sys_userid}\\\"}\" curResult=\"$(_post \"${curData}\" \"${ISPC_Api}?client_get_id\")\" _debug \"Calling _ISPC_ClientGetID: '${curData}' '${ISPC_Api}?client_get_id'\" _debug \"Result of _ISPC_ClientGetID: '$curResult'\" client_id=$(echo \"${curResult}\" | _egrep_o \"response.*\" | cut -d ':' -f 2 | cut -d '\"' -f 2 | tr -d '{}') _debug \"Client ID: '${client_id}'\" case \"${client_id}\" in '' | *[!0-9]*) _err \"Client ID is not numeric.\" return 1 ;; *) _info \"Retrieved Client ID.\" ;; esac } _ISPC_addTxt() { curSerial=\"$(date +%s)\" curStamp=\"$(date +'%F %T')\" params=\"\\\"server_id\\\":\\\"${server_id}\\\",\\\"zone\\\":\\\"${zone}\\\",\\\"name\\\":\\\"${fulldomain}.\\\",\\\"type\\\":\\\"txt\\\",\\\"data\\\":\\\"${txtvalue}\\\",\\\"aux\\\":\\\"0\\\",\\\"ttl\\\":\\\"3600\\\",\\\"active\\\":\\\"y\\\",\\\"stamp\\\":\\\"${curStamp}\\\",\\\"serial\\\":\\\"${curSerial}\\\"\" curData=\"{\\\"session_id\\\":\\\"${sessionID}\\\",\\\"client_id\\\":\\\"${client_id}\\\",\\\"params\\\":{${params}},\\\"update_serial\\\":true}\" curResult=\"$(_post \"${curData}\" \"${ISPC_Api}?dns_txt_add\")\" _debug \"Calling _ISPC_addTxt: '${curData}' '${ISPC_Api}?dns_txt_add'\" _debug \"Result of _ISPC_addTxt: '$curResult'\" record_id=$(echo \"${curResult}\" | _egrep_o \"\\\"response.*\" | cut -d ':' -f 2 | cut -d '\"' -f 2) _debug \"Record ID: '${record_id}'\" case \"${record_id}\" in '' | *[!0-9]*) _err \"Couldn't add ACME Challenge TXT record to zone.\" return 1 ;; *) _info \"Added ACME Challenge TXT record to zone.\" ;; esac } _ISPC_rmTxt() { # Need to get the record ID. curData=\"{\\\"session_id\\\":\\\"${sessionID}\\\",\\\"primary_id\\\":{\\\"name\\\":\\\"${fulldomain}.\\\",\\\"type\\\":\\\"TXT\\\"}}\" curResult=\"$(_post \"${curData}\" \"${ISPC_Api}?dns_txt_get\")\" _debug \"Calling _ISPC_rmTxt: '${curData}' '${ISPC_Api}?dns_txt_get'\" _debug \"Result of _ISPC_rmTxt: '$curResult'\" if _contains \"${curResult}\" '\"code\":\"ok\"'; then record_id=$(echo \"${curResult}\" | _egrep_o \"\\\"id.*\" | cut -d ':' -f 2 | cut -d '\"' -f 2) _debug \"Record ID: '${record_id}'\" case \"${record_id}\" in '' | *[!0-9]*) _err \"Record ID is not numeric.\" return 1 ;; *) unset IFS _info \"Retrieved Record ID.\" curData=\"{\\\"session_id\\\":\\\"${sessionID}\\\",\\\"primary_id\\\":\\\"${record_id}\\\",\\\"update_serial\\\":true}\" curResult=\"$(_post \"${curData}\" \"${ISPC_Api}?dns_txt_delete\")\" _debug \"Calling _ISPC_rmTxt: '${curData}' '${ISPC_Api}?dns_txt_delete'\" _debug \"Result of _ISPC_rmTxt: '$curResult'\" if _contains \"${curResult}\" '\"code\":\"ok\"'; then _info \"Removed ACME Challenge TXT record from zone.\" else _err \"Couldn't remove ACME Challenge TXT record from zone.\" return 1 fi ;; esac fi }"
        },
        {
            "filename": "file_223.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_223.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_jd_info='jdcloud.com Site: jdcloud.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_jd Options: JD_ACCESS_KEY_ID Access key ID JD_ACCESS_KEY_SECRET Access key secret JD_REGION Region. E.g. \"cn-north-1\" Issues: github.com/acmesh-official/acme.sh/issues/2388 ' _JD_ACCOUNT=\"https://uc.jdcloud.com/account/accesskey\" _JD_PROD=\"clouddnsservice\" _JD_API=\"jdcloud-api.com\" _JD_API_VERSION=\"v1\" _JD_DEFAULT_REGION=\"cn-north-1\" _JD_HOST=\"$_JD_PROD.$_JD_API\" ######## Public functions ##################### #Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_jd_add() { fulldomain=$1 txtvalue=$2 JD_ACCESS_KEY_ID=\"${JD_ACCESS_KEY_ID:-$(_readaccountconf_mutable JD_ACCESS_KEY_ID)}\" JD_ACCESS_KEY_SECRET=\"${JD_ACCESS_KEY_SECRET:-$(_readaccountconf_mutable JD_ACCESS_KEY_SECRET)}\" JD_REGION=\"${JD_REGION:-$(_readaccountconf_mutable JD_REGION)}\" if [ -z \"$JD_ACCESS_KEY_ID\" ] || [ -z \"$JD_ACCESS_KEY_SECRET\" ]; then JD_ACCESS_KEY_ID=\"\" JD_ACCESS_KEY_SECRET=\"\" _err \"You haven't specifed the jdcloud api key id or api key secret yet.\" _err \"Please create your key and try again. see $(__green $_JD_ACCOUNT)\" return 1 fi _saveaccountconf_mutable JD_ACCESS_KEY_ID \"$JD_ACCESS_KEY_ID\" _saveaccountconf_mutable JD_ACCESS_KEY_SECRET \"$JD_ACCESS_KEY_SECRET\" if [ -z \"$JD_REGION\" ]; then _debug \"Using default region: $_JD_DEFAULT_REGION\" JD_REGION=\"$_JD_DEFAULT_REGION\" else _saveaccountconf_mutable JD_REGION \"$JD_REGION\" fi _JD_BASE_URI=\"$_JD_API_VERSION/regions/$JD_REGION\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" #_debug \"Getting getViewTree\" _debug \"Adding records\" _addrr=\"{\\\"req\\\":{\\\"hostRecord\\\":\\\"$_sub_domain\\\",\\\"hostValue\\\":\\\"$txtvalue\\\",\\\"ttl\\\":300,\\\"type\\\":\\\"TXT\\\",\\\"viewValue\\\":-1},\\\"regionId\\\":\\\"$JD_REGION\\\",\\\"domainId\\\":\\\"$_domain_id\\\"}\" #_addrr='{\"req\":{\"hostRecord\":\"xx\",\"hostValue\":\"\\\"value4\\\"\",\"jcloudRes\":false,\"mxPriority\":null,\"port\":null,\"ttl\":300,\"type\":\"TXT\",\"weight\":null,\"viewValue\":-1},\"regionId\":\"cn-north-1\",\"domainId\":\"8824\"}' if jd_rest POST \"domain/$_domain_id/RRAdd\" \"\" \"$_addrr\"; then _rid=\"$(echo \"$response\" | tr '{},' '\\n' | grep '\"id\":' | cut -d : -f 2)\" if [ -z \"$_rid\" ]; then _err \"Can not find record id from the result.\" return 1 fi _info \"TXT record added successfully.\" _srid=\"$(_readdomainconf \"JD_CLOUD_RIDS\")\" if [ \"$_srid\" ]; then _rid=\"$_srid,$_rid\" fi _savedomainconf \"JD_CLOUD_RIDS\" \"$_rid\" return 0 fi return 1 } dns_jd_rm() { fulldomain=$1 txtvalue=$2 JD_ACCESS_KEY_ID=\"${JD_ACCESS_KEY_ID:-$(_readaccountconf_mutable JD_ACCESS_KEY_ID)}\" JD_ACCESS_KEY_SECRET=\"${JD_ACCESS_KEY_SECRET:-$(_readaccountconf_mutable JD_ACCESS_KEY_SECRET)}\" JD_REGION=\"${JD_REGION:-$(_readaccountconf_mutable JD_REGION)}\" if [ -z \"$JD_REGION\" ]; then _debug \"Using default region: $_JD_DEFAULT_REGION\" JD_REGION=\"$_JD_DEFAULT_REGION\" fi _JD_BASE_URI=\"$_JD_API_VERSION/regions/$JD_REGION\" _info \"Getting existing records for $fulldomain\" _srid=\"$(_readdomainconf \"JD_CLOUD_RIDS\")\" _debug _srid \"$_srid\" if [ -z \"$_srid\" ]; then _err \"Not rid skip\" return 0 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _cleardomainconf JD_CLOUD_RIDS _aws_tmpl_xml=\"{\\\"ids\\\":[$_srid],\\\"action\\\":\\\"del\\\",\\\"regionId\\\":\\\"$JD_REGION\\\",\\\"domainId\\\":\\\"$_domain_id\\\"}\" if jd_rest POST \"domain/$_domain_id/RROperate\" \"\" \"$_aws_tmpl_xml\" && _contains \"$response\" \"\\\"code\\\":\\\"OK\\\"\"; then _info \"TXT record deleted successfully.\" return 0 fi return 1 } #################### Private functions below ################################## _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug2 \"Checking domain: $h\" if ! jd_rest GET \"domain\"; then _err \"error get domain list\" return 1 fi if [ -z \"$h\" ]; then #not valid _err \"Invalid domain\" return 1 fi if _contains \"$response\" \"\\\"domainName\\\":\\\"$h\\\"\"; then hostedzone=\"$(echo \"$response\" | tr '{}' '\\n' | grep \"\\\"domainName\\\":\\\"$h\\\"\")\" _debug hostedzone \"$hostedzone\" if [ \"$hostedzone\" ]; then _domain_id=\"$(echo \"$hostedzone\" | tr ',' '\\n' | grep \"\\\"id\\\":\" | cut -d : -f 2)\" if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi fi _err \"Can't find domain with id: $h\" return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } #method uri qstr data jd_rest() { mtd=\"$1\" ep=\"$2\" qsr=\"$3\" data=\"$4\" _debug mtd \"$mtd\" _debug ep \"$ep\" _debug qsr \"$qsr\" _debug data \"$data\" CanonicalURI=\"/$_JD_BASE_URI/$ep\" _debug2 CanonicalURI \"$CanonicalURI\" CanonicalQueryString=\"$qsr\" _debug2 CanonicalQueryString \"$CanonicalQueryString\" RequestDate=\"$(date -u +\"%Y%m%dT%H%M%SZ\")\" #RequestDate=\"20190713T082155Z\" ###################################################### _debug2 RequestDate \"$RequestDate\" export _H1=\"X-Jdcloud-Date: $RequestDate\" RequestNonce=\"2bd0852a-8bae-4087-b2d5-$(_time)\" #RequestNonce=\"894baff5-72d4-4244-883a-7b2eb51e7fbe\" ################################# _debug2 RequestNonce \"$RequestNonce\" export _H2=\"X-Jdcloud-Nonce: $RequestNonce\" if [ \"$data\" ]; then CanonicalHeaders=\"content-type:application/json\\n\" SignedHeaders=\"content-type;\" else CanonicalHeaders=\"\" SignedHeaders=\"\" fi CanonicalHeaders=\"${CanonicalHeaders}host:$_JD_HOST\\nx-jdcloud-date:$RequestDate\\nx-jdcloud-nonce:$RequestNonce\\n\" SignedHeaders=\"${SignedHeaders}host;x-jdcloud-date;x-jdcloud-nonce\" _debug2 CanonicalHeaders \"$CanonicalHeaders\" _debug2 SignedHeaders \"$SignedHeaders\" Hash=\"sha256\" RequestPayload=\"$data\" _debug2 RequestPayload \"$RequestPayload\" RequestPayloadHash=\"$(printf \"%s\" \"$RequestPayload\" | _digest \"$Hash\" hex | _lower_case)\" _debug2 RequestPayloadHash \"$RequestPayloadHash\" CanonicalRequest=\"$mtd\\n$CanonicalURI\\n$CanonicalQueryString\\n$CanonicalHeaders\\n$SignedHeaders\\n$RequestPayloadHash\" _debug2 CanonicalRequest \"$CanonicalRequest\" HashedCanonicalRequest=\"$(printf \"$CanonicalRequest%s\" | _digest \"$Hash\" hex)\" _debug2 HashedCanonicalRequest \"$HashedCanonicalRequest\" Algorithm=\"JDCLOUD2-HMAC-SHA256\" _debug2 Algorithm \"$Algorithm\" RequestDateOnly=\"$(echo \"$RequestDate\" | cut -c 1-8)\" _debug2 RequestDateOnly \"$RequestDateOnly\" Region=\"$JD_REGION\" Service=\"$_JD_PROD\" CredentialScope=\"$RequestDateOnly/$Region/$Service/jdcloud2_request\" _debug2 CredentialScope \"$CredentialScope\" StringToSign=\"$Algorithm\\n$RequestDate\\n$CredentialScope\\n$HashedCanonicalRequest\" _debug2 StringToSign \"$StringToSign\" kSecret=\"JDCLOUD2$JD_ACCESS_KEY_SECRET\" _secure_debug2 kSecret \"$kSecret\" kSecretH=\"$(printf \"%s\" \"$kSecret\" | _hex_dump | tr -d \" \")\" _secure_debug2 kSecretH \"$kSecretH\" kDateH=\"$(printf \"$RequestDateOnly%s\" | _hmac \"$Hash\" \"$kSecretH\" hex)\" _debug2 kDateH \"$kDateH\" kRegionH=\"$(printf \"$Region%s\" | _hmac \"$Hash\" \"$kDateH\" hex)\" _debug2 kRegionH \"$kRegionH\" kServiceH=\"$(printf \"$Service%s\" | _hmac \"$Hash\" \"$kRegionH\" hex)\" _debug2 kServiceH \"$kServiceH\" kSigningH=\"$(printf \"%s\" \"jdcloud2_request\" | _hmac \"$Hash\" \"$kServiceH\" hex)\" _debug2 kSigningH \"$kSigningH\" signature=\"$(printf \"$StringToSign%s\" | _hmac \"$Hash\" \"$kSigningH\" hex)\" _debug2 signature \"$signature\" Authorization=\"$Algorithm Credential=$JD_ACCESS_KEY_ID/$CredentialScope, SignedHeaders=$SignedHeaders, Signature=$signature\" _debug2 Authorization \"$Authorization\" _H3=\"Authorization: $Authorization\" _debug _H3 \"$_H3\" url=\"https://$_JD_HOST$CanonicalURI\" if [ \"$qsr\" ]; then url=\"https://$_JD_HOST$CanonicalURI?$qsr\" fi if [ \"$mtd\" = \"GET\" ]; then response=\"$(_get \"$url\")\" else response=\"$(_post \"$data\" \"$url\" \"\" \"$mtd\" \"application/json\")\" fi _ret=\"$?\" _debug2 response \"$response\" if [ \"$_ret\" = \"0\" ]; then if _contains \"$response\" \"\\\"error\\\"\"; then _err \"Response error:$response\" return 1 fi fi return \"$_ret\" }"
        },
        {
            "filename": "file_224.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_224.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_joker_info='Joker.com Site: Joker.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_joker Options: JOKER_USERNAME Username JOKER_PASSWORD Password Issues: github.com/acmesh-official/acme.sh/issues/2840 Author: <https://github.com/aattww/> ' JOKER_API=\"https://svc.joker.com/nic/replace\" ######## Public functions ##################### #Usage: dns_joker_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_joker_add() { fulldomain=$1 txtvalue=$2 JOKER_USERNAME=\"${JOKER_USERNAME:-$(_readaccountconf_mutable JOKER_USERNAME)}\" JOKER_PASSWORD=\"${JOKER_PASSWORD:-$(_readaccountconf_mutable JOKER_PASSWORD)}\" if [ -z \"$JOKER_USERNAME\" ] || [ -z \"$JOKER_PASSWORD\" ]; then _err \"No Joker.com username and password specified.\" return 1 fi _saveaccountconf_mutable JOKER_USERNAME \"$JOKER_USERNAME\" _saveaccountconf_mutable JOKER_PASSWORD \"$JOKER_PASSWORD\" if ! _get_root \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi _info \"Adding TXT record\" if _joker_rest \"username=$JOKER_USERNAME&password=$JOKER_PASSWORD&zone=$_domain&label=$_sub_domain&type=TXT&value=$txtvalue\"; then if _startswith \"$response\" \"OK\"; then _info \"Added, OK\" return 0 fi fi _err \"Error adding TXT record.\" return 1 } #fulldomain txtvalue dns_joker_rm() { fulldomain=$1 txtvalue=$2 JOKER_USERNAME=\"${JOKER_USERNAME:-$(_readaccountconf_mutable JOKER_USERNAME)}\" JOKER_PASSWORD=\"${JOKER_PASSWORD:-$(_readaccountconf_mutable JOKER_PASSWORD)}\" if ! _get_root \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi _info \"Removing TXT record\" # TXT record is removed by setting its value to empty. if _joker_rest \"username=$JOKER_USERNAME&password=$JOKER_PASSWORD&zone=$_domain&label=$_sub_domain&type=TXT&value=\"; then if _startswith \"$response\" \"OK\"; then _info \"Removed, OK\" return 0 fi fi _err \"Error removing TXT record.\" return 1 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { fulldomain=$1 i=1 while true; do h=$(printf \"%s\" \"$fulldomain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then return 1 fi # Try to remove a test record. With correct root domain, username and password this will return \"OK: ...\" regardless # of record in question existing or not. if _joker_rest \"username=$JOKER_USERNAME&password=$JOKER_PASSWORD&zone=$h&label=jokerTXTUpdateTest&type=TXT&value=\"; then if _startswith \"$response\" \"OK\"; then _sub_domain=\"$(echo \"$fulldomain\" | sed \"s/\\\\.$h\\$//\")\" _domain=$h return 0 fi fi i=$(_math \"$i\" + 1) done _debug \"Root domain not found\" return 1 } _joker_rest() { data=\"$1\" _debug data \"$data\" if ! response=\"$(_post \"$data\" \"$JOKER_API\" \"\" \"POST\")\"; then _err \"Error POSTing\" return 1 fi _debug response \"$response\" return 0 }"
        },
        {
            "filename": "file_225.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_225.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_kappernet_info='kapper.net Site: kapper.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_kappernet Options: KAPPERNETDNS_Key API Key KAPPERNETDNS_Secret API Secret Issues: github.com/acmesh-official/acme.sh/issues/2977 ' ############################################################################### # called with # fullhostname: something.example.com # txtvalue: someacmegenerated string dns_kappernet_add() { fullhostname=$1 txtvalue=$2 KAPPERNETDNS_Key=\"${KAPPERNETDNS_Key:-$(_readaccountconf_mutable KAPPERNETDNS_Key)}\" KAPPERNETDNS_Secret=\"${KAPPERNETDNS_Secret:-$(_readaccountconf_mutable KAPPERNETDNS_Secret)}\" KAPPERNETDNS_Api=\"https://dnspanel.kapper.net/API/1.2?APIKey=$KAPPERNETDNS_Key&APISecret=$KAPPERNETDNS_Secret\" if [ -z \"$KAPPERNETDNS_Key\" ] || [ -z \"$KAPPERNETDNS_Secret\" ]; then _err \"Please specify your kapper.net api key and secret.\" _err \"If you have not received yours - send your mail to\" _err \"support@kapper.net to get your key and secret.\" return 1 fi #store the api key and email to the account conf file. _saveaccountconf_mutable KAPPERNETDNS_Key \"$KAPPERNETDNS_Key\" _saveaccountconf_mutable KAPPERNETDNS_Secret \"$KAPPERNETDNS_Secret\" _debug \"Checking Domain ...\" if ! _get_root \"$fullhostname\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"SUBDOMAIN: $_sub_domain\" _debug _domain \"DOMAIN: $_domain\" _info \"Trying to add TXT DNS Record\" data=\"%7B%22name%22%3A%22$fullhostname%22%2C%22type%22%3A%22TXT%22%2C%22content%22%3A%22$txtvalue%22%2C%22ttl%22%3A%22300%22%2C%22prio%22%3A%22%22%7D\" if _kappernet_api GET \"action=new&subject=$_domain&data=$data\"; then if _contains \"$response\" \"{\\\"OK\\\":true\"; then _info \"Waiting 1 second for DNS to spread the new record\" _sleep 1 return 0 else _err \"Error creating a TXT DNS Record: $fullhostname TXT $txtvalue\" _err \"Error Message: $response\" return 1 fi fi _err \"Failed creating TXT Record\" } ############################################################################### # called with # fullhostname: something.example.com dns_kappernet_rm() { fullhostname=$1 txtvalue=$2 KAPPERNETDNS_Key=\"${KAPPERNETDNS_Key:-$(_readaccountconf_mutable KAPPERNETDNS_Key)}\" KAPPERNETDNS_Secret=\"${KAPPERNETDNS_Secret:-$(_readaccountconf_mutable KAPPERNETDNS_Secret)}\" KAPPERNETDNS_Api=\"https://dnspanel.kapper.net/API/1.2?APIKey=$KAPPERNETDNS_Key&APISecret=$KAPPERNETDNS_Secret\" if [ -z \"$KAPPERNETDNS_Key\" ] || [ -z \"$KAPPERNETDNS_Secret\" ]; then _err \"Please specify your kapper.net api key and secret.\" _err \"If you have not received yours - send your mail to\" _err \"support@kapper.net to get your key and secret.\" return 1 fi #store the api key and email to the account conf file. _saveaccountconf_mutable KAPPERNETDNS_Key \"$KAPPERNETDNS_Key\" _saveaccountconf_mutable KAPPERNETDNS_Secret \"$KAPPERNETDNS_Secret\" _info \"Trying to remove the TXT Record: $fullhostname containing $txtvalue\" data=\"%7B%22name%22%3A%22$fullhostname%22%2C%22type%22%3A%22TXT%22%2C%22content%22%3A%22$txtvalue%22%2C%22ttl%22%3A%22300%22%2C%22prio%22%3A%22%22%7D\" if _kappernet_api GET \"action=del&subject=$fullhostname&data=$data\"; then if _contains \"$response\" \"{\\\"OK\\\":true\"; then return 0 else _err \"Error deleting DNS Record: $fullhostname containing $txtvalue\" _err \"Problem: $response\" return 1 fi fi _err \"Problem deleting TXT DNS record\" } #################### Private functions below ################################## # called with hostname # e.g._acme-challenge.www.domain.com returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi if ! _kappernet_api GET \"action=list&subject=$h\"; then return 1 fi if _contains \"$response\" '\"OK\":false'; then _debug \"$h not found\" else _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } ################################################################################ # calls the kapper.net DNS Panel API # with # method # param _kappernet_api() { method=$1 param=\"$2\" _debug param \"PARAMETER=$param\" url=\"$KAPPERNETDNS_Api&$param\" _debug url \"URL=$url\" if [ \"$method\" = \"GET\" ]; then response=\"$(_get \"$url\")\" else _err \"Unsupported method or missing Secret/Key\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_226.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_226.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_kas_info='All-inkl Kas Server Site: kas.all-inkl.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_kas Options: KAS_Login API login name KAS_Authtype API auth type. Default: \"plain\" KAS_Authdata API auth data Issues: github.com/acmesh-official/acme.sh/issues/2715 Author: squared GmbH <github@squaredgmbh.de>, Martin Kammerlander <martin.kammerlander@phlegx.com>, Marc-Oliver Lange <git@die-lang.es> ' ######################################################################## KAS_Api_GET=\"$(_get \"https://kasapi.kasserver.com/soap/wsdl/KasApi.wsdl\")\" KAS_Api=\"$(echo \"$KAS_Api_GET\" | tr -d ' ' | grep -i \"<soap:addresslocation=\" | sed \"s/='/\\n/g\" | grep -i \"http\" | sed \"s/'\\/>//g\")\" _info \"[KAS] -> API URL $KAS_Api\" KAS_Auth_GET=\"$(_get \"https://kasapi.kasserver.com/soap/wsdl/KasAuth.wsdl\")\" KAS_Auth=\"$(echo \"$KAS_Auth_GET\" | tr -d ' ' | grep -i \"<soap:addresslocation=\" | sed \"s/='/\\n/g\" | grep -i \"http\" | sed \"s/'\\/>//g\")\" _info \"[KAS] -> AUTH URL $KAS_Auth\" KAS_default_ratelimit=5 # TODO - Every response delivers a ratelimit (seconds) where KASAPI is blocking a request. ######## Public functions ##################### dns_kas_add() { _fulldomain=$1 _txtvalue=$2 _info \"[KAS] -> Using DNS-01 All-inkl/Kasserver hook\" _info \"[KAS] -> Check and Save Props\" _check_and_save _info \"[KAS] -> Adding $_fulldomain DNS TXT entry on all-inkl.com/Kasserver\" _info \"[KAS] -> Retriving Credential Token\" _get_credential_token _info \"[KAS] -> Checking Zone and Record_Name\" _get_zone_and_record_name \"$_fulldomain\" _info \"[KAS] -> Checking for existing Record entries\" _get_record_id # If there is a record_id, delete the entry if [ -n \"$_record_id\" ]; then _info \"[KAS] -> Existing records found. Now deleting old entries\" for i in $_record_id; do _delete_RecordByID \"$i\" done else _info \"[KAS] -> No record found.\" fi _info \"[KAS] -> Creating TXT DNS record\" action=\"add_dns_settings\" kasReqParam=\"\\\"record_name\\\":\\\"$_record_name\\\"\" kasReqParam=\"$kasReqParam,\\\"record_type\\\":\\\"TXT\\\"\" kasReqParam=\"$kasReqParam,\\\"record_data\\\":\\\"$_txtvalue\\\"\" kasReqParam=\"$kasReqParam,\\\"record_aux\\\":\\\"0\\\"\" kasReqParam=\"$kasReqParam,\\\"zone_host\\\":\\\"$_zone\\\"\" response=\"$(_callAPI \"$action\" \"$kasReqParam\")\" _debug2 \"[KAS] -> Response\" \"$response\" if [ -z \"$response\" ]; then _info \"[KAS] -> Response was empty, please check manually.\" return 1 elif _contains \"$response\" \"<SOAP-ENV:Fault>\"; then faultstring=\"$(echo \"$response\" | tr -d '\\n\\r' | sed \"s/<faultstring>/\\n=> /g\" | sed \"s/<\\/faultstring>/\\n/g\" | grep \"=>\" | sed \"s/=> //g\")\" case \"${faultstring}\" in \"record_already_exists\") _info \"[KAS] -> The record already exists, which must not be a problem. Please check manually.\" ;; *) _err \"[KAS] -> An error =>$faultstring<= occurred, please check manually.\" return 1 ;; esac elif ! _contains \"$response\" \"<item><key xsi:type=\\\"xsd:string\\\">ReturnString</key><value xsi:type=\\\"xsd:string\\\">TRUE</value></item>\"; then _err \"[KAS] -> An unknown error occurred, please check manually.\" return 1 fi return 0 } dns_kas_rm() { _fulldomain=$1 _txtvalue=$2 _info \"[KAS] -> Using DNS-01 All-inkl/Kasserver hook\" _info \"[KAS] -> Check and Save Props\" _check_and_save _info \"[KAS] -> Cleaning up after All-inkl/Kasserver hook\" _info \"[KAS] -> Removing $_fulldomain DNS TXT entry on All-inkl/Kasserver\" _info \"[KAS] -> Retriving Credential Token\" _get_credential_token _info \"[KAS] -> Checking Zone and Record_Name\" _get_zone_and_record_name \"$_fulldomain\" _info \"[KAS] -> Getting Record ID\" _get_record_id _info \"[KAS] -> Removing entries with ID: $_record_id\" # If there is a record_id, delete the entry if [ -n \"$_record_id\" ]; then for i in $_record_id; do _delete_RecordByID \"$i\" done else # Cannot delete or unkown error _info \"[KAS] -> No record_id found that can be deleted. Please check manually.\" fi return 0 } ########################## PRIVATE FUNCTIONS ########################### # Delete Record ID _delete_RecordByID() { recId=$1 action=\"delete_dns_settings\" kasReqParam=\"\\\"record_id\\\":\\\"$recId\\\"\" response=\"$(_callAPI \"$action\" \"$kasReqParam\")\" _debug2 \"[KAS] -> Response\" \"$response\" if [ -z \"$response\" ]; then _info \"[KAS] -> Response was empty, please check manually.\" return 1 elif _contains \"$response\" \"<SOAP-ENV:Fault>\"; then faultstring=\"$(echo \"$response\" | tr -d '\\n\\r' | sed \"s/<faultstring>/\\n=> /g\" | sed \"s/<\\/faultstring>/\\n/g\" | grep \"=>\" | sed \"s/=> //g\")\" case \"${faultstring}\" in \"record_id_not_found\") _info \"[KAS] -> The record was not found, which perhaps is not a problem. Please check manually.\" ;; *) _err \"[KAS] -> An error =>$faultstring<= occurred, please check manually.\" return 1 ;; esac elif ! _contains \"$response\" \"<item><key xsi:type=\\\"xsd:string\\\">ReturnString</key><value xsi:type=\\\"xsd:string\\\">TRUE</value></item>\"; then _err \"[KAS] -> An unknown error occurred, please check manually.\" return 1 fi } # Checks for the ENV variables and saves them _check_and_save() { KAS_Login=\"${KAS_Login:-$(_readaccountconf_mutable KAS_Login)}\" KAS_Authtype=\"${KAS_Authtype:-$(_readaccountconf_mutable KAS_Authtype)}\" KAS_Authdata=\"${KAS_Authdata:-$(_readaccountconf_mutable KAS_Authdata)}\" if [ -z \"$KAS_Login\" ] || [ -z \"$KAS_Authtype\" ] || [ -z \"$KAS_Authdata\" ]; then KAS_Login= KAS_Authtype= KAS_Authdata= _err \"[KAS] -> No auth details provided. Please set user credentials using the \\$KAS_Login, \\$KAS_Authtype, and \\$KAS_Authdata environment variables.\" return 1 fi _saveaccountconf_mutable KAS_Login \"$KAS_Login\" _saveaccountconf_mutable KAS_Authtype \"$KAS_Authtype\" _saveaccountconf_mutable KAS_Authdata \"$KAS_Authdata\" return 0 } # Gets back the base domain/zone and record name. # See: https://github.com/Neilpang/acme.sh/wiki/DNS-API-Dev-Guide _get_zone_and_record_name() { action=\"get_domains\" response=\"$(_callAPI \"$action\")\" _debug2 \"[KAS] -> Response\" \"$response\" if [ -z \"$response\" ]; then _info \"[KAS] -> Response was empty, please check manually.\" return 1 elif _contains \"$response\" \"<SOAP-ENV:Fault>\"; then faultstring=\"$(echo \"$response\" | tr -d '\\n\\r' | sed \"s/<faultstring>/\\n=> /g\" | sed \"s/<\\/faultstring>/\\n/g\" | grep \"=>\" | sed \"s/=> //g\")\" _err \"[KAS] -> Either no domains were found or another error =>$faultstring<= occurred, please check manually.\" return 1 fi zonen=\"$(echo \"$response\" | sed 's/<item>/\\n/g' | sed -r 's/(.*<key xsi:type=\"xsd:string\">domain_name<\\/key><value xsi:type=\"xsd:string\">)(.*)(<\\/value.*)/\\2/' | sed '/^</d')\" domain=\"$1\" temp_domain=\"$(echo \"$1\" | sed 's/\\.$//')\" rootzone=\"$domain\" for i in $zonen; do l1=${#rootzone} l2=${#i} if _endswith \"$domain\" \"$i\" && [ \"$l1\" -ge \"$l2\" ]; then rootzone=\"$i\" fi done _zone=\"${rootzone}.\" temp_record_name=\"$(echo \"$temp_domain\" | sed \"s/$rootzone//g\")\" _record_name=\"$(echo \"$temp_record_name\" | sed 's/\\.$//')\" _debug \"[KAS] -> Zone:\" \"$_zone\" _debug \"[KAS] -> Domain:\" \"$domain\" _debug \"[KAS] -> Record_Name:\" \"$_record_name\" return 0 } # Retrieve the DNS record ID _get_record_id() { action=\"get_dns_settings\" kasReqParam=\"\\\"zone_host\\\":\\\"$_zone\\\"\" response=\"$(_callAPI \"$action\" \"$kasReqParam\")\" _debug2 \"[KAS] -> Response\" \"$response\" if [ -z \"$response\" ]; then _info \"[KAS] -> Response was empty, please check manually.\" return 1 elif _contains \"$response\" \"<SOAP-ENV:Fault>\"; then faultstring=\"$(echo \"$response\" | tr -d '\\n\\r' | sed \"s/<faultstring>/\\n=> /g\" | sed \"s/<\\/faultstring>/\\n/g\" | grep \"=>\" | sed \"s/=> //g\")\" _err \"[KAS] -> Either no domains were found or another error =>$faultstring<= occurred, please check manually.\" return 1 fi _record_id=\"$(echo \"$response\" | tr -d '\\n\\r' | sed \"s/<item xsi:type=\\\"ns2:Map\\\">/\\n/g\" | grep -i \"$_record_name\" | grep -i \">TXT<\" | sed \"s/<item><key xsi:type=\\\"xsd:string\\\">record_id<\\/key><value xsi:type=\\\"xsd:string\\\">/=>/g\" | grep -i \"$_txtvalue\" | sed \"s/<\\/value><\\/item>/\\n/g\" | grep \"=>\" | sed \"s/=>//g\")\" _debug \"[KAS] -> Record Id: \" \"$_record_id\" return 0 } # Retrieve credential token _get_credential_token() { baseParamAuth=\"\\\"kas_login\\\":\\\"$KAS_Login\\\"\" baseParamAuth=\"$baseParamAuth,\\\"kas_auth_type\\\":\\\"$KAS_Authtype\\\"\" baseParamAuth=\"$baseParamAuth,\\\"kas_auth_data\\\":\\\"$KAS_Authdata\\\"\" baseParamAuth=\"$baseParamAuth,\\\"session_lifetime\\\":600\" baseParamAuth=\"$baseParamAuth,\\\"session_update_lifetime\\\":\\\"Y\\\"\" data='<?xml version=\"1.0\" encoding=\"UTF-8\"?><SOAP-ENV:Envelope xmlns:SOAP-ENV=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:ns1=\"urn:xmethodsKasApiAuthentication\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:SOAP-ENC=\"http://schemas.xmlsoap.org/soap/encoding/\" SOAP-ENV:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"><SOAP-ENV:Body><ns1:KasAuth><Params xsi:type=\"xsd:string\">{' data=\"$data$baseParamAuth}</Params></ns1:KasAuth></SOAP-ENV:Body></SOAP-ENV:Envelope>\" _debug \"[KAS] -> Be friendly and wait $KAS_default_ratelimit seconds by default before calling KAS API.\" _sleep $KAS_default_ratelimit contentType=\"text/xml\" export _H1=\"SOAPAction: urn:xmethodsKasApiAuthentication#KasAuth\" response=\"$(_post \"$data\" \"$KAS_Auth\" \"\" \"POST\" \"$contentType\")\" _debug2 \"[KAS] -> Response\" \"$response\" if [ -z \"$response\" ]; then _info \"[KAS] -> Response was empty, please check manually.\" return 1 elif _contains \"$response\" \"<SOAP-ENV:Fault>\"; then faultstring=\"$(echo \"$response\" | tr -d '\\n\\r' | sed \"s/<faultstring>/\\n=> /g\" | sed \"s/<\\/faultstring>/\\n/g\" | grep \"=>\" | sed \"s/=> //g\")\" _err \"[KAS] -> Could not retrieve login token or antoher error =>$faultstring<= occurred, please check manually.\" return 1 fi _credential_token=\"$(echo \"$response\" | tr '\\n' ' ' | sed 's/.*return xsi:type=\"xsd:string\">\\(.*\\)<\\/return>/\\1/' | sed 's/<\\/ns1:KasAuthResponse\\(.*\\)Envelope>.*//')\" _debug \"[KAS] -> Credential Token: \" \"$_credential_token\" return 0 } _callAPI() { kasaction=$1 kasReqParams=$2 baseParamAuth=\"\\\"kas_login\\\":\\\"$KAS_Login\\\"\" baseParamAuth=\"$baseParamAuth,\\\"kas_auth_type\\\":\\\"session\\\"\" baseParamAuth=\"$baseParamAuth,\\\"kas_auth_data\\\":\\\"$_credential_token\\\"\" data='<?xml version=\"1.0\" encoding=\"UTF-8\"?><SOAP-ENV:Envelope xmlns:SOAP-ENV=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:ns1=\"urn:xmethodsKasApi\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:SOAP-ENC=\"http://schemas.xmlsoap.org/soap/encoding/\" SOAP-ENV:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"><SOAP-ENV:Body><ns1:KasApi><Params xsi:type=\"xsd:string\">{' data=\"$data$baseParamAuth,\\\"kas_action\\\":\\\"$kasaction\\\"\" if [ -n \"$kasReqParams\" ]; then data=\"$data,\\\"KasRequestParams\\\":{$kasReqParams}\" fi data=\"$data}</Params></ns1:KasApi></SOAP-ENV:Body></SOAP-ENV:Envelope>\" _debug2 \"[KAS] -> Request\" \"$data\" _debug \"[KAS] -> Be friendly and wait $KAS_default_ratelimit seconds by default before calling KAS API.\" _sleep $KAS_default_ratelimit contentType=\"text/xml\" export _H1=\"SOAPAction: urn:xmethodsKasApi#KasApi\" response=\"$(_post \"$data\" \"$KAS_Api\" \"\" \"POST\" \"$contentType\")\" _debug2 \"[KAS] -> Response\" \"$response\" echo \"$response\" }"
        },
        {
            "filename": "file_227.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_227.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_kinghost_info='King.host Domains: KingHost.net KingHost.com.br Site: King.host Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_kinghost Options: KINGHOST_Username Username KINGHOST_Password Password Author: Felipe Keller Braz <felipebraz@kinghost.com.br> ' # KingHost API support # # https://api.kinghost.net/doc/ # KING_Api=\"https://api.kinghost.net/acme\" # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Used to add txt record dns_kinghost_add() { fulldomain=$1 txtvalue=$2 KINGHOST_Username=\"${KINGHOST_Username:-$(_readaccountconf_mutable KINGHOST_Username)}\" KINGHOST_Password=\"${KINGHOST_Password:-$(_readaccountconf_mutable KINGHOST_Password)}\" if [ -z \"$KINGHOST_Username\" ] || [ -z \"$KINGHOST_Password\" ]; then KINGHOST_Username=\"\" KINGHOST_Password=\"\" _err \"You don't specify KingHost api password and email yet.\" _err \"Please create you key and try again.\" return 1 fi #save the credentials to the account conf file. _saveaccountconf_mutable KINGHOST_Username \"$KINGHOST_Username\" _saveaccountconf_mutable KINGHOST_Password \"$KINGHOST_Password\" _debug \"Getting txt records\" _kinghost_rest GET \"dns\" \"name=$fulldomain&content=$txtvalue\" #This API call returns \"status\":\"ok\" if dns record does not exist #We are creating a new txt record here, so we expect the \"ok\" status if ! echo \"$response\" | grep '\"status\":\"ok\"' >/dev/null; then _err \"Error\" _err \"$response\" return 1 fi _kinghost_rest POST \"dns\" \"name=$fulldomain&content=$txtvalue\" if ! echo \"$response\" | grep '\"status\":\"ok\"' >/dev/null; then _err \"Error\" _err \"$response\" return 1 fi return 0 } # Usage: fulldomain txtvalue # Used to remove the txt record after validation dns_kinghost_rm() { fulldomain=$1 txtvalue=$2 KINGHOST_Password=\"${KINGHOST_Password:-$(_readaccountconf_mutable KINGHOST_Password)}\" KINGHOST_Username=\"${KINGHOST_Username:-$(_readaccountconf_mutable KINGHOST_Username)}\" if [ -z \"$KINGHOST_Password\" ] || [ -z \"$KINGHOST_Username\" ]; then KINGHOST_Password=\"\" KINGHOST_Username=\"\" _err \"You don't specify KingHost api key and email yet.\" _err \"Please create you key and try again.\" return 1 fi _kinghost_rest DELETE \"dns\" \"name=$fulldomain&content=$txtvalue\" if ! echo \"$response\" | grep '\"status\":\"ok\"' >/dev/null; then _err \"Error\" _err \"$response\" return 1 fi return 0 } #################### Private functions below ################################## _kinghost_rest() { method=$1 uri=\"$2\" data=\"$3\" _debug \"$uri\" export _H1=\"X-Auth-Email: $KINGHOST_Username\" export _H2=\"X-Auth-Key: $KINGHOST_Password\" if [ \"$method\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$KING_Api/$uri.json\" \"\" \"$method\")\" else response=\"$(_get \"$KING_Api/$uri.json?$data\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $uri\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_228.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_228.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_knot_info='Knot Server knsupdate Site: www.knot-dns.cz/docs/2.5/html/man_knsupdate.html Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_knot Options: KNOT_SERVER Server hostname. Default: \"localhost\". KNOT_KEY File path to TSIG key ' # See also dns_nsupdate.sh ######## Public functions ##################### #Usage: dns_knot_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_knot_add() { fulldomain=$1 txtvalue=$2 _checkKey || return 1 [ -n \"${KNOT_SERVER}\" ] || KNOT_SERVER=\"localhost\" # save the dns server and key to the account.conf file. _saveaccountconf KNOT_SERVER \"${KNOT_SERVER}\" _saveaccountconf KNOT_KEY \"${KNOT_KEY}\" if ! _get_root \"$fulldomain\"; then _err \"Domain does not exist.\" return 1 fi _info \"Adding ${fulldomain}. 60 TXT \\\"${txtvalue}\\\"\" knsupdate <<EOF server ${KNOT_SERVER} key ${KNOT_KEY} zone ${_domain}. update add ${fulldomain}. 60 TXT \"${txtvalue}\" send quit EOF if [ $? -ne 0 ]; then _err \"Error updating domain.\" return 1 fi _info \"Domain TXT record successfully added.\" return 0 } #Usage: dns_knot_rm _acme-challenge.www.domain.com dns_knot_rm() { fulldomain=$1 _checkKey || return 1 [ -n \"${KNOT_SERVER}\" ] || KNOT_SERVER=\"localhost\" if ! _get_root \"$fulldomain\"; then _err \"Domain does not exist.\" return 1 fi _info \"Removing ${fulldomain}. TXT\" knsupdate <<EOF server ${KNOT_SERVER} key ${KNOT_KEY} zone ${_domain}. update del ${fulldomain}. TXT send quit EOF if [ $? -ne 0 ]; then _err \"error updating domain\" return 1 fi _info \"Domain TXT record successfully deleted.\" return 0 } #################### Private functions below ################################## # _acme-challenge.www.domain.com # returns # _domain=domain.com _get_root() { domain=$1 i=\"$(echo \"$fulldomain\" | tr '.' ' ' | wc -w)\" i=$(_math \"$i\" - 1) while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f \"$i\"-100) if [ -z \"$h\" ]; then return 1 fi _domain=\"$h\" return 0 done _debug \"$domain not found\" return 1 } _checkKey() { if [ -z \"${KNOT_KEY}\" ]; then _err \"You must specify a TSIG key to authenticate the request.\" return 1 fi }"
        },
        {
            "filename": "file_229.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_229.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_la_info='dns.la Site: dns.la Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_la Options: LA_Id API ID LA_Key API key Issues: github.com/acmesh-official/acme.sh/issues/4257 ' LA_Api=\"https://api.dns.la/api\" ######## Public functions ##################### #Usage: dns_la_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_la_add() { fulldomain=$1 txtvalue=$2 LA_Id=\"${LA_Id:-$(_readaccountconf_mutable LA_Id)}\" LA_Key=\"${LA_Key:-$(_readaccountconf_mutable LA_Key)}\" if [ -z \"$LA_Id\" ] || [ -z \"$LA_Key\" ]; then LA_Id=\"\" LA_Key=\"\" _err \"You didn't specify a dnsla api id and key yet.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable LA_Id \"$LA_Id\" _saveaccountconf_mutable LA_Key \"$LA_Key\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if _la_rest \"record.ashx?cmd=create&apiid=$LA_Id&apipass=$LA_Key&rtype=json&domainid=$_domain_id&host=$_sub_domain&recordtype=TXT&recorddata=$txtvalue&recordline=\"; then if _contains \"$response\" '\"resultid\":'; then _info \"Added, OK\" return 0 elif _contains \"$response\" '\"code\":532'; then _info \"Already exists, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_la_rm() { fulldomain=$1 txtvalue=$2 LA_Id=\"${LA_Id:-$(_readaccountconf_mutable LA_Id)}\" LA_Key=\"${LA_Key:-$(_readaccountconf_mutable LA_Key)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" if ! _la_rest \"record.ashx?cmd=listn&apiid=$LA_Id&apipass=$LA_Key&rtype=json&domainid=$_domain_id&domain=$_domain&host=$_sub_domain&recordtype=TXT&recorddata=$txtvalue\"; then _err \"Error\" return 1 fi if ! _contains \"$response\" '\"recordid\":'; then _info \"Don't need to remove.\" return 0 fi record_id=$(printf \"%s\" \"$response\" | grep '\"recordid\":' | cut -d : -f 2 | cut -d , -f 1 | tr -d '\\r' | tr -d '\\n') _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _la_rest \"record.ashx?cmd=remove&apiid=$LA_Id&apipass=$LA_Key&rtype=json&domainid=$_domain_id&domain=$_domain&recordid=$record_id\"; then _err \"Delete record error.\" return 1 fi _contains \"$response\" '\"code\":300' } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi if ! _la_rest \"domain.ashx?cmd=get&apiid=$LA_Id&apipass=$LA_Key&rtype=json&domain=$h\"; then return 1 fi if _contains \"$response\" '\"domainid\":'; then _domain_id=$(printf \"%s\" \"$response\" | grep '\"domainid\":' | cut -d : -f 2 | cut -d , -f 1 | tr -d '\\r' | tr -d '\\n') if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi return 1 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } #Usage: URI _la_rest() { url=\"$LA_Api/$1\" _debug \"$url\" if ! response=\"$(_get \"$url\" | tr -d ' ' | tr \"}\" \",\")\"; then _err \"Error: $url\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_230.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_230.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_leaseweb_info='Leaseweb.com Site: Leaseweb.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_leaseweb Options: LSW_Key API Key Issues: github.com/acmesh-official/acme.sh/issues/2558 Author: Rolph Haspers <r.haspers@global.leaseweb.com> ' #See https://developer.leaseweb.com for more information. ######## Public functions ##################### LSW_API=\"https://api.leaseweb.com/hosting/v2/domains\" #Usage: dns_leaseweb_add _acme-challenge.www.domain.com dns_leaseweb_add() { fulldomain=$1 txtvalue=$2 LSW_Key=\"${LSW_Key:-$(_readaccountconf_mutable LSW_Key)}\" if [ -z \"$LSW_Key\" ]; then LSW_Key=\"\" _err \"You don't specify Leaseweb api key yet.\" _err \"Please create your key and try again.\" return 1 fi #save the api key to the account conf file. _saveaccountconf_mutable LSW_Key \"$LSW_Key\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _root_domain \"$_domain\" _debug _domain \"$fulldomain\" if _lsw_api \"POST\" \"$_domain\" \"$fulldomain\" \"$txtvalue\"; then if [ \"$_code\" = \"201\" ]; then _info \"Added, OK\" return 0 else _err \"Add txt record error, invalid code. Code: $_code\" return 1 fi fi _err \"Add txt record error.\" return 1 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_leaseweb_rm() { fulldomain=$1 txtvalue=$2 LSW_Key=\"${LSW_Key:-$(_readaccountconf_mutable LSW_Key)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _root_domain \"$_domain\" _debug _domain \"$fulldomain\" if _lsw_api \"DELETE\" \"$_domain\" \"$fulldomain\" \"$txtvalue\"; then if [ \"$_code\" = \"204\" ]; then _info \"Deleted, OK\" return 0 else _err \"Delete txt record error.\" return 1 fi fi _err \"Delete txt record error.\" return 1 } #################### Private functions below ################################## # _acme-challenge.www.domain.com # returns # _domain=domain.com _get_root() { rdomain=$1 i=\"$(echo \"$rdomain\" | tr '.' ' ' | wc -w)\" i=$(_math \"$i\" - 1) while true; do h=$(printf \"%s\" \"$rdomain\" | cut -d . -f \"$i\"-100) _debug h \"$h\" if [ -z \"$h\" ]; then return 1 #not valid domain fi #Check API if domain exists if _lsw_api \"GET\" \"$h\"; then if [ \"$_code\" = \"200\" ]; then _domain=\"$h\" return 0 fi fi i=$(_math \"$i\" - 1) if [ \"$i\" -lt 2 ]; then return 1 #not found, no need to check _acme-challenge.sub.domain in leaseweb api. fi done return 1 } _lsw_api() { cmd=$1 d=$2 fd=$3 tvalue=$4 # Construct the HTTP Authorization header export _H2=\"Content-Type: application/json\" export _H1=\"X-Lsw-Auth: ${LSW_Key}\" if [ \"$cmd\" = \"GET\" ]; then response=\"$(_get \"$LSW_API/$d\")\" _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" _debug \"http response code $_code\" _debug response \"$response\" return 0 fi if [ \"$cmd\" = \"POST\" ]; then data=\"{\\\"name\\\": \\\"$fd.\\\",\\\"type\\\": \\\"TXT\\\",\\\"content\\\": [\\\"$tvalue\\\"],\\\"ttl\\\": 60}\" response=\"$(_post \"$data\" \"$LSW_API/$d/resourceRecordSets\" \"$data\" \"POST\")\" _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" _debug \"http response code $_code\" _debug response \"$response\" return 0 fi if [ \"$cmd\" = \"DELETE\" ]; then response=\"$(_post \"\" \"$LSW_API/$d/resourceRecordSets/$fd/TXT\" \"\" \"DELETE\")\" _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" _debug \"http response code $_code\" _debug response \"$response\" return 0 fi return 1 }"
        },
        {
            "filename": "file_231.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_231.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_lexicon_info='Lexicon DNS client Site: github.com/AnalogJ/lexicon Docs: github.com/acmesh-official/acme.sh/wiki/How-to-use-lexicon-DNS-API Options: PROVIDER Provider ' lexicon_cmd=\"lexicon\" wiki=\"https://github.com/acmesh-official/acme.sh/wiki/How-to-use-lexicon-dns-api\" _lexicon_init() { if ! _exists \"$lexicon_cmd\"; then _err \"Please install $lexicon_cmd first: $wiki\" return 1 fi PROVIDER=\"${PROVIDER:-$(_readdomainconf PROVIDER)}\" if [ -z \"$PROVIDER\" ]; then PROVIDER=\"\" _err \"Please define env PROVIDER first: $wiki\" return 1 fi _savedomainconf PROVIDER \"$PROVIDER\" export PROVIDER # e.g. busybox-ash does not know [:upper:] # shellcheck disable=SC2018,SC2019 Lx_name=$(echo LEXICON_\"${PROVIDER}\"_USERNAME | tr 'a-z' 'A-Z') eval \"$Lx_name=\\${$Lx_name:-$(_readaccountconf_mutable \"$Lx_name\")}\" Lx_name_v=$(eval echo \\$\"$Lx_name\") _secure_debug \"$Lx_name\" \"$Lx_name_v\" if [ \"$Lx_name_v\" ]; then _saveaccountconf_mutable \"$Lx_name\" \"$Lx_name_v\" eval export \"$Lx_name\" fi # shellcheck disable=SC2018,SC2019 Lx_token=$(echo LEXICON_\"${PROVIDER}\"_TOKEN | tr 'a-z' 'A-Z') eval \"$Lx_token=\\${$Lx_token:-$(_readaccountconf_mutable \"$Lx_token\")}\" Lx_token_v=$(eval echo \\$\"$Lx_token\") _secure_debug \"$Lx_token\" \"$Lx_token_v\" if [ \"$Lx_token_v\" ]; then _saveaccountconf_mutable \"$Lx_token\" \"$Lx_token_v\" eval export \"$Lx_token\" fi # shellcheck disable=SC2018,SC2019 Lx_password=$(echo LEXICON_\"${PROVIDER}\"_PASSWORD | tr 'a-z' 'A-Z') eval \"$Lx_password=\\${$Lx_password:-$(_readaccountconf_mutable \"$Lx_password\")}\" Lx_password_v=$(eval echo \\$\"$Lx_password\") _secure_debug \"$Lx_password\" \"$Lx_password_v\" if [ \"$Lx_password_v\" ]; then _saveaccountconf_mutable \"$Lx_password\" \"$Lx_password_v\" eval export \"$Lx_password\" fi # shellcheck disable=SC2018,SC2019 Lx_domaintoken=$(echo LEXICON_\"${PROVIDER}\"_DOMAINTOKEN | tr 'a-z' 'A-Z') eval \"$Lx_domaintoken=\\${$Lx_domaintoken:-$(_readaccountconf_mutable \"$Lx_domaintoken\")}\" Lx_domaintoken_v=$(eval echo \\$\"$Lx_domaintoken\") _secure_debug \"$Lx_domaintoken\" \"$Lx_domaintoken_v\" if [ \"$Lx_domaintoken_v\" ]; then _saveaccountconf_mutable \"$Lx_domaintoken\" \"$Lx_domaintoken_v\" eval export \"$Lx_domaintoken\" fi # shellcheck disable=SC2018,SC2019 Lx_api_key=$(echo LEXICON_\"${PROVIDER}\"_API_KEY | tr 'a-z' 'A-Z') eval \"$Lx_api_key=\\${$Lx_api_key:-$(_readaccountconf_mutable \"$Lx_api_key\")}\" Lx_api_key_v=$(eval echo \\$\"$Lx_api_key\") _secure_debug \"$Lx_api_key\" \"$Lx_api_key_v\" if [ \"$Lx_api_key_v\" ]; then _saveaccountconf_mutable \"$Lx_api_key\" \"$Lx_api_key_v\" eval export \"$Lx_api_key\" fi } ######## Public functions ##################### #Usage: dns_lexicon_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_lexicon_add() { fulldomain=$1 txtvalue=$2 if ! _lexicon_init; then return 1 fi domain=$(printf \"%s\" \"$fulldomain\" | cut -d . -f 2-999) _secure_debug LEXICON_OPTS \"$LEXICON_OPTS\" _savedomainconf LEXICON_OPTS \"$LEXICON_OPTS\" # shellcheck disable=SC2086 $lexicon_cmd \"$PROVIDER\" $LEXICON_OPTS create \"${domain}\" TXT --name=\"_acme-challenge.${domain}.\" --content=\"${txtvalue}\" --output QUIET } #Usage: dns_lexicon_rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_lexicon_rm() { fulldomain=$1 txtvalue=$2 if ! _lexicon_init; then return 1 fi domain=$(printf \"%s\" \"$fulldomain\" | cut -d . -f 2-999) # shellcheck disable=SC2086 $lexicon_cmd \"$PROVIDER\" $LEXICON_OPTS delete \"${domain}\" TXT --name=\"_acme-challenge.${domain}.\" --content=\"${txtvalue}\" --output QUIET }"
        },
        {
            "filename": "file_232.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_232.sh",
            "content": "#!/usr/bin/env sh # Created by Laraveluser # # Pass credentials before \"acme.sh --issue --dns dns_limacity ...\" # -- # export LIMACITY_APIKEY=\"<API-KEY>\" # -- # # Pleas note: APIKEY must have following roles: dns.admin, domains.reader ######## Public functions ##################### LIMACITY_APIKEY=\"${LIMACITY_APIKEY:-$(_readaccountconf_mutable LIMACITY_APIKEY)}\" AUTH=$(printf \"%s\" \"api:$LIMACITY_APIKEY\" | _base64 -w 0) export _H1=\"Authorization: Basic $AUTH\" export _H2=\"Content-Type: application/json\" APIBASE=https://www.lima-city.de/usercp #Usage: dns_limacity_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_limacity_add() { _debug LIMACITY_APIKEY \"$LIMACITY_APIKEY\" if [ \"$LIMACITY_APIKEY\" = \"\" ]; then _err \"No Credentials given\" return 1 fi # save the dns server and key to the account conf file. _saveaccountconf_mutable LIMACITY_APIKEY \"${LIMACITY_APIKEY}\" fulldomain=$1 txtvalue=$2 if ! _lima_get_domain_id \"$fulldomain\"; then return 1; fi msg=$(_post \"{\\\"nameserver_record\\\":{\\\"name\\\":\\\"${fulldomain}\\\",\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"${txtvalue}\\\",\\\"ttl\\\":60}}\" \"${APIBASE}/domains/${LIMACITY_DOMAINID}/records.json\" \"\" \"POST\") _debug \"$msg\" if [ \"$(echo \"$msg\" | _egrep_o \"\\\"status\\\":\\\"ok\\\"\")\" = \"\" ]; then _err \"$msg\" return 1 fi return 0 } #Usage: dns_limacity_rm _acme-challenge.www.domain.com dns_limacity_rm() { fulldomain=$1 txtvalue=$2 if ! _lima_get_domain_id \"$fulldomain\"; then return 1; fi for recordId in $(_get \"${APIBASE}/domains/${LIMACITY_DOMAINID}/records.json\" | _egrep_o \"{\\\"id\\\":[0-9]*[^}]*,\\\"name\\\":\\\"${fulldomain}\\\"\" | _egrep_o \"[0-9]*\"); do _post \"\" \"${APIBASE}/domains/${LIMACITY_DOMAINID}/records/${recordId}\" \"\" \"DELETE\" done return 0 } #################### Private functions below ################################## _lima_get_domain_id() { domain=\"$1\" _debug \"$domain\" i=2 p=1 domains=$(_get \"${APIBASE}/domains.json\") if [ \"$(echo \"$domains\" | _egrep_o \"\\{.*\"\"domains\"\"\")\" ]; then response=\"$(echo \"$domains\" | tr -d \"\\n\" | tr '{' \"|\" | sed 's/|/&{/g' | tr \"|\" \"\\n\")\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi hostedzone=\"$(echo \"$response\" | _egrep_o \"\\{.*\"\"unicode_fqdn\"\"[^,]+\"\"$h\"\".*\\}\")\" if [ \"$hostedzone\" ]; then LIMACITY_DOMAINID=$(printf \"%s\\n\" \"$hostedzone\" | _egrep_o \"\\\"id\\\":\\s*[0-9]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\ ) if [ \"$LIMACITY_DOMAINID\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done fi return 1 }"
        },
        {
            "filename": "file_233.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_233.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_linode_info='Linode.com (Old) Deprecated. Use dns_linode_v4 Site: Linode.com Options: LINODE_API_KEY API Key Author: Philipp Grosswiler <philipp.grosswiler@swiss-design.net> ' LINODE_API_URL=\"https://api.linode.com/?api_key=$LINODE_API_KEY&api_action=\" ######## Public functions ##################### #Usage: dns_linode_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_linode_add() { fulldomain=\"${1}\" txtvalue=\"${2}\" if ! _Linode_API; then return 1 fi _info \"Using Linode\" _debug \"Calling: dns_linode_add() '${fulldomain}' '${txtvalue}'\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"Domain does not exist.\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _parameters=\"&DomainID=$_domain_id&Type=TXT&Name=$_sub_domain&Target=$txtvalue\" if _rest GET \"domain.resource.create\" \"$_parameters\" && [ -n \"$response\" ]; then _resource_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"ResourceID\\\":\\s*[0-9]+\" | cut -d : -f 2 | tr -d \" \" | _head_n 1) _debug _resource_id \"$_resource_id\" if [ -z \"$_resource_id\" ]; then _err \"Error adding the domain resource.\" return 1 fi _info \"Domain resource successfully added.\" return 0 fi return 1 } #Usage: dns_linode_rm _acme-challenge.www.domain.com dns_linode_rm() { fulldomain=\"${1}\" if ! _Linode_API; then return 1 fi _info \"Using Linode\" _debug \"Calling: dns_linode_rm() '${fulldomain}'\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"Domain does not exist.\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _parameters=\"&DomainID=$_domain_id\" if _rest GET \"domain.resource.list\" \"$_parameters\" && [ -n \"$response\" ]; then response=\"$(echo \"$response\" | tr -d \"\\n\" | tr '{' \"|\" | sed 's/|/&{/g' | tr \"|\" \"\\n\")\" resource=\"$(echo \"$response\" | _egrep_o \"{.*\\\"NAME\\\":\\s*\\\"$_sub_domain\\\".*}\")\" if [ \"$resource\" ]; then _resource_id=$(printf \"%s\\n\" \"$resource\" | _egrep_o \"\\\"RESOURCEID\\\":\\s*[0-9]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\ ) if [ \"$_resource_id\" ]; then _debug _resource_id \"$_resource_id\" _parameters=\"&DomainID=$_domain_id&ResourceID=$_resource_id\" if _rest GET \"domain.resource.delete\" \"$_parameters\" && [ -n \"$response\" ]; then _resource_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"ResourceID\\\":\\s*[0-9]+\" | cut -d : -f 2 | tr -d \" \" | _head_n 1) _debug _resource_id \"$_resource_id\" if [ -z \"$_resource_id\" ]; then _err \"Error deleting the domain resource.\" return 1 fi _info \"Domain resource successfully deleted.\" return 0 fi fi return 1 fi return 0 fi return 1 } #################### Private functions below ################################## _Linode_API() { if [ -z \"$LINODE_API_KEY\" ]; then LINODE_API_KEY=\"\" _err \"You didn't specify the Linode API key yet.\" _err \"Please create your key and try again.\" return 1 fi _saveaccountconf LINODE_API_KEY \"$LINODE_API_KEY\" } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=12345 _get_root() { domain=$1 i=2 p=1 if _rest GET \"domain.list\"; then response=\"$(echo \"$response\" | tr -d \"\\n\" | tr '{' \"|\" | sed 's/|/&{/g' | tr \"|\" \"\\n\")\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi hostedzone=\"$(echo \"$response\" | _egrep_o \"{.*\\\"DOMAIN\\\":\\s*\\\"$h\\\".*}\")\" if [ \"$hostedzone\" ]; then _domain_id=$(printf \"%s\\n\" \"$hostedzone\" | _egrep_o \"\\\"DOMAINID\\\":\\s*[0-9]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\ ) if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done fi return 1 } #method method action data _rest() { mtd=\"$1\" ep=\"$2\" data=\"$3\" _debug mtd \"$mtd\" _debug ep \"$ep\" export _H1=\"Accept: application/json\" export _H2=\"Content-Type: application/json\" if [ \"$mtd\" != \"GET\" ]; then # both POST and DELETE. _debug data \"$data\" response=\"$(_post \"$data\" \"$LINODE_API_URL$ep\" \"\" \"$mtd\")\" else response=\"$(_get \"$LINODE_API_URL$ep$data\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_234.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_234.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_linode_v4_info='Linode.com Site: Linode.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_linode_v4 Options: LINODE_V4_API_KEY API Key Author: Philipp Grosswiler <philipp.grosswiler@swiss-design.net>, Aaron W. Swenson <aaron@grandmasfridge.org> ' LINODE_V4_API_URL=\"https://api.linode.com/v4/domains\" ######## Public functions ##################### #Usage: dns_linode_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_linode_v4_add() { fulldomain=\"${1}\" txtvalue=\"${2}\" if ! _Linode_API; then return 1 fi _info \"Using Linode\" _debug \"Calling: dns_linode_add() '${fulldomain}' '${txtvalue}'\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"Domain does not exist.\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _payload=\"{ \\\"type\\\": \\\"TXT\\\", \\\"name\\\": \\\"$_sub_domain\\\", \\\"target\\\": \\\"$txtvalue\\\", \\\"ttl_sec\\\": 300 }\" if _rest POST \"/$_domain_id/records\" \"$_payload\" && [ -n \"$response\" ]; then _resource_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\": *[0-9]+\" | cut -d : -f 2 | tr -d \" \" | _head_n 1) _debug _resource_id \"$_resource_id\" if [ -z \"$_resource_id\" ]; then _err \"Error adding the domain resource.\" return 1 fi _info \"Domain resource successfully added.\" return 0 fi return 1 } #Usage: dns_linode_rm _acme-challenge.www.domain.com dns_linode_v4_rm() { fulldomain=\"${1}\" if ! _Linode_API; then return 1 fi _info \"Using Linode\" _debug \"Calling: dns_linode_rm() '${fulldomain}'\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"Domain does not exist.\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" if _rest GET \"/$_domain_id/records\" && [ -n \"$response\" ]; then response=\"$(echo \"$response\" | tr -d \"\\n\" | tr '{' \"|\" | sed 's/|/&{/g' | tr \"|\" \"\\n\")\" resource=\"$(echo \"$response\" | _egrep_o \"\\{.*\\\"name\\\": *\\\"$_sub_domain\\\".*}\")\" if [ \"$resource\" ]; then _resource_id=$(printf \"%s\\n\" \"$resource\" | _egrep_o \"\\\"id\\\": *[0-9]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\ ) if [ \"$_resource_id\" ]; then _debug _resource_id \"$_resource_id\" if _rest DELETE \"/$_domain_id/records/$_resource_id\" && [ -n \"$response\" ]; then # On 200/OK, empty set is returned. Check for error, if any. _error_response=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"errors\\\"\" | cut -d : -f 2 | tr -d \" \" | _head_n 1) if [ -n \"$_error_response\" ]; then _err \"Error deleting the domain resource: $_error_response\" return 1 fi _info \"Domain resource successfully deleted.\" return 0 fi fi return 1 fi return 0 fi return 1 } #################### Private functions below ################################## _Linode_API() { LINODE_V4_API_KEY=\"${LINODE_V4_API_KEY:-$(_readaccountconf_mutable LINODE_V4_API_KEY)}\" if [ -z \"$LINODE_V4_API_KEY\" ]; then LINODE_V4_API_KEY=\"\" _err \"You didn't specify the Linode v4 API key yet.\" _err \"Please create your key and try again.\" return 1 fi _saveaccountconf_mutable LINODE_V4_API_KEY \"$LINODE_V4_API_KEY\" } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=12345 _get_root() { domain=$1 i=2 p=1 if _rest GET; then response=\"$(echo \"$response\" | tr -d \"\\n\" | tr '{' \"|\" | sed 's/|/&{/g' | tr \"|\" \"\\n\")\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi hostedzone=\"$(echo \"$response\" | _egrep_o \"\\{.*\\\"domain\\\": *\\\"$h\\\".*}\")\" if [ \"$hostedzone\" ]; then _domain_id=$(printf \"%s\\n\" \"$hostedzone\" | _egrep_o \"\\\"id\\\": *[0-9]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\ ) if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done fi return 1 } #method method action data _rest() { mtd=\"$1\" ep=\"$2\" data=\"$3\" _debug mtd \"$mtd\" _debug ep \"$ep\" export _H1=\"Accept: application/json\" export _H2=\"Content-Type: application/json\" export _H3=\"Authorization: Bearer $LINODE_V4_API_KEY\" if [ \"$mtd\" != \"GET\" ]; then # both POST and DELETE. _debug data \"$data\" response=\"$(_post \"$data\" \"$LINODE_V4_API_URL$ep\" \"\" \"$mtd\")\" else response=\"$(_get \"$LINODE_V4_API_URL$ep$data\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_235.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_235.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_loopia_info='Loopia.se Site: Loopia.se Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_loopia Options: LOOPIA_Api API URL. E.g. \"https://api.loopia.<TLD>/RPCSERV\" where the <TLD> is one of: com, no, rs, se. Default: \"se\". LOOPIA_User Username LOOPIA_Password Password ' LOOPIA_Api_Default=\"https://api.loopia.se/RPCSERV\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_loopia_add() { fulldomain=$1 txtvalue=$2 if ! _loopia_load_config; then return 1 fi _loopia_save_config _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if ! _loopia_add_sub_domain \"$_domain\" \"$_sub_domain\"; then return 1 fi if ! _loopia_add_record \"$_domain\" \"$_sub_domain\" \"$txtvalue\"; then return 1 fi } dns_loopia_rm() { fulldomain=$1 txtvalue=$2 if ! _loopia_load_config; then return 1 fi _loopia_save_config _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>removeSubdomain</methodName> <params> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> </params> </methodCall>' \"$LOOPIA_User\" \"$Encoded_Password\" \"$_domain\" \"$_sub_domain\") response=\"$(_post \"$xml_content\" \"$LOOPIA_Api\" \"\" \"POST\")\" if ! _contains \"$response\" \"OK\"; then err_response=$(echo \"$response\" | sed 's/.*<string>\\(.*\\)<\\/string>.*/\\1/') _err \"Error could not get txt records: $err_response\" return 1 fi } #################### Private functions below ################################## _loopia_load_config() { LOOPIA_Api=\"${LOOPIA_Api:-$(_readaccountconf_mutable LOOPIA_Api)}\" LOOPIA_User=\"${LOOPIA_User:-$(_readaccountconf_mutable LOOPIA_User)}\" LOOPIA_Password=\"${LOOPIA_Password:-$(_readaccountconf_mutable LOOPIA_Password)}\" if [ -z \"$LOOPIA_Api\" ]; then LOOPIA_Api=\"$LOOPIA_Api_Default\" fi if [ -z \"$LOOPIA_User\" ] || [ -z \"$LOOPIA_Password\" ]; then LOOPIA_User=\"\" LOOPIA_Password=\"\" _err \"A valid Loopia API user and password not provided.\" _err \"Please provide a valid API user and try again.\" return 1 fi if _contains \"$LOOPIA_Password\" \"'\" || _contains \"$LOOPIA_Password\" '\"'; then _err \"Password contains a quotation mark or double quotation marks and this is not supported by dns_loopia.sh\" return 1 fi Encoded_Password=$(_xml_encode \"$LOOPIA_Password\") return 0 } _loopia_save_config() { if [ \"$LOOPIA_Api\" != \"$LOOPIA_Api_Default\" ]; then _saveaccountconf_mutable LOOPIA_Api \"$LOOPIA_Api\" fi _saveaccountconf_mutable LOOPIA_User \"$LOOPIA_User\" _saveaccountconf_mutable LOOPIA_Password \"$LOOPIA_Password\" } _loopia_get_records() { domain=$1 sub_domain=$2 xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>getZoneRecords</methodName> <params> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> </params> </methodCall>' \"$LOOPIA_User\" \"$Encoded_Password\" \"$domain\" \"$sub_domain\") response=\"$(_post \"$xml_content\" \"$LOOPIA_Api\" \"\" \"POST\")\" if ! _contains \"$response\" \"<array>\"; then err_response=$(echo \"$response\" | sed 's/.*<string>\\(.*\\)<\\/string>.*/\\1/') _err \"Error: $err_response\" return 1 fi return 0 } _get_root() { domain=$1 _debug \"get root\" domain=$1 i=2 p=1 xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>getDomains</methodName> <params> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> </params> </methodCall>' \"$LOOPIA_User\" \"$Encoded_Password\") response=\"$(_post \"$xml_content\" \"$LOOPIA_Api\" \"\" \"POST\")\" while true; do h=$(echo \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"$h\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _loopia_add_record() { domain=$1 sub_domain=$2 txtval=$3 xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>addZoneRecord</methodName> <params> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> <param> <value> <struct> <member> <name>type</name> <value><string>TXT</string></value> </member> <member> <name>priority</name> <value><int>0</int></value> </member> <member> <name>ttl</name> <value><int>300</int></value> </member> <member> <name>rdata</name> <value><string>%s</string></value> </member> </struct> </value> </param> </params> </methodCall>' \"$LOOPIA_User\" \"$Encoded_Password\" \"$domain\" \"$sub_domain\" \"$txtval\") response=\"$(_post \"$xml_content\" \"$LOOPIA_Api\" \"\" \"POST\")\" if ! _contains \"$response\" \"OK\"; then err_response=$(echo \"$response\" | sed 's/.*<string>\\(.*\\)<\\/string>.*/\\1/') _err \"Error: $err_response\" return 1 fi return 0 } _sub_domain_exists() { domain=$1 sub_domain=$2 xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>getSubdomains</methodName> <params> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> </params> </methodCall>' \"$LOOPIA_User\" \"$Encoded_Password\" \"$domain\") response=\"$(_post \"$xml_content\" \"$LOOPIA_Api\" \"\" \"POST\")\" if _contains \"$response\" \"$sub_domain\"; then return 0 fi return 1 } _loopia_add_sub_domain() { domain=$1 sub_domain=$2 if _sub_domain_exists \"$domain\" \"$sub_domain\"; then return 0 fi xml_content=$(printf '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <methodCall> <methodName>addSubdomain</methodName> <params> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> <param> <value><string>%s</string></value> </param> </params> </methodCall>' \"$LOOPIA_User\" \"$Encoded_Password\" \"$domain\" \"$sub_domain\") response=\"$(_post \"$xml_content\" \"$LOOPIA_Api\" \"\" \"POST\")\" if ! _contains \"$response\" \"OK\"; then err_response=$(echo \"$response\" | sed 's/.*<string>\\(.*\\)<\\/string>.*/\\1/') _err \"Error: $err_response\" return 1 fi return 0 } _xml_encode() { encoded_string=$1 encoded_string=$(echo \"$encoded_string\" | sed 's/&/\\&amp;/') encoded_string=$(echo \"$encoded_string\" | sed 's/</\\&lt;/') encoded_string=$(echo \"$encoded_string\" | sed 's/>/\\&gt;/') printf \"%s\" \"$encoded_string\" }"
        },
        {
            "filename": "file_236.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_236.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_lua_info='LuaDNS.com Domains: LuaDNS.net Site: LuaDNS.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_lua Options: LUA_Key API key LUA_Email Email Author: <dev@1e.ca> ' LUA_Api=\"https://api.luadns.com/v1\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_lua_add() { fulldomain=$1 txtvalue=$2 LUA_Key=\"${LUA_Key:-$(_readaccountconf_mutable LUA_Key)}\" LUA_Email=\"${LUA_Email:-$(_readaccountconf_mutable LUA_Email)}\" LUA_auth=$(printf \"%s\" \"$LUA_Email:$LUA_Key\" | _base64) if [ -z \"$LUA_Key\" ] || [ -z \"$LUA_Email\" ]; then LUA_Key=\"\" LUA_Email=\"\" _err \"You don't specify luadns api key and email yet.\" _err \"Please create you key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable LUA_Key \"$LUA_Key\" _saveaccountconf_mutable LUA_Email \"$LUA_Email\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if _LUA_rest POST \"zones/$_domain_id/records\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$fulldomain.\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":120}\"; then if _contains \"$response\" \"$fulldomain\"; then _info \"Added\" #todo: check if the record takes effect return 0 else _err \"Add txt record error.\" return 1 fi fi } #fulldomain dns_lua_rm() { fulldomain=$1 txtvalue=$2 LUA_Key=\"${LUA_Key:-$(_readaccountconf_mutable LUA_Key)}\" LUA_Email=\"${LUA_Email:-$(_readaccountconf_mutable LUA_Email)}\" LUA_auth=$(printf \"%s\" \"$LUA_Email:$LUA_Key\" | _base64) _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _LUA_rest GET \"zones/${_domain_id}/records\" count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"name\\\":\\\"$fulldomain.\\\",\\\"type\\\":\\\"TXT\\\"\" | wc -l | tr -d \" \") _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":[^,]*,\\\"name\\\":\\\"$fulldomain.\\\",\\\"type\\\":\\\"TXT\\\"\" | _head_n 1 | cut -d: -f2 | cut -d, -f1) _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _LUA_rest DELETE \"/zones/$_domain_id/records/$record_id\"; then _err \"Delete record error.\" return 1 fi _contains \"$response\" \"$record_id\" fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=2 p=1 if ! _LUA_rest GET \"zones\"; then return 1 fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\"; then _domain_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":[^,]*,\\\"name\\\":\\\"$h\\\"\" | cut -d : -f 2 | cut -d , -f 1) _debug _domain_id \"$_domain_id\" if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _LUA_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Accept: application/json\" export _H2=\"Authorization: Basic $LUA_auth\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$LUA_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$LUA_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_237.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_237.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_maradns_info='MaraDNS Server Site: MaraDNS.samiam.org Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_maradns Options: MARA_ZONE_FILE Zone file path. E.g. \"/etc/maradns/db.domain.com\" MARA_DUENDE_PID_PATH Duende PID Path. E.g. \"/run/maradns/etc_maradns_mararc.pid\" Issues: github.com/acmesh-official/acme.sh/issues/2072 ' #Usage: dns_maradns_add _acme-challenge.www.domain.com \"token\" dns_maradns_add() { fulldomain=\"$1\" txtvalue=\"$2\" MARA_ZONE_FILE=\"${MARA_ZONE_FILE:-$(_readaccountconf_mutable MARA_ZONE_FILE)}\" MARA_DUENDE_PID_PATH=\"${MARA_DUENDE_PID_PATH:-$(_readaccountconf_mutable MARA_DUENDE_PID_PATH)}\" _check_zone_file \"$MARA_ZONE_FILE\" || return 1 _check_duende_pid_path \"$MARA_DUENDE_PID_PATH\" || return 1 _saveaccountconf_mutable MARA_ZONE_FILE \"$MARA_ZONE_FILE\" _saveaccountconf_mutable MARA_DUENDE_PID_PATH \"$MARA_DUENDE_PID_PATH\" printf \"%s. TXT '%s' ~\\n\" \"$fulldomain\" \"$txtvalue\" >>\"$MARA_ZONE_FILE\" _reload_maradns \"$MARA_DUENDE_PID_PATH\" || return 1 } #Usage: dns_maradns_rm _acme-challenge.www.domain.com \"token\" dns_maradns_rm() { fulldomain=\"$1\" txtvalue=\"$2\" MARA_ZONE_FILE=\"${MARA_ZONE_FILE:-$(_readaccountconf_mutable MARA_ZONE_FILE)}\" MARA_DUENDE_PID_PATH=\"${MARA_DUENDE_PID_PATH:-$(_readaccountconf_mutable MARA_DUENDE_PID_PATH)}\" _check_zone_file \"$MARA_ZONE_FILE\" || return 1 _check_duende_pid_path \"$MARA_DUENDE_PID_PATH\" || return 1 _saveaccountconf_mutable MARA_ZONE_FILE \"$MARA_ZONE_FILE\" _saveaccountconf_mutable MARA_DUENDE_PID_PATH \"$MARA_DUENDE_PID_PATH\" _sed_i \"/^$fulldomain.\\+TXT '$txtvalue' ~/d\" \"$MARA_ZONE_FILE\" _reload_maradns \"$MARA_DUENDE_PID_PATH\" || return 1 } _check_zone_file() { zonefile=\"$1\" if [ -z \"$zonefile\" ]; then _err \"MARA_ZONE_FILE not passed!\" return 1 elif [ ! -w \"$zonefile\" ]; then _err \"MARA_ZONE_FILE not writable: $zonefile\" return 1 fi } _check_duende_pid_path() { pidpath=\"$1\" if [ -z \"$pidpath\" ]; then _err \"MARA_DUENDE_PID_PATH not passed!\" return 1 fi if [ ! -r \"$pidpath\" ]; then _err \"MARA_DUENDE_PID_PATH not readable: $pidpath\" return 1 fi } _reload_maradns() { pidpath=\"$1\" kill -s HUP -- \"$(cat \"$pidpath\")\" if [ $? -ne 0 ]; then _err \"Unable to reload MaraDNS, kill returned $?\" return 1 fi }"
        },
        {
            "filename": "file_238.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_238.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_me_info='DnsMadeEasy.com Site: DnsMadeEasy.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_me Options: ME_Key API Key ME_Secret API Secret Author: <dev@1e.ca> ' ME_Api=https://api.dnsmadeeasy.com/V2.0/dns/managed ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_me_add() { fulldomain=$1 txtvalue=$2 if [ -z \"$ME_Key\" ] || [ -z \"$ME_Secret\" ]; then ME_Key=\"\" ME_Secret=\"\" _err \"You didn't specify DNSMadeEasy api key and secret yet.\" _err \"Please create you key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf ME_Key \"$ME_Key\" _saveaccountconf ME_Secret \"$ME_Secret\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _me_rest GET \"${_domain_id}/records?recordName=$_sub_domain&type=TXT\" if ! _contains \"$response\" \"\\\"totalRecords\\\":\"; then _err \"Error\" return 1 fi _info \"Adding record\" if _me_rest POST \"$_domain_id/records/\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"value\\\":\\\"$txtvalue\\\",\\\"gtdLocation\\\":\\\"DEFAULT\\\",\\\"ttl\\\":120}\"; then if printf -- \"%s\" \"$response\" | grep \\\"id\\\": >/dev/null; then _info \"Added\" #todo: check if the record takes effect return 0 else _err \"Add txt record error.\" return 1 fi fi } #fulldomain dns_me_rm() { fulldomain=$1 txtvalue=$2 _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _me_rest GET \"${_domain_id}/records?recordName=$_sub_domain&type=TXT\" count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"totalRecords\\\":[^,]*\" | cut -d : -f 2) _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \",\\\"value\\\":\\\"..$txtvalue..\\\",\\\"id\\\":[^,]*\" | cut -d : -f 3 | head -n 1) _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _me_rest DELETE \"$_domain_id/records/$record_id\"; then _err \"Delete record error.\" return 1 fi _contains \"$response\" '' fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi if ! _me_rest GET \"name?domainname=$h\"; then return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\"; then _domain_id=$(printf \"%s\\n\" \"$response\" | sed 's/^{//; s/}$//; s/{.*}//' | sed -r 's/^.*\"id\":([0-9]+).*$/\\1/') if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _me_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" cdate=$(LANG=C date -u +\"%a, %d %b %Y %T %Z\") hmac=$(printf \"%s\" \"$cdate\" | _hmac sha1 \"$(printf \"%s\" \"$ME_Secret\" | _hex_dump | tr -d \" \")\" hex) export _H1=\"x-dnsme-apiKey: $ME_Key\" export _H2=\"x-dnsme-requestDate: $cdate\" export _H3=\"x-dnsme-hmac: $hmac\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$ME_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$ME_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_239.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_239.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_miab_info='Mail-in-a-Box Site: MailInaBox.email Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_miab Options: MIAB_Username Admin username MIAB_Password Admin password MIAB_Server Server hostname. FQDN of your_MIAB Server Issues: github.com/acmesh-official/acme.sh/issues/2550 Author: Darven Dissek, William Gertz ' ######## Public functions ##################### #Usage: dns_miab_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_miab_add() { fulldomain=$1 # Added \"value=\" and \"&ttl=300\" to accomodate the new TXT record format used by the MIAB/PMIAB API txtvalue=\"value=$2&ttl=300\" _info \"Using miab challenge add\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" #retrieve MIAB environemt vars if ! _retrieve_miab_env; then return 1 fi #check domain and seperate into domain and host if ! _get_root \"$fulldomain\"; then _err \"Cannot find any part of ${fulldomain} is hosted on ${MIAB_Server}\" return 1 fi _debug2 _sub_domain \"$_sub_domain\" _debug2 _domain \"$_domain\" #add the challenge record _api_path=\"custom/${fulldomain}/txt\" _miab_rest \"$txtvalue\" \"$_api_path\" \"POST\" #check if result was good if _contains \"$response\" \"updated DNS\"; then _info \"Successfully created the txt record\" return 0 else _err \"Error encountered during record add\" _err \"$response\" return 1 fi } #Usage: dns_miab_rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_miab_rm() { fulldomain=$1 txtvalue=$2 _info \"Using miab challenge delete\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" #retrieve MIAB environemt vars if ! _retrieve_miab_env; then return 1 fi #check domain and seperate into doamin and host if ! _get_root \"$fulldomain\"; then _err \"Cannot find any part of ${fulldomain} is hosted on ${MIAB_Server}\" return 1 fi _debug2 _sub_domain \"$_sub_domain\" _debug2 _domain \"$_domain\" #Remove the challenge record _api_path=\"custom/${fulldomain}/txt\" _miab_rest \"$txtvalue\" \"$_api_path\" \"DELETE\" #check if result was good if _contains \"$response\" \"updated DNS\"; then _info \"Successfully removed the txt record\" return 0 else _err \"Error encountered during record remove\" _err \"$response\" return 1 fi } #################### Private functions below ################################## # #Usage: _get_root _acme-challenge.www.domain.com #Returns: # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { _passed_domain=$1 _debug _passed_domain \"$_passed_domain\" _i=2 _p=1 #get the zones hosed on MIAB server, must be a json stream _miab_rest \"\" \"zones\" \"GET\" if ! _is_json \"$response\"; then _err \"ERROR fetching domain list\" _err \"$response\" return 1 fi #cycle through the passed domain seperating out a test domain discarding # the subdomain by marching thorugh the dots while true; do _test_domain=$(printf \"%s\" \"$_passed_domain\" | cut -d . -f ${_i}-100) _debug _test_domain \"$_test_domain\" if [ -z \"$_test_domain\" ]; then return 1 fi #report found if the test domain is in the json response and # report the subdomain if _contains \"$response\" \"\\\"$_test_domain\\\"\"; then _sub_domain=$(printf \"%s\" \"$_passed_domain\" | cut -d . -f 1-${_p}) _domain=${_test_domain} return 0 fi #cycle to the next dot in the passed domain _p=${_i} _i=$(_math \"$_i\" + 1) done return 1 } #Usage: _retrieve_miab_env #Returns (from store or environment variables): # MIAB_Username # MIAB_Password # MIAB_Server #retrieve MIAB environment variables, report errors and quit if problems _retrieve_miab_env() { MIAB_Username=\"${MIAB_Username:-$(_readaccountconf_mutable MIAB_Username)}\" MIAB_Password=\"${MIAB_Password:-$(_readaccountconf_mutable MIAB_Password)}\" MIAB_Server=\"${MIAB_Server:-$(_readaccountconf_mutable MIAB_Server)}\" #debug log the environmental variables _debug MIAB_Username \"$MIAB_Username\" _debug MIAB_Password \"$MIAB_Password\" _debug MIAB_Server \"$MIAB_Server\" #check if MIAB environemt vars set and quit if not if [ -z \"$MIAB_Username\" ] || [ -z \"$MIAB_Password\" ] || [ -z \"$MIAB_Server\" ]; then _err \"You didn't specify one or more of MIAB_Username, MIAB_Password or MIAB_Server.\" _err \"Please check these environment variables and try again.\" return 1 fi #save the credentials to the account conf file. _saveaccountconf_mutable MIAB_Username \"$MIAB_Username\" _saveaccountconf_mutable MIAB_Password \"$MIAB_Password\" _saveaccountconf_mutable MIAB_Server \"$MIAB_Server\" return 0 } #Useage: _miab_rest \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" \"custom/_acme-challenge.www.domain.com/txt \"POST\" #Returns: \"updated DNS: domain.com\" #rest interface MIAB dns _miab_rest() { _data=\"$1\" _api_path=\"$2\" _httpmethod=\"$3\" #encode username and password for basic authentication _credentials=\"$(printf \"%s\" \"$MIAB_Username:$MIAB_Password\" | _base64)\" export _H1=\"Authorization: Basic $_credentials\" _url=\"https://${MIAB_Server}/admin/dns/${_api_path}\" _debug2 _data \"$_data\" _debug _api_path \"$_api_path\" _debug2 _url \"$_url\" _debug2 _credentails \"$_credentials\" _debug _httpmethod \"$_httpmethod\" if [ \"$_httpmethod\" = \"GET\" ]; then response=\"$(_get \"$_url\")\" else response=\"$(_post \"$_data\" \"$_url\" \"\" \"$_httpmethod\")\" fi _retcode=\"$?\" if [ \"$_retcode\" != \"0\" ]; then _err \"MIAB REST authentication failed on $_httpmethod\" return 1 fi _debug response \"$response\" return 0 } #Usage: _is_json \"\\[\\n \"mydomain.com\"\\n]\" #Reurns \"\\[\\n \"mydomain.com\"\\n]\" #returns the string if it begins and ends with square braces _is_json() { _str=\"$(echo \"$1\" | _normalizeJson)\" echo \"$_str\" | grep '^\\[.*\\]$' >/dev/null 2>&1 }"
        },
        {
            "filename": "file_240.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_240.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_misaka_info='Misaka.io Site: Misaka.io Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_misaka Options: Misaka_Key API Key Author: <support+acmesh@misaka.io> ' Misaka_Api=\"https://dnsapi.misaka.io/dns\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_misaka_add() { fulldomain=$1 txtvalue=$2 if [ -z \"$Misaka_Key\" ]; then Misaka_Key=\"\" _err \"You didn't specify misaka.io dns api key yet.\" _err \"Please create you key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf Misaka_Key \"$Misaka_Key\" _debug \"checking root zone [$fulldomain]\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _misaka_rest GET \"zones/${_domain}/recordsets?search=${_sub_domain}\" if ! _contains \"$response\" \"\\\"results\\\":\"; then _err \"Error\" return 1 fi count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"name\\\":\\\"$_sub_domain\\\",[^{]*\\\"type\\\":\\\"TXT\\\"\" | wc -l | tr -d \" \") _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Adding record\" if _misaka_rest POST \"zones/${_domain}/recordsets/${_sub_domain}/TXT\" \"{\\\"records\\\":[{\\\"value\\\":\\\"\\\\\\\"$txtvalue\\\\\\\"\\\"}],\\\"filters\\\":[],\\\"ttl\\\":1}\"; then _debug response \"$response\" if _contains \"$response\" \"$_sub_domain\"; then _info \"Added\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" else _info \"Updating record\" _misaka_rest PUT \"zones/${_domain}/recordsets/${_sub_domain}/TXT?append=true\" \"{\\\"records\\\": [{\\\"value\\\": \\\"\\\\\\\"$txtvalue\\\\\\\"\\\"}],\\\"ttl\\\":1}\" if [ \"$?\" = \"0\" ] && _contains \"$response\" \"$_sub_domain\"; then _info \"Updated!\" #todo: check if the record takes effect return 0 fi _err \"Update error\" return 1 fi } #fulldomain dns_misaka_rm() { fulldomain=$1 txtvalue=$2 _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _misaka_rest GET \"zones/${_domain}/recordsets?search=${_sub_domain}\" count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"name\\\":\\\"$_sub_domain\\\",[^{]*\\\"type\\\":\\\"TXT\\\"\" | wc -l | tr -d \" \") _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else if ! _misaka_rest DELETE \"zones/${_domain}/recordsets/${_sub_domain}/TXT\"; then _err \"Delete record error.\" return 1 fi _contains \"$response\" \"\" fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=2 p=1 if ! _misaka_rest GET \"zones?limit=1000\"; then return 1 fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _misaka_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Content-Type: application/json\" export _H2=\"User-Agent: acme.sh/$VER misaka-dns-acmesh/20191213\" export _H3=\"Authorization: Token $Misaka_Key\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$Misaka_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$Misaka_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_241.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_241.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_myapi_info='Custom API Example A sample custom DNS API script. Domains: example.com Site: github.com/acmesh-official/acme.sh/wiki/DNS-API-Dev-Guide Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_duckdns Options: MYAPI_Token API Token. Get API Token from https://example.com/api/. Optional. Issues: github.com/acmesh-official/acme.sh Author: Neil Pang <neilgit@neilpang.com> ' #This file name is \"dns_myapi.sh\" #So, here must be a method dns_myapi_add() #Which will be called by acme.sh to add the txt record to your api system. #returns 0 means success, otherwise error. ######## Public functions ##################### # Please Read this guide first: https://github.com/acmesh-official/acme.sh/wiki/DNS-API-Dev-Guide #Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_myapi_add() { fulldomain=$1 txtvalue=$2 _info \"Using myapi\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _err \"Not implemented!\" return 1 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_myapi_rm() { fulldomain=$1 txtvalue=$2 _info \"Using myapi\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" } #################### Private functions below ##################################"
        },
        {
            "filename": "file_242.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_242.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_mydevil_info='MyDevil.net MyDevil.net already supports automatic Lets Encrypt certificates, except for wildcard domains. This script depends on devil command that MyDevil.net provides, which means that it works only on server side. Site: MyDevil.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_mydevil Issues: github.com/acmesh-official/acme.sh/issues/2079 Author: Marcin Konicki <https://ahwayakchih.neoni.net> ' ######## Public functions ##################### #Usage: dns_mydevil_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_mydevil_add() { fulldomain=$1 txtvalue=$2 domain=\"\" if ! _exists \"devil\"; then _err \"Could not find 'devil' command.\" return 1 fi _info \"Using mydevil\" domain=$(mydevil_get_domain \"$fulldomain\") if [ -z \"$domain\" ]; then _err \"Invalid domain name: could not find root domain of $fulldomain.\" return 1 fi # No need to check if record name exists, `devil` always adds new record. # In worst case scenario, we end up with multiple identical records. _info \"Adding $fulldomain record for domain $domain\" if devil dns add \"$domain\" \"$fulldomain\" TXT \"$txtvalue\"; then _info \"Successfully added TXT record, ready for validation.\" return 0 else _err \"Unable to add DNS record.\" return 1 fi } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_mydevil_rm() { fulldomain=$1 txtvalue=$2 domain=\"\" if ! _exists \"devil\"; then _err \"Could not find 'devil' command.\" return 1 fi _info \"Using mydevil\" domain=$(mydevil_get_domain \"$fulldomain\") if [ -z \"$domain\" ]; then _err \"Invalid domain name: could not find root domain of $fulldomain.\" return 1 fi # catch one or more numbers num='[0-9][0-9]*' # catch one or more whitespace w=$(printf '[\\t ][\\t ]*') # catch anything, except newline any='.*' # filter to make sure we do not delete other records validRecords=\"^${num}${w}${fulldomain}${w}TXT${w}${any}${txtvalue}$\" for id in $(devil dns list \"$domain\" | tail -n+2 | grep \"${validRecords}\" | cut -w -s -f 1); do _info \"Removing record $id from domain $domain\" echo \"y\" | devil dns del \"$domain\" \"$id\" || _err \"Could not remove DNS record.\" done } #################### Private functions below ################################## # Usage: domain=$(mydevil_get_domain \"_acme-challenge.www.domain.com\" || _err \"Invalid domain name\") # echo $domain mydevil_get_domain() { fulldomain=$1 domain=\"\" for domain in $(devil dns list | cut -w -s -f 1 | tail -n+2); do _debug \"Checking domain: $domain\" if _endswith \"$fulldomain\" \"$domain\"; then _debug \"Fulldomain '$fulldomain' matches '$domain'\" printf -- \"%s\" \"$domain\" return 0 fi done return 1 }"
        },
        {
            "filename": "file_243.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_243.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_mydnsjp_info='MyDNS.JP Site: MyDNS.JP Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_mydnsjp Options: MYDNSJP_MasterID Master ID MYDNSJP_Password Password Author: epgdatacapbon ' ######## Public functions ##################### # Export MyDNS.JP MasterID and Password in following variables... # MYDNSJP_MasterID=MasterID # MYDNSJP_Password=Password MYDNSJP_API=\"https://www.mydns.jp\" #Usage: dns_mydnsjp_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_mydnsjp_add() { fulldomain=$1 txtvalue=$2 _info \"Using mydnsjp\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" # Load the credentials from the account conf file MYDNSJP_MasterID=\"${MYDNSJP_MasterID:-$(_readaccountconf_mutable MYDNSJP_MasterID)}\" MYDNSJP_Password=\"${MYDNSJP_Password:-$(_readaccountconf_mutable MYDNSJP_Password)}\" if [ -z \"$MYDNSJP_MasterID\" ] || [ -z \"$MYDNSJP_Password\" ]; then MYDNSJP_MasterID=\"\" MYDNSJP_Password=\"\" _err \"You don't specify mydnsjp api MasterID and Password yet.\" _err \"Please export as MYDNSJP_MasterID / MYDNSJP_Password and try again.\" return 1 fi # Save the credentials to the account conf file _saveaccountconf_mutable MYDNSJP_MasterID \"$MYDNSJP_MasterID\" _saveaccountconf_mutable MYDNSJP_Password \"$MYDNSJP_Password\" _debug \"First detect the root zone.\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" if _mydnsjp_api \"REGIST\" \"$_domain\" \"$txtvalue\"; then if printf -- \"%s\" \"$response\" | grep \"OK.\" >/dev/null; then _info \"Added, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_mydnsjp_rm() { fulldomain=$1 txtvalue=$2 _info \"Removing TXT record\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" # Load the credentials from the account conf file MYDNSJP_MasterID=\"${MYDNSJP_MasterID:-$(_readaccountconf_mutable MYDNSJP_MasterID)}\" MYDNSJP_Password=\"${MYDNSJP_Password:-$(_readaccountconf_mutable MYDNSJP_Password)}\" if [ -z \"$MYDNSJP_MasterID\" ] || [ -z \"$MYDNSJP_Password\" ]; then MYDNSJP_MasterID=\"\" MYDNSJP_Password=\"\" _err \"You don't specify mydnsjp api MasterID and Password yet.\" _err \"Please export as MYDNSJP_MasterID / MYDNSJP_Password and try again.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" if _mydnsjp_api \"DELETE\" \"$_domain\" \"$txtvalue\"; then if printf -- \"%s\" \"$response\" | grep \"OK.\" >/dev/null; then _info \"Deleted, OK\" return 0 else _err \"Delete txt record error.\" return 1 fi fi _err \"Delete txt record error.\" return 1 } #################### Private functions below ################################## # _acme-challenge.www.domain.com # returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { fulldomain=$1 i=2 p=1 # Get the root domain _mydnsjp_retrieve_domain if [ \"$?\" != \"0\" ]; then # not valid return 1 fi while true; do _domain=$(printf \"%s\" \"$fulldomain\" | cut -d . -f $i-100) if [ -z \"$_domain\" ]; then # not valid return 1 fi if [ \"$_domain\" = \"$_root_domain\" ]; then _sub_domain=$(printf \"%s\" \"$fulldomain\" | cut -d . -f 1-$p) return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } # Retrieve the root domain # returns 0 success _mydnsjp_retrieve_domain() { _debug \"Login to MyDNS.JP\" response=\"$(_post \"MENU=100&masterid=$MYDNSJP_MasterID&masterpwd=$MYDNSJP_Password\" \"$MYDNSJP_API/members/\")\" cookie=\"$(grep -i '^set-cookie:' \"$HTTP_HEADER\" | _head_n 1 | cut -d \" \" -f 2)\" # If cookies is not empty then logon successful if [ -z \"$cookie\" ]; then _err \"Fail to get a cookie.\" return 1 fi _root_domain=$(echo \"$response\" | grep \"DNSINFO\\[domainname\\]\" | sed 's/^.*value=\"\\([^\"]*\\)\".*/\\1/') _debug _root_domain \"$_root_domain\" if [ -z \"$_root_domain\" ]; then _err \"Fail to get the root domain.\" return 1 fi return 0 } _mydnsjp_api() { cmd=$1 domain=$2 txtvalue=$3 # Base64 encode the credentials credentials=$(printf \"%s:%s\" \"$MYDNSJP_MasterID\" \"$MYDNSJP_Password\" | _base64) # Construct the HTTP Authorization header export _H1=\"Content-Type: application/x-www-form-urlencoded\" export _H2=\"Authorization: Basic ${credentials}\" response=\"$(_post \"CERTBOT_DOMAIN=$domain&CERTBOT_VALIDATION=$txtvalue&EDIT_CMD=$cmd\" \"$MYDNSJP_API/directedit.html\")\" if [ \"$?\" != \"0\" ]; then _err \"error $domain\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_244.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_244.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_mythic_beasts_info='Mythic-Beasts.com Site: Mythic-Beasts.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_mythic_beasts Options: MB_AK API Key MB_AS API Secret Issues: github.com/acmesh-official/acme.sh/issues/3848 ' # Mythic Beasts is a long-standing UK service provider using standards-based OAuth2 authentication # To test: ./acme.sh --dns dns_mythic_beasts --test --debug 1 --output-insecure --issue --domain domain.com # Cannot retest once cert is issued # OAuth2 tokens only valid for 300 seconds so we do not store # NOTE: This will remove all TXT records matching the fulldomain, not just the added ones (_acme-challenge.www.domain.com) # Test OAuth2 credentials #MB_AK=\"aaaaaaaaaaaaaaaa\" #MB_AS=\"bbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\" # URLs MB_API='https://api.mythic-beasts.com/dns/v2/zones' MB_AUTH='https://auth.mythic-beasts.com/login' ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_mythic_beasts_add() { fulldomain=$1 txtvalue=$2 _info \"MYTHIC BEASTS Adding record $fulldomain = $txtvalue\" if ! _initAuth; then return 1 fi if ! _get_root \"$fulldomain\"; then return 1 fi # method path body_data if _mb_rest POST \"$_domain/records/$_sub_domain/TXT\" \"$txtvalue\"; then if _contains \"$response\" \"1 records added\"; then _info \"Added, verifying...\" # Max 120 seconds to publish for i in $(seq 1 6); do # Retry on error if ! _mb_rest GET \"$_domain/records/$_sub_domain/TXT?verify\"; then _sleep 20 else _info \"Record published!\" return 0 fi done else _err \"\\n$response\" fi fi _err \"Add txt record error.\" return 1 } #Usage: rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_mythic_beasts_rm() { fulldomain=$1 txtvalue=$2 _info \"MYTHIC BEASTS Removing record $fulldomain = $txtvalue\" if ! _initAuth; then return 1 fi if ! _get_root \"$fulldomain\"; then return 1 fi # method path body_data if _mb_rest DELETE \"$_domain/records/$_sub_domain/TXT\" \"$txtvalue\"; then _info \"Record removed\" return 0 fi _err \"Remove txt record error.\" return 1 } #################### Private functions below ################################## #Possible formats: # _acme-challenge.www.example.com # _acme-challenge.example.com # _acme-challenge.example.co.uk # _acme-challenge.www.example.co.uk # _acme-challenge.sub1.sub2.www.example.co.uk # sub1.sub2.example.co.uk # example.com # example.co.uk #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=1 p=1 _debug \"Detect the root zone\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then _err \"Domain exhausted\" return 1 fi # Use the status errors to find the domain, continue on 403 Access denied # method path body_data _mb_rest GET \"$h/records\" ret=\"$?\" if [ \"$ret\" -eq 0 ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" return 0 elif [ \"$ret\" -eq 1 ]; then return 1 fi p=$i i=$(_math \"$i\" + 1) if [ \"$i\" -gt 50 ]; then break fi done _err \"Domain too long\" return 1 } _initAuth() { MB_AK=\"${MB_AK:-$(_readaccountconf_mutable MB_AK)}\" MB_AS=\"${MB_AS:-$(_readaccountconf_mutable MB_AS)}\" if [ -z \"$MB_AK\" ] || [ -z \"$MB_AS\" ]; then MB_AK=\"\" MB_AS=\"\" _err \"Please specify an OAuth2 Key & Secret\" return 1 fi _saveaccountconf_mutable MB_AK \"$MB_AK\" _saveaccountconf_mutable MB_AS \"$MB_AS\" if ! _oauth2; then return 1 fi _info \"Checking authentication\" _secure_debug access_token \"$MB_TK\" _sleep 1 # GET a list of zones # method path body_data if ! _mb_rest GET \"\"; then _err \"The token is invalid\" return 1 fi _info \"Token OK\" return 0 } # Github appears to use an outbound proxy for requests which means subsequent requests may not have the same # source IP. The standard Mythic Beasts OAuth2 tokens are tied to an IP, meaning github test requests fail # authentication. This is a work around using an undocumented MB API to obtain a token not tied to an # IP just for the github tests. _oauth2() { if [ \"$GITHUB_ACTIONS\" = \"true\" ]; then _oauth2_github else _oauth2_std fi return $? } _oauth2_std() { # HTTP Basic Authentication _H1=\"Authorization: Basic $(echo \"$MB_AK:$MB_AS\" | _base64)\" _H2=\"Accepts: application/json\" export _H1 _H2 body=\"grant_type=client_credentials\" _info \"Getting OAuth2 token...\" # body url [needbase64] [POST|PUT|DELETE] [ContentType] response=\"$(_post \"$body\" \"$MB_AUTH\" \"\" \"POST\" \"application/x-www-form-urlencoded\")\" if _contains \"$response\" \"\\\"token_type\\\":\\\"bearer\\\"\"; then MB_TK=\"$(echo \"$response\" | _egrep_o \"access_token\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d '\"')\" if [ -z \"$MB_TK\" ]; then _err \"Unable to get access_token\" _err \"\\n$response\" return 1 fi else _err \"OAuth2 token_type not Bearer\" _err \"\\n$response\" return 1 fi _debug2 response \"$response\" return 0 } _oauth2_github() { _H1=\"Accepts: application/json\" export _H1 body=\"{\\\"login\\\":{\\\"handle\\\":\\\"$MB_AK\\\",\\\"pass\\\":\\\"$MB_AS\\\",\\\"floating\\\":1}}\" _info \"Getting Floating token...\" # body url [needbase64] [POST|PUT|DELETE] [ContentType] response=\"$(_post \"$body\" \"$MB_AUTH\" \"\" \"POST\" \"application/json\")\" MB_TK=\"$(echo \"$response\" | _egrep_o \"\\\"token\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d '\"')\" if [ -z \"$MB_TK\" ]; then _err \"Unable to get token\" _err \"\\n$response\" return 1 fi _debug2 response \"$response\" return 0 } # method path body_data _mb_rest() { # URL encoded body for single API operations m=\"$1\" ep=\"$2\" data=\"$3\" if [ -z \"$ep\" ]; then _mb_url=\"$MB_API\" else _mb_url=\"$MB_API/$ep\" fi _H1=\"Authorization: Bearer $MB_TK\" _H2=\"Accepts: application/json\" export _H1 _H2 if [ \"$data\" ] || [ \"$m\" = \"POST\" ] || [ \"$m\" = \"PUT\" ] || [ \"$m\" = \"DELETE\" ]; then # body url [needbase64] [POST|PUT|DELETE] [ContentType] response=\"$(_post \"data=$data\" \"$_mb_url\" \"\" \"$m\" \"application/x-www-form-urlencoded\")\" else response=\"$(_get \"$_mb_url\")\" fi if [ \"$?\" != \"0\" ]; then _err \"Request error\" return 1 fi header=\"$(cat \"$HTTP_HEADER\")\" status=\"$(echo \"$header\" | _egrep_o \"^HTTP[^ ]* .*$\" | cut -d \" \" -f 2-100 | tr -d \"\\f\\n\")\" code=\"$(echo \"$status\" | _egrep_o \"^[0-9]*\")\" if [ \"$code\" -ge 400 ] || _contains \"$response\" \"\\\"error\\\"\" || _contains \"$response\" \"invalid_client\"; then _err \"error $status\" _err \"\\n$response\" _debug \"\\n$header\" return 2 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_245.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_245.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_namecheap_info='NameCheap.com Site: NameCheap.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_namecheap Options: NAMECHEAP_API_KEY API Key NAMECHEAP_USERNAME Username NAMECHEAP_SOURCEIP Source IP Issues: github.com/acmesh-official/acme.sh/issues/2107 ' # Namecheap API # https://www.namecheap.com/support/api/intro.aspx # Due to Namecheap's API limitation all the records of your domain will be read and re applied, make sure to have a backup of your records you could apply if any issue would arise. ######## Public functions ##################### NAMECHEAP_API=\"https://api.namecheap.com/xml.response\" #Usage: dns_namecheap_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_namecheap_add() { fulldomain=$1 txtvalue=$2 if ! _namecheap_check_config; then _err \"$error\" return 1 fi if ! _namecheap_set_publicip; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug domain \"$_domain\" _debug sub_domain \"$_sub_domain\" _set_namecheap_TXT \"$_domain\" \"$_sub_domain\" \"$txtvalue\" } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_namecheap_rm() { fulldomain=$1 txtvalue=$2 if ! _namecheap_set_publicip; then return 1 fi if ! _namecheap_check_config; then _err \"$error\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug domain \"$_domain\" _debug sub_domain \"$_sub_domain\" _del_namecheap_TXT \"$_domain\" \"$_sub_domain\" \"$txtvalue\" } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { fulldomain=$1 if ! _get_root_by_getList \"$fulldomain\"; then _debug \"Failed domain lookup via domains.getList api call. Trying domain lookup via domains.dns.getHosts api.\" # The above \"getList\" api will only return hosts *owned* by the calling user. However, if the calling # user is not the owner, but still has administrative rights, we must query the getHosts api directly. # See this comment and the official namecheap response: https://disq.us/p/1q6v9x9 if ! _get_root_by_getHosts \"$fulldomain\"; then return 1 fi fi return 0 } _get_root_by_getList() { domain=$1 if ! _namecheap_post \"namecheap.domains.getList\"; then _err \"$error\" return 1 fi i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _contains \"$h\" \"\\\\.\"; then #not valid return 1 fi if ! _contains \"$response\" \"$h\"; then _debug \"$h not found\" else _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } _get_root_by_getHosts() { i=100 p=99 while [ $p -ne 0 ]; do h=$(printf \"%s\" \"$1\" | cut -d . -f $i-100) if [ -n \"$h\" ]; then if _contains \"$h\" \"\\\\.\"; then _debug h \"$h\" if _namecheap_set_tld_sld \"$h\"; then _sub_domain=$(printf \"%s\" \"$1\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 else _debug \"$h not found\" fi fi fi i=\"$p\" p=$(_math \"$p\" - 1) done return 1 } _namecheap_set_publicip() { if [ -z \"$NAMECHEAP_SOURCEIP\" ]; then _err \"No Source IP specified for Namecheap API.\" _err \"Use your public ip address or an url to retrieve it (e.g. https://ifconfig.co/ip) and export it as NAMECHEAP_SOURCEIP\" return 1 else _saveaccountconf NAMECHEAP_SOURCEIP \"$NAMECHEAP_SOURCEIP\" _debug sourceip \"$NAMECHEAP_SOURCEIP\" ip=$(echo \"$NAMECHEAP_SOURCEIP\" | _egrep_o '[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}') addr=$(echo \"$NAMECHEAP_SOURCEIP\" | _egrep_o '(http|https):\\/\\/.*') _debug2 ip \"$ip\" _debug2 addr \"$addr\" if [ -n \"$ip\" ]; then _publicip=\"$ip\" elif [ -n \"$addr\" ]; then _publicip=$(_get \"$addr\") else _err \"No Source IP specified for Namecheap API.\" _err \"Use your public ip address or an url to retrieve it (e.g. https://ifconfig.co/ip) and export it as NAMECHEAP_SOURCEIP\" return 1 fi fi _debug publicip \"$_publicip\" return 0 } _namecheap_post() { command=$1 data=\"ApiUser=${NAMECHEAP_USERNAME}&ApiKey=${NAMECHEAP_API_KEY}&ClientIp=${_publicip}&UserName=${NAMECHEAP_USERNAME}&Command=${command}\" _debug2 \"_namecheap_post data\" \"$data\" response=\"$(_post \"$data\" \"$NAMECHEAP_API\" \"\" \"POST\")\" _debug2 response \"$response\" if _contains \"$response\" \"Status=\\\"ERROR\\\"\" >/dev/null; then error=$(echo \"$response\" | _egrep_o \">.*<\\\\/Error>\" | cut -d '<' -f 1 | tr -d '>') _err \"error $error\" return 1 fi return 0 } _namecheap_parse_host() { _host=$1 _debug _host \"$_host\" _hostid=$(echo \"$_host\" | _egrep_o ' HostId=\"[^\"]*' | cut -d '\"' -f 2) _hostname=$(echo \"$_host\" | _egrep_o ' Name=\"[^\"]*' | cut -d '\"' -f 2) _hosttype=$(echo \"$_host\" | _egrep_o ' Type=\"[^\"]*' | cut -d '\"' -f 2) _hostaddress=$(echo \"$_host\" | _egrep_o ' Address=\"[^\"]*' | cut -d '\"' -f 2 | _xml_decode) _hostmxpref=$(echo \"$_host\" | _egrep_o ' MXPref=\"[^\"]*' | cut -d '\"' -f 2) _hostttl=$(echo \"$_host\" | _egrep_o ' TTL=\"[^\"]*' | cut -d '\"' -f 2) _debug hostid \"$_hostid\" _debug hostname \"$_hostname\" _debug hosttype \"$_hosttype\" _debug hostaddress \"$_hostaddress\" _debug hostmxpref \"$_hostmxpref\" _debug hostttl \"$_hostttl\" } _namecheap_check_config() { if [ -z \"$NAMECHEAP_API_KEY\" ]; then _err \"No API key specified for Namecheap API.\" _err \"Create your key and export it as NAMECHEAP_API_KEY\" return 1 fi if [ -z \"$NAMECHEAP_USERNAME\" ]; then _err \"No username key specified for Namecheap API.\" _err \"Create your key and export it as NAMECHEAP_USERNAME\" return 1 fi _saveaccountconf NAMECHEAP_API_KEY \"$NAMECHEAP_API_KEY\" _saveaccountconf NAMECHEAP_USERNAME \"$NAMECHEAP_USERNAME\" return 0 } _set_namecheap_TXT() { subdomain=$2 txt=$3 if ! _namecheap_set_tld_sld \"$1\"; then return 1 fi request=\"namecheap.domains.dns.getHosts&SLD=${_sld}&TLD=${_tld}\" if ! _namecheap_post \"$request\"; then _err \"$error\" return 1 fi hosts=$(echo \"$response\" | _egrep_o '<host[^>]*') _debug hosts \"$hosts\" if [ -z \"$hosts\" ]; then _err \"Hosts not found\" return 1 fi _namecheap_reset_hostList while read -r host; do if _contains \"$host\" \"<host\"; then _namecheap_parse_host \"$host\" _debug2 _hostname \"_hostname\" _debug2 _hosttype \"_hosttype\" _debug2 _hostaddress \"_hostaddress\" _debug2 _hostmxpref \"_hostmxpref\" _hostaddress=\"$(printf \"%s\" \"$_hostaddress\" | _url_encode)\" _debug2 \"encoded _hostaddress\" \"_hostaddress\" _namecheap_add_host \"$_hostname\" \"$_hosttype\" \"$_hostaddress\" \"$_hostmxpref\" \"$_hostttl\" fi done <<EOT echo \"$hosts\" EOT _namecheap_add_host \"$subdomain\" \"TXT\" \"$txt\" 10 120 _debug hostrequestfinal \"$_hostrequest\" request=\"namecheap.domains.dns.setHosts&SLD=${_sld}&TLD=${_tld}${_hostrequest}\" if ! _namecheap_post \"$request\"; then _err \"$error\" return 1 fi return 0 } _del_namecheap_TXT() { subdomain=$2 txt=$3 if ! _namecheap_set_tld_sld \"$1\"; then return 1 fi request=\"namecheap.domains.dns.getHosts&SLD=${_sld}&TLD=${_tld}\" if ! _namecheap_post \"$request\"; then _err \"$error\" return 1 fi hosts=$(echo \"$response\" | _egrep_o '<host[^>]*') _debug hosts \"$hosts\" if [ -z \"$hosts\" ]; then _err \"Hosts not found\" return 1 fi _namecheap_reset_hostList found=0 while read -r host; do if _contains \"$host\" \"<host\"; then _namecheap_parse_host \"$host\" if [ \"$_hosttype\" = \"TXT\" ] && [ \"$_hostname\" = \"$subdomain\" ] && [ \"$_hostaddress\" = \"$txt\" ]; then _debug \"TXT entry found\" found=1 else _hostaddress=\"$(printf \"%s\" \"$_hostaddress\" | _url_encode)\" _namecheap_add_host \"$_hostname\" \"$_hosttype\" \"$_hostaddress\" \"$_hostmxpref\" \"$_hostttl\" fi fi done <<EOT echo \"$hosts\" EOT if [ $found -eq 0 ]; then _debug \"TXT entry not found\" return 0 fi _debug hostrequestfinal \"$_hostrequest\" request=\"namecheap.domains.dns.setHosts&SLD=${_sld}&TLD=${_tld}${_hostrequest}\" if ! _namecheap_post \"$request\"; then _err \"$error\" return 1 fi return 0 } _namecheap_reset_hostList() { _hostindex=0 _hostrequest=\"\" } #Usage: _namecheap_add_host HostName RecordType Address MxPref TTL _namecheap_add_host() { _hostindex=$(_math \"$_hostindex\" + 1) _hostrequest=$(printf '%s&HostName%d=%s&RecordType%d=%s&Address%d=%s&MXPref%d=%d&TTL%d=%d' \"$_hostrequest\" \"$_hostindex\" \"$1\" \"$_hostindex\" \"$2\" \"$_hostindex\" \"$3\" \"$_hostindex\" \"$4\" \"$_hostindex\" \"$5\") } _namecheap_set_tld_sld() { domain=$1 _tld=\"\" _sld=\"\" i=2 while true; do _tld=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug tld \"$_tld\" if [ -z \"$_tld\" ]; then _debug \"invalid tld\" return 1 fi j=$(_math \"$i\" - 1) _sld=$(printf \"%s\" \"$domain\" | cut -d . -f 1-\"$j\") _debug sld \"$_sld\" if [ -z \"$_sld\" ]; then _debug \"invalid sld\" return 1 fi request=\"namecheap.domains.dns.getHosts&SLD=$_sld&TLD=$_tld\" if ! _namecheap_post \"$request\"; then _debug \"sld($_sld)/tld($_tld) not found\" else _debug \"sld($_sld)/tld($_tld) found\" return 0 fi i=$(_math \"$i\" + 1) done } _xml_decode() { sed 's/&quot;/\"/g' }"
        },
        {
            "filename": "file_246.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_246.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_namecom_info='Name.com Site: Name.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_namecom Options: Namecom_Username Username Namecom_Token API Token Author: RaidenII ' ######## Public functions ##################### Namecom_API=\"https://api.name.com/v4\" #Usage: dns_namecom_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_namecom_add() { fulldomain=$1 txtvalue=$2 Namecom_Username=\"${Namecom_Username:-$(_readaccountconf_mutable Namecom_Username)}\" Namecom_Token=\"${Namecom_Token:-$(_readaccountconf_mutable Namecom_Token)}\" # First we need name.com credentials. if [ -z \"$Namecom_Username\" ]; then Namecom_Username=\"\" _err \"Username for name.com is missing.\" _err \"Please specify that in your environment variable.\" return 1 fi if [ -z \"$Namecom_Token\" ]; then Namecom_Token=\"\" _err \"API token for name.com is missing.\" _err \"Please specify that in your environment variable.\" return 1 fi _debug Namecom_Username \"$Namecom_Username\" _secure_debug Namecom_Token \"$Namecom_Token\" # Save them in configuration. _saveaccountconf_mutable Namecom_Username \"$Namecom_Username\" _saveaccountconf_mutable Namecom_Token \"$Namecom_Token\" # Login in using API if ! _namecom_login; then return 1 fi # Find domain in domain list. if ! _namecom_get_root \"$fulldomain\"; then _err \"Unable to find domain specified.\" return 1 fi # Add TXT record. _namecom_addtxt_json=\"{\\\"host\\\":\\\"$_sub_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"answer\\\":\\\"$txtvalue\\\",\\\"ttl\\\":\\\"300\\\"}\" if _namecom_rest POST \"domains/$_domain/records\" \"$_namecom_addtxt_json\"; then _retvalue=$(echo \"$response\" | _egrep_o \"\\\"$_sub_domain\\\"\") if [ \"$_retvalue\" ]; then _info \"Successfully added TXT record, ready for validation.\" return 0 else _err \"Unable to add the DNS record.\" return 1 fi fi } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_namecom_rm() { fulldomain=$1 txtvalue=$2 Namecom_Username=\"${Namecom_Username:-$(_readaccountconf_mutable Namecom_Username)}\" Namecom_Token=\"${Namecom_Token:-$(_readaccountconf_mutable Namecom_Token)}\" if ! _namecom_login; then return 1 fi # Find domain in domain list. if ! _namecom_get_root \"$fulldomain\"; then _err \"Unable to find domain specified.\" return 1 fi # Get the record id. if _namecom_rest GET \"domains/$_domain/records\"; then _record_id=$(echo \"$response\" | _egrep_o \"\\\"id\\\":[0-9]+,\\\"domainName\\\":\\\"$_domain\\\",\\\"host\\\":\\\"$_sub_domain\\\",\\\"fqdn\\\":\\\"$fulldomain.\\\",\\\"type\\\":\\\"TXT\\\",\\\"answer\\\":\\\"$txtvalue\\\"\" | cut -d \\\" -f 3 | _egrep_o [0-9]+) _debug record_id \"$_record_id\" if [ \"$_record_id\" ]; then _info \"Successfully retrieved the record id for ACME challenge.\" else _err \"Unable to retrieve the record id.\" return 1 fi fi # Remove the DNS record using record id. if _namecom_rest DELETE \"domains/$_domain/records/$_record_id\"; then _info \"Successfully removed the TXT record.\" return 0 else _err \"Unable to delete record id.\" return 1 fi } #################### Private functions below ################################## _namecom_rest() { method=$1 param=$2 data=$3 export _H1=\"Authorization: Basic $_namecom_auth\" export _H2=\"Content-Type: application/json\" if [ \"$method\" != \"GET\" ]; then response=\"$(_post \"$data\" \"$Namecom_API/$param\" \"\" \"$method\")\" else response=\"$(_get \"$Namecom_API/$param\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $param\" return 1 fi _debug2 response \"$response\" return 0 } _namecom_login() { # Auth string # Name.com API v4 uses http basic auth to authenticate # need to convert the token for http auth _namecom_auth=$(printf \"%s:%s\" \"$Namecom_Username\" \"$Namecom_Token\" | _base64) if _namecom_rest GET \"hello\"; then retcode=$(echo \"$response\" | _egrep_o \"\\\"username\\\"\\:\\\"$Namecom_Username\\\"\") if [ \"$retcode\" ]; then _info \"Successfully logged in.\" else _err \"$response\" _err \"Please add your ip to api whitelist\" _err \"Logging in failed.\" return 1 fi fi } _namecom_get_root() { domain=$1 i=2 p=1 if ! _namecom_rest GET \"domains\"; then return 1 fi # Need to exclude the last field (tld) numfields=$(echo \"$domain\" | _egrep_o \"\\.\" | wc -l) while [ $i -le \"$numfields\" ]; do host=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug host \"$host\" if [ -z \"$host\" ]; then return 1 fi if _contains \"$response\" \"$host\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$host\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 }"
        },
        {
            "filename": "file_247.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_247.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_namesilo_info='NameSilo.com Site: NameSilo.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_namesilo Options: Namesilo_Key API Key Author: meowthink ' #Utilize API to finish dns-01 verifications. Namesilo_API=\"https://www.namesilo.com/api\" ######## Public functions ##################### #Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_namesilo_add() { fulldomain=$1 txtvalue=$2 if [ -z \"$Namesilo_Key\" ]; then Namesilo_Key=\"\" _err \"API token for namesilo.com is missing.\" _err \"Please specify that in your environment variable.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf Namesilo_Key \"$Namesilo_Key\" if ! _get_root \"$fulldomain\"; then _err \"Unable to find domain specified.\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug txtvalue \"$txtvalue\" if _namesilo_rest GET \"dnsAddRecord?version=1&type=xml&key=$Namesilo_Key&domain=$_domain&rrtype=TXT&rrhost=$_sub_domain&rrvalue=$txtvalue\"; then retcode=$(printf \"%s\\n\" \"$response\" | _egrep_o \"<code>300\") if [ \"$retcode\" ]; then _info \"Successfully added TXT record, ready for validation.\" return 0 else _err \"Unable to add the DNS record.\" return 1 fi fi } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_namesilo_rm() { fulldomain=$1 txtvalue=$2 if ! _get_root \"$fulldomain\"; then _err \"Unable to find domain specified.\" return 1 fi # Get the record id. if _namesilo_rest GET \"dnsListRecords?version=1&type=xml&key=$Namesilo_Key&domain=$_domain\"; then retcode=$(printf \"%s\\n\" \"$response\" | _egrep_o \"<code>300\") if [ \"$retcode\" ]; then _record_id=$(echo \"$response\" | _egrep_o \"<record_id>([^<]*)</record_id><type>TXT</type><host>$fulldomain</host>\" | _egrep_o \"<record_id>([^<]*)</record_id>\" | sed -r \"s/<record_id>([^<]*)<\\/record_id>/\\1/\" | tail -n 1) _debug _record_id \"$_record_id\" if [ \"$_record_id\" ]; then _info \"Successfully retrieved the record id for ACME challenge.\" else _info \"Empty record id, it seems no such record.\" return 0 fi else _err \"Unable to retrieve the record id.\" return 1 fi fi # Remove the DNS record using record id. if _namesilo_rest GET \"dnsDeleteRecord?version=1&type=xml&key=$Namesilo_Key&domain=$_domain&rrid=$_record_id\"; then retcode=$(printf \"%s\\n\" \"$response\" | _egrep_o \"<code>300\") if [ \"$retcode\" ]; then _info \"Successfully removed the TXT record.\" return 0 else _err \"Unable to remove the DNS record.\" return 1 fi fi } #################### Private functions below ################################## # _acme-challenge.www.domain.com # returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=2 p=1 if ! _namesilo_rest GET \"listDomains?version=1&type=xml&key=$Namesilo_Key\"; then return 1 fi # Need to exclude the last field (tld) numfields=$(echo \"$domain\" | _egrep_o \"\\.\" | wc -l) while [ $i -le \"$numfields\" ]; do host=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug host \"$host\" if [ -z \"$host\" ]; then return 1 fi if _contains \"$response\" \">$host</domain>\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$host\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _namesilo_rest() { method=$1 param=$2 data=$3 if [ \"$method\" != \"GET\" ]; then response=\"$(_post \"$data\" \"$Namesilo_API/$param\" \"\" \"$method\")\" else response=\"$(_get \"$Namesilo_API/$param\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $param\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_248.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_248.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_nanelo_info='Nanelo.com Site: Nanelo.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_nanelo Options: NANELO_TOKEN API Token Issues: github.com/acmesh-official/acme.sh/issues/4519 ' NANELO_API=\"https://api.nanelo.com/v1/\" ######## Public functions ##################### # Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_nanelo_add() { fulldomain=$1 txtvalue=$2 NANELO_TOKEN=\"${NANELO_TOKEN:-$(_readaccountconf_mutable NANELO_TOKEN)}\" if [ -z \"$NANELO_TOKEN\" ]; then NANELO_TOKEN=\"\" _err \"You didn't configure a Nanelo API Key yet.\" _err \"Please set NANELO_TOKEN and try again.\" _err \"Login to Nanelo.com and go to Settings > API Keys to get a Key\" return 1 fi _saveaccountconf_mutable NANELO_TOKEN \"$NANELO_TOKEN\" _info \"Adding TXT record to ${fulldomain}\" response=\"$(_get \"$NANELO_API$NANELO_TOKEN/dns/addrecord?type=TXT&ttl=60&name=${fulldomain}&value=${txtvalue}\")\" if _contains \"${response}\" 'success'; then return 0 fi _err \"Could not create resource record, please check the logs\" _err \"${response}\" return 1 } dns_nanelo_rm() { fulldomain=$1 txtvalue=$2 NANELO_TOKEN=\"${NANELO_TOKEN:-$(_readaccountconf_mutable NANELO_TOKEN)}\" if [ -z \"$NANELO_TOKEN\" ]; then NANELO_TOKEN=\"\" _err \"You didn't configure a Nanelo API Key yet.\" _err \"Please set NANELO_TOKEN and try again.\" _err \"Login to Nanelo.com and go to Settings > API Keys to get a Key\" return 1 fi _saveaccountconf_mutable NANELO_TOKEN \"$NANELO_TOKEN\" _info \"Deleting resource record $fulldomain\" response=\"$(_get \"$NANELO_API$NANELO_TOKEN/dns/deleterecord?type=TXT&ttl=60&name=${fulldomain}&value=${txtvalue}\")\" if _contains \"${response}\" 'success'; then return 0 fi _err \"Could not delete resource record, please check the logs\" _err \"${response}\" return 1 }"
        },
        {
            "filename": "file_249.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_249.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_nederhost_info='NederHost.nl Site: NederHost.nl Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_nederhost Options: NederHost_Key API Key Issues: github.com/acmesh-official/acme.sh/issues/2089 ' NederHost_Api=\"https://api.nederhost.nl/dns/v1\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_nederhost_add() { fulldomain=$1 txtvalue=$2 NederHost_Key=\"${NederHost_Key:-$(_readaccountconf_mutable NederHost_Key)}\" if [ -z \"$NederHost_Key\" ]; then NederHost_Key=\"\" _err \"You didn't specify a NederHost api key.\" _err \"You can get yours from https://www.nederhost.nl/mijn_nederhost\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable NederHost_Key \"$NederHost_Key\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if _nederhost_rest PATCH \"zones/$_domain/records/$fulldomain/TXT\" \"[{\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":60}]\"; then if _contains \"$response\" \"$fulldomain\"; then _info \"Added, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_nederhost_rm() { fulldomain=$1 txtvalue=$2 NederHost_Key=\"${NederHost_Key:-$(_readaccountconf_mutable NederHost_Key)}\" if [ -z \"$NederHost_Key\" ]; then NederHost_Key=\"\" _err \"You didn't specify a NederHost api key.\" _err \"You can get yours from https://www.nederhost.nl/mijn_nederhost\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Removing txt record\" _nederhost_rest DELETE \"zones/${_domain}/records/$fulldomain/TXT?content=$txtvalue\" } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=2 p=1 while true; do _domain=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _debug _domain \"$_domain\" if [ -z \"$_domain\" ]; then #not valid return 1 fi if _nederhost_rest GET \"zones/${_domain}\"; then if [ \"${_code}\" = \"204\" ]; then return 0 fi else return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _nederhost_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Authorization: Bearer $NederHost_Key\" export _H2=\"Content-Type: application/json\" _debug data \"$data\" response=\"$(_post \"$data\" \"$NederHost_Api/$ep\" \"\" \"$m\")\" _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" _debug \"http response code $_code\" if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_250.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_250.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_neodigit_info='Neodigit.net Site: Neodigit.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_neodigit Options: NEODIGIT_API_TOKEN API Token Author: Adrian Almenar ' NEODIGIT_API_URL=\"https://api.neodigit.net/v1\" # ######## Public functions ##################### # Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_neodigit_add() { fulldomain=$1 txtvalue=$2 NEODIGIT_API_TOKEN=\"${NEODIGIT_API_TOKEN:-$(_readaccountconf_mutable NEODIGIT_API_TOKEN)}\" if [ -z \"$NEODIGIT_API_TOKEN\" ]; then NEODIGIT_API_TOKEN=\"\" _err \"You haven't specified a Token api key.\" _err \"Please create the key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable NEODIGIT_API_TOKEN \"$NEODIGIT_API_TOKEN\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug domain \"$_domain\" _debug sub_domain \"$_sub_domain\" _debug \"Getting txt records\" _neo_rest GET \"dns/zones/${_domain_id}/records?type=TXT&name=$fulldomain\" _debug _code \"$_code\" if [ \"$_code\" != \"200\" ]; then _err \"error retrieving data!\" return 1 fi _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _debug domain \"$_domain\" _debug sub_domain \"$_sub_domain\" _info \"Adding record\" if _neo_rest POST \"dns/zones/$_domain_id/records\" \"{\\\"record\\\":{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":60}}\"; then if printf -- \"%s\" \"$response\" | grep \"$_sub_domain\" >/dev/null; then _info \"Added, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_neodigit_rm() { fulldomain=$1 txtvalue=$2 NEODIGIT_API_TOKEN=\"${NEODIGIT_API_TOKEN:-$(_readaccountconf_mutable NEODIGIT_API_TOKEN)}\" if [ -z \"$NEODIGIT_API_TOKEN\" ]; then NEODIGIT_API_TOKEN=\"\" _err \"You haven't specified a Token api key.\" _err \"Please create the key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable NEODIGIT_API_TOKEN \"$NEODIGIT_API_TOKEN\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _neo_rest GET \"dns/zones/${_domain_id}/records?type=TXT&name=$fulldomain&content=$txtvalue\" if [ \"$_code\" != \"200\" ]; then _err \"error retrieving data!\" return 1 fi record_id=$(echo \"$response\" | _egrep_o \"\\\"id\\\":\\s*[0-9]+\" | _head_n 1 | cut -d: -f2 | cut -d, -f1) _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _neo_rest DELETE \"dns/zones/$_domain_id/records/$record_id\"; then _err \"Delete record error.\" return 1 fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=dasfdsafsadg5ythd _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _neo_rest GET \"dns/zones?name=$h\"; then return 1 fi _debug p \"$p\" if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" >/dev/null; then _domain_id=$(echo \"$response\" | _egrep_o \"\\\"id\\\":\\s*[0-9]+\" | _head_n 1 | cut -d: -f2 | cut -d, -f1) if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _neo_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"X-TCPanel-Token: $NEODIGIT_API_TOKEN\" export _H2=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$NEODIGIT_API_URL/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$NEODIGIT_API_URL/$ep\")\" fi _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_251.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_251.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_netcup_info='netcup.eu Domains: netcup.de netcup.net Site: netcup.eu/ Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_netcup Options: NC_Apikey API Key NC_Apipw API Password NC_CID Customer Number Author: linux-insideDE ' NC_Apikey=\"${NC_Apikey:-$(_readaccountconf_mutable NC_Apikey)}\" NC_Apipw=\"${NC_Apipw:-$(_readaccountconf_mutable NC_Apipw)}\" NC_CID=\"${NC_CID:-$(_readaccountconf_mutable NC_CID)}\" end=\"https://ccp.netcup.net/run/webservice/servers/endpoint.php?JSON\" client=\"\" dns_netcup_add() { _debug NC_Apikey \"$NC_Apikey\" login if [ \"$NC_Apikey\" = \"\" ] || [ \"$NC_Apipw\" = \"\" ] || [ \"$NC_CID\" = \"\" ]; then _err \"No Credentials given\" return 1 fi _saveaccountconf_mutable NC_Apikey \"$NC_Apikey\" _saveaccountconf_mutable NC_Apipw \"$NC_Apipw\" _saveaccountconf_mutable NC_CID \"$NC_CID\" fulldomain=$1 txtvalue=$2 domain=\"\" exit=$(echo \"$fulldomain\" | tr -dc '.' | wc -c) exit=$(_math \"$exit\" + 1) i=$exit while [ \"$exit\" -gt 0 ] do tmp=$(echo \"$fulldomain\" | cut -d'.' -f\"$exit\") if [ \"$(_math \"$i\" - \"$exit\")\" -eq 0 ]; then domain=\"$tmp\" else domain=\"$tmp.$domain\" fi if [ \"$(_math \"$i\" - \"$exit\")\" -ge 1 ]; then msg=$(_post \"{\\\"action\\\": \\\"updateDnsRecords\\\", \\\"param\\\": {\\\"apikey\\\": \\\"$NC_Apikey\\\", \\\"apisessionid\\\": \\\"$sid\\\", \\\"customernumber\\\": \\\"$NC_CID\\\",\\\"clientrequestid\\\": \\\"$client\\\" , \\\"domainname\\\": \\\"$domain\\\", \\\"dnsrecordset\\\": { \\\"dnsrecords\\\": [ {\\\"id\\\": \\\"\\\", \\\"hostname\\\": \\\"$fulldomain.\\\", \\\"type\\\": \\\"TXT\\\", \\\"priority\\\": \\\"\\\", \\\"destination\\\": \\\"$txtvalue\\\", \\\"deleterecord\\\": \\\"false\\\", \\\"state\\\": \\\"yes\\\"} ]}}}\" \"$end\" \"\" \"POST\") _debug \"$msg\" if [ \"$(_getfield \"$msg\" \"5\" | sed 's/\"statuscode\"://g')\" != 5028 ]; then if [ \"$(_getfield \"$msg\" \"4\" | sed s/\\\"status\\\":\\\"//g | sed s/\\\"//g)\" != \"success\" ]; then _err \"$msg\" return 1 else break fi fi fi exit=$(_math \"$exit\" - 1) done logout } dns_netcup_rm() { login fulldomain=$1 txtvalue=$2 domain=\"\" exit=$(echo \"$fulldomain\" | tr -dc '.' | wc -c) exit=$(_math \"$exit\" + 1) i=$exit rec=\"\" while [ \"$exit\" -gt 0 ] do tmp=$(echo \"$fulldomain\" | cut -d'.' -f\"$exit\") if [ \"$(_math \"$i\" - \"$exit\")\" -eq 0 ]; then domain=\"$tmp\" else domain=\"$tmp.$domain\" fi if [ \"$(_math \"$i\" - \"$exit\")\" -ge 1 ]; then msg=$(_post \"{\\\"action\\\": \\\"infoDnsRecords\\\", \\\"param\\\": {\\\"apikey\\\": \\\"$NC_Apikey\\\", \\\"apisessionid\\\": \\\"$sid\\\", \\\"customernumber\\\": \\\"$NC_CID\\\", \\\"domainname\\\": \\\"$domain\\\"}}\" \"$end\" \"\" \"POST\") rec=$(echo \"$msg\" | sed 's/\\[//g' | sed 's/\\]//g' | sed 's/{\\\"serverrequestid\\\".*\\\"dnsrecords\\\"://g' | sed 's/},{/};{/g' | sed 's/{//g' | sed 's/}//g') _debug \"$msg\" if [ \"$(_getfield \"$msg\" \"5\" | sed 's/\"statuscode\"://g')\" != 5028 ]; then if [ \"$(_getfield \"$msg\" \"4\" | sed s/\\\"status\\\":\\\"//g | sed s/\\\"//g)\" != \"success\" ]; then _err \"$msg\" return 1 else break fi fi fi exit=$(_math \"$exit\" - 1) done ida=0000 idv=0001 ids=0000000000 i=1 while [ \"$i\" -ne 0 ] do specrec=$(_getfield \"$rec\" \"$i\" \";\") idv=\"$ida\" ida=$(_getfield \"$specrec\" \"1\" \",\" | sed 's/\\\"id\\\":\\\"//g' | sed 's/\\\"//g') txtv=$(_getfield \"$specrec\" \"5\" \",\" | sed 's/\\\"destination\\\":\\\"//g' | sed 's/\\\"//g') i=$(_math \"$i\" + 1) if [ \"$txtvalue\" = \"$txtv\" ]; then i=0 ids=\"$ida\" fi if [ \"$ida\" = \"$idv\" ]; then i=0 fi done msg=$(_post \"{\\\"action\\\": \\\"updateDnsRecords\\\", \\\"param\\\": {\\\"apikey\\\": \\\"$NC_Apikey\\\", \\\"apisessionid\\\": \\\"$sid\\\", \\\"customernumber\\\": \\\"$NC_CID\\\",\\\"clientrequestid\\\": \\\"$client\\\" , \\\"domainname\\\": \\\"$domain\\\", \\\"dnsrecordset\\\": { \\\"dnsrecords\\\": [ {\\\"id\\\": \\\"$ids\\\", \\\"hostname\\\": \\\"$fulldomain.\\\", \\\"type\\\": \\\"TXT\\\", \\\"priority\\\": \\\"\\\", \\\"destination\\\": \\\"$txtvalue\\\", \\\"deleterecord\\\": \\\"TRUE\\\", \\\"state\\\": \\\"yes\\\"} ]}}}\" \"$end\" \"\" \"POST\") _debug \"$msg\" if [ \"$(_getfield \"$msg\" \"4\" | sed s/\\\"status\\\":\\\"//g | sed s/\\\"//g)\" != \"success\" ]; then _err \"$msg\" return 1 fi logout } login() { tmp=$(_post \"{\\\"action\\\": \\\"login\\\", \\\"param\\\": {\\\"apikey\\\": \\\"$NC_Apikey\\\", \\\"apipassword\\\": \\\"$NC_Apipw\\\", \\\"customernumber\\\": \\\"$NC_CID\\\"}}\" \"$end\" \"\" \"POST\") sid=$(echo \"$tmp\" | tr '{}' '\\n' | grep apisessionid | cut -d '\"' -f 4) _debug \"$tmp\" if [ \"$(_getfield \"$tmp\" \"4\" | sed s/\\\"status\\\":\\\"//g | sed s/\\\"//g)\" != \"success\" ]; then _err \"$tmp\" return 1 fi } logout() { tmp=$(_post \"{\\\"action\\\": \\\"logout\\\", \\\"param\\\": {\\\"apikey\\\": \\\"$NC_Apikey\\\", \\\"apisessionid\\\": \\\"$sid\\\", \\\"customernumber\\\": \\\"$NC_CID\\\"}}\" \"$end\" \"\" \"POST\") _debug \"$tmp\" if [ \"$(_getfield \"$tmp\" \"4\" | sed s/\\\"status\\\":\\\"//g | sed s/\\\"//g)\" != \"success\" ]; then _err \"$tmp\" return 1 fi }"
        },
        {
            "filename": "file_252.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_252.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_netlify_info='Netlify.com Site: Netlify.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_netlify Options: NETLIFY_ACCESS_TOKEN API Token Issues: github.com/acmesh-official/acme.sh/issues/3088 ' NETLIFY_HOST=\"api.netlify.com/api/v1/\" NETLIFY_URL=\"https://$NETLIFY_HOST\" ######## Public functions ##################### #Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_netlify_add() { fulldomain=$1 txtvalue=$2 NETLIFY_ACCESS_TOKEN=\"${NETLIFY_ACCESS_TOKEN:-$(_readaccountconf_mutable NETLIFY_ACCESS_TOKEN)}\" if [ -z \"$NETLIFY_ACCESS_TOKEN\" ]; then NETLIFY_ACCESS_TOKEN=\"\" _err \"Please specify your Netlify Access Token and try again.\" return 1 else _saveaccountconf_mutable NETLIFY_ACCESS_TOKEN \"$NETLIFY_ACCESS_TOKEN\" fi _info \"Using Netlify\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" dnsRecordURI=\"dns_zones/$_domain_id/dns_records\" body=\"{\\\"type\\\":\\\"TXT\\\", \\\"hostname\\\":\\\"$_sub_domain\\\", \\\"value\\\":\\\"$txtvalue\\\", \\\"ttl\\\":\\\"10\\\"}\" _netlify_rest POST \"$dnsRecordURI\" \"$body\" \"$NETLIFY_ACCESS_TOKEN\" _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" if [ \"$_code\" = \"200\" ] || [ \"$_code\" = '201' ]; then _info \"validation value added\" return 0 else _err \"error adding validation value ($_code)\" return 1 fi _err \"Not fully implemented!\" return 1 } #Usage: dns_myapi_rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" #Remove the txt record after validation. dns_netlify_rm() { _info \"Using Netlify\" txtdomain=\"$1\" txt=\"$2\" _debug txtdomain \"$txtdomain\" _debug txt \"$txt\" NETLIFY_ACCESS_TOKEN=\"${NETLIFY_ACCESS_TOKEN:-$(_readaccountconf_mutable NETLIFY_ACCESS_TOKEN)}\" if ! _get_root \"$txtdomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" dnsRecordURI=\"dns_zones/$_domain_id/dns_records\" _netlify_rest GET \"$dnsRecordURI\" \"\" \"$NETLIFY_ACCESS_TOKEN\" _record_id=$(echo \"$response\" | _egrep_o \"\\\"type\\\":\\\"TXT\\\",[^\\}]*\\\"value\\\":\\\"$txt\\\"\" | head -n 1 | _egrep_o \"\\\"id\\\":\\\"[^\\\"\\}]*\\\"\" | cut -d : -f 2 | tr -d \\\") _debug _record_id \"$_record_id\" if [ \"$_record_id\" ]; then _netlify_rest DELETE \"$dnsRecordURI/$_record_id\" \"\" \"$NETLIFY_ACCESS_TOKEN\" _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" if [ \"$_code\" = \"200\" ] || [ \"$_code\" = '204' ]; then _info \"validation value removed\" return 0 else _err \"error removing validation value ($_code)\" return 1 fi return 0 fi return 1 } #################### Private functions below ################################## _get_root() { domain=$1 accesstoken=$2 i=1 p=1 _netlify_rest GET \"dns_zones\" \"\" \"$accesstoken\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug2 \"Checking domain: $h\" if [ -z \"$h\" ]; then #not valid _err \"Invalid domain\" return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" >/dev/null; then _domain_id=$(echo \"$response\" | _egrep_o \"\\\"[^\\\"]*\\\",\\\"name\\\":\\\"$h\\\"\" | cut -d , -f 1 | tr -d \\\") if [ \"$_domain_id\" ]; then if [ \"$i\" = 1 ]; then #create the record at the domain apex (@) if only the domain name was provided as --domain-alias _sub_domain=\"@\" else _sub_domain=$(echo \"$domain\" | cut -d . -f 1-$p) fi _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _netlify_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" token_trimmed=$(echo \"$NETLIFY_ACCESS_TOKEN\" | tr -d '\"') export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: Bearer $token_trimmed\" : >\"$HTTP_HEADER\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$NETLIFY_URL$ep\" \"\" \"$m\")\" else response=\"$(_get \"$NETLIFY_URL$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_253.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_253.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_nic_info='nic.ru Site: nic.ru Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_nic Options: NIC_ClientID Client ID NIC_ClientSecret Client Secret NIC_Username Username NIC_Password Password Issues: github.com/acmesh-official/acme.sh/issues/2547 ' NIC_Api=\"https://api.nic.ru\" dns_nic_add() { fulldomain=\"${1}\" txtvalue=\"${2}\" if ! _nic_get_authtoken save; then _err \"get NIC auth token failed\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug _service \"$_service\" _info \"Adding record\" if ! _nic_rest PUT \"services/$_service/zones/$_domain/records\" \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\" ?><request><rr-list><rr><name>$_sub_domain</name><type>TXT</type><txt><string>$txtvalue</string></txt></rr></rr-list></request>\"; then _err \"Add TXT record error\" return 1 fi if ! _nic_rest POST \"services/$_service/zones/$_domain/commit\" \"\"; then return 1 fi _info \"Added, OK\" } dns_nic_rm() { fulldomain=\"${1}\" txtvalue=\"${2}\" if ! _nic_get_authtoken; then _err \"get NIC auth token failed\" return 1 fi if ! _get_root \"$fulldomain\"; then _err \"Invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug _service \"$_service\" if ! _nic_rest GET \"services/$_service/zones/$_domain/records\"; then _err \"Get records error\" return 1 fi _domain_id=$(printf \"%s\" \"$response\" | grep \"$_sub_domain\" | grep -- \"$txtvalue\" | sed -r \"s/.*<rr id=\\\"(.*)\\\".*/\\1/g\") if ! _nic_rest DELETE \"services/$_service/zones/$_domain/records/$_domain_id\"; then _err \"Delete record error\" return 1 fi if ! _nic_rest POST \"services/$_service/zones/$_domain/commit\" \"\"; then return 1 fi } #################### Private functions below ################################## #_nic_get_auth_elements [need2save] _nic_get_auth_elements() { _need2save=$1 NIC_ClientID=\"${NIC_ClientID:-$(_readaccountconf_mutable NIC_ClientID)}\" NIC_ClientSecret=\"${NIC_ClientSecret:-$(_readaccountconf_mutable NIC_ClientSecret)}\" NIC_Username=\"${NIC_Username:-$(_readaccountconf_mutable NIC_Username)}\" NIC_Password=\"${NIC_Password:-$(_readaccountconf_mutable NIC_Password)}\" ## for backward compatibility if [ -z \"$NIC_ClientID\" ] || [ -z \"$NIC_ClientSecret\" ]; then NIC_Token=\"${NIC_Token:-$(_readaccountconf_mutable NIC_Token)}\" _debug NIC_Token \"$NIC_Token\" if [ -n \"$NIC_Token\" ]; then _two_values=\"$(echo \"${NIC_Token}\" | _dbase64)\" _debug _two_values \"$_two_values\" NIC_ClientID=$(echo \"$_two_values\" | cut -d':' -f1) NIC_ClientSecret=$(echo \"$_two_values\" | cut -d':' -f2-) _debug restored_NIC_ClientID \"$NIC_ClientID\" _debug restored_NIC_ClientSecret \"$NIC_ClientSecret\" fi fi if [ -z \"$NIC_ClientID\" ] || [ -z \"$NIC_ClientSecret\" ] || [ -z \"$NIC_Username\" ] || [ -z \"$NIC_Password\" ]; then NIC_ClientID=\"\" NIC_ClientSecret=\"\" NIC_Username=\"\" NIC_Password=\"\" _err \"You must export variables: NIC_ClientID, NIC_ClientSecret, NIC_Username and NIC_Password\" return 1 fi if [ \"$_need2save\" ]; then _saveaccountconf_mutable NIC_ClientID \"$NIC_ClientID\" _saveaccountconf_mutable NIC_ClientSecret \"$NIC_ClientSecret\" _saveaccountconf_mutable NIC_Username \"$NIC_Username\" _saveaccountconf_mutable NIC_Password \"$NIC_Password\" fi NIC_BasicAuth=$(printf \"%s:%s\" \"${NIC_ClientID}\" \"${NIC_ClientSecret}\" | _base64) _debug NIC_BasicAuth \"$NIC_BasicAuth\" } #_nic_get_authtoken [need2save] _nic_get_authtoken() { _need2save=$1 if ! _nic_get_auth_elements \"$_need2save\"; then return 1 fi _info \"Getting NIC auth token\" export _H1=\"Authorization: Basic ${NIC_BasicAuth}\" export _H2=\"Content-Type: application/x-www-form-urlencoded\" res=$(_post \"grant_type=password&username=${NIC_Username}&password=${NIC_Password}&scope=%28GET%7CPUT%7CPOST%7CDELETE%29%3A%2Fdns-master%2F.%2B\" \"$NIC_Api/oauth/token\" \"\" \"POST\") if _contains \"$res\" \"access_token\"; then _auth_token=$(printf \"%s\" \"$res\" | cut -d , -f2 | tr -d \"\\\"\" | sed \"s/access_token://\") _info \"Token received\" _debug _auth_token \"$_auth_token\" return 0 fi return 1 } _get_root() { domain=\"$1\" i=1 p=1 if ! _nic_rest GET \"zones\"; then return 1 fi _all_domains=$(printf \"%s\" \"$response\" | grep \"idn-name\" | sed -r \"s/.*idn-name=\\\"(.*)\\\" name=.*/\\1/g\") _debug2 _all_domains \"$_all_domains\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f \"$i\"-100) _debug h \"$h\" if [ -z \"$h\" ]; then return 1 fi if _contains \"$_all_domains\" \"^$h$\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h _service=$(printf \"%s\" \"$response\" | grep -m 1 \"idn-name=\\\"$_domain\\\"\" | sed -r \"s/.*service=\\\"(.*)\\\".*$/\\1/\") return 0 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } _nic_rest() { m=\"$1\" ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Content-Type: application/xml\" export _H2=\"Authorization: Bearer $_auth_token\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=$(_post \"$data\" \"$NIC_Api/dns-master/$ep\" \"\" \"$m\") else response=$(_get \"$NIC_Api/dns-master/$ep\") fi if _contains \"$response\" \"<errors>\"; then error=$(printf \"%s\" \"$response\" | grep \"error code\" | sed -r \"s/.*<error code=.*>(.*)<\\/error>/\\1/g\") _err \"Error: $error\" return 1 fi if ! _contains \"$response\" \"<status>success</status>\"; then return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_254.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_254.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_njalla_info='Njalla Site: Njal.la Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_njalla Options: NJALLA_Token API Token Issues: github.com/acmesh-official/acme.sh/issues/2913 ' NJALLA_Api=\"https://njal.la/api/1/\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_njalla_add() { fulldomain=$1 txtvalue=$2 NJALLA_Token=\"${NJALLA_Token:-$(_readaccountconf_mutable NJALLA_Token)}\" if [ \"$NJALLA_Token\" ]; then _saveaccountconf_mutable NJALLA_Token \"$NJALLA_Token\" else NJALLA_Token=\"\" _err \"You didn't specify a Njalla api token yet.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # For wildcard cert, the main root domain and the wildcard domain have the same txt subdomain name, so # we can not use updating anymore. # count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"count\\\":[^,]*\" | cut -d : -f 2) # _debug count \"$count\" # if [ \"$count\" = \"0\" ]; then _info \"Adding record\" if _njalla_rest \"{\\\"method\\\":\\\"add-record\\\",\\\"params\\\":{\\\"domain\\\":\\\"$_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":120}}\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"Added, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_njalla_rm() { fulldomain=$1 txtvalue=$2 NJALLA_Token=\"${NJALLA_Token:-$(_readaccountconf_mutable NJALLA_Token)}\" if [ \"$NJALLA_Token\" ]; then _saveaccountconf_mutable NJALLA_Token \"$NJALLA_Token\" else NJALLA_Token=\"\" _err \"You didn't specify a Njalla api token yet.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting records for domain\" if ! _njalla_rest \"{\\\"method\\\":\\\"list-records\\\",\\\"params\\\":{\\\"domain\\\":\\\"${_domain}\\\"}}\"; then return 1 fi if ! echo \"$response\" | tr -d \" \" | grep \"\\\"id\\\":\" >/dev/null; then _err \"Error: $response\" return 1 fi records=$(echo \"$response\" | _egrep_o \"\\\"records\\\":\\s?\\[(.*)\\]\\}\" | _egrep_o \"\\[.*\\]\" | _egrep_o \"\\{[^\\{\\}]*\\\"id\\\":[^\\{\\}]*\\}\") count=$(echo \"$records\" | wc -l) _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else echo \"$records\" | while read -r record; do record_name=$(echo \"$record\" | _egrep_o \"\\\"name\\\":\\s?\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \" \" | tr -d \\\") record_content=$(echo \"$record\" | _egrep_o \"\\\"content\\\":\\s?\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \" \" | tr -d \\\") record_id=$(echo \"$record\" | _egrep_o \"\\\"id\\\":\\s?[0-9]+\" | cut -d : -f 2 | tr -d \" \" | tr -d \\\") if [ \"$_sub_domain\" = \"$record_name\" ]; then if [ \"$txtvalue\" = \"$record_content\" ]; then _debug \"record_id\" \"$record_id\" if ! _njalla_rest \"{\\\"method\\\":\\\"remove-record\\\",\\\"params\\\":{\\\"domain\\\":\\\"${_domain}\\\",\\\"id\\\":${record_id}}}\"; then _err \"Delete record error.\" return 1 fi echo \"$response\" | tr -d \" \" | grep \"\\\"result\\\"\" >/dev/null fi fi done fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _njalla_rest \"{\\\"method\\\":\\\"get-domain\\\",\\\"params\\\":{\\\"domain\\\":\\\"${h}\\\"}}\"; then return 1 fi if _contains \"$response\" \"\\\"$h\\\"\"; then _domain_returned=$(echo \"$response\" | _egrep_o \"\\{\\\"name\\\": *\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \\\" | tr -d \" \") if [ \"$_domain_returned\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _njalla_rest() { data=\"$1\" token_trimmed=$(echo \"$NJALLA_Token\" | tr -d '\"') export _H1=\"Content-Type: application/json\" export _H2=\"Accept: application/json\" export _H3=\"Authorization: Njalla $token_trimmed\" _debug data \"$data\" response=\"$(_post \"$data\" \"$NJALLA_Api\" \"\" \"POST\")\" if [ \"$?\" != \"0\" ]; then _err \"error $data\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_255.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_255.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_nm_info='NameMaster.de Site: NameMaster.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_nm Options: NM_user API Username NM_sha256 API Password as SHA256 hash Author: Thilo Gass <thilo.gass@gmail.com> ' #-- dns_nm_add() - Add TXT record -------------------------------------- # Usage: dns_nm_add _acme-challenge.subdomain.domain.com \"XyZ123...\" namemaster_api=\"https://namemaster.de/api/api.php\" dns_nm_add() { fulldomain=$1 txt_value=$2 _info \"Using DNS-01 namemaster hook\" NM_user=\"${NM_user:-$(_readaccountconf_mutable NM_user)}\" NM_sha256=\"${NM_sha256:-$(_readaccountconf_mutable NM_sha256)}\" if [ -z \"$NM_user\" ] || [ -z \"$NM_sha256\" ]; then NM_user=\"\" NM_sha256=\"\" _err \"No auth details provided. Please set user credentials using the \\$NM_user and \\$NM_sha256 environment variables.\" return 1 fi #save the api user and sha256 password to the account conf file. _debug \"Save user and hash\" _saveaccountconf_mutable NM_user \"$NM_user\" _saveaccountconf_mutable NM_sha256 \"$NM_sha256\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" \"$fulldomain\" return 1 fi _info \"die Zone lautet:\" \"$zone\" get=\"$namemaster_api?User=$NM_user&Password=$NM_sha256&Antwort=csv&Typ=ACME&zone=$zone&hostname=$fulldomain&TXT=$txt_value&Action=Auto&Lifetime=3600\" if ! erg=\"$(_get \"$get\")\"; then _err \"error Adding $fulldomain TXT: $txt_value\" return 1 fi if _contains \"$erg\" \"Success\"; then _info \"Success, TXT Added, OK\" else _err \"error Adding $fulldomain TXT: $txt_value erg: $erg\" return 1 fi _debug \"ok Auto $fulldomain TXT: $txt_value erg: $erg\" return 0 } dns_nm_rm() { fulldomain=$1 txtvalue=$2 _info \"TXT enrty in $fulldomain is deleted automatically\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" } _get_root() { domain=$1 get=\"$namemaster_api?User=$NM_user&Password=$NM_sha256&Typ=acme&hostname=$domain&Action=getzone&antwort=csv\" if ! zone=\"$(_get \"$get\")\"; then _err \"error getting Zone\" return 1 else if _contains \"$zone\" \"hostname not found\"; then return 1 fi fi }"
        },
        {
            "filename": "file_256.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_256.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_nsd_info='NLnetLabs NSD Server Site: github.com/NLnetLabs/nsd Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#nsd Options: Nsd_ZoneFile Zone File path. E.g. \"/etc/nsd/zones/example.com.zone\" Nsd_Command Command. E.g. \"sudo nsd-control reload\" Issues: github.com/acmesh-official/acme.sh/issues/2245 ' # args: fulldomain txtvalue dns_nsd_add() { fulldomain=$1 txtvalue=$2 ttlvalue=300 Nsd_ZoneFile=\"${Nsd_ZoneFile:-$(_readdomainconf Nsd_ZoneFile)}\" Nsd_Command=\"${Nsd_Command:-$(_readdomainconf Nsd_Command)}\" # Arg checks if [ -z \"$Nsd_ZoneFile\" ] || [ -z \"$Nsd_Command\" ]; then Nsd_ZoneFile=\"\" Nsd_Command=\"\" _err \"Specify ENV vars Nsd_ZoneFile and Nsd_Command\" return 1 fi if [ ! -f \"$Nsd_ZoneFile\" ]; then Nsd_ZoneFile=\"\" Nsd_Command=\"\" _err \"No such file: $Nsd_ZoneFile\" return 1 fi _savedomainconf Nsd_ZoneFile \"$Nsd_ZoneFile\" _savedomainconf Nsd_Command \"$Nsd_Command\" echo \"$fulldomain. $ttlvalue IN TXT \\\"$txtvalue\\\"\" >>\"$Nsd_ZoneFile\" _info \"Added TXT record for $fulldomain\" _debug \"Running $Nsd_Command\" if eval \"$Nsd_Command\"; then _info \"Successfully updated the zone\" return 0 else _err \"Problem updating the zone\" return 1 fi } # args: fulldomain txtvalue dns_nsd_rm() { fulldomain=$1 txtvalue=$2 ttlvalue=300 Nsd_ZoneFile=\"${Nsd_ZoneFile:-$(_readdomainconf Nsd_ZoneFile)}\" Nsd_Command=\"${Nsd_Command:-$(_readdomainconf Nsd_Command)}\" _sed_i \"/$fulldomain. $ttlvalue IN TXT \\\"$txtvalue\\\"/d\" \"$Nsd_ZoneFile\" _info \"Removed TXT record for $fulldomain\" _debug \"Running $Nsd_Command\" if eval \"$Nsd_Command\"; then _info \"Successfully reloaded NSD \" return 0 else _err \"Problem reloading NSD\" return 1 fi }"
        },
        {
            "filename": "file_257.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_257.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_nsone_info='ns1.com Domains: ns1.net Site: ns1.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_nsone Options: NS1_Key API Key Author: <dev@1e.ca> ' NS1_Api=\"https://api.nsone.net/v1\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_nsone_add() { fulldomain=$1 txtvalue=$2 if [ -z \"$NS1_Key\" ]; then NS1_Key=\"\" _err \"You didn't specify nsone dns api key yet.\" _err \"Please create you key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf NS1_Key \"$NS1_Key\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _nsone_rest GET \"zones/${_domain}\" if ! _contains \"$response\" \"\\\"records\\\":\"; then _err \"Error\" return 1 fi count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"domain\\\":\\\"$fulldomain\\\",[^{]*\\\"type\\\":\\\"TXT\\\"\" | wc -l | tr -d \" \") _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Adding record\" if _nsone_rest PUT \"zones/$_domain/$fulldomain/TXT\" \"{\\\"answers\\\":[{\\\"answer\\\":[\\\"$txtvalue\\\"]}],\\\"type\\\":\\\"TXT\\\",\\\"domain\\\":\\\"$fulldomain\\\",\\\"zone\\\":\\\"$_domain\\\",\\\"ttl\\\":0}\"; then if _contains \"$response\" \"$fulldomain\"; then _info \"Added\" #todo: check if the record takes effect return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" else _info \"Updating record\" prev_txt=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"domain\\\":\\\"$fulldomain\\\",\\\"short_answers\\\":\\[\\\"[^,]*\\]\" | _head_n 1 | cut -d: -f3 | cut -d, -f1) _debug \"prev_txt\" \"$prev_txt\" _nsone_rest POST \"zones/$_domain/$fulldomain/TXT\" \"{\\\"answers\\\": [{\\\"answer\\\": [\\\"$txtvalue\\\"]},{\\\"answer\\\": $prev_txt}],\\\"type\\\": \\\"TXT\\\",\\\"domain\\\":\\\"$fulldomain\\\",\\\"zone\\\": \\\"$_domain\\\",\\\"ttl\\\":0}\" if [ \"$?\" = \"0\" ] && _contains \"$response\" \"$fulldomain\"; then _info \"Updated!\" #todo: check if the record takes effect return 0 fi _err \"Update error\" return 1 fi } #fulldomain dns_nsone_rm() { fulldomain=$1 txtvalue=$2 _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _nsone_rest GET \"zones/${_domain}/$fulldomain/TXT\" count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"domain\\\":\\\"$fulldomain\\\",.*\\\"type\\\":\\\"TXT\\\"\" | wc -l | tr -d \" \") _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else if ! _nsone_rest DELETE \"zones/${_domain}/$fulldomain/TXT\"; then _err \"Delete record error.\" return 1 fi _contains \"$response\" \"\" fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=2 p=1 if ! _nsone_rest GET \"zones\"; then return 1 fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"\\\"zone\\\":\\\"$h\\\"\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _nsone_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Accept: application/json\" export _H2=\"X-NSONE-Key: $NS1_Key\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$NS1_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$NS1_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_258.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_258.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_nsupdate_info='nsupdate RFC 2136 DynDNS client Site: bind9.readthedocs.io/en/v9.18.19/manpages.html#nsupdate-dynamic-dns-update-utility Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_nsupdate Options: NSUPDATE_SERVER Server hostname. Default: \"localhost\". NSUPDATE_SERVER_PORT Server port. Default: \"53\". NSUPDATE_KEY File path to TSIG key. NSUPDATE_ZONE Domain zone to update. Optional. ' ######## Public functions ##################### #Usage: dns_nsupdate_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_nsupdate_add() { fulldomain=$1 txtvalue=$2 NSUPDATE_SERVER=\"${NSUPDATE_SERVER:-$(_readaccountconf_mutable NSUPDATE_SERVER)}\" NSUPDATE_SERVER_PORT=\"${NSUPDATE_SERVER_PORT:-$(_readaccountconf_mutable NSUPDATE_SERVER_PORT)}\" NSUPDATE_KEY=\"${NSUPDATE_KEY:-$(_readaccountconf_mutable NSUPDATE_KEY)}\" NSUPDATE_ZONE=\"${NSUPDATE_ZONE:-$(_readaccountconf_mutable NSUPDATE_ZONE)}\" NSUPDATE_OPT=\"${NSUPDATE_OPT:-$(_readaccountconf_mutable NSUPDATE_OPT)}\" _checkKeyFile || return 1 # save the dns server and key to the account conf file. _saveaccountconf_mutable NSUPDATE_SERVER \"${NSUPDATE_SERVER}\" _saveaccountconf_mutable NSUPDATE_SERVER_PORT \"${NSUPDATE_SERVER_PORT}\" _saveaccountconf_mutable NSUPDATE_KEY \"${NSUPDATE_KEY}\" _saveaccountconf_mutable NSUPDATE_ZONE \"${NSUPDATE_ZONE}\" _saveaccountconf_mutable NSUPDATE_OPT \"${NSUPDATE_OPT}\" [ -n \"${NSUPDATE_SERVER}\" ] || NSUPDATE_SERVER=\"localhost\" [ -n \"${NSUPDATE_SERVER_PORT}\" ] || NSUPDATE_SERVER_PORT=53 [ -n \"${NSUPDATE_OPT}\" ] || NSUPDATE_OPT=\"\" _info \"adding ${fulldomain}. 60 in txt \\\"${txtvalue}\\\"\" [ -n \"$DEBUG\" ] && [ \"$DEBUG\" -ge \"$DEBUG_LEVEL_1\" ] && nsdebug=\"-d\" [ -n \"$DEBUG\" ] && [ \"$DEBUG\" -ge \"$DEBUG_LEVEL_2\" ] && nsdebug=\"-D\" if [ -z \"${NSUPDATE_ZONE}\" ]; then #shellcheck disable=SC2086 nsupdate -k \"${NSUPDATE_KEY}\" $nsdebug $NSUPDATE_OPT <<EOF server ${NSUPDATE_SERVER} ${NSUPDATE_SERVER_PORT} update add ${fulldomain}. 60 in txt \"${txtvalue}\" send EOF else #shellcheck disable=SC2086 nsupdate -k \"${NSUPDATE_KEY}\" $nsdebug $NSUPDATE_OPT <<EOF server ${NSUPDATE_SERVER} ${NSUPDATE_SERVER_PORT} zone ${NSUPDATE_ZONE}. update add ${fulldomain}. 60 in txt \"${txtvalue}\" send EOF fi if [ $? -ne 0 ]; then _err \"error updating domain\" return 1 fi return 0 } #Usage: dns_nsupdate_rm _acme-challenge.www.domain.com dns_nsupdate_rm() { fulldomain=$1 NSUPDATE_SERVER=\"${NSUPDATE_SERVER:-$(_readaccountconf_mutable NSUPDATE_SERVER)}\" NSUPDATE_SERVER_PORT=\"${NSUPDATE_SERVER_PORT:-$(_readaccountconf_mutable NSUPDATE_SERVER_PORT)}\" NSUPDATE_KEY=\"${NSUPDATE_KEY:-$(_readaccountconf_mutable NSUPDATE_KEY)}\" NSUPDATE_ZONE=\"${NSUPDATE_ZONE:-$(_readaccountconf_mutable NSUPDATE_ZONE)}\" NSUPDATE_OPT=\"${NSUPDATE_OPT:-$(_readaccountconf_mutable NSUPDATE_OPT)}\" _checkKeyFile || return 1 [ -n \"${NSUPDATE_SERVER}\" ] || NSUPDATE_SERVER=\"localhost\" [ -n \"${NSUPDATE_SERVER_PORT}\" ] || NSUPDATE_SERVER_PORT=53 _info \"removing ${fulldomain}. txt\" [ -n \"$DEBUG\" ] && [ \"$DEBUG\" -ge \"$DEBUG_LEVEL_1\" ] && nsdebug=\"-d\" [ -n \"$DEBUG\" ] && [ \"$DEBUG\" -ge \"$DEBUG_LEVEL_2\" ] && nsdebug=\"-D\" if [ -z \"${NSUPDATE_ZONE}\" ]; then #shellcheck disable=SC2086 nsupdate -k \"${NSUPDATE_KEY}\" $nsdebug $NSUPDATE_OPT <<EOF server ${NSUPDATE_SERVER} ${NSUPDATE_SERVER_PORT} update delete ${fulldomain}. txt send EOF else #shellcheck disable=SC2086 nsupdate -k \"${NSUPDATE_KEY}\" $nsdebug $NSUPDATE_OPT <<EOF server ${NSUPDATE_SERVER} ${NSUPDATE_SERVER_PORT} zone ${NSUPDATE_ZONE}. update delete ${fulldomain}. txt send EOF fi if [ $? -ne 0 ]; then _err \"error updating domain\" return 1 fi return 0 } #################### Private functions below ################################## _checkKeyFile() { if [ -z \"${NSUPDATE_KEY}\" ]; then _err \"you must specify a path to the nsupdate key file\" return 1 fi if [ ! -r \"${NSUPDATE_KEY}\" ]; then _err \"key ${NSUPDATE_KEY} is unreadable\" return 1 fi }"
        },
        {
            "filename": "file_259.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_259.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_nw_info='Nexcess.net (NocWorx) Domains: Thermo.io Futurehosting.com Site: Nexcess.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_nw Options: NW_API_TOKEN API Token NW_API_ENDPOINT API Endpoint. Default: \"https://portal.nexcess.net\". Issues: github.com/acmesh-official/acme.sh/issues/2088 Author: Frank Laszlo <flaszlo@nexcess.net> ' # Endpoints: # - https://portal.nexcess.net (default) # - https://core.thermo.io # - https://my.futurehosting.com # # Note: If you do not have an API token, one can be generated at one # of the following URLs: # - https://portal.nexcess.net/api-token # - https://core.thermo.io/api-token # - https://my.futurehosting.com/api-token NW_API_VERSION=\"0\" # dns_nw_add() - Add TXT record # Usage: dns_nw_add _acme-challenge.subdomain.domain.com \"XyZ123...\" dns_nw_add() { host=\"${1}\" txtvalue=\"${2}\" _debug host \"${host}\" _debug txtvalue \"${txtvalue}\" if ! _check_nw_api_creds; then return 1 fi _info \"Using NocWorx (${NW_API_ENDPOINT})\" _debug \"Calling: dns_nw_add() '${host}' '${txtvalue}'\" _debug \"Detecting root zone\" if ! _get_root \"${host}\"; then _err \"Zone for domain does not exist.\" return 1 fi _debug _zone_id \"${_zone_id}\" _debug _sub_domain \"${_sub_domain}\" _debug _domain \"${_domain}\" _post_data=\"{\\\"zone_id\\\": \\\"${_zone_id}\\\", \\\"type\\\": \\\"TXT\\\", \\\"host\\\": \\\"${host}\\\", \\\"target\\\": \\\"${txtvalue}\\\", \\\"ttl\\\": \\\"300\\\"}\" if _rest POST \"dns-record\" \"${_post_data}\" && [ -n \"${response}\" ]; then _record_id=$(printf \"%s\\n\" \"${response}\" | _egrep_o \"\\\"record_id\\\": *[0-9]+\" | cut -d : -f 2 | tr -d \" \" | _head_n 1) _debug _record_id \"${_record_id}\" if [ -z \"$_record_id\" ]; then _err \"Error adding the TXT record.\" return 1 fi _info \"TXT record successfully added.\" return 0 fi return 1 } # dns_nw_rm() - Remove TXT record # Usage: dns_nw_rm _acme-challenge.subdomain.domain.com \"XyZ123...\" dns_nw_rm() { host=\"${1}\" txtvalue=\"${2}\" _debug host \"${host}\" _debug txtvalue \"${txtvalue}\" if ! _check_nw_api_creds; then return 1 fi _info \"Using NocWorx (${NW_API_ENDPOINT})\" _debug \"Calling: dns_nw_rm() '${host}'\" _debug \"Detecting root zone\" if ! _get_root \"${host}\"; then _err \"Zone for domain does not exist.\" return 1 fi _debug _zone_id \"${_zone_id}\" _debug _sub_domain \"${_sub_domain}\" _debug _domain \"${_domain}\" _parameters=\"?zone_id=${_zone_id}\" if _rest GET \"dns-record\" \"${_parameters}\" && [ -n \"${response}\" ]; then response=\"$(echo \"${response}\" | tr -d \"\\n\" | sed 's/^\\[\\(.*\\)\\]$/\\1/' | sed -e 's/{\"record_id\":/|\"record_id\":/g' | sed 's/|/&{/g' | tr \"|\" \"\\n\")\" _debug response \"${response}\" record=\"$(echo \"${response}\" | _egrep_o \"{.*\\\"host\\\": *\\\"${_sub_domain}\\\", *\\\"target\\\": *\\\"${txtvalue}\\\".*}\")\" _debug record \"${record}\" if [ \"${record}\" ]; then _record_id=$(printf \"%s\\n\" \"${record}\" | _egrep_o \"\\\"record_id\\\": *[0-9]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\ ) if [ \"${_record_id}\" ]; then _debug _record_id \"${_record_id}\" _rest DELETE \"dns-record/${_record_id}\" _info \"TXT record successfully deleted.\" return 0 fi return 1 fi return 0 fi return 1 } _check_nw_api_creds() { NW_API_TOKEN=\"${NW_API_TOKEN:-$(_readaccountconf_mutable NW_API_TOKEN)}\" NW_API_ENDPOINT=\"${NW_API_ENDPOINT:-$(_readaccountconf_mutable NW_API_ENDPOINT)}\" if [ -z \"${NW_API_ENDPOINT}\" ]; then NW_API_ENDPOINT=\"https://portal.nexcess.net\" fi if [ -z \"${NW_API_TOKEN}\" ]; then _err \"You have not defined your NW_API_TOKEN.\" _err \"Please create your token and try again.\" _err \"If you need to generate a new token, please visit one of the following URLs:\" _err \" - https://portal.nexcess.net/api-token\" _err \" - https://core.thermo.io/api-token\" _err \" - https://my.futurehosting.com/api-token\" return 1 fi _saveaccountconf_mutable NW_API_TOKEN \"${NW_API_TOKEN}\" _saveaccountconf_mutable NW_API_ENDPOINT \"${NW_API_ENDPOINT}\" } _get_root() { domain=\"${1}\" i=2 p=1 if _rest GET \"dns-zone\"; then response=\"$(echo \"${response}\" | tr -d \"\\n\" | sed 's/^\\[\\(.*\\)\\]$/\\1/' | sed -e 's/{\"zone_id\":/|\"zone_id\":/g' | sed 's/|/&{/g' | tr \"|\" \"\\n\")\" _debug response \"${response}\" while true; do h=$(printf \"%s\" \"${domain}\" | cut -d . -f $i-100) _debug h \"${h}\" if [ -z \"${h}\" ]; then #not valid return 1 fi hostedzone=\"$(echo \"${response}\" | _egrep_o \"{.*\\\"domain\\\": *\\\"${h}\\\".*}\")\" if [ \"${hostedzone}\" ]; then _zone_id=$(printf \"%s\\n\" \"${hostedzone}\" | _egrep_o \"\\\"zone_id\\\": *[0-9]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\ ) if [ \"${_zone_id}\" ]; then _sub_domain=$(printf \"%s\" \"${domain}\" | cut -d . -f 1-${p}) _domain=\"${h}\" return 0 fi return 1 fi p=$i i=$(_math \"${i}\" + 1) done fi return 1 } _rest() { method=\"${1}\" ep=\"/${2}\" data=\"${3}\" _debug method \"${method}\" _debug ep \"${ep}\" export _H1=\"Accept: application/json\" export _H2=\"Content-Type: application/json\" export _H3=\"Api-Version: ${NW_API_VERSION}\" export _H4=\"User-Agent: NW-ACME-CLIENT\" export _H5=\"Authorization: Bearer ${NW_API_TOKEN}\" if [ \"${method}\" != \"GET\" ]; then _debug data \"${data}\" response=\"$(_post \"${data}\" \"${NW_API_ENDPOINT}${ep}\" \"\" \"${method}\")\" else response=\"$(_get \"${NW_API_ENDPOINT}${ep}${data}\")\" fi if [ \"${?}\" != \"0\" ]; then _err \"error ${ep}\" return 1 fi _debug2 response \"${response}\" return 0 }"
        },
        {
            "filename": "file_260.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_260.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_oci_info='Oracle Cloud Infrastructure (OCI) If OCI CLI configuration file ~/.oci/config has a DEFAULT profile then it will be used. Site: Cloud.Oracle.com Docs: github.com/acmesh-official/acme.sh/wiki/How-to-use-Oracle-Cloud-Infrastructure-DNS Options: OCI_CLI_TENANCY OCID of tenancy that contains the target DNS zone. Optional. OCI_CLI_USER OCID of user with permission to add/remove records from zones. Optional. OCI_CLI_REGION Should point to the tenancy home region. Optional. OCI_CLI_KEY_FILE Path to private API signing key file in PEM format. Optional. OCI_CLI_KEY The private API signing key in PEM format. Optional. Issues: github.com/acmesh-official/acme.sh/issues/3540 Author: Avi Miller <me@dje.li> ' # Copyright (c) 2021, Oracle and/or its affiliates # # The plugin will automatically use the default profile from an OCI SDK and CLI # configuration file, if it exists. # # Alternatively, set the following environment variables: # - OCI_CLI_TENANCY : OCID of tenancy that contains the target DNS zone # - OCI_CLI_USER : OCID of user with permission to add/remove records from zones # - OCI_CLI_REGION : Should point to the tenancy home region # # One of the following two variables is required: # - OCI_CLI_KEY_FILE: Path to private API signing key file in PEM format; or # - OCI_CLI_KEY : The private API signing key in PEM format # # NOTE: using an encrypted private key that needs a passphrase is not supported. # dns_oci_add() { _fqdn=\"$1\" _rdata=\"$2\" if _get_oci_zone; then _add_record_body=\"{\\\"items\\\":[{\\\"domain\\\":\\\"${_sub_domain}.${_domain}\\\",\\\"rdata\\\":\\\"$_rdata\\\",\\\"rtype\\\":\\\"TXT\\\",\\\"ttl\\\": 30,\\\"operation\\\":\\\"ADD\\\"}]}\" response=$(_signed_request \"PATCH\" \"/20180115/zones/${_domain}/records\" \"$_add_record_body\") if [ \"$response\" ]; then _info \"Success: added TXT record for ${_sub_domain}.${_domain}.\" else _err \"Error: failed to add TXT record for ${_sub_domain}.${_domain}.\" _err \"Check that the user has permission to add records to this zone.\" return 1 fi else return 1 fi } dns_oci_rm() { _fqdn=\"$1\" _rdata=\"$2\" if _get_oci_zone; then _remove_record_body=\"{\\\"items\\\":[{\\\"domain\\\":\\\"${_sub_domain}.${_domain}\\\",\\\"rdata\\\":\\\"$_rdata\\\",\\\"rtype\\\":\\\"TXT\\\",\\\"operation\\\":\\\"REMOVE\\\"}]}\" response=$(_signed_request \"PATCH\" \"/20180115/zones/${_domain}/records\" \"$_remove_record_body\") if [ \"$response\" ]; then _info \"Success: removed TXT record for ${_sub_domain}.${_domain}.\" else _err \"Error: failed to remove TXT record for ${_sub_domain}.${_domain}.\" _err \"Check that the user has permission to remove records from this zone.\" return 1 fi else return 1 fi } #################### Private functions below ################################## _get_oci_zone() { if ! _oci_config; then return 1 fi if ! _get_zone \"$_fqdn\"; then _err \"Error: DNS Zone not found for $_fqdn in $OCI_CLI_TENANCY\" return 1 fi return 0 } _oci_config() { _DEFAULT_OCI_CLI_CONFIG_FILE=\"$HOME/.oci/config\" OCI_CLI_CONFIG_FILE=\"${OCI_CLI_CONFIG_FILE:-$(_readaccountconf_mutable OCI_CLI_CONFIG_FILE)}\" if [ -z \"$OCI_CLI_CONFIG_FILE\" ]; then OCI_CLI_CONFIG_FILE=\"$_DEFAULT_OCI_CLI_CONFIG_FILE\" fi if [ \"$_DEFAULT_OCI_CLI_CONFIG_FILE\" != \"$OCI_CLI_CONFIG_FILE\" ]; then _saveaccountconf_mutable OCI_CLI_CONFIG_FILE \"$OCI_CLI_CONFIG_FILE\" else _clearaccountconf_mutable OCI_CLI_CONFIG_FILE fi _DEFAULT_OCI_CLI_PROFILE=\"DEFAULT\" OCI_CLI_PROFILE=\"${OCI_CLI_PROFILE:-$(_readaccountconf_mutable OCI_CLI_PROFILE)}\" if [ \"$_DEFAULT_OCI_CLI_PROFILE\" != \"$OCI_CLI_PROFILE\" ]; then _saveaccountconf_mutable OCI_CLI_PROFILE \"$OCI_CLI_PROFILE\" else OCI_CLI_PROFILE=\"$_DEFAULT_OCI_CLI_PROFILE\" _clearaccountconf_mutable OCI_CLI_PROFILE fi OCI_CLI_TENANCY=\"${OCI_CLI_TENANCY:-$(_readaccountconf_mutable OCI_CLI_TENANCY)}\" if [ \"$OCI_CLI_TENANCY\" ]; then _saveaccountconf_mutable OCI_CLI_TENANCY \"$OCI_CLI_TENANCY\" elif [ -f \"$OCI_CLI_CONFIG_FILE\" ]; then _debug \"Reading OCI_CLI_TENANCY value from: $OCI_CLI_CONFIG_FILE\" OCI_CLI_TENANCY=\"${OCI_CLI_TENANCY:-$(_readini \"$OCI_CLI_CONFIG_FILE\" tenancy \"$OCI_CLI_PROFILE\")}\" fi if [ -z \"$OCI_CLI_TENANCY\" ]; then _err \"Error: unable to read OCI_CLI_TENANCY from config file or environment variable.\" return 1 fi OCI_CLI_USER=\"${OCI_CLI_USER:-$(_readaccountconf_mutable OCI_CLI_USER)}\" if [ \"$OCI_CLI_USER\" ]; then _saveaccountconf_mutable OCI_CLI_USER \"$OCI_CLI_USER\" elif [ -f \"$OCI_CLI_CONFIG_FILE\" ]; then _debug \"Reading OCI_CLI_USER value from: $OCI_CLI_CONFIG_FILE\" OCI_CLI_USER=\"${OCI_CLI_USER:-$(_readini \"$OCI_CLI_CONFIG_FILE\" user \"$OCI_CLI_PROFILE\")}\" fi if [ -z \"$OCI_CLI_USER\" ]; then _err \"Error: unable to read OCI_CLI_USER from config file or environment variable.\" return 1 fi OCI_CLI_REGION=\"${OCI_CLI_REGION:-$(_readaccountconf_mutable OCI_CLI_REGION)}\" if [ \"$OCI_CLI_REGION\" ]; then _saveaccountconf_mutable OCI_CLI_REGION \"$OCI_CLI_REGION\" elif [ -f \"$OCI_CLI_CONFIG_FILE\" ]; then _debug \"Reading OCI_CLI_REGION value from: $OCI_CLI_CONFIG_FILE\" OCI_CLI_REGION=\"${OCI_CLI_REGION:-$(_readini \"$OCI_CLI_CONFIG_FILE\" region \"$OCI_CLI_PROFILE\")}\" fi if [ -z \"$OCI_CLI_REGION\" ]; then _err \"Error: unable to read OCI_CLI_REGION from config file or environment variable.\" return 1 fi OCI_CLI_KEY=\"${OCI_CLI_KEY:-$(_readaccountconf_mutable OCI_CLI_KEY)}\" if [ -z \"$OCI_CLI_KEY\" ]; then _clearaccountconf_mutable OCI_CLI_KEY OCI_CLI_KEY_FILE=\"${OCI_CLI_KEY_FILE:-$(_readini \"$OCI_CLI_CONFIG_FILE\" key_file \"$OCI_CLI_PROFILE\")}\" if [ \"$OCI_CLI_KEY_FILE\" ] && [ -f \"$OCI_CLI_KEY_FILE\" ]; then _debug \"Reading OCI_CLI_KEY value from: $OCI_CLI_KEY_FILE\" OCI_CLI_KEY=$(_base64 <\"$OCI_CLI_KEY_FILE\") _saveaccountconf_mutable OCI_CLI_KEY \"$OCI_CLI_KEY\" fi else _saveaccountconf_mutable OCI_CLI_KEY \"$OCI_CLI_KEY\" fi if [ -z \"$OCI_CLI_KEY_FILE\" ] && [ -z \"$OCI_CLI_KEY\" ]; then _err \"Error: unable to find key file path in OCI config file or OCI_CLI_KEY_FILE.\" _err \"Error: unable to load private API signing key from OCI_CLI_KEY.\" return 1 fi if [ \"$(printf \"%s\\n\" \"$OCI_CLI_KEY\" | wc -l)\" -eq 1 ]; then OCI_CLI_KEY=$(printf \"%s\" \"$OCI_CLI_KEY\" | _dbase64) fi return 0 } # _get_zone(): retrieves the Zone name and OCID # # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_ociid=ocid1.dns-zone.oc1.. _get_zone() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then # not valid return 1 fi _domain_id=$(_signed_request \"GET\" \"/20180115/zones/$h\" \"\" \"id\") if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } #Usage: privatekey #Output MD5 fingerprint _fingerprint() { pkey=\"$1\" if [ -z \"$pkey\" ]; then _usage \"Usage: _fingerprint privkey\" return 1 fi printf \"%s\" \"$pkey\" | ${ACME_OPENSSL_BIN:-openssl} rsa -pubout -outform DER 2>/dev/null | ${ACME_OPENSSL_BIN:-openssl} md5 -c | cut -d = -f 2 | tr -d ' ' } _signed_request() { _sig_method=\"$1\" _sig_target=\"$2\" _sig_body=\"$3\" _return_field=\"$4\" _key_fingerprint=$(_fingerprint \"$OCI_CLI_KEY\") _sig_host=\"dns.$OCI_CLI_REGION.oraclecloud.com\" _sig_keyId=\"$OCI_CLI_TENANCY/$OCI_CLI_USER/$_key_fingerprint\" _sig_alg=\"rsa-sha256\" _sig_version=\"1\" _sig_now=\"$(LC_ALL=C \\date -u \"+%a, %d %h %Y %H:%M:%S GMT\")\" _request_method=$(printf %s \"$_sig_method\" | _lower_case) _curl_method=$(printf %s \"$_sig_method\" | _upper_case) _request_target=\"(request-target): $_request_method $_sig_target\" _date_header=\"date: $_sig_now\" _host_header=\"host: $_sig_host\" _string_to_sign=\"$_request_target\\n$_date_header\\n$_host_header\" _sig_headers=\"(request-target) date host\" if [ \"$_sig_body\" ]; then _secure_debug3 _sig_body \"$_sig_body\" _sig_body_sha256=\"x-content-sha256: $(printf %s \"$_sig_body\" | _digest sha256)\" _sig_body_type=\"content-type: application/json\" _sig_body_length=\"content-length: ${#_sig_body}\" _string_to_sign=\"$_string_to_sign\\n$_sig_body_sha256\\n$_sig_body_type\\n$_sig_body_length\" _sig_headers=\"$_sig_headers x-content-sha256 content-type content-length\" fi _tmp_file=$(_mktemp) if [ -f \"$_tmp_file\" ]; then printf '%s' \"$OCI_CLI_KEY\" >\"$_tmp_file\" _signature=$(printf '%b' \"$_string_to_sign\" | _sign \"$_tmp_file\" sha256 | tr -d '\\r\\n') rm -f \"$_tmp_file\" fi _signed_header=\"Authorization: Signature version=\\\"$_sig_version\\\",keyId=\\\"$_sig_keyId\\\",algorithm=\\\"$_sig_alg\\\",headers=\\\"$_sig_headers\\\",signature=\\\"$_signature\\\"\" _secure_debug3 _signed_header \"$_signed_header\" if [ \"$_curl_method\" = \"GET\" ]; then export _H1=\"$_date_header\" export _H2=\"$_signed_header\" _response=\"$(_get \"https://${_sig_host}${_sig_target}\")\" elif [ \"$_curl_method\" = \"PATCH\" ]; then export _H1=\"$_date_header\" # shellcheck disable=SC2090 export _H2=\"$_sig_body_sha256\" export _H3=\"$_sig_body_type\" export _H4=\"$_sig_body_length\" export _H5=\"$_signed_header\" _response=\"$(_post \"$_sig_body\" \"https://${_sig_host}${_sig_target}\" \"\" \"PATCH\")\" else _err \"Unable to process method: $_curl_method.\" fi _ret=\"$?\" if [ \"$_return_field\" ]; then _response=\"$(echo \"$_response\" | sed 's/\\\\\\\"//g'))\" _return=$(echo \"${_response}\" | _egrep_o \"\\\"$_return_field\\\"\\\\s*:\\\\s*\\\"[^\\\"]*\\\"\" | _head_n 1 | cut -d : -f 2 | tr -d \"\\\"\") else _return=\"$_response\" fi printf \"%s\" \"$_return\" return $_ret } # file key [section] _readini() { _file=\"$1\" _key=\"$2\" _section=\"${3:-DEFAULT}\" _start_n=$(grep -n '\\['\"$_section\"']' \"$_file\" | cut -d : -f 1) _debug3 _start_n \"$_start_n\" if [ -z \"$_start_n\" ]; then _err \"Can not find section: $_section\" return 1 fi _start_nn=$(_math \"$_start_n\" + 1) _debug3 \"_start_nn\" \"$_start_nn\" _left=\"$(sed -n \"${_start_nn},99999p\" \"$_file\")\" _debug3 _left \"$_left\" _end=\"$(echo \"$_left\" | grep -n \"^\\[\" | _head_n 1)\" _debug3 \"_end\" \"$_end\" if [ \"$_end\" ]; then _end_n=$(echo \"$_end\" | cut -d : -f 1) _debug3 \"_end_n\" \"$_end_n\" _seg_n=$(echo \"$_left\" | sed -n \"1,${_end_n}p\") else _seg_n=\"$_left\" fi _debug3 \"_seg_n\" \"$_seg_n\" _lineini=\"$(echo \"$_seg_n\" | grep \"^ *$_key *= *\")\" _inivalue=\"$(printf \"%b\" \"$(eval \"echo $_lineini | sed \\\"s/^ *${_key} *= *//g\\\"\")\")\" _debug2 _inivalue \"$_inivalue\" echo \"$_inivalue\" }"
        },
        {
            "filename": "file_261.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_261.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_one_info='one.com Site: one.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_one Options: ONECOM_User Username ONECOM_Password Password Issues: github.com/acmesh-official/acme.sh/issues/2103 ' dns_one_add() { fulldomain=$1 txtvalue=$2 if ! _dns_one_login; then _err \"login failed\" return 1 fi _debug \"detect the root domain\" if ! _get_root \"$fulldomain\"; then _err \"root domain not found\" return 1 fi subdomain=\"${_sub_domain}\" maindomain=${_domain} _debug subdomain \"$subdomain\" _debug maindomain \"$maindomain\" #Check if the TXT exists _dns_one_getrecord \"TXT\" \"$subdomain\" \"$txtvalue\" if [ -n \"$id\" ]; then _info \"$(__green \"Txt record with the same value found. Skip adding.\")\" return 0 fi _dns_one_addrecord \"TXT\" \"$subdomain\" \"$txtvalue\" if [ -z \"$id\" ]; then _err \"Add TXT record error.\" return 1 else _info \"$(__green \"Added, OK ($id)\")\" return 0 fi } dns_one_rm() { fulldomain=$1 txtvalue=$2 if ! _dns_one_login; then _err \"login failed\" return 1 fi _debug \"detect the root domain\" if ! _get_root \"$fulldomain\"; then _err \"root domain not found\" return 1 fi subdomain=\"${_sub_domain}\" maindomain=${_domain} _debug subdomain \"$subdomain\" _debug maindomain \"$maindomain\" #Check if the TXT exists _dns_one_getrecord \"TXT\" \"$subdomain\" \"$txtvalue\" if [ -z \"$id\" ]; then _err \"Txt record not found.\" return 1 fi # delete entry if _dns_one_delrecord \"$id\"; then _info \"$(__green Removed, OK)\" return 0 else _err \"Removing txt record error.\" return 1 fi } #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=\"$1\" i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi response=\"$(_get \"https://www.one.com/admin/api/domains/$h/dns/custom_records\")\" if ! _contains \"$response\" \"CRMRST_000302\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=$i i=$(_math \"$i\" + 1) done _err \"Unable to parse this domain\" return 1 } _dns_one_login() { # get credentials ONECOM_User=\"${ONECOM_User:-$(_readaccountconf_mutable ONECOM_User)}\" ONECOM_Password=\"${ONECOM_Password:-$(_readaccountconf_mutable ONECOM_Password)}\" if [ -z \"$ONECOM_User\" ] || [ -z \"$ONECOM_Password\" ]; then ONECOM_User=\"\" ONECOM_Password=\"\" _err \"You didn't specify a one.com username and password yet.\" _err \"Please create the key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable ONECOM_User \"$ONECOM_User\" _saveaccountconf_mutable ONECOM_Password \"$ONECOM_Password\" # Login with user and password postdata=\"loginDomain=true\" postdata=\"$postdata&displayUsername=$ONECOM_User\" postdata=\"$postdata&username=$ONECOM_User\" postdata=\"$postdata&targetDomain=\" postdata=\"$postdata&password1=$ONECOM_Password\" postdata=\"$postdata&loginTarget=\" #_debug postdata \"$postdata\" response=\"$(_post \"$postdata\" \"https://www.one.com/admin/login.do\" \"\" \"POST\" \"application/x-www-form-urlencoded\")\" #_debug response \"$response\" # Get SessionID JSESSIONID=\"$(grep \"OneSIDCrmAdmin\" \"$HTTP_HEADER\" | grep \"^[Ss]et-[Cc]ookie:\" | _head_n 1 | _egrep_o 'OneSIDCrmAdmin=[^;]*;' | tr -d ';')\" _debug jsessionid \"$JSESSIONID\" if [ -z \"$JSESSIONID\" ]; then _err \"error sessionid cookie not found\" return 1 fi export _H1=\"Cookie: ${JSESSIONID}\" return 0 } _dns_one_getrecord() { type=\"$1\" name=\"$2\" value=\"$3\" if [ -z \"$type\" ]; then type=\"TXT\" fi if [ -z \"$name\" ]; then _err \"Record name is empty.\" return 1 fi response=\"$(_get \"https://www.one.com/admin/api/domains/$maindomain/dns/custom_records\")\" response=\"$(echo \"$response\" | _normalizeJson)\" _debug response \"$response\" if [ -z \"${value}\" ]; then id=$(printf -- \"%s\" \"$response\" | sed -n \"s/.*{\\\"type\\\":\\\"dns_custom_records\\\",\\\"id\\\":\\\"\\([^\\\"]*\\)\\\",\\\"attributes\\\":{\\\"prefix\\\":\\\"${name}\\\",\\\"type\\\":\\\"${type}\\\",\\\"content\\\":\\\"[^\\\"]*\\\",\\\"priority\\\":0,\\\"ttl\\\":600}.*/\\1/p\") response=$(printf -- \"%s\" \"$response\" | sed -n \"s/.*{\\\"type\\\":\\\"dns_custom_records\\\",\\\"id\\\":\\\"[^\\\"]*\\\",\\\"attributes\\\":{\\\"prefix\\\":\\\"${name}\\\",\\\"type\\\":\\\"${type}\\\",\\\"content\\\":\\\"\\([^\\\"]*\\)\\\",\\\"priority\\\":0,\\\"ttl\\\":600}.*/\\1/p\") else id=$(printf -- \"%s\" \"$response\" | sed -n \"s/.*{\\\"type\\\":\\\"dns_custom_records\\\",\\\"id\\\":\\\"\\([^\\\"]*\\)\\\",\\\"attributes\\\":{\\\"prefix\\\":\\\"${name}\\\",\\\"type\\\":\\\"${type}\\\",\\\"content\\\":\\\"${value}\\\",\\\"priority\\\":0,\\\"ttl\\\":600}.*/\\1/p\") fi if [ -z \"$id\" ]; then return 1 fi return 0 } _dns_one_addrecord() { type=\"$1\" name=\"$2\" value=\"$3\" if [ -z \"$type\" ]; then type=\"TXT\" fi if [ -z \"$name\" ]; then _err \"Record name is empty.\" return 1 fi postdata=\"{\\\"type\\\":\\\"dns_custom_records\\\",\\\"attributes\\\":{\\\"priority\\\":0,\\\"ttl\\\":600,\\\"type\\\":\\\"${type}\\\",\\\"prefix\\\":\\\"${name}\\\",\\\"content\\\":\\\"${value}\\\"}}\" _debug postdata \"$postdata\" response=\"$(_post \"$postdata\" \"https://www.one.com/admin/api/domains/$maindomain/dns/custom_records\" \"\" \"POST\" \"application/json\")\" response=\"$(echo \"$response\" | _normalizeJson)\" _debug response \"$response\" id=$(echo \"$response\" | sed -n \"s/{\\\"result\\\":{\\\"data\\\":{\\\"type\\\":\\\"dns_custom_records\\\",\\\"id\\\":\\\"\\([^\\\"]*\\)\\\",\\\"attributes\\\":{\\\"prefix\\\":\\\"$subdomain\\\",\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"priority\\\":0,\\\"ttl\\\":600}}},\\\"metadata\\\":null}/\\1/p\") if [ -z \"$id\" ]; then return 1 else return 0 fi } _dns_one_delrecord() { id=\"$1\" if [ -z \"$id\" ]; then return 1 fi response=\"$(_post \"\" \"https://www.one.com/admin/api/domains/$maindomain/dns/custom_records/$id\" \"\" \"DELETE\" \"application/json\")\" response=\"$(echo \"$response\" | _normalizeJson)\" _debug response \"$response\" if [ \"$response\" = '{\"result\":null,\"metadata\":null}' ]; then return 0 else return 1 fi }"
        },
        {
            "filename": "file_262.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_262.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_online_info='online.net Domains: scaleway.com Site: online.net Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_online Options: ONLINE_API_KEY API Key Issues: github.com/acmesh-official/acme.sh/issues/2093 ' # Online API # https://console.online.net/en/api/ ######## Public functions ##################### ONLINE_API=\"https://api.online.net/api/v1\" #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_online_add() { fulldomain=$1 txtvalue=$2 if ! _online_check_config; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug _real_dns_version \"$_real_dns_version\" _info \"Creating temporary zone version\" _online_create_temporary_zone_version _info \"Enabling temporary zone version\" _online_enable_zone \"$_temporary_dns_version\" _info \"Adding record\" _online_create_TXT_record \"$_real_dns_version\" \"$_sub_domain\" \"$txtvalue\" _info \"Disabling temporary version\" _online_enable_zone \"$_real_dns_version\" _info \"Destroying temporary version\" _online_destroy_zone \"$_temporary_dns_version\" _info \"Record added.\" return 0 } #fulldomain dns_online_rm() { fulldomain=$1 txtvalue=$2 if ! _online_check_config; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug _real_dns_version \"$_real_dns_version\" _debug \"Getting txt records\" if ! _online_rest GET \"domain/$_domain/version/active\"; then return 1 fi rid=$(echo \"$response\" | _egrep_o \"\\\"id\\\":[0-9]+,\\\"name\\\":\\\"$_sub_domain\\\",\\\"data\\\":\\\"\\\\\\u0022$txtvalue\\\\\\u0022\\\"\" | cut -d ':' -f 2 | cut -d ',' -f 1) _debug rid \"$rid\" if [ -z \"$rid\" ]; then return 1 fi _info \"Creating temporary zone version\" _online_create_temporary_zone_version _info \"Enabling temporary zone version\" _online_enable_zone \"$_temporary_dns_version\" _info \"Removing DNS record\" _online_rest DELETE \"domain/$_domain/version/$_real_dns_version/zone/$rid\" _info \"Disabling temporary version\" _online_enable_zone \"$_real_dns_version\" _info \"Destroying temporary version\" _online_destroy_zone \"$_temporary_dns_version\" return 0 } #################### Private functions below ################################## _online_check_config() { ONLINE_API_KEY=\"${ONLINE_API_KEY:-$(_readaccountconf_mutable ONLINE_API_KEY)}\" if [ -z \"$ONLINE_API_KEY\" ]; then _err \"No API key specified for Online API.\" _err \"Create your key and export it as ONLINE_API_KEY\" return 1 fi if ! _online_rest GET \"domain/\"; then _err \"Invalid API key specified for Online API.\" return 1 fi _saveaccountconf_mutable ONLINE_API_KEY \"$ONLINE_API_KEY\" return 0 } #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi _online_rest GET \"domain/$h/version/active\" if ! _contains \"$response\" \"Domain not found\" >/dev/null; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" _real_dns_version=$(echo \"$response\" | _egrep_o '\"uuid_ref\":.*' | cut -d ':' -f 2 | cut -d '\"' -f 2) return 0 fi p=$i i=$(_math \"$i\" + 1) done _err \"Unable to retrive DNS zone matching this domain\" return 1 } # this function create a temporary zone version # as online.net does not allow updating an active version _online_create_temporary_zone_version() { _online_rest POST \"domain/$_domain/version\" \"name=acme.sh\" if [ \"$?\" != \"0\" ]; then return 1 fi _temporary_dns_version=$(echo \"$response\" | _egrep_o '\"uuid_ref\":.*' | cut -d ':' -f 2 | cut -d '\"' -f 2) # Creating a dummy record in this temporary version, because online.net doesn't accept enabling an empty version _online_create_TXT_record \"$_temporary_dns_version\" \"dummy.acme.sh\" \"dummy\" return 0 } _online_destroy_zone() { version_id=$1 _online_rest DELETE \"domain/$_domain/version/$version_id\" if [ \"$?\" != \"0\" ]; then return 1 fi return 0 } _online_enable_zone() { version_id=$1 _online_rest PATCH \"domain/$_domain/version/$version_id/enable\" if [ \"$?\" != \"0\" ]; then return 1 fi return 0 } _online_create_TXT_record() { version=$1 txt_name=$2 txt_value=$3 _online_rest POST \"domain/$_domain/version/$version/zone\" \"type=TXT&name=$txt_name&data=%22$txt_value%22&ttl=60&priority=0\" # Note : the normal, expected response SHOULD be \"Unknown method\". # this happens because the API HTTP response contains a Location: header, that redirect # to an unknown online.net endpoint. if [ \"$?\" != \"0\" ] || _contains \"$response\" \"Unknown method\" || _contains \"$response\" \"\\$ref\"; then return 0 else _err \"error $response\" return 1 fi } _online_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" _online_url=\"$ONLINE_API/$ep\" _debug2 _online_url \"$_online_url\" export _H1=\"Authorization: Bearer $ONLINE_API_KEY\" export _H2=\"X-Pretty-JSON: 1\" if [ \"$data\" ] || [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$_online_url\" \"\" \"$m\")\" else response=\"$(_get \"$_online_url\")\" fi if [ \"$?\" != \"0\" ] || _contains \"$response\" \"invalid_grant\" || _contains \"$response\" \"Method not allowed\"; then _err \"error $response\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_263.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_263.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_openprovider_info='OpenProvider.eu Site: OpenProvider.eu Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_openprovider Options: OPENPROVIDER_USER Username OPENPROVIDER_PASSWORDHASH Password hash Issues: github.com/acmesh-official/acme.sh/issues/2104 Author: Sylvia van Os ' OPENPROVIDER_API=\"https://api.openprovider.eu/\" #OPENPROVIDER_API=\"https://api.cte.openprovider.eu/\" # Test API ######## Public functions ##################### #Usage: dns_openprovider_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_openprovider_add() { fulldomain=\"$1\" txtvalue=\"$2\" OPENPROVIDER_USER=\"${OPENPROVIDER_USER:-$(_readaccountconf_mutable OPENPROVIDER_USER)}\" OPENPROVIDER_PASSWORDHASH=\"${OPENPROVIDER_PASSWORDHASH:-$(_readaccountconf_mutable OPENPROVIDER_PASSWORDHASH)}\" if [ -z \"$OPENPROVIDER_USER\" ] || [ -z \"$OPENPROVIDER_PASSWORDHASH\" ]; then _err \"You didn't specify the openprovider user and/or password hash.\" return 1 fi # save the username and password to the account conf file. _saveaccountconf_mutable OPENPROVIDER_USER \"$OPENPROVIDER_USER\" _saveaccountconf_mutable OPENPROVIDER_PASSWORDHASH \"$OPENPROVIDER_PASSWORDHASH\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_name \"$_domain_name\" _debug _domain_extension \"$_domain_extension\" _debug \"Getting current records\" existing_items=\"\" results_retrieved=0 while true; do _openprovider_request \"$(printf '<searchZoneRecordDnsRequest><name>%s.%s</name><offset>%s</offset></searchZoneRecordDnsRequest>' \"$_domain_name\" \"$_domain_extension\" \"$results_retrieved\")\" items=\"$response\" while true; do item=\"$(echo \"$items\" | _egrep_o '<openXML>.*<\\/openXML>' | sed -n 's/.*\\(<item>.*<\\/item>\\).*/\\1/p')\" _debug existing_items \"$existing_items\" _debug results_retrieved \"$results_retrieved\" _debug item \"$item\" if [ -z \"$item\" ]; then break fi tmpitem=\"$(echo \"$item\" | sed 's/\\*/\\\\*/g')\" items=\"$(echo \"$items\" | sed \"s|${tmpitem}||\")\" results_retrieved=\"$(_math \"$results_retrieved\" + 1)\" new_item=\"$(echo \"$item\" | sed -n 's/.*<item>.*\\(<name>\\(.*\\)\\.'\"$_domain_name\"'\\.'\"$_domain_extension\"'<\\/name>.*\\(<type>.*<\\/type>\\).*\\(<value>.*<\\/value>\\).*\\(<prio>.*<\\/prio>\\).*\\(<ttl>.*<\\/ttl>\\)\\).*<\\/item>.*/<item><name>\\2<\\/name>\\3\\4\\5\\6<\\/item>/p')\" if [ -z \"$new_item\" ]; then # Domain apex new_item=\"$(echo \"$item\" | sed -n 's/.*<item>.*\\(<name>\\(.*\\)'\"$_domain_name\"'\\.'\"$_domain_extension\"'<\\/name>.*\\(<type>.*<\\/type>\\).*\\(<value>.*<\\/value>\\).*\\(<prio>.*<\\/prio>\\).*\\(<ttl>.*<\\/ttl>\\)\\).*<\\/item>.*/<item><name>\\2<\\/name>\\3\\4\\5\\6<\\/item>/p')\" fi if [ -z \"$(echo \"$new_item\" | _egrep_o \".*<type>(A|AAAA|CNAME|MX|SPF|SRV|TXT|TLSA|SSHFP|CAA)<\\/type>.*\")\" ]; then _debug \"not an allowed record type, skipping\" \"$new_item\" continue fi existing_items=\"$existing_items$new_item\" done total=\"$(echo \"$response\" | _egrep_o '<total>.*?<\\/total>' | sed -n 's/.*<total>\\(.*\\)<\\/total>.*/\\1/p')\" _debug total \"$total\" if [ \"$results_retrieved\" -eq \"$total\" ]; then break fi done _debug \"Creating acme record\" acme_record=\"$(echo \"$fulldomain\" | sed -e \"s/.$_domain_name.$_domain_extension$//\")\" _openprovider_request \"$(printf '<modifyZoneDnsRequest><domain><name>%s</name><extension>%s</extension></domain><type>master</type><records><array>%s<item><name>%s</name><type>TXT</type><value>%s</value><ttl>600</ttl></item></array></records></modifyZoneDnsRequest>' \"$_domain_name\" \"$_domain_extension\" \"$existing_items\" \"$acme_record\" \"$txtvalue\")\" return 0 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_openprovider_rm() { fulldomain=\"$1\" txtvalue=\"$2\" OPENPROVIDER_USER=\"${OPENPROVIDER_USER:-$(_readaccountconf_mutable OPENPROVIDER_USER)}\" OPENPROVIDER_PASSWORDHASH=\"${OPENPROVIDER_PASSWORDHASH:-$(_readaccountconf_mutable OPENPROVIDER_PASSWORDHASH)}\" if [ -z \"$OPENPROVIDER_USER\" ] || [ -z \"$OPENPROVIDER_PASSWORDHASH\" ]; then _err \"You didn't specify the openprovider user and/or password hash.\" return 1 fi # save the username and password to the account conf file. _saveaccountconf_mutable OPENPROVIDER_USER \"$OPENPROVIDER_USER\" _saveaccountconf_mutable OPENPROVIDER_PASSWORDHASH \"$OPENPROVIDER_PASSWORDHASH\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_name \"$_domain_name\" _debug _domain_extension \"$_domain_extension\" _debug \"Getting current records\" existing_items=\"\" results_retrieved=0 while true; do _openprovider_request \"$(printf '<searchZoneRecordDnsRequest><name>%s.%s</name><offset>%s</offset></searchZoneRecordDnsRequest>' \"$_domain_name\" \"$_domain_extension\" \"$results_retrieved\")\" # Remove acme records from items items=\"$response\" while true; do item=\"$(echo \"$items\" | _egrep_o '<openXML>.*<\\/openXML>' | sed -n 's/.*\\(<item>.*<\\/item>\\).*/\\1/p')\" _debug existing_items \"$existing_items\" _debug results_retrieved \"$results_retrieved\" _debug item \"$item\" if [ -z \"$item\" ]; then break fi tmpitem=\"$(echo \"$item\" | sed 's/\\*/\\\\*/g')\" items=\"$(echo \"$items\" | sed \"s|${tmpitem}||\")\" results_retrieved=\"$(_math \"$results_retrieved\" + 1)\" if ! echo \"$item\" | grep -v \"$fulldomain\"; then _debug \"acme record, skipping\" \"$item\" continue fi new_item=\"$(echo \"$item\" | sed -n 's/.*<item>.*\\(<name>\\(.*\\)\\.'\"$_domain_name\"'\\.'\"$_domain_extension\"'<\\/name>.*\\(<type>.*<\\/type>\\).*\\(<value>.*<\\/value>\\).*\\(<prio>.*<\\/prio>\\).*\\(<ttl>.*<\\/ttl>\\)\\).*<\\/item>.*/<item><name>\\2<\\/name>\\3\\4\\5\\6<\\/item>/p')\" if [ -z \"$new_item\" ]; then # domain apex new_item=\"$(echo \"$item\" | sed -n 's/.*<item>.*\\(<name>\\(.*\\)'\"$_domain_name\"'\\.'\"$_domain_extension\"'<\\/name>.*\\(<type>.*<\\/type>\\).*\\(<value>.*<\\/value>\\).*\\(<prio>.*<\\/prio>\\).*\\(<ttl>.*<\\/ttl>\\)\\).*<\\/item>.*/<item><name>\\2<\\/name>\\3\\4\\5\\6<\\/item>/p')\" fi if [ -z \"$(echo \"$new_item\" | _egrep_o \".*<type>(A|AAAA|CNAME|MX|SPF|SRV|TXT|TLSA|SSHFP|CAA)<\\/type>.*\")\" ]; then _debug \"not an allowed record type, skipping\" \"$new_item\" continue fi existing_items=\"$existing_items$new_item\" done total=\"$(echo \"$response\" | _egrep_o '<total>.*?<\\/total>' | sed -n 's/.*<total>\\(.*\\)<\\/total>.*/\\1/p')\" _debug total \"$total\" if [ \"$results_retrieved\" -eq \"$total\" ]; then break fi done _debug \"Removing acme record\" _openprovider_request \"$(printf '<modifyZoneDnsRequest><domain><name>%s</name><extension>%s</extension></domain><type>master</type><records><array>%s</array></records></modifyZoneDnsRequest>' \"$_domain_name\" \"$_domain_extension\" \"$existing_items\")\" return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _domain_name=domain # _domain_extension=com _get_root() { domain=$1 i=2 results_retrieved=0 while true; do h=$(echo \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi _openprovider_request \"$(printf '<searchDomainRequest><domainNamePattern>%s</domainNamePattern><offset>%s</offset></searchDomainRequest>' \"$(echo \"$h\" | cut -d . -f 1)\" \"$results_retrieved\")\" items=\"$response\" while true; do item=\"$(echo \"$items\" | _egrep_o '<openXML>.*<\\/openXML>' | sed -n 's/.*\\(<domain>.*<\\/domain>\\).*/\\1/p')\" _debug existing_items \"$existing_items\" _debug results_retrieved \"$results_retrieved\" _debug item \"$item\" if [ -z \"$item\" ]; then break fi tmpitem=\"$(echo \"$item\" | sed 's/\\*/\\\\*/g')\" items=\"$(echo \"$items\" | sed \"s|${tmpitem}||\")\" results_retrieved=\"$(_math \"$results_retrieved\" + 1)\" _domain_name=\"$(echo \"$item\" | sed -n 's/.*<domain>.*<name>\\(.*\\)<\\/name>.*<\\/domain>.*/\\1/p')\" _domain_extension=\"$(echo \"$item\" | sed -n 's/.*<domain>.*<extension>\\(.*\\)<\\/extension>.*<\\/domain>.*/\\1/p')\" _debug _domain_name \"$_domain_name\" _debug _domain_extension \"$_domain_extension\" if [ \"$_domain_name.$_domain_extension\" = \"$h\" ]; then return 0 fi done total=\"$(echo \"$response\" | _egrep_o '<total>.*?<\\/total>' | sed -n 's/.*<total>\\(.*\\)<\\/total>.*/\\1/p')\" _debug total \"$total\" if [ \"$results_retrieved\" -eq \"$total\" ]; then results_retrieved=0 i=\"$(_math \"$i\" + 1)\" fi done return 1 } _openprovider_request() { request_xml=$1 xml_prefix='<?xml version=\"1.0\" encoding=\"UTF-8\"?>' xml_content=$(printf '<openXML><credentials><username>%s</username><hash>%s</hash></credentials>%s</openXML>' \"$OPENPROVIDER_USER\" \"$OPENPROVIDER_PASSWORDHASH\" \"$request_xml\") response=\"$(_post \"$(echo \"$xml_prefix$xml_content\" | tr -d '\\n')\" \"$OPENPROVIDER_API\" \"\" \"POST\" \"application/xml\")\" _debug response \"$response\" if ! _contains \"$response\" \"<openXML><reply><code>0</code>.*</reply></openXML>\"; then _err \"API request failed.\" return 1 fi }"
        },
        {
            "filename": "file_264.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_264.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_openstack_info='OpenStack Designate API Depends on OpenStackClient and python-desginateclient. You will require Keystone V3 credentials loaded into your environment, which could be either password or v3 application credential type. Site: docs.openstack.org/api-ref/dns/ Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_openstack Options: OS_AUTH_URL Auth URL. E.g. \"https://keystone.example.com:5000/\" OS_USERNAME Username OS_PASSWORD Password OS_PROJECT_NAME Project name OS_PROJECT_DOMAIN_NAME Project domain name. E.g. \"Default\" OS_USER_DOMAIN_NAME User domain name. E.g. \"Default\" Issues: github.com/acmesh-official/acme.sh/issues/3054 Author: Andy Botting <andy@andybotting.com> ' ######## Public functions ##################### # Usage: dns_openstack_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_openstack_add() { fulldomain=$1 txtvalue=$2 _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _dns_openstack_credentials || return $? _dns_openstack_check_setup || return $? _dns_openstack_find_zone || return $? _dns_openstack_get_recordset || return $? _debug _recordset_id \"$_recordset_id\" if [ -n \"$_recordset_id\" ]; then _dns_openstack_get_records || return $? _debug _records \"$_records\" fi _dns_openstack_create_recordset || return $? } # Usage: dns_openstack_rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" # Remove the txt record after validation. dns_openstack_rm() { fulldomain=$1 txtvalue=$2 _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" _dns_openstack_credentials || return $? _dns_openstack_check_setup || return $? _dns_openstack_find_zone || return $? _dns_openstack_get_recordset || return $? _debug _recordset_id \"$_recordset_id\" if [ -n \"$_recordset_id\" ]; then _dns_openstack_get_records || return $? _debug _records \"$_records\" fi _dns_openstack_delete_recordset || return $? } #################### Private functions below ################################## _dns_openstack_create_recordset() { if [ -z \"$_recordset_id\" ]; then _info \"Creating a new recordset\" if ! _recordset_id=$(openstack recordset create -c id -f value --type TXT --record=\"$txtvalue\" \"$_zone_id\" \"$fulldomain.\"); then _err \"No recordset ID found after create\" return 1 fi else _info \"Updating existing recordset\" # Build new list of --record=<rec> args for update _record_args=\"--record=$txtvalue\" for _rec in $_records; do _record_args=\"$_record_args --record=$_rec\" done # shellcheck disable=SC2086 if ! _recordset_id=$(openstack recordset set -c id -f value $_record_args \"$_zone_id\" \"$fulldomain.\"); then _err \"Recordset update failed\" return 1 fi fi _max_retries=60 _sleep_sec=5 _retry_times=0 while [ \"$_retry_times\" -lt \"$_max_retries\" ]; do _retry_times=$(_math \"$_retry_times\" + 1) _debug3 _retry_times \"$_retry_times\" _record_status=$(openstack recordset show -c status -f value \"$_zone_id\" \"$_recordset_id\") _info \"Recordset status is $_record_status\" if [ \"$_record_status\" = \"ACTIVE\" ]; then return 0 elif [ \"$_record_status\" = \"ERROR\" ]; then return 1 else _sleep $_sleep_sec fi done _err \"Recordset failed to become ACTIVE\" return 1 } _dns_openstack_delete_recordset() { if [ \"$_records\" = \"$txtvalue\" ]; then _info \"Only one record found, deleting recordset\" if ! openstack recordset delete \"$_zone_id\" \"$fulldomain.\" >/dev/null; then _err \"Failed to delete recordset\" return 1 fi else _info \"Found existing records, updating recordset\" # Build new list of --record=<rec> args for update _record_args=\"\" for _rec in $_records; do if [ \"$_rec\" = \"$txtvalue\" ]; then continue fi _record_args=\"$_record_args --record=$_rec\" done # shellcheck disable=SC2086 if ! openstack recordset set -c id -f value $_record_args \"$_zone_id\" \"$fulldomain.\" >/dev/null; then _err \"Recordset update failed\" return 1 fi fi } _dns_openstack_get_root() { # Take the full fqdn and strip away pieces until we get an exact zone name # match. For example, _acme-challenge.something.domain.com might need to go # into something.domain.com or domain.com _zone_name=$1 _zone_list=$2 while [ \"$_zone_name\" != \"\" ]; do _zone_name=\"$(echo \"$_zone_name\" | sed 's/[^.]*\\.*//')\" echo \"$_zone_list\" | while read -r id name; do if _startswith \"$_zone_name.\" \"$name\"; then echo \"$id\" fi done done | _head_n 1 } _dns_openstack_find_zone() { if ! _zone_list=\"$(openstack zone list -c id -c name -f value)\"; then _err \"Can't list zones. Check your OpenStack credentials\" return 1 fi _debug _zone_list \"$_zone_list\" if ! _zone_id=\"$(_dns_openstack_get_root \"$fulldomain\" \"$_zone_list\")\"; then _err \"Can't find a matching zone. Check your OpenStack credentials\" return 1 fi _debug _zone_id \"$_zone_id\" } _dns_openstack_get_records() { if ! _records=$(openstack recordset show -c records -f value \"$_zone_id\" \"$fulldomain.\"); then _err \"Failed to get records\" return 1 fi return 0 } _dns_openstack_get_recordset() { if ! _recordset_id=$(openstack recordset list -c id -f value --name \"$fulldomain.\" \"$_zone_id\"); then _err \"Failed to get recordset\" return 1 fi return 0 } _dns_openstack_check_setup() { if ! _exists openstack; then _err \"OpenStack client not found\" return 1 fi } _dns_openstack_credentials() { _debug \"Check OpenStack credentials\" # If we have OS_AUTH_URL already set in the environment, then assume we want # to use those, otherwise use stored credentials if [ -n \"$OS_AUTH_URL\" ]; then _debug \"OS_AUTH_URL env var found, using environment\" else _debug \"OS_AUTH_URL not found, loading stored credentials\" OS_AUTH_URL=\"${OS_AUTH_URL:-$(_readaccountconf_mutable OS_AUTH_URL)}\" OS_IDENTITY_API_VERSION=\"${OS_IDENTITY_API_VERSION:-$(_readaccountconf_mutable OS_IDENTITY_API_VERSION)}\" OS_AUTH_TYPE=\"${OS_AUTH_TYPE:-$(_readaccountconf_mutable OS_AUTH_TYPE)}\" OS_APPLICATION_CREDENTIAL_ID=\"${OS_APPLICATION_CREDENTIAL_ID:-$(_readaccountconf_mutable OS_APPLICATION_CREDENTIAL_ID)}\" OS_APPLICATION_CREDENTIAL_SECRET=\"${OS_APPLICATION_CREDENTIAL_SECRET:-$(_readaccountconf_mutable OS_APPLICATION_CREDENTIAL_SECRET)}\" OS_USERNAME=\"${OS_USERNAME:-$(_readaccountconf_mutable OS_USERNAME)}\" OS_PASSWORD=\"${OS_PASSWORD:-$(_readaccountconf_mutable OS_PASSWORD)}\" OS_PROJECT_NAME=\"${OS_PROJECT_NAME:-$(_readaccountconf_mutable OS_PROJECT_NAME)}\" OS_PROJECT_ID=\"${OS_PROJECT_ID:-$(_readaccountconf_mutable OS_PROJECT_ID)}\" OS_USER_DOMAIN_NAME=\"${OS_USER_DOMAIN_NAME:-$(_readaccountconf_mutable OS_USER_DOMAIN_NAME)}\" OS_USER_DOMAIN_ID=\"${OS_USER_DOMAIN_ID:-$(_readaccountconf_mutable OS_USER_DOMAIN_ID)}\" OS_PROJECT_DOMAIN_NAME=\"${OS_PROJECT_DOMAIN_NAME:-$(_readaccountconf_mutable OS_PROJECT_DOMAIN_NAME)}\" OS_PROJECT_DOMAIN_ID=\"${OS_PROJECT_DOMAIN_ID:-$(_readaccountconf_mutable OS_PROJECT_DOMAIN_ID)}\" fi # Check each var and either save or clear it depending on whether its set. # The helps us clear out old vars in the case where a user may want # to switch between password and app creds _debug \"OS_AUTH_URL\" \"$OS_AUTH_URL\" if [ -n \"$OS_AUTH_URL\" ]; then export OS_AUTH_URL _saveaccountconf_mutable OS_AUTH_URL \"$OS_AUTH_URL\" else unset OS_AUTH_URL _clearaccountconf SAVED_OS_AUTH_URL fi _debug \"OS_IDENTITY_API_VERSION\" \"$OS_IDENTITY_API_VERSION\" if [ -n \"$OS_IDENTITY_API_VERSION\" ]; then export OS_IDENTITY_API_VERSION _saveaccountconf_mutable OS_IDENTITY_API_VERSION \"$OS_IDENTITY_API_VERSION\" else unset OS_IDENTITY_API_VERSION _clearaccountconf SAVED_OS_IDENTITY_API_VERSION fi _debug \"OS_AUTH_TYPE\" \"$OS_AUTH_TYPE\" if [ -n \"$OS_AUTH_TYPE\" ]; then export OS_AUTH_TYPE _saveaccountconf_mutable OS_AUTH_TYPE \"$OS_AUTH_TYPE\" else unset OS_AUTH_TYPE _clearaccountconf SAVED_OS_AUTH_TYPE fi _debug \"OS_APPLICATION_CREDENTIAL_ID\" \"$OS_APPLICATION_CREDENTIAL_ID\" if [ -n \"$OS_APPLICATION_CREDENTIAL_ID\" ]; then export OS_APPLICATION_CREDENTIAL_ID _saveaccountconf_mutable OS_APPLICATION_CREDENTIAL_ID \"$OS_APPLICATION_CREDENTIAL_ID\" else unset OS_APPLICATION_CREDENTIAL_ID _clearaccountconf SAVED_OS_APPLICATION_CREDENTIAL_ID fi _secure_debug \"OS_APPLICATION_CREDENTIAL_SECRET\" \"$OS_APPLICATION_CREDENTIAL_SECRET\" if [ -n \"$OS_APPLICATION_CREDENTIAL_SECRET\" ]; then export OS_APPLICATION_CREDENTIAL_SECRET _saveaccountconf_mutable OS_APPLICATION_CREDENTIAL_SECRET \"$OS_APPLICATION_CREDENTIAL_SECRET\" else unset OS_APPLICATION_CREDENTIAL_SECRET _clearaccountconf SAVED_OS_APPLICATION_CREDENTIAL_SECRET fi _debug \"OS_USERNAME\" \"$OS_USERNAME\" if [ -n \"$OS_USERNAME\" ]; then export OS_USERNAME _saveaccountconf_mutable OS_USERNAME \"$OS_USERNAME\" else unset OS_USERNAME _clearaccountconf SAVED_OS_USERNAME fi _secure_debug \"OS_PASSWORD\" \"$OS_PASSWORD\" if [ -n \"$OS_PASSWORD\" ]; then export OS_PASSWORD _saveaccountconf_mutable OS_PASSWORD \"$OS_PASSWORD\" else unset OS_PASSWORD _clearaccountconf SAVED_OS_PASSWORD fi _debug \"OS_PROJECT_NAME\" \"$OS_PROJECT_NAME\" if [ -n \"$OS_PROJECT_NAME\" ]; then export OS_PROJECT_NAME _saveaccountconf_mutable OS_PROJECT_NAME \"$OS_PROJECT_NAME\" else unset OS_PROJECT_NAME _clearaccountconf SAVED_OS_PROJECT_NAME fi _debug \"OS_PROJECT_ID\" \"$OS_PROJECT_ID\" if [ -n \"$OS_PROJECT_ID\" ]; then export OS_PROJECT_ID _saveaccountconf_mutable OS_PROJECT_ID \"$OS_PROJECT_ID\" else unset OS_PROJECT_ID _clearaccountconf SAVED_OS_PROJECT_ID fi _debug \"OS_USER_DOMAIN_NAME\" \"$OS_USER_DOMAIN_NAME\" if [ -n \"$OS_USER_DOMAIN_NAME\" ]; then export OS_USER_DOMAIN_NAME _saveaccountconf_mutable OS_USER_DOMAIN_NAME \"$OS_USER_DOMAIN_NAME\" else unset OS_USER_DOMAIN_NAME _clearaccountconf SAVED_OS_USER_DOMAIN_NAME fi _debug \"OS_USER_DOMAIN_ID\" \"$OS_USER_DOMAIN_ID\" if [ -n \"$OS_USER_DOMAIN_ID\" ]; then export OS_USER_DOMAIN_ID _saveaccountconf_mutable OS_USER_DOMAIN_ID \"$OS_USER_DOMAIN_ID\" else unset OS_USER_DOMAIN_ID _clearaccountconf SAVED_OS_USER_DOMAIN_ID fi _debug \"OS_PROJECT_DOMAIN_NAME\" \"$OS_PROJECT_DOMAIN_NAME\" if [ -n \"$OS_PROJECT_DOMAIN_NAME\" ]; then export OS_PROJECT_DOMAIN_NAME _saveaccountconf_mutable OS_PROJECT_DOMAIN_NAME \"$OS_PROJECT_DOMAIN_NAME\" else unset OS_PROJECT_DOMAIN_NAME _clearaccountconf SAVED_OS_PROJECT_DOMAIN_NAME fi _debug \"OS_PROJECT_DOMAIN_ID\" \"$OS_PROJECT_DOMAIN_ID\" if [ -n \"$OS_PROJECT_DOMAIN_ID\" ]; then export OS_PROJECT_DOMAIN_ID _saveaccountconf_mutable OS_PROJECT_DOMAIN_ID \"$OS_PROJECT_DOMAIN_ID\" else unset OS_PROJECT_DOMAIN_ID _clearaccountconf SAVED_OS_PROJECT_DOMAIN_ID fi if [ \"$OS_AUTH_TYPE\" = \"v3applicationcredential\" ]; then # Application Credential auth if [ -z \"$OS_APPLICATION_CREDENTIAL_ID\" ] || [ -z \"$OS_APPLICATION_CREDENTIAL_SECRET\" ]; then _err \"When using OpenStack application credentials, OS_APPLICATION_CREDENTIAL_ID\" _err \"and OS_APPLICATION_CREDENTIAL_SECRET must be set.\" _err \"Please check your credentials and try again.\" return 1 fi else # Password auth if [ -z \"$OS_USERNAME\" ] || [ -z \"$OS_PASSWORD\" ]; then _err \"OpenStack username or password not found.\" _err \"Please check your credentials and try again.\" return 1 fi if [ -z \"$OS_PROJECT_NAME\" ] && [ -z \"$OS_PROJECT_ID\" ]; then _err \"When using password authentication, OS_PROJECT_NAME or\" _err \"OS_PROJECT_ID must be set.\" _err \"Please check your credentials and try again.\" return 1 fi fi return 0 }"
        },
        {
            "filename": "file_265.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_265.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_opnsense_info='OPNsense Server Site: docs.opnsense.org/development/api.html Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_opnsense Options: OPNs_Host Server Hostname. E.g. \"opnsense.example.com\" OPNs_Port Port. Default: \"443\". OPNs_Key API Key OPNs_Token API Token OPNs_Api_Insecure Insecure TLS. 0: check for cert validity, 1: always accept Issues: github.com/acmesh-official/acme.sh/issues/2480 ' ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"123456789ABCDEF0000000000000000000000000000000000000\" #fulldomain #txtvalue OPNs_DefaultPort=443 OPNs_DefaultApi_Insecure=0 dns_opnsense_add() { fulldomain=$1 txtvalue=$2 _opns_check_auth || return 1 if ! set_record \"$fulldomain\" \"$txtvalue\"; then return 1 fi return 0 } #fulldomain dns_opnsense_rm() { fulldomain=$1 txtvalue=$2 _opns_check_auth || return 1 if ! rm_record \"$fulldomain\" \"$txtvalue\"; then return 1 fi return 0 } set_record() { fulldomain=$1 new_challenge=$2 _info \"Adding record $fulldomain with challenge: $new_challenge\" _debug \"Detect root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain \"$_domain\" _debug _host \"$_host\" _debug _domainid \"$_domainid\" _return_str=\"\" _record_string=\"\" _build_record_string \"$_domainid\" \"$_host\" \"$new_challenge\" _uuid=\"\" if _existingchallenge \"$_domain\" \"$_host\" \"$new_challenge\"; then # Update if _opns_rest \"POST\" \"/record/setRecord/${_uuid}\" \"$_record_string\"; then _return_str=\"$response\" else return 1 fi else #create if _opns_rest \"POST\" \"/record/addRecord\" \"$_record_string\"; then _return_str=\"$response\" else return 1 fi fi if echo \"$_return_str\" | _egrep_o \"\\\"result\\\":\\\"saved\\\"\" >/dev/null; then _opns_rest \"POST\" \"/service/reconfigure\" \"{}\" _debug \"Record created\" else _err \"Error creating record $_record_string\" return 1 fi return 0 } rm_record() { fulldomain=$1 new_challenge=\"$2\" _info \"Remove record $fulldomain with challenge: $new_challenge\" _debug \"Detect root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain \"$_domain\" _debug _host \"$_host\" _debug _domainid \"$_domainid\" _uuid=\"\" if _existingchallenge \"$_domain\" \"$_host\" \"$new_challenge\"; then # Delete if _opns_rest \"POST\" \"/record/delRecord/${_uuid}\" \"\\{\\}\"; then if echo \"$_return_str\" | _egrep_o \"\\\"result\\\":\\\"deleted\\\"\" >/dev/null; then _opns_rest \"POST\" \"/service/reconfigure\" \"{}\" _debug \"Record deleted\" else _err \"Error deleting record $_host from domain $fulldomain\" return 1 fi else _err \"Error deleting record $_host from domain $fulldomain\" return 1 fi else _info \"Record not found, nothing to remove\" fi return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _domainid=domid #_domain=domain.com _get_root() { domain=$1 i=2 p=1 if _opns_rest \"GET\" \"/domain/searchPrimaryDomain\"; then _domain_response=\"$response\" else return 1 fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi _debug h \"$h\" id=$(echo \"$_domain_response\" | _egrep_o \"\\\"uuid\\\":\\\"[a-z0-9\\-]*\\\",\\\"enabled\\\":\\\"1\\\",\\\"type\\\":\\\"primary\\\",\\\"domainname\\\":\\\"${h}\\\"\" | cut -d ':' -f 2 | cut -d '\"' -f 2) if [ -n \"$id\" ]; then _debug id \"$id\" _host=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"${h}\" _domainid=\"${id}\" return 0 fi p=$i i=$(_math $i + 1) done _debug \"$domain not found\" return 1 } _opns_rest() { method=$1 ep=$2 data=$3 #Percent encode user and token key=$(echo \"$OPNs_Key\" | tr -d \"\\n\\r\" | _url_encode) token=$(echo \"$OPNs_Token\" | tr -d \"\\n\\r\" | _url_encode) opnsense_url=\"https://${key}:${token}@${OPNs_Host}:${OPNs_Port:-$OPNs_DefaultPort}/api/bind${ep}\" export _H1=\"Content-Type: application/json\" _debug2 \"Try to call api: https://${OPNs_Host}:${OPNs_Port:-$OPNs_DefaultPort}/api/bind${ep}\" if [ ! \"$method\" = \"GET\" ]; then _debug data \"$data\" export _H1=\"Content-Type: application/json\" response=\"$(_post \"$data\" \"$opnsense_url\" \"\" \"$method\")\" else export _H1=\"\" response=\"$(_get \"$opnsense_url\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 } _build_record_string() { _record_string=\"{\\\"record\\\":{\\\"enabled\\\":\\\"1\\\",\\\"domain\\\":\\\"$1\\\",\\\"name\\\":\\\"$2\\\",\\\"type\\\":\\\"TXT\\\",\\\"value\\\":\\\"$3\\\"}}\" } _existingchallenge() { if _opns_rest \"GET\" \"/record/searchRecord\"; then _record_response=\"$response\" else return 1 fi _uuid=\"\" _uuid=$(echo \"$_record_response\" | _egrep_o \"\\\"uuid\\\":\\\"[^\\\"]*\\\",\\\"enabled\\\":\\\"[01]\\\",\\\"domain\\\":\\\"$1\\\",\\\"name\\\":\\\"$2\\\",\\\"type\\\":\\\"TXT\\\",\\\"value\\\":\\\"$3\\\"\" | cut -d ':' -f 2 | cut -d '\"' -f 2) if [ -n \"$_uuid\" ]; then _debug uuid \"$_uuid\" return 0 fi _debug \"${2}.$1{1} record not found\" return 1 } _opns_check_auth() { OPNs_Host=\"${OPNs_Host:-$(_readaccountconf_mutable OPNs_Host)}\" OPNs_Port=\"${OPNs_Port:-$(_readaccountconf_mutable OPNs_Port)}\" OPNs_Key=\"${OPNs_Key:-$(_readaccountconf_mutable OPNs_Key)}\" OPNs_Token=\"${OPNs_Token:-$(_readaccountconf_mutable OPNs_Token)}\" OPNs_Api_Insecure=\"${OPNs_Api_Insecure:-$(_readaccountconf_mutable OPNs_Api_Insecure)}\" if [ -z \"$OPNs_Host\" ]; then _err \"You don't specify OPNsense address.\" return 1 else _saveaccountconf_mutable OPNs_Host \"$OPNs_Host\" fi if ! printf '%s' \"$OPNs_Port\" | grep '^[0-9]*$' >/dev/null; then _err 'OPNs_Port specified but not numeric value' return 1 elif [ -z \"$OPNs_Port\" ]; then _info \"OPNSense port not specified. Defaulting to using port $OPNs_DefaultPort\" else _saveaccountconf_mutable OPNs_Port \"$OPNs_Port\" fi if ! printf '%s' \"$OPNs_Api_Insecure\" | grep '^[01]$' >/dev/null; then _err 'OPNs_Api_Insecure specified but not 0/1 value' return 1 elif [ -n \"$OPNs_Api_Insecure\" ]; then _saveaccountconf_mutable OPNs_Api_Insecure \"$OPNs_Api_Insecure\" fi export HTTPS_INSECURE=\"${OPNs_Api_Insecure:-$OPNs_DefaultApi_Insecure}\" if [ -z \"$OPNs_Key\" ]; then _err \"you have not specified your OPNsense api key id.\" _err \"Please set OPNs_Key and try again.\" return 1 else _saveaccountconf_mutable OPNs_Key \"$OPNs_Key\" fi if [ -z \"$OPNs_Token\" ]; then _err \"you have not specified your OPNsense token.\" _err \"Please create OPNs_Token and try again.\" return 1 else _saveaccountconf_mutable OPNs_Token \"$OPNs_Token\" fi if ! _opns_rest \"GET\" \"/general/get\"; then _err \"Call to OPNsense API interface failed. Unable to access OPNsense API.\" return 1 fi return 0 }"
        },
        {
            "filename": "file_266.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_266.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_ovh_info='OVH.com Domains: kimsufi.com soyoustart.com Site: OVH.com Docs: github.com/acmesh-official/acme.sh/wiki/How-to-use-OVH-domain-api Options: OVH_END_POINT Endpoint. \"ovh-eu\", \"ovh-us\", \"ovh-ca\", \"kimsufi-eu\", \"kimsufi-ca\", \"soyoustart-eu\", \"soyoustart-ca\" or raw URL. Default: \"ovh-eu\". OVH_AK Application Key OVH_AS Application Secret OVH_CK Consumer Key ' #OVH_END_POINT=ovh-eu #'ovh-eu' OVH_EU='https://eu.api.ovh.com/1.0' #'ovh-us' OVH_US='https://api.us.ovhcloud.com/1.0' #'ovh-ca': OVH_CA='https://ca.api.ovh.com/1.0' #'kimsufi-eu' KSF_EU='https://eu.api.kimsufi.com/1.0' #'kimsufi-ca' KSF_CA='https://ca.api.kimsufi.com/1.0' #'soyoustart-eu' SYS_EU='https://eu.api.soyoustart.com/1.0' #'soyoustart-ca' SYS_CA='https://ca.api.soyoustart.com/1.0' wiki=\"https://github.com/acmesh-official/acme.sh/wiki/How-to-use-OVH-domain-api\" ovh_success=\"https://github.com/acmesh-official/acme.sh/wiki/OVH-Success\" _ovh_get_api() { _ogaep=\"$1\" case \"${_ogaep}\" in ovh-eu | ovheu) printf \"%s\" $OVH_EU return ;; ovh-us | ovhus) printf \"%s\" $OVH_US return ;; ovh-ca | ovhca) printf \"%s\" $OVH_CA return ;; kimsufi-eu | kimsufieu) printf \"%s\" $KSF_EU return ;; kimsufi-ca | kimsufica) printf \"%s\" $KSF_CA return ;; soyoustart-eu | soyoustarteu) printf \"%s\" $SYS_EU return ;; soyoustart-ca | soyoustartca) printf \"%s\" $SYS_CA return ;; # raw API url starts with https:// https*) printf \"%s\" \"$1\" return ;; *) _err \"Unknown endpoint : $1\" return 1 ;; esac } _initAuth() { OVH_AK=\"${OVH_AK:-$(_readaccountconf_mutable OVH_AK)}\" OVH_AS=\"${OVH_AS:-$(_readaccountconf_mutable OVH_AS)}\" if [ -z \"$OVH_AK\" ] || [ -z \"$OVH_AS\" ]; then OVH_AK=\"\" OVH_AS=\"\" _err \"You don't specify OVH application key and application secret yet.\" _err \"Please create you key and try again.\" return 1 fi if [ \"$OVH_AK\" != \"$(_readaccountconf OVH_AK)\" ]; then _info \"It seems that your ovh key is changed, let's clear consumer key first.\" _clearaccountconf_mutable OVH_CK fi _saveaccountconf_mutable OVH_AK \"$OVH_AK\" _saveaccountconf_mutable OVH_AS \"$OVH_AS\" OVH_END_POINT=\"${OVH_END_POINT:-$(_readaccountconf_mutable OVH_END_POINT)}\" if [ -z \"$OVH_END_POINT\" ]; then OVH_END_POINT=\"ovh-eu\" fi _info \"Using OVH endpoint: $OVH_END_POINT\" if [ \"$OVH_END_POINT\" != \"ovh-eu\" ]; then _saveaccountconf_mutable OVH_END_POINT \"$OVH_END_POINT\" fi OVH_API=\"$(_ovh_get_api $OVH_END_POINT)\" _debug OVH_API \"$OVH_API\" OVH_CK=\"${OVH_CK:-$(_readaccountconf_mutable OVH_CK)}\" if [ -z \"$OVH_CK\" ]; then _info \"OVH consumer key is empty, Let's get one:\" if ! _ovh_authentication; then _err \"Can not get consumer key.\" fi #return and wait for retry. return 1 fi _saveaccountconf_mutable OVH_CK \"$OVH_CK\" _info \"Checking authentication\" if ! _ovh_rest GET \"domain\" || _contains \"$response\" \"INVALID_CREDENTIAL\" || _contains \"$response\" \"NOT_CREDENTIAL\"; then _err \"The consumer key is invalid: $OVH_CK\" _err \"Please retry to create a new one.\" _clearaccountconf_mutable OVH_CK return 1 fi _info \"Consumer key is ok.\" return 0 } ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_ovh_add() { fulldomain=$1 txtvalue=$2 if ! _initAuth; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if _ovh_rest POST \"domain/zone/$_domain/record\" \"{\\\"fieldType\\\":\\\"TXT\\\",\\\"subDomain\\\":\\\"$_sub_domain\\\",\\\"target\\\":\\\"$txtvalue\\\",\\\"ttl\\\":60}\"; then if _contains \"$response\" \"$txtvalue\"; then _ovh_rest POST \"domain/zone/$_domain/refresh\" _debug \"Refresh:$response\" _info \"Added, sleep 10 seconds.\" _sleep 10 return 0 fi fi _err \"Add txt record error.\" return 1 } #fulldomain dns_ovh_rm() { fulldomain=$1 txtvalue=$2 if ! _initAuth; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" if ! _ovh_rest GET \"domain/zone/$_domain/record?fieldType=TXT&subDomain=$_sub_domain\"; then return 1 fi for rid in $(echo \"$response\" | tr '][,' ' '); do _debug rid \"$rid\" if ! _ovh_rest GET \"domain/zone/$_domain/record/$rid\"; then return 1 fi if _contains \"$response\" \"\\\"target\\\":\\\"$txtvalue\\\"\"; then _debug \"Found txt id:$rid\" if ! _ovh_rest DELETE \"domain/zone/$_domain/record/$rid\"; then return 1 fi _ovh_rest POST \"domain/zone/$_domain/refresh\" _debug \"Refresh:$response\" return 0 fi done return 1 } #################### Private functions below ################################## _ovh_authentication() { _H1=\"X-Ovh-Application: $OVH_AK\" _H2=\"Content-type: application/json\" _H3=\"\" _H4=\"\" _ovhdata='{\"accessRules\": [{\"method\": \"GET\",\"path\": \"/auth/time\"},{\"method\": \"GET\",\"path\": \"/domain\"},{\"method\": \"GET\",\"path\": \"/domain/zone/*\"},{\"method\": \"GET\",\"path\": \"/domain/zone/*/record\"},{\"method\": \"POST\",\"path\": \"/domain/zone/*/record\"},{\"method\": \"POST\",\"path\": \"/domain/zone/*/refresh\"},{\"method\": \"PUT\",\"path\": \"/domain/zone/*/record/*\"},{\"method\": \"DELETE\",\"path\": \"/domain/zone/*/record/*\"}],\"redirection\":\"'$ovh_success'\"}' response=\"$(_post \"$_ovhdata\" \"$OVH_API/auth/credential\")\" _debug3 response \"$response\" validationUrl=\"$(echo \"$response\" | _egrep_o \"validationUrl\\\":\\\"[^\\\"]*\\\"\" | _egrep_o \"http.*\\\"\" | tr -d '\"')\" if [ -z \"$validationUrl\" ]; then _err \"Unable to get validationUrl\" return 1 fi _debug validationUrl \"$validationUrl\" consumerKey=\"$(echo \"$response\" | _egrep_o \"consumerKey\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d '\"')\" if [ -z \"$consumerKey\" ]; then _err \"Unable to get consumerKey\" return 1 fi _secure_debug consumerKey \"$consumerKey\" OVH_CK=\"$consumerKey\" _saveaccountconf_mutable OVH_CK \"$OVH_CK\" _info \"Please open this link to do authentication: $(__green \"$validationUrl\")\" _info \"Here is a guide for you: $(__green \"$wiki\")\" _info \"Please retry after the authentication is done.\" } #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi if ! _ovh_rest GET \"domain/zone/$h\"; then return 1 fi if ! _contains \"$response\" \"This service does not exist\" >/dev/null && ! _contains \"$response\" \"This call has not been granted\" >/dev/null && ! _contains \"$response\" \"NOT_GRANTED_CALL\" >/dev/null; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _ovh_timestamp() { _H1=\"\" _H2=\"\" _H3=\"\" _H4=\"\" _H5=\"\" _get \"$OVH_API/auth/time\" \"\" 30 } _ovh_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" _ovh_url=\"$OVH_API/$ep\" _debug2 _ovh_url \"$_ovh_url\" _ovh_t=\"$(_ovh_timestamp)\" _debug2 _ovh_t \"$_ovh_t\" _ovh_p=\"$OVH_AS+$OVH_CK+$m+$_ovh_url+$data+$_ovh_t\" _secure_debug _ovh_p \"$_ovh_p\" _ovh_hex=\"$(printf \"%s\" \"$_ovh_p\" | _digest sha1 hex)\" _debug2 _ovh_hex \"$_ovh_hex\" export _H1=\"X-Ovh-Application: $OVH_AK\" export _H2=\"X-Ovh-Signature: \\$1\\$$_ovh_hex\" _debug2 _H2 \"$_H2\" export _H3=\"X-Ovh-Timestamp: $_ovh_t\" export _H4=\"X-Ovh-Consumer: $OVH_CK\" export _H5=\"Content-Type: application/json;charset=utf-8\" if [ \"$data\" ] || [ \"$m\" = \"POST\" ] || [ \"$m\" = \"PUT\" ] || [ \"$m\" = \"DELETE\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$_ovh_url\" \"\" \"$m\")\" else response=\"$(_get \"$_ovh_url\")\" fi if [ \"$?\" != \"0\" ] || _contains \"$response\" \"INVALID_CREDENTIAL\"; then _err \"error $response\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_267.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_267.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_pdns_info='PowerDNS Server API Site: PowerDNS.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_pdns Options: PDNS_Url API URL. E.g. \"http://ns.example.com:8081\" PDNS_ServerId Server ID. E.g. \"localhost\" PDNS_Token API Token PDNS_Ttl=60 Domain TTL. Default: \"60\". ' DEFAULT_PDNS_TTL=60 ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"123456789ABCDEF0000000000000000000000000000000000000\" #fulldomain #txtvalue dns_pdns_add() { fulldomain=$1 txtvalue=$2 if [ -z \"$PDNS_Url\" ]; then PDNS_Url=\"\" _err \"You don't specify PowerDNS address.\" _err \"Please set PDNS_Url and try again.\" return 1 fi if [ -z \"$PDNS_ServerId\" ]; then PDNS_ServerId=\"\" _err \"You don't specify PowerDNS server id.\" _err \"Please set you PDNS_ServerId and try again.\" return 1 fi if [ -z \"$PDNS_Token\" ]; then PDNS_Token=\"\" _err \"You don't specify PowerDNS token.\" _err \"Please create you PDNS_Token and try again.\" return 1 fi if [ -z \"$PDNS_Ttl\" ]; then PDNS_Ttl=\"$DEFAULT_PDNS_TTL\" fi #save the api addr and key to the account conf file. _saveaccountconf PDNS_Url \"$PDNS_Url\" _saveaccountconf PDNS_ServerId \"$PDNS_ServerId\" _saveaccountconf PDNS_Token \"$PDNS_Token\" if [ \"$PDNS_Ttl\" != \"$DEFAULT_PDNS_TTL\" ]; then _saveaccountconf PDNS_Ttl \"$PDNS_Ttl\" fi _debug \"Detect root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain \"$_domain\" if ! set_record \"$_domain\" \"$fulldomain\" \"$txtvalue\"; then return 1 fi return 0 } #fulldomain dns_pdns_rm() { fulldomain=$1 txtvalue=$2 if [ -z \"$PDNS_Ttl\" ]; then PDNS_Ttl=\"$DEFAULT_PDNS_TTL\" fi _debug \"Detect root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain \"$_domain\" if ! rm_record \"$_domain\" \"$fulldomain\" \"$txtvalue\"; then return 1 fi return 0 } set_record() { _info \"Adding record\" root=$1 full=$2 new_challenge=$3 _record_string=\"\" _build_record_string \"$new_challenge\" _list_existingchallenges for oldchallenge in $_existing_challenges; do _build_record_string \"$oldchallenge\" done if ! _pdns_rest \"PATCH\" \"/api/v1/servers/$PDNS_ServerId/zones/$root\" \"{\\\"rrsets\\\": [{\\\"changetype\\\": \\\"REPLACE\\\", \\\"name\\\": \\\"$full.\\\", \\\"type\\\": \\\"TXT\\\", \\\"ttl\\\": $PDNS_Ttl, \\\"records\\\": [$_record_string]}]}\" \"application/json\"; then _err \"Set txt record error.\" return 1 fi if ! notify_slaves \"$root\"; then return 1 fi return 0 } rm_record() { _info \"Remove record\" root=$1 full=$2 txtvalue=$3 #Enumerate existing acme challenges _list_existingchallenges if _contains \"$_existing_challenges\" \"$txtvalue\"; then #Delete all challenges (PowerDNS API does not allow to delete content) if ! _pdns_rest \"PATCH\" \"/api/v1/servers/$PDNS_ServerId/zones/$root\" \"{\\\"rrsets\\\": [{\\\"changetype\\\": \\\"DELETE\\\", \\\"name\\\": \\\"$full.\\\", \\\"type\\\": \\\"TXT\\\"}]}\" \"application/json\"; then _err \"Delete txt record error.\" return 1 fi _record_string=\"\" #If the only existing challenge was the challenge to delete: nothing to do if ! [ \"$_existing_challenges\" = \"$txtvalue\" ]; then for oldchallenge in $_existing_challenges; do #Build up the challenges to re-add, ommitting the one what should be deleted if ! [ \"$oldchallenge\" = \"$txtvalue\" ]; then _build_record_string \"$oldchallenge\" fi done #Recreate the existing challenges if ! _pdns_rest \"PATCH\" \"/api/v1/servers/$PDNS_ServerId/zones/$root\" \"{\\\"rrsets\\\": [{\\\"changetype\\\": \\\"REPLACE\\\", \\\"name\\\": \\\"$full.\\\", \\\"type\\\": \\\"TXT\\\", \\\"ttl\\\": $PDNS_Ttl, \\\"records\\\": [$_record_string]}]}\" \"application/json\"; then _err \"Set txt record error.\" return 1 fi fi if ! notify_slaves \"$root\"; then return 1 fi else _info \"Record not found, nothing to remove\" fi return 0 } notify_slaves() { root=$1 if ! _pdns_rest \"PUT\" \"/api/v1/servers/$PDNS_ServerId/zones/$root/notify\"; then _err \"Notify slaves error.\" return 1 fi return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _domain=domain.com _get_root() { domain=$1 i=1 if _pdns_rest \"GET\" \"/api/v1/servers/$PDNS_ServerId/zones\"; then _zones_response=$(echo \"$response\" | _normalizeJson) fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if _contains \"$_zones_response\" \"\\\"name\\\":\\\"$h.\\\"\"; then _domain=\"$h.\" if [ -z \"$h\" ]; then _domain=\"=2E\" fi return 0 fi if [ -z \"$h\" ]; then return 1 fi i=$(_math $i + 1) done _debug \"$domain not found\" return 1 } _pdns_rest() { method=$1 ep=$2 data=$3 ct=$4 export _H1=\"X-API-Key: $PDNS_Token\" if [ ! \"$method\" = \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$PDNS_Url$ep\" \"\" \"$method\" \"$ct\")\" else response=\"$(_get \"$PDNS_Url$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 } _build_record_string() { _record_string=\"${_record_string:+${_record_string}, }{\\\"content\\\": \\\"\\\\\\\"${1}\\\\\\\"\\\", \\\"disabled\\\": false}\" } _list_existingchallenges() { _pdns_rest \"GET\" \"/api/v1/servers/$PDNS_ServerId/zones/$root\" _existing_challenges=$(echo \"$response\" | _normalizeJson | _egrep_o \"\\\"name\\\":\\\"${fulldomain}[^]]*}\" | _egrep_o 'content\\\":\\\"\\\\\"[^\\\\]*' | sed -n 's/^content\":\"\\\\\"//p') }"
        },
        {
            "filename": "file_268.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_268.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_pleskxml_info='Plesk Server API Site: Plesk.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_pleskxml Options: pleskxml_uri Plesk server API URL. E.g. \"https://your-plesk-server.net:8443/enterprise/control/agent.php\" pleskxml_user Username pleskxml_pass Password Issues: github.com/acmesh-official/acme.sh/issues/2577 Author: Stilez, <https://github.com/romanlum> ' ## Plesk XML API described at: ## https://docs.plesk.com/en-US/12.5/api-rpc/about-xml-api.28709 ## and more specifically: https://docs.plesk.com/en-US/12.5/api-rpc/reference.28784 ## Note: a DNS ID with host = empty string is OK for this API, see ## https://docs.plesk.com/en-US/obsidian/api-rpc/about-xml-api/reference/managing-dns/managing-dns-records/adding-dns-record.34798 ## For example, to add a TXT record to DNS alias domain \"acme-alias.com\" would be a valid Plesk action. ## So this API module can handle such a request, if needed. ## For ACME v2 purposes, new TXT records are appended when added, and removing one TXT record will not affect any other TXT records. ## The user credentials (username+password) and URL/URI for the Plesk XML API must be set by the user #################### INTERNAL VARIABLES + NEWLINE + API TEMPLATES ################################## pleskxml_init_checks_done=0 # Variable containing bare newline - not a style issue # shellcheck disable=SC1004 NEWLINE='\\ ' pleskxml_tplt_get_domains=\"<packet><webspace><get><filter/><dataset><gen_info/></dataset></get></webspace></packet>\" # Get a list of domains that PLESK can manage, so we can check root domain + host for acme.sh # Also used to test credentials and URI. # No params. pleskxml_tplt_get_additional_domains=\"<packet><site><get><filter/><dataset><gen_info/></dataset></get></site></packet>\" # Get a list of additional domains that PLESK can manage, so we can check root domain + host for acme.sh # No params. pleskxml_tplt_get_dns_records=\"<packet><dns><get_rec><filter><site-id>%s</site-id></filter></get_rec></dns></packet>\" # Get all DNS records for a Plesk domain ID. # PARAM = Plesk domain id to query pleskxml_tplt_add_txt_record=\"<packet><dns><add_rec><site-id>%s</site-id><type>TXT</type><host>%s</host><value>%s</value></add_rec></dns></packet>\" # Add a TXT record to a domain. # PARAMS = (1) Plesk internal domain ID, (2) \"hostname\" for the new record, eg '_acme_challenge', (3) TXT record value pleskxml_tplt_rmv_dns_record=\"<packet><dns><del_rec><filter><id>%s</id></filter></del_rec></dns></packet>\" # Delete a specific TXT record from a domain. # PARAM = the Plesk internal ID for the DNS record to be deleted #################### Public functions ################################## #Usage: dns_pleskxml_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_pleskxml_add() { fulldomain=$1 txtvalue=$2 _info \"Entering dns_pleskxml_add() to add TXT record '$txtvalue' to domain '$fulldomain'...\" # Get credentials if not already checked, and confirm we can log in to Plesk XML API if ! _credential_check; then return 1 fi # Get root and subdomain details, and Plesk domain ID if ! _pleskxml_get_root_domain \"$fulldomain\"; then return 1 fi _debug 'Credentials OK, and domain identified. Calling Plesk XML API to add TXT record' # printf using template in a variable - not a style issue # shellcheck disable=SC2059 request=\"$(printf \"$pleskxml_tplt_add_txt_record\" \"$root_domain_id\" \"$sub_domain_name\" \"$txtvalue\")\" if ! _call_api \"$request\"; then return 1 fi # OK, we should have added a TXT record. Let's check and return success if so. # All that should be left in the result, is one section, containing <result><status>ok</status><id>NEW_DNS_RECORD_ID</id></result> results=\"$(_api_response_split \"$pleskxml_prettyprint_result\" 'result' '<status>')\" if ! _value \"$results\" | grep '<status>ok</status>' | grep '<id>[0-9]\\{1,\\}</id>' >/dev/null; then # Error - doesn't contain expected string. Something's wrong. _err 'Error when calling Plesk XML API.' _err 'The result did not contain the expected <id>XXXXX</id> section, or contained other values as well.' _err 'This is unexpected: something has gone wrong.' _err 'The full response was:' _err \"$pleskxml_prettyprint_result\" return 1 fi recid=\"$(_value \"$results\" | grep '<id>[0-9]\\{1,\\}</id>' | sed 's/^.*<id>\\([0-9]\\{1,\\}\\)<\\/id>.*$/\\1/')\" _info \"Success. TXT record appears to be correctly added (Plesk record ID=$recid). Exiting dns_pleskxml_add().\" return 0 } #Usage: dns_pleskxml_rm _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_pleskxml_rm() { fulldomain=$1 txtvalue=$2 _info \"Entering dns_pleskxml_rm() to remove TXT record '$txtvalue' from domain '$fulldomain'...\" # Get credentials if not already checked, and confirm we can log in to Plesk XML API if ! _credential_check; then return 1 fi # Get root and subdomain details, and Plesk domain ID if ! _pleskxml_get_root_domain \"$fulldomain\"; then return 1 fi _debug 'Credentials OK, and domain identified. Calling Plesk XML API to get list of TXT records and their IDs' # printf using template in a variable - not a style issue # shellcheck disable=SC2059 request=\"$(printf \"$pleskxml_tplt_get_dns_records\" \"$root_domain_id\")\" if ! _call_api \"$request\"; then return 1 fi # Reduce output to one line per DNS record, filtered for TXT records with a record ID only (which they should all have) # Also strip out spaces between tags, redundant <data> and </data> group tags and any <self-closing/> tags reclist=\"$( _api_response_split \"$pleskxml_prettyprint_result\" 'result' '<status>ok</status>' | sed 's# \\{1,\\}<\\([a-zA-Z]\\)#<\\1#g;s#</\\{0,1\\}data>##g;s#<[a-z][^/<>]*/>##g' | grep \"<site-id>${root_domain_id}</site-id>\" | grep '<id>[0-9]\\{1,\\}</id>' | grep '<type>TXT</type>' )\" if [ -z \"$reclist\" ]; then _err \"No TXT records found for root domain $fulldomain (Plesk domain ID ${root_domain_id}). Exiting.\" return 1 fi _debug \"Got list of DNS TXT records for root Plesk domain ID ${root_domain_id} of root domain $fulldomain:\" _debug \"$reclist\" # Extracting the id of the TXT record for the full domain (NOT case-sensitive) and corresponding value recid=\"$( _value \"$reclist\" | grep -i \"<host>${fulldomain}.</host>\" | grep \"<value>${txtvalue}</value>\" | sed 's/^.*<id>\\([0-9]\\{1,\\}\\)<\\/id>.*$/\\1/' )\" _debug \"Got id from line: $recid\" if ! _value \"$recid\" | grep '^[0-9]\\{1,\\}$' >/dev/null; then _err \"DNS records for root domain '${fulldomain}.' (Plesk ID ${root_domain_id}) + host '${sub_domain_name}' do not contain the TXT record '${txtvalue}'\" _err \"Cannot delete TXT record. Exiting.\" return 1 fi _debug \"Found Plesk record ID for target text string '${txtvalue}': ID=${recid}\" _debug 'Calling Plesk XML API to remove TXT record' # printf using template in a variable - not a style issue # shellcheck disable=SC2059 request=\"$(printf \"$pleskxml_tplt_rmv_dns_record\" \"$recid\")\" if ! _call_api \"$request\"; then return 1 fi # OK, we should have removed a TXT record. Let's check and return success if so. # All that should be left in the result, is one section, containing <result><status>ok</status><id>PLESK_DELETED_DNS_RECORD_ID</id></result> results=\"$(_api_response_split \"$pleskxml_prettyprint_result\" 'result' '<status>')\" if ! _value \"$results\" | grep '<status>ok</status>' | grep '<id>[0-9]\\{1,\\}</id>' >/dev/null; then # Error - doesn't contain expected string. Something's wrong. _err 'Error when calling Plesk XML API.' _err 'The result did not contain the expected <id>XXXXX</id> section, or contained other values as well.' _err 'This is unexpected: something has gone wrong.' _err 'The full response was:' _err \"$pleskxml_prettyprint_result\" return 1 fi _info \"Success. TXT record appears to be correctly removed. Exiting dns_pleskxml_rm().\" return 0 } #################### Private functions below (utility functions) ################################## # Outputs value of a variable without additional newlines etc _value() { printf '%s' \"$1\" } # Outputs value of a variable (FQDN) and cuts it at 2 specified '.' delimiters, returning the text in between # $1, $2 = where to cut # $3 = FQDN _valuecut() { printf '%s' \"$3\" | cut -d . -f \"${1}-${2}\" } # Counts '.' present in a domain name or other string # $1 = domain name _countdots() { _value \"$1\" | tr -dc '.' | wc -c | sed 's/ //g' } # Cleans up an API response, splits it \"one line per item in the response\" and greps for a string that in the context, identifies \"useful\" lines # $1 - result string from API # $2 - plain text tag to resplit on (usually \"result\" or \"domain\"). NOT REGEX # $3 - basic regex to recognise useful return lines # note: $3 matches via basic NOT extended regex (BRE), as extended regex capabilities not needed at the moment. # Last line could change to <sed -n '/.../p'> instead, with suitable escaping of ['\"/$], # if future Plesk XML API changes ever require extended regex _api_response_split() { printf '%s' \"$1\" | sed 's/^ +//;s/ +$//' | tr -d '\\n\\r' | sed \"s/<\\/\\{0,1\\}$2>/${NEWLINE}/g\" | grep \"$3\" } #################### Private functions below (DNS functions) ################################## # Calls Plesk XML API, and checks results for obvious issues _call_api() { request=\"$1\" errtext='' _debug 'Entered _call_api(). Calling Plesk XML API with request:' _debug \"'$request'\" export _H1=\"HTTP_AUTH_LOGIN: $pleskxml_user\" export _H2=\"HTTP_AUTH_PASSWD: $pleskxml_pass\" export _H3=\"content-Type: text/xml\" export _H4=\"HTTP_PRETTY_PRINT: true\" pleskxml_prettyprint_result=\"$(_post \"${request}\" \"$pleskxml_uri\" \"\" \"POST\")\" pleskxml_retcode=\"$?\" _debug 'The responses from the Plesk XML server were:' _debug \"retcode=$pleskxml_retcode. Literal response:\" _debug \"'$pleskxml_prettyprint_result'\" # Detect any <status> that isn't \"ok\". None of the used calls should fail if the API is working correctly. # Also detect if there simply aren't any status lines (null result?) and report that, as well. # Remove <data></data> structure from result string, since it might contain <status> values that are related to the status of the domain and not to the API request statuslines_count_total=\"$(echo \"$pleskxml_prettyprint_result\" | sed '/<data>/,/<\\/data>/d' | grep -c '^ *<status>[^<]*</status> *$')\" statuslines_count_okay=\"$(echo \"$pleskxml_prettyprint_result\" | sed '/<data>/,/<\\/data>/d' | grep -c '^ *<status>ok</status> *$')\" _debug \"statuslines_count_total=$statuslines_count_total.\" _debug \"statuslines_count_okay=$statuslines_count_okay.\" if [ -z \"$statuslines_count_total\" ]; then # We have no status lines at all. Results are empty errtext='The Plesk XML API unexpectedly returned an empty set of results for this call.' elif [ \"$statuslines_count_okay\" -ne \"$statuslines_count_total\" ]; then # We have some status lines that aren't \"ok\". Any available details are in API response fields \"status\" \"errcode\" and \"errtext\" # Workaround for basic regex: # - filter output to keep only lines like this: \"SPACES<TAG>text</TAG>SPACES\" (shouldn't be necessary with prettyprint but guarantees subsequent code is ok) # - then edit the 3 \"useful\" error tokens individually and remove closing tags on all lines # - then filter again to remove all lines not edited (which will be the lines not starting A-Z) errtext=\"$( _value \"$pleskxml_prettyprint_result\" | grep '^ *<[a-z]\\{1,\\}>[^<]*<\\/[a-z]\\{1,\\}> *$' | sed 's/^ *<status>/Status: /;s/^ *<errcode>/Error code: /;s/^ *<errtext>/Error text: /;s/<\\/.*$//' | grep '^[A-Z]' )\" fi if [ \"$pleskxml_retcode\" -ne 0 ] || [ \"$errtext\" != \"\" ]; then # Call failed, for reasons either in the retcode or the response text... if [ \"$pleskxml_retcode\" -eq 0 ]; then _err \"The POST request was successfully sent to the Plesk server.\" else _err \"The return code for the POST request was $pleskxml_retcode (non-zero = failure in submitting request to server).\" fi if [ \"$errtext\" != \"\" ]; then _err 'The error responses received from the Plesk server were:' _err \"$errtext\" else _err \"No additional error messages were received back from the Plesk server\" fi _err \"The Plesk XML API call failed.\" return 1 fi _debug \"Leaving _call_api(). Successful call.\" return 0 } # Startup checks (credentials, URI) _credential_check() { _debug \"Checking Plesk XML API login credentials and URI...\" if [ \"$pleskxml_init_checks_done\" -eq 1 ]; then _debug \"Initial checks already done, no need to repeat. Skipped.\" return 0 fi pleskxml_user=\"${pleskxml_user:-$(_readaccountconf_mutable pleskxml_user)}\" pleskxml_pass=\"${pleskxml_pass:-$(_readaccountconf_mutable pleskxml_pass)}\" pleskxml_uri=\"${pleskxml_uri:-$(_readaccountconf_mutable pleskxml_uri)}\" if [ -z \"$pleskxml_user\" ] || [ -z \"$pleskxml_pass\" ] || [ -z \"$pleskxml_uri\" ]; then pleskxml_user=\"\" pleskxml_pass=\"\" pleskxml_uri=\"\" _err \"You didn't specify one or more of the Plesk XML API username, password, or URI.\" _err \"Please create these and try again.\" _err \"Instructions are in the 'dns_pleskxml' plugin source code or in the acme.sh documentation.\" return 1 fi # Test the API is usable, by trying to read the list of managed domains... _call_api \"$pleskxml_tplt_get_domains\" if [ \"$pleskxml_retcode\" -ne 0 ]; then _err 'Failed to access Plesk XML API.' _err \"Please check your login credentials and Plesk URI, and that the URI is reachable, and try again.\" return 1 fi _saveaccountconf_mutable pleskxml_uri \"$pleskxml_uri\" _saveaccountconf_mutable pleskxml_user \"$pleskxml_user\" _saveaccountconf_mutable pleskxml_pass \"$pleskxml_pass\" _debug \"Test login to Plesk XML API successful. Login credentials and URI successfully saved to the acme.sh configuration file for future use.\" pleskxml_init_checks_done=1 return 0 } # For a FQDN, identify the root domain managed by Plesk, its domain ID in Plesk, and the host if any. # IMPORTANT NOTE: a result with host = empty string is OK for this API, see # https://docs.plesk.com/en-US/obsidian/api-rpc/about-xml-api/reference/managing-dns/managing-dns-records/adding-dns-record.34798 # See notes at top of this file _pleskxml_get_root_domain() { original_full_domain_name=\"$1\" _debug \"Identifying DNS root domain for '$original_full_domain_name' that is managed by the Plesk account.\" # test if the domain as provided is valid for splitting. if [ \"$(_countdots \"$original_full_domain_name\")\" -eq 0 ]; then _err \"Invalid domain. The ACME domain must contain at least two parts (aa.bb) to identify a domain and tld for the TXT record.\" return 1 fi _debug \"Querying Plesk server for list of managed domains...\" _call_api \"$pleskxml_tplt_get_domains\" if [ \"$pleskxml_retcode\" -ne 0 ]; then return 1 fi # Generate a crude list of domains known to this Plesk account based on subscriptions. # We convert <ascii-name> tags to <name> so it'll flag on a hit with either <name> or <ascii-name> fields, # for non-Western character sets. # Output will be one line per known domain, containing 2 <name> tages and a single <id> tag # We don't actually need to check for type, name, *and* id, but it guarantees only usable lines are returned. output=\"$(_api_response_split \"$pleskxml_prettyprint_result\" 'result' '<status>ok</status>' | sed 's/<ascii-name>/<name>/g;s/<\\/ascii-name>/<\\/name>/g' | grep '<name>' | grep '<id>')\" debug_output=\"$(printf \"%s\" \"$output\" | sed -n 's:.*<name>\\(.*\\)</name>.*:\\1:p')\" _debug 'Domains managed by Plesk server are:' _debug \"$debug_output\" _debug \"Querying Plesk server for list of additional managed domains...\" _call_api \"$pleskxml_tplt_get_additional_domains\" if [ \"$pleskxml_retcode\" -ne 0 ]; then return 1 fi # Generate a crude list of additional domains known to this Plesk account based on sites. # We convert <ascii-name> tags to <name> so it'll flag on a hit with either <name> or <ascii-name> fields, # for non-Western character sets. # Output will be one line per known domain, containing 2 <name> tages and a single <id> tag # We don't actually need to check for type, name, *and* id, but it guarantees only usable lines are returned. output_additional=\"$(_api_response_split \"$pleskxml_prettyprint_result\" 'result' '<status>ok</status>' | sed 's/<ascii-name>/<name>/g;s/<\\/ascii-name>/<\\/name>/g' | grep '<name>' | grep '<id>')\" debug_additional=\"$(printf \"%s\" \"$output_additional\" | sed -n 's:.*<name>\\(.*\\)</name>.*:\\1:p')\" _debug 'Additional domains managed by Plesk server are:' _debug \"$debug_additional\" # Concate the two outputs together. output=\"$(printf \"%s\" \"$output $NEWLINE $output_additional\")\" debug_output=\"$(printf \"%s\" \"$output\" | sed -n 's:.*<name>\\(.*\\)</name>.*:\\1:p')\" _debug 'Domains (including additional) managed by Plesk server are:' _debug \"$debug_output\" # loop and test if domain, or any parent domain, is managed by Plesk # Loop until we don't have any '.' in the string we're testing as a candidate Plesk-managed domain root_domain_name=\"$original_full_domain_name\" while true; do _debug \"Checking if '$root_domain_name' is managed by the Plesk server...\" root_domain_id=\"$(_value \"$output\" | grep \"<name>$root_domain_name</name>\" | _head_n 1 | sed 's/^.*<id>\\([0-9]\\{1,\\}\\)<\\/id>.*$/\\1/')\" if [ -n \"$root_domain_id\" ]; then # Found a match # SEE IMPORTANT NOTE ABOVE - THIS FUNCTION CAN RETURN HOST='', AND THAT'S OK FOR PLESK XML API WHICH ALLOWS IT. # SO WE HANDLE IT AND DON'T PREVENT IT sub_domain_name=\"$(_value \"$original_full_domain_name\" | sed \"s/\\.\\{0,1\\}${root_domain_name}\"'$//')\" _info \"Success. Matched host '$original_full_domain_name' to: DOMAIN '${root_domain_name}' (Plesk ID '${root_domain_id}'), HOST '${sub_domain_name}'. Returning.\" return 0 fi # No match, try next parent up (if any)... root_domain_name=\"$(_valuecut 2 1000 \"$root_domain_name\")\" if [ \"$(_countdots \"$root_domain_name\")\" -eq 0 ]; then _debug \"No match, and next parent would be a TLD...\" _err \"Cannot find '$original_full_domain_name' or any parent domain of it, in Plesk.\" _err \"Are you sure that this domain is managed by this Plesk server?\" return 1 fi _debug \"No match, trying next parent up...\" done }"
        },
        {
            "filename": "file_269.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_269.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_pointhq_info='pointhq.com PointDNS Site: pointhq.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_pointhq Options: PointHQ_Key API Key PointHQ_Email Email Issues: github.com/acmesh-official/acme.sh/issues/2060 ' PointHQ_Api=\"https://api.pointhq.com\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_pointhq_add() { fulldomain=$1 txtvalue=$2 PointHQ_Key=\"${PointHQ_Key:-$(_readaccountconf_mutable PointHQ_Key)}\" PointHQ_Email=\"${PointHQ_Email:-$(_readaccountconf_mutable PointHQ_Email)}\" if [ -z \"$PointHQ_Key\" ] || [ -z \"$PointHQ_Email\" ]; then PointHQ_Key=\"\" PointHQ_Email=\"\" _err \"You didn't specify a PointHQ API key and email yet.\" _err \"Please create the key and try again.\" return 1 fi if ! _contains \"$PointHQ_Email\" \"@\"; then _err \"It seems that the PointHQ_Email=$PointHQ_Email is not a valid email address.\" _err \"Please check and retry.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable PointHQ_Key \"$PointHQ_Key\" _saveaccountconf_mutable PointHQ_Email \"$PointHQ_Email\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if _pointhq_rest POST \"zones/$_domain/records\" \"{\\\"zone_record\\\": {\\\"name\\\":\\\"$_sub_domain\\\",\\\"record_type\\\":\\\"TXT\\\",\\\"data\\\":\\\"$txtvalue\\\",\\\"ttl\\\":3600}}\"; then if printf -- \"%s\" \"$response\" | grep \"$fulldomain\" >/dev/null; then _info \"Added, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_pointhq_rm() { fulldomain=$1 txtvalue=$2 PointHQ_Key=\"${PointHQ_Key:-$(_readaccountconf_mutable PointHQ_Key)}\" PointHQ_Email=\"${PointHQ_Email:-$(_readaccountconf_mutable PointHQ_Email)}\" if [ -z \"$PointHQ_Key\" ] || [ -z \"$PointHQ_Email\" ]; then PointHQ_Key=\"\" PointHQ_Email=\"\" _err \"You didn't specify a PointHQ API key and email yet.\" _err \"Please create the key and try again.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _pointhq_rest GET \"zones/${_domain}/records?record_type=TXT&name=$_sub_domain\" if ! printf \"%s\" \"$response\" | grep \"^\\[\" >/dev/null; then _err \"Error\" return 1 fi if [ \"$response\" = \"[]\" ]; then _info \"No records to remove.\" else record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":[^,]*\" | cut -d : -f 2 | tr -d \\\" | head -n 1) _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _pointhq_rest DELETE \"zones/$_domain/records/$record_id\"; then _err \"Delete record error.\" return 1 fi _contains \"$response\" '\"status\":\"OK\"' fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _pointhq_rest GET \"zones\"; then return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" >/dev/null; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _pointhq_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" _pointhq_auth=$(printf \"%s:%s\" \"$PointHQ_Email\" \"$PointHQ_Key\" | _base64) export _H1=\"Authorization: Basic $_pointhq_auth\" export _H2=\"Content-Type: application/json\" export _H3=\"Accept: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$PointHQ_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$PointHQ_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_270.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_270.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_porkbun_info='Porkbun.com Site: Porkbun.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_porkbun Options: PORKBUN_API_KEY API Key PORKBUN_SECRET_API_KEY API Secret Issues: github.com/acmesh-official/acme.sh/issues/3450 ' PORKBUN_Api=\"https://porkbun.com/api/json/v3\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_porkbun_add() { fulldomain=$1 txtvalue=$2 PORKBUN_API_KEY=\"${PORKBUN_API_KEY:-$(_readaccountconf_mutable PORKBUN_API_KEY)}\" PORKBUN_SECRET_API_KEY=\"${PORKBUN_SECRET_API_KEY:-$(_readaccountconf_mutable PORKBUN_SECRET_API_KEY)}\" if [ -z \"$PORKBUN_API_KEY\" ] || [ -z \"$PORKBUN_SECRET_API_KEY\" ]; then PORKBUN_API_KEY='' PORKBUN_SECRET_API_KEY='' _err \"You didn't specify a Porkbun api key and secret api key yet.\" _err \"You can get yours from here https://porkbun.com/account/api.\" return 1 fi #save the credentials to the account conf file. _saveaccountconf_mutable PORKBUN_API_KEY \"$PORKBUN_API_KEY\" _saveaccountconf_mutable PORKBUN_SECRET_API_KEY \"$PORKBUN_SECRET_API_KEY\" _debug 'First detect the root zone' if ! _get_root \"$fulldomain\"; then return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # For wildcard cert, the main root domain and the wildcard domain have the same txt subdomain name, so # we can not use updating anymore. # count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"count\\\":[^,]*\" | cut -d : -f 2) # _debug count \"$count\" # if [ \"$count\" = \"0\" ]; then _info \"Adding record\" if _porkbun_rest POST \"dns/create/$_domain\" \"{\\\"name\\\":\\\"$_sub_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":120}\"; then if _contains \"$response\" '\\\"status\\\":\"SUCCESS\"'; then _info \"Added, OK\" return 0 elif _contains \"$response\" \"The record already exists\"; then _info \"Already exists, OK\" return 0 else _err \"Add txt record error. ($response)\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_porkbun_rm() { fulldomain=$1 txtvalue=$2 PORKBUN_API_KEY=\"${PORKBUN_API_KEY:-$(_readaccountconf_mutable PORKBUN_API_KEY)}\" PORKBUN_SECRET_API_KEY=\"${PORKBUN_SECRET_API_KEY:-$(_readaccountconf_mutable PORKBUN_SECRET_API_KEY)}\" _debug 'First detect the root zone' if ! _get_root \"$fulldomain\"; then return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" count=$(echo \"$response\" | _egrep_o \"\\\"count\\\": *[^,]*\" | cut -d : -f 2 | tr -d \" \") _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else record_id=$(echo \"$response\" | tr '{' '\\n' | grep -- \"$txtvalue\" | cut -d, -f1 | cut -d: -f2 | tr -d \\\") _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _porkbun_rest POST \"dns/delete/$_domain/$record_id\"; then _err \"Delete record error.\" return 1 fi echo \"$response\" | tr -d \" \" | grep '\"status\":\"SUCCESS\"' >/dev/null fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then return 1 fi if _porkbun_rest POST \"dns/retrieve/$h\"; then if _contains \"$response\" \"\\\"status\\\":\\\"SUCCESS\\\"\"; then _domain=$h _sub_domain=\"$(echo \"$fulldomain\" | sed \"s/\\\\.$_domain\\$//\")\" return 0 else _debug \"Go to next level of $_domain\" fi else _debug \"Go to next level of $_domain\" fi i=$(_math \"$i\" + 1) done return 1 } _porkbun_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" api_key_trimmed=$(echo \"$PORKBUN_API_KEY\" | tr -d '\"') secret_api_key_trimmed=$(echo \"$PORKBUN_SECRET_API_KEY\" | tr -d '\"') test -z \"$data\" && data=\"{\" || data=\"$(echo \"$data\" | cut -d'}' -f1),\" data=\"$data\\\"apikey\\\":\\\"$api_key_trimmed\\\",\\\"secretapikey\\\":\\\"$secret_api_key_trimmed\\\"}\" export _H1=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$PORKBUN_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$PORKBUN_Api/$ep\")\" fi _sleep 3 # prevent rate limit if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_271.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_271.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_rackcorp_info='RackCorp.com Site: RackCorp.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_rackcorp Options: RACKCORP_APIUUID API UUID. See Portal: ADMINISTRATION -> API RACKCORP_APISECRET API Secret Issues: github.com/acmesh-official/acme.sh/issues/3351 Author: Stephen Dendtler <sdendtler@rackcorp.com> ' RACKCORP_API_ENDPOINT=\"https://api.rackcorp.net/api/rest/v2.4/json.php\" ######## Public functions ##################### dns_rackcorp_add() { fulldomain=\"$1\" txtvalue=\"$2\" _debug fulldomain=\"$fulldomain\" _debug txtvalue=\"$txtvalue\" if ! _rackcorp_validate; then return 1 fi _debug \"Searching for root zone\" if ! _get_root \"$fulldomain\"; then return 1 fi _debug _lookup \"$_lookup\" _debug _domain \"$_domain\" _info \"Creating TXT record.\" if ! _rackcorp_api dns.record.create \"\\\"name\\\":\\\"$_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"lookup\\\":\\\"$_lookup\\\",\\\"data\\\":\\\"$txtvalue\\\",\\\"ttl\\\":300\"; then return 1 fi return 0 } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_rackcorp_rm() { fulldomain=$1 txtvalue=$2 _debug fulldomain=\"$fulldomain\" _debug txtvalue=\"$txtvalue\" if ! _rackcorp_validate; then return 1 fi _debug \"Searching for root zone\" if ! _get_root \"$fulldomain\"; then return 1 fi _debug _lookup \"$_lookup\" _debug _domain \"$_domain\" _info \"Creating TXT record.\" if ! _rackcorp_api dns.record.delete \"\\\"name\\\":\\\"$_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"lookup\\\":\\\"$_lookup\\\",\\\"data\\\":\\\"$txtvalue\\\"\"; then return 1 fi return 0 } #################### Private functions below ################################## #_acme-challenge.domain.com #returns # _lookup=_acme-challenge # _domain=domain.com _get_root() { domain=$1 i=1 p=1 if ! _rackcorp_api dns.domain.getall \"\\\"name\\\":\\\"$domain\\\"\"; then return 1 fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug searchhost \"$h\" if [ -z \"$h\" ]; then _err \"Could not find domain for record $domain in RackCorp using the provided credentials\" #not valid return 1 fi _rackcorp_api dns.domain.getall \"\\\"exactName\\\":\\\"$h\\\"\" if _contains \"$response\" \"\\\"matches\\\":1\"; then if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\"; then _lookup=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi fi p=$i i=$(_math \"$i\" + 1) done return 1 } _rackcorp_validate() { RACKCORP_APIUUID=\"${RACKCORP_APIUUID:-$(_readaccountconf_mutable RACKCORP_APIUUID)}\" if [ -z \"$RACKCORP_APIUUID\" ]; then RACKCORP_APIUUID=\"\" _err \"You require a RackCorp API UUID (export RACKCORP_APIUUID=\\\"<api uuid>\\\")\" _err \"Please login to the portal and create an API key and try again.\" return 1 fi _saveaccountconf_mutable RACKCORP_APIUUID \"$RACKCORP_APIUUID\" RACKCORP_APISECRET=\"${RACKCORP_APISECRET:-$(_readaccountconf_mutable RACKCORP_APISECRET)}\" if [ -z \"$RACKCORP_APISECRET\" ]; then RACKCORP_APISECRET=\"\" _err \"You require a RackCorp API secret (export RACKCORP_APISECRET=\\\"<api secret>\\\")\" _err \"Please login to the portal and create an API key and try again.\" return 1 fi _saveaccountconf_mutable RACKCORP_APISECRET \"$RACKCORP_APISECRET\" return 0 } _rackcorp_api() { _rackcorpcmd=$1 _rackcorpinputdata=$2 _debug cmd \"$_rackcorpcmd $_rackcorpinputdata\" export _H1=\"Accept: application/json\" response=\"$(_post \"{\\\"APIUUID\\\":\\\"$RACKCORP_APIUUID\\\",\\\"APISECRET\\\":\\\"$RACKCORP_APISECRET\\\",\\\"cmd\\\":\\\"$_rackcorpcmd\\\",$_rackcorpinputdata}\" \"$RACKCORP_API_ENDPOINT\" \"\" \"POST\")\" if [ \"$?\" != \"0\" ]; then _err \"error $response\" return 1 fi _debug2 response \"$response\" if _contains \"$response\" \"\\\"code\\\":\\\"OK\\\"\"; then _debug code \"OK\" else _debug code \"FAILED\" response=\"\" return 1 fi return 0 }"
        },
        {
            "filename": "file_272.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_272.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_rackspace_info='RackSpace.com Site: RackSpace.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_rackspace Options: RACKSPACE_Apikey API Key RACKSPACE_Username Username Issues: github.com/acmesh-official/acme.sh/issues/2091 ' RACKSPACE_Endpoint=\"https://dns.api.rackspacecloud.com/v1.0\" # 20210923 - RS changed the fields in the API response; fix sed # 20190213 - The name & id fields swapped in the API response; fix sed # 20190101 - Duplicating file for new pull request to dev branch # Original - tcocca:rackspace_dnsapi https://github.com/acmesh-official/acme.sh/pull/1297 ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_rackspace_add() { fulldomain=\"$1\" _debug fulldomain=\"$fulldomain\" txtvalue=\"$2\" _debug txtvalue=\"$txtvalue\" _rackspace_check_auth || return 1 _rackspace_check_rootzone || return 1 _info \"Creating TXT record.\" if ! _rackspace_rest POST \"$RACKSPACE_Tenant/domains/$_domain_id/records\" \"{\\\"records\\\":[{\\\"name\\\":\\\"$fulldomain\\\",\\\"type\\\":\\\"TXT\\\",\\\"data\\\":\\\"$txtvalue\\\",\\\"ttl\\\":300}]}\"; then return 1 fi _debug2 response \"$response\" if ! _contains \"$response\" \"$txtvalue\" >/dev/null; then _err \"Could not add TXT record.\" return 1 fi return 0 } #fulldomain txtvalue dns_rackspace_rm() { fulldomain=$1 _debug fulldomain=\"$fulldomain\" txtvalue=$2 _debug txtvalue=\"$txtvalue\" _rackspace_check_auth || return 1 _rackspace_check_rootzone || return 1 _info \"Checking for TXT record.\" if ! _get_recordid \"$_domain_id\" \"$fulldomain\" \"$txtvalue\"; then _err \"Could not get TXT record id.\" return 1 fi if [ \"$_dns_record_id\" = \"\" ]; then _err \"TXT record not found.\" return 1 fi _info \"Removing TXT record.\" if ! _delete_txt_record \"$_domain_id\" \"$_dns_record_id\"; then _err \"Could not remove TXT record $_dns_record_id.\" fi return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root_zone() { domain=\"$1\" i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _rackspace_rest GET \"$RACKSPACE_Tenant/domains/search?name=$h\"; then return 1 fi _debug2 response \"$response\" if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" >/dev/null; then # Response looks like: # {\"id\":\"12345\",\"accountId\":\"1111111\",\"name\": \"example.com\",\"ttl\":3600,\"emailAddress\": ... <and so on> _domain_id=$(echo \"$response\" | sed -n \"s/^.*\\\"id\\\":\\\"\\([^,]*\\)\\\",\\\"accountId\\\":\\\"[0-9]*\\\",\\\"name\\\":\\\"$h\\\",.*/\\1/p\") _debug2 domain_id \"$_domain_id\" if [ -n \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _get_recordid() { domainid=\"$1\" fulldomain=\"$2\" txtvalue=\"$3\" if ! _rackspace_rest GET \"$RACKSPACE_Tenant/domains/$domainid/records?name=$fulldomain&type=TXT\"; then return 1 fi _debug response \"$response\" if ! _contains \"$response\" \"$txtvalue\"; then _dns_record_id=0 return 0 fi _dns_record_id=$(echo \"$response\" | tr '{' \"\\n\" | grep \"\\\"data\\\":\\\"$txtvalue\\\"\" | sed -n 's/^.*\"id\":\"\\([^\"]*\\)\".*/\\1/p') _debug _dns_record_id \"$_dns_record_id\" return 0 } _delete_txt_record() { domainid=\"$1\" _dns_record_id=\"$2\" if ! _rackspace_rest DELETE \"$RACKSPACE_Tenant/domains/$domainid/records?id=$_dns_record_id\"; then return 1 fi _debug response \"$response\" if ! _contains \"$response\" \"RUNNING\"; then return 1 fi return 0 } _rackspace_rest() { m=\"$1\" ep=\"$2\" data=\"$3\" _debug ep \"$ep\" export _H1=\"Accept: application/json\" export _H2=\"X-Auth-Token: $RACKSPACE_Token\" export _H3=\"X-Project-Id: $RACKSPACE_Tenant\" export _H4=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$RACKSPACE_Endpoint/$ep\" \"\" \"$m\")\" retcode=$? else _info \"Getting $RACKSPACE_Endpoint/$ep\" response=\"$(_get \"$RACKSPACE_Endpoint/$ep\")\" retcode=$? fi if [ \"$retcode\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 } _rackspace_authorization() { export _H1=\"Content-Type: application/json\" data=\"{\\\"auth\\\":{\\\"RAX-KSKEY:apiKeyCredentials\\\":{\\\"username\\\":\\\"$RACKSPACE_Username\\\",\\\"apiKey\\\":\\\"$RACKSPACE_Apikey\\\"}}}\" _debug data \"$data\" response=\"$(_post \"$data\" \"https://identity.api.rackspacecloud.com/v2.0/tokens\" \"\" \"POST\")\" retcode=$? _debug2 response \"$response\" if [ \"$retcode\" != \"0\" ]; then _err \"Authentication failed.\" return 1 fi if _contains \"$response\" \"token\"; then RACKSPACE_Token=\"$(echo \"$response\" | _normalizeJson | sed -n 's/^.*\"token\":{.*,\"id\":\"\\([^\"]*\\)\",\".*/\\1/p')\" RACKSPACE_Tenant=\"$(echo \"$response\" | _normalizeJson | sed -n 's/^.*\"token\":{.*,\"id\":\"\\([^\"]*\\)\"}.*/\\1/p')\" _debug RACKSPACE_Token \"$RACKSPACE_Token\" _debug RACKSPACE_Tenant \"$RACKSPACE_Tenant\" fi return 0 } _rackspace_check_auth() { # retrieve the rackspace creds RACKSPACE_Username=\"${RACKSPACE_Username:-$(_readaccountconf_mutable RACKSPACE_Username)}\" RACKSPACE_Apikey=\"${RACKSPACE_Apikey:-$(_readaccountconf_mutable RACKSPACE_Apikey)}\" # check their vals for null if [ -z \"$RACKSPACE_Username\" ] || [ -z \"$RACKSPACE_Apikey\" ]; then RACKSPACE_Username=\"\" RACKSPACE_Apikey=\"\" _err \"You didn't specify a Rackspace username and api key.\" _err \"Please set those values and try again.\" return 1 fi # save the username and api key to the account conf file. _saveaccountconf_mutable RACKSPACE_Username \"$RACKSPACE_Username\" _saveaccountconf_mutable RACKSPACE_Apikey \"$RACKSPACE_Apikey\" if [ -z \"$RACKSPACE_Token\" ]; then _info \"Getting authorization token.\" if ! _rackspace_authorization; then _err \"Can not get token.\" fi fi } _rackspace_check_rootzone() { _debug \"First detect the root zone\" if ! _get_root_zone \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" }"
        },
        {
            "filename": "file_273.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_273.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_rage4_info='rage4.com Site: rage4.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_rage4 Options: RAGE4_TOKEN API Key RAGE4_USERNAME Username Issues: github.com/acmesh-official/acme.sh/issues/4306 ' RAGE4_Api=\"https://rage4.com/rapi/\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_rage4_add() { fulldomain=$1 txtvalue=$2 unquotedtxtvalue=$(echo \"$txtvalue\" | tr -d \\\") RAGE4_USERNAME=\"${RAGE4_USERNAME:-$(_readaccountconf_mutable RAGE4_USERNAME)}\" RAGE4_TOKEN=\"${RAGE4_TOKEN:-$(_readaccountconf_mutable RAGE4_TOKEN)}\" if [ -z \"$RAGE4_USERNAME\" ] || [ -z \"$RAGE4_TOKEN\" ]; then RAGE4_USERNAME=\"\" RAGE4_TOKEN=\"\" _err \"You didn't specify a Rage4 api token and username yet.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable RAGE4_USERNAME \"$RAGE4_USERNAME\" _saveaccountconf_mutable RAGE4_TOKEN \"$RAGE4_TOKEN\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _rage4_rest \"createrecord/?id=$_domain_id&name=$fulldomain&content=$unquotedtxtvalue&type=TXT&active=true&ttl=1\" return 0 } #fulldomain txtvalue dns_rage4_rm() { fulldomain=$1 txtvalue=$2 RAGE4_USERNAME=\"${RAGE4_USERNAME:-$(_readaccountconf_mutable RAGE4_USERNAME)}\" RAGE4_TOKEN=\"${RAGE4_TOKEN:-$(_readaccountconf_mutable RAGE4_TOKEN)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug \"Getting txt records\" _rage4_rest \"getrecords/?id=${_domain_id}\" _record_id=$(echo \"$response\" | sed -rn 's/.*\"id\":([[:digit:]]+)[^\\}]*'\"$txtvalue\"'.*/\\1/p') _rage4_rest \"deleterecord/?id=${_record_id}\" return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 if ! _rage4_rest \"getdomains\"; then return 1 fi _debug _get_root_domain \"$domain\" for line in $(echo \"$response\" | tr '}' '\\n'); do __domain=$(echo \"$line\" | sed -rn 's/.*\"name\":\"([^\"]*)\",.*/\\1/p') __domain_id=$(echo \"$line\" | sed -rn 's/.*\"id\":([^,]*),.*/\\1/p') if [ \"$domain\" != \"${domain%\"$__domain\"*}\" ]; then _domain_id=\"$__domain_id\" break fi done if [ -z \"$_domain_id\" ]; then return 1 fi return 0 } _rage4_rest() { ep=\"$1\" _debug \"$ep\" username_trimmed=$(echo \"$RAGE4_USERNAME\" | tr -d '\"') token_trimmed=$(echo \"$RAGE4_TOKEN\" | tr -d '\"') auth=$(printf '%s:%s' \"$username_trimmed\" \"$token_trimmed\" | _base64) export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: Basic $auth\" response=\"$(_get \"$RAGE4_Api$ep\")\" if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_274.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_274.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_rcode0_info='Rcode0 rcodezero.at Site: rcodezero.at Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_rcode0 Options: RCODE0_URL API URL. E.g. \"https://my.rcodezero.at\" RCODE0_API_TOKEN API Token RCODE0_TTL TTL. Default: \"60\". Issues: github.com/acmesh-official/acme.sh/issues/2490 ' #Rcode0 API Integration #https://my.rcodezero.at/api-doc # # log into https://my.rcodezero.at/enableapi and get your ACME API Token (the ACME API token has limited # access to the REST calls needed for acme.sh only) DEFAULT_RCODE0_URL=\"https://my.rcodezero.at\" DEFAULT_RCODE0_TTL=60 ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"123456789ABCDEF0000000000000000000000000000000000000\" #fulldomain #txtvalue dns_rcode0_add() { fulldomain=$1 txtvalue=$2 RCODE0_API_TOKEN=\"${RCODE0_API_TOKEN:-$(_readaccountconf_mutable RCODE0_API_TOKEN)}\" RCODE0_URL=\"${RCODE0_URL:-$(_readaccountconf_mutable RCODE0_URL)}\" RCODE0_TTL=\"${RCODE0_TTL:-$(_readaccountconf_mutable RCODE0_TTL)}\" if [ -z \"$RCODE0_URL\" ]; then RCODE0_URL=\"$DEFAULT_RCODE0_URL\" fi if [ -z \"$RCODE0_API_TOKEN\" ]; then RCODE0_API_TOKEN=\"\" _err \"Missing Rcode0 ACME API Token.\" _err \"Please login and create your token at httsp://my.rcodezero.at/enableapi and try again.\" return 1 fi if [ -z \"$RCODE0_TTL\" ]; then RCODE0_TTL=\"$DEFAULT_RCODE0_TTL\" fi #save the token to the account conf file. _saveaccountconf_mutable RCODE0_API_TOKEN \"$RCODE0_API_TOKEN\" if [ \"$RCODE0_URL\" != \"$DEFAULT_RCODE0_URL\" ]; then _saveaccountconf_mutable RCODE0_URL \"$RCODE0_URL\" fi if [ \"$RCODE0_TTL\" != \"$DEFAULT_RCODE0_TTL\" ]; then _saveaccountconf_mutable RCODE0_TTL \"$RCODE0_TTL\" fi _debug \"Detect root zone\" if ! _get_root \"$fulldomain\"; then _err \"No 'MASTER' zone for $fulldomain found at RcodeZero Anycast.\" return 1 fi _debug _domain \"$_domain\" _debug \"Adding record\" _record_string=\"\" _build_record_string \"$txtvalue\" _list_existingchallenges for oldchallenge in $_existing_challenges; do _build_record_string \"$oldchallenge\" done _debug \"Challenges: $_existing_challenges\" if [ -z \"$_existing_challenges\" ]; then if ! _rcode0_rest \"PATCH\" \"/api/v1/acme/zones/$_domain/rrsets\" \"[{\\\"changetype\\\": \\\"add\\\", \\\"name\\\": \\\"$fulldomain.\\\", \\\"type\\\": \\\"TXT\\\", \\\"ttl\\\": $RCODE0_TTL, \\\"records\\\": [$_record_string]}]\"; then _err \"Add txt record error.\" return 1 fi else # try update in case a records exists (need for wildcard certs) if ! _rcode0_rest \"PATCH\" \"/api/v1/acme/zones/$_domain/rrsets\" \"[{\\\"changetype\\\": \\\"update\\\", \\\"name\\\": \\\"$fulldomain.\\\", \\\"type\\\": \\\"TXT\\\", \\\"ttl\\\": $RCODE0_TTL, \\\"records\\\": [$_record_string]}]\"; then _err \"Set txt record error.\" return 1 fi fi return 0 } #fulldomain txtvalue dns_rcode0_rm() { fulldomain=$1 txtvalue=$2 RCODE0_API_TOKEN=\"${RCODE0_API_TOKEN:-$(_readaccountconf_mutable RCODE0_API_TOKEN)}\" RCODE0_URL=\"${RCODE0_URL:-$(_readaccountconf_mutable RCODE0_URL)}\" RCODE0_TTL=\"${RCODE0_TTL:-$(_readaccountconf_mutable RCODE0_TTL)}\" if [ -z \"$RCODE0_URL\" ]; then RCODE0_URL=\"$DEFAULT_RCODE0_URL\" fi if [ -z \"$RCODE0_API_TOKEN\" ]; then RCODE0_API_TOKEN=\"\" _err \"Missing Rcode0 API Token.\" _err \"Please login and create your token at httsp://my.rcodezero.at/enableapi and try again.\" return 1 fi #save the api addr and key to the account conf file. _saveaccountconf_mutable RCODE0_URL \"$RCODE0_URL\" _saveaccountconf_mutable RCODE0_API_TOKEN \"$RCODE0_API_TOKEN\" if [ \"$RCODE0_TTL\" != \"$DEFAULT_RCODE0_TTL\" ]; then _saveaccountconf_mutable RCODE0_TTL \"$RCODE0_TTL\" fi if [ -z \"$RCODE0_TTL\" ]; then RCODE0_TTL=\"$DEFAULT_RCODE0_TTL\" fi _debug \"Detect root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug \"Remove record\" #Enumerate existing acme challenges _list_existingchallenges if _contains \"$_existing_challenges\" \"$txtvalue\"; then #Delete all challenges (PowerDNS API does not allow to delete content) if ! _rcode0_rest \"PATCH\" \"/api/v1/acme/zones/$_domain/rrsets\" \"[{\\\"changetype\\\": \\\"delete\\\", \\\"name\\\": \\\"$fulldomain.\\\", \\\"type\\\": \\\"TXT\\\"}]\"; then _err \"Delete txt record error.\" return 1 fi _record_string=\"\" #If the only existing challenge was the challenge to delete: nothing to do if ! [ \"$_existing_challenges\" = \"$txtvalue\" ]; then for oldchallenge in $_existing_challenges; do #Build up the challenges to re-add, ommitting the one what should be deleted if ! [ \"$oldchallenge\" = \"$txtvalue\" ]; then _build_record_string \"$oldchallenge\" fi done #Recreate the existing challenges if ! _rcode0_rest \"PATCH\" \"/api/v1/acme/zones/$_domain/rrsets\" \"[{\\\"changetype\\\": \\\"update\\\", \\\"name\\\": \\\"$fulldomain.\\\", \\\"type\\\": \\\"TXT\\\", \\\"ttl\\\": $RCODE0_TTL, \\\"records\\\": [$_record_string]}]\"; then _err \"Set txt record error.\" return 1 fi fi else _info \"Record not found, nothing to remove\" fi return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _domain=domain.com _get_root() { domain=$1 i=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug \"try to find: $h\" if _rcode0_rest \"GET\" \"/api/v1/acme/zones/$h\"; then if [ \"$response\" = \"[\\\"found\\\"]\" ]; then _domain=\"$h\" if [ -z \"$h\" ]; then _domain=\"=2E\" fi return 0 elif [ \"$response\" = \"[\\\"not a master domain\\\"]\" ]; then return 1 fi fi if [ -z \"$h\" ]; then return 1 fi i=$(_math $i + 1) done _debug \"no matching domain for $domain found\" return 1 } _rcode0_rest() { method=$1 ep=$2 data=$3 export _H1=\"Authorization: Bearer $RCODE0_API_TOKEN\" if [ ! \"$method\" = \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$RCODE0_URL$ep\" \"\" \"$method\")\" else response=\"$(_get \"$RCODE0_URL$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 } _build_record_string() { _record_string=\"${_record_string:+${_record_string}, }{\\\"content\\\": \\\"\\\\\\\"${1}\\\\\\\"\\\", \\\"disabled\\\": false}\" } _list_existingchallenges() { _rcode0_rest \"GET\" \"/api/v1/acme/zones/$_domain/rrsets\" _existing_challenges=$(echo \"$response\" | _normalizeJson | _egrep_o \"\\\"name\\\":\\\"${fulldomain}[^]]*}\" | _egrep_o 'content\\\":\\\"\\\\\"[^\\\\]*' | sed -n 's/^content\":\"\\\\\"//p') _debug2 \"$_existing_challenges\" }"
        },
        {
            "filename": "file_275.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_275.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_regru_info='reg.ru Site: reg.ru Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_regru Options: REGRU_API_Username Username REGRU_API_Password Password Issues: github.com/acmesh-official/acme.sh/issues/2336 ' REGRU_API_URL=\"https://api.reg.ru/api/regru2\" ######## Public functions ##################### dns_regru_add() { fulldomain=$1 txtvalue=$2 REGRU_API_Username=\"${REGRU_API_Username:-$(_readaccountconf_mutable REGRU_API_Username)}\" REGRU_API_Password=\"${REGRU_API_Password:-$(_readaccountconf_mutable REGRU_API_Password)}\" if [ -z \"$REGRU_API_Username\" ] || [ -z \"$REGRU_API_Password\" ]; then REGRU_API_Username=\"\" REGRU_API_Password=\"\" _err \"You don't specify regru password or username.\" return 1 fi _saveaccountconf_mutable REGRU_API_Username \"$REGRU_API_Username\" _saveaccountconf_mutable REGRU_API_Password \"$REGRU_API_Password\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain \"$_domain\" _subdomain=$(echo \"$fulldomain\" | sed -r \"s/.$_domain//\") _debug _subdomain \"$_subdomain\" _info \"Adding TXT record to ${fulldomain}\" _regru_rest POST \"zone/add_txt\" \"input_data={%22username%22:%22${REGRU_API_Username}%22,%22password%22:%22${REGRU_API_Password}%22,%22domains%22:[{%22dname%22:%22${_domain}%22}],%22subdomain%22:%22${_subdomain}%22,%22text%22:%22${txtvalue}%22,%22output_content_type%22:%22plain%22}&input_format=json\" if ! _contains \"${response}\" 'error'; then return 0 fi _err \"Could not create resource record, check logs\" _err \"${response}\" return 1 } dns_regru_rm() { fulldomain=$1 txtvalue=$2 REGRU_API_Username=\"${REGRU_API_Username:-$(_readaccountconf_mutable REGRU_API_Username)}\" REGRU_API_Password=\"${REGRU_API_Password:-$(_readaccountconf_mutable REGRU_API_Password)}\" if [ -z \"$REGRU_API_Username\" ] || [ -z \"$REGRU_API_Password\" ]; then REGRU_API_Username=\"\" REGRU_API_Password=\"\" _err \"You don't specify regru password or username.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain \"$_domain\" _subdomain=$(echo \"$fulldomain\" | sed -r \"s/.$_domain//\") _debug _subdomain \"$_subdomain\" _info \"Deleting resource record $fulldomain\" _regru_rest POST \"zone/remove_record\" \"input_data={%22username%22:%22${REGRU_API_Username}%22,%22password%22:%22${REGRU_API_Password}%22,%22domains%22:[{%22dname%22:%22${_domain}%22}],%22subdomain%22:%22${_subdomain}%22,%22content%22:%22${txtvalue}%22,%22record_type%22:%22TXT%22,%22output_content_type%22:%22plain%22}&input_format=json\" if ! _contains \"${response}\" 'error'; then return 0 fi _err \"Could not delete resource record, check logs\" _err \"${response}\" return 1 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _domain=domain.com _get_root() { domain=$1 _regru_rest POST \"service/get_list\" \"username=${REGRU_API_Username}&password=${REGRU_API_Password}&output_format=xml&servtype=domain\" domains_list=$(echo \"${response}\" | grep dname | sed -r \"s/.*dname=\\\"([^\\\"]+)\\\".*/\\\\1/g\") for ITEM in ${domains_list}; do IDN_ITEM=${ITEM} case \"${domain}\" in *${IDN_ITEM}*) _domain=\"$(_idn \"${ITEM}\")\" _debug _domain \"${_domain}\" return 0 ;; esac done return 1 } #returns # response _regru_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Content-Type: application/x-www-form-urlencoded\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$REGRU_API_URL/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$REGRU_API_URL/$ep?$data\")\" fi _debug response \"${response}\" return 0 }"
        },
        {
            "filename": "file_276.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_276.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_scaleway_info='ScaleWay.com Site: ScaleWay.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_scaleway Options: SCALEWAY_API_TOKEN API Token Issues: github.com/acmesh-official/acme.sh/issues/3295 ' # Scaleway API # https://developers.scaleway.com/en/products/domain/dns/api/ ######## Public functions ##################### SCALEWAY_API=\"https://api.scaleway.com/domain/v2beta1\" #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_scaleway_add() { fulldomain=$1 txtvalue=$2 if ! _scaleway_check_config; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" _scaleway_create_TXT_record \"$_domain\" \"$_sub_domain\" \"$txtvalue\" if _contains \"$response\" \"records\"; then return 0 else _err error \"$response\" return 1 fi _info \"Record added.\" return 0 } dns_scaleway_rm() { fulldomain=$1 txtvalue=$2 if ! _scaleway_check_config; then return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Deleting record\" _scaleway_delete_TXT_record \"$_domain\" \"$_sub_domain\" \"$txtvalue\" if _contains \"$response\" \"records\"; then return 0 else _err error \"$response\" return 1 fi _info \"Record deleted.\" return 0 } #################### Private functions below ################################## _scaleway_check_config() { SCALEWAY_API_TOKEN=\"${SCALEWAY_API_TOKEN:-$(_readaccountconf_mutable SCALEWAY_API_TOKEN)}\" if [ -z \"$SCALEWAY_API_TOKEN\" ]; then _err \"No API key specified for Scaleway API.\" _err \"Create your key and export it as SCALEWAY_API_TOKEN\" return 1 fi if ! _scaleway_rest GET \"dns-zones\"; then _err \"Invalid API key specified for Scaleway API.\" return 1 fi _saveaccountconf_mutable SCALEWAY_API_TOKEN \"$SCALEWAY_API_TOKEN\" return 0 } #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi _scaleway_rest GET \"dns-zones/$h/records\" if ! _contains \"$response\" \"subdomain not found\" >/dev/null; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=$i i=$(_math \"$i\" + 1) done _err \"Unable to retrive DNS zone matching this domain\" return 1 } # this function add a TXT record _scaleway_create_TXT_record() { txt_zone=$1 txt_name=$2 txt_value=$3 _scaleway_rest PATCH \"dns-zones/$txt_zone/records\" \"{\\\"return_all_records\\\":false,\\\"changes\\\":[{\\\"add\\\":{\\\"records\\\":[{\\\"name\\\":\\\"$txt_name\\\",\\\"data\\\":\\\"$txt_value\\\",\\\"type\\\":\\\"TXT\\\",\\\"ttl\\\":60}]}}]}\" if _contains \"$response\" \"records\"; then return 0 else _err \"error1 $response\" return 1 fi } # this function delete a TXT record based on name and content _scaleway_delete_TXT_record() { txt_zone=$1 txt_name=$2 txt_value=$3 _scaleway_rest PATCH \"dns-zones/$txt_zone/records\" \"{\\\"return_all_records\\\":false,\\\"changes\\\":[{\\\"delete\\\":{\\\"id_fields\\\":{\\\"name\\\":\\\"$txt_name\\\",\\\"data\\\":\\\"$txt_value\\\",\\\"type\\\":\\\"TXT\\\"}}}]}\" if _contains \"$response\" \"records\"; then return 0 else _err \"error2 $response\" return 1 fi } _scaleway_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" _scaleway_url=\"$SCALEWAY_API/$ep\" _debug2 _scaleway_url \"$_scaleway_url\" export _H1=\"x-auth-token: $SCALEWAY_API_TOKEN\" export _H2=\"Accept: application/json\" export _H3=\"Content-Type: application/json\" if [ \"$data\" ] || [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$_scaleway_url\" \"\" \"$m\")\" else response=\"$(_get \"$_scaleway_url\")\" fi if [ \"$?\" != \"0\" ] || _contains \"$response\" \"denied_authentication\" || _contains \"$response\" \"Method not allowed\" || _contains \"$response\" \"json parse error: unexpected EOF\"; then _err \"error $response\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_277.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_277.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_schlundtech_info='SchlundTech.de Site: SchlundTech.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_schlundtech Options: SCHLUNDTECH_USER Username SCHLUNDTECH_PASSWORD Password Issues: github.com/acmesh-official/acme.sh/issues/2246 Author: <https://github.com/mod242> ' SCHLUNDTECH_API=\"https://gateway.schlundtech.de\" # Arguments: # txtdomain # txt dns_schlundtech_add() { fulldomain=\"$1\" txtvalue=\"$2\" SCHLUNDTECH_USER=\"${SCHLUNDTECH_USER:-$(_readaccountconf_mutable SCHLUNDTECH_USER)}\" SCHLUNDTECH_PASSWORD=\"${SCHLUNDTECH_PASSWORD:-$(_readaccountconf_mutable SCHLUNDTECH_PASSWORD)}\" if [ -z \"$SCHLUNDTECH_USER\" ] || [ -z \"$SCHLUNDTECH_PASSWORD\" ]; then _err \"You didn't specify schlundtech user and password.\" return 1 fi _saveaccountconf_mutable SCHLUNDTECH_USER \"$SCHLUNDTECH_USER\" _saveaccountconf_mutable SCHLUNDTECH_PASSWORD \"$SCHLUNDTECH_PASSWORD\" _debug \"First detect the root zone\" if ! _get_autodns_zone \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _zone \"$_zone\" _debug _system_ns \"$_system_ns\" _info \"Adding TXT record\" autodns_response=\"$(_autodns_zone_update \"$_zone\" \"$_sub_domain\" \"$txtvalue\" \"$_system_ns\")\" if [ \"$?\" -eq \"0\" ]; then _info \"Added, OK\" return 0 fi return 1 } # Arguments: # txtdomain # txt dns_schlundtech_rm() { fulldomain=\"$1\" txtvalue=\"$2\" SCHLUNDTECH_USER=\"${SCHLUNDTECH_USER:-$(_readaccountconf_mutable SCHLUNDTECH_USER)}\" SCHLUNDTECH_PASSWORD=\"${SCHLUNDTECH_PASSWORD:-$(_readaccountconf_mutable SCHLUNDTECH_PASSWORD)}\" if [ -z \"$SCHLUNDTECH_USER\" ] || [ -z \"$SCHLUNDTECH_PASSWORD\" ]; then _err \"You didn't specify schlundtech user and password.\" return 1 fi _debug \"First detect the root zone\" if ! _get_autodns_zone \"$fulldomain\"; then _err \"zone not found\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _zone \"$_zone\" _debug _system_ns \"$_system_ns\" _info \"Delete TXT record\" autodns_response=\"$(_autodns_zone_cleanup \"$_zone\" \"$_sub_domain\" \"$txtvalue\" \"$_system_ns\")\" if [ \"$?\" -eq \"0\" ]; then _info \"Deleted, OK\" return 0 fi return 1 } #################### Private functions below ################################## # Arguments: # fulldomain # Returns: # _sub_domain=_acme-challenge.www # _zone=domain.com # _system_ns _get_autodns_zone() { domain=\"$1\" i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then # not valid return 1 fi autodns_response=\"$(_autodns_zone_inquire \"$h\")\" if [ \"$?\" -ne \"0\" ]; then _err \"invalid domain\" return 1 fi if _contains \"$autodns_response\" \"<summary>1</summary>\" >/dev/null; then _zone=\"$(echo \"$autodns_response\" | _egrep_o '<name>[^<]*</name>' | cut -d '>' -f 2 | cut -d '<' -f 1)\" _system_ns=\"$(echo \"$autodns_response\" | _egrep_o '<system_ns>[^<]*</system_ns>' | cut -d '>' -f 2 | cut -d '<' -f 1)\" _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _build_request_auth_xml() { printf \"<auth> <user>%s</user> <password>%s</password> <context>10</context> </auth>\" \"$SCHLUNDTECH_USER\" \"$SCHLUNDTECH_PASSWORD\" } # Arguments: # zone _build_zone_inquire_xml() { printf \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?> <request> %s <task> <code>0205</code> <view> <children>1</children> <limit>1</limit> </view> <where> <key>name</key> <operator>eq</operator> <value>%s</value> </where> </task> </request>\" \"$(_build_request_auth_xml)\" \"$1\" } # Arguments: # zone # subdomain # txtvalue # system_ns _build_zone_update_xml() { printf \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?> <request> %s <task> <code>0202001</code> <default> <rr_add> <name>%s</name> <ttl>600</ttl> <type>TXT</type> <value>%s</value> </rr_add> </default> <zone> <name>%s</name> <system_ns>%s</system_ns> </zone> </task> </request>\" \"$(_build_request_auth_xml)\" \"$2\" \"$3\" \"$1\" \"$4\" } # Arguments: # zone _autodns_zone_inquire() { request_data=\"$(_build_zone_inquire_xml \"$1\")\" autodns_response=\"$(_autodns_api_call \"$request_data\")\" ret=\"$?\" printf \"%s\" \"$autodns_response\" return \"$ret\" } # Arguments: # zone # subdomain # txtvalue # system_ns _autodns_zone_update() { request_data=\"$(_build_zone_update_xml \"$1\" \"$2\" \"$3\" \"$4\")\" autodns_response=\"$(_autodns_api_call \"$request_data\")\" ret=\"$?\" printf \"%s\" \"$autodns_response\" return \"$ret\" } # Arguments: # zone # subdomain # txtvalue # system_ns _autodns_zone_cleanup() { request_data=\"$(_build_zone_update_xml \"$1\" \"$2\" \"$3\" \"$4\")\" # replace 'rr_add>' with 'rr_rem>' in request_data request_data=\"$(printf -- \"%s\" \"$request_data\" | sed 's/rr_add>/rr_rem>/g')\" autodns_response=\"$(_autodns_api_call \"$request_data\")\" ret=\"$?\" printf \"%s\" \"$autodns_response\" return \"$ret\" } # Arguments: # request_data _autodns_api_call() { request_data=\"$1\" _debug request_data \"$request_data\" autodns_response=\"$(_post \"$request_data\" \"$SCHLUNDTECH_API\")\" ret=\"$?\" _debug autodns_response \"$autodns_response\" if [ \"$ret\" -ne \"0\" ]; then _err \"error\" return 1 fi if _contains \"$autodns_response\" \"<type>success</type>\" >/dev/null; then _info \"success\" printf \"%s\" \"$autodns_response\" return 0 fi return 1 }"
        },
        {
            "filename": "file_278.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_278.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_selectel_info='Selectel.com Domains: Selectel.ru Site: Selectel.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_selectel Options: SL_Key API Key ' SL_Api=\"https://api.selectel.ru/domains/v1\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_selectel_add() { fulldomain=$1 txtvalue=$2 SL_Key=\"${SL_Key:-$(_readaccountconf_mutable SL_Key)}\" if [ -z \"$SL_Key\" ]; then SL_Key=\"\" _err \"You don't specify selectel.ru api key yet.\" _err \"Please create you key and try again.\" return 1 fi #save the api key to the account conf file. _saveaccountconf_mutable SL_Key \"$SL_Key\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if _sl_rest POST \"/$_domain_id/records/\" \"{\\\"type\\\": \\\"TXT\\\", \\\"ttl\\\": 60, \\\"name\\\": \\\"$fulldomain\\\", \\\"content\\\": \\\"$txtvalue\\\"}\"; then if _contains \"$response\" \"$txtvalue\" || _contains \"$response\" \"record_already_exists\"; then _info \"Added, OK\" return 0 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_selectel_rm() { fulldomain=$1 txtvalue=$2 SL_Key=\"${SL_Key:-$(_readaccountconf_mutable SL_Key)}\" if [ -z \"$SL_Key\" ]; then SL_Key=\"\" _err \"You don't specify slectel api key yet.\" _err \"Please create you key and try again.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _sl_rest GET \"/${_domain_id}/records/\" if ! _contains \"$response\" \"$txtvalue\"; then _err \"Txt record not found\" return 1 fi _record_seg=\"$(echo \"$response\" | _egrep_o \"[^{]*\\\"content\\\" *: *\\\"$txtvalue\\\"[^}]*}\")\" _debug2 \"_record_seg\" \"$_record_seg\" if [ -z \"$_record_seg\" ]; then _err \"can not find _record_seg\" return 1 fi _record_id=\"$(echo \"$_record_seg\" | tr \",\" \"\\n\" | tr \"}\" \"\\n\" | tr -d \" \" | grep \"\\\"id\\\"\" | cut -d : -f 2)\" _debug2 \"_record_id\" \"$_record_id\" if [ -z \"$_record_id\" ]; then _err \"can not find _record_id\" return 1 fi if ! _sl_rest DELETE \"/$_domain_id/records/$_record_id\"; then _err \"Delete record error.\" return 1 fi return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 if ! _sl_rest GET \"/\"; then return 1 fi i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"\\\"name\\\" *: *\\\"$h\\\",\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h _debug \"Getting domain id for $h\" if ! _sl_rest GET \"/$h\"; then return 1 fi _domain_id=\"$(echo \"$response\" | tr \",\" \"\\n\" | tr \"}\" \"\\n\" | tr -d \" \" | grep \"\\\"id\\\":\" | cut -d : -f 2)\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _sl_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"X-Token: $SL_Key\" export _H2=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$SL_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$SL_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_279.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_279.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_selfhost_info='SelfHost.de Site: SelfHost.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_selfhost Options: SELFHOSTDNS_USERNAME Username SELFHOSTDNS_PASSWORD Password SELFHOSTDNS_MAP Subdomain name Issues: github.com/acmesh-official/acme.sh/issues/4291 Author: Marvin Edeler ' dns_selfhost_add() { fulldomain=$1 txt=$2 _info \"Calling acme-dns on selfhost\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txt\" SELFHOSTDNS_UPDATE_URL=\"https://selfhost.de/cgi-bin/api.pl\" # Get values, but don't save until we successfully validated SELFHOSTDNS_USERNAME=\"${SELFHOSTDNS_USERNAME:-$(_readaccountconf_mutable SELFHOSTDNS_USERNAME)}\" SELFHOSTDNS_PASSWORD=\"${SELFHOSTDNS_PASSWORD:-$(_readaccountconf_mutable SELFHOSTDNS_PASSWORD)}\" # These values are domain dependent, so read them from there SELFHOSTDNS_MAP=\"${SELFHOSTDNS_MAP:-$(_readdomainconf SELFHOSTDNS_MAP)}\" # Selfhost api can't dynamically add TXT record, # so we have to store the last used RID of the domain to support a second RID for wildcard domains # (format: 'fulldomainA:lastRid fulldomainB:lastRid ...') SELFHOSTDNS_MAP_LAST_USED_INTERNAL=$(_readdomainconf SELFHOSTDNS_MAP_LAST_USED_INTERNAL) if [ -z \"${SELFHOSTDNS_USERNAME:-}\" ] || [ -z \"${SELFHOSTDNS_PASSWORD:-}\" ]; then _err \"SELFHOSTDNS_USERNAME and SELFHOSTDNS_PASSWORD must be set\" return 1 fi # get the domain entry from SELFHOSTDNS_MAP # only match full domains (at the beginning of the string or with a leading whitespace), # e.g. don't match mytest.example.com or sub.test.example.com for test.example.com # if the domain is defined multiple times only the last occurance will be matched mapEntry=$(echo \"$SELFHOSTDNS_MAP\" | sed -n -E \"s/(^|^.*[[:space:]])($fulldomain)(:[[:digit:]]+)([:]?[[:digit:]]*)(.*)/\\2\\3\\4/p\") _debug2 mapEntry \"$mapEntry\" if test -z \"$mapEntry\"; then _err \"SELFHOSTDNS_MAP must contain the fulldomain incl. prefix and at least one RID\" return 1 fi # get the RIDs from the map entry rid1=$(echo \"$mapEntry\" | cut -d: -f2) rid2=$(echo \"$mapEntry\" | cut -d: -f3) # read last used rid domain lastUsedRidForDomainEntry=$(echo \"$SELFHOSTDNS_MAP_LAST_USED_INTERNAL\" | sed -n -E \"s/(^|^.*[[:space:]])($fulldomain:[[:digit:]]+)(.*)/\\2/p\") _debug2 lastUsedRidForDomainEntry \"$lastUsedRidForDomainEntry\" lastUsedRidForDomain=$(echo \"$lastUsedRidForDomainEntry\" | cut -d: -f2) rid=\"$rid1\" if [ \"$lastUsedRidForDomain\" = \"$rid\" ] && ! test -z \"$rid2\"; then rid=\"$rid2\" fi _info \"Trying to add $txt on selfhost for rid: $rid\" data=\"?username=$SELFHOSTDNS_USERNAME&password=$SELFHOSTDNS_PASSWORD&rid=$rid&content=$txt\" response=\"$(_get \"$SELFHOSTDNS_UPDATE_URL$data\")\" if ! echo \"$response\" | grep \"200 OK\" >/dev/null; then _err \"Invalid response of acme-dns for selfhost\" return 1 fi # write last used rid domain newLastUsedRidForDomainEntry=\"$fulldomain:$rid\" if ! test -z \"$lastUsedRidForDomainEntry\"; then # replace last used rid entry for domain SELFHOSTDNS_MAP_LAST_USED_INTERNAL=$(echo \"$SELFHOSTDNS_MAP_LAST_USED_INTERNAL\" | sed -n -E \"s/$lastUsedRidForDomainEntry/$newLastUsedRidForDomainEntry/p\") else # add last used rid entry for domain if test -z \"$SELFHOSTDNS_MAP_LAST_USED_INTERNAL\"; then SELFHOSTDNS_MAP_LAST_USED_INTERNAL=\"$newLastUsedRidForDomainEntry\" else SELFHOSTDNS_MAP_LAST_USED_INTERNAL=\"$SELFHOSTDNS_MAP_LAST_USED_INTERNAL $newLastUsedRidForDomainEntry\" fi fi # Now that we know the values are good, save them _saveaccountconf_mutable SELFHOSTDNS_USERNAME \"$SELFHOSTDNS_USERNAME\" _saveaccountconf_mutable SELFHOSTDNS_PASSWORD \"$SELFHOSTDNS_PASSWORD\" # These values are domain dependent, so store them there _savedomainconf SELFHOSTDNS_MAP \"$SELFHOSTDNS_MAP\" _savedomainconf SELFHOSTDNS_MAP_LAST_USED_INTERNAL \"$SELFHOSTDNS_MAP_LAST_USED_INTERNAL\" } dns_selfhost_rm() { fulldomain=$1 txt=$2 _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txt\" _info \"Creating and removing of records is not supported by selfhost API, will not delete anything.\" }"
        },
        {
            "filename": "file_280.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_280.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_servercow_info='ServerCow.de Site: ServerCow.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_servercow Options: SERVERCOW_API_Username Username SERVERCOW_API_Password Password Issues: github.com/jhartlep/servercow-dns-api/issues Author: Jens Hartlep ' SERVERCOW_API=\"https://api.servercow.de/dns/v1/domains\" # Usage dns_servercow_add _acme-challenge.www.domain.com \"abcdefghijklmnopqrstuvwxyz\" dns_servercow_add() { fulldomain=$1 txtvalue=$2 _info \"Using servercow\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" SERVERCOW_API_Username=\"${SERVERCOW_API_Username:-$(_readaccountconf_mutable SERVERCOW_API_Username)}\" SERVERCOW_API_Password=\"${SERVERCOW_API_Password:-$(_readaccountconf_mutable SERVERCOW_API_Password)}\" if [ -z \"$SERVERCOW_API_Username\" ] || [ -z \"$SERVERCOW_API_Password\" ]; then SERVERCOW_API_Username=\"\" SERVERCOW_API_Password=\"\" _err \"You don't specify servercow api username and password yet.\" _err \"Please create your username and password and try again.\" return 1 fi # save the credentials to the account conf file _saveaccountconf_mutable SERVERCOW_API_Username \"$SERVERCOW_API_Username\" _saveaccountconf_mutable SERVERCOW_API_Password \"$SERVERCOW_API_Password\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # check whether a txt record already exists for the subdomain if printf -- \"%s\" \"$response\" | grep \"{\\\"name\\\":\\\"$_sub_domain\\\",\\\"ttl\\\":20,\\\"type\\\":\\\"TXT\\\"\" >/dev/null; then _info \"A txt record with the same name already exists.\" # trim the string on the left txtvalue_old=${response#*{\\\"name\\\":\\\"\"$_sub_domain\"\\\",\\\"ttl\\\":20,\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"} # trim the string on the right txtvalue_old=${txtvalue_old%%\\\"*} _debug txtvalue_old \"$txtvalue_old\" _info \"Add the new txtvalue to the existing txt record.\" if _servercow_api POST \"$_domain\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$fulldomain\\\",\\\"content\\\":[\\\"$txtvalue\\\",\\\"$txtvalue_old\\\"],\\\"ttl\\\":20}\"; then if printf -- \"%s\" \"$response\" | grep \"ok\" >/dev/null; then _info \"Added additional txtvalue, OK\" return 0 else _err \"add txt record error.\" return 1 fi fi _err \"add txt record error.\" return 1 else _info \"There is no txt record with the name yet.\" if _servercow_api POST \"$_domain\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$fulldomain\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":20}\"; then if printf -- \"%s\" \"$response\" | grep \"ok\" >/dev/null; then _info \"Added, OK\" return 0 else _err \"add txt record error.\" return 1 fi fi _err \"add txt record error.\" return 1 fi return 1 } # Usage fulldomain txtvalue # Remove the txt record after validation dns_servercow_rm() { fulldomain=$1 txtvalue=$2 _info \"Using servercow\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$fulldomain\" SERVERCOW_API_Username=\"${SERVERCOW_API_Username:-$(_readaccountconf_mutable SERVERCOW_API_Username)}\" SERVERCOW_API_Password=\"${SERVERCOW_API_Password:-$(_readaccountconf_mutable SERVERCOW_API_Password)}\" if [ -z \"$SERVERCOW_API_Username\" ] || [ -z \"$SERVERCOW_API_Password\" ]; then SERVERCOW_API_Username=\"\" SERVERCOW_API_Password=\"\" _err \"You don't specify servercow api username and password yet.\" _err \"Please create your username and password and try again.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" if _servercow_api DELETE \"$_domain\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$fulldomain\\\"}\"; then if printf -- \"%s\" \"$response\" | grep \"ok\" >/dev/null; then _info \"Deleted, OK\" _contains \"$response\" '\"message\":\"ok\"' else _err \"delete txt record error.\" return 1 fi fi } #################### Private functions below ################################## # _acme-challenge.www.domain.com # returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { fulldomain=$1 i=2 p=1 while true; do _domain=$(printf \"%s\" \"$fulldomain\" | cut -d . -f $i-100) _debug _domain \"$_domain\" if [ -z \"$_domain\" ]; then # not valid return 1 fi if ! _servercow_api GET \"$_domain\"; then return 1 fi if ! _contains \"$response\" '\"error\":\"no such domain in user context\"' >/dev/null; then _sub_domain=$(printf \"%s\" \"$fulldomain\" | cut -d . -f 1-$p) if [ -z \"$_sub_domain\" ]; then # not valid return 1 fi return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _servercow_api() { method=$1 domain=$2 data=\"$3\" export _H1=\"Content-Type: application/json\" export _H2=\"X-Auth-Username: $SERVERCOW_API_Username\" export _H3=\"X-Auth-Password: $SERVERCOW_API_Password\" if [ \"$method\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$SERVERCOW_API/$domain\" \"\" \"$method\")\" else response=\"$(_get \"$SERVERCOW_API/$domain\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $domain\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_281.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_281.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_simply_info='Simply.com Site: Simply.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_simply Options: SIMPLY_AccountName Account name SIMPLY_ApiKey API Key ' #SIMPLY_Api=\"https://api.simply.com/2/\" SIMPLY_Api_Default=\"https://api.simply.com/2\" #This is used for determining success of REST call SIMPLY_SUCCESS_CODE='\"status\":200' ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_simply_add() { fulldomain=$1 txtvalue=$2 if ! _simply_load_config; then return 1 fi _simply_save_config _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if ! _simply_add_record \"$_domain\" \"$_sub_domain\" \"$txtvalue\"; then _err \"Could not add DNS record\" return 1 fi return 0 } dns_simply_rm() { fulldomain=$1 txtvalue=$2 if ! _simply_load_config; then return 1 fi _simply_save_config _debug \"Find the DNS zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug txtvalue \"$txtvalue\" _info \"Getting all existing records\" if ! _simply_get_all_records \"$_domain\"; then _err \"invalid domain\" return 1 fi records=$(echo \"$response\" | tr '{' \"\\n\" | grep 'record_id\\|type\\|data\\|\\name' | sed 's/\\\"record_id/;\\\"record_id/' | tr \"\\n\" ' ' | tr -d ' ' | tr ';' ' ') nr_of_deleted_records=0 _info \"Fetching txt record\" for record in $records; do _debug record \"$record\" record_data=$(echo \"$record\" | sed -n \"s/.*\\\"data\\\":\\\"\\([^\\\"]*\\)\\\".*/\\1/p\") record_type=$(echo \"$record\" | sed -n \"s/.*\\\"type\\\":\\\"\\([^\\\"]*\\)\\\".*/\\1/p\") _debug2 record_data \"$record_data\" _debug2 record_type \"$record_type\" if [ \"$record_data\" = \"$txtvalue\" ] && [ \"$record_type\" = \"TXT\" ]; then record_id=$(echo \"$record\" | cut -d \",\" -f 1 | grep \"record_id\" | cut -d \":\" -f 2) _info \"Deleting record $record\" _debug2 record_id \"$record_id\" if [ \"$record_id\" -gt 0 ]; then if ! _simply_delete_record \"$_domain\" \"$_sub_domain\" \"$record_id\"; then _err \"Record with id $record_id could not be deleted\" return 1 fi nr_of_deleted_records=1 break else _err \"Fetching record_id could not be done, this should not happen, exiting function. Failing record is $record\" break fi fi done if [ \"$nr_of_deleted_records\" -eq 0 ]; then _err \"No record deleted, the DNS record needs to be removed manually.\" else _info \"Deleted $nr_of_deleted_records record\" fi return 0 } #################### Private functions below ################################## _simply_load_config() { SIMPLY_Api=\"${SIMPLY_Api:-$(_readaccountconf_mutable SIMPLY_Api)}\" SIMPLY_AccountName=\"${SIMPLY_AccountName:-$(_readaccountconf_mutable SIMPLY_AccountName)}\" SIMPLY_ApiKey=\"${SIMPLY_ApiKey:-$(_readaccountconf_mutable SIMPLY_ApiKey)}\" if [ -z \"$SIMPLY_Api\" ]; then SIMPLY_Api=\"$SIMPLY_Api_Default\" fi if [ -z \"$SIMPLY_AccountName\" ] || [ -z \"$SIMPLY_ApiKey\" ]; then SIMPLY_AccountName=\"\" SIMPLY_ApiKey=\"\" _err \"A valid Simply API account and apikey not provided.\" _err \"Please provide a valid API user and try again.\" return 1 fi return 0 } _simply_save_config() { if [ \"$SIMPLY_Api\" != \"$SIMPLY_Api_Default\" ]; then _saveaccountconf_mutable SIMPLY_Api \"$SIMPLY_Api\" fi _saveaccountconf_mutable SIMPLY_AccountName \"$SIMPLY_AccountName\" _saveaccountconf_mutable SIMPLY_ApiKey \"$SIMPLY_ApiKey\" } _simply_get_all_records() { domain=$1 if ! _simply_rest GET \"my/products/$domain/dns/records/\"; then return 1 fi return 0 } _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi if ! _simply_rest GET \"my/products/$h/dns/\"; then return 1 fi if ! _contains \"$response\" \"$SIMPLY_SUCCESS_CODE\"; then _debug \"$h not found\" else _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } _simply_add_record() { domain=$1 sub_domain=$2 txtval=$3 data=\"{\\\"name\\\": \\\"$sub_domain\\\", \\\"type\\\":\\\"TXT\\\", \\\"data\\\": \\\"$txtval\\\", \\\"priority\\\":0, \\\"ttl\\\": 3600}\" if ! _simply_rest POST \"my/products/$domain/dns/records/\" \"$data\"; then _err \"Adding record not successfull!\" return 1 fi if ! _contains \"$response\" \"$SIMPLY_SUCCESS_CODE\"; then _err \"Call to API not sucessfull, see below message for more details\" _err \"$response\" return 1 fi return 0 } _simply_delete_record() { domain=$1 sub_domain=$2 record_id=$3 _debug record_id \"Delete record with id $record_id\" if ! _simply_rest DELETE \"my/products/$domain/dns/records/$record_id/\"; then _err \"Deleting record not successfull!\" return 1 fi if ! _contains \"$response\" \"$SIMPLY_SUCCESS_CODE\"; then _err \"Call to API not sucessfull, see below message for more details\" _err \"$response\" return 1 fi return 0 } _simply_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug2 data \"$data\" _debug2 ep \"$ep\" _debug2 m \"$m\" basicauth=$(printf \"%s:%s\" \"$SIMPLY_AccountName\" \"$SIMPLY_ApiKey\" | _base64) if [ \"$basicauth\" ]; then export _H1=\"Authorization: Basic $basicauth\" fi export _H2=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then response=\"$(_post \"$data\" \"$SIMPLY_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$SIMPLY_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi response=\"$(echo \"$response\" | _normalizeJson)\" _debug2 response \"$response\" if _contains \"$response\" \"Invalid account authorization\"; then _err \"It seems that your api key or accountnumber is not correct.\" return 1 fi return 0 }"
        },
        {
            "filename": "file_282.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_282.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_tele3_info='tele3.cz Site: tele3.cz Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#tele3 Options: TELE3_Key API Key TELE3_Secret API Secret Author: Roman Blizik <https://github.com/par-pa> ' TELE3_API=\"https://www.tele3.cz/acme/\" ######## Public functions ##################### dns_tele3_add() { _info \"Using TELE3 DNS\" data=\"\\\"ope\\\":\\\"add\\\", \\\"domain\\\":\\\"$1\\\", \\\"value\\\":\\\"$2\\\"\" if ! _tele3_call; then _err \"Publish zone failed\" return 1 fi _info \"Zone published\" } dns_tele3_rm() { _info \"Using TELE3 DNS\" data=\"\\\"ope\\\":\\\"rm\\\", \\\"domain\\\":\\\"$1\\\", \\\"value\\\":\\\"$2\\\"\" if ! _tele3_call; then _err \"delete TXT record failed\" return 1 fi _info \"TXT record successfully deleted\" } #################### Private functions below ################################## _tele3_init() { TELE3_Key=\"${TELE3_Key:-$(_readaccountconf_mutable TELE3_Key)}\" TELE3_Secret=\"${TELE3_Secret:-$(_readaccountconf_mutable TELE3_Secret)}\" if [ -z \"$TELE3_Key\" ] || [ -z \"$TELE3_Secret\" ]; then TELE3_Key=\"\" TELE3_Secret=\"\" _err \"You must export variables: TELE3_Key and TELE3_Secret\" return 1 fi #save the config variables to the account conf file. _saveaccountconf_mutable TELE3_Key \"$TELE3_Key\" _saveaccountconf_mutable TELE3_Secret \"$TELE3_Secret\" } _tele3_call() { _tele3_init data=\"{\\\"key\\\":\\\"$TELE3_Key\\\", \\\"secret\\\":\\\"$TELE3_Secret\\\", $data}\" _debug data \"$data\" response=\"$(_post \"$data\" \"$TELE3_API\" \"\" \"POST\")\" _debug response \"$response\" if [ \"$response\" != \"success\" ]; then _err \"$response\" return 1 fi }"
        },
        {
            "filename": "file_283.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_283.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_tencent_info='Tencent.com Site: cloud.Tencent.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_tencent Options: Tencent_SecretId Secret ID Tencent_SecretKey Secret Key Issues: github.com/acmesh-official/acme.sh/issues/4781 ' Tencent_API=\"https://dnspod.tencentcloudapi.com\" #Usage: dns_tencent_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_tencent_add() { fulldomain=$1 txtvalue=$2 Tencent_SecretId=\"${Tencent_SecretId:-$(_readaccountconf_mutable Tencent_SecretId)}\" Tencent_SecretKey=\"${Tencent_SecretKey:-$(_readaccountconf_mutable Tencent_SecretKey)}\" if [ -z \"$Tencent_SecretId\" ] || [ -z \"$Tencent_SecretKey\" ]; then Tencent_SecretId=\"\" Tencent_SecretKey=\"\" _err \"You don't specify tencent api SecretId and SecretKey yet.\" return 1 fi #save the api SecretId and SecretKey to the account conf file. _saveaccountconf_mutable Tencent_SecretId \"$Tencent_SecretId\" _saveaccountconf_mutable Tencent_SecretKey \"$Tencent_SecretKey\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then return 1 fi _debug \"Add record\" _add_record_query \"$_domain\" \"$_sub_domain\" \"$txtvalue\" && _tencent_rest \"CreateRecord\" } dns_tencent_rm() { fulldomain=$1 txtvalue=$2 Tencent_SecretId=\"${Tencent_SecretId:-$(_readaccountconf_mutable Tencent_SecretId)}\" Tencent_SecretKey=\"${Tencent_SecretKey:-$(_readaccountconf_mutable Tencent_SecretKey)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then return 1 fi _debug \"Get record list\" attempt=1 max_attempts=5 while [ -z \"$record_id\" ] && [ \"$attempt\" -le $max_attempts ]; do _check_exist_query \"$_domain\" \"$_sub_domain\" \"$txtvalue\" && _tencent_rest \"DescribeRecordFilterList\" record_id=\"$(echo \"$response\" | _egrep_o \"\\\"RecordId\\\":\\s*[0-9]+\" | _egrep_o \"[0-9]+\")\" _debug2 record_id \"$record_id\" if [ -z \"$record_id\" ]; then _debug \"Due to TencentCloud API synchronization delay, record not found, waiting 10 seconds and retrying\" _sleep 10 attempt=$(_math \"$attempt + 1\") fi done record_id=\"$(echo \"$response\" | _egrep_o \"\\\"RecordId\\\":\\s*[0-9]+\" | _egrep_o \"[0-9]+\")\" _debug2 record_id \"$record_id\" if [ -z \"$record_id\" ]; then _debug \"record not found after $max_attempts attempts, skip\" else _debug \"Delete record\" _delete_record_query \"$record_id\" && _tencent_rest \"DeleteRecord\" fi } #################### Private functions below ################################## _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f \"$i\"-100) if [ -z \"$h\" ]; then #not valid return 1 fi _describe_records_query \"$h\" \"@\" if ! _tencent_rest \"DescribeRecordList\" \"ignore\"; then return 1 fi if _contains \"$response\" \"\\\"TotalCount\\\":\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-\"$p\") _debug _sub_domain \"$_sub_domain\" _domain=\"$h\" _debug _domain \"$_domain\" return 0 fi p=\"$i\" i=$(_math \"$i\" + 1) done return 1 } _tencent_rest() { action=$1 service=\"dnspod\" payload=\"${query}\" timestamp=$(date -u +%s) token=$(tencent_signature_v3 $service \"$action\" \"$payload\" \"$timestamp\") version=\"2021-03-23\" if ! response=\"$(tencent_api_request $service $version \"$action\" \"$payload\" \"$timestamp\")\"; then _err \"Error <$1>\" return 1 fi _debug2 response \"$response\" if [ -z \"$2\" ]; then message=\"$(echo \"$response\" | _egrep_o \"\\\"Message\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\")\" if [ \"$message\" ]; then _err \"$message\" return 1 fi fi } _add_record_query() { query=\"{\\\"Domain\\\":\\\"$1\\\",\\\"SubDomain\\\":\\\"$2\\\",\\\"RecordType\\\":\\\"TXT\\\",\\\"RecordLineId\\\":\\\"0\\\",\\\"RecordLine\\\":\\\"0\\\",\\\"Value\\\":\\\"$3\\\",\\\"TTL\\\":600}\" } _describe_records_query() { query=\"{\\\"Domain\\\":\\\"$1\\\",\\\"Limit\\\":3000}\" } _delete_record_query() { query=\"{\\\"Domain\\\":\\\"$_domain\\\",\\\"RecordId\\\":$1}\" } _check_exist_query() { _domain=\"$1\" _subdomain=\"$2\" _value=\"$3\" query=\"{\\\"Domain\\\":\\\"$_domain\\\",\\\"SubDomain\\\":\\\"$_subdomain\\\",\\\"RecordValue\\\":\\\"$_value\\\"}\" } # shell client for tencent cloud api v3 | @author: rehiy tencent_sha256() { printf %b \"$@\" | _digest sha256 hex } tencent_hmac_sha256() { k=$1 shift hex_key=$(printf %b \"$k\" | _hex_dump | tr -d ' ') printf %b \"$@\" | _hmac sha256 \"$hex_key\" hex } tencent_hmac_sha256_hexkey() { k=$1 shift printf %b \"$@\" | _hmac sha256 \"$k\" hex } tencent_signature_v3() { service=$1 action=$(echo \"$2\" | _lower_case) payload=${3:-'{}'} timestamp=${4:-$(date +%s)} domain=\"$service.tencentcloudapi.com\" secretId=${Tencent_SecretId:-'tencent-cloud-secret-id'} secretKey=${Tencent_SecretKey:-'tencent-cloud-secret-key'} algorithm='TC3-HMAC-SHA256' date=$(date -u -d \"@$timestamp\" +%Y-%m-%d 2>/dev/null) [ -z \"$date\" ] && date=$(date -u -r \"$timestamp\" +%Y-%m-%d) canonicalUri='/' canonicalQuery='' canonicalHeaders=\"content-type:application/json\\nhost:$domain\\nx-tc-action:$action\\n\" signedHeaders='content-type;host;x-tc-action' canonicalRequest=\"POST\\n$canonicalUri\\n$canonicalQuery\\n$canonicalHeaders\\n$signedHeaders\\n$(tencent_sha256 \"$payload\")\" credentialScope=\"$date/$service/tc3_request\" stringToSign=\"$algorithm\\n$timestamp\\n$credentialScope\\n$(tencent_sha256 \"$canonicalRequest\")\" secretDate=$(tencent_hmac_sha256 \"TC3$secretKey\" \"$date\") secretService=$(tencent_hmac_sha256_hexkey \"$secretDate\" \"$service\") secretSigning=$(tencent_hmac_sha256_hexkey \"$secretService\" 'tc3_request') signature=$(tencent_hmac_sha256_hexkey \"$secretSigning\" \"$stringToSign\") echo \"$algorithm Credential=$secretId/$credentialScope, SignedHeaders=$signedHeaders, Signature=$signature\" } tencent_api_request() { service=$1 version=$2 action=$3 payload=${4:-'{}'} timestamp=${5:-$(date +%s)} token=$(tencent_signature_v3 \"$service\" \"$action\" \"$payload\" \"$timestamp\") _H1=\"Content-Type: application/json\" _H2=\"Authorization: $token\" _H3=\"X-TC-Version: $version\" _H4=\"X-TC-Timestamp: $timestamp\" _H5=\"X-TC-Action: $action\" _post \"$payload\" \"$Tencent_API\" \"\" \"POST\" \"application/json\" }"
        },
        {
            "filename": "file_284.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_284.sh",
            "content": "#!/usr/bin/env sh # acme.sh DNS API for Timeweb Cloud provider (https://timeweb.cloud). # # Author: https://github.com/nikolaypronchev. # # Prerequisites: # Timeweb Cloud API JWT token. Obtain one from the Timeweb Cloud control panel # (\"API and Terraform\" section: https://timeweb.cloud/my/api-keys). The JWT token # must be provided to this script in one of two ways: # 1. As the \"TW_Token\" variable, for example: \"export TW_Token=eyJhbG...zUxMiIs\"; # 2. As a \"TW_Token\" config entry in acme.sh account config file # (usually located at ~/.acme.sh/account.conf by default). TW_Api=\"https://api.timeweb.cloud/api/v1\" ################ Public functions ################ # Adds an ACME DNS-01 challenge DNS TXT record via the Timeweb Cloud API. # # Param1: The ACME DNS-01 challenge FQDN. # Param2: The value of the ACME DNS-01 challenge TXT record. # # Example: dns_timeweb_add \"_acme-challenge.sub.domain.com\" \"D-52Wm...4uYM\" dns_timeweb_add() { _debug \"$(__green \"Timeweb DNS API\"): \\\"dns_timeweb_add\\\" started.\" _timeweb_set_acme_fqdn \"$1\" || return 1 _timeweb_set_acme_txt \"$2\" || return 1 _timeweb_check_token || return 1 _timeweb_split_acme_fqdn || return 1 _timeweb_dns_txt_add || return 1 _debug \"$(__green \"Timeweb DNS API\"): \\\"dns_timeweb_add\\\" finished.\" } # Removes a DNS TXT record via the Timeweb Cloud API. # # Param1: The ACME DNS-01 challenge FQDN. # Param2: The value of the ACME DNS-01 challenge TXT record. # # Example: dns_timeweb_rm \"_acme-challenge.sub.domain.com\" \"D-52Wm...4uYM\" dns_timeweb_rm() { _debug \"$(__green \"Timeweb DNS API\"): \\\"dns_timeweb_rm\\\" started.\" _timeweb_set_acme_fqdn \"$1\" || return 1 _timeweb_set_acme_txt \"$2\" || return 1 _timeweb_check_token || return 1 _timeweb_split_acme_fqdn || return 1 _timeweb_get_dns_txt || return 1 _timeweb_dns_txt_remove || return 1 _debug \"$(__green \"Timeweb DNS API\"): \\\"dns_timeweb_rm\\\" finished.\" } ################ Private functions ################ # Checks and sets the ACME DNS-01 challenge FQDN. # # Param1: The ACME DNS-01 challenge FQDN. # # Example: _timeweb_set_acme_fqdn \"_acme-challenge.sub.domain.com\" # # Sets the \"Acme_Fqdn\" variable (_acme-challenge.sub.domain.com) _timeweb_set_acme_fqdn() { Acme_Fqdn=$1 _debug \"Setting ACME DNS-01 challenge FQDN \\\"$Acme_Fqdn\\\".\" [ -z \"$Acme_Fqdn\" ] && { _err \"ACME DNS-01 challenge FQDN is empty.\" return 1 } return 0 } # Checks and sets the value of the ACME DNS-01 challenge TXT record. # # Param1: Value of the ACME DNS-01 challenge TXT record. # # Example: _timeweb_set_acme_txt \"D-52Wm...4uYM\" # # Sets the \"Acme_Txt\" variable to the provided value (D-52Wm...4uYM) _timeweb_set_acme_txt() { Acme_Txt=$1 _debug \"Setting the value of the ACME DNS-01 challenge TXT record to \\\"$Acme_Txt\\\".\" [ -z \"$Acme_Txt\" ] && { _err \"ACME DNS-01 challenge TXT record value is empty.\" return 1 } return 0 } # Checks if the Timeweb Cloud API JWT token is present (refer to the script description). # Adds or updates the token in the acme.sh account configuration. _timeweb_check_token() { _debug \"Checking for the presence of the Timeweb Cloud API JWT token.\" TW_Token=\"${TW_Token:-$(_readaccountconf_mutable TW_Token)}\" [ -z \"$TW_Token\" ] && { _err \"Timeweb Cloud API JWT token was not found.\" return 1 } _saveaccountconf_mutable TW_Token \"$TW_Token\" } # Divides the ACME DNS-01 challenge FQDN into its main domain and subdomain components. _timeweb_split_acme_fqdn() { _debug \"Trying to divide \\\"$Acme_Fqdn\\\" into its main domain and subdomain components.\" TW_Page_Limit=100 TW_Page_Offset=0 TW_Domains_Returned=\"\" while [ -z \"$TW_Domains_Returned\" ] || [ \"$TW_Domains_Returned\" -ge \"$TW_Page_Limit\" ]; do _timeweb_list_domains \"$TW_Page_Limit\" \"$TW_Page_Offset\" || return 1 # Remove the 'subdomains' subarray to prevent confusion with FQDNs. TW_Domains=$( echo \"$TW_Domains\" | sed 's/\"subdomains\":\\[[^]]*]//g' ) [ -z \"$TW_Domains\" ] && { _err \"Failed to parse the list of domains.\" return 1 } while TW_Domain=$( echo \"$TW_Domains\" | sed -n 's/.*{[^{]*\"fqdn\":\"\\([^\"]*\\)\"[^}]*}.*/\\1/p' ) [ -n \"$TW_Domain\" ] && { _timeweb_is_main_domain \"$TW_Domain\" && return 0 TW_Domains=$( echo \"$TW_Domains\" | sed 's/{\\([^{]*\"fqdn\":\"'\"$TW_Domain\"'\"[^}]*\\)}//' ) continue } do :; done TW_Page_Offset=$(_math \"$TW_Page_Offset\" + \"$TW_Page_Limit\") done _err \"Failed to divide \\\"$Acme_Fqdn\\\" into its main domain and subdomain components.\" return 1 } # Searches for a previously added DNS TXT record. # # Sets the \"TW_Dns_Txt_Id\" variable. _timeweb_get_dns_txt() { _debug \"Trying to locate a DNS TXT record with the value \\\"$Acme_Txt\\\".\" TW_Page_Limit=100 TW_Page_Offset=0 TW_Dns_Records_Returned=\"\" while [ -z \"$TW_Dns_Records_Returned\" ] || [ \"$TW_Dns_Records_Returned\" -ge \"$TW_Page_Limit\" ]; do _timeweb_list_dns_records \"$TW_Page_Limit\" \"$TW_Page_Offset\" || return 1 while Dns_Record=$( echo \"$TW_Dns_Records\" | sed -n 's/.*{\\([^{]*{[^{]*'\"$Acme_Txt\"'[^}]*}[^}]*\\)}.*/\\1/p' ) [ -n \"$Dns_Record\" ] && { _timeweb_is_added_txt \"$Dns_Record\" && return 0 TW_Dns_Records=$( echo \"$TW_Dns_Records\" | sed 's/{\\([^{]*{[^{]*'\"$Acme_Txt\"'[^}]*}[^}]*\\)}//' ) continue } do :; done TW_Page_Offset=$(_math \"$TW_Page_Offset\" + \"$TW_Page_Limit\") done _err \"DNS TXT record was not found.\" return 1 } # Lists domains via the Timeweb Cloud API. # # Param 1: Limit for listed domains. # Param 2: Offset for domains list. # # Sets the \"TW_Domains\" variable. # Sets the \"TW_Domains_Returned\" variable. _timeweb_list_domains() { _debug \"Listing domains via Timeweb Cloud API. Limit: $1, offset: $2.\" export _H1=\"Authorization: Bearer $TW_Token\" if ! TW_Domains=$(_get \"$TW_Api/domains?limit=$1&offset=$2\"); then _err \"The request to the Timeweb Cloud API failed.\" return 1 fi [ -z \"$TW_Domains\" ] && { _err \"Empty response from the Timeweb Cloud API.\" return 1 } TW_Domains_Returned=$( echo \"$TW_Domains\" | sed 's/.*\"meta\":{\"total\":\\([0-9]*\\)[^0-9].*/\\1/' ) [ -z \"$TW_Domains_Returned\" ] && { _err \"Failed to extract the total count of domains.\" return 1 } [ \"$TW_Domains_Returned\" -eq \"0\" ] && { _err \"Domains are missing.\" return 1 } _debug \"Domains returned by Timeweb Cloud API: $TW_Domains_Returned.\" } # Lists domain DNS records via the Timeweb Cloud API. # # Param 1: Limit for listed DNS records. # Param 2: Offset for DNS records list. # # Sets the \"TW_Dns_Records\" variable. # Sets the \"TW_Dns_Records_Returned\" variable. _timeweb_list_dns_records() { _debug \"Listing domain DNS records via the Timeweb Cloud API. Limit: $1, offset: $2.\" export _H1=\"Authorization: Bearer $TW_Token\" if ! TW_Dns_Records=$(_get \"$TW_Api/domains/$TW_Main_Domain/dns-records?limit=$1&offset=$2\"); then _err \"The request to the Timeweb Cloud API failed.\" return 1 fi [ -z \"$TW_Dns_Records\" ] && { _err \"Empty response from the Timeweb Cloud API.\" return 1 } TW_Dns_Records_Returned=$( echo \"$TW_Dns_Records\" | sed 's/.*\"meta\":{\"total\":\\([0-9]*\\)[^0-9].*/\\1/' ) [ -z \"$TW_Dns_Records_Returned\" ] && { _err \"Failed to extract the total count of DNS records.\" return 1 } [ \"$TW_Dns_Records_Returned\" -eq \"0\" ] && { _err \"DNS records are missing.\" return 1 } _debug \"DNS records returned by Timeweb Cloud API: $TW_Dns_Records_Returned.\" } # Verifies whether the domain is the primary domain for the ACME DNS-01 challenge FQDN. # The requirement is that the provided domain is the top-level domain # for the ACME DNS-01 challenge FQDN. # # Param 1: Domain object returned by Timeweb Cloud API. # # Sets the \"TW_Main_Domain\" variable (e.g. \"_acme-challenge.s1.domain.co.uk\" \u2192 \"domain.co.uk\"). # Sets the \"TW_Subdomains\" variable (e.g. \"_acme-challenge.s1.domain.co.uk\" \u2192 \"_acme-challenge.s1\"). _timeweb_is_main_domain() { _debug \"Checking if \\\"$1\\\" is the main domain of the ACME DNS-01 challenge FQDN.\" [ -z \"$1\" ] && { _debug \"Failed to extract FQDN. Skipping domain.\" return 1 } ! echo \".$Acme_Fqdn\" | grep -qi \"\\.$1$\" && { _debug \"Domain does not match the ACME DNS-01 challenge FQDN. Skipping domain.\" return 1 } TW_Main_Domain=$1 TW_Subdomains=$( echo \"$Acme_Fqdn\" | sed \"s/\\.*.\\{${#1}\\}$//\" ) _debug \"Matched domain. ACME DNS-01 challenge FQDN split as [$TW_Subdomains].[$TW_Main_Domain].\" return 0 } # Verifies whether a DNS record was previously added based on the following criteria: # - The value matches the ACME DNS-01 challenge TXT record value; # - The record type is TXT; # - The subdomain matches the ACME DNS-01 challenge FQDN. # # Param 1: DNS record object returned by Timeweb Cloud API. # # Sets the \"TW_Dns_Txt_Id\" variable. _timeweb_is_added_txt() { _debug \"Checking if \\\"$1\\\" is a previously added DNS TXT record.\" echo \"$1\" | grep -qv '\"type\":\"TXT\"' && { _debug \"Not a TXT record. Skipping the record.\" return 1 } if [ -n \"$TW_Subdomains\" ]; then echo \"$1\" | grep -qvi \"\\\"subdomain\\\":\\\"$TW_Subdomains\\\"\" && { _debug \"Subdomains do not match. Skipping the record.\" return 1 } else echo \"$1\" | grep -q '\"subdomain\\\":\"..*\"' && { _debug \"Subdomains do not match. Skipping the record.\" return 1 } fi TW_Dns_Txt_Id=$( echo \"$1\" | sed 's/.*\"id\":\\([0-9]*\\)[^0-9].*/\\1/' ) [ -z \"$TW_Dns_Txt_Id\" ] && { _debug \"Failed to extract the DNS record ID. Skipping the record.\" return 1 } _debug \"Matching DNS TXT record ID is \\\"$TW_Dns_Txt_Id\\\".\" return 0 } # Adds a DNS TXT record via the Timeweb Cloud API. _timeweb_dns_txt_add() { _debug \"Adding a new DNS TXT record via the Timeweb Cloud API.\" export _H1=\"Authorization: Bearer $TW_Token\" export _H2=\"Content-Type: application/json\" if ! TW_Response=$( _post \"{ \\\"subdomain\\\":\\\"$TW_Subdomains\\\", \\\"type\\\":\\\"TXT\\\", \\\"value\\\":\\\"$Acme_Txt\\\" }\" \\ \"$TW_Api/domains/$TW_Main_Domain/dns-records\" ); then _err \"The request to the Timeweb Cloud API failed.\" return 1 fi [ -z \"$TW_Response\" ] && { _err \"An unexpected empty response was received from the Timeweb Cloud API.\" return 1 } TW_Dns_Txt_Id=$( echo \"$TW_Response\" | sed 's/.*\"id\":\\([0-9]*\\)[^0-9].*/\\1/' ) [ -z \"$TW_Dns_Txt_Id\" ] && { _err \"Failed to extract the DNS TXT Record ID.\" return 1 } _debug \"DNS TXT record has been added. ID: \\\"$TW_Dns_Txt_Id\\\".\" } # Removes a DNS record via the Timeweb Cloud API. _timeweb_dns_txt_remove() { _debug \"Removing DNS record via the Timeweb Cloud API.\" export _H1=\"Authorization: Bearer $TW_Token\" if ! TW_Response=$( _post \\ \"\" \\ \"$TW_Api/domains/$TW_Main_Domain/dns-records/$TW_Dns_Txt_Id\" \\ \"\" \\ \"DELETE\" ); then _err \"The request to the Timeweb Cloud API failed.\" return 1 fi [ -n \"$TW_Response\" ] && { _err \"Received an unexpected response body from the Timeweb Cloud API.\" return 1 } _debug \"DNS TXT record with ID \\\"$TW_Dns_Txt_Id\\\" has been removed.\" }"
        },
        {
            "filename": "file_285.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_285.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_transip_info='TransIP.nl Site: TransIP.nl Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_transip Options: TRANSIP_Username Username TRANSIP_Key_File Private key file path Issues: github.com/acmesh-official/acme.sh/issues/2949 ' TRANSIP_Api_Url=\"https://api.transip.nl/v6\" TRANSIP_Token_Read_Only=\"false\" TRANSIP_Token_Expiration=\"30 minutes\" # You can't reuse a label token, so we leave this empty normally TRANSIP_Token_Label=\"\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_transip_add() { fulldomain=\"$1\" _debug fulldomain=\"$fulldomain\" txtvalue=\"$2\" _debug txtvalue=\"$txtvalue\" _transip_setup \"$fulldomain\" || return 1 _info \"Creating TXT record.\" if ! _transip_rest POST \"domains/$_domain/dns\" \"{\\\"dnsEntry\\\":{\\\"name\\\":\\\"$_sub_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"expire\\\":300}}\"; then _err \"Could not add TXT record.\" return 1 fi return 0 } dns_transip_rm() { fulldomain=$1 _debug fulldomain=\"$fulldomain\" txtvalue=$2 _debug txtvalue=\"$txtvalue\" _transip_setup \"$fulldomain\" || return 1 _info \"Removing TXT record.\" if ! _transip_rest DELETE \"domains/$_domain/dns\" \"{\\\"dnsEntry\\\":{\\\"name\\\":\\\"$_sub_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"expire\\\":300}}\"; then _err \"Could not remove TXT record $_sub_domain for $domain\" return 1 fi return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=\"$1\" i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" if _transip_rest GET \"domains/$h/dns\" && _contains \"$response\" \"dnsEntries\"; then return 0 fi p=$i i=$(_math \"$i\" + 1) done _err \"Unable to parse this domain\" return 1 } _transip_rest() { m=\"$1\" ep=\"$2\" data=\"$3\" _debug ep \"$ep\" export _H1=\"Accept: application/json\" export _H2=\"Authorization: Bearer $_token\" export _H4=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$TRANSIP_Api_Url/$ep\" \"\" \"$m\")\" retcode=$? else response=\"$(_get \"$TRANSIP_Api_Url/$ep\")\" retcode=$? fi if [ \"$retcode\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 } _transip_get_token() { nonce=$(echo \"TRANSIP$(_time)\" | _digest sha1 hex | cut -c 1-32) _debug nonce \"$nonce\" # make IP whitelisting configurable TRANSIP_Token_Global_Key=\"${TRANSIP_Token_Global_Key:-$(_readaccountconf_mutable TRANSIP_Token_Global_Key)}\" _saveaccountconf_mutable TRANSIP_Token_Global_Key \"$TRANSIP_Token_Global_Key\" data=\"{\\\"login\\\":\\\"${TRANSIP_Username}\\\",\\\"nonce\\\":\\\"${nonce}\\\",\\\"read_only\\\":\\\"${TRANSIP_Token_Read_Only}\\\",\\\"expiration_time\\\":\\\"${TRANSIP_Token_Expiration}\\\",\\\"label\\\":\\\"${TRANSIP_Token_Label}\\\",\\\"global_key\\\":\\\"${TRANSIP_Token_Global_Key:-false}\\\"}\" _debug data \"$data\" #_signature=$(printf \"%s\" \"$data\" | openssl dgst -sha512 -sign \"$TRANSIP_Key_File\" | _base64) _signature=$(printf \"%s\" \"$data\" | _sign \"$TRANSIP_Key_File\" \"sha512\") _debug2 _signature \"$_signature\" export _H1=\"Signature: $_signature\" export _H2=\"Content-Type: application/json\" response=\"$(_post \"$data\" \"$TRANSIP_Api_Url/auth\" \"\" \"POST\")\" retcode=$? _debug2 response \"$response\" if [ \"$retcode\" != \"0\" ]; then _err \"Authentication failed.\" return 1 fi if _contains \"$response\" \"token\"; then _token=\"$(echo \"$response\" | _normalizeJson | sed -n 's/^{\"token\":\"\\(.*\\)\"}/\\1/p')\" _debug _token \"$_token\" return 0 fi return 1 } _transip_setup() { fulldomain=$1 # retrieve the transip creds TRANSIP_Username=\"${TRANSIP_Username:-$(_readaccountconf_mutable TRANSIP_Username)}\" TRANSIP_Key_File=\"${TRANSIP_Key_File:-$(_readaccountconf_mutable TRANSIP_Key_File)}\" # check their vals for null if [ -z \"$TRANSIP_Username\" ] || [ -z \"$TRANSIP_Key_File\" ]; then TRANSIP_Username=\"\" TRANSIP_Key_File=\"\" _err \"You didn't specify a TransIP username and api key file location\" _err \"Please set those values and try again.\" return 1 fi # save the username and api key to the account conf file. _saveaccountconf_mutable TRANSIP_Username \"$TRANSIP_Username\" _saveaccountconf_mutable TRANSIP_Key_File \"$TRANSIP_Key_File\" # download key file if it's an URL if _startswith \"$TRANSIP_Key_File\" \"http\"; then _debug \"download transip key file\" TRANSIP_Key_URL=$TRANSIP_Key_File TRANSIP_Key_File=\"$(_mktemp)\" chmod 600 \"$TRANSIP_Key_File\" if ! _get \"$TRANSIP_Key_URL\" >\"$TRANSIP_Key_File\"; then _err \"Error getting key file from : $TRANSIP_Key_URL\" return 1 fi fi if [ -f \"$TRANSIP_Key_File\" ]; then if ! grep \"BEGIN PRIVATE KEY\" \"$TRANSIP_Key_File\" >/dev/null 2>&1; then _err \"Key file doesn't seem to be a valid key: ${TRANSIP_Key_File}\" return 1 fi else _err \"Can't read private key file: ${TRANSIP_Key_File}\" return 1 fi if [ -z \"$_token\" ]; then if ! _transip_get_token; then _err \"Can not get token.\" return 1 fi fi if [ -n \"${TRANSIP_Key_URL}\" ]; then _debug \"delete transip key file\" rm \"${TRANSIP_Key_File}\" TRANSIP_Key_File=$TRANSIP_Key_URL fi _get_root \"$fulldomain\" || return 1 return 0 }"
        },
        {
            "filename": "file_286.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_286.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_udr_info='united-domains Reselling Site: ud-reselling.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_udr Options: UDR_USER Username UDR_PASS Password Issues: github.com/acmesh-official/acme.sh/issues/3923 Author: Andreas Scherer <https://github.com/andischerer> ' UDR_API=\"https://api.domainreselling.de/api/call.cgi\" UDR_TTL=\"30\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"some_long_string_of_characters_go_here_from_lets_encrypt\" dns_udr_add() { fulldomain=$1 txtvalue=$2 UDR_USER=\"${UDR_USER:-$(_readaccountconf_mutable UDR_USER)}\" UDR_PASS=\"${UDR_PASS:-$(_readaccountconf_mutable UDR_PASS)}\" if [ -z \"$UDR_USER\" ] || [ -z \"$UDR_PASS\" ]; then UDR_USER=\"\" UDR_PASS=\"\" _err \"You didn't specify an UD-Reselling username and password yet\" return 1 fi # save the username and password to the account conf file. _saveaccountconf_mutable UDR_USER \"$UDR_USER\" _saveaccountconf_mutable UDR_PASS \"$UDR_PASS\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _dnszone \"${_dnszone}\" _debug \"Getting txt records\" if ! _udr_rest \"QueryDNSZoneRRList\" \"dnszone=${_dnszone}\"; then return 1 fi rr=\"${fulldomain}. ${UDR_TTL} IN TXT ${txtvalue}\" _debug resource_record \"${rr}\" if _contains \"$response\" \"$rr\" >/dev/null; then _err \"Error, it would appear that this record already exists. Please review existing TXT records for this domain.\" return 1 fi _info \"Adding record\" if ! _udr_rest \"UpdateDNSZone\" \"dnszone=${_dnszone}&addrr0=${rr}\"; then _err \"Adding the record did not succeed, please verify/check.\" return 1 fi _info \"Added, OK\" return 0 } dns_udr_rm() { fulldomain=$1 txtvalue=$2 UDR_USER=\"${UDR_USER:-$(_readaccountconf_mutable UDR_USER)}\" UDR_PASS=\"${UDR_PASS:-$(_readaccountconf_mutable UDR_PASS)}\" if [ -z \"$UDR_USER\" ] || [ -z \"$UDR_PASS\" ]; then UDR_USER=\"\" UDR_PASS=\"\" _err \"You didn't specify an UD-Reselling username and password yet\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _dnszone \"${_dnszone}\" _debug \"Getting txt records\" if ! _udr_rest \"QueryDNSZoneRRList\" \"dnszone=${_dnszone}\"; then return 1 fi rr=\"${fulldomain}. ${UDR_TTL} IN TXT ${txtvalue}\" _debug resource_record \"${rr}\" if _contains \"$response\" \"$rr\" >/dev/null; then if ! _udr_rest \"UpdateDNSZone\" \"dnszone=${_dnszone}&delrr0=${rr}\"; then _err \"Deleting the record did not succeed, please verify/check.\" return 1 fi _info \"Removed, OK\" return 0 else _info \"Text record is not present, will not delete anything.\" return 0 fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=1 if ! _udr_rest \"QueryDNSZoneList\" \"\"; then return 1 fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"${response}\" \"${h}.\" >/dev/null; then _dnszone=$(echo \"$response\" | _egrep_o \"${h}\") if [ \"$_dnszone\" ]; then return 0 fi return 1 fi i=$(_math \"$i\" + 1) done return 1 } _udr_rest() { if [ -n \"$2\" ]; then data=\"command=$1&$2\" else data=\"command=$1\" fi _debug data \"${data}\" response=\"$(_post \"${data}\" \"${UDR_API}?s_login=${UDR_USER}&s_pw=${UDR_PASS}\" \"\" \"POST\")\" _code=$(echo \"$response\" | _egrep_o \"code = ([0-9]+)\" | _head_n 1 | cut -d = -f 2 | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//') _description=$(echo \"$response\" | _egrep_o \"description = .*\" | _head_n 1 | cut -d = -f 2 | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//') _debug response_code \"$_code\" _debug response_description \"$_description\" if [ ! \"$_code\" = \"200\" ]; then _err \"DNS-API-Error: $_description\" return 1 fi return 0 }"
        },
        {
            "filename": "file_287.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_287.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_ultra_info='UltraDNS.com Site: UltraDNS.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_ultra Options: ULTRA_USR Username ULTRA_PWD Password Issues: github.com/acmesh-official/acme.sh/issues/2118 ' ULTRA_API=\"https://api.ultradns.com/v3/\" ULTRA_AUTH_API=\"https://api.ultradns.com/v2/\" #Usage: add _acme-challenge.www.domain.com \"some_long_string_of_characters_go_here_from_lets_encrypt\" dns_ultra_add() { fulldomain=$1 txtvalue=$2 export txtvalue ULTRA_USR=\"${ULTRA_USR:-$(_readaccountconf_mutable ULTRA_USR)}\" ULTRA_PWD=\"${ULTRA_PWD:-$(_readaccountconf_mutable ULTRA_PWD)}\" if [ -z \"$ULTRA_USR\" ] || [ -z \"$ULTRA_PWD\" ]; then ULTRA_USR=\"\" ULTRA_PWD=\"\" _err \"You didn't specify an UltraDNS username and password yet\" return 1 fi # save the username and password to the account conf file. _saveaccountconf_mutable ULTRA_USR \"$ULTRA_USR\" _saveaccountconf_mutable ULTRA_PWD \"$ULTRA_PWD\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"${_domain_id}\" _debug _sub_domain \"${_sub_domain}\" _debug _domain \"${_domain}\" _debug \"Getting txt records\" _ultra_rest GET \"zones/${_domain_id}/rrsets/TXT?q=value:${fulldomain}\" if printf \"%s\" \"$response\" | grep \\\"totalCount\\\" >/dev/null; then _err \"Error, it would appear that this record already exists. Please review existing TXT records for this domain.\" return 1 fi _info \"Adding record\" if _ultra_rest POST \"zones/$_domain_id/rrsets/TXT/${_sub_domain}\" '{\"ttl\":300,\"rdata\":[\"'\"${txtvalue}\"'\"]}'; then if _contains \"$response\" \"Successful\"; then _info \"Added, OK\" return 0 elif _contains \"$response\" \"Resource Record of type 16 with these attributes already exists\"; then _info \"Already exists, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" } dns_ultra_rm() { fulldomain=$1 txtvalue=$2 export txtvalue ULTRA_USR=\"${ULTRA_USR:-$(_readaccountconf_mutable ULTRA_USR)}\" ULTRA_PWD=\"${ULTRA_PWD:-$(_readaccountconf_mutable ULTRA_PWD)}\" if [ -z \"$ULTRA_USR\" ] || [ -z \"$ULTRA_PWD\" ]; then ULTRA_USR=\"\" ULTRA_PWD=\"\" _err \"You didn't specify an UltraDNS username and password yet\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"${_domain_id}\" _debug _sub_domain \"${_sub_domain}\" _debug _domain \"${domain}\" _debug \"Getting TXT records\" _ultra_rest GET \"zones/${_domain_id}/rrsets?q=kind:RECORDS+owner:${_sub_domain}\" if ! printf \"%s\" \"$response\" | grep \\\"resultInfo\\\" >/dev/null; then _err \"There was an error in obtaining the resource records for ${_domain_id}\" return 1 fi count=$(echo \"$response\" | _egrep_o \"\\\"returnedCount\\\":[^,]*\" | cut -d: -f2 | cut -d'}' -f1) _debug count \"${count}\" if [ \"${count}\" = \"\" ]; then _info \"Text record is not present, will not delete anything.\" else if ! _ultra_rest DELETE \"zones/$_domain_id/rrsets/TXT/${_sub_domain}\" '{\"ttl\":300,\"rdata\":[\"'\"${txtvalue}\"'\"]}'; then _err \"Deleting the record did not succeed, please verify/check.\" return 1 fi _contains \"$response\" \"\" fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" _debug response \"$response\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _ultra_rest GET \"zones\"; then return 1 fi if _contains \"${response}\" \"${h}.\" >/dev/null; then _domain_id=$(echo \"$response\" | _egrep_o \"${h}\" | head -1) if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"${h}\" _debug sub_domain \"${_sub_domain}\" _debug domain \"${_domain}\" return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _ultra_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" if [ -z \"$AUTH_TOKEN\" ]; then _ultra_login fi _debug TOKEN \"$AUTH_TOKEN\" export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: Bearer $AUTH_TOKEN\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$ULTRA_API$ep\" \"\" \"$m\")\" else response=\"$(_get \"$ULTRA_API$ep\")\" fi } _ultra_login() { export _H1=\"\" export _H2=\"\" AUTH_TOKEN=$(_post \"grant_type=password&username=${ULTRA_USR}&password=${ULTRA_PWD}\" \"${ULTRA_AUTH_API}authorization/token\" | cut -d, -f3 | cut -d\\\" -f4) export AUTH_TOKEN }"
        },
        {
            "filename": "file_288.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_288.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_unoeuro_info='unoeuro.com Deprecated. The unoeuro.com is now simply.com Site: unoeuro.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_unoeuro Options: UNO_Key API Key UNO_User Username ' Uno_Api=\"https://api.simply.com/1\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_unoeuro_add() { fulldomain=$1 txtvalue=$2 UNO_Key=\"${UNO_Key:-$(_readaccountconf_mutable UNO_Key)}\" UNO_User=\"${UNO_User:-$(_readaccountconf_mutable UNO_User)}\" if [ -z \"$UNO_Key\" ] || [ -z \"$UNO_User\" ]; then UNO_Key=\"\" UNO_User=\"\" _err \"You haven't specified a UnoEuro api key and account yet.\" _err \"Please create your key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable UNO_Key \"$UNO_Key\" _saveaccountconf_mutable UNO_User \"$UNO_User\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _uno_rest GET \"my/products/$h/dns/records\" if ! _contains \"$response\" \"\\\"status\\\": 200\" >/dev/null; then _err \"Error\" return 1 fi _info \"Adding record\" if _uno_rest POST \"my/products/$h/dns/records\" \"{\\\"name\\\":\\\"$fulldomain\\\",\\\"type\\\":\\\"TXT\\\",\\\"data\\\":\\\"$txtvalue\\\",\\\"ttl\\\":120,\\\"priority\\\":0}\"; then if _contains \"$response\" \"\\\"status\\\": 200\" >/dev/null; then _info \"Added, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi } #fulldomain txtvalue dns_unoeuro_rm() { fulldomain=$1 txtvalue=$2 UNO_Key=\"${UNO_Key:-$(_readaccountconf_mutable UNO_Key)}\" UNO_User=\"${UNO_User:-$(_readaccountconf_mutable UNO_User)}\" if [ -z \"$UNO_Key\" ] || [ -z \"$UNO_User\" ]; then UNO_Key=\"\" UNO_User=\"\" _err \"You haven't specified a UnoEuro api key and account yet.\" _err \"Please create your key and try again.\" return 1 fi if ! _contains \"$UNO_User\" \"UE\"; then _err \"It seems that the UNO_User=$UNO_User is not a valid username.\" _err \"Please check and retry.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _uno_rest GET \"my/products/$h/dns/records\" if ! _contains \"$response\" \"\\\"status\\\": 200\"; then _err \"Error\" return 1 fi if ! _contains \"$response\" \"$_sub_domain\"; then _info \"Don't need to remove.\" else for record_line_number in $(echo \"$response\" | grep -n \"$_sub_domain\" | cut -d : -f 1); do record_line_number=$(_math \"$record_line_number\" - 1) _debug \"record_line_number\" \"$record_line_number\" record_id=$(echo \"$response\" | _head_n \"$record_line_number\" | _tail_n 1 1 | _egrep_o \"[0-9]{1,}\") _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _uno_rest DELETE \"my/products/$h/dns/records/$record_id\"; then _err \"Delete record error.\" return 1 fi _contains \"$response\" \"\\\"status\\\": 200\" done fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=2 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _uno_rest GET \"my/products/$h/dns/records\"; then return 1 fi if _contains \"$response\" \"\\\"status\\\": 200\"; then _domain_id=$h if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _uno_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$Uno_Api/$UNO_User/$UNO_Key/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$Uno_Api/$UNO_User/$UNO_Key/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_289.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_289.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_variomedia_info='variomedia.de Site: variomedia.de Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_variomedia Options: VARIOMEDIA_API_TOKEN API Token Issues: github.com/acmesh-official/acme.sh/issues/2564 ' VARIOMEDIA_API=\"https://api.variomedia.de\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_variomedia_add() { fulldomain=$1 txtvalue=$2 _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" VARIOMEDIA_API_TOKEN=\"${VARIOMEDIA_API_TOKEN:-$(_readaccountconf_mutable VARIOMEDIA_API_TOKEN)}\" if test -z \"$VARIOMEDIA_API_TOKEN\"; then VARIOMEDIA_API_TOKEN=\"\" _err 'VARIOMEDIA_API_TOKEN was not exported' return 1 fi _saveaccountconf_mutable VARIOMEDIA_API_TOKEN \"$VARIOMEDIA_API_TOKEN\" _debug 'First detect the root zone' if ! _get_root \"$fulldomain\"; then return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" if ! _variomedia_rest POST \"dns-records\" \"{\\\"data\\\": {\\\"type\\\": \\\"dns-record\\\", \\\"attributes\\\": {\\\"record_type\\\": \\\"TXT\\\", \\\"name\\\": \\\"$_sub_domain\\\", \\\"domain\\\": \\\"$_domain\\\", \\\"data\\\": \\\"$txtvalue\\\", \\\"ttl\\\":300}}}\"; then _err \"$response\" return 1 fi _debug2 _response \"$response\" return 0 } #fulldomain txtvalue dns_variomedia_rm() { fulldomain=$1 txtvalue=$2 _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" VARIOMEDIA_API_TOKEN=\"${VARIOMEDIA_API_TOKEN:-$(_readaccountconf_mutable VARIOMEDIA_API_TOKEN)}\" if test -z \"$VARIOMEDIA_API_TOKEN\"; then VARIOMEDIA_API_TOKEN=\"\" _err 'VARIOMEDIA_API_TOKEN was not exported' return 1 fi _saveaccountconf_mutable VARIOMEDIA_API_TOKEN \"$VARIOMEDIA_API_TOKEN\" _debug 'First detect the root zone' if ! _get_root \"$fulldomain\"; then return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug 'Getting txt records' if ! _variomedia_rest GET \"dns-records?filter[domain]=$_domain\"; then _err 'Error' return 1 fi _record_id=\"$(echo \"$response\" | sed -E 's/,\"tags\":\\[[^]]*\\]//g' | cut -d '[' -f2 | cut -d']' -f1 | sed 's/},[ \\t]*{/\\},\u00a7\\{/g' | tr \u00a7 '\\n' | grep \"$_sub_domain\" | grep -- \"$txtvalue\" | sed 's/^{//;s/}[,]?$//' | tr , '\\n' | tr -d '\\\"' | grep ^id | cut -d : -f2 | tr -d ' ')\" _debug _record_id \"$_record_id\" if [ \"$_record_id\" ]; then _info \"Successfully retrieved the record id for ACME challenge.\" else _info \"Empty record id, it seems no such record.\" return 0 fi if ! _variomedia_rest DELETE \"/dns-records/$_record_id\"; then _err \"$response\" return 1 fi _debug2 _response \"$response\" return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then return 1 fi if ! _variomedia_rest GET \"domains/$h\"; then return 1 fi if _contains \"$response\" \"\\\"id\\\":\\\"$h\\\"\"; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d '.' -f 1-$p) _domain=\"$h\" return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _variomedia_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Authorization: token $VARIOMEDIA_API_TOKEN\" export _H2=\"Content-Type: application/vnd.api+json\" export _H3=\"Accept: application/vnd.variomedia.v1+json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$VARIOMEDIA_API/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$VARIOMEDIA_API/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"Error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_290.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_290.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_veesp_info='veesp.com Site: veesp.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_veesp Options: VEESP_User Username VEESP_Password Password Issues: github.com/acmesh-official/acme.sh/issues/3712 Author: <stepan@plyask.in> ' VEESP_Api=\"https://secure.veesp.com/api\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_veesp_add() { fulldomain=$1 txtvalue=$2 VEESP_Password=\"${VEESP_Password:-$(_readaccountconf_mutable VEESP_Password)}\" VEESP_User=\"${VEESP_User:-$(_readaccountconf_mutable VEESP_User)}\" VEESP_auth=$(printf \"%s\" \"$VEESP_User:$VEESP_Password\" | _base64) if [ -z \"$VEESP_Password\" ] || [ -z \"$VEESP_User\" ]; then VEESP_Password=\"\" VEESP_User=\"\" _err \"You don't specify veesp api key and email yet.\" _err \"Please create you key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable VEESP_Password \"$VEESP_Password\" _saveaccountconf_mutable VEESP_User \"$VEESP_User\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if VEESP_rest POST \"service/$_service_id/dns/$_domain_id/records\" \"{\\\"name\\\":\\\"$fulldomain\\\",\\\"ttl\\\":1,\\\"priority\\\":0,\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\"$txtvalue\\\"}\"; then if _contains \"$response\" \"\\\"success\\\":true\"; then _info \"Added\" #todo: check if the record takes effect return 0 else _err \"Add txt record error.\" return 1 fi fi } # Usage: fulldomain txtvalue # Used to remove the txt record after validation dns_veesp_rm() { fulldomain=$1 txtvalue=$2 VEESP_Password=\"${VEESP_Password:-$(_readaccountconf_mutable VEESP_Password)}\" VEESP_User=\"${VEESP_User:-$(_readaccountconf_mutable VEESP_User)}\" VEESP_auth=$(printf \"%s\" \"$VEESP_User:$VEESP_Password\" | _base64) _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" VEESP_rest GET \"service/$_service_id/dns/$_domain_id\" count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\".\\\"$txtvalue.\\\"\\\"\" | wc -l | tr -d \" \") _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"{\\\"id\\\":[^}]*\\\"type\\\":\\\"TXT\\\",\\\"content\\\":\\\".\\\"$txtvalue.\\\"\\\"\" | cut -d\\\" -f4) _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! VEESP_rest DELETE \"service/$_service_id/dns/$_domain_id/records/$record_id\"; then _err \"Delete record error.\" return 1 fi _contains \"$response\" \"\\\"success\\\":true\" fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=2 p=1 if ! VEESP_rest GET \"dns\"; then return 1 fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\"; then _domain_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"domain_id\\\":[^,]*,\\\"name\\\":\\\"$h\\\"\" | cut -d : -f 2 | cut -d , -f 1 | cut -d '\"' -f 2) _debug _domain_id \"$_domain_id\" _service_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"name\\\":\\\"$h\\\",\\\"service_id\\\":[^}]*\" | cut -d : -f 3 | cut -d '\"' -f 2) _debug _service_id \"$_service_id\" if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=\"$h\" return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } VEESP_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" export _H1=\"Accept: application/json\" export _H2=\"Authorization: Basic $VEESP_auth\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" export _H3=\"Content-Type: application/json\" response=\"$(_post \"$data\" \"$VEESP_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$VEESP_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_291.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_291.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_vercel_info='Vercel.com Site: Vercel.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_vercel Options: VERCEL_TOKEN API Token ' # This is your API token which can be acquired on the account page. # https://vercel.com/account/tokens VERCEL_API=\"https://api.vercel.com\" #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_vercel_add() { fulldomain=$1 txtvalue=$2 _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" VERCEL_TOKEN=\"${VERCEL_TOKEN:-$(_readaccountconf_mutable VERCEL_TOKEN)}\" if [ -z \"$VERCEL_TOKEN\" ]; then VERCEL_TOKEN=\"\" _err \"You have not set the Vercel API token yet.\" _err \"Please visit https://vercel.com/account/tokens to generate it.\" return 1 fi _saveaccountconf_mutable VERCEL_TOKEN \"$VERCEL_TOKEN\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _info \"Adding record\" if _vercel_rest POST \"v2/domains/$_domain/records\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"value\\\":\\\"$txtvalue\\\"}\"; then if printf -- \"%s\" \"$response\" | grep \"\\\"uid\\\":\\\"\" >/dev/null; then _info \"Added\" return 0 else _err \"Unexpected response while adding text record.\" return 1 fi fi _err \"Add txt record error.\" } dns_vercel_rm() { fulldomain=$1 txtvalue=$2 if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _vercel_rest GET \"v2/domains/$_domain/records\" count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"name\\\":\\\"$_sub_domain\\\",[^{]*\\\"type\\\":\\\"TXT\\\"\" | wc -l | tr -d \" \") if [ \"$count\" = \"0\" ]; then _info \"Don't need to remove.\" else _record_id=$(printf \"%s\" \"$response\" | _egrep_o \"\\\"id\\\":[^,]*,\\\"slug\\\":\\\"[^,]*\\\",\\\"name\\\":\\\"$_sub_domain\\\",[^{]*\\\"type\\\":\\\"TXT\\\",\\\"value\\\":\\\"$txtvalue\\\"\" | cut -d: -f2 | cut -d, -f1 | tr -d '\"') if [ \"$_record_id\" ]; then echo \"$_record_id\" | while read -r item; do if _vercel_rest DELETE \"v2/domains/$_domain/records/$item\"; then _info \"removed record\" \"$item\" return 0 else _err \"failed to remove record\" \"$item\" return 1 fi done fi fi } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com _get_root() { domain=\"$1\" ep=\"$2\" i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) if [ -z \"$h\" ]; then #not valid return 1 fi if ! _vercel_rest GET \"v4/domains/$h\"; then return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\" >/dev/null; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _vercel_rest() { m=\"$1\" ep=\"$2\" data=\"$3\" path=\"$VERCEL_API/$ep\" export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: Bearer $VERCEL_TOKEN\" if [ \"$m\" != \"GET\" ]; then _secure_debug2 data \"$data\" response=\"$(_post \"$data\" \"$path\" \"\" \"$m\")\" else response=\"$(_get \"$path\")\" fi _ret=\"$?\" _code=\"$(grep \"^HTTP\" \"$HTTP_HEADER\" | _tail_n 1 | cut -d \" \" -f 2 | tr -d \"\\\\r\\\\n\")\" _debug \"http response code $_code\" _secure_debug2 response \"$response\" if [ \"$_ret\" != \"0\" ]; then _err \"error $ep\" return 1 fi response=\"$(printf \"%s\" \"$response\" | _normalizeJson)\" return 0 }"
        },
        {
            "filename": "file_292.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_292.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_vscale_info='vscale.io Site: vscale.io Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_vscale Options: VSCALE_API_KEY API Key Author: Alex Loban <https://github.com/LAV45> ' VSCALE_API_URL=\"https://api.vscale.io/v1\" ######## Public functions ##################### #Usage: dns_myapi_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_vscale_add() { fulldomain=$1 txtvalue=$2 if [ -z \"$VSCALE_API_KEY\" ]; then VSCALE_API_KEY=\"\" _err \"You didn't specify the VSCALE api key yet.\" _err \"Please create you key and try again.\" return 1 fi _saveaccountconf VSCALE_API_KEY \"$VSCALE_API_KEY\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _vscale_tmpl_json=\"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain.$_domain\\\",\\\"content\\\":\\\"$txtvalue\\\"}\" if _vscale_rest POST \"domains/$_domain_id/records/\" \"$_vscale_tmpl_json\"; then response=$(printf \"%s\\n\" \"$response\" | _egrep_o \"{\\\"error\\\": \\\".+\\\"\" | cut -d : -f 2) if [ -z \"$response\" ]; then _info \"txt record updated success.\" return 0 fi fi return 1 } #fulldomain txtvalue dns_vscale_rm() { fulldomain=$1 txtvalue=$2 _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _vscale_rest GET \"domains/$_domain_id/records/\" if [ -n \"$response\" ]; then record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"TXT\\\", \\\"id\\\": [0-9]+, \\\"name\\\": \\\"$_sub_domain.$_domain\\\"\" | cut -d : -f 2 | tr -d \", \\\"name\\\"\") _debug record_id \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if _vscale_rest DELETE \"domains/$_domain_id/records/$record_id\" && [ -z \"$response\" ]; then _info \"txt record deleted success.\" return 0 fi _debug response \"$response\" return 1 fi return 1 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=12345 _get_root() { domain=$1 i=2 p=1 if _vscale_rest GET \"domains/\"; then response=\"$(echo \"$response\" | tr -d \"\\n\" | sed 's/{/\\n&/g')\" while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi hostedzone=\"$(echo \"$response\" | tr \"{\" \"\\n\" | _egrep_o \"\\\"name\\\":\\s*\\\"$h\\\".*}\")\" if [ \"$hostedzone\" ]; then _domain_id=$(printf \"%s\\n\" \"$hostedzone\" | _egrep_o \"\\\"id\\\":\\s*[0-9]+\" | _head_n 1 | cut -d : -f 2 | tr -d \\ ) if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done fi return 1 } #method uri qstr data _vscale_rest() { mtd=\"$1\" ep=\"$2\" data=\"$3\" _debug mtd \"$mtd\" _debug ep \"$ep\" export _H1=\"Accept: application/json\" export _H2=\"Content-Type: application/json\" export _H3=\"X-Token: ${VSCALE_API_KEY}\" if [ \"$mtd\" != \"GET\" ]; then # both POST and DELETE. _debug data \"$data\" response=\"$(_post \"$data\" \"$VSCALE_API_URL/$ep\" \"\" \"$mtd\")\" else response=\"$(_get \"$VSCALE_API_URL/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_293.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_293.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_vultr_info='vultr.com Site: vultr.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_vultr Options: VULTR_API_KEY API Key Issues: github.com/acmesh-official/acme.sh/issues/2374 Author: ' VULTR_Api=\"https://api.vultr.com/v2\" ######## Public functions ##################### # #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_vultr_add() { fulldomain=$1 txtvalue=$2 _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" VULTR_API_KEY=\"${VULTR_API_KEY:-$(_readaccountconf_mutable VULTR_API_KEY)}\" if test -z \"$VULTR_API_KEY\"; then VULTR_API_KEY='' _err 'VULTR_API_KEY was not exported' return 1 fi _saveaccountconf_mutable VULTR_API_KEY \"$VULTR_API_KEY\" _debug 'First detect the root zone' if ! _get_root \"$fulldomain\"; then return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug 'Getting txt records' _vultr_rest GET \"domains/$_domain/records\" if printf \"%s\\n\" \"$response\" | grep -- \"\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$fulldomain\\\"\" >/dev/null; then _err 'Error' return 1 fi if ! _vultr_rest POST \"domains/$_domain/records\" \"{\\\"name\\\":\\\"$_sub_domain\\\",\\\"data\\\":\\\"$txtvalue\\\",\\\"type\\\":\\\"TXT\\\"}\"; then _err \"$response\" return 1 fi _debug2 _response \"$response\" return 0 } #fulldomain txtvalue dns_vultr_rm() { fulldomain=$1 txtvalue=$2 _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" VULTR_API_KEY=\"${VULTR_API_KEY:-$(_readaccountconf_mutable VULTR_API_KEY)}\" if test -z \"$VULTR_API_KEY\"; then VULTR_API_KEY=\"\" _err 'VULTR_API_KEY was not exported' return 1 fi _saveaccountconf_mutable VULTR_API_KEY \"$VULTR_API_KEY\" _debug 'First detect the root zone' if ! _get_root \"$fulldomain\"; then return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug 'Getting txt records' _vultr_rest GET \"domains/$_domain/records\" if printf \"%s\\n\" \"$response\" | grep -- \"\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$fulldomain\\\"\" >/dev/null; then _err 'Error' return 1 fi _record_id=\"$(echo \"$response\" | tr '{}' '\\n' | grep '\"TXT\"' | grep -- \"$txtvalue\" | tr ',' '\\n' | grep -i 'id' | cut -d : -f 2 | tr -d '\"')\" _debug _record_id \"$_record_id\" if [ \"$_record_id\" ]; then _info \"Successfully retrieved the record id for ACME challenge.\" else _info \"Empty record id, it seems no such record.\" return 0 fi if ! _vultr_rest DELETE \"domains/$_domain/records/$_record_id\"; then _err \"$response\" return 1 fi _debug2 _response \"$response\" return 0 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=1 while true; do _domain=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$_domain\" if [ -z \"$_domain\" ]; then return 1 fi if ! _vultr_rest GET \"domains\"; then return 1 fi if printf \"%s\\n\" \"$response\" | grep -E '^\\{.*\\}' >/dev/null; then if _contains \"$response\" \"\\\"domain\\\":\\\"$_domain\\\"\"; then _sub_domain=\"$(echo \"$fulldomain\" | sed \"s/\\\\.$_domain\\$//\")\" return 0 else _debug \"Go to next level of $_domain\" fi else _err \"$response\" return 1 fi i=$(_math \"$i\" + 1) done return 1 } _vultr_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" api_key_trimmed=$(echo \"$VULTR_API_KEY\" | tr -d '\"') export _H1=\"Authorization: Bearer $api_key_trimmed\" export _H2='Content-Type: application/json' if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$VULTR_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$VULTR_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"Error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_294.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_294.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_websupport_info='Websupport.sk Site: Websupport.sk Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_websupport Options: WS_ApiKey API Key. Called \"Identifier\" in the WS Admin WS_ApiSecret API Secret. Called \"Secret key\" in the WS Admin Issues: github.com/acmesh-official/acme.sh/issues/3486 Author: trgo.sk <https://github.com/trgosk>, akulumbeg <https://github.com/akulumbeg> ' # Requirements: API Key and Secret from https://admin.websupport.sk/en/auth/apiKey WS_Api=\"https://rest.websupport.sk\" ######## Public functions ##################### dns_websupport_add() { fulldomain=$1 txtvalue=$2 WS_ApiKey=\"${WS_ApiKey:-$(_readaccountconf_mutable WS_ApiKey)}\" WS_ApiSecret=\"${WS_ApiSecret:-$(_readaccountconf_mutable WS_ApiSecret)}\" if [ \"$WS_ApiKey\" ] && [ \"$WS_ApiSecret\" ]; then _saveaccountconf_mutable WS_ApiKey \"$WS_ApiKey\" _saveaccountconf_mutable WS_ApiSecret \"$WS_ApiSecret\" else WS_ApiKey=\"\" WS_ApiSecret=\"\" _err \"You did not specify the API Key and/or API Secret\" _err \"You can get the API login credentials from https://admin.websupport.sk/en/auth/apiKey\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" # For wildcard cert, the main root domain and the wildcard domain have the same txt subdomain name, so # we can not use updating anymore. # count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"count\\\":[^,]*\" | cut -d : -f 2) # _debug count \"$count\" # if [ \"$count\" = \"0\" ]; then _info \"Adding record\" if _ws_rest POST \"/v1/user/self/zone/$_domain/record\" \"{\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$_sub_domain\\\",\\\"content\\\":\\\"$txtvalue\\\",\\\"ttl\\\":120}\"; then if _contains \"$response\" \"$txtvalue\"; then _info \"Added, OK\" return 0 elif _contains \"$response\" \"The record already exists\"; then _info \"Already exists, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } dns_websupport_rm() { fulldomain=$1 txtvalue=$2 _debug2 fulldomain \"$fulldomain\" _debug2 txtvalue \"$txtvalue\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" _ws_rest GET \"/v1/user/self/zone/$_domain/record\" if [ \"$(printf \"%s\" \"$response\" | tr -d \" \" | grep -c \\\"items\\\")\" -lt \"1\" ]; then _err \"Error: $response\" return 1 fi record_line=\"$(_get_from_array \"$response\" \"$txtvalue\")\" _debug record_line \"$record_line\" if [ -z \"$record_line\" ]; then _info \"Don't need to remove.\" else record_id=$(echo \"$record_line\" | _egrep_o \"\\\"id\\\": *[^,]*\" | _head_n 1 | cut -d : -f 2 | tr -d \\\" | tr -d \" \") _debug \"record_id\" \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id to remove.\" return 1 fi if ! _ws_rest DELETE \"/v1/user/self/zone/$_domain/record/$record_id\"; then _err \"Delete record error.\" return 1 fi if [ \"$(printf \"%s\" \"$response\" | tr -d \" \" | grep -c \\\"success\\\")\" -lt \"1\" ]; then return 1 else return 0 fi fi } #################### Private Functions ################################## _get_root() { domain=$1 i=1 p=1 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _ws_rest GET \"/v1/user/self/zone\"; then return 1 fi if _contains \"$response\" \"\\\"name\\\":\\\"$h\\\"\"; then _domain_id=$(echo \"$response\" | _egrep_o \"\\[.\\\"id\\\": *[^,]*\" | _head_n 1 | cut -d : -f 2 | tr -d \\\" | tr -d \" \") if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _ws_rest() { me=$1 pa=\"$2\" da=\"$3\" _debug2 api_key \"$WS_ApiKey\" _debug2 api_secret \"$WS_ApiSecret\" timestamp=$(_time) datez=\"$(_utc_date | sed \"s/ /T/\" | sed \"s/$/+0000/\")\" canonical_request=\"${me} ${pa} ${timestamp}\" signature_hash=$(printf \"%s\" \"$canonical_request\" | _hmac sha1 \"$(printf \"%s\" \"$WS_ApiSecret\" | _hex_dump | tr -d \" \")\" hex) basicauth=\"$(printf \"%s:%s\" \"$WS_ApiKey\" \"$signature_hash\" | _base64)\" _debug2 method \"$me\" _debug2 path \"$pa\" _debug2 data \"$da\" _debug2 timestamp \"$timestamp\" _debug2 datez \"$datez\" _debug2 canonical_request \"$canonical_request\" _debug2 signature_hash \"$signature_hash\" _debug2 basicauth \"$basicauth\" export _H1=\"Accept: application/json\" export _H2=\"Content-Type: application/json\" export _H3=\"Authorization: Basic ${basicauth}\" export _H4=\"Date: ${datez}\" _debug2 H1 \"$_H1\" _debug2 H2 \"$_H2\" _debug2 H3 \"$_H3\" _debug2 H4 \"$_H4\" if [ \"$me\" != \"GET\" ]; then _debug2 \"${me} $WS_Api${pa}\" _debug data \"$da\" response=\"$(_post \"$da\" \"${WS_Api}${pa}\" \"\" \"$me\")\" else _debug2 \"GET $WS_Api${pa}\" response=\"$(_get \"$WS_Api${pa}\")\" fi _debug2 response \"$response\" return \"$?\" } _get_from_array() { va=\"$1\" fi=\"$2\" for i in $(echo \"$va\" | sed \"s/{/ /g\"); do if _contains \"$i\" \"$fi\"; then echo \"$i\" break fi done }"
        },
        {
            "filename": "file_295.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_295.sh",
            "content": "#!/usr/bin/env sh # West.cn Domain api #WEST_Username=\"username\" #WEST_Key=\"sADDsdasdgdsf\" #Set key at https://www.west.cn/manager/API/APIconfig.asp REST_API=\"https://api.west.cn/API/v2\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_west_cn_add() { fulldomain=$1 txtvalue=$2 WEST_Username=\"${WEST_Username:-$(_readaccountconf_mutable WEST_Username)}\" WEST_Key=\"${WEST_Key:-$(_readaccountconf_mutable WEST_Key)}\" if [ -z \"$WEST_Username\" ] || [ -z \"$WEST_Key\" ]; then WEST_Username=\"\" WEST_Key=\"\" _err \"You don't specify west api key and username yet.\" _err \"Please set you key and try again.\" return 1 fi #save the api key and email to the account conf file. _saveaccountconf_mutable WEST_Username \"$WEST_Username\" _saveaccountconf_mutable WEST_Key \"$WEST_Key\" add_record \"$fulldomain\" \"$txtvalue\" } #Usage: rm _acme-challenge.www.domain.com dns_west_cn_rm() { fulldomain=$1 txtvalue=$2 WEST_Username=\"${WEST_Username:-$(_readaccountconf_mutable WEST_Username)}\" WEST_Key=\"${WEST_Key:-$(_readaccountconf_mutable WEST_Key)}\" if ! _rest POST \"domain/dns/\" \"act=dnsrec.list&username=$WEST_Username&apikey=$WEST_Key&domain=$fulldomain&hostname=$fulldomain&record_type=TXT\"; then _err \"dnsrec.list error.\" return 1 fi if _contains \"$response\" 'no records'; then _info \"Don't need to remove.\" return 0 fi record_id=$(echo \"$response\" | tr \"{\" \"\\n\" | grep -- \"$txtvalue\" | grep '^\"record_id\"' | cut -d : -f 2 | cut -d ',' -f 1) _debug record_id \"$record_id\" if [ -z \"$record_id\" ]; then _err \"Can not get record id.\" return 1 fi if ! _rest POST \"domain/dns/\" \"act=dnsrec.remove&username=$WEST_Username&apikey=$WEST_Key&domain=$fulldomain&hostname=$fulldomain&record_id=$record_id\"; then _err \"dnsrec.remove error.\" return 1 fi _contains \"$response\" \"success\" } #add the txt record. #usage: add fulldomain txtvalue add_record() { fulldomain=$1 txtvalue=$2 _info \"Adding record\" if ! _rest POST \"domain/dns/\" \"act=dnsrec.add&username=$WEST_Username&apikey=$WEST_Key&domain=$fulldomain&hostname=$fulldomain&record_type=TXT&record_value=$txtvalue\"; then return 1 fi _contains \"$response\" \"success\" } #Usage: method URI data _rest() { m=\"$1\" ep=\"$2\" data=\"$3\" _debug \"$ep\" url=\"$REST_API/$ep\" _debug url \"$url\" if [ \"$m\" = \"GET\" ]; then response=\"$(_get \"$url\" | tr -d '\\r')\" else _debug2 data \"$data\" response=\"$(_post \"$data\" \"$url\" | tr -d '\\r')\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_296.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_296.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_world4you_info='World4You.com Site: World4You.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_world4you Options: WORLD4YOU_USERNAME Username WORLD4YOU_PASSWORD Password Issues: github.com/acmesh-official/acme.sh/issues/3269 Author: Lorenz Stechauner <https://www.github.com/NerLOR> ' WORLD4YOU_API=\"https://my.world4you.com/en\" PAKETNR='' TLD='' RECORD='' ################ Public functions ################ # Usage: dns_world4you_add <fqdn> <value> dns_world4you_add() { fqdn=$(echo \"$1\" | _lower_case) value=\"$2\" _info \"Using world4you to add record\" _debug fulldomain \"$fqdn\" _debug txtvalue \"$value\" _login if [ \"$?\" != 0 ]; then return 1 fi export _H1=\"Cookie: W4YSESSID=$sessid\" form=$(_get \"$WORLD4YOU_API/\") _get_paketnr \"$fqdn\" \"$form\" paketnr=\"$PAKETNR\" if [ -z \"$paketnr\" ]; then _err \"Unable to parse paketnr\" return 3 fi _debug paketnr \"$paketnr\" export _H1=\"Cookie: W4YSESSID=$sessid\" form=$(_get \"$WORLD4YOU_API/$paketnr/dns\") formiddp=$(echo \"$form\" | grep 'AddDnsRecordForm\\[uniqueFormIdDP\\]' | sed 's/^.*name=\"AddDnsRecordForm\\[uniqueFormIdDP\\]\" value=\"\\([^\"]*\\)\".*$/\\1/') form_token=$(echo \"$form\" | grep 'AddDnsRecordForm\\[_token\\]' | sed 's/^.*name=\"AddDnsRecordForm\\[_token\\]\" value=\"\\([^\"]*\\)\".*$/\\1/') if [ -z \"$formiddp\" ]; then _err \"Unable to parse form\" return 3 fi _resethttp export ACME_HTTP_NO_REDIRECTS=1 body=\"AddDnsRecordForm[name]=$RECORD&AddDnsRecordForm[dnsType][type]=TXT&AddDnsRecordForm[value]=$value&AddDnsRecordForm[uniqueFormIdDP]=$formiddp&AddDnsRecordForm[_token]=$form_token\" _info \"Adding record...\" ret=$(_post \"$body\" \"$WORLD4YOU_API/$paketnr/dns\" '' POST 'application/x-www-form-urlencoded') _resethttp if _contains \"$(_head_n 1 <\"$HTTP_HEADER\")\" '302'; then res=$(_get \"$WORLD4YOU_API/$paketnr/dns\") if _contains \"$res\" \"successfully\"; then return 0 else msg=$(echo \"$res\" | grep -A 15 'data-type=\"danger\"' | grep \"<h3[^>]*>[^<]\" | sed 's/<[^>]*>//g' | sed 's/^\\s*//g') if [ \"$msg\" = '' ]; then _err \"Unable to add record: Unknown error\" echo \"$ret\" >'error-01.html' echo \"$res\" >'error-02.html' _err \"View error-01.html and error-02.html for debugging\" else _err \"Unable to add record: my.world4you.com: $msg\" fi return 1 fi else msg=$(echo \"$ret\" | grep '\"form-error-message\"' | sed 's/^.*<div class=\"form-error-message\">\\([^<]*\\)<\\/div>.*$/\\1/') _err \"Unable to add record: my.world4you.com: $msg\" return 1 fi } # Usage: dns_world4you_rm <fqdn> <value> dns_world4you_rm() { fqdn=$(echo \"$1\" | _lower_case) value=\"$2\" _info \"Using world4you to remove record\" _debug fulldomain \"$fqdn\" _debug txtvalue \"$value\" _login if [ \"$?\" != 0 ]; then return 1 fi export _H1=\"Cookie: W4YSESSID=$sessid\" form=$(_get \"$WORLD4YOU_API/\") _get_paketnr \"$fqdn\" \"$form\" paketnr=\"$PAKETNR\" if [ -z \"$paketnr\" ]; then _err \"Unable to parse paketnr\" return 3 fi _debug paketnr \"$paketnr\" form=$(_get \"$WORLD4YOU_API/$paketnr/dns\") formiddp=$(echo \"$form\" | grep 'DeleteDnsRecordForm\\[uniqueFormIdDP\\]' | sed 's/^.*name=\"DeleteDnsRecordForm\\[uniqueFormIdDP\\]\" value=\"\\([^\"]*\\)\".*$/\\1/') form_token=$(echo \"$form\" | grep 'DeleteDnsRecordForm\\[_token\\]' | sed 's/^.*name=\"DeleteDnsRecordForm\\[_token\\]\" value=\"\\([^\"]*\\)\".*$/\\1/') if [ -z \"$formiddp\" ]; then _err \"Unable to parse form\" return 3 fi recordid=$(printf \"TXT:%s.:\\\"%s\\\"\" \"$fqdn\" \"$value\" | _base64) _debug recordid \"$recordid\" _resethttp export ACME_HTTP_NO_REDIRECTS=1 body=\"DeleteDnsRecordForm[recordId]=$recordid&DeleteDnsRecordForm[uniqueFormIdDP]=$formiddp&DeleteDnsRecordForm[_token]=$form_token\" _info \"Removing record...\" ret=$(_post \"$body\" \"$WORLD4YOU_API/$paketnr/dns/record/delete\" '' POST 'application/x-www-form-urlencoded') _resethttp if _contains \"$(_head_n 1 <\"$HTTP_HEADER\")\" '302'; then res=$(_get \"$WORLD4YOU_API/$paketnr/dns\") if _contains \"$res\" \"successfully\"; then return 0 else msg=$(echo \"$res\" | grep -A 15 'data-type=\"danger\"' | grep \"<h3[^>]*>[^<]\" | sed 's/<[^>]*>//g' | sed 's/^\\s*//g') if [ \"$msg\" = '' ]; then _err \"Unable to remove record: Unknown error\" echo \"$ret\" >'error-01.html' echo \"$res\" >'error-02.html' _err \"View error-01.html and error-02.html for debugging\" else _err \"Unable to remove record: my.world4you.com: $msg\" fi return 1 fi else msg=$(echo \"$ret\" | grep \"form-error-message\" | sed 's/^.*<div class=\"form-error-message\">\\([^<]*\\)<\\/div>.*$/\\1/') _err \"Unable to remove record: my.world4you.com: $msg\" return 1 fi } ################ Private functions ################ # Usage: _login _login() { WORLD4YOU_USERNAME=\"${WORLD4YOU_USERNAME:-$(_readaccountconf_mutable WORLD4YOU_USERNAME)}\" WORLD4YOU_PASSWORD=\"${WORLD4YOU_PASSWORD:-$(_readaccountconf_mutable WORLD4YOU_PASSWORD)}\" if [ -z \"$WORLD4YOU_USERNAME\" ] || [ -z \"$WORLD4YOU_PASSWORD\" ]; then WORLD4YOU_USERNAME=\"\" WORLD4YOU_PASSWORD=\"\" _err \"You didn't specify world4you username and password yet.\" _err \"Usage: export WORLD4YOU_USERNAME=<name>\" _err \"Usage: export WORLD4YOU_PASSWORD=<password>\" return 1 fi _saveaccountconf_mutable WORLD4YOU_USERNAME \"$WORLD4YOU_USERNAME\" _saveaccountconf_mutable WORLD4YOU_PASSWORD \"$WORLD4YOU_PASSWORD\" _resethttp export ACME_HTTP_NO_REDIRECTS=1 page=$(_get \"$WORLD4YOU_API/login\") _resethttp if _contains \"$(_head_n 1 <\"$HTTP_HEADER\")\" '302'; then _info \"Already logged in\" _parse_sessid return 0 fi _info \"Logging in...\" username=\"$WORLD4YOU_USERNAME\" password=\"$WORLD4YOU_PASSWORD\" csrf_token=$(echo \"$page\" | grep '_csrf_token' | sed 's/^.*<input[^>]*value=\\\"\\([^\"]*\\)\\\".*$/\\1/') _parse_sessid export _H1=\"Cookie: W4YSESSID=$sessid\" export _H2=\"X-Requested-With: XMLHttpRequest\" body=\"_username=$username&_password=$password&_csrf_token=$csrf_token\" ret=$(_post \"$body\" \"$WORLD4YOU_API/login\" '' POST 'application/x-www-form-urlencoded') unset _H2 _debug ret \"$ret\" if _contains \"$ret\" \"\\\"success\\\":true\"; then _info \"Successfully logged in\" _parse_sessid else msg=$(echo \"$ret\" | sed 's/^.*\"message\":\"\\([^\\\"]*\\)\".*$/\\1/') _err \"Unable to log in: my.world4you.com: $msg\" return 1 fi } # Usage: _get_paketnr <fqdn> <form> _get_paketnr() { fqdn=\"$1\" form=\"$2\" domains=$(echo \"$form\" | grep '<ul class=\"nav header-paket-list\">' | sed 's/<li/\\n<li/g' | sed 's/<[^>]*>/ /g' | sed 's/^.*>\\([^>]*\\)$/\\1/') domain='' for domain in $domains; do if _contains \"$fqdn\" \"$domain\\$\"; then break fi domain='' done if [ -z \"$domain\" ]; then return 1 fi TLD=\"$domain\" _debug domain \"$domain\" RECORD=$(echo \"$fqdn\" | cut -c\"1-$((${#fqdn} - ${#TLD} - 1))\") PAKETNR=$(echo \"$domains\" | grep \"$domain\" | sed 's/^[^,]*, *\\([0-9]*\\).*$/\\1/') return 0 } # Usage: _parse_sessid _parse_sessid() { sessid=$(grep 'W4YSESSID' <\"$HTTP_HEADER\" | _tail_n 1 | sed 's/^.*W4YSESSID=\\([^;]*\\);.*$/\\1/') }"
        },
        {
            "filename": "file_297.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_297.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_yandex360_info='Yandex 360 for Business DNS API. Yandex 360 for Business is a digital environment for effective collaboration. Site: https://360.yandex.com/ Docs: https://github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_yandex360 Options: YANDEX360_CLIENT_ID OAuth 2.0 ClientID YANDEX360_CLIENT_SECRET OAuth 2.0 Client secret OptionsAlt: YANDEX360_ORG_ID Organization ID. Optional. YANDEX360_ACCESS_TOKEN OAuth 2.0 Access token. Optional. Issues: https://github.com/acmesh-official/acme.sh/issues/5213 Author: <Als@admin.ru.net> ' YANDEX360_API_BASE='https://api360.yandex.net/directory/v1' YANDEX360_OAUTH_BASE='https://oauth.yandex.ru' ######## Public functions ##################### dns_yandex360_add() { fulldomain=\"$(_idn \"$1\")\" txtvalue=$2 _info 'Using Yandex 360 DNS API' if ! _check_variables; then return 1 fi if ! _get_root \"$fulldomain\"; then return 1 fi sub_domain=$(echo \"$fulldomain\" | sed \"s/\\.$root_domain$//\") _debug 'Adding Yandex 360 DNS record for subdomain' \"$sub_domain\" dns_api_url=\"${YANDEX360_API_BASE}/org/${YANDEX360_ORG_ID}/domains/${root_domain}/dns\" data='{\"name\":\"'\"$sub_domain\"'\",\"type\":\"TXT\",\"ttl\":60,\"text\":\"'\"$txtvalue\"'\"}' response=\"$(_post \"$data\" \"$dns_api_url\" '' 'POST' 'application/json')\" if _contains \"$response\" 'recordId'; then return 0 else _debug 'Response' \"$response\" return 1 fi } dns_yandex360_rm() { fulldomain=\"$(_idn \"$1\")\" txtvalue=$2 _info 'Using Yandex 360 DNS API' if ! _check_variables; then return 1 fi if ! _get_root \"$fulldomain\"; then return 1 fi _debug 'Retrieving 100 records from Yandex 360 DNS' dns_api_url=\"${YANDEX360_API_BASE}/org/${YANDEX360_ORG_ID}/domains/${root_domain}/dns?perPage=100\" response=\"$(_get \"$dns_api_url\" '' '')\" if ! _contains \"$response\" \"$txtvalue\"; then _info 'DNS record not found. Nothing to remove.' _debug 'Response' \"$response\" return 1 fi response=\"$(echo \"$response\" | _normalizeJson)\" record_id=$( echo \"$response\" | _egrep_o '\\{[^}]*'\"${txtvalue}\"'[^}]*\\}' | _egrep_o '\"recordId\":[0-9]*' | cut -d':' -f2 ) if [ -z \"$record_id\" ]; then _err 'Unable to get record ID to remove' return 1 fi _debug 'Removing DNS record' \"$record_id\" delete_url=\"${YANDEX360_API_BASE}/org/${YANDEX360_ORG_ID}/domains/${root_domain}/dns/${record_id}\" response=\"$(_post '' \"$delete_url\" '' 'DELETE')\" if _contains \"$response\" '{}'; then return 0 else _debug 'Response' \"$response\" return 1 fi } #################### Private functions below ################################## _check_variables() { YANDEX360_CLIENT_ID=\"${YANDEX360_CLIENT_ID:-$(_readaccountconf_mutable YANDEX360_CLIENT_ID)}\" YANDEX360_CLIENT_SECRET=\"${YANDEX360_CLIENT_SECRET:-$(_readaccountconf_mutable YANDEX360_CLIENT_SECRET)}\" YANDEX360_ORG_ID=\"${YANDEX360_ORG_ID:-$(_readaccountconf_mutable YANDEX360_ORG_ID)}\" YANDEX360_ACCESS_TOKEN=\"${YANDEX360_ACCESS_TOKEN:-$(_readaccountconf_mutable YANDEX360_ACCESS_TOKEN)}\" YANDEX360_REFRESH_TOKEN=\"${YANDEX360_REFRESH_TOKEN:-$(_readaccountconf_mutable YANDEX360_REFRESH_TOKEN)}\" if [ -n \"$YANDEX360_ACCESS_TOKEN\" ]; then _info '=========================================' _info ' ATTENTION' _info '=========================================' _info 'A manually provided Yandex 360 access token has been detected, which is not recommended.' _info 'Please note that this token is valid for a limited time after issuance.' _info 'It is recommended to obtain the token interactively using acme.sh for one-time setup.' _info 'Subsequent token renewals will be handled automatically.' _info 'For more details, please visit: https://github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_yandex360' _info '=========================================' _saveaccountconf_mutable YANDEX360_ACCESS_TOKEN \"$YANDEX360_ACCESS_TOKEN\" export _H1=\"Authorization: OAuth $YANDEX360_ACCESS_TOKEN\" elif [ -z \"$YANDEX360_CLIENT_ID\" ] || [ -z \"$YANDEX360_CLIENT_SECRET\" ]; then _err '=========================================' _err ' ERROR' _err '=========================================' _err 'The required environment variables YANDEX360_CLIENT_ID and YANDEX360_CLIENT_SECRET are not set.' _err 'Alternatively, you can set YANDEX360_ACCESS_TOKEN environment variable.' _err 'For more details, please visit: https://github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_yandex360' _err '=========================================' return 1 else _saveaccountconf_mutable YANDEX360_CLIENT_ID \"$YANDEX360_CLIENT_ID\" _saveaccountconf_mutable YANDEX360_CLIENT_SECRET \"$YANDEX360_CLIENT_SECRET\" if [ -n \"$YANDEX360_REFRESH_TOKEN\" ]; then _debug 'Refresh token found. Attempting to refresh access token.' fi _refresh_token || _get_token || return 1 fi if [ -z \"$YANDEX360_ORG_ID\" ]; then org_response=\"$(_get \"${YANDEX360_API_BASE}/org\" '' '')\" if _contains \"$org_response\" '\"organizations\"'; then org_response=\"$(echo \"$org_response\" | _normalizeJson)\" YANDEX360_ORG_ID=$( echo \"$org_response\" | _egrep_o '\"id\":[[:space:]]*[0-9]+' | cut -d':' -f2 ) _debug 'Automatically retrieved YANDEX360_ORG_ID' \"$YANDEX360_ORG_ID\" else _err '=========================================' _err ' ERROR' _err '=========================================' _err \"Failed to retrieve YANDEX360_ORG_ID automatically.\" _err 'For more details, please visit: https://github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_yandex360' _err '=========================================' _debug 'Response' \"$org_response\" return 1 fi fi return 0 } _get_token() { _info \"$(__red '=========================================')\" _info \"$(__red ' NOTICE')\" _info \"$(__red '=========================================')\" _info \"$(__red 'Before using the Yandex 360 API, you need to complete an authorization procedure.')\" _info \"$(__red 'The initial access token is obtained interactively and is a one-time operation.')\" _info \"$(__red 'Subsequent API requests will be handled automatically.')\" _info \"$(__red '=========================================')\" _info 'Initiating device authorization flow' device_code_url=\"${YANDEX360_OAUTH_BASE}/device/code\" hostname=$(uname -n) data=\"client_id=$YANDEX360_CLIENT_ID&device_id=acme.sh ${hostname}&device_name=acme.sh ${hostname}\" response=\"$(_post \"$data\" \"$device_code_url\" '' 'POST')\" if ! _contains \"$response\" 'device_code'; then _err 'Failed to get device code' _debug 'Response' \"$response\" return 1 fi response=\"$(echo \"$response\" | _normalizeJson)\" device_code=$( echo \"$response\" | _egrep_o '\"device_code\":\"[^\"]*\"' | cut -d'\"' -f4 ) _debug 'Device code' \"$device_code\" user_code=$( echo \"$response\" | _egrep_o '\"user_code\":\"[^\"]*\"' | cut -d'\"' -f4 ) _debug 'User code' \"$user_code\" verification_url=$( echo \"$response\" | _egrep_o '\"verification_url\":\"[^\"]*\"' | cut -d'\"' -f4 ) _debug 'Verification URL' \"$verification_url\" interval=$( echo \"$response\" | _egrep_o '\"interval\":[[:space:]]*[0-9]+' | cut -d':' -f2 ) _debug 'Polling interval' \"$interval\" _info \"$(__red 'Please visit '\"$verification_url\"' and log in as an organization administrator')\" _info \"$(__red 'Once logged in, enter the code: '\"$user_code\"' on the page from the previous step')\" _info \"$(__red 'Waiting for authorization...')\" _debug 'Polling for token' token_url=\"${YANDEX360_OAUTH_BASE}/token\" while true; do data=\"grant_type=device_code&code=$device_code&client_id=$YANDEX360_CLIENT_ID&client_secret=$YANDEX360_CLIENT_SECRET\" response=\"$(_post \"$data\" \"$token_url\" '' 'POST')\" if _contains \"$response\" 'access_token'; then response=\"$(echo \"$response\" | _normalizeJson)\" YANDEX360_ACCESS_TOKEN=$( echo \"$response\" | _egrep_o '\"access_token\":\"[^\"]*\"' | cut -d'\"' -f4 ) YANDEX360_REFRESH_TOKEN=$( echo \"$response\" | _egrep_o '\"refresh_token\":\"[^\"]*\"' | cut -d'\"' -f4 ) _secure_debug 'Obtained access token' \"$YANDEX360_ACCESS_TOKEN\" _secure_debug 'Obtained refresh token' \"$YANDEX360_REFRESH_TOKEN\" _saveaccountconf_mutable YANDEX360_REFRESH_TOKEN \"$YANDEX360_REFRESH_TOKEN\" export _H1=\"Authorization: OAuth $YANDEX360_ACCESS_TOKEN\" _info 'Access token obtained successfully' return 0 elif _contains \"$response\" 'authorization_pending'; then _debug 'Response' \"$response\" _debug \"Authorization pending. Waiting $interval seconds before next attempt.\" _sleep \"$interval\" else _debug 'Response' \"$response\" _err 'Failed to get access token' return 1 fi done } _refresh_token() { token_url=\"${YANDEX360_OAUTH_BASE}/token\" data=\"grant_type=refresh_token&refresh_token=$YANDEX360_REFRESH_TOKEN&client_id=$YANDEX360_CLIENT_ID&client_secret=$YANDEX360_CLIENT_SECRET\" response=\"$(_post \"$data\" \"$token_url\" '' 'POST')\" if _contains \"$response\" 'access_token'; then response=\"$(echo \"$response\" | _normalizeJson)\" YANDEX360_ACCESS_TOKEN=$( echo \"$response\" | _egrep_o '\"access_token\":\"[^\"]*\"' | cut -d'\"' -f4 ) YANDEX360_REFRESH_TOKEN=$( echo \"$response\" | _egrep_o '\"refresh_token\":\"[^\"]*\"' | cut -d'\"' -f4 ) _secure_debug 'Received access token' \"$YANDEX360_ACCESS_TOKEN\" _secure_debug 'Received refresh token' \"$YANDEX360_REFRESH_TOKEN\" _saveaccountconf_mutable YANDEX360_REFRESH_TOKEN \"$YANDEX360_REFRESH_TOKEN\" export _H1=\"Authorization: OAuth $YANDEX360_ACCESS_TOKEN\" _info 'Access token refreshed successfully' return 0 else _info 'Failed to refresh token. Will attempt to obtain a new one.' _debug 'Response' \"$response\" return 1 fi } _get_root() { domain=\"$1\" for org_id in $YANDEX360_ORG_ID; do _debug 'Checking organization ID' \"$org_id\" domains_api_url=\"${YANDEX360_API_BASE}/org/${org_id}/domains\" domains_response=\"$(_get \"$domains_api_url\" '' '')\" if ! _contains \"$domains_response\" '\"domains\"'; then _debug 'No domains found for organization' \"$org_id\" _debug 'Response' \"$domains_response\" continue fi domains_response=\"$(echo \"$domains_response\" | _normalizeJson)\" domain_names=$( echo \"$domains_response\" | _egrep_o '\"name\":\"[^\"]*\"' | cut -d'\"' -f4 ) for d in $domain_names; do d=\"$(_idn \"$d\")\" _debug 'Checking domain' \"$d\" if _endswith \"$domain\" \"$d\"; then root_domain=\"$d\" break fi done if [ -n \"$root_domain\" ]; then _debug \"Root domain found: $root_domain in organization $org_id\" YANDEX360_ORG_ID=\"$org_id\" _saveaccountconf_mutable YANDEX360_ORG_ID \"$YANDEX360_ORG_ID\" return 0 fi done if [ -z \"$root_domain\" ]; then _err \"Could not find a matching root domain for $domain in any organization\" return 1 fi }"
        },
        {
            "filename": "file_298.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_298.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_yc_info='Yandex Cloud DNS Site: Cloud.Yandex.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_yc Options: YC_Zone_ID DNS Zone ID YC_Folder_ID YC Folder ID YC_SA_ID Service Account ID YC_SA_Key_ID Service Account IAM Key ID YC_SA_Key_File_Path Private key file path. Optional. YC_SA_Key_File_PEM_b64 Base64 content of private key file. Use instead of Path to private key file. Optional. Issues: github.com/acmesh-official/acme.sh/issues/4210 ' YC_Api=\"https://dns.api.cloud.yandex.net/dns/v1\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_yc_add() { fulldomain=\"$(echo \"$1\". | _lower_case)\" # Add dot at end of domain name txtvalue=$2 YC_SA_Key_File_PEM_b64=\"${YC_SA_Key_File_PEM_b64:-$(_readaccountconf_mutable YC_SA_Key_File_PEM_b64)}\" YC_SA_Key_File_Path=\"${YC_SA_Key_File_Path:-$(_readaccountconf_mutable YC_SA_Key_File_Path)}\" if [ \"$YC_SA_Key_File_PEM_b64\" ]; then echo \"$YC_SA_Key_File_PEM_b64\" | _dbase64 >private.key YC_SA_Key_File=\"private.key\" _savedomainconf YC_SA_Key_File_PEM_b64 \"$YC_SA_Key_File_PEM_b64\" else YC_SA_Key_File=\"$YC_SA_Key_File_Path\" _savedomainconf YC_SA_Key_File_Path \"$YC_SA_Key_File_Path\" fi YC_Zone_ID=\"${YC_Zone_ID:-$(_readaccountconf_mutable YC_Zone_ID)}\" YC_Folder_ID=\"${YC_Folder_ID:-$(_readaccountconf_mutable YC_Folder_ID)}\" YC_SA_ID=\"${YC_SA_ID:-$(_readaccountconf_mutable YC_SA_ID)}\" YC_SA_Key_ID=\"${YC_SA_Key_ID:-$(_readaccountconf_mutable YC_SA_Key_ID)}\" if [ \"$YC_SA_ID\" ] && [ \"$YC_SA_Key_ID\" ] && [ \"$YC_SA_Key_File\" ]; then if [ -f \"$YC_SA_Key_File\" ]; then if _isRSA \"$YC_SA_Key_File\" >/dev/null 2>&1; then if [ \"$YC_Zone_ID\" ]; then _savedomainconf YC_Zone_ID \"$YC_Zone_ID\" _savedomainconf YC_SA_ID \"$YC_SA_ID\" _savedomainconf YC_SA_Key_ID \"$YC_SA_Key_ID\" elif [ \"$YC_Folder_ID\" ]; then _savedomainconf YC_Folder_ID \"$YC_Folder_ID\" _saveaccountconf_mutable YC_SA_ID \"$YC_SA_ID\" _saveaccountconf_mutable YC_SA_Key_ID \"$YC_SA_Key_ID\" _clearaccountconf_mutable YC_Zone_ID _clearaccountconf YC_Zone_ID else _err \"You didn't specify a Yandex Cloud Zone ID or Folder ID yet.\" return 1 fi else _err \"YC_SA_Key_File not a RSA file(_isRSA function return false).\" return 1 fi else _err \"YC_SA_Key_File not found in path $YC_SA_Key_File.\" return 1 fi else _clearaccountconf YC_Zone_ID _clearaccountconf YC_Folder_ID _clearaccountconf YC_SA_ID _clearaccountconf YC_SA_Key_ID _clearaccountconf YC_SA_Key_File_PEM_b64 _clearaccountconf YC_SA_Key_File_Path _err \"You didn't specify a YC_SA_ID or YC_SA_Key_ID or YC_SA_Key_File.\" return 1 fi _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" if ! _yc_rest GET \"zones/${_domain_id}:getRecordSet?type=TXT&name=$_sub_domain\"; then _err \"Error: $response\" return 1 fi _info \"Adding record\" if _yc_rest POST \"zones/$_domain_id:upsertRecordSets\" \"{\\\"merges\\\": [ { \\\"name\\\":\\\"$_sub_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"ttl\\\":\\\"120\\\",\\\"data\\\":[\\\"$txtvalue\\\"]}]}\"; then if _contains \"$response\" \"\\\"done\\\": true\"; then _info \"Added, OK\" return 0 else _err \"Add txt record error.\" return 1 fi fi _err \"Add txt record error.\" return 1 } #fulldomain txtvalue dns_yc_rm() { fulldomain=\"$(echo \"$1\". | _lower_case)\" # Add dot at end of domain name txtvalue=$2 YC_Zone_ID=\"${YC_Zone_ID:-$(_readaccountconf_mutable YC_Zone_ID)}\" YC_Folder_ID=\"${YC_Folder_ID:-$(_readaccountconf_mutable YC_Folder_ID)}\" YC_SA_ID=\"${YC_SA_ID:-$(_readaccountconf_mutable YC_SA_ID)}\" YC_SA_Key_ID=\"${YC_SA_Key_ID:-$(_readaccountconf_mutable YC_SA_Key_ID)}\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug _domain_id \"$_domain_id\" _debug _sub_domain \"$_sub_domain\" _debug _domain \"$_domain\" _debug \"Getting txt records\" if _yc_rest GET \"zones/${_domain_id}:getRecordSet?type=TXT&name=$_sub_domain\"; then exists_txtvalue=$(echo \"$response\" | _normalizeJson | _egrep_o \"\\\"data\\\".*\\][^,]*\" | _egrep_o \"[^:]*$\") _debug exists_txtvalue \"$exists_txtvalue\" else _err \"Error: $response\" return 1 fi if _yc_rest POST \"zones/$_domain_id:updateRecordSets\" \"{\\\"deletions\\\": [ { \\\"name\\\":\\\"$_sub_domain\\\",\\\"type\\\":\\\"TXT\\\",\\\"ttl\\\":\\\"120\\\",\\\"data\\\":$exists_txtvalue}]}\"; then if _contains \"$response\" \"\\\"done\\\": true\"; then _info \"Delete, OK\" return 0 else _err \"Delete record error.\" return 1 fi fi _err \"Delete record error.\" return 1 } #################### Private functions below ################################## #_acme-challenge.www.domain.com #returns # _sub_domain=_acme-challenge.www # _domain=domain.com # _domain_id=sdjkglgdfewsdfg _get_root() { domain=$1 i=1 p=1 # Use Zone ID directly if provided if [ \"$YC_Zone_ID\" ]; then if ! _yc_rest GET \"zones/$YC_Zone_ID\"; then return 1 else if echo \"$response\" | tr -d \" \" | _egrep_o \"\\\"id\\\":\\\"$YC_Zone_ID\\\"\" >/dev/null; then _domain=$(echo \"$response\" | _egrep_o \"\\\"zone\\\": *\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\" | _head_n 1 | tr -d \" \") if [ \"$_domain\" ]; then _cutlength=$((${#domain} - ${#_domain})) _sub_domain=$(printf \"%s\" \"$domain\" | cut -c \"1-$_cutlength\") _domain_id=$YC_Zone_ID return 0 else return 1 fi else return 1 fi fi fi while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if [ \"$YC_Folder_ID\" ]; then if ! _yc_rest GET \"zones?folderId=$YC_Folder_ID\"; then return 1 fi else echo \"You didn't specify a Yandex Cloud Folder ID.\" return 1 fi if _contains \"$response\" \"\\\"zone\\\": \\\"$h\\\"\"; then _domain_id=$(echo \"$response\" | _normalizeJson | _egrep_o \"[^{]*\\\"zone\\\":\\\"$h\\\"[^}]*\" | _egrep_o \"\\\"id\\\"[^,]*\" | _egrep_o \"[^:]*$\" | tr -d '\"') _debug _domain_id \"$_domain_id\" if [ \"$_domain_id\" ]; then _sub_domain=$(printf \"%s\" \"$domain\" | cut -d . -f 1-$p) _domain=$h return 0 fi return 1 fi p=$i i=$(_math \"$i\" + 1) done return 1 } _yc_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" if [ ! \"$YC_Token\" ]; then _debug \"Login\" _yc_login else _debug \"Token already exists. Skip Login.\" fi token_trimmed=$(echo \"$YC_Token\" | tr -d '\"') export _H1=\"Content-Type: application/json\" export _H2=\"Authorization: Bearer $token_trimmed\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$YC_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$YC_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 } _yc_login() { header=$(echo \"{\\\"typ\\\":\\\"JWT\\\",\\\"alg\\\":\\\"PS256\\\",\\\"kid\\\":\\\"$YC_SA_Key_ID\\\"}\" | _normalizeJson | _base64 | _url_replace) _debug header \"$header\" _current_timestamp=$(_time) _expire_timestamp=$(_math \"$_current_timestamp\" + 1200) # 20 minutes payload=$(echo \"{\\\"iss\\\":\\\"$YC_SA_ID\\\",\\\"aud\\\":\\\"https://iam.api.cloud.yandex.net/iam/v1/tokens\\\",\\\"iat\\\":$_current_timestamp,\\\"exp\\\":$_expire_timestamp}\" | _normalizeJson | _base64 | _url_replace) _debug payload \"$payload\" #signature=$(printf \"%s.%s\" \"$header\" \"$payload\" | ${ACME_OPENSSL_BIN:-openssl} dgst -sign \"$YC_SA_Key_File -sha256 -sigopt rsa_padding_mode:pss -sigopt rsa_pss_saltlen:-1\" | _base64 | _url_replace ) _signature=$(printf \"%s.%s\" \"$header\" \"$payload\" | _sign \"$YC_SA_Key_File\" \"sha256 -sigopt rsa_padding_mode:pss -sigopt rsa_pss_saltlen:-1\" | _url_replace) _debug2 _signature \"$_signature\" rm -rf \"$YC_SA_Key_File\" _jwt=$(printf \"{\\\"jwt\\\": \\\"%s.%s.%s\\\"}\" \"$header\" \"$payload\" \"$_signature\") _debug2 _jwt \"$_jwt\" export _H1=\"Content-Type: application/json\" _iam_response=\"$(_post \"$_jwt\" \"https://iam.api.cloud.yandex.net/iam/v1/tokens\" \"\" \"POST\")\" _debug3 _iam_response \"$(echo \"$_iam_response\" | _normalizeJson)\" YC_Token=\"$(echo \"$_iam_response\" | _normalizeJson | _egrep_o \"\\\"iamToken\\\"[^,]*\" | _egrep_o \"[^:]*$\" | tr -d '\"')\" _debug3 YC_Token return 0 }"
        },
        {
            "filename": "file_299.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_299.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_zilore_info='Zilore.com Site: Zilore.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_zilore Options: Zilore_Key API Key ' Zilore_API=\"https://api.zilore.com/dns/v1\" ######## Public functions ##################### dns_zilore_add() { fulldomain=$1 txtvalue=$2 _info \"Using Zilore\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" Zilore_Key=\"${Zilore_Key:-$(_readaccountconf_mutable Zilore_Key)}\" if [ -z \"$Zilore_Key\" ]; then Zilore_Key=\"\" _err \"Please define Zilore API key\" return 1 fi _saveaccountconf_mutable Zilore_Key \"$Zilore_Key\" if ! _get_root \"$fulldomain\"; then _err \"Unable to determine root domain\" return 1 else _debug _domain \"$_domain\" fi if _zilore_rest POST \"domains/$_domain/records?record_type=TXT&record_ttl=600&record_name=$fulldomain&record_value=\\\"$txtvalue\\\"\"; then if _contains \"$response\" '\"added\"' >/dev/null; then _info \"Added TXT record, waiting for validation\" return 0 else _debug response \"$response\" _err \"Error while adding DNS records\" return 1 fi fi return 1 } dns_zilore_rm() { fulldomain=$1 txtvalue=$2 _info \"Using Zilore\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" Zilore_Key=\"${Zilore_Key:-$(_readaccountconf_mutable Zilore_Key)}\" if [ -z \"$Zilore_Key\" ]; then Zilore_Key=\"\" _err \"Please define Zilore API key\" return 1 fi _saveaccountconf_mutable Zilore_Key \"$Zilore_Key\" if ! _get_root \"$fulldomain\"; then _err \"Unable to determine root domain\" return 1 else _debug _domain \"$_domain\" fi _debug \"Getting TXT records\" _zilore_rest GET \"domains/${_domain}/records?search_text=$txtvalue&search_record_type=TXT\" _debug response \"$response\" if ! _contains \"$response\" '\"ok\"' >/dev/null; then _err \"Error while getting records list\" return 1 else _record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"record_id\\\":\\\"[^\\\"]+\\\"\" | cut -d : -f 2 | tr -d \\\" | _head_n 1) if [ -z \"$_record_id\" ]; then _err \"Cannot determine _record_id\" return 1 else _debug _record_id \"$_record_id\" fi if ! _zilore_rest DELETE \"domains/${_domain}/records?record_id=$_record_id\"; then _err \"Error while deleting chosen record\" return 1 fi _contains \"$response\" '\"ok\"' fi } #################### Private functions below ################################## _get_root() { domain=$1 i=2 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then #not valid return 1 fi if ! _zilore_rest GET \"domains?search_text=$h\"; then return 1 fi if _contains \"$response\" \"\\\"$h\\\"\" >/dev/null; then _domain=$h return 0 else _debug \"$h not found\" fi i=$(_math \"$i\" + 1) done return 1 } _zilore_rest() { method=$1 param=$2 data=$3 export _H1=\"X-Auth-Key: $Zilore_Key\" if [ \"$method\" != \"GET\" ]; then response=\"$(_post \"$data\" \"$Zilore_API/$param\" \"\" \"$method\")\" else response=\"$(_get \"$Zilore_API/$param\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $param\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_300.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_300.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_zone_info='Zone.eu Site: Zone.eu Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_zone Options: ZONE_Username Username ZONE_Key API Key Issues: github.com/acmesh-official/acme.sh/issues/2146 ' # Zone.ee dns API # https://help.zone.eu/kb/zoneid-api-v2/ ZONE_Api=\"https://api.zone.eu/v2\" ######## Public functions ##################### #Usage: dns_zone_add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_zone_add() { fulldomain=$1 txtvalue=$2 _info \"Using zone.ee dns api\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" ZONE_Username=\"${ZONE_Username:-$(_readaccountconf_mutable ZONE_Username)}\" ZONE_Key=\"${ZONE_Key:-$(_readaccountconf_mutable ZONE_Key)}\" if [ -z \"$ZONE_Username\" ] || [ -z \"$ZONE_Key\" ]; then ZONE_Username=\"\" ZONE_Key=\"\" _err \"Zone api key and username must be present.\" return 1 fi _saveaccountconf_mutable ZONE_Username \"$ZONE_Username\" _saveaccountconf_mutable ZONE_Key \"$ZONE_Key\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug \"Adding txt record\" if _zone_rest POST \"dns/${_domain}/txt\" \"{\\\"name\\\": \\\"$fulldomain\\\", \\\"destination\\\": \\\"$txtvalue\\\"}\"; then if printf -- \"%s\" \"$response\" | grep \"$fulldomain\" >/dev/null; then _info \"Added, OK\" return 0 else _err \"Adding txt record error.\" return 1 fi else _err \"Adding txt record error.\" fi } #Usage: fulldomain txtvalue #Remove the txt record after validation. dns_zone_rm() { fulldomain=$1 txtvalue=$2 _info \"Using zone.ee dns api\" _debug fulldomain \"$fulldomain\" _debug txtvalue \"$txtvalue\" ZONE_Username=\"${ZONE_Username:-$(_readaccountconf_mutable ZONE_Username)}\" ZONE_Key=\"${ZONE_Key:-$(_readaccountconf_mutable ZONE_Key)}\" if [ -z \"$ZONE_Username\" ] || [ -z \"$ZONE_Key\" ]; then ZONE_Username=\"\" ZONE_Key=\"\" _err \"Zone api key and username must be present.\" return 1 fi _saveaccountconf_mutable ZONE_Username \"$ZONE_Username\" _saveaccountconf_mutable ZONE_Key \"$ZONE_Key\" _debug \"First detect the root zone\" if ! _get_root \"$fulldomain\"; then _err \"invalid domain\" return 1 fi _debug \"Getting txt records\" _debug _domain \"$_domain\" _zone_rest GET \"dns/${_domain}/txt\" if printf \"%s\" \"$response\" | grep \\\"error\\\" >/dev/null; then _err \"Error\" return 1 fi count=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"name\\\":\\\"$fulldomain\\\"\" | wc -l) _debug count \"$count\" if [ \"$count\" = \"0\" ]; then _info \"Nothing to remove.\" else record_id=$(printf \"%s\\n\" \"$response\" | _egrep_o \"\\\"id\\\":\\\"[^\\\"]*\\\",\\\"resource_url\\\":\\\"[^\\\"]*\\\",\\\"name\\\":\\\"$fulldomain\\\",\" | cut -d : -f2 | cut -d , -f1 | tr -d \\\" | _head_n 1) if [ -z \"$record_id\" ]; then _err \"No id found to remove.\" return 1 fi if ! _zone_rest DELETE \"dns/${_domain}/txt/$record_id\"; then _err \"Record deleting error.\" return 1 fi _info \"Record deleted\" return 0 fi } #################### Private functions below ################################## _zone_rest() { m=$1 ep=\"$2\" data=\"$3\" _debug \"$ep\" realm=\"$(printf \"%s\" \"$ZONE_Username:$ZONE_Key\" | _base64)\" export _H1=\"Authorization: Basic $realm\" export _H2=\"Content-Type: application/json\" if [ \"$m\" != \"GET\" ]; then _debug data \"$data\" response=\"$(_post \"$data\" \"$ZONE_Api/$ep\" \"\" \"$m\")\" else response=\"$(_get \"$ZONE_Api/$ep\")\" fi if [ \"$?\" != \"0\" ]; then _err \"error $ep\" return 1 fi _debug2 response \"$response\" return 0 } _get_root() { domain=$1 i=2 while true; do h=$(printf \"%s\" \"$domain\" | cut -d . -f $i-100) _debug h \"$h\" if [ -z \"$h\" ]; then return 1 fi if ! _zone_rest GET \"dns/$h\"; then return 1 fi if _contains \"$response\" \"\\\"identificator\\\":\\\"$h\\\"\" >/dev/null; then _domain=$h return 0 fi i=$(_math \"$i\" + 1) done return 0 }"
        },
        {
            "filename": "file_301.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\dnsapi\\file_301.sh",
            "content": "#!/usr/bin/env sh # shellcheck disable=SC2034 dns_zonomi_info='zonomi.com Site: zonomi.com Docs: github.com/acmesh-official/acme.sh/wiki/dnsapi#dns_zonomi Options: ZM_Key API Key ' ZM_Api=\"https://zonomi.com/app/dns/dyndns.jsp\" ######## Public functions ##################### #Usage: add _acme-challenge.www.domain.com \"XKrxpRBosdIKFzxW_CT3KLZNf6q0HG9i01zxXp5CPBs\" dns_zonomi_add() { fulldomain=$1 txtvalue=$2 ZM_Key=\"${ZM_Key:-$(_readaccountconf_mutable ZM_Key)}\" if [ -z \"$ZM_Key\" ]; then ZM_Key=\"\" _err \"You don't specify zonomi api key yet.\" _err \"Please create your key and try again.\" return 1 fi #save the api key to the account conf file. _saveaccountconf_mutable ZM_Key \"$ZM_Key\" _info \"Get existing txt records for $fulldomain\" if ! _zm_request \"action=QUERY&name=$fulldomain\"; then _err \"error\" return 1 fi if _contains \"$response\" \"<record\"; then _debug \"get and update records\" _qstr=\"action[1]=SET&type[1]=TXT&name[1]=$fulldomain&value[1]=$txtvalue\" _qindex=2 for t in $(echo \"$response\" | tr -d \"\\r\\n\" | _egrep_o '<action.*</action>' | tr \"<\" \"\\n\" | grep record | grep 'type=\"TXT\"' | cut -d '\"' -f 6); do _debug2 t \"$t\" _qstr=\"$_qstr&action[$_qindex]=SET&type[$_qindex]=TXT&name[$_qindex]=$fulldomain&value[$_qindex]=$t\" _qindex=\"$(_math \"$_qindex\" + 1)\" done _zm_request \"$_qstr\" else _debug \"Just add record\" _zm_request \"action=SET&type=TXT&name=$fulldomain&value=$txtvalue\" fi } #fulldomain txtvalue dns_zonomi_rm() { fulldomain=$1 txtvalue=$2 ZM_Key=\"${ZM_Key:-$(_readaccountconf_mutable ZM_Key)}\" if [ -z \"$ZM_Key\" ]; then ZM_Key=\"\" _err \"You don't specify zonomi api key yet.\" _err \"Please create your key and try again.\" return 1 fi _zm_request \"action=DELETE&type=TXT&name=$fulldomain\" } #################### Private functions below ################################## #qstr _zm_request() { qstr=\"$1\" _debug2 \"qstr\" \"$qstr\" _zm_url=\"$ZM_Api?api_key=$ZM_Key&$qstr\" _debug2 \"_zm_url\" \"$_zm_url\" response=\"$(_get \"$_zm_url\")\" if [ \"$?\" != \"0\" ]; then return 1 fi _debug2 response \"$response\" _contains \"$response\" \"<is_ok>OK:\" }"
        },
        {
            "filename": "file_302.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_302.sh",
            "content": "#!/usr/bin/env sh # #AWS_ACCESS_KEY_ID=\"sdfsdfsdfljlbjkljlkjsdfoiwje\" # #AWS_SECRET_ACCESS_KEY=\"xxxxxxx\" # #AWS_SES_REGION=\"us-east-1\" # #AWS_SES_TO=\"xxxx@xxx.com\" # #AWS_SES_FROM=\"xxxx@cccc.com\" # #AWS_SES_FROM_NAME=\"Something something\" #This is the Amazon SES api wrapper for acme.sh AWS_WIKI=\"https://docs.aws.amazon.com/ses/latest/dg/send-email-api.html\" aws_ses_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" AWS_ACCESS_KEY_ID=\"${AWS_ACCESS_KEY_ID:-$(_readaccountconf_mutable AWS_ACCESS_KEY_ID)}\" AWS_SECRET_ACCESS_KEY=\"${AWS_SECRET_ACCESS_KEY:-$(_readaccountconf_mutable AWS_SECRET_ACCESS_KEY)}\" AWS_SES_REGION=\"${AWS_SES_REGION:-$(_readaccountconf_mutable AWS_SES_REGION)}\" if [ -z \"$AWS_ACCESS_KEY_ID\" ] || [ -z \"$AWS_SECRET_ACCESS_KEY\" ]; then _use_container_role || _use_instance_role fi if [ -z \"$AWS_ACCESS_KEY_ID\" ] || [ -z \"$AWS_SECRET_ACCESS_KEY\" ]; then AWS_ACCESS_KEY_ID=\"\" AWS_SECRET_ACCESS_KEY=\"\" _err \"You haven't specified the aws SES api key id and and api key secret yet.\" _err \"Please create your key and try again. see $(__green $AWS_WIKI)\" return 1 fi if [ -z \"$AWS_SES_REGION\" ]; then AWS_SES_REGION=\"\" _err \"You haven't specified the aws SES api region yet.\" _err \"Please specify your region and try again. see https://docs.aws.amazon.com/general/latest/gr/ses.html\" return 1 fi _saveaccountconf_mutable AWS_SES_REGION \"$AWS_SES_REGION\" #save for future use, unless using a role which will be fetched as needed if [ -z \"$_using_role\" ]; then _saveaccountconf_mutable AWS_ACCESS_KEY_ID \"$AWS_ACCESS_KEY_ID\" _saveaccountconf_mutable AWS_SECRET_ACCESS_KEY \"$AWS_SECRET_ACCESS_KEY\" fi AWS_SES_TO=\"${AWS_SES_TO:-$(_readaccountconf_mutable AWS_SES_TO)}\" if [ -z \"$AWS_SES_TO\" ]; then AWS_SES_TO=\"\" _err \"You didn't specify an email to AWS_SES_TO receive messages.\" return 1 fi _saveaccountconf_mutable AWS_SES_TO \"$AWS_SES_TO\" AWS_SES_FROM=\"${AWS_SES_FROM:-$(_readaccountconf_mutable AWS_SES_FROM)}\" if [ -z \"$AWS_SES_FROM\" ]; then AWS_SES_FROM=\"\" _err \"You didn't specify an email to AWS_SES_FROM receive messages.\" return 1 fi _saveaccountconf_mutable AWS_SES_FROM \"$AWS_SES_FROM\" AWS_SES_FROM_NAME=\"${AWS_SES_FROM_NAME:-$(_readaccountconf_mutable AWS_SES_FROM_NAME)}\" _saveaccountconf_mutable AWS_SES_FROM_NAME \"$AWS_SES_FROM_NAME\" AWS_SES_SENDFROM=\"$AWS_SES_FROM_NAME <$AWS_SES_FROM>\" AWS_SES_ACTION=\"Action=SendEmail\" AWS_SES_SOURCE=\"Source=$AWS_SES_SENDFROM\" AWS_SES_TO=\"Destination.ToAddresses.member.1=$AWS_SES_TO\" AWS_SES_SUBJECT=\"Message.Subject.Data=$_subject\" AWS_SES_MESSAGE=\"Message.Body.Text.Data=$_content\" _data=\"${AWS_SES_ACTION}&${AWS_SES_SOURCE}&${AWS_SES_TO}&${AWS_SES_SUBJECT}&${AWS_SES_MESSAGE}\" response=\"$(aws_rest POST \"\" \"\" \"$_data\")\" } _use_metadata() { _aws_creds=\"$( _get \"$1\" \"\" 1 | _normalizeJson | tr '{,}' '\\n' | while read -r _line; do _key=\"$(echo \"${_line%%:*}\" | tr -d '\"')\" _value=\"${_line#*:}\" _debug3 \"_key\" \"$_key\" _secure_debug3 \"_value\" \"$_value\" case \"$_key\" in AccessKeyId) echo \"AWS_ACCESS_KEY_ID=$_value\" ;; SecretAccessKey) echo \"AWS_SECRET_ACCESS_KEY=$_value\" ;; Token) echo \"AWS_SESSION_TOKEN=$_value\" ;; esac done | paste -sd' ' - )\" _secure_debug \"_aws_creds\" \"$_aws_creds\" if [ -z \"$_aws_creds\" ]; then return 1 fi eval \"$_aws_creds\" _using_role=true } #method uri qstr data aws_rest() { mtd=\"$1\" ep=\"$2\" qsr=\"$3\" data=\"$4\" _debug mtd \"$mtd\" _debug ep \"$ep\" _debug qsr \"$qsr\" _debug data \"$data\" CanonicalURI=\"/$ep\" _debug2 CanonicalURI \"$CanonicalURI\" CanonicalQueryString=\"$qsr\" _debug2 CanonicalQueryString \"$CanonicalQueryString\" RequestDate=\"$(date -u +\"%Y%m%dT%H%M%SZ\")\" _debug2 RequestDate \"$RequestDate\" #RequestDate=\"20161120T141056Z\" ############## export _H1=\"x-amz-date: $RequestDate\" aws_host=\"email.$AWS_SES_REGION.amazonaws.com\" CanonicalHeaders=\"host:$aws_host\\nx-amz-date:$RequestDate\\n\" SignedHeaders=\"host;x-amz-date\" if [ -n \"$AWS_SESSION_TOKEN\" ]; then export _H3=\"x-amz-security-token: $AWS_SESSION_TOKEN\" CanonicalHeaders=\"${CanonicalHeaders}x-amz-security-token:$AWS_SESSION_TOKEN\\n\" SignedHeaders=\"${SignedHeaders};x-amz-security-token\" fi _debug2 CanonicalHeaders \"$CanonicalHeaders\" _debug2 SignedHeaders \"$SignedHeaders\" RequestPayload=\"$data\" _debug2 RequestPayload \"$RequestPayload\" Hash=\"sha256\" CanonicalRequest=\"$mtd\\n$CanonicalURI\\n$CanonicalQueryString\\n$CanonicalHeaders\\n$SignedHeaders\\n$(printf \"%s\" \"$RequestPayload\" | _digest \"$Hash\" hex)\" _debug2 CanonicalRequest \"$CanonicalRequest\" HashedCanonicalRequest=\"$(printf \"$CanonicalRequest%s\" | _digest \"$Hash\" hex)\" _debug2 HashedCanonicalRequest \"$HashedCanonicalRequest\" Algorithm=\"AWS4-HMAC-SHA256\" _debug2 Algorithm \"$Algorithm\" RequestDateOnly=\"$(echo \"$RequestDate\" | cut -c 1-8)\" _debug2 RequestDateOnly \"$RequestDateOnly\" Region=\"$AWS_SES_REGION\" Service=\"ses\" CredentialScope=\"$RequestDateOnly/$Region/$Service/aws4_request\" _debug2 CredentialScope \"$CredentialScope\" StringToSign=\"$Algorithm\\n$RequestDate\\n$CredentialScope\\n$HashedCanonicalRequest\" _debug2 StringToSign \"$StringToSign\" kSecret=\"AWS4$AWS_SECRET_ACCESS_KEY\" #kSecret=\"wJalrXUtnFEMI/K7MDENG+bPxRfiCYEXAMPLEKEY\" ############################ _secure_debug2 kSecret \"$kSecret\" kSecretH=\"$(printf \"%s\" \"$kSecret\" | _hex_dump | tr -d \" \")\" _secure_debug2 kSecretH \"$kSecretH\" kDateH=\"$(printf \"$RequestDateOnly%s\" | _hmac \"$Hash\" \"$kSecretH\" hex)\" _debug2 kDateH \"$kDateH\" kRegionH=\"$(printf \"$Region%s\" | _hmac \"$Hash\" \"$kDateH\" hex)\" _debug2 kRegionH \"$kRegionH\" kServiceH=\"$(printf \"$Service%s\" | _hmac \"$Hash\" \"$kRegionH\" hex)\" _debug2 kServiceH \"$kServiceH\" kSigningH=\"$(printf \"%s\" \"aws4_request\" | _hmac \"$Hash\" \"$kServiceH\" hex)\" _debug2 kSigningH \"$kSigningH\" signature=\"$(printf \"$StringToSign%s\" | _hmac \"$Hash\" \"$kSigningH\" hex)\" _debug2 signature \"$signature\" Authorization=\"$Algorithm Credential=$AWS_ACCESS_KEY_ID/$CredentialScope, SignedHeaders=$SignedHeaders, Signature=$signature\" _debug2 Authorization \"$Authorization\" _H2=\"Authorization: $Authorization\" _debug _H2 \"$_H2\" url=\"https://$aws_host/$ep\" if [ \"$qsr\" ]; then url=\"https://$aws_host/$ep?$qsr\" fi if [ \"$mtd\" = \"GET\" ]; then response=\"$(_get \"$url\")\" else response=\"$(_post \"$data\" \"$url\")\" fi _ret=\"$?\" _debug2 response \"$response\" if [ \"$_ret\" = \"0\" ]; then if _contains \"$response\" \"<ErrorResponse\"; then _err \"Response error:$response\" return 1 fi fi }"
        },
        {
            "filename": "file_303.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_303.sh",
            "content": "#!/usr/bin/env sh # Support iOS Bark Notification # Every parameter explained: https://github.com/Finb/bark-server/blob/master/docs/API_V2.md#push # BARK_API_URL=\"https://api.day.app/xxxx\" (required) # BARK_GROUP=\"ACME\" (optional) # BARK_SOUND=\"alarm\" (optional) # BARK_LEVEL=\"active\" (optional) # BARK_BADGE=0 (optional) # BARK_AUTOMATICALLYCOPY=\"1\" (optional) # BARK_COPY=\"My clipboard Content\" (optional) # BARK_ICON=\"https://example.com/icon.png\" (optional) # BARK_ISARCHIVE=\"1\" (optional) # BARK_URL=\"https://example.com\" (optional) # subject content statusCode bark_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" # 0: success, 1: error, 2: skipped _debug \"_subject\" \"$_subject\" _debug \"_content\" \"$_content\" _debug \"_statusCode\" \"$_statusCode\" _content=$(echo \"$_content\" | _url_encode) _subject=$(echo \"$_subject\" | _url_encode) BARK_API_URL=\"${BARK_API_URL:-$(_readaccountconf_mutable BARK_API_URL)}\" if [ -z \"$BARK_API_URL\" ]; then _err \"You didn't specify a Bark API URL BARK_API_URL yet.\" _err \"You can download Bark from App Store and get yours.\" return 1 fi _saveaccountconf_mutable BARK_API_URL \"$BARK_API_URL\" BARK_GROUP=\"${BARK_GROUP:-$(_readaccountconf_mutable BARK_GROUP)}\" if [ -z \"$BARK_GROUP\" ]; then BARK_GROUP=\"ACME\" _info \"The BARK_GROUP is not set, so use the default ACME as group name.\" else _saveaccountconf_mutable BARK_GROUP \"$BARK_GROUP\" fi BARK_SOUND=\"${BARK_SOUND:-$(_readaccountconf_mutable BARK_SOUND)}\" if [ -n \"$BARK_SOUND\" ]; then _saveaccountconf_mutable BARK_SOUND \"$BARK_SOUND\" fi BARK_LEVEL=\"${BARK_LEVEL:-$(_readaccountconf_mutable BARK_LEVEL)}\" if [ -n \"$BARK_LEVEL\" ]; then _saveaccountconf_mutable BARK_LEVEL \"$BARK_LEVEL\" fi BARK_BADGE=\"${BARK_BADGE:-$(_readaccountconf_mutable BARK_BADGE)}\" if [ -n \"$BARK_BADGE\" ]; then _saveaccountconf_mutable BARK_BADGE \"$BARK_BADGE\" fi BARK_AUTOMATICALLYCOPY=\"${BARK_AUTOMATICALLYCOPY:-$(_readaccountconf_mutable BARK_AUTOMATICALLYCOPY)}\" if [ -n \"$BARK_AUTOMATICALLYCOPY\" ]; then _saveaccountconf_mutable BARK_AUTOMATICALLYCOPY \"$BARK_AUTOMATICALLYCOPY\" fi BARK_COPY=\"${BARK_COPY:-$(_readaccountconf_mutable BARK_COPY)}\" if [ -n \"$BARK_COPY\" ]; then _saveaccountconf_mutable BARK_COPY \"$BARK_COPY\" fi BARK_ICON=\"${BARK_ICON:-$(_readaccountconf_mutable BARK_ICON)}\" if [ -n \"$BARK_ICON\" ]; then _saveaccountconf_mutable BARK_ICON \"$BARK_ICON\" fi BARK_ISARCHIVE=\"${BARK_ISARCHIVE:-$(_readaccountconf_mutable BARK_ISARCHIVE)}\" if [ -n \"$BARK_ISARCHIVE\" ]; then _saveaccountconf_mutable BARK_ISARCHIVE \"$BARK_ISARCHIVE\" fi BARK_URL=\"${BARK_URL:-$(_readaccountconf_mutable BARK_URL)}\" if [ -n \"$BARK_URL\" ]; then _saveaccountconf_mutable BARK_URL \"$BARK_URL\" fi _params=\"\" if [ -n \"$BARK_SOUND\" ]; then _params=\"$_params&sound=$BARK_SOUND\" fi if [ -n \"$BARK_GROUP\" ]; then _params=\"$_params&group=$BARK_GROUP\" fi if [ -n \"$BARK_LEVEL\" ]; then _params=\"$_params&level=$BARK_LEVEL\" fi if [ -n \"$BARK_BADGE\" ]; then _params=\"$_params&badge=$BARK_BADGE\" fi if [ -n \"$BARK_AUTOMATICALLYCOPY\" ]; then _params=\"$_params&automaticallyCopy=$BARK_AUTOMATICALLYCOPY\" fi if [ -n \"$BARK_COPY\" ]; then _params=\"$_params&copy=$BARK_COPY\" fi if [ -n \"$BARK_ICON\" ]; then _params=\"$_params&icon=$BARK_ICON\" fi if [ -n \"$BARK_ISARCHIVE\" ]; then _params=\"$_params&isArchive=$BARK_ISARCHIVE\" fi if [ -n \"$BARK_URL\" ]; then _params=\"$_params&url=$BARK_URL\" fi _params=$(echo \"$_params\" | sed 's/^&//') # remove leading '&' if exists response=\"$(_get \"$BARK_API_URL/$_subject/$_content?$_params\")\" if [ \"$?\" = \"0\" ] && _contains \"$response\" \"success\"; then _info \"Bark API fired success.\" return 0 fi _err \"Bark API fired error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_304.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_304.sh",
            "content": "#!/usr/bin/env sh #Support CallMeBot Whatsapp webhooks #CALLMEBOT_YOUR_PHONE_NO=\"\" #CALLMEBOT_API_KEY=\"\" callmebotWhatsApp_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" CALLMEBOT_YOUR_PHONE_NO=\"${CALLMEBOT_YOUR_PHONE_NO:-$(_readaccountconf_mutable CALLMEBOT_YOUR_PHONE_NO)}\" if [ -z \"$CALLMEBOT_YOUR_PHONE_NO\" ]; then CALLMEBOT_YOUR_PHONE_NO=\"\" _err \"You didn't specify a Slack webhook url CALLMEBOT_YOUR_PHONE_NO yet.\" return 1 fi _saveaccountconf_mutable CALLMEBOT_YOUR_PHONE_NO \"$CALLMEBOT_YOUR_PHONE_NO\" CALLMEBOT_API_KEY=\"${CALLMEBOT_API_KEY:-$(_readaccountconf_mutable CALLMEBOT_API_KEY)}\" if [ \"$CALLMEBOT_API_KEY\" ]; then _saveaccountconf_mutable CALLMEBOT_API_KEY \"$CALLMEBOT_API_KEY\" fi _waUrl=\"https://api.callmebot.com/whatsapp.php\" _Phone_No=\"$(printf \"%s\" \"$CALLMEBOT_YOUR_PHONE_NO\" | _url_encode)\" _apikey=\"$(printf \"%s\" \"$CALLMEBOT_API_KEY\" | _url_encode)\" _message=\"$(printf \"*%s*\\\\n%s\" \"$_subject\" \"$_content\" | _url_encode)\" _finalUrl=\"$_waUrl?phone=$_Phone_No&apikey=$_apikey&text=$_message\" response=\"$(_get \"$_finalUrl\")\" if [ \"$?\" = \"0\" ] && _contains \".<p><b>Message queued.</b> You will receive it in a few seconds.\"; then _info \"wa send success.\" return 0 fi _err \"wa send error.\" _debug \"URL\" \"$_finalUrl\" _debug \"Response\" \"$response\" return 1 }"
        },
        {
            "filename": "file_305.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_305.sh",
            "content": "#!/usr/bin/env sh #Support for CQHTTP api. Push notification on CoolQ #CQHTTP_TOKEN=\"\" Recommended to be not empty, QQ application token #CQHTTP_USER=\"\" Required, QQ receiver ID #CQHTTP_APIROOT=\"\" Required, CQHTTP Server URL (without slash suffix) #CQHTTP_CUSTOM_MSGHEAD=\"\" Optional, custom message header CQHTTP_APIPATH=\"/send_private_msg\" cqhttp_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" CQHTTP_TOKEN=\"${CQHTTP_TOKEN:-$(_readaccountconf_mutable CQHTTP_TOKEN)}\" if [ -z \"$CQHTTP_TOKEN\" ]; then CQHTTP_TOKEN=\"\" _info \"You didn't specify a CQHTTP application token yet, which is unsafe. Assuming it to be empty.\" else _saveaccountconf_mutable CQHTTP_TOKEN \"$CQHTTP_TOKEN\" fi CQHTTP_USER=\"${CQHTTP_USER:-$(_readaccountconf_mutable CQHTTP_USER)}\" if [ -z \"$CQHTTP_USER\" ]; then CQHTTP_USER=\"\" _err \"You didn't specify a QQ user yet.\" return 1 fi _saveaccountconf_mutable CQHTTP_USER \"$CQHTTP_USER\" CQHTTP_APIROOT=\"${CQHTTP_APIROOT:-$(_readaccountconf_mutable CQHTTP_APIROOT)}\" if [ -z \"$CQHTTP_APIROOT\" ]; then CQHTTP_APIROOT=\"\" _err \"You didn't specify the API root yet.\" return 1 fi _saveaccountconf_mutable CQHTTP_APIROOT \"$CQHTTP_APIROOT\" CQHTTP_CUSTOM_MSGHEAD=\"${CQHTTP_CUSTOM_MSGHEAD:-$(_readaccountconf_mutable CQHTTP_CUSTOM_MSGHEAD)}\" if [ -z \"$CQHTTP_CUSTOM_MSGHEAD\" ]; then CQHTTP_CUSTOM_MSGHEAD=\"A message from acme.sh:\" else _saveaccountconf_mutable CQHTTP_CUSTOM_MSGHEAD \"$CQHTTP_CUSTOM_MSGHEAD\" fi _access_token=\"$(printf \"%s\" \"$CQHTTP_TOKEN\" | _url_encode)\" _user_id=\"$(printf \"%s\" \"$CQHTTP_USER\" | _url_encode)\" _message=\"$(printf \"$CQHTTP_CUSTOM_MSGHEAD %s\\\\n%s\" \"$_subject\" \"$_content\" | _url_encode)\" _finalUrl=\"$CQHTTP_APIROOT$CQHTTP_APIPATH?access_token=$_access_token&user_id=$_user_id&message=$_message\" response=\"$(_get \"$_finalUrl\")\" if [ \"$?\" = \"0\" ] && _contains \"$response\" \"\\\"retcode\\\":0,\\\"status\\\":\\\"ok\\\"\"; then _info \"QQ send success.\" return 0 fi _err \"QQ send error.\" _debug \"URL\" \"$_finalUrl\" _debug \"Response\" \"$response\" return 1 }"
        },
        {
            "filename": "file_306.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_306.sh",
            "content": "#!/usr/bin/env sh #Support dingtalk webhooks api #DINGTALK_WEBHOOK=\"xxxx\" #optional #DINGTALK_KEYWORD=\"yyyy\" #DINGTALK_SIGNING_KEY=\"SEC08ffdbd403cbc3fc8a65xxxxxxxxxxxxxxxxxxxx\" # subject content statusCode dingtalk_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_subject\" \"$_subject\" _debug \"_content\" \"$_content\" _debug \"_statusCode\" \"$_statusCode\" DINGTALK_WEBHOOK=\"${DINGTALK_WEBHOOK:-$(_readaccountconf_mutable DINGTALK_WEBHOOK)}\" if [ -z \"$DINGTALK_WEBHOOK\" ]; then DINGTALK_WEBHOOK=\"\" _err \"You didn't specify a dingtalk webhooks DINGTALK_WEBHOOK yet.\" _err \"You can get yours from https://dingtalk.com\" return 1 fi _saveaccountconf_mutable DINGTALK_WEBHOOK \"$DINGTALK_WEBHOOK\" DINGTALK_KEYWORD=\"${DINGTALK_KEYWORD:-$(_readaccountconf_mutable DINGTALK_KEYWORD)}\" if [ \"$DINGTALK_KEYWORD\" ]; then _saveaccountconf_mutable DINGTALK_KEYWORD \"$DINGTALK_KEYWORD\" fi # DINGTALK_SIGNING_KEY=\"${DINGTALK_SIGNING_KEY:-$(_readaccountconf_mutable DINGTALK_SIGNING_KEY)}\" # if [ -z \"$DINGTALK_SIGNING_KEY\" ]; then # DINGTALK_SIGNING_KEY=\"value1\" # _info \"The DINGTALK_SIGNING_KEY is not set, so use the default value1 as key.\" # elif ! _hasfield \"$_IFTTT_AVAIL_MSG_KEYS\" \"$DINGTALK_SIGNING_KEY\"; then # _err \"The DINGTALK_SIGNING_KEY \\\"$DINGTALK_SIGNING_KEY\\\" is not available, should be one of $_IFTTT_AVAIL_MSG_KEYS\" # DINGTALK_SIGNING_KEY=\"\" # return 1 # else # _saveaccountconf_mutable DINGTALK_SIGNING_KEY \"$DINGTALK_SIGNING_KEY\" # fi # if [ \"$DINGTALK_SIGNING_KEY\" = \"$IFTTT_CONTENT_KEY\" ]; then # DINGTALK_SIGNING_KEY=\"\" # IFTTT_CONTENT_KEY=\"\" # _err \"The DINGTALK_SIGNING_KEY must not be same as IFTTT_CONTENT_KEY.\" # return 1 # fi _content=$(echo \"$_content\" | _json_encode) _subject=$(echo \"$_subject\" | _json_encode) _data=\"{\\\"msgtype\\\": \\\"text\\\", \\\"text\\\": {\\\"content\\\": \\\"[$DINGTALK_KEYWORD]\\n$_subject\\n$_content\\\"}}\" response=\"$(_post \"$_data\" \"$DINGTALK_WEBHOOK\" \"\" \"POST\" \"application/json\")\" if [ \"$?\" = \"0\" ] && _contains \"$response\" \"errmsg\\\":\\\"ok\"; then _info \"dingtalk webhooks event fired success.\" return 0 fi _err \"dingtalk webhooks event fired error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_307.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_307.sh",
            "content": "#!/usr/bin/env sh #Support Discord webhooks # Required: #DISCORD_WEBHOOK_URL=\"\" # Optional: #DISCORD_USERNAME=\"\" #DISCORD_AVATAR_URL=\"\" discord_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" DISCORD_WEBHOOK_URL=\"${DISCORD_WEBHOOK_URL:-$(_readaccountconf_mutable DISCORD_WEBHOOK_URL)}\" if [ -z \"$DISCORD_WEBHOOK_URL\" ]; then DISCORD_WEBHOOK_URL=\"\" _err \"You didn't specify a Discord webhook url DISCORD_WEBHOOK_URL yet.\" return 1 fi _saveaccountconf_mutable DISCORD_WEBHOOK_URL \"$DISCORD_WEBHOOK_URL\" DISCORD_USERNAME=\"${DISCORD_USERNAME:-$(_readaccountconf_mutable DISCORD_USERNAME)}\" if [ \"$DISCORD_USERNAME\" ]; then _saveaccountconf_mutable DISCORD_USERNAME \"$DISCORD_USERNAME\" fi DISCORD_AVATAR_URL=\"${DISCORD_AVATAR_URL:-$(_readaccountconf_mutable DISCORD_AVATAR_URL)}\" if [ \"$DISCORD_AVATAR_URL\" ]; then _saveaccountconf_mutable DISCORD_AVATAR_URL \"$DISCORD_AVATAR_URL\" fi export _H1=\"Content-Type: application/json\" _content=\"$(printf \"**%s**\\n%s\" \"$_subject\" \"$_content\" | _json_encode)\" _data=\"{\\\"content\\\": \\\"$_content\\\" \" if [ \"$DISCORD_USERNAME\" ]; then _data=\"$_data, \\\"username\\\": \\\"$DISCORD_USERNAME\\\" \" fi if [ \"$DISCORD_AVATAR_URL\" ]; then _data=\"$_data, \\\"avatar_url\\\": \\\"$DISCORD_AVATAR_URL\\\" \" fi _data=\"$_data}\" if _post \"$_data\" \"$DISCORD_WEBHOOK_URL?wait=true\"; then # shellcheck disable=SC2154 if [ \"$response\" ]; then _info \"discord send success.\" return 0 fi fi _err \"discord send error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_308.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_308.sh",
            "content": "#!/usr/bin/env sh #Support feishu webhooks api #required #FEISHU_WEBHOOK=\"xxxx\" #optional #FEISHU_KEYWORD=\"yyyy\" # subject content statusCode feishu_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_subject\" \"$_subject\" _debug \"_content\" \"$_content\" _debug \"_statusCode\" \"$_statusCode\" FEISHU_WEBHOOK=\"${FEISHU_WEBHOOK:-$(_readaccountconf_mutable FEISHU_WEBHOOK)}\" if [ -z \"$FEISHU_WEBHOOK\" ]; then FEISHU_WEBHOOK=\"\" _err \"You didn't specify a feishu webhooks FEISHU_WEBHOOK yet.\" _err \"You can get yours from https://www.feishu.cn\" return 1 fi _saveaccountconf_mutable FEISHU_WEBHOOK \"$FEISHU_WEBHOOK\" FEISHU_KEYWORD=\"${FEISHU_KEYWORD:-$(_readaccountconf_mutable FEISHU_KEYWORD)}\" if [ \"$FEISHU_KEYWORD\" ]; then _saveaccountconf_mutable FEISHU_KEYWORD \"$FEISHU_KEYWORD\" fi _content=$(echo \"$_content\" | _json_encode) _subject=$(echo \"$_subject\" | _json_encode) _data=\"{\\\"msg_type\\\": \\\"text\\\", \\\"content\\\": {\\\"text\\\": \\\"[$FEISHU_KEYWORD]\\n$_subject\\n$_content\\\"}}\" response=\"$(_post \"$_data\" \"$FEISHU_WEBHOOK\" \"\" \"POST\" \"application/json\")\" if [ \"$?\" = \"0\" ] && _contains \"$response\" \"StatusCode\\\":0\"; then _info \"feishu webhooks event fired success.\" return 0 fi _err \"feishu webhooks event fired error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_309.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_309.sh",
            "content": "#!/usr/bin/env sh #Support Gotify #GOTIFY_URL=\"https://gotify.example.com\" #GOTIFY_TOKEN=\"123456789ABCDEF\" #optional #GOTIFY_PRIORITY=0 # subject content statusCode gotify_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_subject\" \"$_subject\" _debug \"_content\" \"$_content\" _debug \"_statusCode\" \"$_statusCode\" GOTIFY_URL=\"${GOTIFY_URL:-$(_readaccountconf_mutable GOTIFY_URL)}\" if [ -z \"$GOTIFY_URL\" ]; then GOTIFY_URL=\"\" _err \"You didn't specify the gotify server url GOTIFY_URL.\" return 1 fi _saveaccountconf_mutable GOTIFY_URL \"$GOTIFY_URL\" GOTIFY_TOKEN=\"${GOTIFY_TOKEN:-$(_readaccountconf_mutable GOTIFY_TOKEN)}\" if [ -z \"$GOTIFY_TOKEN\" ]; then GOTIFY_TOKEN=\"\" _err \"You didn't specify the gotify token GOTIFY_TOKEN.\" return 1 fi _saveaccountconf_mutable GOTIFY_TOKEN \"$GOTIFY_TOKEN\" GOTIFY_PRIORITY=\"${GOTIFY_PRIORITY:-$(_readaccountconf_mutable GOTIFY_PRIORITY)}\" if [ -z \"$GOTIFY_PRIORITY\" ]; then GOTIFY_PRIORITY=0 else _saveaccountconf_mutable GOTIFY_PRIORITY \"$GOTIFY_PRIORITY\" fi export _H1=\"X-Gotify-Key: ${GOTIFY_TOKEN}\" export _H2=\"Content-Type: application/json\" _content=$(echo \"$_content\" | _json_encode) _subject=$(echo \"$_subject\" | _json_encode) _data=\"{\\\"title\\\": \\\"${_subject}\\\", \\\"message\\\": \\\"${_content}\\\", \\\"priority\\\": ${GOTIFY_PRIORITY}}\" response=\"$(_post \"${_data}\" \"${GOTIFY_URL}/message\" \"\" \"POST\" \"application/json\")\" if [ \"$?\" != \"0\" ]; then _err \"Failed to send message\" _err \"$response\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_310.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_310.sh",
            "content": "#!/usr/bin/env sh #Support ifttt.com webhooks api #IFTTT_API_KEY=\"xxxx\" #IFTTT_EVENT_NAME=\"yyyy\" #IFTTT_SUBJECT_KEY=\"value1|value2|value3\" #optional, use \"value1\" as default #IFTTT_CONTENT_KEY=\"value1|value2|value3\" #optional, use \"value2\" as default _IFTTT_AVAIL_MSG_KEYS=\"value1,value2,value3\" # subject content statusCode ifttt_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_subject\" \"$_subject\" _debug \"_content\" \"$_content\" _debug \"_statusCode\" \"$_statusCode\" IFTTT_API_KEY=\"${IFTTT_API_KEY:-$(_readaccountconf_mutable IFTTT_API_KEY)}\" if [ -z \"$IFTTT_API_KEY\" ]; then IFTTT_API_KEY=\"\" _err \"You didn't specify a ifttt webhooks api key IFTTT_API_KEY yet.\" _err \"You can get yours from https://ifttt.com\" return 1 fi _saveaccountconf_mutable IFTTT_API_KEY \"$IFTTT_API_KEY\" IFTTT_EVENT_NAME=\"${IFTTT_EVENT_NAME:-$(_readaccountconf_mutable IFTTT_EVENT_NAME)}\" if [ -z \"$IFTTT_EVENT_NAME\" ]; then IFTTT_EVENT_NAME=\"\" _err \"You didn't specify a ifttt webhooks event name IFTTT_EVENT_NAME yet.\" return 1 fi _saveaccountconf_mutable IFTTT_EVENT_NAME \"$IFTTT_EVENT_NAME\" IFTTT_SUBJECT_KEY=\"${IFTTT_SUBJECT_KEY:-$(_readaccountconf_mutable IFTTT_SUBJECT_KEY)}\" if [ -z \"$IFTTT_SUBJECT_KEY\" ]; then IFTTT_SUBJECT_KEY=\"value1\" _info \"The IFTTT_SUBJECT_KEY is not set, so use the default value1 as key.\" elif ! _hasfield \"$_IFTTT_AVAIL_MSG_KEYS\" \"$IFTTT_SUBJECT_KEY\"; then _err \"The IFTTT_SUBJECT_KEY \\\"$IFTTT_SUBJECT_KEY\\\" is not available, should be one of $_IFTTT_AVAIL_MSG_KEYS\" IFTTT_SUBJECT_KEY=\"\" return 1 else _saveaccountconf_mutable IFTTT_SUBJECT_KEY \"$IFTTT_SUBJECT_KEY\" fi IFTTT_CONTENT_KEY=\"${IFTTT_CONTENT_KEY:-$(_readaccountconf_mutable IFTTT_CONTENT_KEY)}\" if [ -z \"$IFTTT_CONTENT_KEY\" ]; then IFTTT_CONTENT_KEY=\"value2\" _info \"The IFTTT_CONTENT_KEY is not set, so use the default value2 as key.\" elif ! _hasfield \"$_IFTTT_AVAIL_MSG_KEYS\" \"$IFTTT_CONTENT_KEY\"; then _err \"The IFTTT_CONTENT_KEY \\\"$IFTTT_CONTENT_KEY\\\" is not available, should be one of $_IFTTT_AVAIL_MSG_KEYS\" IFTTT_CONTENT_KEY=\"\" return 1 else _saveaccountconf_mutable IFTTT_CONTENT_KEY \"$IFTTT_CONTENT_KEY\" fi if [ \"$IFTTT_SUBJECT_KEY\" = \"$IFTTT_CONTENT_KEY\" ]; then IFTTT_SUBJECT_KEY=\"\" IFTTT_CONTENT_KEY=\"\" _err \"The IFTTT_SUBJECT_KEY must not be same as IFTTT_CONTENT_KEY.\" return 1 fi IFTTT_API_URL=\"https://maker.ifttt.com/trigger/$IFTTT_EVENT_NAME/with/key/$IFTTT_API_KEY\" _content=$(echo \"$_content\" | _json_encode) _subject=$(echo \"$_subject\" | _json_encode) _data=\"{\\\"$IFTTT_SUBJECT_KEY\\\": \\\"$_subject\\\", \\\"$IFTTT_CONTENT_KEY\\\": \\\"$_content\\\"}\" response=\"$(_post \"$_data\" \"$IFTTT_API_URL\" \"\" \"POST\" \"application/json\")\" if [ \"$?\" = \"0\" ] && _contains \"$response\" \"Congratulations\"; then _info \"IFTTT webhooks event fired success.\" return 0 fi _err \"IFTTT webhooks event fired error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_311.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_311.sh",
            "content": "#!/usr/bin/env sh #Support local mail app #MAIL_BIN=\"sendmail\" #MAIL_FROM=\"yyyy@gmail.com\" #MAIL_TO=\"yyyy@gmail.com\" #MAIL_NOVALIDATE=\"\" #MAIL_MSMTP_ACCOUNT=\"\" mail_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_subject\" \"$_subject\" _debug \"_content\" \"$_content\" _debug \"_statusCode\" \"$_statusCode\" MAIL_NOVALIDATE=\"${MAIL_NOVALIDATE:-$(_readaccountconf_mutable MAIL_NOVALIDATE)}\" if [ -n \"$MAIL_NOVALIDATE\" ]; then _saveaccountconf_mutable MAIL_NOVALIDATE 1 else _clearaccountconf \"MAIL_NOVALIDATE\" fi MAIL_BIN=\"${MAIL_BIN:-$(_readaccountconf_mutable MAIL_BIN)}\" if [ -n \"$MAIL_BIN\" ] && ! _exists \"$MAIL_BIN\"; then _err \"It seems that the command $MAIL_BIN is not in path.\" return 1 fi _MAIL_BIN=$(_mail_bin) if [ -n \"$MAIL_BIN\" ]; then _saveaccountconf_mutable MAIL_BIN \"$MAIL_BIN\" else _clearaccountconf \"MAIL_BIN\" fi MAIL_FROM=\"${MAIL_FROM:-$(_readaccountconf_mutable MAIL_FROM)}\" if [ -n \"$MAIL_FROM\" ]; then if ! _mail_valid \"$MAIL_FROM\"; then _err \"It seems that the MAIL_FROM=$MAIL_FROM is not a valid email address.\" return 1 fi _saveaccountconf_mutable MAIL_FROM \"$MAIL_FROM\" fi MAIL_TO=\"${MAIL_TO:-$(_readaccountconf_mutable MAIL_TO)}\" if [ -n \"$MAIL_TO\" ]; then if ! _mail_valid \"$MAIL_TO\"; then _err \"It seems that the MAIL_TO=$MAIL_TO is not a valid email address.\" return 1 fi _saveaccountconf_mutable MAIL_TO \"$MAIL_TO\" else MAIL_TO=\"$(_readaccountconf ACCOUNT_EMAIL)\" if [ -z \"$MAIL_TO\" ]; then _err \"It seems that account email is empty.\" return 1 fi fi contenttype=\"text/plain; charset=utf-8\" subject=\"=?UTF-8?B?$(printf -- \"%b\" \"$_subject\" | _base64)?=\" result=$({ _mail_body | eval \"$(_mail_cmnd)\"; } 2>&1) # shellcheck disable=SC2181 if [ $? -ne 0 ]; then _debug \"mail send error.\" _err \"$result\" return 1 fi _debug \"mail send success.\" return 0 } _mail_bin() { _MAIL_BIN=\"\" for b in $MAIL_BIN sendmail ssmtp mutt mail msmtp; do if _exists \"$b\"; then _MAIL_BIN=\"$b\" break fi done if [ -z \"$_MAIL_BIN\" ]; then _err \"Please install sendmail, ssmtp, mutt, mail or msmtp first.\" return 1 fi echo \"$_MAIL_BIN\" } _mail_cmnd() { _MAIL_ARGS=\"\" case $(basename \"$_MAIL_BIN\") in sendmail) if [ -n \"$MAIL_FROM\" ]; then _MAIL_ARGS=\"-f '$MAIL_FROM'\" fi ;; mutt | mail) _MAIL_ARGS=\"-s '$_subject'\" ;; msmtp) if [ -n \"$MAIL_FROM\" ]; then _MAIL_ARGS=\"-f '$MAIL_FROM'\" fi if [ -n \"$MAIL_MSMTP_ACCOUNT\" ]; then _MAIL_ARGS=\"$_MAIL_ARGS -a '$MAIL_MSMTP_ACCOUNT'\" fi ;; *) ;; esac echo \"'$_MAIL_BIN' $_MAIL_ARGS '$MAIL_TO'\" } _mail_body() { case $(basename \"$_MAIL_BIN\") in sendmail | ssmtp | msmtp) if [ -n \"$MAIL_FROM\" ]; then echo \"From: $MAIL_FROM\" fi echo \"To: $MAIL_TO\" echo \"Subject: $subject\" echo \"Content-Type: $contenttype\" echo \"MIME-Version: 1.0\" echo ;; esac echo \"$_content\" } _mail_valid() { [ -n \"$MAIL_NOVALIDATE\" ] || _contains \"$1\" \"@\" }"
        },
        {
            "filename": "file_312.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_312.sh",
            "content": "#!/usr/bin/env sh #Support mailgun.com api #MAILGUN_API_KEY=\"xxxx\" #MAILGUN_TO=\"yyyy@gmail.com\" #MAILGUN_REGION=\"us|eu\" #optional, use \"us\" as default #MAILGUN_API_DOMAIN=\"xxxxxx.com\" #optional, use the default sandbox domain #MAILGUN_FROM=\"xxx@xxxxx.com\" #optional, use the default sandbox account _MAILGUN_BASE_US=\"https://api.mailgun.net/v3\" _MAILGUN_BASE_EU=\"https://api.eu.mailgun.net/v3\" _MAILGUN_BASE=\"$_MAILGUN_BASE_US\" # subject content statusCode mailgun_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" MAILGUN_API_KEY=\"${MAILGUN_API_KEY:-$(_readaccountconf_mutable MAILGUN_API_KEY)}\" if [ -z \"$MAILGUN_API_KEY\" ]; then MAILGUN_API_KEY=\"\" _err \"You didn't specify a mailgun api key MAILGUN_API_KEY yet .\" _err \"You can get yours from here https://mailgun.com\" return 1 fi _saveaccountconf_mutable MAILGUN_API_KEY \"$MAILGUN_API_KEY\" MAILGUN_REGION=\"${MAILGUN_REGION:-$(_readaccountconf_mutable MAILGUN_REGION)}\" if [ -z \"$MAILGUN_REGION\" ]; then MAILGUN_REGION=\"\" _debug \"The MAILGUN_REGION is not set, so use the default us region.\" _MAILGUN_BASE=\"$_MAILGUN_BASE_US\" else MAILGUN_REGION=\"$(echo \"$MAILGUN_REGION\" | _lower_case)\" _saveaccountconf_mutable MAILGUN_REGION \"$MAILGUN_REGION\" if [ \"$MAILGUN_REGION\" = \"us\" ]; then _MAILGUN_BASE=\"$_MAILGUN_BASE_US\" else _MAILGUN_BASE=\"$_MAILGUN_BASE_EU\" fi fi _debug _MAILGUN_BASE \"$_MAILGUN_BASE\" MAILGUN_TO=\"${MAILGUN_TO:-$(_readaccountconf_mutable MAILGUN_TO)}\" if [ -z \"$MAILGUN_TO\" ]; then MAILGUN_TO=\"\" _err \"You didn't specify an email to MAILGUN_TO receive messages.\" return 1 fi _saveaccountconf_mutable MAILGUN_TO \"$MAILGUN_TO\" MAILGUN_API_DOMAIN=\"${MAILGUN_API_DOMAIN:-$(_readaccountconf_mutable MAILGUN_API_DOMAIN)}\" if [ -z \"$MAILGUN_API_DOMAIN\" ]; then _info \"The MAILGUN_API_DOMAIN is not set, try to get the default sending sandbox domain for you.\" if ! _mailgun_rest GET \"/domains\"; then _err \"Can not get sandbox domain.\" return 1 fi _sendboxDomain=\"$(echo \"$response\" | _egrep_o '\"name\": *\"sandbox.*.mailgun.org\"' | cut -d : -f 2 | tr -d '\" ')\" _debug _sendboxDomain \"$_sendboxDomain\" MAILGUN_API_DOMAIN=\"$_sendboxDomain\" if [ -z \"$MAILGUN_API_DOMAIN\" ]; then _err \"Can not get sandbox domain for MAILGUN_API_DOMAIN\" return 1 fi _info \"$(__green \"When using sandbox domain, you must verify your email first.\")\" #todo: add recepient fi if [ -z \"$MAILGUN_API_DOMAIN\" ]; then _err \"Can not get MAILGUN_API_DOMAIN\" return 1 fi _saveaccountconf_mutable MAILGUN_API_DOMAIN \"$MAILGUN_API_DOMAIN\" MAILGUN_FROM=\"${MAILGUN_FROM:-$(_readaccountconf_mutable MAILGUN_FROM)}\" if [ -z \"$MAILGUN_FROM\" ]; then MAILGUN_FROM=\"$PROJECT_NAME@$MAILGUN_API_DOMAIN\" _info \"The MAILGUN_FROM is not set, so use the default value: $MAILGUN_FROM\" else _debug MAILGUN_FROM \"$MAILGUN_FROM\" _saveaccountconf_mutable MAILGUN_FROM \"$MAILGUN_FROM\" fi #send from url _msg=\"/$MAILGUN_API_DOMAIN/messages?from=$(printf \"%s\" \"$MAILGUN_FROM\" | _url_encode)&to=$(printf \"%s\" \"$MAILGUN_TO\" | _url_encode)&subject=$(printf \"%s\" \"$_subject\" | _url_encode)&text=$(printf \"%s\" \"$_content\" | _url_encode)\" _debug \"_msg\" \"$_msg\" _mailgun_rest POST \"$_msg\" if _contains \"$response\" \"Queued. Thank you.\"; then _debug \"mailgun send success.\" return 0 else _err \"mailgun send error\" _err \"$response\" return 1 fi } # method uri data _mailgun_rest() { _method=\"$1\" _mguri=\"$2\" _mgdata=\"$3\" _debug _mguri \"$_mguri\" _mgurl=\"$_MAILGUN_BASE$_mguri\" _debug _mgurl \"$_mgurl\" _auth=\"$(printf \"%s\" \"api:$MAILGUN_API_KEY\" | _base64)\" export _H1=\"Authorization: Basic $_auth\" export _H2=\"Content-Type: application/json\" if [ \"$_method\" = \"GET\" ]; then response=\"$(_get \"$_mgurl\")\" else _debug _mgdata \"$_mgdata\" response=\"$(_post \"$_mgdata\" \"$_mgurl\" \"\" \"$_method\")\" fi if [ \"$?\" != \"0\" ]; then _err \"Error: $_mguri\" _err \"$response\" return 1 fi _debug2 response \"$response\" return 0 }"
        },
        {
            "filename": "file_313.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_313.sh",
            "content": "#!/usr/bin/env sh # Support mattermost bots #MATTERMOST_API_URL=\"\" #MATTERMOST_CHANNEL_ID=\"\" #MATTERMOST_BOT_TOKEN=\"\" mattermost_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" MATTERMOST_API_URL=\"${MATTERMOST_API_URL:-$(_readaccountconf_mutable MATTERMOST_API_URL)}\" if [ -z \"$MATTERMOST_API_URL\" ]; then _err \"You didn't specify a Mattermost API URL MATTERMOST_API_URL yet.\" return 1 fi _saveaccountconf_mutable MATTERMOST_API_URL \"$MATTERMOST_API_URL\" MATTERMOST_CHANNEL_ID=\"${MATTERMOST_CHANNEL_ID:-$(_readaccountconf_mutable MATTERMOST_CHANNEL_ID)}\" if [ -z \"$MATTERMOST_CHANNEL_ID\" ]; then _err \"You didn't specify a Mattermost channel id MATTERMOST_CHANNEL_ID yet.\" return 1 fi _saveaccountconf_mutable MATTERMOST_CHANNEL_ID \"$MATTERMOST_CHANNEL_ID\" MATTERMOST_BOT_TOKEN=\"${MATTERMOST_BOT_TOKEN:-$(_readaccountconf_mutable MATTERMOST_BOT_TOKEN)}\" if [ -z \"$MATTERMOST_BOT_TOKEN\" ]; then _err \"You didn't specify a Mattermost bot API token MATTERMOST_BOT_TOKEN yet.\" return 1 fi _saveaccountconf_mutable MATTERMOST_BOT_TOKEN \"$MATTERMOST_BOT_TOKEN\" _content=\"$(printf \"*%s*\\n%s\" \"$_subject\" \"$_content\" | _json_encode)\" _data=\"{\\\"channel_id\\\": \\\"$MATTERMOST_CHANNEL_ID\\\", \" _data=\"$_data\\\"message\\\": \\\"$_content\\\"}\" export _H1=\"Authorization: Bearer $MATTERMOST_BOT_TOKEN\" response=\"\" if _post \"$_data\" \"$MATTERMOST_API_URL\" \"\" \"POST\" \"application/json; charset=utf-8\"; then MATTERMOST_RESULT_OK=$(echo \"$response\" | _egrep_o 'create_at') if [ \"$?\" = \"0\" ] && [ \"$MATTERMOST_RESULT_OK\" ]; then _info \"mattermost send success.\" return 0 fi fi _err \"mattermost send error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_314.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_314.sh",
            "content": "#!/usr/bin/env sh # support ntfy #NTFY_URL=\"https://ntfy.sh\" #NTFY_TOPIC=\"xxxxxxxxxxxxx\" ntfy_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_subject\" \"$_subject\" _debug \"_content\" \"$_content\" _debug \"_statusCode\" \"$_statusCode\" NTFY_URL=\"${NTFY_URL:-$(_readaccountconf_mutable NTFY_URL)}\" if [ \"$NTFY_URL\" ]; then _saveaccountconf_mutable NTFY_URL \"$NTFY_URL\" fi NTFY_TOPIC=\"${NTFY_TOPIC:-$(_readaccountconf_mutable NTFY_TOPIC)}\" if [ \"$NTFY_TOPIC\" ]; then _saveaccountconf_mutable NTFY_TOPIC \"$NTFY_TOPIC\" fi _data=\"${_subject}. $_content\" response=\"$(_post \"$_data\" \"$NTFY_URL/$NTFY_TOPIC\" \"\" \"POST\" \"\")\" if [ \"$?\" = \"0\" ] && _contains \"$response\" \"expires\"; then _info \"ntfy event fired success.\" return 0 fi _err \"ntfy event fired error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_315.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_315.sh",
            "content": "#!/usr/bin/env sh # support pop pop_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_subject\" \"$_subject\" _debug \"_content\" \"$_content\" _debug \"_statusCode\" \"$_statusCode\" _err \"Not implemented yet.\" return 1 }"
        },
        {
            "filename": "file_316.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_316.sh",
            "content": "#!/usr/bin/env sh #Support postmarkapp.com API (https://postmarkapp.com/developer/user-guide/sending-email/sending-with-api) #POSTMARK_TOKEN=\"\" #POSTMARK_TO=\"xxxx@xxx.com\" #POSTMARK_FROM=\"xxxx@cccc.com\" postmark_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" POSTMARK_TOKEN=\"${POSTMARK_TOKEN:-$(_readaccountconf_mutable POSTMARK_TOKEN)}\" if [ -z \"$POSTMARK_TOKEN\" ]; then POSTMARK_TOKEN=\"\" _err \"You didn't specify a POSTMARK api token POSTMARK_TOKEN yet .\" _err \"You can get yours from here https://account.postmarkapp.com\" return 1 fi _saveaccountconf_mutable POSTMARK_TOKEN \"$POSTMARK_TOKEN\" POSTMARK_TO=\"${POSTMARK_TO:-$(_readaccountconf_mutable POSTMARK_TO)}\" if [ -z \"$POSTMARK_TO\" ]; then POSTMARK_TO=\"\" _err \"You didn't specify an email to POSTMARK_TO receive messages.\" return 1 fi _saveaccountconf_mutable POSTMARK_TO \"$POSTMARK_TO\" POSTMARK_FROM=\"${POSTMARK_FROM:-$(_readaccountconf_mutable POSTMARK_FROM)}\" if [ -z \"$POSTMARK_FROM\" ]; then POSTMARK_FROM=\"\" _err \"You didn't specify an email from POSTMARK_FROM receive messages.\" return 1 fi _saveaccountconf_mutable POSTMARK_FROM \"$POSTMARK_FROM\" export _H1=\"Accept: application/json\" export _H2=\"Content-Type: application/json\" export _H3=\"X-Postmark-Server-Token: $POSTMARK_TOKEN\" _content=\"$(echo \"$_content\" | _json_encode)\" _data=\"{\\\"To\\\": \\\"$POSTMARK_TO\\\", \\\"From\\\": \\\"$POSTMARK_FROM\\\", \\\"Subject\\\": \\\"$_subject\\\", \\\"TextBody\\\": \\\"$_content\\\"}\" if _post \"$_data\" \"https://api.postmarkapp.com/email\"; then # shellcheck disable=SC2154 _message=$(printf \"%s\\n\" \"$response\" | _lower_case | _egrep_o \"\\\"message\\\":\\\"[^\\\"]*\\\"\" | cut -d : -f 2 | tr -d \\\" | head -n 1) if [ \"$_message\" = \"ok\" ]; then _info \"postmark send success.\" return 0 fi fi _err \"postmark send error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_317.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_317.sh",
            "content": "#!/usr/bin/env sh #Support for pushbullet.com's api. Push notification, notification sync and message platform for multiple platforms #PUSHBULLET_TOKEN=\"\" Required, pushbullet application token #PUSHBULLET_DEVICE=\"\" Optional, Specific device, ignore to send to all devices PUSHBULLET_URI=\"https://api.pushbullet.com/v2/pushes\" pushbullet_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" PUSHBULLET_TOKEN=\"${PUSHBULLET_TOKEN:-$(_readaccountconf_mutable PUSHBULLET_TOKEN)}\" if [ -z \"$PUSHBULLET_TOKEN\" ]; then PUSHBULLET_TOKEN=\"\" _err \"You didn't specify a Pushbullet application token yet.\" return 1 fi _saveaccountconf_mutable PUSHBULLET_TOKEN \"$PUSHBULLET_TOKEN\" PUSHBULLET_DEVICE=\"${PUSHBULLET_DEVICE:-$(_readaccountconf_mutable PUSHBULLET_DEVICE)}\" if [ -z \"$PUSHBULLET_DEVICE\" ]; then _clearaccountconf_mutable PUSHBULLET_DEVICE else _saveaccountconf_mutable PUSHBULLET_DEVICE \"$PUSHBULLET_DEVICE\" fi export _H1=\"Content-Type: application/json\" export _H2=\"Access-Token: ${PUSHBULLET_TOKEN}\" _content=\"$(printf \"*%s*\\n\" \"$_content\" | _json_encode)\" _subject=\"$(printf \"*%s*\\n\" \"$_subject\" | _json_encode)\" _data=\"{\\\"type\\\": \\\"note\\\",\\\"title\\\": \\\"${_subject}\\\",\\\"body\\\": \\\"${_content}\\\",\\\"device_iden\\\": \\\"${PUSHBULLET_DEVICE}\\\"}\" response=\"$(_post \"$_data\" \"$PUSHBULLET_URI\")\" if [ \"$?\" != \"0\" ] || _contains \"$response\" \"\\\"error_code\\\"\"; then _err \"PUSHBULLET send error.\" _err \"$response\" return 1 fi _info \"PUSHBULLET send success.\" return 0 }"
        },
        {
            "filename": "file_318.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_318.sh",
            "content": "#!/usr/bin/env sh #Support for pushover.net's api. Push notification platform for multiple platforms #PUSHOVER_TOKEN=\"\" Required, pushover application token #PUSHOVER_USER=\"\" Required, pushover userkey #PUSHOVER_DEVICE=\"\" Optional, Specific device or devices by hostnames, joining multiples with a comma (such as device=iphone,nexus5) #PUSHOVER_PRIORITY=\"\" Optional, Lowest Priority (-2), Low Priority (-1), Normal Priority (0), High Priority (1) PUSHOVER_URI=\"https://api.pushover.net/1/messages.json\" pushover_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" PUSHOVER_TOKEN=\"${PUSHOVER_TOKEN:-$(_readaccountconf_mutable PUSHOVER_TOKEN)}\" if [ -z \"$PUSHOVER_TOKEN\" ]; then PUSHOVER_TOKEN=\"\" _err \"You didn't specify a PushOver application token yet.\" return 1 fi _saveaccountconf_mutable PUSHOVER_TOKEN \"$PUSHOVER_TOKEN\" PUSHOVER_USER=\"${PUSHOVER_USER:-$(_readaccountconf_mutable PUSHOVER_USER)}\" if [ -z \"$PUSHOVER_USER\" ]; then PUSHOVER_USER=\"\" _err \"You didn't specify a PushOver UserKey yet.\" return 1 fi _saveaccountconf_mutable PUSHOVER_USER \"$PUSHOVER_USER\" PUSHOVER_DEVICE=\"${PUSHOVER_DEVICE:-$(_readaccountconf_mutable PUSHOVER_DEVICE)}\" if [ \"$PUSHOVER_DEVICE\" ]; then _saveaccountconf_mutable PUSHOVER_DEVICE \"$PUSHOVER_DEVICE\" fi PUSHOVER_PRIORITY=\"${PUSHOVER_PRIORITY:-$(_readaccountconf_mutable PUSHOVER_PRIORITY)}\" if [ \"$PUSHOVER_PRIORITY\" ]; then _saveaccountconf_mutable PUSHOVER_PRIORITY \"$PUSHOVER_PRIORITY\" fi PUSHOVER_SOUND=\"${PUSHOVER_SOUND:-$(_readaccountconf_mutable PUSHOVER_SOUND)}\" if [ \"$PUSHOVER_SOUND\" ]; then _saveaccountconf_mutable PUSHOVER_SOUND \"$PUSHOVER_SOUND\" fi export _H1=\"Content-Type: application/json\" _content=\"$(printf \"*%s*\\n\" \"$_content\" | _json_encode)\" _subject=\"$(printf \"*%s*\\n\" \"$_subject\" | _json_encode)\" _data=\"{\\\"token\\\": \\\"$PUSHOVER_TOKEN\\\",\\\"user\\\": \\\"$PUSHOVER_USER\\\",\\\"title\\\": \\\"$_subject\\\",\\\"message\\\": \\\"$_content\\\",\\\"sound\\\": \\\"$PUSHOVER_SOUND\\\", \\\"device\\\": \\\"$PUSHOVER_DEVICE\\\", \\\"priority\\\": \\\"$PUSHOVER_PRIORITY\\\"}\" response=\"$(_post \"$_data\" \"$PUSHOVER_URI\")\" if [ \"$?\" = \"0\" ] && _contains \"$response\" \"{\\\"status\\\":1\"; then _info \"PUSHOVER send success.\" return 0 fi _err \"PUSHOVER send error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_319.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_319.sh",
            "content": "#!/usr/bin/env sh #Support SENDGRID.com api #SENDGRID_API_KEY=\"\" #SENDGRID_TO=\"xxxx@xxx.com\" #SENDGRID_FROM=\"xxxx@cccc.com\" sendgrid_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" SENDGRID_API_KEY=\"${SENDGRID_API_KEY:-$(_readaccountconf_mutable SENDGRID_API_KEY)}\" if [ -z \"$SENDGRID_API_KEY\" ]; then SENDGRID_API_KEY=\"\" _err \"You didn't specify a sendgrid api key SENDGRID_API_KEY yet .\" _err \"You can get yours from here https://sendgrid.com\" return 1 fi _saveaccountconf_mutable SENDGRID_API_KEY \"$SENDGRID_API_KEY\" SENDGRID_TO=\"${SENDGRID_TO:-$(_readaccountconf_mutable SENDGRID_TO)}\" if [ -z \"$SENDGRID_TO\" ]; then SENDGRID_TO=\"\" _err \"You didn't specify an email to SENDGRID_TO receive messages.\" return 1 fi _saveaccountconf_mutable SENDGRID_TO \"$SENDGRID_TO\" SENDGRID_FROM=\"${SENDGRID_FROM:-$(_readaccountconf_mutable SENDGRID_FROM)}\" if [ -z \"$SENDGRID_FROM\" ]; then SENDGRID_FROM=\"\" _err \"You didn't specify an email to SENDGRID_FROM receive messages.\" return 1 fi _saveaccountconf_mutable SENDGRID_FROM \"$SENDGRID_FROM\" SENDGRID_FROM_NAME=\"${SENDGRID_FROM_NAME:-$(_readaccountconf_mutable SENDGRID_FROM_NAME)}\" _saveaccountconf_mutable SENDGRID_FROM_NAME \"$SENDGRID_FROM_NAME\" export _H1=\"Authorization: Bearer $SENDGRID_API_KEY\" export _H2=\"Content-Type: application/json\" _content=\"$(echo \"$_content\" | _json_encode)\" if [ -z \"$SENDGRID_FROM_NAME\" ]; then _data=\"{\\\"personalizations\\\": [{\\\"to\\\": [{\\\"email\\\": \\\"$SENDGRID_TO\\\"}]}],\\\"from\\\": {\\\"email\\\": \\\"$SENDGRID_FROM\\\"},\\\"subject\\\": \\\"$_subject\\\",\\\"content\\\": [{\\\"type\\\": \\\"text/plain\\\", \\\"value\\\": \\\"$_content\\\"}]}\" else _data=\"{\\\"personalizations\\\": [{\\\"to\\\": [{\\\"email\\\": \\\"$SENDGRID_TO\\\"}]}],\\\"from\\\": {\\\"email\\\": \\\"$SENDGRID_FROM\\\", \\\"name\\\": \\\"$SENDGRID_FROM_NAME\\\"},\\\"subject\\\": \\\"$_subject\\\",\\\"content\\\": [{\\\"type\\\": \\\"text/plain\\\", \\\"value\\\": \\\"$_content\\\"}]}\" fi response=\"$(_post \"$_data\" \"https://api.sendgrid.com/v3/mail/send\")\" if [ \"$?\" = \"0\" ] && [ -z \"$response\" ]; then _info \"sendgrid send sccess.\" return 0 fi _err \"sendgrid send error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_320.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_320.sh",
            "content": "#!/usr/bin/env sh #Support Slack webhooks #SLACK_WEBHOOK_URL=\"\" #SLACK_CHANNEL=\"\" #SLACK_USERNAME=\"\" slack_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" SLACK_WEBHOOK_URL=\"${SLACK_WEBHOOK_URL:-$(_readaccountconf_mutable SLACK_WEBHOOK_URL)}\" if [ -z \"$SLACK_WEBHOOK_URL\" ]; then SLACK_WEBHOOK_URL=\"\" _err \"You didn't specify a Slack webhook url SLACK_WEBHOOK_URL yet.\" return 1 fi _saveaccountconf_mutable SLACK_WEBHOOK_URL \"$SLACK_WEBHOOK_URL\" SLACK_CHANNEL=\"${SLACK_CHANNEL:-$(_readaccountconf_mutable SLACK_CHANNEL)}\" if [ -n \"$SLACK_CHANNEL\" ]; then _saveaccountconf_mutable SLACK_CHANNEL \"$SLACK_CHANNEL\" fi SLACK_USERNAME=\"${SLACK_USERNAME:-$(_readaccountconf_mutable SLACK_USERNAME)}\" if [ -n \"$SLACK_USERNAME\" ]; then _saveaccountconf_mutable SLACK_USERNAME \"$SLACK_USERNAME\" fi export _H1=\"Content-Type: application/json\" _content=\"$(printf \"*%s*\\n%s\" \"$_subject\" \"$_content\" | _json_encode)\" _data=\"{\\\"text\\\": \\\"$_content\\\", \" if [ -n \"$SLACK_CHANNEL\" ]; then _data=\"$_data\\\"channel\\\": \\\"$SLACK_CHANNEL\\\", \" fi if [ -n \"$SLACK_USERNAME\" ]; then _data=\"$_data\\\"username\\\": \\\"$SLACK_USERNAME\\\", \" fi _data=\"$_data\\\"mrkdwn\\\": \\\"true\\\"}\" if _post \"$_data\" \"$SLACK_WEBHOOK_URL\"; then # shellcheck disable=SC2154 if [ \"$response\" = \"ok\" ]; then _info \"slack send success.\" return 0 fi fi _err \"slack send error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_321.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_321.sh",
            "content": "#!/usr/bin/env sh #Support Slack APP notifications #SLACK_APP_CHANNEL=\"\" #SLACK_APP_TOKEN=\"\" slack_app_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" SLACK_APP_CHANNEL=\"${SLACK_APP_CHANNEL:-$(_readaccountconf_mutable SLACK_APP_CHANNEL)}\" if [ -n \"$SLACK_APP_CHANNEL\" ]; then _saveaccountconf_mutable SLACK_APP_CHANNEL \"$SLACK_APP_CHANNEL\" fi SLACK_APP_TOKEN=\"${SLACK_APP_TOKEN:-$(_readaccountconf_mutable SLACK_APP_TOKEN)}\" if [ -n \"$SLACK_APP_TOKEN\" ]; then _saveaccountconf_mutable SLACK_APP_TOKEN \"$SLACK_APP_TOKEN\" fi _content=\"$(printf \"*%s*\\n%s\" \"$_subject\" \"$_content\" | _json_encode)\" _data=\"{\\\"text\\\": \\\"$_content\\\", \" if [ -n \"$SLACK_APP_CHANNEL\" ]; then _data=\"$_data\\\"channel\\\": \\\"$SLACK_APP_CHANNEL\\\", \" fi _data=\"$_data\\\"mrkdwn\\\": \\\"true\\\"}\" export _H1=\"Authorization: Bearer $SLACK_APP_TOKEN\" SLACK_APP_API_URL=\"https://slack.com/api/chat.postMessage\" if _post \"$_data\" \"$SLACK_APP_API_URL\" \"\" \"POST\" \"application/json; charset=utf-8\"; then # shellcheck disable=SC2154 SLACK_APP_RESULT_OK=$(echo \"$response\" | _egrep_o 'ok\" *: *true') if [ \"$?\" = \"0\" ] && [ \"$SLACK_APP_RESULT_OK\" ]; then _info \"slack send success.\" return 0 fi fi _err \"slack send error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_322.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_322.sh",
            "content": "#!/usr/bin/env sh # support smtp # Please report bugs to https://github.com/acmesh-official/acme.sh/issues/3358 # This implementation uses either curl or Python (3 or 2.7). # (See also the \"mail\" notify hook, which supports other ways to send mail.) # SMTP_FROM=\"from@example.com\" # required # SMTP_TO=\"to@example.com\" # required # SMTP_HOST=\"smtp.example.com\" # required # SMTP_PORT=\"25\" # defaults to 25, 465 or 587 depending on SMTP_SECURE # SMTP_SECURE=\"tls\" # one of \"none\", \"ssl\" (implicit TLS, TLS Wrapper), \"tls\" (explicit TLS, STARTTLS) # SMTP_USERNAME=\"\" # set if SMTP server requires login # SMTP_PASSWORD=\"\" # set if SMTP server requires login # SMTP_TIMEOUT=\"30\" # seconds for SMTP operations to timeout # SMTP_BIN=\"/path/to/python_or_curl\" # default finds first of python3, python2.7, python, pypy3, pypy, curl on PATH SMTP_SECURE_DEFAULT=\"tls\" SMTP_TIMEOUT_DEFAULT=\"30\" # subject content statuscode smtp_send() { SMTP_SUBJECT=\"$1\" SMTP_CONTENT=\"$2\" # UNUSED: _statusCode=\"$3\" # 0: success, 1: error 2($RENEW_SKIP): skipped # Load and validate config: SMTP_BIN=\"$(_readaccountconf_mutable_default SMTP_BIN)\" if [ -n \"$SMTP_BIN\" ] && ! _exists \"$SMTP_BIN\"; then _err \"SMTP_BIN '$SMTP_BIN' does not exist.\" return 1 fi if [ -z \"$SMTP_BIN\" ]; then # Look for a command that can communicate with an SMTP server. # (Please don't add sendmail, ssmtp, mutt, mail, or msmtp here. # Those are already handled by the \"mail\" notify hook.) for cmd in python3 python2.7 python pypy3 pypy curl; do if _exists \"$cmd\"; then SMTP_BIN=\"$cmd\" break fi done if [ -z \"$SMTP_BIN\" ]; then _err \"The smtp notify-hook requires curl or Python, but can't find any.\" _err 'If you have one of them, define SMTP_BIN=\"/path/to/curl_or_python\".' _err 'Otherwise, see if you can use the \"mail\" notify-hook instead.' return 1 fi fi _debug SMTP_BIN \"$SMTP_BIN\" _saveaccountconf_mutable_default SMTP_BIN \"$SMTP_BIN\" SMTP_FROM=\"$(_readaccountconf_mutable_default SMTP_FROM)\" SMTP_FROM=\"$(_clean_email_header \"$SMTP_FROM\")\" if [ -z \"$SMTP_FROM\" ]; then _err \"You must define SMTP_FROM as the sender email address.\" return 1 fi if _email_has_display_name \"$SMTP_FROM\"; then _err \"SMTP_FROM must be only a simple email address (sender@example.com).\" _err \"Change your SMTP_FROM='$SMTP_FROM' to remove the display name.\" return 1 fi _debug SMTP_FROM \"$SMTP_FROM\" _saveaccountconf_mutable_default SMTP_FROM \"$SMTP_FROM\" SMTP_TO=\"$(_readaccountconf_mutable_default SMTP_TO)\" SMTP_TO=\"$(_clean_email_header \"$SMTP_TO\")\" if [ -z \"$SMTP_TO\" ]; then _err \"You must define SMTP_TO as the recipient email address(es).\" return 1 fi if _email_has_display_name \"$SMTP_TO\"; then _err \"SMTP_TO must be only simple email addresses (to@example.com,to2@example.com).\" _err \"Change your SMTP_TO='$SMTP_TO' to remove the display name(s).\" return 1 fi _debug SMTP_TO \"$SMTP_TO\" _saveaccountconf_mutable_default SMTP_TO \"$SMTP_TO\" SMTP_HOST=\"$(_readaccountconf_mutable_default SMTP_HOST)\" if [ -z \"$SMTP_HOST\" ]; then _err \"You must define SMTP_HOST as the SMTP server hostname.\" return 1 fi _debug SMTP_HOST \"$SMTP_HOST\" _saveaccountconf_mutable_default SMTP_HOST \"$SMTP_HOST\" SMTP_SECURE=\"$(_readaccountconf_mutable_default SMTP_SECURE \"$SMTP_SECURE_DEFAULT\")\" case \"$SMTP_SECURE\" in \"none\") smtp_port_default=\"25\" ;; \"ssl\") smtp_port_default=\"465\" ;; \"tls\") smtp_port_default=\"587\" ;; *) _err \"Invalid SMTP_SECURE='$SMTP_SECURE'. It must be 'ssl', 'tls' or 'none'.\" return 1 ;; esac _debug SMTP_SECURE \"$SMTP_SECURE\" _saveaccountconf_mutable_default SMTP_SECURE \"$SMTP_SECURE\" \"$SMTP_SECURE_DEFAULT\" SMTP_PORT=\"$(_readaccountconf_mutable_default SMTP_PORT \"$smtp_port_default\")\" case \"$SMTP_PORT\" in *[!0-9]*) _err \"Invalid SMTP_PORT='$SMTP_PORT'. It must be a port number.\" return 1 ;; esac _debug SMTP_PORT \"$SMTP_PORT\" _saveaccountconf_mutable_default SMTP_PORT \"$SMTP_PORT\" \"$smtp_port_default\" SMTP_USERNAME=\"$(_readaccountconf_mutable_default SMTP_USERNAME)\" _debug SMTP_USERNAME \"$SMTP_USERNAME\" _saveaccountconf_mutable_default SMTP_USERNAME \"$SMTP_USERNAME\" SMTP_PASSWORD=\"$(_readaccountconf_mutable_default SMTP_PASSWORD)\" _secure_debug SMTP_PASSWORD \"$SMTP_PASSWORD\" _saveaccountconf_mutable_default SMTP_PASSWORD \"$SMTP_PASSWORD\" SMTP_TIMEOUT=\"$(_readaccountconf_mutable_default SMTP_TIMEOUT \"$SMTP_TIMEOUT_DEFAULT\")\" _debug SMTP_TIMEOUT \"$SMTP_TIMEOUT\" _saveaccountconf_mutable_default SMTP_TIMEOUT \"$SMTP_TIMEOUT\" \"$SMTP_TIMEOUT_DEFAULT\" SMTP_X_MAILER=\"$(_clean_email_header \"$PROJECT_NAME $VER --notify-hook smtp\")\" # Run with --debug 2 (or above) to echo the transcript of the SMTP session. # Careful: this may include SMTP_PASSWORD in plaintext! if [ \"${DEBUG:-$DEBUG_LEVEL_NONE}\" -ge \"$DEBUG_LEVEL_2\" ]; then SMTP_SHOW_TRANSCRIPT=\"True\" else SMTP_SHOW_TRANSCRIPT=\"\" fi SMTP_SUBJECT=$(_clean_email_header \"$SMTP_SUBJECT\") _debug SMTP_SUBJECT \"$SMTP_SUBJECT\" _debug SMTP_CONTENT \"$SMTP_CONTENT\" # Send the message: case \"$(basename \"$SMTP_BIN\")\" in curl) _smtp_send=_smtp_send_curl ;; py*) _smtp_send=_smtp_send_python ;; *) _err \"Can't figure out how to invoke '$SMTP_BIN'.\" _err \"Check your SMTP_BIN setting.\" return 1 ;; esac if ! smtp_output=\"$($_smtp_send)\"; then _err \"Error sending message with $SMTP_BIN.\" if [ -n \"$smtp_output\" ]; then _err \"$smtp_output\" fi return 1 fi return 0 } # Strip CR and NL from text to prevent MIME header injection # text _clean_email_header() { printf \"%s\" \"$(echo \"$1\" | tr -d \"\\r\\n\")\" } # Simple check for display name in an email address (< > or \") # email _email_has_display_name() { _email=\"$1\" echo \"$_email\" | grep -q -E '^.*[<>\"]' } ## ## curl smtp sending ## # Send the message via curl using SMTP_* variables _smtp_send_curl() { # Build curl args in $@ case \"$SMTP_SECURE\" in none) set -- --url \"smtp://${SMTP_HOST}:${SMTP_PORT}\" ;; ssl) set -- --url \"smtps://${SMTP_HOST}:${SMTP_PORT}\" ;; tls) set -- --url \"smtp://${SMTP_HOST}:${SMTP_PORT}\" --ssl-reqd ;; *) # This will only occur if someone adds a new SMTP_SECURE option above # without updating this code for it. _err \"Unhandled SMTP_SECURE='$SMTP_SECURE' in _smtp_send_curl\" _err \"Please re-run with --debug and report a bug.\" return 1 ;; esac set -- \"$@\" \\ --upload-file - \\ --mail-from \"$SMTP_FROM\" \\ --max-time \"$SMTP_TIMEOUT\" # Burst comma-separated $SMTP_TO into individual --mail-rcpt args. _to=\"${SMTP_TO},\" while [ -n \"$_to\" ]; do _rcpt=\"${_to%%,*}\" _to=\"${_to#*,}\" set -- \"$@\" --mail-rcpt \"$_rcpt\" done _smtp_login=\"${SMTP_USERNAME}:${SMTP_PASSWORD}\" if [ \"$_smtp_login\" != \":\" ]; then set -- \"$@\" --user \"$_smtp_login\" fi if [ \"$SMTP_SHOW_TRANSCRIPT\" = \"True\" ]; then set -- \"$@\" --verbose else set -- \"$@\" --silent --show-error fi raw_message=\"$(_smtp_raw_message)\" _debug2 \"curl command:\" \"$SMTP_BIN\" \"$*\" _debug2 \"raw_message:\\n$raw_message\" echo \"$raw_message\" | \"$SMTP_BIN\" \"$@\" } # Output an RFC-822 / RFC-5322 email message using SMTP_* variables. # (This assumes variables have already been cleaned for use in email headers.) _smtp_raw_message() { echo \"From: $SMTP_FROM\" echo \"To: $SMTP_TO\" echo \"Subject: $(_mime_encoded_word \"$SMTP_SUBJECT\")\" echo \"Date: $(_rfc2822_date)\" echo \"Content-Type: text/plain; charset=utf-8\" echo \"X-Mailer: $SMTP_X_MAILER\" echo echo \"$SMTP_CONTENT\" } # Convert text to RFC-2047 MIME \"encoded word\" format if it contains non-ASCII chars # text _mime_encoded_word() { _text=\"$1\" # (regex character ranges like [a-z] can be locale-dependent; enumerate ASCII chars to avoid that) _ascii='] $`\"'\"[!#%&'()*+,./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ~^_abcdefghijklmnopqrstuvwxyz{|}~-\" if echo \"$_text\" | grep -q -E \"^.*[^$_ascii]\"; then # At least one non-ASCII char; convert entire thing to encoded word printf \"%s\" \"=?UTF-8?B?$(printf \"%s\" \"$_text\" | _base64)?=\" else # Just printable ASCII, no conversion needed printf \"%s\" \"$_text\" fi } # Output current date in RFC-2822 Section 3.3 format as required in email headers # (e.g., \"Mon, 15 Feb 2021 14:22:01 -0800\") _rfc2822_date() { # Notes: # - this is deliberately not UTC, because it \"SHOULD express local time\" per spec # - the spec requires weekday and month in the C locale (English), not localized # - this date format specifier has been tested on Linux, Mac, Solaris and FreeBSD _old_lc_time=\"$LC_TIME\" LC_TIME=C date +'%a, %-d %b %Y %H:%M:%S %z' LC_TIME=\"$_old_lc_time\" } ## ## Python smtp sending ## # Send the message via Python using SMTP_* variables _smtp_send_python() { _debug \"Python version\" \"$(\"$SMTP_BIN\" --version 2>&1)\" # language=Python \"$SMTP_BIN\" <<PYTHON # This code is meant to work with either Python 2.7.x or Python 3.4+. try: try: from email.message import EmailMessage from email.policy import default as email_policy_default except ImportError: # Python 2 (or < 3.3) from email.mime.text import MIMEText as EmailMessage email_policy_default = None from email.utils import formatdate as rfc2822_date from smtplib import SMTP, SMTP_SSL, SMTPException from socket import error as SocketError except ImportError as err: print(\"A required Python standard package is missing. This system may have\" \" a reduced version of Python unsuitable for sending mail: %s\" % err) exit(1) show_transcript = \"\"\"$SMTP_SHOW_TRANSCRIPT\"\"\" == \"True\" smtp_host = \"\"\"$SMTP_HOST\"\"\" smtp_port = int(\"\"\"$SMTP_PORT\"\"\") smtp_secure = \"\"\"$SMTP_SECURE\"\"\" username = \"\"\"$SMTP_USERNAME\"\"\" password = \"\"\"$SMTP_PASSWORD\"\"\" timeout=int(\"\"\"$SMTP_TIMEOUT\"\"\") # seconds x_mailer=\"\"\"$SMTP_X_MAILER\"\"\" from_email=\"\"\"$SMTP_FROM\"\"\" to_emails=\"\"\"$SMTP_TO\"\"\" # can be comma-separated subject=\"\"\"$SMTP_SUBJECT\"\"\" content=\"\"\"$SMTP_CONTENT\"\"\" try: msg = EmailMessage(policy=email_policy_default) msg.set_content(content) except (AttributeError, TypeError): # Python 2 MIMEText msg = EmailMessage(content) msg[\"Subject\"] = subject msg[\"From\"] = from_email msg[\"To\"] = to_emails msg[\"Date\"] = rfc2822_date(localtime=True) msg[\"X-Mailer\"] = x_mailer smtp = None try: if smtp_secure == \"ssl\": smtp = SMTP_SSL(smtp_host, smtp_port, timeout=timeout) else: smtp = SMTP(smtp_host, smtp_port, timeout=timeout) smtp.set_debuglevel(show_transcript) if smtp_secure == \"tls\": smtp.starttls() if username or password: smtp.login(username, password) smtp.sendmail(msg[\"From\"], msg[\"To\"].split(\",\"), msg.as_string()) except SMTPException as err: # Output just the error (skip the Python stack trace) for SMTP errors print(\"Error sending: %r\" % err) exit(1) except SocketError as err: print(\"Error connecting to %s:%d: %r\" % (smtp_host, smtp_port, err)) exit(1) finally: if smtp is not None: smtp.quit() PYTHON } ## ## Conf helpers ## #_readaccountconf_mutable_default name default_value # Given a name like MY_CONF: # - if MY_CONF is set and non-empty, output $MY_CONF # - if MY_CONF is set _empty_, output $default_value # (lets user `export MY_CONF=` to clear previous saved value # and return to default, without user having to know default) # - otherwise if _readaccountconf_mutable MY_CONF is non-empty, return that # (value of SAVED_MY_CONF from account.conf) # - otherwise output $default_value _readaccountconf_mutable_default() { _name=\"$1\" _default_value=\"$2\" eval \"_value=\\\"\\$$_name\\\"\" eval \"_name_is_set=\\\"\\${${_name}+true}\\\"\" # ($_name_is_set is \"true\" if $$_name is set to anything, including empty) if [ -z \"${_value}\" ] && [ \"${_name_is_set:-}\" != \"true\" ]; then _value=\"$(_readaccountconf_mutable \"$_name\")\" fi if [ -z \"${_value}\" ]; then _value=\"$_default_value\" fi printf \"%s\" \"$_value\" } #_saveaccountconf_mutable_default name value default_value base64encode # Like _saveaccountconf_mutable, but if value is default_value # then _clearaccountconf_mutable instead _saveaccountconf_mutable_default() { _name=\"$1\" _value=\"$2\" _default_value=\"$3\" _base64encode=\"$4\" if [ \"$_value\" != \"$_default_value\" ]; then _saveaccountconf_mutable \"$_name\" \"$_value\" \"$_base64encode\" else _clearaccountconf_mutable \"$_name\" fi }"
        },
        {
            "filename": "file_323.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_323.sh",
            "content": "#!/usr/bin/env sh #Support Microsoft Teams webhooks #TEAMS_WEBHOOK_URL=\"\" teams_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" _color_success=\"Good\" _color_danger=\"Attention\" _color_muted=\"Accent\" TEAMS_WEBHOOK_URL=\"${TEAMS_WEBHOOK_URL:-$(_readaccountconf_mutable TEAMS_WEBHOOK_URL)}\" if [ -z \"$TEAMS_WEBHOOK_URL\" ]; then TEAMS_WEBHOOK_URL=\"\" _err \"You didn't specify a Microsoft Teams webhook url TEAMS_WEBHOOK_URL yet.\" return 1 fi _saveaccountconf_mutable TEAMS_WEBHOOK_URL \"$TEAMS_WEBHOOK_URL\" export _H1=\"Content-Type: application/json\" _subject=$(echo \"$_subject\" | _json_encode) _content=$(echo \"$_content\" | _json_encode) case \"$_statusCode\" in 0) _color=\"${TEAMS_SUCCESS_COLOR:-$_color_success}\" ;; 1) _color=\"${TEAMS_ERROR_COLOR:-$_color_danger}\" ;; 2) _color=\"${TEAMS_SKIP_COLOR:-$_color_muted}\" ;; esac _data=\"{ \\\"type\\\": \\\"message\\\", \\\"attachments\\\": [ { \\\"contentType\\\": \\\"application/vnd.microsoft.card.adaptive\\\", \\\"contentUrl\\\": null, \\\"content\\\": { \\\"schema\\\": \\\"http://adaptivecards.io/schemas/adaptive-card.json\\\", \\\"type\\\": \\\"AdaptiveCard\\\", \\\"version\\\": \\\"1.2\\\", \\\"body\\\": [ { \\\"type\\\": \\\"TextBlock\\\", \\\"size\\\": \\\"large\\\", \\\"weight\\\": \\\"bolder\\\", \\\"wrap\\\": true, \\\"color\\\": \\\"$_color\\\", \\\"text\\\": \\\"$_subject\\\" }, { \\\"type\\\": \\\"TextBlock\\\", \\\"text\\\": \\\"$_content\\\", \\\"wrap\\\": true } ] } } ] }\" if response=$(_post \"$_data\" \"$TEAMS_WEBHOOK_URL\"); then if ! _contains \"$response\" error; then _info \"teams send success.\" return 0 fi fi _err \"teams send error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_324.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_324.sh",
            "content": "#!/usr/bin/env sh #Support Telegram Bots #TELEGRAM_BOT_APITOKEN=\"\" #TELEGRAM_BOT_CHATID=\"\" telegram_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_statusCode\" \"$_statusCode\" TELEGRAM_BOT_APITOKEN=\"${TELEGRAM_BOT_APITOKEN:-$(_readaccountconf_mutable TELEGRAM_BOT_APITOKEN)}\" if [ -z \"$TELEGRAM_BOT_APITOKEN\" ]; then TELEGRAM_BOT_APITOKEN=\"\" _err \"You didn't specify a Telegram BOT API Token TELEGRAM_BOT_APITOKEN yet.\" return 1 fi _saveaccountconf_mutable TELEGRAM_BOT_APITOKEN \"$TELEGRAM_BOT_APITOKEN\" TELEGRAM_BOT_CHATID=\"${TELEGRAM_BOT_CHATID:-$(_readaccountconf_mutable TELEGRAM_BOT_CHATID)}\" if [ -z \"$TELEGRAM_BOT_CHATID\" ]; then TELEGRAM_BOT_CHATID=\"\" _err \"You didn't specify a Telegram Chat id TELEGRAM_BOT_CHATID yet.\" return 1 fi _saveaccountconf_mutable TELEGRAM_BOT_CHATID \"$TELEGRAM_BOT_CHATID\" _content=\"$(printf \"%s\" \"$_content\" | sed -e 's/\\([_*`\\[]\\)/\\\\\\\\\\1/g')\" _content=\"$(printf \"*%s*\\n%s\" \"$_subject\" \"$_content\" | _json_encode)\" _data=\"{\\\"text\\\": \\\"$_content\\\", \" _data=\"$_data\\\"chat_id\\\": \\\"$TELEGRAM_BOT_CHATID\\\", \" _data=\"$_data\\\"parse_mode\\\": \\\"markdown\\\", \" _data=\"$_data\\\"disable_web_page_preview\\\": \\\"1\\\"}\" _debug \"$_data\" export _H1=\"Content-Type: application/json\" _telegram_bot_url=\"https://api.telegram.org/bot${TELEGRAM_BOT_APITOKEN}/sendMessage\" if _post \"$_data\" \"$_telegram_bot_url\" >/dev/null; then # shellcheck disable=SC2154 _message=$(printf \"%s\\n\" \"$response\" | sed -n 's/.*\"ok\":\\([^,]*\\).*/\\1/p') if [ \"$_message\" = \"true\" ]; then _info \"telegram send success.\" return 0 fi fi _err \"telegram send error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_325.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_325.sh",
            "content": "#!/usr/bin/env sh #Support weixin work webhooks api #WEIXIN_WORK_WEBHOOK=\"xxxx\" #optional #WEIXIN_WORK_KEYWORD=\"yyyy\" #`WEIXIN_WORK_SIGNING_KEY`=\"SEC08ffdbd403cbc3fc8a65xxxxxxxxxxxxxxxxxxxx\" # subject content statusCode weixin_work_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_subject\" \"$_subject\" _debug \"_content\" \"$_content\" _debug \"_statusCode\" \"$_statusCode\" WEIXIN_WORK_WEBHOOK=\"${WEIXIN_WORK_WEBHOOK:-$(_readaccountconf_mutable WEIXIN_WORK_WEBHOOK)}\" if [ -z \"$WEIXIN_WORK_WEBHOOK\" ]; then WEIXIN_WORK_WEBHOOK=\"\" _err \"You didn't specify a weixin_work webhooks WEIXIN_WORK_WEBHOOK yet.\" _err \"You can get yours from https://work.weixin.qq.com/api/doc/90000/90136/91770\" return 1 fi _saveaccountconf_mutable WEIXIN_WORK_WEBHOOK \"$WEIXIN_WORK_WEBHOOK\" WEIXIN_WORK_KEYWORD=\"${WEIXIN_WORK_KEYWORD:-$(_readaccountconf_mutable WEIXIN_WORK_KEYWORD)}\" if [ \"$WEIXIN_WORK_KEYWORD\" ]; then _saveaccountconf_mutable WEIXIN_WORK_KEYWORD \"$WEIXIN_WORK_KEYWORD\" fi _content=$(echo \"$_content\" | _json_encode) _subject=$(echo \"$_subject\" | _json_encode) _data=\"{\\\"msgtype\\\": \\\"text\\\", \\\"text\\\": {\\\"content\\\": \\\"[$WEIXIN_WORK_KEYWORD]\\n$_subject\\n$_content\\\"}}\" response=\"$(_post \"$_data\" \"$WEIXIN_WORK_WEBHOOK\" \"\" \"POST\" \"application/json\")\" if [ \"$?\" = \"0\" ] && _contains \"$response\" \"errmsg\\\":\\\"ok\"; then _info \"weixin_work webhooks event fired success.\" return 0 fi _err \"weixin_work webhooks event fired error.\" _err \"$response\" return 1 }"
        },
        {
            "filename": "file_326.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\acme.sh\\notify\\file_326.sh",
            "content": "#!/usr/bin/env sh #Support xmpp via sendxmpp #XMPP_BIN=\"/usr/bin/sendxmpp\" #XMPP_BIN_ARGS=\"-n -t --tls-ca-path=/etc/ssl/certs\" #XMPP_TO=\"zzzz@example.com\" xmpp_send() { _subject=\"$1\" _content=\"$2\" _statusCode=\"$3\" #0: success, 1: error 2($RENEW_SKIP): skipped _debug \"_subject\" \"$_subject\" _debug \"_content\" \"$_content\" _debug \"_statusCode\" \"$_statusCode\" XMPP_BIN=\"${XMPP_BIN:-$(_readaccountconf_mutable XMPP_BIN)}\" if [ -n \"$XMPP_BIN\" ] && ! _exists \"$XMPP_BIN\"; then _err \"It seems that the command $XMPP_BIN is not in path.\" return 1 fi _XMPP_BIN=$(_xmpp_bin) if [ -n \"$XMPP_BIN\" ]; then _saveaccountconf_mutable XMPP_BIN \"$XMPP_BIN\" else _clearaccountconf \"XMPP_BIN\" fi XMPP_BIN_ARGS=\"${XMPP_BIN_ARGS:-$(_readaccountconf_mutable XMPP_BIN_ARGS)}\" if [ -n \"$XMPP_BIN_ARGS\" ]; then _saveaccountconf_mutable XMPP_BIN_ARGS \"$XMPP_BIN_ARGS\" else _clearaccountconf \"XMPP_BIN_ARGS\" fi XMPP_TO=\"${XMPP_TO:-$(_readaccountconf_mutable XMPP_TO)}\" if [ -n \"$XMPP_TO\" ]; then if ! _xmpp_valid \"$XMPP_TO\"; then _err \"It seems that the XMPP_TO=$XMPP_TO is not a valid xmpp address.\" return 1 fi _saveaccountconf_mutable XMPP_TO \"$XMPP_TO\" fi result=$({ _xmpp_message | eval \"$(_xmpp_cmnd)\"; } 2>&1) # shellcheck disable=SC2181 if [ $? -ne 0 ]; then _debug \"xmpp send error.\" _err \"$result\" return 1 fi _debug \"xmpp send success.\" return 0 } _xmpp_bin() { if [ -n \"$XMPP_BIN\" ]; then _XMPP_BIN=\"$XMPP_BIN\" elif _exists \"sendxmpp\"; then _XMPP_BIN=\"sendxmpp\" else _err \"Please install sendxmpp first.\" return 1 fi echo \"$_XMPP_BIN\" } _xmpp_cmnd() { case $(basename \"$_XMPP_BIN\") in sendxmpp) echo \"'$_XMPP_BIN' '$XMPP_TO' $XMPP_BIN_ARGS\" ;; *) _err \"Command $XMPP_BIN is not supported, use sendxmpp.\" return 1 ;; esac } _xmpp_message() { echo \"$_subject\" } _xmpp_valid() { _contains \"$1\" \"@\" }"
        },
        {
            "filename": "file_327.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\10. Input and Output Commands\\file_327.sh",
            "content": "#!/usr/bin/bash << mycom read -p \"Enter your name: \" my_name my_name_up=${my_name^^} echo \"Your name in upper-case is: $my_name_up\" mycom read -p \"Enter your name: \" echo \"$REPLY\""
        },
        {
            "filename": "file_328.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\10. Input and Output Commands\\file_328.sh",
            "content": "#!/usr/bin/bash << mycom echo \"$0\" echo \"$1\" echo \"$2\" echo \"$3\" echo \"${10}\" mycom echo \"The number command line arguments: $#\" echo \"All command line arguments are: $*\" echo \"All command line arguments are: $@\""
        },
        {
            "filename": "file_329.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\11.Arithemetic operators for Shell Scripting\\file_329.sh",
            "content": "#!/usr/bin/bash read -p \"Enter any number: \" num case $num in [0-9]) echo \"you enterd single number\" ;; [a-z]) echo \"you entered lower case alph\" ;; [A-Z]) echo \"you enterd upper case alph\" ;; *) echo \"Unable to identify your input\" ;; esac"
        },
        {
            "filename": "file_330.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\11.Arithemetic operators for Shell Scripting\\file_330.sh",
            "content": "#!/usr/bin/bash clear read -p \"Enter your file extention: \" ext case $ext in \".txt\") ls -lrt *.txt ;; \".sh\") ls -lrt *.sh ;; *) echo \"Sorry!. You entered invalid file extention\" ;; esac"
        },
        {
            "filename": "file_331.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\11.Arithemetic operators for Shell Scripting\\file_331.sh",
            "content": "#!/usr/bin/bash clear read -p \"Enter num-1: \" a read -p \"Enter num-2: \" b echo \"=========================\" echo \"Enter 1. Addition\" echo \" 2. Sub\" echo \" 3. Mul\" echo \" 4. Div\" echo \"=========================\" read -p \"Enter your option(1-4): \" opt case $opt in 1) echo \"The addition of $a and $b is: $((a+b))\" ;; 2) echo \"The sub of $a and $b is: $((a-b))\" ;; 3) echo \"The mul of $a and $b is: $((a*b))\" ;; 4) echo \"The div of $a with $b is: $((a/b))\" ;; *) echo \"Your entered invalid option\" ;; esac"
        },
        {
            "filename": "file_332.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\23.Real Time Practice (Low Level To High Level )\\file_332.sh",
            "content": "#!/bin/bash #Author: Narendra #Version: 1.0 COLUMNS=$(tput cols) get_date_time(){ echo $(date '+%d-%m-%Y %r') } prRed(){ echo -e \"\\033[91m$1 \\033[00m\" } prGreen(){ echo -e \"\\033[92m$1 \\033[00m\" } prYellow(){ echo -e \"\\033[93m$1 \\033[00m\" } prPurple(){ echo -e \"\\033[95m$1 \\033[00m\" } prCyan(){ echo -e \"\\033[96m$1 \\033[00m\" } prHeader(){ for each in $(seq 1 $COLUMNS) do echo -n $1 done } prtxtCentre(){ title=$1 printf \"%*s\\n\" $(((${#title}+$COLUMNS)/2)) \"$title\" } download_git_versions_info(){ GIT_VERS_URL=\"https://mirrors.edge.kernel.org/pub/software/scm/git/\" GIT_VERS_FILE=\"git_vers_info.html\" if [ -e \"${GIT_VERS_FILE}\" ] then prYellow \"$(get_date_time) Found old ${GIT_VERS_FILE}.Deleting this old file and downloading new content.Please wait...\" rm -rf ${GIT_VERS_FILE} else prGreen \"$(get_date_time) Downloading git vers info. Please wait...\" fi which wget 1>/dev/null 2>&1 if [ $? -ne 0 ] then prRed \"$(get_date_time) Sorry unable to download , wget command is not installed on this host. Please install it and retry\" exit 2 fi wget ${GIT_VERS_URL} --output-document=${GIT_VERS_FILE} 1>/dev/null 2>&1 if [ $? -ne 0 ] then prRed \"$(get_date_time) Unable to download. Please try the below command manually and verify\" prRed \"$(get_date_time) wget ${GIT_VERS_URL} --output-document=${GIT_VERS_FILE}\" else prGreen \"$(get_date_time) Successfully downloaded git vers info from git-scm and stored the info into a file: ${GIT_VERS_FILE}\" fi } diplay_all_available_git_versions(){ if [ ! -e ${GIT_VERS_FILE} ] then prRed \"$(get_date_time) Unable to find the ${GIT_VERS_FILE}\" fi prPurple \"$(get_date_time) Sorting git versions. Please wait...\" while read line do git_vers+=($(echo $line | sed -n '/git-\\([0-9]\\+\\.\\)\\+tar.gz/p'|awk -F '\"' '{ print $2 }'|cut -c 5- | awk -F '.tar.gz' '{ print $1}')) done < ${GIT_VERS_FILE} #echo ${#git_vers[@]} prHeader \"=\" prtxtCentre \"$(get_date_time) Displaying all available git versions\" cnt=0 no_vers=${#git_vers[*]} WIDTH=14 prHeader \"=\" for each_ver in ${git_vers[*]} do printf \"%-*s %-*s %-*s %-*s %-*s %-*s %-*s %-*s\\n\" $WIDTH ${git_vers[$cnt]} $WIDTH ${git_vers[$((cnt+1))]} $WIDTH ${git_vers[$((cnt+2))]} $WIDTH ${git_vers[$((cnt+3))]} $WIDTH ${git_vers[$((cnt+4))]} $WIDTH ${git_vers[$((cnt+5))]} $WIDTH ${git_vers[$((cnt+6))]} $WIDTH ${git_vers[$((cnt+7))]} cnt=$((cnt+8)) if [ $cnt -ge $no_vers ] then break fi done prHeader \"_\" } display_existing_git_info(){ which git 1>/dev/null 2>/dev/null if [ $? -ne 0 ] then prCyan \"$(get_date_time) select git version to install \" return 0 fi git_ver=$(git --version | awk '{ print $3}') prCyan \"$(get_date_time) The existing git version: $git_ver\" return 1 } get_git_install_location(){ which git 1>/dev/null 2>&1 if [ $? -eq 0 ] then git_path=$(dirname $(which git)) mv $git_path/git $git_path/git_bkp echo $git_path else echo '/usr/local' fi } install_update_git(){ req_git=$1 git_loc=$(get_git_install_location) url_for_req_git=\"https://mirrors.edge.kernel.org/pub/software/scm/git/git-${req_git}.tar.gz\" echo \"$(get_date_time): Downloading --> $url_for_req_git\" if [ ! -e \"git-${req_git}.tar.gz\" ] then wget $url_for_req_git fi echo \"$(get_date_time): Extracting git-${req_git}.tar.gz....\" if [ ! -e git-${req_git} ] then tar -xvzf git-${req_git}.tar.gz fi which gcc 1>/dev/null 2>/dev/null || yum install gcc -y cd git-${req_git}; ./configure ; make ; make install } display_current_git(){ which git 1>/dev/null 2>&1 if [ $? -eq 0 ] then prPurple \"$(get_date_time): Now the Git on host is: $(git --version)\" else prYellow \"Unable to install ur required git.\" if [ -e \"$git_path/git_bkp\" ] then $git_path/git_bkp $git_path/git fi fi } main() { clear prHeader \"=\" prtxtCentre \"Welcome to Automate Git installation using shell script\" prHeader \"=\" prCyan \"$(get_date_time) Checking all available git versions from official git-scm websites. Please wait....\" download_git_versions_info diplay_all_available_git_versions display_existing_git_info if [ $? -eq 0 ] then read -p \"$(get_date_time) Enter your required git version to install: \" GIT_TO_INSTALL install_update_git $GIT_TO_INSTALL display_current_git else read -e -i no -p \"$(get_date_time) Do you want to update/downgrade git ? (yes/no)\" GIT_CNF GIT_CNF=${GIT_CNF,,} #echo $GIT_CNF if [ \"${GIT_CNF}\" == \"yes\" ] then read -e -i ${git_ver} -p \"$(get_date_time) Enter your required git version to update: \" GIT_TO_INSTALL if [ \"${GIT_TO_INSTALL}\" == \"${git_ver}\" ] then prRed \"$(get_date_time) Thank you for using $0 script\" prHeader \"=\" exit 0 fi if [ \"${GIT_TO_INSTALL}\" \\< \"${git_ver}\" ] then prGreen \"$(get_date_time) Downgrading existing git ${git_ver} to required git ${GIT_TO_INSTALL}. Please wait...\" install_update_git $GIT_TO_INSTALL display_current_git prHeader \"=\" exit 0 else prGreen \"$(get_date_time) Updating existing git ${git_ver} to required git ${GIT_TO_INSTALL}. Please wait...\" install_update_git $GIT_TO_INSTALL display_current_git prHeader \"=\" exit 0 fi else prGreen \"$(get_date_time) Thank you for using $0 script\" fi fi } if [ $USER != \"root\" ] then prRed \"$(get_date_time) :Please run this script from root user\" exit 1 else main fi"
        },
        {
            "filename": "file_333.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\Additional Resources\\file_333.sh",
            "content": "#!/usr/bin/bash << mycom read -p \"Enter your name: \" my_name my_name_up=${my_name^^} echo \"Your name in upper-case is: $my_name_up\" mycom read -p \"Enter your name: \" echo \"$REPLY\""
        },
        {
            "filename": "file_334.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\Additional Resources\\file_334.sh",
            "content": "#!/usr/bin/bash read -p \"Enter any number: \" num case $num in [0-9]) echo \"you enterd single number\" ;; [a-z]) echo \"you entered lower case alph\" ;; [A-Z]) echo \"you enterd upper case alph\" ;; *) echo \"Unable to identify your input\" ;; esac"
        },
        {
            "filename": "file_335.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\Additional Resources\\file_335.sh",
            "content": "#!/usr/bin/bash clear read -p \"Enter your file extention: \" ext case $ext in \".txt\") ls -lrt *.txt ;; \".sh\") ls -lrt *.sh ;; *) echo \"Sorry!. You entered invalid file extention\" ;; esac"
        },
        {
            "filename": "file_336.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\Additional Resources\\file_336.sh",
            "content": "#!/usr/bin/bash clear read -p \"Enter num-1: \" a read -p \"Enter num-2: \" b echo \"=========================\" echo \"Enter 1. Addition\" echo \" 2. Sub\" echo \" 3. Mul\" echo \" 4. Div\" echo \"=========================\" read -p \"Enter your option(1-4): \" opt case $opt in 1) echo \"The addition of $a and $b is: $((a+b))\" ;; 2) echo \"The sub of $a and $b is: $((a-b))\" ;; 3) echo \"The mul of $a and $b is: $((a*b))\" ;; 4) echo \"The div of $a with $b is: $((a/b))\" ;; *) echo \"Your entered invalid option\" ;; esac"
        },
        {
            "filename": "file_337.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\Additional Resources\\file_337.sh",
            "content": "#!/usr/bin/bash << mycom echo \"$0\" echo \"$1\" echo \"$2\" echo \"$3\" echo \"${10}\" mycom echo \"The number command line arguments: $#\" echo \"All command line arguments are: $*\" echo \"All command line arguments are: $@\""
        },
        {
            "filename": "file_338.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Complete-Bash-Shell-Scripting-\\Additional Resources\\file_338.sh",
            "content": "#!/bin/bash #Author: Narendra #Version: 1.0 COLUMNS=$(tput cols) get_date_time(){ echo $(date '+%d-%m-%Y %r') } prRed(){ echo -e \"\\033[91m$1 \\033[00m\" } prGreen(){ echo -e \"\\033[92m$1 \\033[00m\" } prYellow(){ echo -e \"\\033[93m$1 \\033[00m\" } prPurple(){ echo -e \"\\033[95m$1 \\033[00m\" } prCyan(){ echo -e \"\\033[96m$1 \\033[00m\" } prHeader(){ for each in $(seq 1 $COLUMNS) do echo -n $1 done } prtxtCentre(){ title=$1 printf \"%*s\\n\" $(((${#title}+$COLUMNS)/2)) \"$title\" } download_git_versions_info(){ GIT_VERS_URL=\"https://mirrors.edge.kernel.org/pub/software/scm/git/\" GIT_VERS_FILE=\"git_vers_info.html\" if [ -e \"${GIT_VERS_FILE}\" ] then prYellow \"$(get_date_time) Found old ${GIT_VERS_FILE}.Deleting this old file and downloading new content.Please wait...\" rm -rf ${GIT_VERS_FILE} else prGreen \"$(get_date_time) Downloading git vers info. Please wait...\" fi which wget 1>/dev/null 2>&1 if [ $? -ne 0 ] then prRed \"$(get_date_time) Sorry unable to download , wget command is not installed on this host. Please install it and retry\" exit 2 fi wget ${GIT_VERS_URL} --output-document=${GIT_VERS_FILE} 1>/dev/null 2>&1 if [ $? -ne 0 ] then prRed \"$(get_date_time) Unable to download. Please try the below command manually and verify\" prRed \"$(get_date_time) wget ${GIT_VERS_URL} --output-document=${GIT_VERS_FILE}\" else prGreen \"$(get_date_time) Successfully downloaded git vers info from git-scm and stored the info into a file: ${GIT_VERS_FILE}\" fi } diplay_all_available_git_versions(){ if [ ! -e ${GIT_VERS_FILE} ] then prRed \"$(get_date_time) Unable to find the ${GIT_VERS_FILE}\" fi prPurple \"$(get_date_time) Sorting git versions. Please wait...\" while read line do git_vers+=($(echo $line | sed -n '/git-\\([0-9]\\+\\.\\)\\+tar.gz/p'|awk -F '\"' '{ print $2 }'|cut -c 5- | awk -F '.tar.gz' '{ print $1}')) done < ${GIT_VERS_FILE} #echo ${#git_vers[@]} prHeader \"=\" prtxtCentre \"$(get_date_time) Displaying all available git versions\" cnt=0 no_vers=${#git_vers[*]} WIDTH=14 prHeader \"=\" for each_ver in ${git_vers[*]} do printf \"%-*s %-*s %-*s %-*s %-*s %-*s %-*s %-*s\\n\" $WIDTH ${git_vers[$cnt]} $WIDTH ${git_vers[$((cnt+1))]} $WIDTH ${git_vers[$((cnt+2))]} $WIDTH ${git_vers[$((cnt+3))]} $WIDTH ${git_vers[$((cnt+4))]} $WIDTH ${git_vers[$((cnt+5))]} $WIDTH ${git_vers[$((cnt+6))]} $WIDTH ${git_vers[$((cnt+7))]} cnt=$((cnt+8)) if [ $cnt -ge $no_vers ] then break fi done prHeader \"_\" } display_existing_git_info(){ which git 1>/dev/null 2>/dev/null if [ $? -ne 0 ] then prCyan \"$(get_date_time) select git version to install \" return 0 fi git_ver=$(git --version | awk '{ print $3}') prCyan \"$(get_date_time) The existing git version: $git_ver\" return 1 } get_git_install_location(){ which git 1>/dev/null 2>&1 if [ $? -eq 0 ] then git_path=$(dirname $(which git)) mv $git_path/git $git_path/git_bkp echo $git_path else echo '/usr/local' fi } install_update_git(){ req_git=$1 git_loc=$(get_git_install_location) url_for_req_git=\"https://mirrors.edge.kernel.org/pub/software/scm/git/git-${req_git}.tar.gz\" echo \"$(get_date_time): Downloading --> $url_for_req_git\" if [ ! -e \"git-${req_git}.tar.gz\" ] then wget $url_for_req_git fi echo \"$(get_date_time): Extracting git-${req_git}.tar.gz....\" if [ ! -e git-${req_git} ] then tar -xvzf git-${req_git}.tar.gz fi which gcc 1>/dev/null 2>/dev/null || yum install gcc -y cd git-${req_git}; ./configure ; make ; make install } display_current_git(){ which git 1>/dev/null 2>&1 if [ $? -eq 0 ] then prPurple \"$(get_date_time): Now the Git on host is: $(git --version)\" else prYellow \"Unable to install ur required git.\" if [ -e \"$git_path/git_bkp\" ] then $git_path/git_bkp $git_path/git fi fi } main() { clear prHeader \"=\" prtxtCentre \"Welcome to Automate Git installation using shell script\" prHeader \"=\" prCyan \"$(get_date_time) Checking all available git versions from official git-scm websites. Please wait....\" download_git_versions_info diplay_all_available_git_versions display_existing_git_info if [ $? -eq 0 ] then read -p \"$(get_date_time) Enter your required git version to install: \" GIT_TO_INSTALL install_update_git $GIT_TO_INSTALL display_current_git else read -e -i no -p \"$(get_date_time) Do you want to update/downgrade git ? (yes/no)\" GIT_CNF GIT_CNF=${GIT_CNF,,} #echo $GIT_CNF if [ \"${GIT_CNF}\" == \"yes\" ] then read -e -i ${git_ver} -p \"$(get_date_time) Enter your required git version to update: \" GIT_TO_INSTALL if [ \"${GIT_TO_INSTALL}\" == \"${git_ver}\" ] then prRed \"$(get_date_time) Thank you for using $0 script\" prHeader \"=\" exit 0 fi if [ \"${GIT_TO_INSTALL}\" \\< \"${git_ver}\" ] then prGreen \"$(get_date_time) Downgrading existing git ${git_ver} to required git ${GIT_TO_INSTALL}. Please wait...\" install_update_git $GIT_TO_INSTALL display_current_git prHeader \"=\" exit 0 else prGreen \"$(get_date_time) Updating existing git ${git_ver} to required git ${GIT_TO_INSTALL}. Please wait...\" install_update_git $GIT_TO_INSTALL display_current_git prHeader \"=\" exit 0 fi else prGreen \"$(get_date_time) Thank you for using $0 script\" fi fi } if [ $USER != \"root\" ] then prRed \"$(get_date_time) :Please run this script from root user\" exit 1 else main fi"
        },
        {
            "filename": "file_339.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\dehydrated\\docs\\examples\\file_339.sh",
            "content": "#!/usr/bin/env bash deploy_challenge() { local DOMAIN=\"${1}\" TOKEN_FILENAME=\"${2}\" TOKEN_VALUE=\"${3}\" # This hook is called once for every domain that needs to be # validated, including any alternative names you may have listed. # # Parameters: # - DOMAIN # The domain name (CN or subject alternative name) being # validated. # - TOKEN_FILENAME # The name of the file containing the token to be served for HTTP # validation. Should be served by your web server as # /.well-known/acme-challenge/${TOKEN_FILENAME}. # - TOKEN_VALUE # The token value that needs to be served for validation. For DNS # validation, this is what you want to put in the _acme-challenge # TXT record. For HTTP validation it is the value that is expected # be found in the $TOKEN_FILENAME file. # Simple example: Use nsupdate with local named # printf 'server 127.0.0.1\\nupdate add _acme-challenge.%s 300 IN TXT \"%s\"\\nsend\\n' \"${DOMAIN}\" \"${TOKEN_VALUE}\" | nsupdate -k /var/run/named/session.key } clean_challenge() { local DOMAIN=\"${1}\" TOKEN_FILENAME=\"${2}\" TOKEN_VALUE=\"${3}\" # This hook is called after attempting to validate each domain, # whether or not validation was successful. Here you can delete # files or DNS records that are no longer needed. # # The parameters are the same as for deploy_challenge. # Simple example: Use nsupdate with local named # printf 'server 127.0.0.1\\nupdate delete _acme-challenge.%s TXT \"%s\"\\nsend\\n' \"${DOMAIN}\" \"${TOKEN_VALUE}\" | nsupdate -k /var/run/named/session.key } sync_cert() { local KEYFILE=\"${1}\" CERTFILE=\"${2}\" FULLCHAINFILE=\"${3}\" CHAINFILE=\"${4}\" REQUESTFILE=\"${5}\" # This hook is called after the certificates have been created but before # they are symlinked. This allows you to sync the files to disk to prevent # creating a symlink to empty files on unexpected system crashes. # # This hook is not intended to be used for further processing of certificate # files, see deploy_cert for that. # # Parameters: # - KEYFILE # The path of the file containing the private key. # - CERTFILE # The path of the file containing the signed certificate. # - FULLCHAINFILE # The path of the file containing the full certificate chain. # - CHAINFILE # The path of the file containing the intermediate certificate(s). # - REQUESTFILE # The path of the file containing the certificate signing request. # Simple example: sync the files before symlinking them # sync \"${KEYFILE}\" \"${CERTFILE}\" \"${FULLCHAINFILE}\" \"${CHAINFILE}\" \"${REQUESTFILE}\" } deploy_cert() { local DOMAIN=\"${1}\" KEYFILE=\"${2}\" CERTFILE=\"${3}\" FULLCHAINFILE=\"${4}\" CHAINFILE=\"${5}\" TIMESTAMP=\"${6}\" # This hook is called once for each certificate that has been # produced. Here you might, for instance, copy your new certificates # to service-specific locations and reload the service. # # Parameters: # - DOMAIN # The primary domain name, i.e. the certificate common # name (CN). # - KEYFILE # The path of the file containing the private key. # - CERTFILE # The path of the file containing the signed certificate. # - FULLCHAINFILE # The path of the file containing the full certificate chain. # - CHAINFILE # The path of the file containing the intermediate certificate(s). # - TIMESTAMP # Timestamp when the specified certificate was created. # Simple example: Copy file to nginx config # cp \"${KEYFILE}\" \"${FULLCHAINFILE}\" /etc/nginx/ssl/; chown -R nginx: /etc/nginx/ssl # systemctl reload nginx } deploy_ocsp() { local DOMAIN=\"${1}\" OCSPFILE=\"${2}\" TIMESTAMP=\"${3}\" # This hook is called once for each updated ocsp stapling file that has # been produced. Here you might, for instance, copy your new ocsp stapling # files to service-specific locations and reload the service. # # Parameters: # - DOMAIN # The primary domain name, i.e. the certificate common # name (CN). # - OCSPFILE # The path of the ocsp stapling file # - TIMESTAMP # Timestamp when the specified ocsp stapling file was created. # Simple example: Copy file to nginx config # cp \"${OCSPFILE}\" /etc/nginx/ssl/; chown -R nginx: /etc/nginx/ssl # systemctl reload nginx } unchanged_cert() { local DOMAIN=\"${1}\" KEYFILE=\"${2}\" CERTFILE=\"${3}\" FULLCHAINFILE=\"${4}\" CHAINFILE=\"${5}\" # This hook is called once for each certificate that is still # valid and therefore wasn't reissued. # # Parameters: # - DOMAIN # The primary domain name, i.e. the certificate common # name (CN). # - KEYFILE # The path of the file containing the private key. # - CERTFILE # The path of the file containing the signed certificate. # - FULLCHAINFILE # The path of the file containing the full certificate chain. # - CHAINFILE # The path of the file containing the intermediate certificate(s). } invalid_challenge() { local DOMAIN=\"${1}\" RESPONSE=\"${2}\" # This hook is called if the challenge response has failed, so domain # owners can be aware and act accordingly. # # Parameters: # - DOMAIN # The primary domain name, i.e. the certificate common # name (CN). # - RESPONSE # The response that the verification server returned # Simple example: Send mail to root # printf \"Subject: Validation of ${DOMAIN} failed!\\n\\nOh noez!\" | sendmail root } request_failure() { local STATUSCODE=\"${1}\" REASON=\"${2}\" REQTYPE=\"${3}\" HEADERS=\"${4}\" # This hook is called when an HTTP request fails (e.g., when the ACME # server is busy, returns an error, etc). It will be called upon any # response code that does not start with '2'. Useful to alert admins # about problems with requests. # # Parameters: # - STATUSCODE # The HTML status code that originated the error. # - REASON # The specified reason for the error. # - REQTYPE # The kind of request that was made (GET, POST...) # - HEADERS # HTTP headers returned by the CA # Simple example: Send mail to root # printf \"Subject: HTTP request failed failed!\\n\\nA http request failed with status ${STATUSCODE}!\" | sendmail root } generate_csr() { local DOMAIN=\"${1}\" CERTDIR=\"${2}\" ALTNAMES=\"${3}\" # This hook is called before any certificate signing operation takes place. # It can be used to generate or fetch a certificate signing request with external # tools. # The output should be just the certificate signing request formatted as PEM. # # Parameters: # - DOMAIN # The primary domain as specified in domains.txt. This does not need to # match with the domains in the CSR, it's basically just the directory name. # - CERTDIR # Certificate output directory for this particular certificate. Can be used # for storing additional files. # - ALTNAMES # All domain names for the current certificate as specified in domains.txt. # Again, this doesn't need to match with the CSR, it's just there for convenience. # Simple example: Look for pre-generated CSRs # if [ -e \"${CERTDIR}/pre-generated.csr\" ]; then # cat \"${CERTDIR}/pre-generated.csr\" # fi } startup_hook() { # This hook is called before the cron command to do some initial tasks # (e.g. starting a webserver). : } exit_hook() { local ERROR=\"${1:-}\" # This hook is called at the end of the cron command and can be used to # do some final (cleanup or other) tasks. # # Parameters: # - ERROR # Contains error message if dehydrated exits with error } HANDLER=\"$1\"; shift if [[ \"${HANDLER}\" =~ ^(deploy_challenge|clean_challenge|sync_cert|deploy_cert|deploy_ocsp|unchanged_cert|invalid_challenge|request_failure|generate_csr|startup_hook|exit_hook)$ ]]; then \"$HANDLER\" \"$@\" fi"
        },
        {
            "filename": "file_340.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\elvish\\tools\\file_340.sh",
            "content": "#!/bin/sh # Check Go source files for disallowed content. ret=0 # We have our own trimmed-down copy of net/rpc to reduce binary size. Make sure # that dependency on net/rpc is not accidentally introduced. x=$(find . -name '*.go' | xargs grep '\"net/rpc\"') if test \"$x\" != \"\"; then echo \"======================================================================\" echo 'Disallowed import of net/rpc:' echo \"======================================================================\" echo \"$x\" ret=1 fi # The correct functioning of the unix: module depends on some certain calls not # being made elsewhere. x=$(find . -name '*.go' | egrep -v '\\./pkg/(mods/unix|daemon|testutil)' | xargs egrep 'unix\\.(Umask|Getrlimit|Setrlimit)') if test \"$x\" != \"\"; then echo \"======================================================================\" echo 'Disallowed call of unix.{Umask,Getrlimit,Setrlimit}:' echo \"======================================================================\" echo \"$x\" ret=1 fi # doc:show depends on references to language.html to not have a ./ prefix. x=$(find . -name '*.elv' | xargs grep '(\\.\\/language\\.html') if test \"$x\" != \"\"; then echo \"======================================================================\" echo 'Disallowed use of ./ in link destination to language.html' echo \"======================================================================\" echo \"$x\" ret=1 fi exit $ret"
        },
        {
            "filename": "file_341.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\elvish\\tools\\file_341.sh",
            "content": "#!/bin/sh -e # Check if Go files are properly formatted without modifying them. echo 'Go files need these changes:' # The grep is needed because `goimports -d` and `gofmt -d` always exits with 0. if find . -name '*.go' | xargs goimports -d | grep .; then exit 1 fi if find . -name '*.go' | xargs gofmt -s -d | grep .; then exit 1 fi echo ' None!'"
        },
        {
            "filename": "file_342.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\elvish\\tools\\file_342.sh",
            "content": "#!/bin/sh -e # Check if Markdown files are properly formatted without modifying them. echo 'Markdown files that need changes:' if find . -name '*.md' | grep -v '/node_modules/' | xargs go run src.elv.sh/cmd/elvmdfmt -width 80 -d | grep .; then exit 1 fi echo ' None!'"
        },
        {
            "filename": "file_343.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\elvish\\tools\\file_343.sh",
            "content": "#!/bin/sh # Check that generated Go source files are up to date. git_unstaged() { # The output of \"git status -s\" starts with two letters XY, where Y is the # status in the working tree. Files that are staged in the index have Y # being a space; exclude them. git status -s | grep '^.[^ ]' } if ! which git >/dev/null; then echo \"$0 requires Git\" exit 1 fi if test \"$(git_unstaged)\" != \"\"; then echo \"$0 must be run from a Git repo with no unstaged changes or untracked files\" exit 1 fi go generate ./... || exit 1 x=$(git_unstaged) if test \"$x\" != \"\"; then echo \"======================================================================\" echo \"Generated Go code is out of date. See\" echo \"https://github.com/elves/elvish/blob/master/CONTRIBUTING.md#generated-code\" echo \"======================================================================\" echo \"$x\" exit 1 fi"
        },
        {
            "filename": "file_344.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\elvish\\tools\\file_344.sh",
            "content": "#!/bin/sh -e # Prune the same objects from the \"make cover\" report that we tell Codecov # (https://codecov.io/gh/elves/elvish/) to ignore. if test $# != 2 then echo 'Usage: cover_prune.sh ${codecov.yml} $cover' >&2 exit 1 fi yaml=\"$1\" data=\"$2\" sed -En '/^ignore:/,/^[^ ]/s/^ *- \"(.*)\"/src.elv.sh\\/\\1/p' $yaml > $yaml.ignore grep -F -v -f $yaml.ignore $data > $data.pruned mv $data.pruned $data rm $yaml.ignore"
        },
        {
            "filename": "file_345.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\FFmpeg-iOS-build-script\\file_345.sh",
            "content": "#!/bin/sh # directories SCRATCH=`pwd`/\"scratch\" ARCHS=\"arm64 armv7 i386 x86_64\" FFMPEG_VERSION=\"3.4\" export FFMPEG_VERSION HEADER_SUFFIX=\".h\" CURRENT_FOLDER=`pwd` FRAMEWORK_NAME=\"FFmpeg\" FRAMEWORK_EXT=\".framework\" FRAMEWORK=\"$FRAMEWORK_NAME$FRAMEWORK_EXT\" BUILD_FOLDER=\"$CURRENT_FOLDER/FFmpeg-iOS\" BUILD_THIN_FOLDER=\"$CURRENT_FOLDER/thin\" BUILD_INCLUDE_FOLDER=\"$BUILD_FOLDER/include\" BUILD_LIB_FOLDER=\"$BUILD_FOLDER/lib\" OUTPUT_FOLDER=\"$CURRENT_FOLDER/$FRAMEWORK\" OUTPUT_INFO_PLIST_FILE=\"$OUTPUT_FOLDER/Info.plist\" OUTPUT_HEADER_FOLDER=\"$OUTPUT_FOLDER/Headers\" OUTPUT_UMBRELLA_HEADER=\"$OUTPUT_HEADER_FOLDER/ffmpeg.h\" OUTPUT_MODULES_FOLDER=\"$OUTPUT_FOLDER/Modules\" OUTPUT_MODULES_FILE=\"$OUTPUT_MODULES_FOLDER/module.modulemap\" VERSION_NEW_NAME=\"Version.h\" BUNDLE_ID=\"org.ffmpeg.FFmpeg\" function CreateFramework() { rm -rf $OUTPUT_FOLDER mkdir -p $OUTPUT_HEADER_FOLDER $OUTPUT_MODULES_FOLDER } function CompileSource() { ./build-ffmpeg.sh $ARCHS ./build-ffmpeg.sh lipo } function MergeStaticLibrary() { local files=\"\" for ARCH in $ARCHS; do folder=\"$SCRATCH/$ARCH\" name=\"$FRAMEWORK_NAME$ARCH.a\" ar cru $name $(find $folder -name \"*.o\") files=\"$files $name\" done lipo -create $files -output FFmpeg for file in $files; do rm -rf $file done mv $FRAMEWORK_NAME $OUTPUT_FOLDER } function RenameHeader() { local include_folder=\"$(pwd)/FFmpeg-iOS/include\" local need_replace_version_folder=\"\" for folder in \"$include_folder\"/*; do local folder_name=`basename $folder` local verstion_file_name=\"$folder_name$VERSION_NEW_NAME\" for header in \"$folder\"/*; do local header_name=`basename $header` local dst_name=$header_name if [ $header_name == \"version.h\" ]; then dst_name=$verstion_file_name fi local dst_folder=$OUTPUT_HEADER_FOLDER local file_name=\"$folder/$header_name\" local dst_file_name=\"$dst_folder/$dst_name\" cp $file_name $dst_file_name find \"$dst_folder\" -name \"$dst_name\" -type f -exec sed -i '' \"s/\\\"version.h\\\"/\\\"$verstion_file_name\\\"/g\" {} \\; done need_replace_version_folder=\"$need_replace_version_folder $folder_name\" done for folder_name in $need_replace_version_folder; do local verstion_file_name=\"$folder_name$VERSION_NEW_NAME\" find $OUTPUT_HEADER_FOLDER -type f -exec sed -i '' \"s/\\\"$folder_name\\/version.h\\\"/\\\"$verstion_file_name\\\"/g\" {} \\; done find $OUTPUT_HEADER_FOLDER -type f -exec sed -i '' \"s/libavformat\\///g\" {} \\; find $OUTPUT_HEADER_FOLDER -type f -exec sed -i '' \"s/libavutil\\///g\" {} \\; find $OUTPUT_HEADER_FOLDER -type f -exec sed -i '' \"s/libavcodec\\///g\" {} \\; } # COPY MISSING inttypes.h function CopyInttype() { local file=\"$(xcode-select -p)/Toolchains/XcodeDefault.xctoolchain/usr/lib/swift/clang/include/inttypes.h\" cp $file $OUTPUT_HEADER_FOLDER find $OUTPUT_HEADER_FOLDER -type f -exec sed -i '' \"s/<inttypes.h>/\\\"inttypes.h\\\"/g\" {} \\; } function CreateModulemapAndUmbrellaHeader() { #create ffmpeg.h cat > $OUTPUT_UMBRELLA_HEADER <<EOF #import <Foundation/Foundation.h> #import <VideoToolbox/VideoToolbox.h> #import <AudioToolbox/AudioToolbox.h> #include \"avcodec.h\" #include \"avdevice.h\" #include \"avfilter.h\" #include \"avformat.h\" #include \"avutil.h\" #include \"swscale.h\" #include \"swresample.h\" double FFmpegVersionNumber = $FFMPEG_VERSION; EOF cat > $OUTPUT_MODULES_FILE <<EOF framework module $FRAMEWORK_NAME { umbrella header \"ffmpeg.h\" export * module * { export * } } EOF } function CreateInfoPlist() { DEFAULT_iOS_SDK_VERSION=`defaults read $(xcode-select -p)/Platforms/iPhoneOS.platform/version CFBundleShortVersionString` DTCompiler=`defaults read $(xcode-select -p)/../info DTCompiler` DTPlatformBuild=`defaults read $(xcode-select -p)/../info DTPlatformBuild` DTSDKBuild=`defaults read $(xcode-select -p)/../info DTSDKBuild` DTXcode=`defaults read $(xcode-select -p)/../info DTXcode` DTXcodeBuild=`defaults read $(xcode-select -p)/../info DTXcodeBuild` OS_BUILD_VERSION=$(sw_vers -buildVersion) cat > $OUTPUT_INFO_PLIST_FILE <<EOF <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"> <plist version=\"1.0\"> <dict> <key>BuildMachineOSBuild</key> <string>$OS_BUILD_VERSION</string> <key>CFBundleDevelopmentRegion</key> <string>en</string> <key>CFBundleExecutable</key> <string>$FRAMEWORK_NAME</string> <key>CFBundleIdentifier</key> <string>$BUNDLE_ID</string> <key>CFBundleInfoDictionaryVersion</key> <string>6.0</string> <key>CFBundleName</key> <string>$FRAMEWORK_NAME</string> <key>CFBundlePackageType</key> <string>FMWK</string> <key>CFBundleShortVersionString</key> <string>$FFMPEG_VERSION</string> <key>CFBundleSignature</key> <string>????</string> <key>CFBundleSupportedPlatforms</key> <array> <string>iPhoneOS</string> </array> <key>CFBundleVersion</key> <string>1</string> <key>DTCompiler</key> <string>$DTCompiler</string> <key>DTPlatformBuild</key> <string>$DTPlatformBuild</string> <key>DTPlatformName</key> <string>iphoneos</string> <key>DTPlatformVersion</key> <string>$DEFAULT_iOS_SDK_VERSION</string> <key>DTSDKBuild</key> <string>$DTSDKBuild</string> <key>DTSDKName</key> <string>iphoneos$DEFAULT_iOS_SDK_VERSION</string> <key>DTXcode</key> <string>$DTXcode</string> <key>DTXcodeBuild</key> <string>$DTXcodeBuild</string> <key>MinimumOSVersion</key> <string>8.0</string> <key>UIDeviceFamily</key> <array> <integer>1</integer> <integer>2</integer> </array> </dict> </plist> EOF } CompileSource CreateFramework MergeStaticLibrary RenameHeader CreateModulemapAndUmbrellaHeader CopyInttype CreateInfoPlist"
        },
        {
            "filename": "file_346.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\FFmpeg-iOS-build-script\\file_346.sh",
            "content": "#!/bin/sh # directories SOURCE=\"ffmpeg-3.1.1\" FAT=\"FFmpeg-tvOS\" SCRATCH=\"scratch-tvos\" # must be an absolute path THIN=`pwd`/\"thin-tvos\" # absolute path to x264 library #X264=`pwd`/../x264-ios/x264-iOS #FDK_AAC=`pwd`/fdk-aac/fdk-aac-ios CONFIGURE_FLAGS=\"--enable-cross-compile --disable-debug --disable-programs \\ --disable-doc --enable-pic --disable-indev=avfoundation\" if [ \"$X264\" ] then CONFIGURE_FLAGS=\"$CONFIGURE_FLAGS --enable-gpl --enable-libx264\" fi if [ \"$FDK_AAC\" ] then CONFIGURE_FLAGS=\"$CONFIGURE_FLAGS --enable-libfdk-aac\" fi # avresample #CONFIGURE_FLAGS=\"$CONFIGURE_FLAGS --enable-avresample\" ARCHS=\"arm64 x86_64\" COMPILE=\"y\" LIPO=\"y\" DEPLOYMENT_TARGET=\"9.0\" if [ \"$*\" ] then if [ \"$*\" = \"lipo\" ] then # skip compile COMPILE= else ARCHS=\"$*\" if [ $# -eq 1 ] then # skip lipo LIPO= fi fi fi if [ \"$COMPILE\" ] then if [ ! `which yasm` ] then echo 'Yasm not found' if [ ! `which brew` ] then echo 'Homebrew not found. Trying to install...' ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" \\ || exit 1 fi echo 'Trying to install Yasm...' brew install yasm || exit 1 fi if [ ! `which gas-preprocessor.pl` ] then echo 'gas-preprocessor.pl not found. Trying to install...' (curl -L https://github.com/libav/gas-preprocessor/raw/master/gas-preprocessor.pl \\ -o /usr/local/bin/gas-preprocessor.pl \\ && chmod +x /usr/local/bin/gas-preprocessor.pl) \\ || exit 1 fi if [ ! -r $SOURCE ] then echo 'FFmpeg source not found. Trying to download...' curl http://www.ffmpeg.org/releases/$SOURCE.tar.bz2 | tar xj \\ || exit 1 fi CWD=`pwd` for ARCH in $ARCHS do echo \"building $ARCH...\" mkdir -p \"$SCRATCH/$ARCH\" cd \"$SCRATCH/$ARCH\" CFLAGS=\"-arch $ARCH\" if [ \"$ARCH\" = \"x86_64\" ] then PLATFORM=\"AppleTVSimulator\" CFLAGS=\"$CFLAGS -mtvos-simulator-version-min=$DEPLOYMENT_TARGET\" else PLATFORM=\"AppleTVOS\" CFLAGS=\"$CFLAGS -mtvos-version-min=$DEPLOYMENT_TARGET -fembed-bitcode\" if [ \"$ARCH\" = \"arm64\" ] then EXPORT=\"GASPP_FIX_XCODE5=1\" fi fi XCRUN_SDK=`echo $PLATFORM | tr '[:upper:]' '[:lower:]'` CC=\"xcrun -sdk $XCRUN_SDK clang\" AR=\"xcrun -sdk $XCRUN_SDK ar\" CXXFLAGS=\"$CFLAGS\" LDFLAGS=\"$CFLAGS\" if [ \"$X264\" ] then CFLAGS=\"$CFLAGS -I$X264/include\" LDFLAGS=\"$LDFLAGS -L$X264/lib\" fi if [ \"$FDK_AAC\" ] then CFLAGS=\"$CFLAGS -I$FDK_AAC/include\" LDFLAGS=\"$LDFLAGS -L$FDK_AAC/lib\" fi TMPDIR=${TMPDIR/%\\/} $CWD/$SOURCE/configure \\ --target-os=darwin \\ --arch=$ARCH \\ --cc=\"$CC\" \\ --ar=\"$AR\" \\ $CONFIGURE_FLAGS \\ --extra-cflags=\"$CFLAGS\" \\ --extra-ldflags=\"$LDFLAGS\" \\ --prefix=\"$THIN/`basename $PWD`\" \\ || exit 1 xcrun -sdk $XCRUN_SDK make -j3 install $EXPORT || exit 1 cd $CWD done fi if [ \"$LIPO\" ] then echo \"building fat binaries...\" mkdir -p $FAT/lib set - $ARCHS CWD=`pwd` cd $THIN/$1/lib for LIB in *.a do cd $CWD echo lipo -create `find $THIN -name $LIB` -output $FAT/lib/$LIB 1>&2 lipo -create `find $THIN -name $LIB` -output $FAT/lib/$LIB || exit 1 done cd $CWD cp -rf $THIN/$1/include $FAT fi echo Done"
        },
        {
            "filename": "file_347.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\FFmpeg-iOS-build-script\\file_347.sh",
            "content": "#!/bin/sh # directories FF_VERSION=\"4.3.1\" #FF_VERSION=\"snapshot-git\" if [[ $FFMPEG_VERSION != \"\" ]]; then FF_VERSION=$FFMPEG_VERSION fi SOURCE=\"ffmpeg-$FF_VERSION\" FAT=\"FFmpeg-iOS\" SCRATCH=\"scratch\" # must be an absolute path THIN=`pwd`/\"thin\" # absolute path to x264 library #X264=`pwd`/fat-x264 #FDK_AAC=`pwd`/../fdk-aac-build-script-for-iOS/fdk-aac-ios CONFIGURE_FLAGS=\"--enable-cross-compile --disable-debug --disable-programs \\ --disable-doc --enable-pic\" if [ \"$X264\" ] then CONFIGURE_FLAGS=\"$CONFIGURE_FLAGS --enable-gpl --enable-libx264\" fi if [ \"$FDK_AAC\" ] then CONFIGURE_FLAGS=\"$CONFIGURE_FLAGS --enable-libfdk-aac --enable-nonfree\" fi # avresample #CONFIGURE_FLAGS=\"$CONFIGURE_FLAGS --enable-avresample\" ARCHS=\"arm64 armv7 x86_64 i386\" COMPILE=\"y\" LIPO=\"y\" DEPLOYMENT_TARGET=\"8.0\" if [ \"$*\" ] then if [ \"$*\" = \"lipo\" ] then # skip compile COMPILE= else ARCHS=\"$*\" if [ $# -eq 1 ] then # skip lipo LIPO= fi fi fi if [ \"$COMPILE\" ] then if [ ! `which yasm` ] then echo 'Yasm not found' if [ ! `which brew` ] then echo 'Homebrew not found. Trying to install...' ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" \\ || exit 1 fi echo 'Trying to install Yasm...' brew install yasm || exit 1 fi if [ ! `which gas-preprocessor.pl` ] then echo 'gas-preprocessor.pl not found. Trying to install...' (curl -L https://github.com/libav/gas-preprocessor/raw/master/gas-preprocessor.pl \\ -o /usr/local/bin/gas-preprocessor.pl \\ && chmod +x /usr/local/bin/gas-preprocessor.pl) \\ || exit 1 fi if [ ! -r $SOURCE ] then echo 'FFmpeg source not found. Trying to download...' curl http://www.ffmpeg.org/releases/$SOURCE.tar.bz2 | tar xj \\ || exit 1 fi CWD=`pwd` for ARCH in $ARCHS do echo \"building $ARCH...\" mkdir -p \"$SCRATCH/$ARCH\" cd \"$SCRATCH/$ARCH\" CFLAGS=\"-arch $ARCH\" if [ \"$ARCH\" = \"i386\" -o \"$ARCH\" = \"x86_64\" ] then PLATFORM=\"iPhoneSimulator\" CFLAGS=\"$CFLAGS -mios-simulator-version-min=$DEPLOYMENT_TARGET\" else PLATFORM=\"iPhoneOS\" CFLAGS=\"$CFLAGS -mios-version-min=$DEPLOYMENT_TARGET -fembed-bitcode\" if [ \"$ARCH\" = \"arm64\" ] then EXPORT=\"GASPP_FIX_XCODE5=1\" fi fi XCRUN_SDK=`echo $PLATFORM | tr '[:upper:]' '[:lower:]'` CC=\"xcrun -sdk $XCRUN_SDK clang\" # force \"configure\" to use \"gas-preprocessor.pl\" (FFmpeg 3.3) if [ \"$ARCH\" = \"arm64\" ] then AS=\"gas-preprocessor.pl -arch aarch64 -- $CC\" else AS=\"gas-preprocessor.pl -- $CC\" fi CXXFLAGS=\"$CFLAGS\" LDFLAGS=\"$CFLAGS\" if [ \"$X264\" ] then CFLAGS=\"$CFLAGS -I$X264/include\" LDFLAGS=\"$LDFLAGS -L$X264/lib\" fi if [ \"$FDK_AAC\" ] then CFLAGS=\"$CFLAGS -I$FDK_AAC/include\" LDFLAGS=\"$LDFLAGS -L$FDK_AAC/lib\" fi TMPDIR=${TMPDIR/%\\/} $CWD/$SOURCE/configure \\ --target-os=darwin \\ --arch=$ARCH \\ --cc=\"$CC\" \\ --as=\"$AS\" \\ $CONFIGURE_FLAGS \\ --extra-cflags=\"$CFLAGS\" \\ --extra-ldflags=\"$LDFLAGS\" \\ --prefix=\"$THIN/$ARCH\" \\ || exit 1 make -j3 install $EXPORT || exit 1 cd $CWD done fi if [ \"$LIPO\" ] then echo \"building fat binaries...\" mkdir -p $FAT/lib set - $ARCHS CWD=`pwd` cd $THIN/$1/lib for LIB in *.a do cd $CWD echo lipo -create `find $THIN -name $LIB` -output $FAT/lib/$LIB 1>&2 lipo -create `find $THIN -name $LIB` -output $FAT/lib/$LIB || exit 1 done cd $CWD cp -rf $THIN/$1/include $FAT fi echo Done"
        },
        {
            "filename": "file_348.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_348.sh",
            "content": "#!/bin/sh # This script is used to write a conventional commit message. # It prompts the user to choose the type of commit as specified in the # conventional commit spec. And then prompts for the summary and detailed # description of the message and uses the values provided. as the summary and # details of the message. # # If you want to add a simpler version of this script to your dotfiles, use: # # alias gcm='git commit -m \"$(gum input)\" -m \"$(gum write)\"' # if [ -z \"$(git status -s -uno | grep -v '^ ' | awk '{print $2}')\" ]; then # gum confirm \"Stage all?\" && git add . # fi TYPE=$(gum choose \"fix\" \"feat\" \"docs\" \"style\" \"refactor\" \"test\" \"chore\" \"revert\") SCOPE=$(gum input --placeholder \"scope\") # Since the scope is optional, wrap it in parentheses if it has a value. test -n \"$SCOPE\" && SCOPE=\"($SCOPE)\" # Pre-populate the input with the type(scope): so that the user may change it SUMMARY=$(gum input --value \"$TYPE$SCOPE: \" --placeholder \"Summary of this change\") DESCRIPTION=$(gum write --placeholder \"Details of this change\") # Commit these changes if user confirms gum confirm \"Commit changes?\" && git commit -m \"$SUMMARY\" -m \"$DESCRIPTION\""
        },
        {
            "filename": "file_349.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_349.sh",
            "content": "#!/bin/bash # This script converts some video to a GIF. It prompts the user to select an # video file with `gum filter` Set the frame rate, desired width, and max # colors to use Then, converts the video to a GIF. INPUT=$(gum filter --placeholder \"Input file\") FRAMERATE=$(gum input --prompt \"Frame rate: \" --placeholder \"Frame Rate\" --prompt.foreground 240 --value \"50\") WIDTH=$(gum input --prompt \"Width: \" --placeholder \"Width\" --prompt.foreground 240 --value \"1200\") MAXCOLORS=$(gum input --prompt \"Max Colors: \" --placeholder \"Max Colors\" --prompt.foreground 240 --value \"256\") BASENAME=$(basename \"$INPUT\") BASENAME=\"${BASENAME%%.*}\" gum spin --title \"Converting to GIF\" -- ffmpeg -i \"$INPUT\" -vf \"fps=$FRAMERATE,scale=$WIDTH:-1:flags=lanczos,split[s0][s1];[s0]palettegen=max_colors=$MAXCOLORS[p];[s1][p]paletteuse\" \"$BASENAME.gif\""
        },
        {
            "filename": "file_350.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_350.sh",
            "content": "#!/bin/bash gum style --border normal --margin \"1\" --padding \"1 2\" --border-foreground 212 \"Hello, there! Welcome to $(gum style --foreground 212 'Gum').\" NAME=$(gum input --placeholder \"What is your name?\") echo -e \"Well, it is nice to meet you, $(gum style --foreground 212 \"$NAME\").\" sleep 1; clear echo -e \"Can you tell me a $(gum style --italic --foreground 99 'secret')?\\n\" gum write --placeholder \"I'll keep it to myself, I promise!\" > /dev/null # we keep the secret to ourselves clear; echo \"What should I do with this information?\"; sleep 1 READ=\"Read\"; THINK=\"Think\"; DISCARD=\"Discard\" ACTIONS=$(gum choose --no-limit \"$READ\" \"$THINK\" \"$DISCARD\") clear; echo \"One moment, please.\" grep -q \"$READ\" <<< \"$ACTIONS\" && gum spin -s line --title \"Reading the secret...\" -- sleep 1 grep -q \"$THINK\" <<< \"$ACTIONS\" && gum spin -s pulse --title \"Thinking about your secret...\" -- sleep 1 grep -q \"$DISCARD\" <<< \"$ACTIONS\" && gum spin -s monkey --title \" Discarding your secret...\" -- sleep 2 sleep 1; clear GUM=$(echo -e \"Cherry\\nGrape\\nLime\\nOrange\" | gum filter --placeholder \"Favorite flavor?\") echo \"I'll keep that in mind!\" sleep 1; clear echo \"Do you like $(gum style --foreground \"#04B575\" \"Bubble Gum?\")\" sleep 1 CHOICE=$(gum choose --item.foreground 250 \"Yes\" \"No\" \"It's complicated\") [[ \"$CHOICE\" == \"Yes\" ]] && echo \"I thought so, $(gum style --bold \"Bubble Gum\") is the best.\" || echo \"I'm sorry to hear that.\" sleep 1 gum spin --title \"Chewing some $(gum style --foreground \"#04B575\" \"$GUM\") bubble gum...\" -- sleep 2.5 clear NICE_MEETING_YOU=$(gum style --height 5 --width 20 --padding '1 3' --border double --border-foreground 57 \"Nice meeting you, $(gum style --foreground 212 \"$NAME\"). See you soon!\") CHEW_BUBBLE_GUM=$(gum style --width 17 --padding '1 3' --border double --border-foreground 212 \"Go chew some $(gum style --foreground \"#04B575\" \"$GUM\") bubble gum.\") gum join --horizontal \"$NICE_MEETING_YOU\" \"$CHEW_BUBBLE_GUM\""
        },
        {
            "filename": "file_351.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_351.sh",
            "content": "#!/bin/bash export LIST=$(cat <<END Cow:Moo Cat:Meow Dog:Woof END ) ANIMAL=$(echo \"$LIST\" | cut -d':' -f1 | gum filter) SOUND=$(echo \"$LIST\" | grep $ANIMAL | cut -d':' -f2) echo \"The $ANIMAL goes $SOUND\""
        },
        {
            "filename": "file_352.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_352.sh",
            "content": "#! /bin/sh # This script is used to manage git branches such as delete, update, and rebase # them. It prompts the user to choose the branches and the action they want to # perform. # # For an explanation on the script and tutorial on how to create it, watch: # https://www.youtube.com/watch?v=tnikefEuArQ GIT_COLOR=\"#f14e32\" git_color_text () { gum style --foreground \"$GIT_COLOR\" \"$1\" } get_branches () { if [ ${1+x} ]; then gum choose --selected.foreground=\"$GIT_COLOR\" --limit=\"$1\" $(git branch --format=\"%(refname:short)\") else gum choose --selected.foreground=\"$GIT_COLOR\" --no-limit $(git branch --format=\"%(refname:short)\") fi } git rev-parse --git-dir > /dev/null 2>&1 if [ $? -ne 0 ]; then echo \"$(git_color_text \"!!\") Must be run in a $(git_color_text \"git\") repo\" exit 1 fi gum style \\ --border normal \\ --margin \"1\" \\ --padding \"1\" \\ --border-foreground \"$GIT_COLOR\" \\ \"$(git_color_text '\uf418 Git') Branch Manager\" echo \"Choose $(git_color_text 'branches') to operate on:\" branches=$(get_branches) echo \"\" echo \"Choose a $(git_color_text \"command\"):\" command=$(gum choose --cursor.foreground=\"$GIT_COLOR\" rebase delete update) echo \"\" echo $branches | tr \" \" \"\\n\" | while read -r branch do case $command in rebase) base_branch=$(get_branches 1) git fetch origin git checkout \"$branch\" git rebase \"origin/$base_branch\" ;; delete) git branch -D \"$branch\" ;; update) git checkout \"$branch\" git pull --ff-only ;; esac done"
        },
        {
            "filename": "file_353.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_353.sh",
            "content": "#!/bin/bash ADD=\"Add\" RESET=\"Reset\" ACTION=$(gum choose \"$ADD\" \"$RESET\") if [ \"$ACTION\" == \"$ADD\" ]; then git status --short | cut -c 4- | gum choose --no-limit | xargs git add else git status --short | cut -c 4- | gum choose --no-limit | xargs git restore fi"
        },
        {
            "filename": "file_354.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_354.sh",
            "content": "#!/usr/bin/env bash # If the user passes '-h', '--help', or 'help' print out a little bit of help. # text. case \"$1\" in \"-h\" | \"--help\" | \"help\") printf 'Generate kaomojis on request.\\n\\n' printf 'Usage: %s [kind]\\n' \"$(basename \"$0\")\" exit 1 ;; esac # The user can pass an argument like \"bear\" or \"angry\" to specify the general # kind of Kaomoji produced. sentiment=\"\" if [[ $1 != \"\" ]]; then sentiment=\" $1\" fi # Ask mods to generate Kaomojis. Save the output in a variable. kaomoji=\"$(mods \"generate 10${sentiment} kaomojis. number them and put each one on its own line.\")\" if [[ $kaomoji == \"\" ]]; then exit 1 fi # Pipe mods output to gum so the user can choose the perfect kaomoji. Save that # choice in a variable. Also note that we're using cut to drop the item number # in front of the Kaomoji. choice=\"$(echo \"$kaomoji\" | gum choose | cut -d ' ' -f 2)\" if [[ $choice == \"\" ]]; then exit 1 fi # If xsel (X11) or pbcopy (macOS) exists, copy to the clipboard. If not, just # print the Kaomoji. if command -v xsel &> /dev/null; then printf '%s' \"$choice\" | xclip -sel clip # X11 elif command -v pbcopy &> /dev/null; then printf '%s' \"$choice\" | pbcopy # macOS else # We can't copy, so just print it out. printf 'Here you go: %s\\n' \"$choice\" exit 0 fi # We're done! printf 'Copied %s to the clipboard\\n' \"$choice\""
        },
        {
            "filename": "file_355.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_355.sh",
            "content": "#!/bin/bash # Always ask for permission! echo \"Do you want to see a magic trick?\" YES=\"Yes, please!\" NO=\"No, thank you!\" CHOICE=$(gum choose \"$YES\" \"$NO\") if [ \"$CHOICE\" != \"$YES\" ]; then echo \"Alright, then. Have a nice day!\" exit 1 fi # Let the magic begin. echo \"Alright, then. Let's begin!\" gum style --foreground 212 \"Pick a card, any card...\" CARD=$(gum choose \"Ace (A)\" \"Two (2)\" \"Three (3)\" \"Four (4)\" \"Five (5)\" \"Six (6)\" \"Seven (7)\" \"Eight (8)\" \"Nine (9)\" \"Ten (10)\" \"Jack (J)\" \"Queen (Q)\" \"King (K)\") SUIT=$(gum choose \"Hearts (\u2665)\" \"Diamonds (\u2666)\" \"Clubs (\u2663)\" \"Spades (\u2660)\") gum style --foreground 212 \"You picked the $CARD of $SUIT.\" SHORT_CARD=$(echo $CARD | cut -d' ' -f2 | tr -d '()') SHORT_SUIT=$(echo $SUIT | cut -d' ' -f2 | tr -d '()') TOP_LEFT=$(gum join --vertical \"$SHORT_CARD\" \"$SHORT_SUIT\") BOTTOM_RIGHT=$(gum join --vertical \"$SHORT_SUIT\" \"$SHORT_CARD\") TOP_LEFT=$(gum style --width 10 --height 5 --align left \"$TOP_LEFT\") BOTTOM_RIGHT=$(gum style --width 10 --align right \"$BOTTOM_RIGHT\") if [[ \"$SHORT_SUIT\" == \"\u2665\" || \"$SHORT_SUIT\" == \"\u2666\" ]]; then CARD_COLOR=\"1\" # Red else CARD_COLOR=\"7\" # Black fi gum style --border rounded --padding \"0 1\" --margin 2 --border-foreground \"$CARD_COLOR\" --foreground \"$CARD_COLOR\" \"$(gum join --vertical \"$TOP_LEFT\" \"$BOTTOM_RIGHT\")\" echo \"Is this your card?\" gum choose \"Omg, yes!\" \"Nope, sorry!\""
        },
        {
            "filename": "file_356.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_356.sh",
            "content": "#!/bin/sh echo \"What's your favorite shell?\" gum choose \"Posix\" \"Bash\" \"Zsh\" \"Fish\" \"Elvish\""
        },
        {
            "filename": "file_357.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_357.sh",
            "content": "#!/bin/sh # Building a simple `skate` TUI with gum to allow you to select a database and # pick a value from skate. DATABASE=$(skate list-dbs | gum choose) skate list --keys-only \"$DATABASE\" | gum filter | xargs -I {} skate get {}\"$DATABASE\""
        },
        {
            "filename": "file_358.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\gum\\examples\\file_358.sh",
            "content": "#!/bin/sh # Choose gum choose Foo Bar Baz gum choose Choose One Item --cursor \"* \" --cursor.foreground 99 --selected.foreground 99 gum choose Pick Two Items Maximum --limit 2 --cursor \"* \" --cursor-prefix \"(\u2022) \" --selected-prefix \"(x) \" --unselected-prefix \"( ) \" --cursor.foreground 99 --selected.foreground 99 gum choose Unlimited Choice Of Items --no-limit --cursor \"* \" --cursor-prefix \"(\u2022) \" --selected-prefix \"(x) \" --unselected-prefix \"( ) \" --cursor.foreground 99 --selected.foreground 99 # Confirm gum confirm \"Testing?\" gum confirm \"No?\" --default=false --affirmative \"Okay.\" --negative \"Cancel.\" # Filter gum filter echo {1..500} | sed 's/ /\\n/g' | gum filter echo {1..500} | sed 's/ /\\n/g' | gum filter --indicator \">\" --placeholder \"Pick a number...\" --indicator.foreground 1 --text.foreground 2 --match.foreground 3 --prompt.foreground 4 --height 5 # Format echo \"# Header\\nBody\" | gum format echo 'package main\\n\\nimport \"fmt\"\\n\\nfunc main() {\\n\\tfmt.Println(\"Hello, Gum!\")\\n}\\n' | gum format -t code echo \":candy:\" | gum format -t emoji echo '{{ Bold \"Bold\" }}' | gum format -t template # Input gum input gum input --prompt \"Email: \" --placeholder \"john@doe.com\" --prompt.foreground 99 --cursor.foreground 99 --width 50 gum input --password --prompt \"Password: \" --placeholder \"hunter2\" --prompt.foreground 99 --cursor.foreground 99 --width 50 # Join gum join \"Horizontal\" \"Join\" gum join --vertical \"Vertical\" \"Join\" # Spin gum spin -- sleep 1 gum spin --spinner minidot --title \"Loading...\" --title.foreground 99 -- sleep 1 gum spin --show-output --spinner monkey --title \"Loading...\" --title.foreground 99 -- sh -c 'sleep 1; echo \"Hello, Gum!\"' # Style gum style --foreground 99 --border double --border-foreground 99 --padding \"1 2\" --margin 1 \"Hello, Gum.\" # Write gum write gum write --width 40 --height 6 --placeholder \"Type whatever you want\" --prompt \"| \" --show-cursor-line --show-line-numbers --value \"Something...\" --base.padding 1 --cursor.foreground 99 --prompt.foreground 99 # Table gum table < table/example.csv # Pager gum pager < README.md # File gum file"
        },
        {
            "filename": "file_359.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\check_if_exists\\file_359.sh",
            "content": "#!/usr/bin/env bash # Check if a command already exists function command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } function command_exists_v2() { # man bash, search hash hash \"$@\" >/dev/null 2>&1 } function is_command_exists(){ if [ -z \"$(command -v \"$@\" 2> /dev/null)\" ] || [ -z \"$(command -v \"$@\" 2> /dev/null)\" ] ; then return 1 else return 0 fi }"
        },
        {
            "filename": "file_360.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\check_if_exists\\file_360.sh",
            "content": "#!/usr/bin/env bash # Check if a function already exists function function_exists { declare -f -F \"$1\" > /dev/null }"
        },
        {
            "filename": "file_361.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\date\\file_361.sh",
            "content": "#!/usr/bin/env bash # common date format date +\"%F-%H-%M-%S\" # 2016-05-17-10-20-36 date +\"%Y%m%d%H%M%S\" # 20160517102021 date +\"%Y/%m/%d %H:%M:%S %s\" # 2016/05/17 10:20:07 1463451607 date +'%Y-%m-%d %H:%M:%S.%N %z' # 2016-05-17 10:19:54.070654194 +0800 date --rfc-2822 # equal to 'date -R', Tue, 17 May 2016 10:19:35 +0800"
        },
        {
            "filename": "file_362.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\debug\\file_362.sh",
            "content": "#!/usr/bin/env bash function exit_with_error_msg() { msg=\"$1\" # message prefix=\"$2\" # logger name lineno=\"$3\" # line no echo \"${prefix:=\"self\"}: ${lineno:=\"undefined\"}: ${msg:=\"default error msg\"}.\" exit 1 } echo \"here\" # call example exit_with_error_msg exit_with_error_msg hello_message mylog $LINENO"
        },
        {
            "filename": "file_363.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\debug\\file_363.sh",
            "content": "#!/usr/bin/env bash # Control Functions # ================= # Prints backtrace info # filename:lineno:function # backtrace level function backtrace { local level=$1 local deep deep=$((${#BASH_SOURCE[@]} - 1)) echo \"[Call Trace]\" while [ \"${level}\" -le ${deep} ]; do echo \"${BASH_SOURCE[$deep]}:${BASH_LINENO[$deep-1]}:${FUNCNAME[$deep-1]}\" deep=$((deep - 1)) done } # Prints line number and \"message\" then exits # die $LINENO \"message\" function die { local exitcode=$? set +o xtrace local line=$1; shift if [ ${exitcode} == 0 ]; then exitcode=1 fi backtrace 2 err \"${line}\" \"$*\" # Give buffers a second to flush sleep 1 exit ${exitcode} } # Checks an environment variable is not set or has length 0 OR if the # exit code is non-zero and prints \"message\" and exits # NOTE: env-var is the variable name without a '$' # die_if_not_set $LINENO env-var \"message\" function die_if_not_set { local exitcode=$? local xtrace xtrace=$(set +o | grep xtrace) set +o xtrace local line=$1; shift local evar=$1; shift if ! is_set \"${evar}\" || [ ${exitcode} != 0 ]; then die \"${line}\" \"$*\" fi ${xtrace} } function deprecated { local text=$1 DEPRECATED_TEXT+=\"\\n$text\" echo \"WARNING: $text\" } # Prints line number and \"message\" in error format # err $LINENO \"message\" function err { local exitcode=$? local xtrace xtrace=$(set +o | grep xtrace) set +o xtrace local msg=\"[ERROR] ${BASH_SOURCE[2]}:$1 $2\" echo \"${msg}\" 1>&2; if [[ -n ${LOGDIR} ]]; then echo \"$msg\" >> \"${LOGDIR}/error.log\" fi ${xtrace} return ${exitcode} } # Checks an environment variable is not set or has length 0 OR if the # exit code is non-zero and prints \"message\" # NOTE: env-var is the variable name without a '$' # err_if_not_set $LINENO env-var \"message\" function err_if_not_set { local exitcode=$? local xtrace xtrace=$(set +o | grep xtrace) set +o xtrace local line=$1; shift local evar=$1; shift if ! is_set \"${evar}\" || [ ${exitcode} != 0 ]; then err \"${line}\" \"$*\" fi ${xtrace} return ${exitcode} } # Test if the named environment variable is set and not zero length # is_set env-var function is_set { local var=\\$\"$1\" eval \"[ -n \\\"${var}\\\" ]\" # For ex.: sh -c \"[ -n \\\"$var\\\" ]\" would be better, but several exercises depends on this } # Prints line number and \"message\" in warning format # warn $LINENO \"message\" function warn { local exitcode=$? local xtrace xtrace=$(set +o | grep xtrace) set +o xtrace local msg=\"[WARNING] ${BASH_SOURCE[2]}:$1 $2\" echo \"${msg}\" ${xtrace} return ${exitcode} }"
        },
        {
            "filename": "file_364.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\debug\\file_364.sh",
            "content": "#!/usr/bin/env bash old_PS4=$PS4 export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' # do something export PS4=${old_PS4}"
        },
        {
            "filename": "file_365.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\debug\\file_365.sh",
            "content": "#!/usr/bin/env bash # same as set -e, set +e set -o errexit set +o errexit"
        },
        {
            "filename": "file_366.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\debug\\file_366.sh",
            "content": "#!/usr/bin/env bash set -u # Or set -o nounset"
        },
        {
            "filename": "file_367.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\debug\\file_367.sh",
            "content": "#!/usr/bin/env bash # Print the commands being run so that we can see the command that triggers # an error. It is also useful for following along as the install occurs. # same as set -u # Save trace setting # debug option DEBUG=false #DEBUG=true if ${DEBUG} ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi ############################### # do something you want here ############################### # debug option if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_368.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\distribution-release\\file_368.sh",
            "content": "#!/usr/bin/env bash # # Function description: # determine which Linux distribution running # # Useful function list: # is_centos # is_ubuntu # is_debian # is_rhel # is_package_installed \"package\" && install_package \"package\" # # Usage: # <function-common> distro.sh # # Birth Time: # 2016-04-28 18:04:27.151203523 +0800 # # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong # # Refer: # https://github.com/openstack-dev/devstack # functions-common # Save trace setting _XTRACE_FUNCTIONS_COMMON=$(set +o | grep xtrace) set +o xtrace check_network_connectivity(){ echo \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c $ping_count $network_address_to_check >/dev/null retval=$? if [ $retval -ne 0 ] ; then if ping -c $ping_count $stable_network_address_to_check >/dev/null;then echo \"Network to $stable_network_address_to_check succeed! \" echo \"Note: network to $network_address_to_check failed once! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo \"Network is unreachable, gateway is not set.\" elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo \"Network is unreachable, gateway is unreachable.\" else echo \"Network is blocked! \" return 0 fi OFFLINE=\"True\" return 1 elif [ $retval -eq 0 ]; then echo \"Check network connectivity passed! \" OFFLINE=\"False\" return 0 fi } check_name_resolve(){ echo \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c$ping_count $target_name_to_resolve >/dev/null; then echo \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c$ping_count $stable_target_name_to_resolve >/dev/null; then echo \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 8.8.4.4 nameserver 114.114.114.114 eof check_name_resolve else echo \"Check DNS name resolve passed! \" return 0 fi } # Like sudo but forwarding http_proxy https_proxy no_proxy environment vars. # If it is run as superuser then sudo is replaced by env. # function sudo_with_proxies() { local sudo [[ \"$(id -u)\" = \"0\" ]] && sudo=\"env\" || sudo=\"sudo\" $sudo http_proxy=\"${http_proxy:-}\" https_proxy=\"${https_proxy:-}\"\\ no_proxy=\"${no_proxy:-}\" \"$@\" } # Timing infrastructure - figure out where large blocks of time are # used # # The timing infrastructure is about collecting buckets # of time that are spend in some sub-task. For instance, that might be # 'apt', 'pip', 'osc', even database migrations. We do this by a pair # of functions: time_start / time_stop. # # These take a single parameter: $name - which specifies the name of # the bucket to be accounted against. time_totals function spits out # the results. # # Resolution is only in whole seconds, so should be used for long # running activities. declare -A _TIME_TOTAL=() declare -A _TIME_START=() declare -r _TIME_BEGIN=$(date +%s) # time_start $name # # starts the clock for a timer by name. Errors if that clock is # already started. function time_start() { local name=$1 local start_time=${_TIME_START[$name]} if [[ -n \"$start_time\" ]]; then die $LINENO \"Trying to start the clock on $name, but it's already been started\" fi _TIME_START[$name]=$(date +%s) } # time_stop $name # # stops the clock for a timer by name, and accumulate that time in the # global counter for that name. Errors if that clock had not # previously been started. function time_stop() { local name local end_time local elapsed_time local total local start_time name=$1 start_time=${_TIME_START[$name]} if [[ -z \"$start_time\" ]]; then die $LINENO \"Trying to stop the clock on $name, but it was never started\" fi end_time=$(date +%s) elapsed_time=$(($end_time - $start_time)) total=${_TIME_TOTAL[$name]:-0} # reset the clock so we can start it in the future _TIME_START[$name]=\"\" _TIME_TOTAL[$name]=$(($total + $elapsed_time)) } # time_totals # Print out total time summary function time_totals() { local elapsed_time local end_time local len=15 local xtrace end_time=$(date +%s) elapsed_time=$(($end_time - $_TIME_BEGIN)) # pad 1st column this far t=() for t in ${!_TIME_TOTAL[*]}; do if [[ ${#t} -gt $len ]]; then len=${#t} fi done xtrace=$(set +o | grep xtrace) set +o xtrace echo printf \"%-${len}s %3d\\n\" \"Total runtime\" \"$elapsed_time\" echo t=() for t in ${!_TIME_TOTAL[*]}; do local v=${_TIME_TOTAL[$t]} printf \"%-${len}s %3d\\n\" \"$t\" \"$v\" done $xtrace } # Prints backtrace info # backtrace level function backtrace() { local level=$1 local deep deep=$((${#BASH_SOURCE[@]} - 1)) echo \"[Call Trace]\" while [ $level -le $deep ]; do echo \"${BASH_SOURCE[$deep]}:${BASH_LINENO[$deep-1]}:${FUNCNAME[$deep-1]}\" deep=$((deep - 1)) done } # Prints line number and \"message\" in error format # err $LINENO \"message\" function err() { local exitcode=$? local xtrace xtrace=$(set +o | grep xtrace) set +o xtrace local msg=\"[ERROR] ${BASH_SOURCE[2]}:$1 $2\" echo $msg 1>&2; if test -n ${LOGDIR}; then echo $msg >> \"${LOGDIR}/error.log\" fi $xtrace return $exitcode } # Checks an environment variable is not set or has length 0 OR if the # exit code is non-zero and prints \"message\" # NOTE: env-var is the variable name without a '$' # err_if_not_set $LINENO env-var \"message\" function err_if_not_set() { local exitcode=$? local xtrace xtrace=$(set +o | grep xtrace) set +o xtrace local line=$1; shift local val=$1; shift if ! is_set $val || [ $exitcode != 0 ]; then err $line \"$*\" fi $xtrace return $exitcode } # Test if the named environment variable is set and not zero length # is_set env-var function is_set() { local var=\\$\"$1\" eval \"[ -n \\\"$var\\\" ]\" # For ex.: sh -c \"[ -n \\\"$var\\\" ]\" would be better, but several exercises depends on this } # Prints line number and \"message\" then exits # die $LINENO \"message\" # $LINENO is refer to \"man bash\": BASH_LINENO, Use LINENO to obtain the current line number. function die() { local exitcode=$? set +o xtrace local line=$1; shift if [ $exitcode == 0 ]; then exitcode=1 fi backtrace 2 err $line \"$*\" # Give buffers a second to flush sleep 1 exit $exitcode } # Checks an environment variable is not set or has length 0 OR if the # exit code is non-zero and prints \"message\" and exits # NOTE: env-var is the variable name without a '$' # die_if_not_set $LINENO env-var \"message\" function die_if_not_set() { local exitcode=$? local xtrace xtrace=$(set +o | grep xtrace) set +o xtrace local line=$1; shift local val=$1; shift if ! is_set $val || [ $exitcode != 0 ]; then die $line \"$*\" fi $xtrace } function deprecated() { local text=$1 DEPRECATED_TEXT+=\"\\n$text\" echo \"WARNING: $text\" } # Prints line number and \"message\" in warning format # warn $LINENO \"message\" function warn() { local exitcode=$? local xtrace xtrace=$(set +o | grep xtrace) set +o xtrace local msg=\"[WARNING] ${BASH_SOURCE[2]}:$1 $2\" echo $msg $xtrace return $exitcode } # Distro Functions # ================ # Determine OS Vendor, Release and Update # # NOTE : For portability, you almost certainly do not want to use # these variables directly! The \"is_*\" functions defined below this # bundle up compatible platforms under larger umbrellas that we have # determined are compatible enough (e.g. is_ubuntu covers Ubuntu & # Debian, is_fedora covers RPM-based distros). Higher-level functions # such as \"install_package\" further abstract things in better ways. # # ``OS_VENDOR`` - vendor name: ``Ubuntu``, ``Fedora``, etc # ``OS_RELEASE`` - major release: ``14.04`` (Ubuntu), ``20`` (Fedora) # ``OS_PACKAGE`` - package type: ``deb`` or ``rpm`` # ``OS_CODENAME`` - vendor's codename for release: ``trusty`` declare OS_VENDOR OS_RELEASE OS_PACKAGE OS_CODENAME # Make a *best effort* attempt to install lsb_release packages for the # user if not available. Note can't use generic install_package* # because they depend on this! function _ensure_lsb_release(){ if test -x $(command -v lsb_release 2>/dev/null); then return fi if test -x $(command -v apt-get 2>/dev/null); then sudo apt-get install -y lsb-release elif test -x $(command -v zypper 2>/dev/null); then # XXX: old code paths seem to have assumed SUSE platforms also # had \"yum\". Keep this ordered above yum so we don't try to # install the rh package. suse calls it just \"lsb\" sudo zypper -n install lsb elif test -x $(command -v dnf 2>/dev/null); then sudo dnf install -y redhat-lsb-core elif test -x $(command -v yum 2>/dev/null); then # all rh platforms (fedora, centos, rhel) have this pkg sudo yum install -y redhat-lsb-core else die $LINENO \"Unable to find or auto-install lsb_release\" fi } # GetOSVersion # Set the following variables: # - OS_RELEASE # - OS_CODENAME # - OS_VENDOR # - OS_PACKAGE function GetOSVersion(){ # We only support distros that provide a sane lsb_release _ensure_lsb_release OS_RELEASE=$(lsb_release -r -s) OS_CODENAME=$(lsb_release -c -s) OS_VENDOR=$(lsb_release -i -s) if [[ ${OS_VENDOR} =~ (Debian|Ubuntu|LinuxMint) ]]; then OS_PACKAGE=\"deb\" else OS_PACKAGE=\"rpm\" fi typeset -xr OS_VENDOR typeset -xr OS_RELEASE typeset -xr OS_PACKAGE typeset -xr OS_CODENAME } # Translate the OS version values into common nomenclature # Sets global ``DISTRO`` from the ``os_*`` values declare DISTRO function GetDistro() { GetOSVersion if [[ \"$OS_VENDOR\" =~ (Ubuntu) || \"$OS_VENDOR\" =~ (Debian) || \\ \"$OS_VENDOR\" =~ (LinuxMint) ]]; then # 'Everyone' refers to Ubuntu / Debian / Mint releases by # the code name adjective DISTRO=$OS_CODENAME elif [[ \"$OS_VENDOR\" =~ (Fedora) ]]; then # For Fedora, just use 'f' and the release DISTRO=\"f$OS_RELEASE\" elif [[ \"$OS_VENDOR\" =~ (openSUSE) ]]; then DISTRO=\"opensuse-$OS_RELEASE\" elif [[ \"$OS_VENDOR\" =~ (SUSE LINUX) ]]; then # just use major release DISTRO=\"sle${OS_RELEASE%.*}\" elif [[ \"$OS_VENDOR\" =~ (Red.*Hat) || \\ \"$OS_VENDOR\" =~ (CentOS) || \\ \"$OS_VENDOR\" =~ (OracleServer) || \\ \"$OS_VENDOR\" =~ (Virtuozzo) ]]; then # Drop the . release as we assume it's compatible # XXX re-evaluate when we get RHEL10 DISTRO=\"rhel${OS_RELEASE::1}\" elif [[ \"$OS_VENDOR\" =~ (XenServer) ]]; then DISTRO=\"xs${OS_RELEASE%.*}\" elif [[ \"$OS_VENDOR\" =~ (kvmibm) ]]; then DISTRO=\"${OS_VENDOR}${OS_RELEASE::1}\" else # We can't make a good choice here. Setting a sensible DISTRO # is part of the problem, but not the major issue -- we really # only use DISTRO in the code as a fine-filter. # # The bigger problem is categorising the system into one of # our two big categories as Ubuntu/Debian-ish or # Fedora/CentOS-ish. # # The setting of OS_PACKAGE above is only set to \"deb\" based # on a hard-coded list of vendor names ... thus we will # default to thinking unknown distros are RPM based # (ie. is_ubuntu does not match). But the platform will then # also not match in is_fedora, because that also has a list of # names. # # So, if you are reading this, getting your distro supported # is really about making sure it matches correctly in these # functions. Then you can choose a sensible way to construct # DISTRO based on your distros release approach. die $LINENO \"Unable to determine DISTRO, can not continue.\" fi typeset -xr DISTRO } # Utility function for checking machine architecture # is_arch arch-type function is_arch() { [[ \"$(uname -m)\" == \"$1\" ]] } # Determine if current distribution is an Oracle distribution # is_oraclelinux function is_oraclelinux() { if [[ -z \"$OS_VENDOR\" ]]; then GetOSVersion fi [ \"$OS_VENDOR\" = \"OracleServer\" ] } # Determine if current distribution is a Fedora-based distribution # (Fedora, RHEL, CentOS, etc). # is_fedora function is_fedora() { if [[ -z \"$OS_VENDOR\" ]]; then GetOSVersion fi [ \"$OS_VENDOR\" = \"Fedora\" ] || [ \"$OS_VENDOR\" = \"Red Hat\" ] || \\ [ \"$OS_VENDOR\" = \"RedHatEnterpriseServer\" ] || \\ [ \"$OS_VENDOR\" = \"CentOS\" ] || [ \"$OS_VENDOR\" = \"OracleServer\" ] || \\ [ \"$OS_VENDOR\" = \"Virtuozzo\" ] } # Determine if current distribution is a Fedora-based distribution # (Fedora, RHEL, CentOS, etc). # is_centos function is_centos() { if [[ -z \"$OS_VENDOR\" ]]; then GetOSVersion fi [ \"$OS_VENDOR\" = \"Fedora\" ] || [ \"$OS_VENDOR\" = \"Red Hat\" ] || \\ [ \"$OS_VENDOR\" = \"RedHatEnterpriseServer\" ] || \\ [ \"$OS_VENDOR\" = \"CentOS\" ] || [ \"$OS_VENDOR\" = \"OracleServer\" ] || \\ [ \"$OS_VENDOR\" = \"Virtuozzo\" ] } # Determine if current distribution is a Fedora-based distribution # (Fedora, RHEL, CentOS, etc). # is_rhel function is_rhel() { if [[ -z \"$OS_VENDOR\" ]]; then GetOSVersion fi [ \"$OS_VENDOR\" = \"Fedora\" ] || [ \"$OS_VENDOR\" = \"Red Hat\" ] || \\ [ \"$OS_VENDOR\" = \"RedHatEnterpriseServer\" ] || \\ [ \"$OS_VENDOR\" = \"CentOS\" ] || [ \"$OS_VENDOR\" = \"OracleServer\" ] || \\ [ \"$OS_VENDOR\" = \"Virtuozzo\" ] } # Determine if current distribution is a SUSE-based distribution # (openSUSE, SLE). # is_suse function is_suse() { if [[ -z \"$OS_VENDOR\" ]]; then GetOSVersion fi [[ \"$OS_VENDOR\" =~ (openSUSE) || \"$OS_VENDOR\" == \"SUSE LINUX\" ]] } # Determine if current distribution is an Ubuntu-based distribution # It will also detect non-Ubuntu but Debian-based distros # is_ubuntu function is_ubuntu() { if [[ -z \"$OS_PACKAGE\" ]]; then GetOSVersion fi [ \"$OS_PACKAGE\" = \"deb\" ] } # Determine if current distribution is an Ubuntu-based distribution # It will also detect non-Ubuntu but Debian-based distros # is_debian function is_debian() { if [[ -z \"$OS_PACKAGE\" ]]; then GetOSVersion fi [ \"$OS_PACKAGE\" = \"deb\" ] } # Exit after outputting a message about the distribution not being supported. # exit_distro_not_supported [optional-string-telling-what-is-missing] function exit_distro_not_supported() { if [[ -z \"$DISTRO\" ]]; then GetDistro fi if [ $# -gt 0 ]; then die $LINENO \"Support for $DISTRO is incomplete: no support for $@\" else die $LINENO \"Support for $DISTRO is incomplete.\" fi } # Wrapper for ``apt-get update`` to try multiple times on the update # to address bad package mirrors (which happen all the time). function apt_get_update() { # only do this once per run if [[ \"$REPOS_UPDATED\" == \"True\" && \"$RETRY_UPDATE\" != \"True\" ]]; then return fi # bail if we are offline check_network_connectivity [[ \"$OFFLINE\" = \"True\" ]] && return local sudo=\"sudo\" [[ \"$(id -u)\" = \"0\" ]] && sudo=\"env\" # time all the apt operations time_start \"apt-get-update\" local proxies=\"http_proxy=${http_proxy:-} https_proxy=${https_proxy:-} no_proxy=${no_proxy:-} \" local update_cmd=\"$sudo $proxies apt-get update\" if ! timeout 300 sh -c \"while ! $update_cmd; do sleep 30; done\"; then die $LINENO \"Failed to update apt repos, we're dead now\" fi REPOS_UPDATED=True # stop the clock time_stop \"apt-get-update\" } # Wrapper for ``apt-get`` to set cache and proxy environment variables # Uses globals ``OFFLINE``, ``*_proxy`` # apt_get operation package [package ...] function apt_get() { local xtrace result xtrace=$(set +o | grep xtrace) set +o xtrace check_network_connectivity [[ \"$OFFLINE\" = \"True\" || -z \"$@\" ]] && return local sudo=\"sudo\" [[ \"$(id -u)\" = \"0\" ]] && sudo=\"env\" # time all the apt operations time_start \"apt-get\" $xtrace $sudo DEBIAN_FRONTEND=noninteractive \\ http_proxy=${http_proxy:-} https_proxy=${https_proxy:-} \\ no_proxy=${no_proxy:-} \\ apt-get --option \"Dpkg::Options::=--force-confold\" --assume-yes \"$@\" < /dev/null result=$? # stop the clock time_stop \"apt-get\" return $result } # Distro-agnostic package installer # Uses globals ``NO_UPDATE_REPOS``, ``REPOS_UPDATED``, ``RETRY_UPDATE`` # install_package package [package ...] function update_package_repo() { NO_UPDATE_REPOS=${NO_UPDATE_REPOS:-False} REPOS_UPDATED=${REPOS_UPDATED:-False} RETRY_UPDATE=${RETRY_UPDATE:-False} if [[ \"$NO_UPDATE_REPOS\" = \"True\" ]]; then return 0 fi if is_ubuntu; then apt_get_update fi } function real_install_package() { if is_ubuntu; then apt_get install \"$@\" elif is_fedora; then yum_install \"$@\" elif is_suse; then zypper_install \"$@\" else exit_distro_not_supported \"installing packages\" fi } # Distro-agnostic package installer # install_package package [package ...] function install_package() { update_package_repo if ! real_install_package \"$@\"; then RETRY_UPDATE=True update_package_repo && real_install_package \"$@\" fi } # Distro-agnostic function to tell if a package is installed # is_package_installed package [package ...] function is_package_installed() { if [[ -z \"$@\" ]]; then return 1 fi if [[ -z \"$OS_PACKAGE\" ]]; then GetOSVersion fi if [[ \"$OS_PACKAGE\" = \"deb\" ]]; then dpkg -s \"$@\" > /dev/null 2> /dev/null elif [[ \"$OS_PACKAGE\" = \"rpm\" ]]; then rpm --quiet -q \"$@\" else exit_distro_not_supported \"finding if a package is installed\" fi } # Distro-agnostic package uninstaller # uninstall_package package [package ...] function uninstall_package() { if is_ubuntu; then apt_get purge \"$@\" elif is_fedora; then sudo ${YUM:-yum} remove -y \"$@\" ||: elif is_suse; then sudo zypper rm \"$@\" ||: else exit_distro_not_supported \"uninstalling packages\" fi } # Wrapper for ``yum`` to set proxy environment variables # Uses globals ``OFFLINE``, ``*_proxy``, ``YUM`` # yum_install package [package ...] function yum_install() { local result parse_yum_result check_network_connectivity [[ \"$OFFLINE\" = \"True\" ]] && return time_start \"yum_install\" # - We run with LC_ALL=C so string matching *should* be OK # - Exit 1 if the failure might get better with a retry. # - Exit 2 if it is fatal. parse_yum_result=' \\ BEGIN { result=0 } \\ /^YUM_FAILED/ { exit $2 } \\ /^No package/ { result=2 } \\ /^Failed:/ { result=2 } \\ //{ print } \\ END { exit result }' # The manual check for missing packages is because yum -y assumes # missing or failed packages are OK. # See https://bugzilla.redhat.com/show_bug.cgi?id=965567 (sudo_with_proxies \"${YUM:-yum}\" install -y \"$@\" 2>&1 || echo YUM_FAILED $?) \\ | awk \"$parse_yum_result\" && result=$? || result=$? time_stop \"yum_install\" # if we return 1, then the wrapper functions will run an update # and try installing the package again as a defense against bad # mirrors. This can hide failures, especially when we have # packages that are in the \"Failed:\" section because their rpm # install scripts failed to run correctly (in this case, the # package looks installed, so when the retry happens we just think # the package is OK, and incorrectly continue on). if [ \"$result\" == 2 ]; then die \"Detected fatal package install failure\" fi return \"$result\" } # zypper wrapper to set arguments correctly # Uses globals ``OFFLINE``, ``*_proxy`` # zypper_install package [package ...] function zypper_install() { check_network_connectivity [[ \"$OFFLINE\" = \"True\" ]] && return local sudo=\"sudo\" [[ \"$(id -u)\" = \"0\" ]] && sudo=\"env\" $sudo http_proxy=\"${http_proxy:-}\" https_proxy=\"${https_proxy:-}\" \\ no_proxy=\"${no_proxy:-}\" \\ zypper --non-interactive install --auto-agree-with-licenses \"$@\" } # Restore xtrace $_XTRACE_FUNCTIONS_COMMON"
        },
        {
            "filename": "file_369.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\distribution-release\\file_369.sh",
            "content": "#!/bin/bash if [ \"$(id -u)\" != \"0\" ]; then echo \"This script must be run as root\" 1>&2 exit 1 fi DISTRO= OS= if grep 'Debian' /etc/issue > /dev/null 2>&1 ; then OS=debian DISTRO=debian fi if grep 'Ubuntu' /etc/issue > /dev/null 2>&1 ; then OS=debian DISTRO=ubuntu fi if grep 'ubuntu' /etc/os-release > /dev/null 2>&1 ; then OS=debian DISTRO=ubuntu fi if grep 'CentOS' /etc/issue > /dev/null 2>&1 ; then OS=rhel DISTRO=centos fi if grep 'CentOS' /etc/os-release > /dev/null 2>&1 ; then OS=rhel DISTRO=centos fi if grep 'Red' /etc/issue > /dev/null 2>&1 ; then OS=rhel DISTRO=rhel fi if [ ! ${OS} ] ; then echo \":: Could not detect OS\" echo \":: Press Enter to continue\" read -n1 -r fi echo \":: OS: $OS\" echo \":: Distro: $DISTRO\" if [ \"$OS\" == \"rhel\" ] ; then echo fi if [ \"$OS\" == \"debian\" ] ; then echo fi"
        },
        {
            "filename": "file_370.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\file\\file_370.sh",
            "content": "#!/usr/bin/env bash # # Function description: # Add some hosts record into /etc/hosts file # # Usage: # bash backupFileOrRollback.sh # # Create Time: # 2016-04-27 9:45:00.956620365 +0800 #date +'%Y-%m-%d %H:%M:%S.%N %z' # # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong # # Print the commands being run so that we can see the command that triggers # an error. It is also useful for following along as the install occurs. # same as set -u # Save trace setting _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace # TODO(Guodong Ding) add directory support # Function description: backup files # Note: accept $* parameters backup_files() { set -o errexit if [ \"$#\" -eq 0 ]; then return 1 fi file_list=$* operation_date_time=\"_$(date +\"%Y%m%d%H%M%S\")\" log_filename=\".log_$$_$RANDOM\" log_filename_full_path=/tmp/${log_filename} touch ${log_filename_full_path} old_IFS=$IFS IFS=\" \" for file in ${file_list}; do real_file=$(realpath \"${file}\") [ -f \"${real_file}\" ] && cp \"${real_file}\" \"${file}${operation_date_time}~\" [ -f ${log_filename_full_path} ] && echo \"\\mv -f $file$operation_date_time~ $file\" >>${log_filename_full_path} done IFS=\"$old_IFS\" set +o errexit return 0 } # Function description: rollback_files() { # shellcheck disable=SC1090 [ -f ${log_filename_full_path} ] && . ${log_filename_full_path} \\rm -f ${log_filename_full_path} exit 2 } function main() { lock_filename=\"lock_$$_$RANDOM\" lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" if ( set -o noclobber echo \"$$\" >\"$lock_filename_full_path\" ) 2>/dev/null; then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT # do backup_files \"$@\" || rollback_files # done rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main \"$@\" # restore xtrace setting ${_XTRACE_FUNCTIONS}"
        },
        {
            "filename": "file_371.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\file\\file_371.sh",
            "content": "#!/usr/bin/env bash FILES= test \"$(stat -c \"%s\" ${FILES})\" = \"0\""
        },
        {
            "filename": "file_372.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\file\\file_372.sh",
            "content": "#!/usr/bin/env bash # this is an example use for create a file with keep special character themselves # we called RAW contents, using this method to skip expand variable cat >/path/to/filename <<'eof' $ eof"
        },
        {
            "filename": "file_373.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\file\\file_373.sh",
            "content": "#!/bin/bash # delete all spaces and comments of specialized file [[ \"$1\" == \"\" ]] && echo \"usage: delete all spaces and comments of specialized file, using with \\\"$0 filename\\\"\" && exit 1 if cat -A \"$1\" | grep '\\^M\\$' >/dev/null || file \"$1\" | grep \"with CRLF line terminators\" >/dev/null ; then command -v dos2unix >/dev/null 2>&1 || yum -q -y install dos2unix || apt-get -qq -y install dos2unix dos2unix \"$1\" >/dev/null fi if test -f \"$1\" && file \"$1\" | grep \"XML\" >/dev/null; then command -v tidy >/dev/null 2>&1 || yum -q -y install tidy || apt-get -qq -y install tidy tidy -quiet -asxml -xml -indent -wrap 1024 --hide-comments 1 \"$1\" elif test -f \"$1\"; then grep -v \\# \"$1\" | grep -v ^\\; |grep -v ^$ | grep -v \"^\\ *$\" fi # Others: # sed -e '/^#/d;/^$/d' # Refer: https://github.com/mysfitt/nocomment/blob/master/nocomment.sh # grep -Ev '^\\s*#|^//|^\\s\\*|^/\\*|^\\*/' | grep -Ev '^$|^\\s+$'"
        },
        {
            "filename": "file_374.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\file\\file_374.sh",
            "content": "#!/bin/bash # bash shell template # debug option DEBUG=false if ${DEBUG} ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi function usage(){ cat - <<eof For reference only, this is just a demo. using this script to find files in a specified directory between 'time_start' to 'time_end', or find files between 'time_start' to now. default directory is \"/tmp/.test\", and this is fixed, please change it to changeable or other names which you need. function generate_test_example(), juet a sample test, it is called in function main(), remove it as you wish. eof cat - <<eof Example: # ls /tmp/.test/ -al total 8 drwxr-xr-x 2 root root 4096 Dec 8 12:36 . drwxrwxrwt 3 root root 4096 Dec 8 12:35 .. -rw-r--r-- 1 root root 0 Dec 8 12:35 global2.log.20161208.123505 -rw-r--r-- 1 root root 0 Dec 8 12:35 global2.log.20161208.123507 -rw-r--r-- 1 root root 0 Dec 8 12:35 global2.log.20161208.123508 -rw-r--r-- 1 root root 0 Dec 8 12:35 global2.log.20161208.123524 -rw-r--r-- 1 root root 0 Dec 8 12:35 global2.log.20161208.123527 -rw-r--r-- 1 root root 0 Dec 8 12:35 global2.log.20161208.123535 -rw-r--r-- 1 root root 0 Dec 8 12:35 global2.log.20161208.123543 -rw-r--r-- 1 root root 0 Dec 8 12:35 global2.log.20161208.123547 -rw-r--r-- 1 root root 0 Dec 8 12:35 global2.log.20161208.123551 -rw-r--r-- 1 root root 0 Dec 8 12:35 global2.log.20161208.123559 -rw-r--r-- 1 root root 0 Dec 8 12:36 global2.log.20161208.123607 # ./tt.sh 20161208.123550 -rw-r--r-- 1 root root 0 Dec 8 12:35 /tmp/.test/global2.log.20161208.123551 -rw-r--r-- 1 root root 0 Dec 8 12:35 /tmp/.test/global2.log.20161208.123559 -rw-r--r-- 1 root root 0 Dec 8 12:36 /tmp/.test/global2.log.20161208.123607 # ./tt.sh 20161208.123550 20161208.123559 -rw-r--r-- 1 root root 0 Dec 8 12:35 /tmp/.test/global2.log.20161208.123551 # eof } function date_format_transform(){ # date --date='2016-12-08 12:49:56' +\"%Y%m%d.%H%M%S\" # python -c \"import time;print time.mktime(time.strptime('20160823.140801', '%Y%m%d.%H%M%S'))\" if [ \"x$1\" != \"x\" ]; then unix_timestamp=$(python -c \"import time;print time.mktime(time.strptime('$1', '%Y%m%d.%H%M%S'))\") result=$(date -d@\"$unix_timestamp\" +\"%Y-%m-%d %H:%M:%S\") echo \"${result}\" else echo \"bad parameter\" exit fi } function find_with_time_from_range(){ # find /tmp/.test/ -type f -newermt '2016-12-08 12:35:07' ! -newermt '2016-12-08 12:35:51' if test \"x$1\" != \"x\" -a \"x$2\" != \"x\" ; then time_start=$(date_format_transform $1) time_end=$(date_format_transform $2) find /tmp/.test/ -type f -newermt \"${time_start}\" ! -newermt \"${time_end}\" | xargs ls -al else exit fi } function find_with_time_to_now(){ # find /tmp/.test/ -type f -newermt '2016-12-08 12:35:07' if test \"x$1\" != \"x\" -a \"x$2\" == \"x\" ; then time_start=$(date_format_transform $1) find /tmp/.test/ -type f -newermt \"${time_start}\" | xargs ls -al else exit fi } function generate_test_example() { echo \"generating test example directories and files... Please waiting 0~max(10*9) seconds.\" date_format=\"%Y%m%d.%H%M%S\" # filename_tail=\"`date +\"$date_format\"`\" [ -d /tmp/.test ] || mkdir -p /tmp/.test for (( i=1 ; i<10 ; i++ )); do touch /tmp/.test/global2.log.\"`date +\"$date_format\"`\" sleep \"`expr $RANDOM % 9`\" done [ -d /tmp/.test ] && ls -al /tmp/.test } function main(){ lock_filename=\"lock_$$_$RANDOM\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT # do something here generate_test_example if [[ \"x$@\" == \"x\" ]]; then usage else if test \"x$1\" != \"x\" -a \"x$2\" != \"x\" ; then find_with_time_from_range $@ elif test \"x$1\" != \"x\" -a \"x$2\" == \"x\" ; then find_with_time_to_now $@ else usage fi fi # end do something here rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_375.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\file\\file_375.sh",
            "content": "#!/usr/bin/env bash #!/bin/bash # delete all spaces and comments of specialized file, using with $@ filename [[ \"$1\" == \"\" ]] && echo \"delete all spaces and comments of specialized file, using with $0 filename\" && exit 1 if cat -A \"$1\" | grep '\\^M\\\\$' >/dev/null || file \"$1\" | grep \"with CRLF line terminators\" >/dev/null ; then command -v dos2unix >/dev/null 2>&1 || yum -q -y install dos2unix || apt-get -qq -y install dos2unix dos2unix \"$1\" >/dev/null fi if test -f \"$1\" && file \"$1\" | grep \"XML\" >/dev/null; then command -v tidy >/dev/null 2>&1 || yum -q -y install tidy || apt-get -qq -y install tidy tidy -quiet -asxml -xml -indent -wrap 1024 --hide-comments 1 \"$1\" elif test -f \"$1\"; then grep -v \\# \"$1\" | grep -v ^\\; |grep -v ^$ | grep -v \"^\\ *$\" fi # Others: # cat -A /path/to/filename # sed -e '/^#/d;/^$/d' $1 # Refer: https://github.com/mysfitt/nocomment/blob/master/nocomment.sh # grep -Ev '^\\s*#|^//|^\\s\\*|^/\\*|^\\*/' $1 | grep -Ev '^$|^\\s+$'"
        },
        {
            "filename": "file_376.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\file\\file_376.sh",
            "content": "#!/usr/bin/env bash # Function description: # set logrotate for logfile # Usage: # bash setLogrotate.sh </absolutely/path/to/logfile/name1> [/absolutely/path/to/logfile/name2...] # Birth Time: # 2016-05-30 10:07:13.289403529 +0800 # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong # Test result: # test passed on CentOS 6.7 and Ubuntu 14.04.4 LTS # Refer: # /etc/cron.daily/logrotate # /etc/logrotate.conf # /etc/logrotate.conf # /etc/logrotate.d # /etc/logrotate.d/rsyslog #set -x set -e # Usage: $0 </absolutely/path/to/logfile/name1> [/absolutely/path/to/logfile/name2...] if [ $# -eq 0 ]; then echo \"Usage: bash $0 </absolutely/path/to/logfile/name1> [/absolutely/path/to/logfile/name2...]\" exit 1 fi function generate_file_name() { s1=${1//.log/} # replace \".log\" to \"\" s2=${s1//\\//_} # replace \"\\\" to \"_\" s3=${s2#_} # remove first \"_\" echo \"$s3\" } for logfile in \"$@\"; do if test -f \"${logfile}\"; then echo \"set logrotate for $logfile ... \" filename_core=$(generate_file_name \"${logfile}\") # logrotate_config_file=\"/etc/logrotate.d/customized_logfile_${RANDOM}_$$\" logrotate_config_file=\"/etc/logrotate.d/$filename_core\" # check if there are duplicated configs for same logfile if test -f \"$logrotate_config_file\"; then echo \"logrotate config for file \\\"${logfile}\\\" is already exist, now exit\" echo \"exist file is: \\\"${logrotate_config_file}\\\"\" exit 1 fi # `man logrotate` cat >\"${logrotate_config_file}\" <<eof ${logfile} { daily # su user group # create 640 user group rotate 30 # size 10M missingok notifempty # compress # delaycompress } eof logrotate --debug \"${logrotate_config_file}\" >/dev/null 2>&1 # -d, --debug Don't do anything, just test (implies -v) if test \"$?\" = \"0\"; then echo \"set logrotate for $logfile successfully! \" else echo \"set logrotate for $logfile failed: bad config file or logrotate command is not exist or system incompatible , please alter to system administrators. \" fi else echo \"set logrotate for $logfile failed: Bad logfile, $(ls \"$logfile\")\" fi done set +e"
        },
        {
            "filename": "file_377.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\file\\GoogleHostsFileForLinux\\file_377.sh",
            "content": "#!/bin/bash # Function description: # GoogleHostsFileForLinux # Google Hosts File For Linux, a Linux shell script make you access Google easily! Run it directly and enjoy Google services. # Usage: # bash replaceLocalHostsFileAgainstGfw.sh # Birth Time: # 2016-04-22 10:04:43.895515929 +0800 # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter WORKDIR=\"$PRGDIR\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi # Name: replaceLocalHostsFileAgainstGfw.sh # Refer to: https://github.com/racaljk/hosts # Backups: https://coding.net/u/scaffrey/p/hosts/git # define user friendly messages header=\" Function: Execute this shell script to access Google, etc easily. Open source software Written by Guodong Ding <dgdenterprise@gmail.com>. Blog: http://dgd2010.blog.51cto.com/ Github: https://github.com/DingGuodong Last updated: 2016-4-19 \" function check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 \"$(ip route | awk '/default/ {print $3}')\" >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" echo fi } function check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"$(md5sum /etc/resolv.conf | awk '{ print $1 }')\" if test \"${eval_md5sum_of_nameserver_config}\" = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_\"$(date +%Y%m%d%H%M%S)\"~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" echo return 0 fi } command_exists() { # which \"$*\" >/dev/null 2>&1 command -v \"$*\" >/dev/null 2>&1 } check_command_can_be_execute(){ command_exists } yum_install_packages(){ echo_b \"yum install $* ...\" yum -q -yy install \"$*\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"yum install $* failed! \" exit 1 else echo_g \"yum install $* successfully! \" fi } apt_get_install_packages(){ echo_b \"apt-get install $* ...\" apt-get -qq -y install \"$*\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"apt-get install $* failed! \" exit 1 else echo_g \"apt-get install $* successfully! \" fi } # Refer: https://get.docker.com/ # 'curl -sSL https://get.docker.com/ | sh' # or: # 'wget -qO- https://get.docker.com/ | sh' # # Check if this is a forked Linux distro check_linux_distribution_forked() { # Check for lsb_release command existence, it usually exists in forked distros if command_exists lsb_release; then # Check if the `-u` option is supported set +e lsb_release -a -u > /dev/null 2>&1 lsb_release_exit_code=$? set -e # Check if the command has exited successfully, it means we're in a forked distro if [ \"$lsb_release_exit_code\" = \"0\" ]; then # Print info about current distro # Get the upstream release info lsb_dist=$(lsb_release -a -u 2>&1 | tr '[:upper:]' '[:lower:]' | grep -E 'id' | cut -d ':' -f 2 | tr -d '[[:space:]]') dist_version=$(lsb_release -a -u 2>&1 | tr '[:upper:]' '[:lower:]' | grep -E 'codename' | cut -d ':' -f 2 | tr -d '[[:space:]]') cat <<-EOF You're using '${lsb_dist}' version '${dist_version}'. EOF # Print info about upstream distro cat <<-EOF Upstream release is '${lsb_dist}' version '${dist_version}'. EOF else if [ -r /etc/debian_version ] && [ \"$lsb_dist\" != \"ubuntu\" ]; then # We're Debian and don't even know it! lsb_dist=debian dist_version=\"$(cat /etc/debian_version | sed 's/\\/.*//' | sed 's/\\..*//')\" case \"$dist_version\" in 8|'Kali Linux 2') dist_version=\"jessie\" ;; 7) dist_version=\"wheezy\" ;; esac fi fi fi } check_linux_distribution(){ # refer to /etc/issue and /etc/*-release maybe more better choice # perform some very rudimentary platform detection lsb_dist='' dist_version='' if command_exists lsb_release; then lsb_dist=\"$(lsb_release -si)\" fi DISTRIB_ID=\"\" if [ -z \"$lsb_dist\" ] && [ -r /etc/lsb-release ]; then lsb_dist=$(test -f /etc/lsb-release && . /etc/lsb-release && echo \"$DISTRIB_ID\") fi if [ -z \"$lsb_dist\" ] && [ -r /etc/debian_version ]; then lsb_dist='debian' fi if [ -z \"$lsb_dist\" ] && [ -r /etc/fedora-release ]; then lsb_dist='fedora' fi if [ -z \"$lsb_dist\" ] && [ -r /etc/oracle-release ]; then lsb_dist='oracleserver' fi if [ -z \"$lsb_dist\" ]; then if [ -r /etc/centos-release ] || [ -r /etc/redhat-release ]; then lsb_dist='centos' fi fi ID=\"\" if [ -z \"$lsb_dist\" ] && [ -r /etc/os-release ]; then lsb_dist=\"$(. /etc/os-release && echo \"$ID\")\" fi lsb_dist=\"$(echo \"$lsb_dist\" | tr '[:upper:]' '[:lower:]')\" case \"$lsb_dist\" in ubuntu) if command_exists lsb_release; then dist_version=\"$(lsb_release --codename | cut -f2)\" fi DISTRIB_CODENAME=\"\" if [ -z \"$dist_version\" ] && [ -r /etc/lsb-release ]; then dist_version=\"$(. /etc/lsb-release && echo \"$DISTRIB_CODENAME\")\" fi ;; debian) dist_version=\"$(cat /etc/debian_version | sed 's/\\/.*//' | sed 's/\\..*//')\" case \"$dist_version\" in 8) dist_version=\"jessie\" ;; 7) dist_version=\"wheezy\" ;; esac ;; oracleserver) # need to switch lsb_dist to match yum repo URL lsb_dist=\"oraclelinux\" dist_version=\"$(rpm -q --whatprovides redhat-release --queryformat \"%{VERSION}\\n\" | sed 's/\\/.*//' | sed 's/\\..*//' | sed 's/Server*//')\" ;; fedora|centos) dist_version=\"$(rpm -q --whatprovides redhat-release --queryformat \"%{VERSION}\\n\" | sed 's/\\/.*//' | sed 's/\\..*//' | sed 's/Server*//')\" ;; *) if command_exists lsb_release; then dist_version=\"$(lsb_release --codename | cut -f2)\" fi VERSION_ID=\"\" if [ -z \"$dist_version\" ] && [ -r /etc/os-release ]; then dist_version=\"$(. /etc/os-release && echo \"$VERSION_ID\")\" fi ;; esac # Check if this is a forked Linux distro check_linux_distribution_forked } # end Refer above # refer to LNMP, http://lnmp.org/download.html function Get_OS_Bit(){ if [[ $(getconf WORD_BIT) = '32' && $(getconf LONG_BIT) = '64' ]] ; then Is_64bit='y' else Is_64bit='n' fi } function Get_Dist_Name(){ if grep -Eqi \"CentOS\" /etc/issue || grep -Eq \"CentOS\" /etc/*-release; then DISTRO='CentOS' PM='yum' elif grep -Eqi \"Red Hat Enterprise Linux Server\" /etc/issue || grep -Eq \"Red Hat Enterprise Linux Server\" /etc/*-release; then DISTRO='RHEL' PM='yum' elif grep -Eqi \"Aliyun\" /etc/issue || grep -Eq \"Aliyun\" /etc/*-release; then DISTRO='Aliyun' PM='yum' elif grep -Eqi \"Fedora\" /etc/issue || grep -Eq \"Fedora\" /etc/*-release; then DISTRO='Fedora' PM='yum' elif grep -Eqi \"Debian\" /etc/issue || grep -Eq \"Debian\" /etc/*-release; then DISTRO='Debian' PM='apt' elif grep -Eqi \"Ubuntu\" /etc/issue || grep -Eq \"Ubuntu\" /etc/*-release; then DISTRO='Ubuntu' PM='apt' elif grep -Eqi \"Raspbian\" /etc/issue || grep -Eq \"Raspbian\" /etc/*-release; then DISTRO='Raspbian' PM='apt' else DISTRO='unknow' fi Get_OS_Bit } function Get_RHEL_Version(){ Get_Dist_Name if [ \"${DISTRO}\" = \"RHEL\" ]; then if grep -Eqi \"release 5.\" /etc/redhat-release; then echo \"Current Version: RHEL Ver 5\" RHEL_Ver='5' elif grep -Eqi \"release 6.\" /etc/redhat-release; then echo \"Current Version: RHEL Ver 6\" RHEL_Ver='6' elif grep -Eqi \"release 7.\" /etc/redhat-release; then echo \"Current Version: RHEL Ver 7\" RHEL_Ver='7' fi fi } function Get_ARM(){ if uname -m | grep -Eqi \"arm\"; then Is_ARM='y' fi } Install_LSB() { if [ \"$PM\" = \"yum\" ]; then yum -y install redhat-lsb elif [ \"$PM\" = \"apt\" ]; then apt-get update apt-get install -y lsb-release fi } Get_Dist_Version() { Install_LSB eval ${DISTRO}_Version=$(lsb_release -rs) eval echo \"${DISTRO} \\${${DISTRO}_Version}\" } # end refer to http://lnmp.org/download.html function restorecon_if_selinux_is_enabled(){ [ -f /selinux/enforce ] && SELINUX_STATE=$(cat \"/selinux/enforce\") [ -n \"$SELINUX_STATE\" ] && [ -x /sbin/restorecon ] && /sbin/restorecon -r \"$*\" } function backup_old_hosts_file(){ echo_b \"backup old hosts file ... \" ops_time=\"$(date +%Y%m%d%H%M%S)~\" [ -f /etc/hosts ] && cp /etc/hosts /etc/hosts_\"${ops_time}\" [ -f /etc/hosts_\"${ops_time}\" ] && echo_g \"backup old hosts file successfully! file is\\\"/etc/hosts_$ops_time\\\" \" } function roll_back_to_old_hosts_file(){ echo_b \"rolling back to old hosts file ... \" if [ \"x$ops_time\" = \"x\" ]; then echo_y \"Can NOT find backup files, try to find a oldest backup manually! \\ But do NOT worry, it usually because you have backup it last time\" oldest_backup_file=\"$(find /etc -name 'hosts*~' ! -type d -printf \"%T@ %p\\n\" | sort -n | head -n1 | awk '{print $NF}')\" [ -f oldest_backup_file ] && \\mv -f \"${oldest_backup_file}\" /etc/hosts [ -s /etc/hosts ] && echo_g \"Rolling back to old hosts file successfully! \" else \\mv -f /etc/hosts_\"${ops_time}\" /etc/hosts restorecon_if_selinux_is_enabled /etc/hosts [ -s /etc/hosts ] && echo_g \"Rolling back to old hosts file successfully! \" fi } function get_hosts_file_from_backup_site(){ echo_b \"getting hosts file backup site ... \" if ! grep github /etc/hosts >/dev/null; then backup_old_hosts_file else # TODO(Guodong Ding) # rm: cannot remove \u2018/etc/hosts\u2019: Device or resource busy # it occurs in docker when mount /etc/hosts to container as a volume rm -f /etc/hosts fi wget -q https://coding.net/u/scaffrey/p/hosts/git/raw/master/hosts -O /etc/hosts # test 1 -eq 2 # debug if test $? -eq 0 -a -f /etc/hosts; then echo_g \"Get and set hosts file from backup site successfully! \" else echo_r \"Get hosts file from backup site failed! try to rolling back \" roll_back_to_old_hosts_file fi } # AI: wget https://raw.githubusercontent.com/racaljk/hosts/master/hosts -qO /tmp/hosts && sudo sh -c 'cat /tmp/hosts > /etc/hosts' function get_hosts_file_from_github(){ echo_b \"getting hosts file from GitHub ... \" if [ ! -d hosts ]; then command_exists git && git clone https://github.com/racaljk/hosts.git >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"git clone failed! \" get_hosts_file_from_backup_site return else [ -s hosts/hosts ] && echo_g \"git clone successfully! \" || exit 1 fi elif [ -d hosts/.git ]; then echo_y \"Note: a existed git repo is found! Attempt to update it! \" cd hosts command_exists git && git pull >/dev/null 2>&1 # test 1 -eq 2 # debug retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"git pull failed! \" get_hosts_file_from_backup_site return else echo_g \"git pull successfully! \" fi cd .. else echo_r \"There was a directory named \\\"hosts\\\", please remove it or change a work directory and try again, failed! \" exit 1 fi if ! grep github /etc/hosts >/dev/null && test hosts/hosts -nt /etc/hosts; then backup_old_hosts_file [ -f hosts/hosts ] && \\cp -f hosts/hosts /etc/hosts || ( echo_r \"can NOT find file \\\"hosts/hosts\\\"\" && exit 1 ) echo_g \"Replace hosts file succeeded!\" else # TODO(Guodong Ding) # rm: cannot remove \u2018/etc/hosts\u2019: Device or resource busy # it occurs in docker when mount /etc/hosts to container as a volume rm -f /etc/hosts ([ -f hosts/hosts ] && \\cp -f hosts/hosts /etc/hosts) || ( echo_r \"can NOT find file \\\"hosts/hosts\\\"\" && exit 1 ) # check if able to resolve host `hostname -f`, if not, sudo will throw a exception 'sudo: unable to resolve host xxx' echo \"127.0.0.1 $(hostname) $(hostname -f)\" >> /etc/hosts echo \"$(ip addr show scope global \"$(ip route | awk '/^default/ {print $NF}')\" | awk -F '[ /]+' '/global/ {print $3}') $(hostname) $(hostname -f)\" >> /etc/hosts echo_g \"Replace hosts file succeeded!\" fi } function validate_network_to_outside(){ echo_b \"validating hosts file ... \" for (( i=1 ; i<=3 ; i++ )) do http_code=$(curl -o /dev/null -m 10 --connect-timeout 10 -s -w \"%{http_code}\" https://www.google.com.hk/) retval=$? if test \"$http_code\" = \"200\" -o \"${http_code}\" -eq 200 ; then echo_g \"Now you can access Google via HTTPS not HTTP protocol, etc easily! \" break else echo \"Process returned with HTTP code is: $http_code\" echo_y \"replace hosts file failed! Try again, times $i\" fi done if [[ ${retval} -ne 0 ]]; then echo \"Process returned with exit RETURN code: $retval\" echo_r \"Google can NOT be reached! Please let we know via email to \\\"dgdenterprise@gmail.com\"\\\" exit 1 fi } function validate_etc_host_conf(){ echo_b \"validating /etc/host.conf file ... \" if [ -f /etc/host.conf ]; then command_exists md5sum || ( echo_r \"system is broken, md5sum comes from coreutils usually! \" && exit 1 ) md5=\"$(md5sum /etc/host.conf)\" content=\"$(cat /etc/host.conf)\" if test \"$md5\" == \"ea2ffefe1a1afb7042be04cd52f611a6\" -o \"$content\" == \"order hosts,bind\" -o \\ \"$md5\" == \"4eb63731c9f5e30903ac4fc07a7fe3d6\" -o \"$content\" == \"multi on\"; then echo_g \"Validating /etc/host.conf file passed! \" return else echo_y \"Note: /etc/host.conf file's content is \\\"$(cat /etc/host.conf)\\\"\" return fi else echo_y \"System maybe broken, can NOT find file \\\"/etc/host.conf\\\", make a new one\" cat >/etc/host.conf<<eof order hosts,bind eof fi validate_etc_host_conf } # main function # Run setup for each distro accordingly, install git here. cat -<<eof ${header} eof cd \"$WORKDIR\" || exit 1 check_network_connectivity validate_etc_host_conf check_name_resolve check_linux_distribution case \"$lsb_dist\" in amzn) ;; 'opensuse project'|opensuse) ;; 'suse linux'|sle[sd]) ;; ubuntu) command_exists git || apt_get_install_packages git ;; centos) command_exists git || yum_install_packages git ;; *) echo_r \"unsupported system type\" exit 1 esac get_hosts_file_from_github validate_network_to_outside"
        },
        {
            "filename": "file_378.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\file_lock\\file_378.sh",
            "content": "#!/usr/bin/env bash lock=/var/lock/subsys/lock if ( set -o noclobber; echo \"$$\" > \"$lock\") 2> /dev/null;then trap 'rm -f \"$lock\"; exit $?' INT TERM EXIT critical-section rm -f \"$lock\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock\" echo \"held by $(cat ${lock})\" fi"
        },
        {
            "filename": "file_379.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\file_lock\\file_379.sh",
            "content": "#!/usr/bin/env bash lock=/var/lock/subsys/lock if [ ! -e ${lock} ]; then trap ' rm -f ${lock}; exit' INT TERM EXIT touch ${lock} #critical-section rm ${lock} trap - INT TERM EXIT else echo \"critical-section is already running\" fi"
        },
        {
            "filename": "file_380.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\ip\\file_380.sh",
            "content": "#!/usr/bin/env bash # Get the default routing IP # get_default_host_ip #\u6821\u9a8c\u9a8c\u8bc1IP\u662f\u5426\u5408\u6cd5 ipcalc -c 10.20.0.7 # \u9a8c\u8bc1\u4e00\u4e2aIP\u662f\u5426\u662f\u5408\u6cd5\u7684IP\u9700\u8981\u4e0e\u5b50\u7f51\u63a9\u7801\u4e00\u8d77\u8ba1\u7b97 ipcalc -c 10.104.28.0/255.255.192.0 #egrep is the same as grep -E. IP=$(ifconfig | grep inet | grep -Ev \"(inet6|127.0.0.1)\" | awk -F \":\" '{print $2}' | awk '{print $1}') hostname -i facter ipaddress_eth0 # A system used standard method to get ip address from '/etc/rc.d/rc.sysinit' line 346 on CentOS, useless for Ubuntu ip addr show to 0.0.0.0/0 scope global | gawk '/[[:space:]]inet / { print gensub(\"/.*\",\"\",\"g\",$2) }' # Ubuntu DEVICE=\"$(route -n | awk '/^0.0.0.0/ { print $NF }')\" ip addr show to 0.0.0.0/0 scope global \"${DEVICE}\" | gawk '/[[:space:]]inet / { print gensub(\"/.*\",\"\",\"g\",$2) }' # Get all IP ifconfig | grep inet | egrep -v \"(inet6|127.0.0.1)\" | cut -d \":\" -f2 | cut -d \" \" -f1 # CentOS IP DEVICE=$(route -n | awk '/^0.0.0.0/ && /UG/ {print $NF}') IP=$(ifconfig \"${DEVICE}\" | awk -F '[ :]+' '/inet/ && !/inet6/ {print $3}') echo \"$IP\" # Ubuntu IP DEVICE=$(route -n | awk '/^0.0.0.0/ && /UG/ {print $NF}') IP=$(ifconfig \"${DEVICE}\" | awk -F '[ :]+' '/inet/ && !/inet6/ {print $4}') echo \"$IP\" # general distro using ip command # TODO(Guodong Ding) Ubuntu 16.04.1 LTS maybe not support, see 'ip route' for detail ip addr show scope global \"$(ip route | awk '/^default/ {print $NF}')\" | awk -F '[ /]+' '/global/ {print $3}' #without awk or cut IP1=$(ifconfig | grep inet | grep -Ev \"(inet6|127.0.0.1)\") IP2=${IP1#*addr:} IP=${IP2%% Bcast*} echo \"$IP\" # using grep ifconfig | grep -Po '(?<=:).*(?= B)' # others ifconfig eth0 | awk -F '[ :]+' 'NR==2 {print $4}' # \u83b7\u53d6\u5185\u7f51\u7f51\u5361\u540d\u79f0(\u9002\u7528\u4e8e2\u4e2a\u7f51\u5361\uff0c1\u4e2a\u7528\u505a\u5185\u7f51\uff0c1\u4e2a\u7528\u4f5c\u5916\u7f51), U (route is up), G (use gateway), see 'man route' Flags route -n | awk '/UG/&&!/0.0.0.0/ {print$NF;exit}' # \u83b7\u53d6\u5916\u7f51\u7f51\u5361\u540d\u79f0 route -n | awk '/^0.0.0.0/ {print$NF}' # \u83b7\u53d6\u5185\u7f51\u7f51\u5361IP\u5730\u5740(\u9002\u7528\u4e8e2\u4e2a\u7f51\u5361\uff0c1\u4e2a\u7528\u505a\u5185\u7f51\uff0c1\u4e2a\u7528\u4f5c\u5916\u7f51) ip addr show scope global \"$(route -n | awk '/UG/ && ! /0.0.0.0/ {print$NF;exit}')\" | awk -F '[ /]+' '/global/ {print $3}' # \u83b7\u53d6\u5916\u7f51\u7f51\u5361IP ip addr show scope global \"$(ip route | awk '/^default/ {print $5}')\" | awk -F '[ /]+' '/global/ {print $3}'"
        },
        {
            "filename": "file_381.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\ip\\file_381.sh",
            "content": "#!/usr/bin/env bash # Define some regular expressions for matching addresses. # The regexp here is far from precise, but good enough. IP_REGEXP=\"[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\" CIDR_REGEXP=\"$IP_REGEXP/[0-9]{1,2}\" echo \"$1\" | grep -E \"^$CIDR_REGEXP$\" >/dev/null # TODO validate command ipcalc if exists # /etc/sysconfig/network-scripts/network-functions-ipv6 (CentOS Linux release 7.2.1511 (Core)) ## Test a given IPv6 address for validity # $1: <IPv6 address> # return code: 0=ok 1=not valid ipv6_test_ipv6_addr_valid() { ipcalc -cs6 \"$1\" } ## Test a given IPv4 address for validity # $1: <IPv4 address> # return code: 0=ok 1=not valid ipv6_test_ipv4_addr_valid() { ipcalc -cs4 \"$1\" } ## Test a given IPv4 address for not a private but unicast one # $1: <IPv4 address> # return code: 0=ok 1=argument error 10=private or not unicast ipv6_test_ipv4_addr_global_usable() { # local fn=\"ipv6_test_ipv4_addr_global_usable\" local testipv4addr_globalusable=$1 if [ -z \"$testipv4addr_globalusable\" ]; then return 1 fi # Test for a globally usable IPv4 address now # test 0.0.0.0/8 /bin/ipcalc --network \"$testipv4addr_globalusable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=0\\.0\\.0\\.0\" && return 10 # test 10.0.0.0/8 (RFC 1918 / private) /bin/ipcalc --network \"$testipv4addr_globalusable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=10\\.0\\.0\\.0\" && return 10 # test 127.0.0.0/8 (loopback) /bin/ipcalc --network \"$testipv4addr_globalusable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=127\\.0\\.0\\.0\" && return 10 # test 169.254.0.0/16 (APIPA / DHCP link local) /bin/ipcalc --network \"$testipv4addr_globalusable\" 255.255.0.0 | LC_ALL=C grep -q \"NETWORK=169\\.254\\.0\\.0\" && return 10 # test 172.16.0.0/12 (RFC 1918 / private) /bin/ipcalc --network \"$testipv4addr_globalusable\" 255.240.0.0 | LC_ALL=C grep -q \"NETWORK=172\\.16\\.0\\.0\" && return 10 # test 192.168.0.0/16 (RFC 1918 / private) /bin/ipcalc --network \"$testipv4addr_globalusable\" 255.255.0.0 | LC_ALL=C grep -q \"NETWORK=192\\.168\\.0\\.0\" && return 10 # test 224.0.0.0/3 (multicast and reserved, broadcast) /bin/ipcalc --network \"$testipv4addr_globalusable\" 224.0.0.0 | LC_ALL=C grep -q \"NETWORK=224\\.0\\.0\\.0\" && return 10 return 0 } function is_reserved_ip_address() { # Refer to: https://en.wikipedia.org/wiki/Reserved_IP_addresses # /etc/sysconfig/network-scripts/network-functions-ipv6 (CentOS Linux release 7.2.1511 (Core)) test_ipv4_addr_global_usable=$1 ipcalc -cs4 \"$test_ipv4_addr_global_usable\" ipcalc -cs6 \"$test_ipv4_addr_global_usable\" /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=0\\.0\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=10\\.0\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=127\\.0\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.255.0.0 | LC_ALL=C grep -q \"NETWORK=169\\.254\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.240.0.0 | LC_ALL=C grep -q \"NETWORK=172\\.16\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.255.0.0 | LC_ALL=C grep -q \"NETWORK=192\\.168\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 224.0.0.0 | LC_ALL=C grep -q \"NETWORK=224\\.0\\.0\\.0\" && return 10 }"
        },
        {
            "filename": "file_382.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\others\\file_382.sh",
            "content": "#!/usr/bin/env bash # scan an IP nmap -F 192.168.88.18 | grep 'Host is up' # scan an IP using ping nmap -n -sn 192.168.88.0/24 # scan a network nmap -nF 192.168.88.0/24 | awk '/Nmap scan report for/ {print $NF}'"
        },
        {
            "filename": "file_383.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\tcp\\email\\file_383.sh",
            "content": "#! /bin/bash # Zabbix Email alert shell script(**Deprecated**) # msmtp is an SMTP client # TODO(DingGuodong) set a configuration for msmtp # refer: https://askubuntu.com/questions/1289573/msmtp-sendmail-account-default-not-found-no-configuration-file-available-sys DEBUG=1 if [[ ${DEBUG} -gt 0 ]]; then exec 2>>/tmp/zabbix_msmtp.log set -x fi FROM='example@example.com' account_name='zabbix' # Parameters (as passed by Zabbix): # $1 : Recipient # $2 : Subject # $3 : Message recipient=$1 subject=$2 message=$3 date=$(date --rfc-2822) sed 's/$/\\r/' <<eof | /usr/bin/msmtp --account ${account_name} \"${recipient}\" From: <${FROM}> To: <${recipient}> Subject: ${subject} Date: ${date} ${message} eof"
        },
        {
            "filename": "file_384.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\tcp\\email\\file_384.sh",
            "content": "#!/usr/bin/env bash ################################################################ # Created by PyCharm. # File: LinuxBashShellScriptForOps:alterscript_sendmailbycurl.sh # User: Guodong # Create Date: 2017/6/30 # Create Time: 11:04 # Function: send email by curl # Note: # Prerequisite: curl >= 7.20 or latest version, Internet access both way # Description: ################################################################ cat >mail.txt<<eof From: \"Chris.Ding <chris.ding@gmail.com> To: \"DingGuodong\" <uberurey_ups@163.com> Subject: This is a test mail from curl Hi Guodong, I'm sending this mail with curl from my gmail.com account. Bye! eof ## curl -V #curl 7.54.1 (x86_64-pc-linux-gnu) libcurl/7.54.1 OpenSSL/1.0.1e zlib/1.2.3 libssh2/1.4.2 #Release-Date: 2017-06-14 #Protocols: dict file ftp ftps gopher http https imap imaps pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp #Features: Largefile NTLM NTLM_WB SSL libz UnixSockets HTTPS-proxy #wget -c https://curl.haxx.se/download/curl-7.54.1.tar.gz #tar zxf curl-7.54.1.tar.gz #cd curl-7.54.1 #./configure --prefix=/usr/local/curl #make install #ls /usr/local/curl/ #mv /usr/lib64/libcurl.so.4 /usr/lib64/libcurl.so.4~ #ln -s /usr/local/curl/lib/libcurl.so.4 /usr/lib64/libcurl.so.4 #ldconfig #cd export PATH=/usr/local/curl/bin:$PATH curl --url 'smtp://smtp.gmail.com:465' --ssl-reqd \\ --mail-from 'chris.ding@gmail.com' --mail-rcpt 'uberurey_ups@163.com' \\ --upload-file mail.txt --user 'chris.ding@gmail.com:password' --insecure"
        },
        {
            "filename": "file_385.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\tcp\\http\\file_385.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File: LinuxBashShellScriptForOps:${NAME}.sh # User: Guodong # Create Date: 2017/7/6 # Create Time: 16:33 # Function: # Note: curl --head --silent --show-error --connect-timeout 5 --retry 3 --retry-delay 2 --retry-max-time 5 --url http://www.baidu.com/ --output /dev/null # Prerequisite: # Description: Linux curl examples, sleep random seconds # Reference: url_list=\" www.baidu.com www.aliyun.com www.163.com \" for url in ${url_list}; do curl -sL -w \"%{http_code} %{size_download}\\\\n\" \"${url}\" -o /dev/null done # or # Note: The file must use UNIX and OS X(LF, \\n) line ending(Know as 'Line separators') not Windows(CRLF, \\r\\n), # you can use 'dos2unix -n url.txt url_unix.txt' to change it easily, # use 'dos2unix url.txt' will convert in old file mode while IFS= read -r url do curl -sL -w \"%{http_code} %{size_download}\\\\n\" \"${url}\" -o /dev/null sleep $((RANDOM % 7 + 3 )) done < <(grep -v '^ *#' < url.txt)"
        },
        {
            "filename": "file_386.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\tcp\\http\\download\\file_386.sh",
            "content": "#!/usr/bin/env bash #nohup curl -q --fail --location --max-redirs 10 --user-agent 'Vagrant/1.8.1 (+https://www.vagrantup.com; ruby2.2.3)' --continue-at - --output /root/box3c0998296d01dea7d3da811797eac21584a8b71a http://files.edx.org/vagrant-images/20151221-dogwood-fullstack-rc2.box & #curl -q --fail --location --max-redirs 10 --user-agent 'Vagrant/1.8.1 (+https://www.vagrantup.com; ruby2.2.3)' --continue-at - --output /tmp/curl_path_to_file http://files.edx.org/vagrant-images/20151221-dogwood-fullstack-rc2.box #wget -c <url> # wget <url> -O /path/to/file -t 2 # set number of retries to NUMBER (0 unlimits) # curl -LSs <url> -o /path/to/file # curl -LOSs <url>"
        },
        {
            "filename": "file_387.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\tcp\\port\\file_387.sh",
            "content": "#!/usr/bin/env bash # code snippets for TCP status monitoring tcp_summary_statistics=$(ss -s) function get_tcp_state_from_ss() { case $1 in tcp_total | total) echo \"$tcp_summary_statistics\" | awk \"NR==2\" | awk '{print $2}' ;; tcp_estab | estab) echo \"$tcp_summary_statistics\" | awk \"NR==2\" | awk '{print +$4}' ;; tcp_closed | closed) echo \"$tcp_summary_statistics\" | awk \"NR==2\" | awk '{print +$6}' ;; tcp_orphaned | orphaned) echo \"$tcp_summary_statistics\" | awk \"NR==2\" | awk '{print +$8}' ;; tcp_synrecv | synrecv) echo \"$tcp_summary_statistics\" | awk \"NR==2\" | awk '{print +$10}' ;; tcp_timewait | timewait) echo \"$tcp_summary_statistics\" | awk \"NR==2\" | awk '{print +$12}' ;; tcp_ports | ports) echo \"$tcp_summary_statistics\" | awk \"NR==2\" | awk '{print +$NF}' ;; esac } function get_tcp_states_from_netstat() { # netstat -n | awk '/^tcp/ {++STATES[$NF]} END {for(TYPE in STATES) print TYPE, STATES[TYPE]}' # netstat -n | awk '/^tcp/ {++STATES[$NF]} END {print STATES[\"TIME_WAIT\"]}' netstat -n | awk \"/^tcp/ {++STATES[\\$NF]} END {print STATES[\\\"$1\\\"]}\" } get_tcp_state_from_ss total get_tcp_state_from_ss estab get_tcp_state_from_ss closed get_tcp_state_from_ss orphaned get_tcp_state_from_ss synrecv get_tcp_state_from_ss timewait get_tcp_state_from_ss ports get_tcp_states_from_netstat TIME_WAIT get_tcp_states_from_netstat SYN_SENT get_tcp_states_from_netstat FIN_WAIT1 get_tcp_states_from_netstat FIN_WAIT2 get_tcp_states_from_netstat ESTABLISHED get_tcp_states_from_netstat CLOSING"
        },
        {
            "filename": "file_388.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\tcp\\ssh\\file_388.sh",
            "content": "#!/usr/bin/env bash exit 0 cd || exit ssh-keygen -N \"\" -f /root/.ssh/id_rsa cd /root/.ssh/ || exit [[ ! -e /root/.ssh/authorized_keys ]] && cp id_rsa.pub authorized_keys cat >>authorized_keys<<eof ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCawuOgQup3Qc1OILytyH+u3S9te85ctEKTvzPtRjHfnEEOjpRS6v6/PsuDHplHO1PAm8cKbEZmqR9tg4mWSweosBYW7blUUB4yWfBu6cHAnJOZ7ADNWHHJHAYi8QFZd4SLAAKbf9J12Xrkw2qZkdUyTBVbm+Y8Ay9bHqGX7KKLhjt0FIqQHRizcvncBFHXbCTJWsAduj2i7GQ5vJ507+MgFl2ZTKD2BGX5m0Jq9z3NTJD7fEb2J6RxC9PypYjayXyQBhgACxaBrPXRdYVXmy3f3zRQ4/OmJvkgoSodB7fYL8tcUZWSoXFa33vdPlVlBYx91uuA6onvOXDnryo3frN1 ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAIEAumQ2srRwd9slaeYTdr/dGd0H4NzJ3uQdBQABTe/nhJsUFWVG3titj7JiOYjCb54dmpHoi4rAYIElwrolQttZSCDKTVjamnzXfbV8HvJapLLLJTdKraSXhiUkdS4D004uleMpaqhmgNxCLu7onesCCWQzsNw9Hgpx5Hicpko6Xh0= eof cd || exit cd || exit [ ! -d /root/.ssh ] && mkdir /root/.ssh [ ! -e /root/.ssh/authorized_keys ] && touch /root/.ssh/authorized_keys cat >>/root/.ssh/authorized_keys<<eof ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCawuOgQup3Qc1OILytyH+u3S9te85ctEKTvzPtRjHfnEEOjpRS6v6/PsuDHplHO1PAm8cKbEZmqR9tg4mWSweosBYW7blUUB4yWfBu6cHAnJOZ7ADNWHHJHAYi8QFZd4SLAAKbf9J12Xrkw2qZkdUyTBVbm+Y8Ay9bHqGX7KKLhjt0FIqQHRizcvncBFHXbCTJWsAduj2i7GQ5vJ507+MgFl2ZTKD2BGX5m0Jq9z3NTJD7fEb2J6RxC9PypYjayXyQBhgACxaBrPXRdYVXmy3f3zRQ4/OmJvkgoSodB7fYL8tcUZWSoXFa33vdPlVlBYx91uuA6onvOXDnryo3frN1 ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAIEAumQ2srRwd9slaeYTdr/dGd0H4NzJ3uQdBQABTe/nhJsUFWVG3titj7JiOYjCb54dmpHoi4rAYIElwrolQttZSCDKTVjamnzXfbV8HvJapLLLJTdKraSXhiUkdS4D004uleMpaqhmgNxCLu7onesCCWQzsNw9Hgpx5Hicpko6Xh0= eof cat /root/.ssh/authorized_keys cd || exit cat >/root/.ssh/authorized_keys<<eof ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCawuOgQup3Qc1OILytyH+u3S9te85ctEKTvzPtRjHfnEEOjpRS6v6/PsuDHplHO1PAm8cKbEZmqR9tg4mWSweosBYW7blUUB4yWfBu6cHAnJOZ7ADNWHHJHAYi8QFZd4SLAAKbf9J12Xrkw2qZkdUyTBVbm+Y8Ay9bHqGX7KKLhjt0FIqQHRizcvncBFHXbCTJWsAduj2i7GQ5vJ507+MgFl2ZTKD2BGX5m0Jq9z3NTJD7fEb2J6RxC9PypYjayXyQBhgACxaBrPXRdYVXmy3f3zRQ4/OmJvkgoSodB7fYL8tcUZWSoXFa33vdPlVlBYx91uuA6onvOXDnryo3frN1 ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAIEAumQ2srRwd9slaeYTdr/dGd0H4NzJ3uQdBQABTe/nhJsUFWVG3titj7JiOYjCb54dmpHoi4rAYIElwrolQttZSCDKTVjamnzXfbV8HvJapLLLJTdKraSXhiUkdS4D004uleMpaqhmgNxCLu7onesCCWQzsNw9Hgpx5Hicpko6Xh0= eof history -c && exit # Multi host register SSH key 1 # ssh-keygen -N \"\" -f /root/.ssh/id_rsa [ ! -e /root/.ssh/authorized_keys ] && mkdir /root/.ssh # ssh-keyscan 192.168.1.241 192.168.1.242 192.168.1.243 |& awk -F '[ ]+' '!/^#/ {print $2\" \"$3}' >> /root/.ssh/authorized_keys ssh-keyscan -t rsa 192.168.1.241 192.168.1.242 192.168.1.243 |& awk -F '[ ]+' '!/^#/ {print $2\" \"$3}' >> /root/.ssh/authorized_keys ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@192.168.1.242 \"uname -a\" # Multi host register SSH key 2 # ssh-keygen -N \"\" -f /root/.ssh/id_rsa [ ! -e /root/.ssh/authorized_keys ] && mkdir /root/.ssh # ssh-keyscan 192.168.1.241 192.168.1.242 192.168.1.243 |& awk -F '[ ]+' '!/^#/ {print $2\" \"$3}' >> /root/.ssh/authorized_keys if grep -v \"trust host ssh key\" /root/.ssh/authorized_keys >/dev/null ; then { echo \"trust host ssh key lists, begin\" ssh-keyscan -t rsa 10.6.28.46 10.6.28.135 10.6.28.27 10.6.28.125 10.6.28.28 10.6.28.35 10.6.28.93 |& awk -F '[ ]+' '!/^#/ {print $2\" \"$3}' echo \"trust host ssh key lists, end\" } >> /root/.ssh/authorized_keys fi ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@10.6.28.46 \"uname -a\" # scp nohup scp -i /etc/ssh/ssh_host_rsa_key -oStrictHostKeyChecking=no -rp /data root@10.144.138.248:/data/backup/data_directory_from_42.96.187.191 >/tmp/.log_backup_$$_$RANDOM 2>&1 &"
        },
        {
            "filename": "file_389.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\tcp\\ssl\\certbot_acme\\file_389.sh",
            "content": "#!/usr/bin/env sh #https://github.com/Neilpang/get.acme.sh _exists() { cmd=\"$1\" if [ -z \"$cmd\" ] ; then echo \"Usage: _exists cmd\" return 1 fi if type command >/dev/null 2>&1 ; then command -v \"$cmd\" >/dev/null 2>&1 else type \"$cmd\" >/dev/null 2>&1 fi ret=\"$?\" return $ret } if _exists curl && [ \"${ACME_USE_WGET:-0}\" = \"0\" ]; then curl https://raw.githubusercontent.com/Neilpang/acme.sh/master/acme.sh | INSTALLONLINE=1 sh elif _exists wget ; then wget -O - https://raw.githubusercontent.com/Neilpang/acme.sh/master/acme.sh | INSTALLONLINE=1 sh else echo \"Sorry, you must have curl or wget installed first.\" echo \"Please install either of them and try again.\" fi"
        },
        {
            "filename": "file_390.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\tcp\\ssl\\certbot_acme\\file_390.sh",
            "content": "#!/usr/bin/env bash # use acme.sh to get Let's Encrypt HTTPS certificates # A pure Unix shell script implementing ACME client protocol # https://github.com/Neilpang/acme.sh # https://github.com/Neilpang/acme.sh/wiki/dnsapi aliyun_dns_access_key=\"your access key\" aliyun_dns_secret=\"your secret\" domain_name=\"example.com\" if [ \"$(id -u)\" != \"0\" ]; then echo \"Error: You must be root to run this script.\" exit 1 fi export Ali_Key=\"$aliyun_dns_access_key\" export Ali_Secret=\"$aliyun_dns_secret\" git clone https://github.com/Neilpang/acme.sh.git cd ./acme.sh || exit ./acme.sh --install crontab -l . /root/.bashrc || . \"/root/.acme.sh/acme.sh.env\" acme.sh --issue -d \"$domain_name\" -d \"*.$domain_name\" --dns dns_ali ls /root/.acme.sh/\"$domain_name\"/\"$domain_name\".cer ls /root/.acme.sh/\"$domain_name\"/\"$domain_name\".key cat /root/.acme.sh/account.conf"
        },
        {
            "filename": "file_391.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\net\\tcp\\ssl\\certbot_acme\\file_391.sh",
            "content": "#!/usr/bin/env bash HOST=\"192.168.88.18\" SRC=\"/root/.acme.sh\" DEST=\"/root/.acme.sh\" USER=\"root\" SSH_OPTION=\"-p 22 -oStrictHostKeyChecking=no\" RSYNC_LOG_FILE=\"/tmp/rsync.log\" /usr/bin/rsync -azurR \\ -e \"ssh ${SSH_OPTION}\" \\ --delete --delete-excluded \\ --log-file=${RSYNC_LOG_FILE} \\ ${USER}@${HOST}:${SRC} \"${DEST}\""
        },
        {
            "filename": "file_392.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\options\\file_392.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File: LinuxBashShellScriptForOps:askUserYesNoToConfirmOrContinue.sh # User: Guodong # Create Date: 2017/7/19 # Create Time: 15:26 # Function: # Note: # Prerequisite: # Description: ask user yes or no to confirm or continue in bash # Reference: /usr/share/yum-cli/cli.py # /usr/share/yum-cli/output.py # /usr/lib/python2.7/site-packages/yum/plugins.py function confirm_continue(){ echo \"Is this ok? \" read -n 1 -r -p \"Enter the y or Y to continue:\" user_answer # read -n1 -r -p \"Press any key to continue...\" key if [[ \"${user_answer}\" != \"y\" ]] && [[ \"${user_answer}\" != \"Y\" ]]; then echo -e \"\\n\\nExiting on user cancel.\" # exiting because \"Download Only\" specified exit 1 else echo fi } confirm_continue # main job echo \"foo\""
        },
        {
            "filename": "file_393.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\options\\file_393.sh",
            "content": "#!/bin/bash set -e branch=\"\" tag=\"\" while getopts 'b:h:t:' opt; do case ${opt}$OPTARG in b*) branch=\"$OPTARG\" ;; t*) tag=\"$OPTARG\" ;; h|?|*) echo \"$0 -b <branch name> -t <tag name> <parameter>...\" echo \"$0 -b <branch name> <parameter>...\" echo \"$0 -t <tag name> <parameter>...\" exit 1 ;; esac done shift \"$((OPTIND - 1))\" echo \"position parameter is $*.\" echo \"branch is $branch.\" echo \"tag is $tag.\""
        },
        {
            "filename": "file_394.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\options\\file_394.sh",
            "content": "#!/bin/bash # Check for root if [ \"$EUID\" -ne 0 ]; then echo -e \"You must be root\" exit 1 fi function usage() { exit 1; } # see more about \"args\", long args(--option)? while getopts \":d:b:\" opts; do case \"${opts}\" in d) BACKUPPED_DIR_ROOT=${OPTARG} ;; b) BACKUP_DAEMON=${OPTARG} ;; *) echo \"see $0 usage\" ;; esac done shift $((OPTIND-1)) if [ -z \"${BACKUPPED_DIR_ROOT}\" ] || [ -z \"${BACKUP_DAEMON}\" ]; then echo \"see $0 usage\" else echo \"opts are $BACKUPPED_DIR_ROOT, $BACKUP_DAEMON\" fi"
        },
        {
            "filename": "file_395.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\others\\ui\\console\\file_395.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File: LinuxBashShellScriptForOps:${NAME}.sh # User: Guodong # Create Date: 2017/8/28 # Create Time: 12:02 # Function: # Note: # Prerequisite: # Description: # Reference: coreutils:ls.c function red(){ # Color red [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function red_bright (){ # Color bright red [ $# -ne 1 ] && return 1 echo -e \"\\033[01;31m$1\\033[0m\" } function green (){ # Color green [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function green_bright (){ # Color bright green [ $# -ne 1 ] && return 1 echo -e \"\\033[01;32m$1\\033[0m\" } function yellow (){ # Color yellow [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function yellow_bright (){ # Color bright yellow [ $# -ne 1 ] && return 1 echo -e \"\\033[01;33m$1\\033[0m\" } function blue (){ # Color blue [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function blue_bright (){ # Color bright blue [ $# -ne 1 ] && return 1 echo -e \"\\033[01;34m$1\\033[0m\" } function magenta (){ # Color purple,magenta [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function magenta_bright (){ # Color bright purple,magenta [ $# -ne 1 ] && return 1 echo -e \"\\033[01;35m$1\\033[0m\" } function cyan (){ # Color cyan [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } function cyan_bright (){ # Color bright cyan [ $# -ne 1 ] && return 1 echo -e \"\\033[01;36m$1\\033[0m\" }"
        },
        {
            "filename": "file_396.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\others\\ui\\description\\file_396.sh",
            "content": "#!/usr/bin/env bash # Progress: 0% (Rate: 106k/s, Estimated time remaining: 8:31:25) # Estimated time remaining # ==> default: Adding box"
        },
        {
            "filename": "file_397.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\path\\file_397.sh",
            "content": "#!/usr/bin/env bash #realpath /path/to/file #readlink -f /path/to/file #find /path/to/file -name file #basename - strip directory and suffix from filenames #dirname - strip last component from file name"
        },
        {
            "filename": "file_398.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\path\\file_398.sh",
            "content": "#!/usr/bin/env bash # Not all Linux distribution Operating System have sbin in PATH for regular users. PATH=$PATH:/usr/local/sbin:/usr/sbin:/sbin"
        },
        {
            "filename": "file_399.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\process\\file_399.sh",
            "content": "#!/usr/bin/env bash PIDFILE=\"\" # about \"kill -0 <pid>\", see man 2 kill # If sig is 0, then no signal is sent, but error checking is still performed; # this can be used to check for the existence of a process ID or process group ID. if test -s ${PIDFILE}; then if ! kill -0 \"$(cat ${PIDFILE})\" >/dev/null 2>&1; then echo xxx fi else echo \"PID file could not be found!\" exit 1 fi"
        },
        {
            "filename": "file_400.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\process\\file_400.sh",
            "content": "#!/usr/bin/env bash # Program name: pstree2 # Usage: bash $0 <pid> # Description: show the cmdline of the recursively by its ppid, # like the `pstree` display a tree of processes but only show related items. # Author: dgden # Create Date: 2021/5/10 # Create Time: 22:24 #if [ \"$(id -u)\" != \"0\" ]; then # echo \"WARNING: This script should be run as root\" 2>&1 #fi [[ \"$1\" == \"\" ]] && echo \"usage: show the ppid recursively of the pid, using with \\\"$0 <pid>\\\"\" && exit 1 current_pid=\"$1\" # shellcheck disable=SC2001 current_pid_grep=$(echo \"$current_pid\" | sed 's/^\\(.\\)/[\\1]/') # shellcheck disable=SC2009 ps -ef | grep \"$current_pid_grep\" | awk -v pid=\"$current_pid\" '$2==pid' | grep \"$current_pid_grep\" # shellcheck disable=SC2009 current_ppid=\"$(ps -ef | grep \"$current_pid_grep\" | awk -v ppid=\"$current_pid\" '$2==ppid {print $3}')\" if [[ \"$current_ppid\" == \"\" || \"$current_ppid\" == \"0\" ]]; then echo \"the pid not exists.\" exit 1 fi while [[ $current_ppid -ne 1 ]]; do # shellcheck disable=SC2001 current_ppid_grep=$(echo \"$current_ppid\" | sed 's/^\\(.\\)/[\\1]/') # shellcheck disable=SC2009 ps -ef | grep \"$current_ppid_grep\" | awk -v pid=\"$current_ppid\" '$2==pid' # shellcheck disable=SC2009 current_ppid=\"$(ps -ef | grep \"$current_ppid_grep\" | awk -v ppid=\"$current_ppid\" '$2==ppid {print $3}')\" if [[ $current_ppid -eq 1 ]]; then break fi done"
        },
        {
            "filename": "file_401.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\security\\file_401.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File Name: LinuxBashShellScriptForOps:check-command-outputs.sh # Version: 0.0.1 # Author: Guodong # Author Email: dgdenterprise@gmail.com # URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps # Download URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps/tarball/master # Create Date: 2019/5/20 # Create Time: 9:54 # Description: # Long Description: \u6301\u7eed\u67e5\u8be2\u67d0\u4e2a\u7aef\u53e3\u598222\u7684\u7f51\u7edc\u8fde\u63a5\u60c5\u51b5\uff0c\u5c06\u65f6\u95f4\u6233\u548c\u8fde\u63a5\u4fe1\u606f\u5199\u5165\u6587\u4ef6 # \u5e94\u7528\u573a\u666f\uff1a # 1. \u5bf9\u5916\u653b\u51fb\uff0c\u67e5\u88ab\u653b\u51fb\u5bf9\u8c61\uff1b\u906d\u53d7\u653b\u51fb\uff0c\u67e5\u653b\u51fb\u5bf9\u8c61 # Usage: # References: https://www.tldp.org/LDP/abs/html/string-manipulation.html # Prerequisites: [] # Development Status: 3 - Alpha, 5 - Production/Stable # Environment: Console # Intended Audience: System Administrators, Developers, End Users/Desktop # License: Freeware, Freely Distributable # Natural Language: English, Chinese (Simplified) # Operating System: POSIX :: Linux # Programming Language: GNU bash :: 4+ # Topic: Utilities statistics_file=\"statistics-$(date +%Y%m%d%H%M%S).log\" touch \"${statistics_file}\" echo \"tail -f $statistics_file\" while true; do msg=$(netstat -anop|grep -E '(:3128|:8080)') if test -n \"${msg::15}\"; then # bash string manipulation(Substring Extraction), like str[:15] in Python now=$(date +%Y%m%d%H%M%S) data=$(netstat -anop|grep -E '(:3128|:8080)') echo \"$now $data\">>\"${statistics_file}\" fi done"
        },
        {
            "filename": "file_402.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\security\\file_402.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File: LinuxBashShellScriptForOps:iptables-default-centos6.sh # User: Guodong # Create Date: 2017/7/12 # Create Time: 17:47 # Function: # Note: # Prerequisite: # Description: Default Firewall configuration on CentOS6 # Reference: /etc/sysconfig/iptables # Firewall configuration written by system-config-firewall # Manual customization of this file is not recommended. *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [0:0] -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT"
        },
        {
            "filename": "file_403.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\security\\file_403.sh",
            "content": "#!/usr/bin/env bash # https://www.gnu.org/software/bash/manual/bashref.html#Bash-Variables # PROMPT_COMMAND # If set, the value is interpreted as a command to execute before the printing of each primary prompt ($PS1). # refer 1 echo 'export HISTTIMEFORMAT=\"%Y-%m-%d %H:%M:%S \"' >>/etc/bashrc echo export PROMPT_COMMAND=\"'\"'{ msg=$(history 1 | { read x y; echo $y; }); user=$(whoami); logger -p local4.info $(date \"+%Y-%m-%d %H:%M:%S\") \"$user\" \"$msg\"; }'\"'\" >>/etc/bashrc # refer 1 will send message to syslog, depends logger # refer 2 # Refer: http://dl528888.blog.51cto.com/2382721/1703059 cat >refer2 <<'eof' HISTDIR='/var/log/command.log' if [ ! -f ${HISTDIR} ];then touch ${HISTDIR} chmod 666 ${HISTDIR} fi export HISTTIMEFORMAT=\"{\\\"TIME\\\":\\\"%F %T\\\",\\\"HOSTNAME\\\":\\\"$HOSTNAME\\\",\\\"LI\\\":\\\"$(who -u am i 2>/dev/null| awk '{print $NF}'|sed -e 's/[()]//g')\\\",\\\"LU\\\":\\\"$(who am i|awk '{print $1}')\\\",\\\"NU\\\":\\\"${USER}\\\",\\\"CMD\\\":\\\"\" export PROMPT_COMMAND=\"history 1|sed 's/^[ ]\\+[0-9]\\+ //' | sed 's/$/\\\"}/'>> /var/log/command.log\" eof source refer2 # TODO(Guodong Ding) a known bug, using 'refer 2' above will make user confused when a command line include a double quotes(\") #like this \"{\"TIME\":\"2016-05-18 15:43:14\", \"HOSTNAME\":\"chris.51devops.com\", \"IP\":\"10.20.0.1\", \"LOGIN\":\"root\", \"USER\":\"root\", \"CMD\":\"echo \"xxx\"\"}\" #FIXED: use 'base64' to encoding history # refer 3 \u2713\u2713\u2713 **production environment ready** cat >refer3 <<'eof' HISTDIR='/var/spool/insight' if [ ! -f ${HISTDIR} ];then touch ${HISTDIR} chmod 666 ${HISTDIR} fi export PROMPT_COMMAND='history 1|sed \"s/^[\\ 0-9]\\+//\"| sed \"s/^/\\{\\\"TIME\\\":\\\"$(date +%F\\ %T)\\\",\\\"USER\\\"\\:\\\"$USER\\\",\\\"SSH_CLIENT\\\":\\\"$(echo $SSH_CLIENT | cut -f1,2 -d \" \")\\\",\\\"CMD\\\"\\:\\\"/\"|sed \"s/$/\\\"\\}/\">>${HISTDIR}' eof source refer3 rm -f refer3 cat >/etc/profile.d/insight.sh <<'eof' HISTDIR='/var/spool/insight' if [ ! -f ${HISTDIR} ];then touch ${HISTDIR} chmod 666 ${HISTDIR} fi export PROMPT_COMMAND='history 1|sed \"s/^[\\ 0-9]\\+//\"| sed \"s/^/\\{\\\"TIME\\\":\\\"$(date +%F\\ %T)\\\",\\\"USER\\\"\\:\\\"$USER\\\",\\\"SSH_CLIENT\\\":\\\"$(echo $SSH_CLIENT | cut -f1,2 -d \" \")\\\",\\\"CMD\\\"\\:\\\"/\"|sed \"s/$/\\\"\\}/\">>${HISTDIR}' eof tail -f -n20 /var/spool/insight # TODO(Guodong Ding) using 'refer 3' can not ignore enter key when users type nothing but press enter key, there will be many duplicate content. # TODO(Guodong Ding) previous history record will be recorded into log file when user login to system. # refer 4 cat >/etc/profile.d/insight.sh <<'eof' declare -r HISTDIR='/var/spool/insight' if [ ! -f ${HISTDIR} ];then touch ${HISTDIR} chmod 666 ${HISTDIR} fi export PROMPT_COMMAND='{ time_now=$(date +%F\\ %T); last_history=$(history 1|sed \"s/^[\\ 0-9]\\+//\"); real_ip=$(who -m 2>/dev/null| awk \"{print \\$NF}\"|sed -e \"s/[()]//g\"); ssh_client=$(echo $SSH_CLIENT | cut -f1,2 -d \" \"); echo \"{\\\"TIME\\\":\\\"${time_now}\\\",\\\"USER\\\":\\\"${USER}\\\",\\\"REAL_IP\\\":\\\"${real_ip}\\\",\\\"SSH_CLIENT\\\":\\\"${ssh_client}\\\",\\\"CMD\\\":\\\"${last_history}\\\"}\">>${HISTDIR}; }' eof source /etc/profile.d/insight.sh tail -n20 -f /var/spool/insight # export $HISTCONTROL=ignoredups:ignorespace # /root/.bashrc:HISTCONTROL=ignoredups:ignorespace # /etc/skel/.bashrc:HISTCONTROL=ignoreboth # /etc/skel creates standard files for new users # 'bash -c \"\"' syntax can NOT execute 'history' command # bash -c \"echo 1|sed s/^[\\ ]\\+[0-9]\\+// | sed s/^/$(echo \"xxx\")/\"|sed 's/$/x/' # bash -c 'echo 1|sed s/^[\\ ]\\+[0-9]\\+// | sed \"s/^/$(echo \\{\\\"TIME\\\":\\\"$(date +%F\\ %T)\\\")/\"|sed \"s/$/\\\"\\}/\"' # bash -c 'echo 1|sed s/^[\\ ]\\+[0-9]\\+// | sed \"s/^/$(echo \\{\\\"TIME\\\":\\\"$(date +%F\\ %T)\\\",\\\"USER\\\"\\:\\\"$USER\\\",\\\"SSH_CLIENT\\\":\\\"$SSH_CLIENT\\\",\\\"CMD\\\"\\:\\\")/\"|sed \"s/$/\\\"\\}/\"' # bash -c 'echo 1|sed s/^[\\ ]\\+[0-9]\\+// | sed \"s/^/\\{\\\"TIME\\\":\\\"$(date +%F\\ %T)\\\",\\\"USER\\\"\\:\\\"$USER\\\",\\\"SSH_CLIENT\\\":\\\"$SSH_CLIENT\\\",\\\"CMD\\\"\\:\\\"/\"|sed \"s/$/\\\"\\}/\"' # bash -c 'echo 1|sed s/^[\\ ]\\+[0-9]\\+// | sed \"s/^/\\{\\\"TIME\\\":\\\"$(date +%F\\ %T)\\\",\\\"USER\\\"\\:\\\"$USER\\\",\\\"SSH_CLIENT\\\":\\\"$SSH_CLIENT,$(echo $SSH_CLIENT | cut -f1 -d \" \")\\\",\\\"CMD\\\"\\:\\\"/\"|sed \"s/$/\\\"\\}/\"' # { time_now=$(date +%F\\ %T); last_history=$(history 1|sed \"s/^[\\ 0-9]\\+//\"); real_ip=$(who -m 2>/dev/null| awk \"{print \\$NF}\"|sed -e \"s/[()]//g\"); ssh_client=$(echo $SSH_CLIENT | cut -f1,2 -d \" \"); echo \"{\\\"TIME\\\":\\\"${time_now}\\\",\\\"USER\\\":\\\"${USER}\\\",\\\"REAL_IP\\\":\\\"${real_ip}\\\",\\\"SSH_CLIENT\\\":\\\"${ssh_client}\\\",\\\"CMD\\\":\\\"${last_history}\\\"}\"; } # bash -c '{ time_now=$(date +%F\\ %T); last_history=$(history 1|sed \"s/^[\\ 0-9]\\+//\"); real_ip=$(who -m 2>/dev/null| awk \"{print \\$NF}\"|sed -e \"s/[()]//g\"); ssh_client=$(echo $SSH_CLIENT | cut -f1,2 -d \" \"); echo \"{\\\"TIME\\\":\\\"${time_now}\\\",\\\"USER\\\":\\\"${USER}\\\",\\\"REAL_IP\\\":\\\"${real_ip}\\\",\\\"SSH_CLIENT\\\":\\\"${ssh_client}\\\",\\\"CMD\\\":\\\"${last_history}\\\"}\"; }' # others echo readonly PROMPT_COMMAND=\"'\"'{ echo \"$(date \"+%F %T\") $(who am i |awk \"{print \\$1\\\" \\\"\\$2\\\" \\\"\\$5}\") $(whoami) $(pwd) # $(history 1 | { read a b c cmd; echo \"$cmd\"; })\"; } >> /var/log/cmd.log'\"'\" >/etc/profile.d/cmd_log.sh # using a `logger` using a `logger` to log bash history, test passed on Ubuntu 20.04.1 LTS, logger in some old version(< util-linux 2.34) may not support '--id' option sudo tee /etc/profile.d/insight.sh <<'eof' # using a `logger` using a `logger` to log bash history declare -r HISTTIMEFORMAT=\"%F %T \" #declare -r PS1=\"[\\u@\\h \\[\\e[36m\\]\\w\\[\\e[0m\\]]\\\\$ \" # see man bash \"PROMPTING\" section declare -r PROMPT_COMMAND='{ cmd=$(history 1 | { read a b c d; echo \"$d\"; });msg=$(who am i |awk \"{print \\$2,\\$5}\");logger --id=$$ -p user.notice \"$msg $USER $PWD # $cmd\"; }' eof # using a `logger` to log bash history, test passed on CentOS release 6.10 (Final), CentOS Linux release 7.6.1810 (Core) cat >/etc/profile.d/insight.sh <<'eof' # using a `logger` using a `logger` to log bash history declare -r HISTTIMEFORMAT=\"%F %T \" declare -r PS1=\"[\\u@\\h \\w]\\\\$ \" # about PS1, see man bash \"PROMPTING\" section declare -r PROMPT_COMMAND='{ cmd=$(history 1 | { read a b c d; echo \"$d\"; });msg=$(who am i |awk \"{print \\$2,\\$5}\");logger -p user.notice \"[$$] $msg $USER $PWD # $cmd\"; }' eof"
        },
        {
            "filename": "file_404.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\service\\file_404.sh",
            "content": "#!/bin/sh ### BEGIN INIT INFO # Provides: ajenti # Required-Start: $network $syslog $local_fs # Required-Stop: $network $syslog $local_fs # Should-Start: $local_fs # Should-Stop: $local_fs # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Ajenti # Description: Ajenti administration frontend ### END INIT INFO if [ -e /lib/lsb/init-functions ]; then . /lib/lsb/init-functions log_success() { log_success_msg \"$1\" } log_failure() { log_failure_msg \"$1\" } else . /etc/rc.d/init.d/functions log_success() { echo_success echo \"$1\" } log_failure() { echo_failure echo \"$1\" } fi NAME=Ajenti DAEMON=/usr/bin/ajenti-panel PIDFILE=/var/run/ajenti.pid case \"$1\" in start) echo \"Starting $NAME:\" export LC_CTYPE=en_US.UTF8 if pidofproc -p $PIDFILE $DAEMON > /dev/null; then log_failure \"already running\" exit 1 fi if $DAEMON -d ; then log_success \"started\" else log_failure \"failed\" fi ;; stop) echo \"Stopping $NAME:\" if pidofproc -p $PIDFILE $DAEMON > /dev/null; then killproc -p $PIDFILE $DAEMON /bin/rm -rf $PIDFILE log_success \"stopped\" else log_failure \"not running\" fi ;; restart) $0 stop && sleep 2 && $0 start ;; status) if pidofproc -p $PIDFILE $DAEMON > /dev/null; then log_success \"$NAME is running\" else log_success \"$NAME is not running\" fi ;; *) echo \"Usage: $0 {start|stop|restart|status}\" exit 1 esac exit 0"
        },
        {
            "filename": "file_405.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\service\\file_405.sh",
            "content": "# -*-Shell-script-*- # # functions This file contains functions to be used by most or all # shell scripts in the /etc/init.d directory. # TEXTDOMAIN=initscripts # Make sure umask is sane umask 022 # Set up a default search path. PATH=\"/sbin:/usr/sbin:/bin:/usr/bin\" export PATH # Get a sane screen width [ -z \"${COLUMNS:-}\" ] && COLUMNS=80 [ -z \"${CONSOLETYPE:-}\" ] && CONSOLETYPE=\"$(/sbin/consoletype)\" if [ -f /etc/sysconfig/i18n -a -z \"${NOLOCALE:-}\" -a -z \"${LANGSH_SOURCED:-}\" ] ; then . /etc/profile.d/lang.sh 2>/dev/null # avoid propagating LANGSH_SOURCED any further unset LANGSH_SOURCED fi # Read in our configuration if [ -z \"${BOOTUP:-}\" ]; then if [ -f /etc/sysconfig/init ]; then . /etc/sysconfig/init else # This all seem confusing? Look in /etc/sysconfig/init, # or in /usr/doc/initscripts-*/sysconfig.txt BOOTUP=color RES_COL=60 MOVE_TO_COL=\"echo -en \\\\033[${RES_COL}G\" SETCOLOR_SUCCESS=\"echo -en \\\\033[1;32m\" SETCOLOR_FAILURE=\"echo -en \\\\033[1;31m\" SETCOLOR_WARNING=\"echo -en \\\\033[1;33m\" SETCOLOR_NORMAL=\"echo -en \\\\033[0;39m\" LOGLEVEL=1 fi if [ \"$CONSOLETYPE\" = \"serial\" ]; then BOOTUP=serial MOVE_TO_COL= SETCOLOR_SUCCESS= SETCOLOR_FAILURE= SETCOLOR_WARNING= SETCOLOR_NORMAL= fi fi # Interpret escape sequences in an fstab entry fstab_decode_str() { fstab-decode echo \"$1\" } # Check if any of $pid (could be plural) are running checkpid() { local i for i in $* ; do [ -d \"/proc/$i\" ] && return 0 done return 1 } __readlink() { ls -bl \"$@\" 2>/dev/null| awk '{ print $NF }' } __fgrep() { s=$1 f=$2 while read line; do if strstr \"$line\" \"$s\"; then echo $line return 0 fi done < $f return 1 } __kill_pids_term_kill_checkpids() { local base_stime=$1 shift 1 local pid= local pids=$* local remaining= local stat= local stime= for pid in $pids ; do [ -e \"/proc/$pid\" ] || continue read -r line < \"/proc/$pid/stat\" 2> /dev/null || continue stat=($line) stime=${stat[21]} [ -n \"$stime\" ] && [ \"$base_stime\" -lt \"$stime\" ] && continue remaining+=\"$pid \" done echo \"$remaining\" [ -n \"$remaining\" ] && return 1 return 0 } __kill_pids_term_kill() { local try=0 local delay=3; local pid= local stat=($(< /proc/self/stat)) local base_stime=${stat[21]} if [ \"$1\" = \"-d\" ]; then delay=$2 shift 2 fi local kill_list=$* kill_list=$(__kill_pids_term_kill_checkpids $base_stime $kill_list) [ -z \"$kill_list\" ] && return 0 kill -TERM $kill_list >/dev/null 2>&1 usleep 100000 kill_list=$(__kill_pids_term_kill_checkpids $base_stime $kill_list) if [ -n \"$kill_list\" ] ; then while [ $try -lt $delay ] ; do sleep 1 kill_list=$(__kill_pids_term_kill_checkpids $base_stime $kill_list) [ -z \"$kill_list\" ] && break let try+=1 done if [ -n \"$kill_list\" ] ; then kill -KILL $kill_list >/dev/null 2>&1 usleep 100000 kill_list=$(__kill_pids_term_kill_checkpids $base_stime $kill_list) fi fi [ -n \"$kill_list\" ] && return 1 return 0 } # __umount_loop awk_program fstab_file first_msg retry_msg retry_umount_args # awk_program should process fstab_file and return a list of fstab-encoded # paths; it doesn't have to handle comments in fstab_file. __umount_loop() { local remaining sig= local retry=3 count remaining=$(LC_ALL=C awk \"/^#/ {next} $1\" \"$2\" | sort -r) while [ -n \"$remaining\" -a \"$retry\" -gt 0 ]; do if [ \"$retry\" -eq 3 ]; then action \"$3\" fstab-decode umount $remaining else action \"$4\" fstab-decode umount $5 $remaining fi count=4 remaining=$(LC_ALL=C awk \"/^#/ {next} $1\" \"$2\" | sort -r) while [ \"$count\" -gt 0 ]; do [ -z \"$remaining\" ] && break count=$(($count-1)) usleep 500000 remaining=$(LC_ALL=C awk \"/^#/ {next} $1\" \"$2\" | sort -r) done [ -z \"$remaining\" ] && break kill $sig $(fstab-decode /sbin/fuser -m $remaining 2>/dev/null | sed -e \"s/\\b$$\\b//g\") > /dev/null sleep 3 retry=$(($retry -1)) sig=-9 done } # Similar to __umount loop above, without calling fuser __umount_loop_2() { local remaining= local count local kill_list #call regular umount remaining=$(LC_ALL=C awk \"/^#/ {next} $1\" \"$2\" | sort -r) action \"$3\" fstab-decode umount $remaining count=4 remaining=$(LC_ALL=C awk \"/^#/ {next} $1\" \"$2\" | sort -r) while [ \"$count\" -gt 0 ]; do [ -z \"$remaining\" ] && break count=$(($count-1)) usleep 500000 remaining=$(LC_ALL=C awk \"/^#/ {next} $1\" \"$2\" | sort -r) done [ -z \"$remaining\" ] && return 0 devs=$(stat -c \"%d\" $remaining) action \"$4\" fstab-decode umount \"-l\" $remaining # find fds that don't start with /, are not sockets or pipes or other. # these are potentially detached fds detached_fds=$(find /proc/ -regex '/proc/[0-9]+/fd/.*' -printf \"%p %l\\n\" 2>/dev/null |\\ grep -Ev '/proc/[0-9]+/fd/[0-9]+ (/.*|inotify|\\[.+\\]|(socket|pipe):\\[[0-9]+\\])') # check each detached fd to see if it has the same device # as one of our lazy umounted filesystems kill_list= [ -n \"$detached_fds\" ] && while read fdline; do fd=${fdline%% *} pid=$(echo $fdline | sed -r 's/\\/proc\\/([0-9]+).+/\\1/') fd_dev=$(stat -L -c \"%d\" $fd) for dev in $devs ; do [ \"$dev\" = \"$fd_dev\" ] && kill_list+=\"$pid \" done done <<< \"$detached_fds\" if [ -n \"$kill_list\" ] ; then STRING=$\"Killing processes with open filedescriptors on the unmounted disk:\" __kill_pids_term_kill $kill_list && success \"$STRING\" || failure \"$STRING\" echo fi } __source_netdevs_fstab() { NFSFSTAB=$(LC_ALL=C awk '!/^#/ && $3 ~ /^nfs/ && $3 != \"nfsd\" && $4 !~ /noauto/ { print $2 }' /etc/fstab) CIFSFSTAB=$(LC_ALL=C awk '!/^#/ && $3 == \"cifs\" && $4 !~ /noauto/ { print $2 }' /etc/fstab) NCPFSTAB=$(LC_ALL=C awk '!/^#/ && $3 == \"ncpfs\" && $4 !~ /noauto/ { print $2 }' /etc/fstab) GLUSTERFSFSTAB=$(LC_ALL=C awk '!/^#/ && $3 == \"glusterfs\" && $4 !~ /noauto/ { print $2 }' /etc/fstab) NETDEVFSTAB=$(LC_ALL=C awk '!/^#/ && $4 ~/_netdev/ && $4 !~ /noauto/ { print $1 }' /etc/fstab) } __source_netdevs_mtab() { NFSMTAB=$(LC_ALL=C awk '$3 ~ /^nfs/ && $3 != \"nfsd\" && $2 != \"/\" { print $2 }' /proc/mounts) CIFSMTAB=$(LC_ALL=C awk '$3 == \"cifs\" { print $2 }' /proc/mounts) NCPMTAB=$(LC_ALL=C awk '$3 == \"ncpfs\" { print $2 }' /proc/mounts) GLUSTERFSMTAB=$(LC_ALL=C awk '$3 == \"fuse.glusterfs\" { print $2 }' /proc/mounts) NETDEVMTAB=$(LC_ALL=C awk '$4 ~ /_netdev/ && $2 != \"/\" { print $2 }' /etc/mtab) ALLNETDEVMTAB=\"$NFSMTAB $CIFSMTAB $NCPMTAB $GLUSTERFSMTAB $NETDEVMTAB\" } # Similar to __umount loop above, specialized for loopback devices __umount_loopback_loop() { local remaining devremaining sig= local retry=3 __find_mounts() { if [ \"$1\" = \"--netdev\" ] ; then __source_netdevs_mtab remaining= devremaining= local mount= netdev= _rest while read -r dev mount _rest ; do [ \"$dev\" = \"${dev##/dev/loop}\" ] && continue local back_file=$(losetup $dev | sed -e 's/^\\/dev\\/loop[0-9]\\+: \\[[0-9a-f]\\+\\]:[0-9]\\+ (\\(.*\\))$/\\1/') for netdev in $ALLNETDEVMTAB ; do local netdev_decoded= netdev=\"${netdev}/\" netdev_decoded=$(fstab_decode_str ${netdev}) if [ \"$mount\" != \"${mount##$netdev}\" ] || [ \"$back_file\" != \"${back_file##$netdev_decoded}\" ] ; then remaining=\"$remaining $mount\" #device might be mounted in other location, #but then losetup -d will be noop, so meh devremaining=\"$devremaining $dev\" continue 2 fi done done < /proc/mounts else remaining=$(awk '$1 ~ /^\\/dev\\/loop/ && $2 != \"/\" {print $2}' /proc/mounts) devremaining=$(awk '$1 ~ /^\\/dev\\/loop/ && $2 != \"/\" {print $1}' /proc/mounts) fi } __find_mounts $1 while [ -n \"$remaining\" -a \"$retry\" -gt 0 ]; do if [ \"$retry\" -eq 3 ]; then action $\"Unmounting loopback filesystems: \" \\ fstab-decode umount $remaining else action $\"Unmounting loopback filesystems (retry):\" \\ fstab-decode umount $remaining fi for dev in $devremaining ; do if [ \"$1\" = \"--netdev\" ] ; then #some loopdevices might be mounted on top of non-netdev #so ignore failures losetup -d $dev > /dev/null 2>&1 else losetup $dev > /dev/null 2>&1 && \\ action $\"Detaching loopback device $dev: \" \\ losetup -d $dev fi done #check what is still mounted __find_mounts $1 [ -z \"$remaining\" ] && break fstab-decode /sbin/fuser -k -m $sig $remaining >/dev/null sleep 3 retry=$(($retry -1)) sig=-9 done } # __proc_pids {program} [pidfile] # Set $pid to pids from /var/run* for {program}. $pid should be declared # local in the caller. # Returns LSB exit code for the 'status' action. __pids_var_run() { local base=${1##*/} local pid_file=${2:-/var/run/$base.pid} local pid_dir=$(/usr/bin/dirname $pid_file) local binary=$3 [ -d \"$pid_dir\" -a ! -r \"$pid_dir\" ] && return 4 pid= if [ -f \"$pid_file\" ] ; then local line p [ ! -r \"$pid_file\" ] && return 4 # \"user had insufficient privilege\" while : ; do read line [ -z \"$line\" ] && break for p in $line ; do if [ -z \"${p//[0-9]/}\" -a -d \"/proc/$p\" ] ; then if [ -n \"$binary\" ] ; then local b=$(readlink /proc/$p/exe | sed -e 's/\\s*(deleted)$//') [ \"$b\" != \"$binary\" ] && continue fi pid=\"$pid $p\" fi done done < \"$pid_file\" if [ -n \"$pid\" ]; then return 0 fi return 1 # \"Program is dead and /var/run pid file exists\" fi return 3 # \"Program is not running\" } # Output PIDs of matching processes, found using pidof __pids_pidof() { pidof -c -m -o $$ -o $PPID -o %PPID -x \"$1\" || \\ pidof -c -m -o $$ -o $PPID -o %PPID -x \"${1##*/}\" } # A function to start a program. daemon() { # Test syntax. local gotbase= force= nicelevel corelimit local pid base= user= nice= bg= pid_file= local cgroup= nicelevel=0 while [ \"$1\" != \"${1##[-+]}\" ]; do case $1 in '') echo $\"$0: Usage: daemon [+/-nicelevel] {program}\" \"[arg1]...\" return 1;; --check) base=$2 gotbase=\"yes\" shift 2 ;; --check=?*) base=${1#--check=} gotbase=\"yes\" shift ;; --user) user=$2 shift 2 ;; --user=?*) user=${1#--user=} shift ;; --pidfile) pid_file=$2 shift 2 ;; --pidfile=?*) pid_file=${1#--pidfile=} shift ;; --force) force=\"force\" shift ;; [-+][0-9]*) nice=\"nice -n $1\" shift ;; *) echo $\"$0: Usage: daemon [+/-nicelevel] {program}\" \"[arg1]...\" return 1;; esac done # Save basename. [ -z \"$gotbase\" ] && base=${1##*/} # See if it's already running. Look *only* at the pid file. __pids_var_run \"$base\" \"$pid_file\" [ -n \"$pid\" -a -z \"$force\" ] && return # make sure it doesn't core dump anywhere unless requested corelimit=\"ulimit -S -c ${DAEMON_COREFILE_LIMIT:-0}\" # if they set NICELEVEL in /etc/sysconfig/foo, honor it [ -n \"${NICELEVEL:-}\" ] && nice=\"nice -n $NICELEVEL\" # if they set CGROUP_DAEMON in /etc/sysconfig/foo, honor it if [ -n \"${CGROUP_DAEMON}\" ]; then if [ ! -x /bin/cgexec ]; then echo -n \"Cgroups not installed\"; warning echo else cgroup=\"/bin/cgexec\"; for i in $CGROUP_DAEMON; do cgroup=\"$cgroup -g $i\"; done fi fi # Echo daemon [ \"${BOOTUP:-}\" = \"verbose\" -a -z \"${LSB:-}\" ] && echo -n \" $base\" # And start it up. if [ -z \"$user\" ]; then $cgroup $nice /bin/bash -c \"$corelimit >/dev/null 2>&1 ; $*\" else $cgroup $nice runuser -s /bin/bash $user -c \"$corelimit >/dev/null 2>&1 ; $*\" fi [ \"$?\" -eq 0 ] && success $\"$base startup\" || failure $\"$base startup\" } # A function to stop a program. killproc() { local RC killlevel= base pid pid_file= delay try binary= RC=0; delay=3; try=0 # Test syntax. if [ \"$#\" -eq 0 ]; then echo $\"Usage: killproc [-p pidfile] [ -d delay] {program} [-signal]\" return 1 fi if [ \"$1\" = \"-p\" ]; then pid_file=$2 shift 2 fi if [ \"$1\" = \"-b\" ]; then if [ -z $pid_file ]; then echo $\"-b option can be used only with -p\" echo $\"Usage: killproc -p pidfile -b binary program\" return 1 fi binary=$2 shift 2 fi if [ \"$1\" = \"-d\" ]; then delay=$(echo $2 | awk -v RS=' ' -v IGNORECASE=1 '{if($1!~/^[0-9.]+[smhd]?$/) exit 1;d=$1~/s$|^[0-9.]*$/?1:$1~/m$/?60:$1~/h$/?60*60:$1~/d$/?24*60*60:-1;if(d==-1) exit 1;delay+=d*$1} END {printf(\"%d\",delay+0.5)}') if [ \"$?\" -eq 1 ]; then echo $\"Usage: killproc [-p pidfile] [ -d delay] {program} [-signal]\" return 1 fi shift 2 fi # check for second arg to be kill level [ -n \"${2:-}\" ] && killlevel=$2 # Save basename. base=${1##*/} # Find pid. __pids_var_run \"$1\" \"$pid_file\" \"$binary\" RC=$? if [ -z \"$pid\" ]; then if [ -z \"$pid_file\" ]; then pid=\"$(__pids_pidof \"$1\")\" else [ \"$RC\" = \"4\" ] && { failure $\"$base shutdown\" ; return $RC ;} fi fi # Kill it. if [ -n \"$pid\" ] ; then [ \"$BOOTUP\" = \"verbose\" -a -z \"${LSB:-}\" ] && echo -n \"$base \" if [ -z \"$killlevel\" ] ; then __kill_pids_term_kill -d $delay $pid RC=$? [ \"$RC\" -eq 0 ] && success $\"$base shutdown\" || failure $\"$base shutdown\" # use specified level only else if checkpid $pid; then kill $killlevel $pid >/dev/null 2>&1 RC=$? [ \"$RC\" -eq 0 ] && success $\"$base $killlevel\" || failure $\"$base $killlevel\" elif [ -n \"${LSB:-}\" ]; then RC=7 # Program is not running fi fi else if [ -n \"${LSB:-}\" -a -n \"$killlevel\" ]; then RC=7 # Program is not running else failure $\"$base shutdown\" RC=0 fi fi # Remove pid file if any. if [ -z \"$killlevel\" ]; then rm -f \"${pid_file:-/var/run/$base.pid}\" fi return $RC } # A function to find the pid of a program. Looks *only* at the pidfile pidfileofproc() { local pid # Test syntax. if [ \"$#\" = 0 ] ; then echo $\"Usage: pidfileofproc {program}\" return 1 fi __pids_var_run \"$1\" [ -n \"$pid\" ] && echo $pid return 0 } # A function to find the pid of a program. pidofproc() { local RC pid pid_file= # Test syntax. if [ \"$#\" = 0 ]; then echo $\"Usage: pidofproc [-p pidfile] {program}\" return 1 fi if [ \"$1\" = \"-p\" ]; then pid_file=$2 shift 2 fi fail_code=3 # \"Program is not running\" # First try \"/var/run/*.pid\" files __pids_var_run \"$1\" \"$pid_file\" RC=$? if [ -n \"$pid\" ]; then echo $pid return 0 fi [ -n \"$pid_file\" ] && return $RC __pids_pidof \"$1\" || return $RC } status() { local base pid lock_file= pid_file= binary= # Test syntax. if [ \"$#\" = 0 ] ; then echo $\"Usage: status [-p pidfile] {program}\" return 1 fi if [ \"$1\" = \"-p\" ]; then pid_file=$2 shift 2 fi if [ \"$1\" = \"-l\" ]; then lock_file=$2 shift 2 fi if [ \"$1\" = \"-b\" ]; then if [ -z $pid_file ]; then echo $\"-b option can be used only with -p\" echo $\"Usage: status -p pidfile -b binary program\" return 1 fi binary=$2 shift 2 fi base=${1##*/} # First try \"pidof\" __pids_var_run \"$1\" \"$pid_file\" \"$binary\" RC=$? if [ -z \"$pid_file\" -a -z \"$pid\" ]; then pid=\"$(__pids_pidof \"$1\")\" fi if [ -n \"$pid\" ]; then echo $\"${base} (pid $pid) is running...\" return 0 fi case \"$RC\" in 0) echo $\"${base} (pid $pid) is running...\" return 0 ;; 1) echo $\"${base} dead but pid file exists\" return 1 ;; 4) echo $\"${base} status unknown due to insufficient privileges.\" return 4 ;; esac if [ -z \"${lock_file}\" ]; then lock_file=${base} fi # See if /var/lock/subsys/${lock_file} exists if [ -f /var/lock/subsys/${lock_file} ]; then echo $\"${base} dead but subsys locked\" return 2 fi echo $\"${base} is stopped\" return 3 } echo_success() { [ \"$BOOTUP\" = \"color\" ] && $MOVE_TO_COL echo -n \"[\" [ \"$BOOTUP\" = \"color\" ] && $SETCOLOR_SUCCESS echo -n $\" OK \" [ \"$BOOTUP\" = \"color\" ] && $SETCOLOR_NORMAL echo -n \"]\" echo -ne \"\\r\" return 0 } echo_failure() { [ \"$BOOTUP\" = \"color\" ] && $MOVE_TO_COL echo -n \"[\" [ \"$BOOTUP\" = \"color\" ] && $SETCOLOR_FAILURE echo -n $\"FAILED\" [ \"$BOOTUP\" = \"color\" ] && $SETCOLOR_NORMAL echo -n \"]\" echo -ne \"\\r\" return 1 } echo_passed() { [ \"$BOOTUP\" = \"color\" ] && $MOVE_TO_COL echo -n \"[\" [ \"$BOOTUP\" = \"color\" ] && $SETCOLOR_WARNING echo -n $\"PASSED\" [ \"$BOOTUP\" = \"color\" ] && $SETCOLOR_NORMAL echo -n \"]\" echo -ne \"\\r\" return 1 } echo_warning() { [ \"$BOOTUP\" = \"color\" ] && $MOVE_TO_COL echo -n \"[\" [ \"$BOOTUP\" = \"color\" ] && $SETCOLOR_WARNING echo -n $\"WARNING\" [ \"$BOOTUP\" = \"color\" ] && $SETCOLOR_NORMAL echo -n \"]\" echo -ne \"\\r\" return 1 } # Inform the graphical boot of our current state update_boot_stage() { if [ -x /bin/plymouth ]; then /bin/plymouth --update=\"$1\" fi return 0 } # Log that something succeeded success() { [ \"$BOOTUP\" != \"verbose\" -a -z \"${LSB:-}\" ] && echo_success return 0 } # Log that something failed failure() { local rc=$? [ \"$BOOTUP\" != \"verbose\" -a -z \"${LSB:-}\" ] && echo_failure [ -x /bin/plymouth ] && /bin/plymouth --details return $rc } # Log that something passed, but may have had errors. Useful for fsck passed() { local rc=$? [ \"$BOOTUP\" != \"verbose\" -a -z \"${LSB:-}\" ] && echo_passed return $rc } # Log a warning warning() { local rc=$? [ \"$BOOTUP\" != \"verbose\" -a -z \"${LSB:-}\" ] && echo_warning return $rc } # Run some action. Log its output. action() { local STRING rc STRING=$1 echo -n \"$STRING \" shift \"$@\" && success $\"$STRING\" || failure $\"$STRING\" rc=$? echo return $rc } # Run some action. Silently. action_silent() { local STRING rc STRING=$1 echo -n \"$STRING \" shift \"$@\" >/dev/null && success $\"$STRING\" || failure $\"$STRING\" rc=$? echo return $rc } # returns OK if $1 contains $2 strstr() { [ \"${1#*$2*}\" = \"$1\" ] && return 1 return 0 } # Confirm whether we really want to run this service confirm() { [ -x /bin/plymouth ] && /bin/plymouth --hide-splash while : ; do echo -n $\"Start service $1 (Y)es/(N)o/(C)ontinue? [Y] \" read answer if strstr $\"yY\" \"$answer\" || [ \"$answer\" = \"\" ] ; then return 0 elif strstr $\"cC\" \"$answer\" ; then rm -f /var/run/confirm [ -x /bin/plymouth ] && /bin/plymouth --show-splash return 2 elif strstr $\"nN\" \"$answer\" ; then return 1 fi done } # resolve a device node to its major:minor numbers in decimal or hex get_numeric_dev() { ( fmt=\"%d:%d\" if [ \"$1\" == \"hex\" ]; then fmt=\"%x:%x\" fi ls -lH \"$2\" | awk '{ sub(/,/, \"\", $5); printf(\"'\"$fmt\"'\", $5, $6); }' ) 2>/dev/null } # Check whether file $1 is a backup or rpm-generated file and should be ignored is_ignored_file() { case \"$1\" in *~ | *.bak | *.orig | *.rpmnew | *.rpmorig | *.rpmsave) return 0 ;; esac return 1 } # Evaluate shvar-style booleans is_true() { case \"$1\" in [tT] | [yY] | [yY][eE][sS] | [tT][rR][uU][eE]) return 0 ;; esac return 1 } # Evaluate shvar-style booleans is_false() { case \"$1\" in [fF] | [nN] | [nN][oO] | [fF][aA][lL][sS][eE]) return 0 ;; esac return 1 } # Apply sysctl settings, including files in /etc/sysctl.d apply_sysctl() { sysctl -e -p /etc/sysctl.conf >/dev/null 2>&1 for file in /etc/sysctl.d/* ; do is_ignored_file \"$file\" && continue test -f \"$file\" && sysctl -e -p \"$file\" >/dev/null 2>&1 done } key_is_random() { [ \"$1\" = \"/dev/urandom\" -o \"$1\" = \"/dev/hw_random\" \\ -o \"$1\" = \"/dev/random\" ] } find_crypto_mount_point() { local fs_spec fs_file fs_vfstype remaining_fields local fs while read fs_spec fs_file remaining_fields; do if [ \"$fs_spec\" = \"/dev/mapper/$1\" ]; then echo $fs_file break; fi done < /etc/fstab } # Because of a chicken/egg problem, init_crypto must be run twice. /var may be # encrypted but /var/lib/random-seed is needed to initialize swap. init_crypto() { local have_random dst src key opt mode owner params makeswap skip arg opt local param value rc ret mke2fs mdir prompt mount_point ret=0 have_random=$1 while read dst src key opt; do [ -z \"$dst\" -o \"${dst#\\#}\" != \"$dst\" ] && continue [ -b \"/dev/mapper/$dst\" ] && continue; if [ \"$have_random\" = 0 ] && key_is_random \"$key\"; then continue fi if [ -n \"$key\" -a \"x$key\" != \"xnone\" ]; then if test -e \"$key\" ; then owner=$(ls -l $key | (read a b owner rest; echo $owner)) if ! key_is_random \"$key\"; then mode=$(ls -l \"$key\" | cut -c 5-10) if [ \"$mode\" != \"------\" ]; then echo $\"INSECURE MODE FOR $key\" fi fi if [ \"$owner\" != root ]; then echo $\"INSECURE OWNER FOR $key\" fi else echo $\"Key file for $dst not found, skipping\" ret=1 continue fi else key=\"\" fi params=\"\" makeswap=\"\" mke2fs=\"\" skip=\"\" # Parse the src field for UUID= and convert to real device names if [ \"${src%%=*}\" == \"UUID\" ]; then src=$(/sbin/blkid -t \"$src\" -l -o device) elif [ \"${src/^\\/dev\\/disk\\/by-uuid\\/}\" != \"$src\" ]; then src=$(__readlink $src) fi # Is it a block device? [ -b \"$src\" ] || continue # Is it already a device mapper slave? (this is gross) devesc=${src##/dev/} devesc=${devesc//\\//!} for d in /sys/block/dm-*/slaves ; do [ -e $d/$devesc ] && continue 2 done # Parse the options field, convert to cryptsetup parameters and # contruct the command line while [ -n \"$opt\" ]; do arg=${opt%%,*} opt=${opt##$arg} opt=${opt##,} param=${arg%%=*} value=${arg##$param=} case \"$param\" in cipher) params=\"$params -c $value\" if [ -z \"$value\" ]; then echo $\"$dst: no value for cipher option, skipping\" skip=\"yes\" fi ;; size) params=\"$params -s $value\" if [ -z \"$value\" ]; then echo $\"$dst: no value for size option, skipping\" skip=\"yes\" fi ;; hash) params=\"$params -h $value\" if [ -z \"$value\" ]; then echo $\"$dst: no value for hash option, skipping\" skip=\"yes\" fi ;; verify) params=\"$params -y\" ;; swap) makeswap=yes ;; tmp) mke2fs=yes esac done if [ \"$skip\" = \"yes\" ]; then ret=1 continue fi if [ -z \"$makeswap\" ] && cryptsetup isLuks \"$src\" 2>/dev/null ; then if key_is_random \"$key\"; then echo $\"$dst: LUKS requires non-random key, skipping\" ret=1 continue fi if [ -n \"$params\" ]; then echo \"$dst: options are invalid for LUKS partitions,\" \\ \"ignoring them\" fi if [ -n \"$key\" ]; then /sbin/cryptsetup -d $key luksOpen \"$src\" \"$dst\" <&1 2>/dev/null && success || failure rc=$? else mount_point=\"$(find_crypto_mount_point $dst)\" [ -n \"$mount_point\" ] || mount_point=${src##*/} prompt=$(printf $\"%s is password protected\" \"$mount_point\") plymouth ask-for-password --prompt \"$prompt\" --command=\"/sbin/cryptsetup luksOpen -T1 $src $dst\" <&1 rc=$? fi else [ -z \"$key\" ] && plymouth --hide-splash /sbin/cryptsetup $params ${key:+-d $key} create \"$dst\" \"$src\" <&1 2>/dev/null && success || failure rc=$? [ -z \"$key\" ] && plymouth --show-splash fi if [ $rc -ne 0 ]; then ret=1 continue fi if [ -b \"/dev/mapper/$dst\" ]; then if [ \"$makeswap\" = \"yes\" ]; then mkswap \"/dev/mapper/$dst\" 2>/dev/null >/dev/null fi if [ \"$mke2fs\" = \"yes\" ]; then if mke2fs \"/dev/mapper/$dst\" 2>/dev/null >/dev/null \\ && mdir=$(mktemp -d /tmp/mountXXXXXX); then mount \"/dev/mapper/$dst\" \"$mdir\" && chmod 1777 \"$mdir\" umount \"$mdir\" rmdir \"$mdir\" fi fi fi done < /etc/crypttab return $ret } # A sed expression to filter out the files that is_ignored_file recognizes __sed_discard_ignored_files='/\\(~\\|\\.bak\\|\\.orig\\|\\.rpmnew\\|\\.rpmorig\\|\\.rpmsave\\)$/d' #if we have privileges lets log to kmsg, otherwise to stderr if strstr \"$(cat /proc/cmdline)\" \"rc.debug\"; then [ -w /dev/kmsg ] && exec 30>/dev/kmsg && BASH_XTRACEFD=30 set -x fi"
        },
        {
            "filename": "file_406.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\service\\file_406.sh",
            "content": "#!/bin/sh # From-release: CentOS release 6.8 (Final) # From-file: /lib/lsb/init-functions # LSB initscript functions, as defined in the LSB Spec 1.1.0 # # Lawrence Lim <llim@redhat.com> - Tue, 26 June 2007 # Updated to the latest LSB 3.1 spec # http://refspecs.freestandards.org/LSB_3.1.0/LSB-Core-generic/LSB-Core-generic_lines.txt start_daemon () { /etc/redhat-lsb/lsb_start_daemon \"$@\" } killproc () { /etc/redhat-lsb/lsb_killproc \"$@\" } pidofproc () { /etc/redhat-lsb/lsb_pidofproc \"$@\" } log_success_msg () { /etc/redhat-lsb/lsb_log_message success \"$@\" } log_failure_msg () { /etc/redhat-lsb/lsb_log_message failure \"$@\" } log_warning_msg () { /etc/redhat-lsb/lsb_log_message warning \"$@\" }"
        },
        {
            "filename": "file_407.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\service\\file_407.sh",
            "content": "#!/usr/bin/env bash # /lib/lsb/init-functions for Debian -*- shell-script -*- # #Copyright (c) 2002-08 Chris Lawrence #All rights reserved. # #Redistribution and use in source and binary forms, with or without #modification, are permitted provided that the following conditions #are met: #1. Redistributions of source code must retain the above copyright # notice, this list of conditions and the following disclaimer. #2. Redistributions in binary form must reproduce the above copyright # notice, this list of conditions and the following disclaimer in the # documentation and/or other materials provided with the distribution. #3. Neither the name of the author nor the names of other contributors # may be used to endorse or promote products derived from this software # without specific prior written permission. # #THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR #IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED #WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE #ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE #LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR #CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF #SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR #BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, #WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE #OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, #EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. start_daemon () { local force nice pidfile exec args OPTIND force=\"\" nice=0 pidfile=/dev/null OPTIND=1 while getopts fn:p: opt ; do case \"$opt\" in f) force=\"force\";; n) nice=\"$OPTARG\";; p) pidfile=\"$OPTARG\";; esac done shift $(($OPTIND - 1)) if [ \"$1\" = '--' ]; then shift fi exec=\"$1\"; shift args=\"--start --nicelevel $nice --quiet --oknodo\" if [ \"$force\" ]; then /sbin/start-stop-daemon $args \\ --chdir \"$PWD\" --startas $exec --pidfile /dev/null -- \"$@\" elif [ $pidfile ]; then /sbin/start-stop-daemon $args \\ --chdir \"$PWD\" --exec $exec --oknodo --pidfile \"$pidfile\" -- \"$@\" else /sbin/start-stop-daemon $args --chdir \"$PWD\" --exec $exec -- \"$@\" fi } pidofproc () { local pidfile base status specified pid OPTIND pidfile= specified= OPTIND=1 while getopts p: opt ; do case \"$opt\" in p) pidfile=\"$OPTARG\" specified=\"specified\" ;; esac done shift $(($OPTIND - 1)) if [ $# -ne 1 ]; then echo \"$0: invalid arguments\" >&2 return 4 fi base=${1##*/} if [ ! \"$specified\" ]; then pidfile=\"/var/run/$base.pid\" fi if [ -n \"${pidfile:-}\" ]; then if [ -e \"$pidfile\" ]; then if [ -r \"$pidfile\" ]; then read pid < \"$pidfile\" if [ -n \"${pid:-}\" ]; then if $(kill -0 \"${pid:-}\" 2> /dev/null); then echo \"$pid\" || true return 0 elif ps \"${pid:-}\" >/dev/null 2>&1; then echo \"$pid\" || true return 0 # program is running, but not owned by this user else return 1 # program is dead and /var/run pid file exists fi fi else return 4 # pid file not readable, hence status is unknown. fi else # pid file doesn't exist, try to find the pid nevertheless if [ -x /bin/pidof ] && [ ! \"$specified\" ]; then status=\"0\" /bin/pidof -o %PPID -x $1 || status=\"$?\" if [ \"$status\" = 1 ]; then return 3 # program is not running fi return 0 fi return 3 # specified pid file doesn't exist, program probably stopped fi fi if [ \"$specified\" ]; then return 3 # almost certain it's not running fi return 4 # Unable to determine status } # start-stop-daemon uses the same algorithm as \"pidofproc\" above. killproc () { local pidfile sig status base name_param is_term_sig OPTIND pidfile= name_param= is_term_sig= OPTIND=1 while getopts p: opt ; do case \"$opt\" in p) pidfile=\"$OPTARG\";; esac done shift $(($OPTIND - 1)) base=${1##*/} if [ ! $pidfile ]; then name_param=\"--name $base --pidfile /var/run/$base.pid\" else name_param=\"--pidfile $pidfile\" fi sig=$(echo ${2:-} | sed -e 's/^-\\(.*\\)/\\1/') sig=$(echo $sig | sed -e 's/^SIG\\(.*\\)/\\1/') if [ \"$sig\" = 15 ] || [ \"$sig\" = TERM ]; then is_term_sig=\"terminate_signal\" fi status=0 if [ ! \"$is_term_sig\" ]; then if [ -n \"$sig\" ]; then /sbin/start-stop-daemon --stop --signal \"$sig\" \\ --quiet $name_param || status=\"$?\" else /sbin/start-stop-daemon --stop \\ --retry 5 \\ --quiet $name_param || status=\"$?\" fi else /sbin/start-stop-daemon --stop --quiet \\ --oknodo $name_param || status=\"$?\" fi if [ \"$status\" = 1 ]; then if [ -z \"$sig\" ]; then return 0 fi return 3 # program is not running fi if [ \"$status\" = 0 ] && [ \"$is_term_sig\" ] && [ \"$pidfile\" ]; then pidofproc -p \"$pidfile\" \"$1\" >/dev/null || rm -f \"$pidfile\" fi return 0 } # Return LSB status status_of_proc () { local pidfile daemon name status OPTIND pidfile= OPTIND=1 while getopts p: opt ; do case \"$opt\" in p) pidfile=\"$OPTARG\";; esac done shift $(($OPTIND - 1)) if [ -n \"$pidfile\" ]; then pidfile=\"-p $pidfile\" fi daemon=\"$1\" name=\"$2\" status=\"0\" pidofproc $pidfile $daemon >/dev/null || status=\"$?\" if [ \"$status\" = 0 ]; then log_success_msg \"$name is running\" return 0 elif [ \"$status\" = 4 ]; then log_failure_msg \"could not access PID file for $name\" return $status else log_failure_msg \"$name is not running\" return $status fi } log_use_fancy_output () { TPUT=/usr/bin/tput EXPR=/usr/bin/expr if [ -t 1 ] && [ \"x${TERM:-}\" != \"x\" ] && [ \"x${TERM:-}\" != \"xdumb\" ] && [ -x $TPUT ] && [ -x $EXPR ] && $TPUT hpa 60 >/dev/null 2>&1 && $TPUT setaf 1 >/dev/null 2>&1 then [ -z $FANCYTTY ] && FANCYTTY=1 || true else FANCYTTY=0 fi case \"$FANCYTTY\" in 1|Y|yes|true) true;; *) false;; esac } log_success_msg () { if [ -n \"${1:-}\" ]; then log_begin_msg $@ fi log_end_msg 0 } log_failure_msg () { if [ -n \"${1:-}\" ]; then log_begin_msg $@ \"...\" fi log_end_msg 1 || true } log_warning_msg () { if [ -n \"${1:-}\" ]; then log_begin_msg $@ \"...\" fi log_end_msg 255 || true } # # NON-LSB HELPER FUNCTIONS # # int get_lsb_header_val (char *scriptpathname, char *key) get_lsb_header_val () { if [ ! -f \"$1\" ] || [ -z \"${2:-}\" ]; then return 1 fi LSB_S=\"### BEGIN INIT INFO\" LSB_E=\"### END INIT INFO\" sed -n \"/$LSB_S/,/$LSB_E/ s/# $2: \\(.*\\)/\\1/p\" $1 } # If the currently running init daemon is upstart, return zero; if the # calling init script belongs to a package which also provides a native # upstart job, it should generally exit non-zero in this case. init_is_upstart() { if [ -x /sbin/initctl ] && /sbin/initctl version 2>/dev/null | /bin/grep -q upstart; then return 0 fi return 1 } # int log_begin_message (char *message) log_begin_msg () { log_begin_msg_pre \"$@\" if [ -z \"${1:-}\" ]; then return 1 fi echo -n \"$@\" || true log_begin_msg_post \"$@\" } # Sample usage: # log_daemon_msg \"Starting GNOME Login Manager\" \"gdm\" # # On Debian, would output \"Starting GNOME Login Manager: gdm\" # On Ubuntu, would output \" * Starting GNOME Login Manager...\" # # If the second argument is omitted, logging suitable for use with # log_progress_msg() is used: # # log_daemon_msg \"Starting remote filesystem services\" # # On Debian, would output \"Starting remote filesystem services:\" # On Ubuntu, would output \" * Starting remote filesystem services...\" log_daemon_msg () { if [ -z \"${1:-}\" ]; then return 1 fi log_daemon_msg_pre \"$@\" if [ -z \"${2:-}\" ]; then echo -n \"$1:\" || true return fi echo -n \"$1: $2\" || true log_daemon_msg_post \"$@\" } # #319739 # # Per policy docs: # # log_daemon_msg \"Starting remote file system services\" # log_progress_msg \"nfsd\"; start-stop-daemon --start --quiet nfsd # log_progress_msg \"mountd\"; start-stop-daemon --start --quiet mountd # log_progress_msg \"ugidd\"; start-stop-daemon --start --quiet ugidd # log_end_msg 0 # # You could also do something fancy with log_end_msg here based on the # return values of start-stop-daemon; this is left as an exercise for # the reader... # # On Ubuntu, one would expect log_progress_msg to be a no-op. log_progress_msg () { if [ -z \"${1:-}\" ]; then return 1 fi echo -n \" $@\" || true } # int log_end_message (int exitstatus) log_end_msg () { # If no arguments were passed, return if [ -z \"${1:-}\" ]; then return 1 fi local retval retval=$1 log_end_msg_pre \"$@\" # Only do the fancy stuff if we have an appropriate terminal # and if /usr is already mounted if log_use_fancy_output; then RED=$( $TPUT setaf 1) YELLOW=$( $TPUT setaf 3) NORMAL=$( $TPUT op) else RED='' YELLOW='' NORMAL='' fi if [ $1 -eq 0 ]; then echo \".\" || true elif [ $1 -eq 255 ]; then /bin/echo -e \" ${YELLOW}(warning).${NORMAL}\" || true else /bin/echo -e \" ${RED}failed!${NORMAL}\" || true fi log_end_msg_post \"$@\" return $retval } log_action_msg () { log_action_msg_pre \"$@\" echo \"$@.\" || true log_action_msg_post \"$@\" } log_action_begin_msg () { log_action_begin_msg_pre \"$@\" echo -n \"$@...\" || true log_action_begin_msg_post \"$@\" } log_action_cont_msg () { echo -n \"$@...\" || true } log_action_end_msg () { local end log_action_end_msg_pre \"$@\" if [ -z \"${2:-}\" ]; then end=\".\" else end=\" ($2).\" fi if [ $1 -eq 0 ]; then echo \"done${end}\" || true else if log_use_fancy_output; then RED=$( $TPUT setaf 1) NORMAL=$( $TPUT op) /bin/echo -e \"${RED}failed${end}${NORMAL}\" || true else echo \"failed${end}\" || true fi fi log_action_end_msg_post \"$@\" } # Pre&Post empty function declaration, to be overriden from /lib/lsb/init-functions.d/* log_daemon_msg_pre () { :; } log_daemon_msg_post () { :; } log_begin_msg_pre () { :; } log_begin_msg_post () { :; } log_end_msg_pre () { :; } log_end_msg_post () { :; } log_action_msg_pre () { :; } log_action_msg_post () { :; } log_action_begin_msg_pre () { :; } log_action_begin_msg_post () { :; } log_action_end_msg_pre () { :; } log_action_end_msg_post () { :; } # Include hooks from other packages in /lib/lsb/init-functions.d for hook in $(run-parts --lsbsysinit --list /lib/lsb/init-functions.d 2>/dev/null); do [ -r $hook ] && . $hook || true done FANCYTTY= [ -e /etc/lsb-base-logging.sh ] && . /etc/lsb-base-logging.sh || true"
        },
        {
            "filename": "file_408.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\file_408.sh",
            "content": "#!/usr/bin/env bash #!/usr/bin/env sh #!/bin/sh # # Function description: # # About Interactive and non-interactive shells and scripts # Interactive script to be one that requires input from the user, # usually with read statements or positional parameters # Non-interactive shells run without human intervention. # Many administrative and system maintenance scripts are likewise non-interactive. # # Usage: # shell_script_name.sh parameters # # Birth Time: # date +'%Y-%m-%d %H:%M:%S.%N %z' # # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong #"
        },
        {
            "filename": "file_409.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_409.sh",
            "content": "#!/bin/bash begin_time=$(date +%s) sleep 2 end_time=$(date +%s) elapsed_time=$((end_time - begin_time)) echo ${elapsed_time }"
        },
        {
            "filename": "file_410.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_410.sh",
            "content": "#!/bin/bash ### DO NOT MODIFY THE FOLLOWING PART, UNLESS YOU KNOW WHAT IT MEANS ### echo_r () { [[ $# -ne 1 ]] && return 0 echo -e \"\\033[31m$1\\033[0m\" } echo_g () { [[ $# -ne 1 ]] && return 0 echo -e \"\\033[32m$1\\033[0m\" } echo_y () { [[ $# -ne 1 ]] && return 0 echo -e \"\\033[33m$1\\033[0m\" } echo_b () { [[ $# -ne 1 ]] && return 0 echo -e \"\\033[34m$1\\033[0m\" } usage() { echo \"Usage: $0 argument [argument2...]\" } # [ $# -lt 1 ] && usage && exit"
        },
        {
            "filename": "file_411.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_411.sh",
            "content": "#!/bin/bash function cecho { while [[ \"$1\" ]]; do case \"$1\" in -normal) color=\"\\033[00m\" ;; -black) color=\"\\033[30;01m\" ;; -red) color=\"\\033[31;01m\" ;; -green) color=\"\\033[32;01m\" ;; -yellow) color=\"\\033[33;01m\" ;; -blue) color=\"\\033[34;01m\" ;; -magenta) color=\"\\033[35;01m\" ;; -cyan) color=\"\\033[36;01m\" ;; -white) color=\"\\033[37;01m\" ;; -n) one_line=1; shift ; continue ;; *) echo -n \"$1\"; shift ; continue ;; esac shift echo -en \"$color\" echo -en \"$1\" echo -en \"\\033[00m\" shift done if [[ ! $one_line ]]; then echo fi }"
        },
        {
            "filename": "file_412.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_412.sh",
            "content": "#!/bin/bash # refer to: https://raw.githubusercontent.com/springlie/cecho/master/cecho.sh cecho() { #FOREGROUND local FG_BLACK=\"\\e[30m\" local FG_RED=\"\\e[31m\" local FG_GREEN=\"\\e[32m\" local FG_YELLOW=\"\\e[33m\" local FG_BLUE=\"\\e[34m\" local FG_PURPLE=\"\\e[35m\" local FG_CYAN=\"\\e[36m\" local FG_WHITE=\"\\e[37m\" #BACKGROUND local BG_BLACK=\"\\e[40m\" local BG_RED=\"\\e[41m\" local BG_GREEN=\"\\e[42m\" local BG_YELLOW=\"\\e[43m\" local BG_BLUE=\"\\e[44m\" local BG_PURPLE=\"\\e[45m\" local BG_CYAN=\"\\e[46m\" local BG_WHITE=\"\\e[47m\" #ACTION local DONE=\"\\e[0m\" local HIGHLIGHT=\"\\e[1m\" local UNDERLINE=\"\\e[4m\" local BLINK=\"\\e[5m\" local REVERSE=\"\\e[7m\" local INVISIBLE=\"\\e[8m\" }"
        },
        {
            "filename": "file_413.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_413.sh",
            "content": "#!/usr/bin/env bash # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [[ $# -ne 1 ]] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [[ $# -ne 1 ]] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [[ $# -ne 1 ]] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter"
        },
        {
            "filename": "file_414.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_414.sh",
            "content": "#!/bin/bash # resolve links - $0 may be a symbolic link PRG=\"$0\" while [[ -h \"$PRG\" ]]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"`"
        },
        {
            "filename": "file_415.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_415.sh",
            "content": "#!/bin/bash # resolve links - $0 may be a symbolic link # learning from ActiveMQ # get a canonical path, macosx and slowlaris does not support readlink -f :-) pathCanonical() { local dst=\"${1}\" while [[ -h \"${dst}\" ]] ; do ls=`ls -ld \"${dst}\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then dst=\"$link\" else dst=\"`dirname \"${dst}\"`/$link\" fi done local bas=\"`basename \"${dst}\"`\" local dir=\"`dirname \"${dst}\"`\" if [[ \"$bas\" != \"$dir\" ]]; then dst=\"`pathCanonical \"$dir\"`/$bas\" fi echo \"${dst}\" | sed -e 's#//#/#g' -e 's#/\\./#/#g' -e 's#/[^/]*/\\.\\./#/#g' } # a simple helper to get the activemq installation dir getActiveMQHome(){ # get the real path to the binary local REAL_BIN=\"`pathCanonical $0`\" local REAL_DIR=\"`dirname $REAL_BIN`/../\" REAL_DIR=\"`cd $REAL_DIR && pwd -P`\" if [[ -z \"$REAL_DIR\" ]];then echo 'ERROR: unable to find real installation path fo activemq, you have to define ACTIVEMQ_HOME manually in the config' >&2 exit 1 fi echo \"$REAL_DIR/\" } # Active MQ installation dir if [[ -z \"$ACTIVEMQ_HOME\" ]] ; then ACTIVEMQ_HOME=\"`getActiveMQHome`\" fi"
        },
        {
            "filename": "file_416.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_416.sh",
            "content": "#!/bin/sh # Mode1: all line error will cause exit immediately set -e # set -e # Exit immediately if a pipeline (which may consist of a single simple command), a subshell command enclosed in parentheses, or one of the commands # executed as part of a command list enclosed by braces (see SHELL GRAMMAR above) exits with a non-zero status. The shell does not exit if the command # that fails is part of the command list immediately following a while or until keyword, part of the test following the if or elif reserved words, part # of any command executed in a && or \u2502\u2502 list except the command following the final && or \u2502\u2502, any command in a pipeline but the last, or if the com- # mand\u2019s return value is being inverted with !. A trap on ERR, if set, is executed before the shell exits. This option applies to the shell environ- # ment and each subshell environment separately (see COMMAND EXECUTION ENVIRONMENT above), and may cause subshells to exit before executing all the # commands in the subshell. # Mode2: all line error will cause exit immediately AND all vars variable or parameter must be declared set -eu # set -e # Exit immediately if a pipeline (which may consist of a single simple command), a subshell command enclosed in parentheses, or one of the commands # executed as part of a command list enclosed by braces (see SHELL GRAMMAR above) exits with a non-zero status. The shell does not exit if the command # that fails is part of the command list immediately following a while or until keyword, part of the test following the if or elif reserved words, part # of any command executed in a && or \u2502\u2502 list except the command following the final && or \u2502\u2502, any command in a pipeline but the last, or if the com- # mand\u2019s return value is being inverted with !. A trap on ERR, if set, is executed before the shell exits. This option applies to the shell environ- # ment and each subshell environment separately (see COMMAND EXECUTION ENVIRONMENT above), and may cause subshells to exit before executing all the # commands in the subshell. # set -u # Treat unset variables and parameters other than the special parameters \"@\" and \"*\" as an error when performing parameter expansion. If expansion is # attempted on an unset variable or parameter, the shell prints an error message, and, if not interactive, exits with a non-zero status. # Following Mode1 or Mode2: refer to next comment [[ -n \"$ENABLE_DEBUG_MODE\" ]] && set -x # set -x # After expanding each simple command, for command, case command, select command, or arithmetic for command, display the expanded value of PS4, fol- # lowed by the command and its expanded arguments or associated word list."
        },
        {
            "filename": "file_417.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_417.sh",
            "content": "#!/usr/bin/env bash # # Function description: # Use this script to initialize system after full refresh installation # # Usage: # bash centos6-init.sh # # Birth Time: # 2016-05-17 10:19:33.005064327 +0800 # # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong # # debug option #_XTRACE_FUNCTIONS=$(set +o | grep xtrace) #set -o xtrace # define user friendly messages header=\" Use this script to initialize system after full refresh installation \" # user defined variables user_defined_=\"\" # end user defined variables # pretreatment # end pretreatment # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [[ -h \"$PRG\" ]]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [[ $# -ne 1 ]] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [[ $# -ne 1 ]] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [[ $# -ne 1 ]] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple: Debug Level 2 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [[ $UID -ne 0 ]]; then echo_y \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options.\" echo_y \"Retry to using \\\"sudo bash $0 $@\\\".\" fi command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } check_command_can_be_execute(){ [[ $# -ne 1 ]] && return 1 command_exists $1 } check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [[ ${retval} -ne 0 ]] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [[ ${retval} -eq 0 ]]; then echo_g \"Check network connectivity passed! \" fi } check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [[ -f /etc/resolv.conf ]] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" return 0 fi } function main(){ lock_filename=\"lock_$$_$RANDOM\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT # Just a test for call itself, comment it if [[ $# -ne 1 ]]; then [[ ! -x ${WORKDIR}/`basename $0` ]] && chmod +x ${WORKDIR}/`basename $0` test -z ${header} || echo_b \"$header\" ${WORKDIR}/`basename $0` deploy exit 0 fi case $1 in deploy) deploy ;; rollback) rollback ;; destroy) destroy ;; help|*) echo \"Usage: $0 {deploy|rollback|destroy} with $0 itself\" exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option #${_XTRACE_FUNCTIONS}"
        },
        {
            "filename": "file_418.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_418.sh",
            "content": "#!/bin/bash # Name: doSomething.sh # Execute this shell script to # Do NOT modify anything expect for \"user defined variables\" unless you know what it means and what are you doing. # debug option #_XTRACE_FUNCTIONS=$(set +o | grep xtrace) #set -o xtrace # define user friendly messages header=\" \" # user defined variables user_defined_=\"\" # end user defined variables # pretreatment # end pretreatment # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } check_command_can_be_execute(){ [ $# -ne 1 ] && return 1 command_exists $1 } check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" fi } check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" return 0 fi } function checkOtherDependencies() { echo_b \"Checking other dependencies for deploy procedure... \" echo_b \"\\tChecking user customized variables...\" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi echo_g \"\\tChecking user customized variables passed! \" echo_b \"\\tChecking disk space available...\" disk_space_available=`df ${WORKDIR} | tail -n1 | awk '{print $(NF-2)}'` if [[ ${disk_space_available} -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 else echo_g \"\\tChecking disk space available passed! \" fi echo_g \"All required dependencies check passed! \" } function main(){ lock_filename=\"lock_$$_$RANDOM\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT # Just a test for call itself, comment it if [[ $# -ne 1 ]]; then [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` test -z ${header} || echo_b \"$header\" ${WORKDIR}/`basename $0` deploy exit 0 fi case $1 in deploy) deploy ;; rollback) rollback ;; destroy) destroy ;; help|*) echo \"Usage: $0 {deploy|rollback|destroy} with $0 itself\" exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option #${_XTRACE_FUNCTIONS}"
        },
        {
            "filename": "file_419.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_419.sh",
            "content": "#!/bin/bash # Name: doDeploy.sh # Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. # Do NOT modify anything expect for \"user defined variables\" unless you know what it means and what are you doing. # debug option, if you want see what command is executing, then uncomment next 2 lines below and last line at bottom. #_XTRACE_FUNCTIONS=$(set +o | grep xtrace) #set -o xtrace # define user friendly messages header=\" Function: Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. License: Open source software \" # user defined variables # Where to get source code project_clone_depends_1=\"ssh://git@git.example.com:18082/core/business-service-base.git\" project_clone=\"ssh://git@git.example.com:18082/core/business-service-core.git\" deploy_target_host_ip=\"10.6.28.135\" #project_top_directory_to_target_host=\"/data/docker/business-service/bs-core-01\" #docker_container_name=\"bs-core-01\" project_top_directory_to_target_host=\"/tmp/deploy_test_target\" docker_container_name=\"\" # if you using a docker container other than a startup script located in sourcecode/bin/startup.sh, then set this to docker container name project_conf_directory=\"\" # if you do NOT want to use configurations from deploy target, you should set this variable to where pointed to config files # Setting how many days do you want save old releases, default is 10 days save_old_releases_for_days=10 # end user defined variables # pretreatment test -z ${project_clone_depends_1} || project_clone_target_depends_1=\"`echo ${project_clone_depends_1} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_target=\"`echo ${project_clone} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_repository_name=${project_clone_target} # end pretreatment # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } check_command_can_be_execute(){ [ $# -ne 1 ] && return 1 command_exists $1 } check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" fi } check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" return 0 fi } function checkOtherDependencies() { echo_b \"Checking other dependencies for deploy procedure... \" echo_b \"\\tChecking user customized variables...\" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z ${project_clone} ]]; then echo_r \"Error: project_clone is undefined! \" exit 1 elif [[ -z ${deploy_target_host_ip} ]]; then echo_r \"Error: deploy_target_host_ip is undefined! \" exit 1 elif [[ -z ${project_top_directory_to_target_host} ]]; then echo_r \"Error: project_top_directory_to_target_host is undefined! \" exit 1 fi echo_g \"\\tChecking user customized variables passed! \" echo_b \"\\tChecking disk space available...\" disk_space_available=`df ${WORKDIR} | tail -n1 | awk '{print $(NF-2)}'` if [[ ${disk_space_available} -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 else echo_g \"\\tChecking disk space available passed! \" fi echo_g \"All required dependencies check passed! \" } function setDirectoryStructureOnLocalHost() { if [ -f ${WORKDIR}/.capistrano_ds_lock ];then echo_g \"Set directory structure has been done, skipping. \" return fi echo_b \"Setting directory structure... \" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branch names or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy [ ! -d ${WORKDIR}/release ] && mkdir ${WORKDIR}/release [ ! -d ${WORKDIR}/repository ] && mkdir ${WORKDIR}/repository [ ! -d ${WORKDIR}/share ] && mkdir ${WORKDIR}/share # end directories structure # Additional directories structure for full deploy operation # for backup remote host config file [ ! -d ${WORKDIR}/backup ] && mkdir ${WORKDIR}/backup # set a directories structure lock touch ${WORKDIR}/.capistrano_ds_lock echo_g \"Set directory structure successfully! \" } function cleanOldReleases(){ save_days=${save_old_releases_for_days:-10} if [ ! -d ${WORKDIR}/release ]; then echo_b \"Can NOT find release directory, skipping . \" return fi need_clean=$(find ${WORKDIR}/release -mtime +${save_days} -exec ls '{}' \\;) if [ ! -z ${need_clean} ]; then echo_g \"Expired releases found and will be removed from project! \" find ${WORKDIR}/release -mtime +${save_days} -exec rm -rf '{}' \\; if [ $? -eq 0 ]; then echo_g \"Expired releases have removed from project! \" else echo_r \"Can NOT remove expired releases, please alter to Admin users. \" fi else echo_g \"All releases are not expired, skipping. \" fi } # git_project_clone repository branch function git_project_clone(){ set -o errexit [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} if test -n $2; then branch=\"$2\" else branch=\"develop\" fi if test ! -d ${project_clone_directory}; then echo_b \"git clone from $project_clone_repository\" # git clone git@github.com:name/app.git -b master git clone ${project_clone_repository} ${project_clone_directory} >>${WORKDIR}/git_$(date +%Y%m%d)_$$.log 2>&1 # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd ${project_clone_directory} git checkout ${branch} >>${WORKDIR}/git_$(date +%Y%m%d)_$$.log 2>&1 cd .. echo_g \"git clone from $project_clone_repository successfully! \" else echo_b \"git pull from $project_clone_repository\" cd ${project_clone_directory} git pull >>${WORKDIR}/git_$(date +%Y%m%d)_$$.log 2>&1 git checkout ${branch} >>${WORKDIR}/git_$(date +%Y%m%d)_$$.log 2>&1 # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd .. echo_g \"git pull from $project_clone_repository successfully! \" fi set +o errexit } function maven_build_project_deprecated(){ set -o errexit echo_b \"Do mvn build java project... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log 2>&1 mvn clean package >>${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log 2>&1 cd .. echo_g \"Do mvn build java project finished with exit code 0! \" set +o errexit } function maven_build_project(){ echo_b \"Do mvn build java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi mvn clean package >>${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd .. echo_g \"Do mvn build java project finished for ${project_clone_repository_name} with exit code 0! \" } function check_ssh_can_be_connect(){ [ $# -ne 1 ] && return 1 echo_b \"Check if can ssh to remote host $1 ... \" check_command_can_be_execute ssh || return 1 ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"uname -a >/dev/null 2>&1\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"Check ssh to remote host $1 failed! \" exit 1 else echo_g \"Check ssh to remote host $1 successfully! \" fi } # ssh_execute_command_on_remote_host hostname command function ssh_execute_command_on_remote_host(){ [ $# -ne 2 ] && return 1 ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"$2\" >>${WORKDIR}/ssh_command_$(date +%Y%m%d)_$$.log retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"ssh execute command on remote host $2 failed! More details refer to ${WORKDIR}/ssh_command_$(date +%Y%m%d)_$$.log\" return 1 else echo_g \"ssh execute command on remote host $2 successfully! \" return 0 fi } function restart_docker_container(){ echo_b \"Restarting docker container...\" [ $# -ne 1 ] && return 1 # TODO(Guodong Ding) if we need restart more related docker container local docker_container_name=\"\" test -n $1 && docker_container_name=\"$1\" ssh_execute_command_on_remote_host \"docker restart $docker_container_name\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"restart docker container for $docker_container_name failed! \" exit 1 else echo_g \"restart docker container for $docker_container_name successfully! \" return 0 fi } # scp_local_files_to_remote_host local_path remote_hostname remote_path function scp_local_files_to_remote_host(){ [ $# -ne 3 ] && return 1 [ ! -d $1 -a ! -f $1 ] && return 1 check_ssh_can_be_connect $2 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp local files to remote host failed! \" exit 1 else echo_g \"scp local files to remote host successfully! \" fi } # scp_remote_files_to_local_host remote_hostname remote_path local_path function scp_remote_files_to_local_host(){ [ $# -ne 3 ] && return 1 check_ssh_can_be_connect $1 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp root@$1:$2 $3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp remote files to local host failed! \" exit 1 else echo_g \"scp remote files to local host successfully! \" fi } function backup_remote_host_config_files(){ echo_b \"backup remote host config files...\" scp_remote_files_to_local_host ${deploy_target_host_ip} ${project_top_directory_to_target_host}/* ${WORKDIR}/backup # get config files [ \"$(ls -A ${WORKDIR}/backup)\" ] && find ${WORKDIR}/backup/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -exec rm -f -- '{}' \\; # remove empty directory find ${WORKDIR}/backup/. -empty -type d -delete # TODO(Guodong Ding) improvements here echo_g \"backup remote host config files finished.\" } function rollback_remote_host_config_files(){ echo_b \"rollback remote host config files...\" #scp_local_files_to_remote_host ${WORKDIR}/backup ${deploy_target_host_ip} ${project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/backup/*;do scp_local_files_to_remote_host ${file} ${deploy_target_host_ip} ${project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # TODO(Guodong Ding) if save remote host config files, if there are no changes on config files # some ops # TODO(Guodong Ding) improvements here echo_g \"rollback remote host config files finished.\" } function deploy() { [ -n \"$header\" ] && echo \"$header\" # check a directories lock, Note: this is redundant if [[ ! -f ${WORKDIR}/.lock ]]; then setDirectoryStructureOnLocalHost fi cleanOldReleases # do dependencies checking check_network_connectivity check_name_resolve checkOtherDependencies check_ssh_can_be_connect ${deploy_target_host_ip} # do core job # TODO(Guodong Ding) if we need a git_project_clone \"$project_clone_depends_1\" here using auto judgment statement test -z ${project_clone_depends_1} || git_project_clone \"$project_clone_depends_1\" git_project_clone \"$project_clone\" test -z ${project_clone_depends_1} || maven_build_project \"$project_clone_depends_1\" maven_build_project \"$project_clone\" cd ${WORKDIR} # links_target_directory_to_current # Make directory to release directory if test ! -d ${WORKDIR}/release -o ! -d ${WORKDIR}/share; then echo_r \"capistrano directory structure is broken, make sure the file .capistrano_ds_lock is deleted before a new deploy! \" exit 1 # test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock fi new_release_just_created=\"$WORKDIR/release/$(date +%Y%m%d%H%M%S)\" [ ! -d ${new_release_just_created} ] && mkdir ${new_release_just_created} [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/ ] && \\ \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/* ${new_release_just_created} # Make source code symbolic link to current ( [ -f ${WORKDIR}/current ] || [ -d ${WORKDIR}/current ] ) && rm -rf ${WORKDIR}/current ln -s ${new_release_just_created} ${WORKDIR}/current # backup remote host config files [ -z ${project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${deploy_target_host_ip} ${project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${deploy_target_host_ip} ${project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${project_conf_directory} ] && rollback_remote_host_config_files if [ ! -z ${project_conf_directory} ]; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${deploy_target_host_ip} ${project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Move conf and logs directives from release to share [ -d ${WORKDIR}/release/conf ] && mv ${WORKDIR}/release/conf ${WORKDIR}/share/conf [ -d ${WORKDIR}/release/logs ] && mv ${WORKDIR}/release/logs ${WORKDIR}/share/logs # Make conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current/conf [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current/logs # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ${WORKDIR}/current/bin/startup.sh start retval=$? else test -z ${docker_container_name} || restart_docker_container ${docker_container_name} # TODO(Guodong Ding) external health check retval=$? fi # if started ok, then create a workable program to a file if [[ ${retval} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy successfully! \" echo_g \"current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" # ls --color=auto -l ${WORKDIR}/current # ls --color=auto -l ${WORKDIR}/current/ else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollback fi } # Rollback to last right configuration function rollback() { [ -n \"$header\" ] && echo \"$header\" echo_b \"Rollback to last right configuration... \" # The key is find last files which can work WORKABLE_PROGRAM=`cat ${WORKDIR}/share/workable_program.log` if [[ -z ${WORKABLE_PROGRAM} ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # Stop service if we have if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ${WORKDIR}/current/bin/startup.sh stop fi # Remove failed deploy rm -rf ${WORKDIR}/current # Remake source code symbolic link to current ln -s ${WORKABLE_PROGRAM} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ${WORKDIR}/current/bin/startup.sh start retval=$? else test -z ${docker_container_name} || restart_docker_container ${docker_container_name} # TODO(Guodong Ding) external health check retval=$? fi # if started ok, then create a workable program to a file if [[ ${retval} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $WORKABLE_PROGRAM\" # ls --color=auto -l ${WORKDIR}/current fi } function destroy() { [ -n \"$header\" ] && echo \"$header\" # echo a Warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" answer=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" answer case \"$answer\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"filename\" | xargs rm -rf find -L ${WORKDIR} -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf '{}' \\; if [ $? -eq 0 ];then test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } function main(){ lock_filename=\"lock_$$_$RANDOM\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT # Just a test for call itself, comment it if [[ $# -ne 1 ]]; then # $0 deploy [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` ${WORKDIR}/`basename $0` deploy exit 0 fi case $1 in deploy) deploy ;; rollback) rollback ;; destroy) destroy ;; help|*) echo \"Usage: $0 {deploy|rollback|destroy} with $0 itself\" exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option #${_XTRACE_FUNCTIONS}"
        },
        {
            "filename": "file_420.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_420.sh",
            "content": "#!/bin/bash # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link PRG=\"$0\" while [[ -h \"$PRG\" ]]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function function cecho { # Usage: # cecho -red sometext # Error, Failed # cecho -green sometext # Success # cecho -yellow sometext # Warning # cecho -blue sometext # Debug # cecho -white sometext # info # cecho -n # new line # end while [[ \"$1\" ]]; do case \"$1\" in -normal) color=\"\\033[00m\" ;; # -black) color=\"\\033[30;01m\" ;; -red) color=\"\\033[31;01m\" ;; -green) color=\"\\033[32;01m\" ;; -yellow) color=\"\\033[33;01m\" ;; -blue) color=\"\\033[34;01m\" ;; # -magenta) color=\"\\033[35;01m\" ;; # -cyan) color=\"\\033[36;01m\" ;; -white) color=\"\\033[37;01m\" ;; -n) one_line=1; shift ; continue ;; *) echo -n \"$1\"; shift ; continue ;; esac shift echo -en \"$color\" echo -en \"$1\" echo -en \"\\033[00m\" shift done if [[ ! ${one_line} ]]; then echo fi } # end echo color function # echo color function, smarter function echo_r () { #Error, Failed [[ $# -ne 1 ]] && return 0 echo -e \"\\033[31m$1\\033[0m\" } function echo_g () { # Success [[ $# -ne 1 ]] && return 0 echo -e \"\\033[32m$1\\033[0m\" } function echo_y () { # Warning [[ $# -ne 1 ]] && return 0 echo -e \"\\033[33m$1\\033[0m\" } function echo_b () { # Debug [[ $# -ne 1 ]] && return 0 echo -e \"\\033[34m$1\\033[0m\" } # end echo color function, smarter WORKDIR=${PRGDIR} # end public header # ============================================================================================================================= # Where to get source code SOURCEURL=https://github.com/DingGuodong/GitOSCAutoDeploy.git # Setting how many days do you want save old releases, default is 10 days save_old_releases_for_days=10 function setDirectoryStructure() { if [[ -f ${WORKDIR}/.lock ]];then echo_g \"Set directory structure has been done, skipping. \" return fi echo_b \"Setting directory structure.\" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branchnames or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy # [ ! -d ${WORKDIR}/current ] && mkdir ${WORKDIR}/current [[ ! -d ${WORKDIR}/release ]] && mkdir ${WORKDIR}/release [[ ! -d ${WORKDIR}/repository ]] && mkdir ${WORKDIR}/repository [[ ! -d ${WORKDIR}/share ]] && mkdir ${WORKDIR}/share # end directories structure touch ${WORKDIR}/.lock echo_g \"Set directory structure successfully! \" } function checkDependencies() { echo_b \"Checking dependencies for deploy procedure. \" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z ${SOURCEURL} ]]; then echo_r \"Error: SOURCEURL is undefined! \" exit 1 fi DISKSPACE=`df ${WORKDIR} | tail -n1 | awk '{print $(NF -2)}'` if [[ ${DISKSPACE} -lt 2097152 ]]; then echo_y \"Warning: Disk space of ${WORKDIR} is smaller than 2GB\" #exit 1 fi echo_g \"All required dependencies check pass! \" } function cleanOldReleases(){ save_days=${save_old_releases_for_days:-10} if [[ ! -d ${WORKDIR}/release ]]; then echo_b \"Can NOT find release directory, skipping . \" return fi need_clean=$(find ${WORKDIR}/release -mtime +${save_days} -exec ls '{}' \\;) if [[ ! -z ${need_clean} ]]; then echo_g \"Expired releases found and will be removed from project! \" find ${WORKDIR}/release -mtime +${save_days} -exec rm -rf '{}' \\; if [[ $? -eq 0 ]]; then echo_g \"Expired releases have removed from project! \" else echo_r \"Can NOT remove expired releases, please alter to Admin users. \" fi else echo_g \"All releases are not expired, skipping. \" fi } function deploy() { # check a directories lock, Note: this is redundant if [[ ! -f ${WORKDIR}/.lock ]]; then setDirectoryStructure fi cleanOldReleases checkDependencies # Make directory to release directory SOURCEDIR=\"${WORKDIR}/release/$(date +%Y%m%d%H%M%S)\" [[ ! -d ${SOURCEDIR} ]] && mkdir ${SOURCEDIR} # Get files from source code repository git clone ${SOURCEURL} ${SOURCEDIR} # svn co http://$SOURCEURL ${WORKDIR}/repository # TODO # get branchnames or revision numbers from VCS data # Remove .git or .svn [[ -d ${SOURCEDIR}/.git ]] && rm -rf ${SOURCEDIR}/.git [[ -d ${SOURCEDIR}/.svn ]] && rm -rf ${SOURCEDIR}/.svn # ifdef Complie # endif # Make source code symbolic link to current ( [[ -f ${WORKDIR}/current ]] || [[ -d ${WORKDIR}/current ]] ) && rm -rf ${WORKDIR}/current ln -s ${SOURCEDIR} ${WORKDIR}/current # Move conf and logs directories from release to share [[ -d ${WORKDIR}/release/conf ]] && mv ${WORKDIR}/release/conf ${WORKDIR}/share/conf [[ -d ${WORKDIR}/release/logs ]] && mv ${WORKDIR}/release/logs ${WORKDIR}/share/logs # Make conf and logs symbolic link to current [[ -d ${WORKDIR}/share/conf ]] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current/conf [[ -d ${WORKDIR}/share/logs ]] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current/logs # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ${WORKDIR}/current/bin/startup.sh start retval=$? else # TODO # external health check retval=0 fi retval=$? # if started ok, then create a workable program to a file if [[ ${retval} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${SOURCEDIR} eof echo_g \"Deploy successfully! \" echo_g \"current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" ls --color=auto -l ${WORKDIR}/current else echo_r \"Error: Deploy failed! \" $0 rollback fi } # Rollback to last right configuraton function rollback() { # The key is find last files which can work WORKABLE_PROGRAM=`cat ${WORKDIR}/share/workable_program.log` if [[ -z WORKABLE_PROGRAM ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # # Stop service if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ${WORKDIR}/current/bin/startup.sh stop fi # Remove failed deploy rm -rf ${WORKDIR}/current # Remake source code symbolic link to current ln -s ${WORKABLE_PROGRAM} ${WORKDIR}/current # Remake conf and logs symbolic link to current [[ -d ${WORKDIR}/share/conf ]] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [[ -d ${WORKDIR}/share/logs ]] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ${WORKDIR}/current/bin/startup.sh start retval=$? else # TODO # external health check retval=0 fi retval=$? # if started ok, then create a workable program to a file if [[ ${retval} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $WORKABLE_PROGRAM\" ls --color=auto -l ${WORKDIR}/current fi } function destroy() { # echo a warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" answer=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" answer case \"$answer\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo ${WORKDIR}/ #find -L ${WORKDIR} -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"fielname\" |xargs rm -rf find -L ${WORKDIR} -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"${WORKDIR}\" -exec rm -rf '{}' \\; if [[ $? -eq 0 ]];then echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } # Just a test for call itself, comment it # if [[ $# -lt 1 ]]; then # $0 help # exit # fi case $1 in deploy) deploy ;; rollback) rollback ;; destroy) destroy ;; help|*) echo \"Usage: $0 {deploy|rollback|destroy} with $0 itself\" exit 1 ;; esac # This is not essential with 'case .. esac' handled no args excutions # replace \"exit 0\" with \":\" #exit 0 :"
        },
        {
            "filename": "file_421.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\sh_header\\BashShellHeader\\file_421.sh",
            "content": "#!/usr/bin/env bash # Public header # ============================================================================================================================= # Check that we are root ... so non-root users stop here [[ `id -u` -eq \"0\" ]] || exit 4 # resolve links - $0 may be a symbolic link PRG=\"$0\" while [[ -h \"$PRG\" ]]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function function cecho { # Usage: # cecho -red sometext #Error, Failed # cecho -green sometext # Success # cecho -yellow sometext # Warning # cecho -blue sometext # Debug # cecho -white sometext # info # cecho -n # new line # end while [[ \"$1\" ]]; do case \"$1\" in -normal) color=\"\\033[00m\" ;; # -black) color=\"\\033[30;01m\" ;; -red) color=\"\\033[31;01m\" ;; -green) color=\"\\033[32;01m\" ;; -yellow) color=\"\\033[33;01m\" ;; -blue) color=\"\\033[34;01m\" ;; # -magenta) color=\"\\033[35;01m\" ;; # -cyan) color=\"\\033[36;01m\" ;; -white) color=\"\\033[37;01m\" ;; -n) one_line=1; shift ; continue ;; *) echo -n \"$1\"; shift ; continue ;; esac shift echo -en \"$color\" echo -en \"$1\" echo -en \"\\033[00m\" shift done if [[ ! $one_line ]]; then echo fi } # end echo color function # echo color function, smarter function echo_r () { #Error, Failed [[ $# -ne 1 ]] && return 0 echo -e \"\\033[31m$1\\033[0m\" } function echo_g () { # Success [[ $# -ne 1 ]] && return 0 echo -e \"\\033[32m$1\\033[0m\" } function echo_y () { # Warning [[ $# -ne 1 ]] && return 0 echo -e \"\\033[33m$1\\033[0m\" } function echo_b () { # Debug [[ $# -ne 1 ]] && return 0 echo -e \"\\033[34m$1\\033[0m\" } # end echo color function, smarter WORKDIR=$PRGDIR # end public header # ============================================================================================================================= # begin customization for special case # ============================================================================= # project directory to waiting for update config_project_dir=example_projects # resources directory which contains config file and update files config_resources_dir=example_resources # backup directory which to contains backup of whole project config_backup_dir=example_backup_dir # remote options, \"y\" can be supported, \"-\" not supported #config_remote_execution=yes|no [y] #config_remote_execution=true|false [y] #config_remote_execution=enable|disable [-], conflicted to bash #config_remote_execution=1|0 [y] config_remote_execution=no # TODO # not ready for remote execution # if config_remote_execution set to true, then blew is a must config_remote_backup_server= config_remote_backup_directory= # end customization for special case # ============================================================================= # this is can NOT be edited. config_config_file=$config_resources_dir/config_update.conf # log options, set a log file to record backup log for restore use, this is can NOT be edited. config_this_logfile=$WORKDIR/.update_backup.log identity_file=~/.ssh/id_rsa.pub # end # check if user want to execute on remote clients function parse_config_remote_execution() { if [[ -z \"`eval ${config_remote_execution}`\" ]]; then echo_r \"Error: config_remote_execution is NOT set, if you want execute it local, set it no, else set it yes. \" exit 1 elif [[ x${config_remote_execution} != x ]];then case ${config_remote_execution} in yes|true|1) config_remote_execution=1 ;; no|false|0) config_remote_execution=0 ;; *) echo_r \"Error: config_remote_execution has a bad set, please check and correct it. \" exit 1 ;; esac else echo_y \"Can NOT find config_remote_execution, is it unset? Setting a default value for config_remote_execution. \" config_remote_execution=0 fi } function test_self(){ # How to use this function: # First execute \"$0 test_self\", then execute \"$0 update\" echo_b \"Test purpose begin. \" # clean old test example echo_b \"Clean old test example. \" [[ -d $WORKDIR/example_projects ]] && rm -rf $WORKDIR/example_projects [[ -d $WORKDIR/example_resources ]] && rm -rf $WORKDIR/example_resources [[ -d $WORKDIR/example_backup_dir ]] && rm -rf $WORKDIR/example_backup_dir # make an example project directory if [[ -z $config_project_dir -o ! -d $config_project_dir ]]; then echo_b \"Making an example project directory. \" mkdir $WORKDIR/example_projects config_project_dir=example_projects # Padding example_projects directory touch $config_project_dir/example_filename mkdir $config_project_dir/example_directory fi # make an example resources directory if [[ -z $config_resources_dir -o ! -d $config_resources_dir ]]; then echo_b \"Making an example resources directory. \" mkdir $WORKDIR/example_resources config_resources_dir=$WORKDIR/example_resources fi # make an example config_update.conf if [[ -z $config_config_file -o ! -f $config_config_file ]]; then echo_b \"Making an example config_update.conf file. \" touch $config_resources_dir/config_update.conf config_config_file=$config_resources_dir/config_update.conf # Padding config_update.conf file cat >$config_config_file <<eof file filename1 add file filename2 remove file filename3 update file filename4 add config cleancachea enable config cleancacheb disable config restartservicea enable config restartserviceb disable target 192.168.1.241 ssh 22 root yiCxVyW2DydhE target 192.168.1.242 ssh 22 root yiCxVyW2DydhE target 192.168.1.243 ssh 22 root yiCxVyW2DydhE target 192.168.1.244 ssh 22 root yiCxVyW2DydhE eof files=`awk -F '[ ]+' '/^file/ { print $2 }' $config_config_file` echo_b \"Making an example files(patches) refer to $config_config_file. \" for names in $files; do [[ ! -f $config_resources_dir/$names ]] && touch $config_resources_dir/$names done fi # TODO # not ready for remote execution # test network and ssh for remote call # make an example backup directory if [[ -z $config_backup_dir -o ! -d $config_backup_dir ]]; then echo_b \"Making an example backup directory\" mkdir $WORKDIR/example_backup_dir config_backup_dir=$WORKDIR/example_backup_dir fi echo_g \"Test purpose is finished and successfully! \" } #function parse_config_file(){ # # unbanned action # files=`awk -F '[ ]+' '/^file/ { print $2 }' $config_config_file` # configs=`awk -F '[ ]+' '/^config/ { print $2 }' $config_config_file` #} function ssh_keygen(){ echo_b \"generate SSH key and related files for itself.\" cd # Improvement # ssh-keygen parameters ssh-keygen -N \"\" -f /root/.ssh/id_rsa if [[ $? -ne 0 ]]; then echo_r \"Error: generate SSH key and related files for itself failed! \" exit 1 fi cd ~/.ssh/ [[ ! -e ~/.ssh/authorized_keys ]] && cp id_rsa.pub authorized_keys cd identity_file=~/.ssh/id_rsa.pub } # this action can NOT be replaced with check_ssh_connection function function inject_ssh_key(){ # ssh-copy-id Line:41 which sshpass >/dev/null 2>&1 || yum -q -y install sshpass if [[ $? -ne 0 -a ! -f /etc/yum.repos.d/epel.repo ]]; then echo_y \"sshpass can NOT install on system with yum repolist, install epel first. \" yum -q -y install http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm yum -q -y install sshpass if ! which sshpass >/dev/null 2>&1; then echo_r \"Error: sshpass is can NOT install on system, please install it manually. \" exit 1 fi fi # inject ssh key for each host found in config files hostname_list=$(awk -F '[ ]+' '/target/ {print $2}' $config_config_file) for hostname in $hostname_list; do port=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$4}\") user=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$5}\") password=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$6}\") # echo issue but it is less than ssh issue(It will report \"Pseudo-terminal will not be allocated because stdin is not a terminal.\" when use stdin to ssh command.) sshpass -p $password ssh -p $port -oStrictHostKeyChecking=no $user@$hostname \"exec sh -c 'echo $(cat ~/.ssh/id_rsa.pub) >> ~/.ssh/authorized_keys && (test -x /sbin/restorecon && /sbin/restorecon ~/.ssh ~/.ssh/authorized_keys >/dev/null 2>&1 || true)'\" # sshpass issue: Pseudo-terminal will not be allocated because stdin is not a terminal. # to resolve this issue, do NOT give ssh command any stdin, sometimes \"known host\" maybe worked with this issue # Refer: http://unix.stackexchange.com/questions/151757/script-to-ssh-and-run-a-command-doesnt-work # Refer: http://stackoverflow.com/questions/305035/how-to-use-ssh-to-run-shell-script-on-a-remote-machine # comment this line #sshpass -p $password cat ~/.ssh/id_rsa.pub | ssh -T -p $port -oStrictHostKeyChecking=no $user@$hostname \"exec sh -c 'cat >> ~/.ssh/authorized_keys && (test -x /sbin/restorecon && /sbin/restorecon ~/.ssh ~/.ssh/authorized_keys >/dev/null 2>&1 || true)'\" if [[ $? -eq 0 ]]; then echo_g \"SSH key inject to $hostname successfully! \" else echo_r \"SSH key inject to $hostname failed! \" exit 1 fi done } # this action has some duplicates to inject_ssh_key function function check_ssh_connection(){ hostname_list=$(awk -F '[ ]+' '/target/ {print $2}' $config_config_file) for hostname in $hostname_list; do port=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$4}\") user=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$5}\") password=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$6}\") if ! ssh -i ~/.ssh/id_rsa -p $port -oPasswordAuthentication=no $user@$hostname \"exec sh -c 'true'\" >/dev/null 2>&1; then echo_b \"Can NOT login $hostname through SSH key ~/.ssh/id_rsa, retry to inject SSH keys. \" sshpass -p $password ssh -p $port -oStrictHostKeyChecking=no $user@$hostname \"exec sh -c 'echo $(cat ~/.ssh/id_rsa.pub) >> ~/.ssh/authorized_keys && (test -x /sbin/restorecon && /sbin/restorecon ~/.ssh ~/.ssh/authorized_keys >/dev/null 2>&1 || true)'\" if [[ $? -ne 0 ]]; then echo_r \"Error: SSH key inject to $hostname failed! \" exit 1 else echo_g \"SSH key inject to $hostname successfully! \" if ssh -p $port -oStrictHostKeyChecking=no $user@$hostname \"exec sh -c 'cat ~/.ssh/authorized_keys | sort | uniq --repeated | grep ssh'\"; then echo_y \"Duplicate lines found in ~/.ssh/authorized_keys, remove them. \" ssh -p $port -oStrictHostKeyChecking=no $user@$hostname \"exec sh -c 'cat ~/.ssh/authorized_keys | sort | uniq > ~/.ssh/authorized_keys~;\\mv ~/.ssh/authorized_keys~ ~/.ssh/authorized_keys'\" if [[ $? -eq 0 ]]; then echo_g \"Duplicate lines found in ~/.ssh/authorized_keys removed successfully! \" else echo_y \"Duplicate lines found in ~/.ssh/authorized_keys removed failed! \" fi else echo_g \"SSH connection to $hostname is ok! \" fi fi else echo_g \"SSH connection to $hostname is ok! \" fi done } function do_cp(){ SOURCE=$1 # echo \"var: $SOURCE\" # echo \"result: $(dirname $SOURCE | grep ^\\/ | awk '{print substr($1,1,1)}' )\" # exit 0 if test \"$(dirname $SOURCE | grep ^\\/ | awk '{print substr($1,1,1)}')\" == \"\"; then echo_b \"Execute copy action. \" DEST=$config_project_dir/$SOURCE \\cp $SOURCE $DEST else echo_y \"Self test purpose found! But we can do this action! \" [[ ! -d $config_project_dir/$(dirname $SOURCE) ]] && mkdir -p $config_project_dir/$(dirname $SOURCE) \\cp $SOURCE $config_project_dir/$(dirname $SOURCE) fi } function do_remove(){ FILE=$1 if test \"$(dirname $SOURCE | awk -F '/' '{print $1}')\" == \"\"; then rm -rf $config_project_dir/$FILE else echo_y \"Self test purpose found! This can NOT do remove action on self test purpose, skipping...\" return fi } # TODO # not ready for remote execution # for remote call #function do_remote_cp(){} #function fo_remote_remove(){} function file_operation(){ echo_b \"Begin files operations\" files=`awk -F '[ ]+' '/^file/ { print $2 }' $config_config_file` for names in $files; do if grep $names $config_config_file | grep add >/dev/null 2>&1 ; then # do_cp do_cp $names elif grep $names $config_config_file | grep update >/dev/null 2>&1 ;then # do_cp do_cp $names elif grep $names $config_config_file | grep remove >/dev/null 2>&1 ;then # do_remove do_remove $names else exit 1 fi done echo_g \"Files operations finished successfully! \" } # TODO # no example here, please refer to your real production environment #function do_clean_cache(){} #function do_restart_service(){} function service_operation(){ echo_b \"Begin services operations\" configs=`awk -F '[ ]+' '/^config/ { print $2 }' $config_config_file` for names in $configs; do if grep $names $config_config_file | grep cleancache | grep enable >/dev/null 2>&1 ; then # do_clean_cache echo do_clean_cache $names elif grep $names $config_config_file | grep cleancache | grep disable >/dev/null 2>&1 ; then # echo a warning echo_y \"Warning: disable action is NOT recommended, $names skipped.\" elif grep $names $config_config_file | grep restartservice | grep enable >/dev/null 2>&1 ; then # do_restart_service echo do_restart_service $names elif grep $names $config_config_file | grep restartservice | grep disable >/dev/null 2>&1 ; then # echo a warning echo_y \"Warning: disable action is NOT recommended, $names skipped.\" else echo $names echo_r \"Error: Wrong config file $config_config_file, please check it. \" exit 1 fi done echo_g \"Services operations finished successfully! \" } function check_remote_server_status(){ # TODO # not ready for remote execution # for remote call echo } function backup(){ echo_b \"Backup files before update\" # backup_filename=backup_$(date +%F_%H_%M_%S).tgz backup_filename=backup_$(date +%Y_%m_%d_%H_%M_%S).tgz # tar directory cd $config_project_dir/.. tar --create --gzip --absolute-names --file=$config_backup_dir/$backup_filename $config_project_dir if [[ $? -eq 0 ]]; then echo_g \"Backup files before update finished and successfully! \" echo \"restore_least_file=$config_backup_dir/$backup_filename\" > $config_this_logfile else echo_r \"Error: Backup files before update failed! Please alter to administrator. \" exit 1 fi } function restore(){ echo_b \"Restore files for rollback\" if [[ -f $config_this_logfile ]]; then . $config_this_logfile fi restore_least_file=${restore_least_file:-1} if [[ -s $restore_least_file ]]; then tar -C $config_project_dir/.. -zxf $restore_least_file if [[ $? -eq 0 ]]; then echo_g \"Restore files finished and successfully! \" else echo_r \"Restore files failed! Please alter to administrator. \" exit 1 fi else echo_r \"Can NOT find backup files in $config_backup_dir, backup once indeed? \" exit 1 fi } # TODO # not ready for remote execution # for remote call # function remote_backup(){} # function remote_restore(){} function rollback(){ echo_b \"rollback after update failed\" $0 restore echo_g \"rollback finished and successfully! \" } function update_status(){ # TODO # no example here, please refer to your real production environment # check if update success or failure echo update_status # if failure, do rollback action # service_operation } # Put check_dependencies in front of update function function check_dependencies(){ echo_b \"Checking dependencies for update procedure. \" if [[ -z $config_project_dir ]]; then echo_r \"Error: config_project_dir is undefined! \" exit 1 fi if [[ ! -d $config_resources_dir ]]; then echo_r \"Error: config_resources_dir is undefined! \" fi if [[ -z $config_config_file ]]; then echo_r \"Error: config_config_file is undefined! \" exit 1 fi left_disk_space=`df $config_backup_dir | tail -n1 | awk '{print $(NF -2)}'` # set 2097152 to project directory size if [[ -z $config_project_dir -o ! -d $config_project_dir ]]; then project_file_space_usage=$(du -s /root | awk '{print $1}') required_size=$(expr $project_file_space_usage \\* 2) fi if [[ $left_disk_space -lt $required_size ]]; then echo_r \"Disk space of $config_backup_dir is smaller than $required_size. \" exit 1 fi if [[ ! -f /root/.ssh/id_rsa ]]; then ssh_keygen fi echo_g \"All required dependencies check pass! \" } function update(){ # TODO # thinking carefully with all exit status, which is not good for automatic update check_dependencies backup file_operation service_operation update_status } function destroy() { # echo a warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" answer=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" answer case \"$answer\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"fielname\" |xargs rm -rf find -L $WORKDIR -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf {} \\; if [[ $? -eq 0 ]];then echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } case $1 in update) update ;; backup) backup ;; restore) restore ;; rollback) rollback ;; destroy) destroy ;; help|*) echo \"Usage: $0 {update|backup|restore|rollback|destroy} with $0 itself\" exit 1 ;; esac # This is not essential with 'case .. esac' handled no args excutions # replace \"exit 0\" with \":\" #exit 0 :"
        },
        {
            "filename": "file_422.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\string\\file_422.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File: LinuxBashShellScriptForOps:get_cpu_usage_idle.sh # User: Guodong # Create Date: 2017/8/14 # Create Time: 10:32 # Function: get cpu idle percentage of certain program # Note: # Prerequisite: sed, awk, vmstat, top, etc # Description: get cpu idle percentage of certain program # Reference: Getting cpu usage realtime # https://askubuntu.com/questions/274349/getting-cpu-usage-realtime # How does ps aux | grep '[p]attern' exclude grep itself? # https://stackoverflow.com/questions/20528894/how-does-ps-aux-grep-pattern-exclude-grep-itself daemon_name=\"dockerd\" # the program name to check out ## shellcheck disable=SC2001 #daemon_name_to_search_pid=$(echo ${daemon_name} | sed \"s/\\([a-z]\\{1\\}\\)\\(.*\\)/\\[\\1\\]\\2/g\") #pid_to_trace=$(ps -ef | grep \"${daemon_name_to_search_pid}\" | awk 'NR==1{print $2}') pid_to_trace=$(pgrep $daemon_name) if \"x$pid_to_trace\" == \"x\"; then echo \"pid can NOT be found\" exit 1 fi cpu_idle_percentage_threshold=10 keep_running_flag=1 while [[ ${keep_running_flag} -eq 1 ]]; do cpu_idle=$(vmstat 1 2|tail -1|awk '{print $15}') if [[ ${cpu_idle} -lt ${cpu_idle_percentage_threshold} ]]; then date --rfc-2822 echo \"CPU idle percentage is too small!\" vmstat 1 5 top -bn 2 -d 0.01 -p \"${pid_to_trace}\" keep_running_flag=0 fi done :"
        },
        {
            "filename": "file_423.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\string\\file_423.sh",
            "content": "#!/bin/bash # delete all spaces and comments of specialized file, using with $@ filename [[ \"$1\" == \"\" ]] && echo \"delete all spaces and comments of specialized file, using with $@ filename\" && exit 1 if cat -A $1 | grep '\\^M\\\\$' >/dev/null || file $1 | grep \"with CRLF line terminators\" >/dev/null ; then which dos2unix >/dev/null 2>&1 || yum -q -y install dos2unix || apt-get -qq -y install dos2unix dos2unix $1 >/dev/null fi if test -f $1 && file $1 | grep \"XML\" >/dev/null; then which tidy >/dev/null 2>&1 || yum -q -y install tidy || apt-get -qq -y install tidy tidy -quiet -asxml -xml -indent -wrap 1024 --hide-comments 1 $1 elif test -f $1; then grep -v \\# $1 | grep -v ^\\; |grep -v ^$ | grep -v ^\\ *$ fi # Others: # sed -e '/^#/d;/^$/d' $1 # Refer: https://github.com/mysfitt/nocomment/blob/master/nocomment.sh # grep -Ev '^\\s*#|^//|^\\s\\*|^/\\*|^\\*/' $1 | grep -Ev '^$|^\\s+$'"
        },
        {
            "filename": "file_424.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\string\\file_424.sh",
            "content": "#!/bin/bash # delete all spaces and comments of specialized file, using with $@ filename DEBUG=false if ${DEBUG} ; then old_PS4=$PS4 # system builtin variable does not need '${var}' expression # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi function is_file_exist(){ test -f $1 || echo \"ls: cannot access $file: No such file or directory\" && exit 1 } function dos2unix_text_file_format_converter(){ if cat -A ${file} | grep '\\^M\\\\$' >/dev/null || file ${file} | grep \"with CRLF line terminators\" >/dev/null ; then which dos2unix >/dev/null 2>&1 || yum -q -y install dos2unix || apt-get -qq -y install dos2unix dos2unix ${file} >/dev/null fi } function del_comment_in_c_cpp_file(){ tmp_file=/tmp/.noComment_$(date +%Y%m%d%H%M%S%N$RANDOM) cp ${file} ${tmp_file} #delete the comment line begin with '//comment' sed -i \"/^[ \\t]*\\/\\//d\" ${tmp_file} #delete the comment line end with '//comment' sed -i \"s/\\/\\/[^\\\"]*//\" ${tmp_file} #delete the comment only occupied one line '/* comment */' sed -i \"s/\\/\\*.*\\*\\///\" ${tmp_file} #delete the comment that occupied many lines '/*comment # *comment # */ sed -i \"/^[ \\t]*\\/\\*/,/.*\\*\\//d\" ${tmp_file} grep -v ^$ ${tmp_file} \\rm -f ${tmp_file} } function del_comment_in_sh_conf_file(){ #ignore the comment line end with '# comment' grep -v \"^[ \\t]*\\#\" ${file} | grep -v \"^$\" # grep -vP \"^[ \\t]*\\#|^$\" ${file} # grep -vP \"^\\s\\#|^$\" ${file} #Perl regular expressions give additional functionality, and are documented in # pcresyntax(3) and pcrepattern(3), but only work if pcre is available in the system. } function del_comment_in_xml_file(){ if test -f ${file} && file ${file} | grep \"XML\" >/dev/null; then which tidy >/dev/null 2>&1 || yum -q -y install tidy >/dev/null 2>&1 || apt-get -qq -y install tidy >/dev/null 2>&1 tidy -quiet -asxml -xml -indent -wrap 1024 --hide-comments 1 ${file} else which tidy >/dev/null 2>&1 || yum -q -y install tidy >/dev/null 2>&1 || apt-get -qq -y install tidy >/dev/null 2>&1 tidy -quiet -asxml -xml -indent -wrap 1024 --hide-comments 1 ${file} fi } function del_comment_in_general_file(){ #ignore the comment line end with '# comment' grep -v \"^[ \\t]*\\#\" ${file} | grep -v \"^[ \\t]*\\;\" |grep -v \"^$\" # TODO(Guodong Ding) comment style in python using ''', \"\"\" } function del_comment(){ case ${file} in *.c|*.cpp|*.h) del_comment_in_c_cpp_file ;; *.sh|*.conf) del_comment_in_sh_conf_file ;; *.xml) del_comment_in_xml_file ;; *) del_comment_in_general_file ;; esac } file=$1 if [[ -f ${file} ]]; then del_comment else echo \"ls: cannot access $file: No such file or directory\" && exit 1 fi if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_425.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\string\\json\\file_425.sh",
            "content": "#!/usr/bin/env bash # Validate a text if is json format using jsonlint(bin from package 'python-demjson') # Example cat a json file pipe to jsonlint curl 'https://api.github.com/repos/stedolan/jq/commits?per_page=5' | jsonlint # jq is like sed for JSON data - you can use it to slice and filter and map and transform structured data with the same ease that sed, awk, grep and friends let you play with text. curl 'https://api.github.com/repos/stedolan/jq/commits?per_page=5' | jq '.'"
        },
        {
            "filename": "file_426.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\string\\statisticsanalyse\\file_426.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File: LinuxBashShellScriptForOps:${NAME}.sh # User: Guodong # Create Date: 2017/7/6 # Create Time: 9:13 # Function: # Note: # Prerequisite: # Description: # Reference: # \u67e5\u8be2\u672c\u5730IP\u5df2\u7ecf\u4f7f\u7528\u7684\u7aef\u53e3 netstat -ltn | sed '1,2d' | awk -F'[ :]+' '{print $5}' LC_ALL=C netstat -ltn | sed '1,2d' | awk '{print $4}' | awk -F ':' '{print $NF}' | sort -n # \u6309\u7aef\u53e3\u53f7\u6392\u5e8f\u67e5\u8be2\u76d1\u542c\u7684\u7aef\u53e3 netstat -nltp | awk 'NR>2{split($4,a,\":\");t=sprintf(\"%5d\",a[2]);b[t]=$0}END{for(i=0;i++<asorti(b,c);)print b[c[i]]}' netstat -nolpt | awk 'BEGIN{print \"PID/SER\\tIP\\tPORT\"}/^t/{print gensub(\"([^,]+),(.*):(.*)\",\"\\\\1 \\\\2 \\\\3\",\"g\",$7\",\"$4)}' |column -t | sort -k3n # \u67e5\u8be2\u5916\u90e8IP\u6253\u5f00\u672c\u5730\u7aef\u53e3\u7684\u7edf\u8ba1\u60c5\u51b5 netstat -anot | awk '{print $5}' | awk -F ':' '{print $1}' | grep -v 192.168 | sort | uniq -c| sort -n -r | head -n 5 netstat -anopt | grep 6379 | awk -F[\\ ]+ '{print $5}' | awk -F':' '{print $1}' | sort | uniq -c |sort -n -r # \u67e5\u770b\u7cfb\u7edf\u7684\u7f51\u7edc\u8fde\u63a5\u6570\u60c5\u51b5\u786e\u8ba4\u662f\u5426\u6709\u8f83\u5927\u7684\u94fe\u63a5\u6570 netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'"
        },
        {
            "filename": "file_427.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\string\\xml\\file_427.sh",
            "content": "#!/usr/bin/env bash # centos, yum info xml2 #Available Packages #Name : xml2 #Arch : x86_64 #Version : 0.5 #Release : 7.el6 #Size : 22 k #Repo : epel #Summary : XML/Unix Processing Tools #URL : http://dan.egnor.name/xml2/ #License : GPLv2+ #Description : These tools are used to convert XML and HTML to and from a # : line-oriented format more amenable to processing by classic Unix # : pipeline processing tools, like grep, sed, awk, cut, shell scripts, # : and so forth. # debian/ubuntu, apt-cache show xml2 #Description-en: Convert between XML, HTML, CSV and a line-oriented format # xml2 tools are used to convert XML, HTML and CSV to and from a # line-oriented format more amenable to processing by classic Unix # pipeline processing tools, like grep, sed, awk, cut, shell scripts, # and so forth. # for xmllint, sudo apt install libxml2-utils which xmllint || sudo apt install -y libxml2-utils || yum install -y libxml2-utils # for xml2, sudo apt install xml2 which xml2 || sudo apt install -y xml2 || yum install -y xml2 cat >d.xml<<'eof' <?xml version=\"1.0\" encoding=\"UTF-8\"?> <Result> <Error>8</Error> <Failure>5</Failure> </Result> eof xml2 < d.xml xml2 < d.xml | grep '/Result/Error'|sed 's/.*=//g' rm -f d.xml"
        },
        {
            "filename": "file_428.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\system\\file_428.sh",
            "content": "#!/usr/bin/env bash # facter # dmidecode # lspci"
        },
        {
            "filename": "file_429.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\system\\file_429.sh",
            "content": "#!/bin/sh # Refer to: http://blog.csdn.net/wzb56_earl/article/details/50625705 uptime_ts=`cat /proc/uptime | awk '{ print $1}'` dmesg | awk -v uptime_ts=${uptime_ts} 'BEGIN { now_ts = systime(); start_ts = now_ts - uptime_ts; #print \"system start time seconds:\", start_ts; #print \"system start time:\", strftime(\"[%Y/%m/%d %H:%M:%S]\", start_ts); } { print strftime(\"[%Y/%m/%d %H:%M:%S]\", start_ts + substr($1, 2, length($1) - 2)), $0 }'"
        },
        {
            "filename": "file_430.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\user\\file_430.sh",
            "content": "#!/usr/bin/env bash if [ \"$(id -u)\" != \"0\" ]; then echo \"This script must be run as root\" 1>&2 exit 1 fi"
        },
        {
            "filename": "file_431.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\user\\file_431.sh",
            "content": "#!/usr/bin/env bash # Refers: man useradd UID_MAX=6000 UID_MIN=1000 SYS_UID_MAX=$((UID_MIN - 1)) SYS_UID_MIN=101 # root user awk -F\":\" '$3==0 {print}' /etc/passwd # system user awk -F\":\" \"\\$3>=$SYS_UID_MIN&&\\$3<$SYS_UID_MAX{print}\" /etc/passwd # normal user awk -F\":\" \"\\$3>=$UID_MIN&&\\$3<$UID_MAX {print}\" /etc/passwd"
        },
        {
            "filename": "file_432.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\variables\\file_432.sh",
            "content": "#!/usr/bin/env bash # ensure we don't re-source this in the same environment [[ -z \"$_FUNCTIONS_COMMON\" ]] || return 0 declare -r _FUNCTIONS_COMMON=1 # -r, read only # Global Config Variables declare -A VAR1 declare -A VAR2 declare -A VAR3"
        },
        {
            "filename": "file_433.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\functions\\variables\\file_433.sh",
            "content": "#!/usr/bin/env bash if [ \"x${GRUB_DISABLE_OS_PROBER}\" = \"xtrue\" ]; then exit 0 fi"
        },
        {
            "filename": "file_434.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\file_434.sh",
            "content": "#!/bin/bash # Name: doDeploy.sh #Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. # debug option DEBUG=true if $DEBUG ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi # define user friendly messages header=\" Function: Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. License: Open source software \" # user defined variables # Where to get source code user_defined_project_clone_depends=\"ssh://git@git.example.com:18082/core/business-service-base.git\" user_defined_project_clone=\"ssh://git@git.example.com:18082/core/business-service-core.git\" # TODO(Guodong Ding) do deploy once time with multi-hosts support, try using 'for + deploy' user_defined_deploy_target_host_ip=\"10.6.28.135\" #user_defined_project_top_directory_to_target_host=\"/data/docker/business-service/bs-core-01\" #user_defined_docker_container_name=\"bs-core-01\" user_defined_project_top_directory_to_target_host=\"/tmp/deploy_test_target\" user_defined_docker_container_name=\"\" # if you using a docker container other than a startup script located in sourcecode/bin/startup.sh, then set this to docker container name user_defined_project_conf_directory=\"\" # if you do NOT want to use configurations from deploy target, you should set this variable to where pointed to config files user_defined_skip_check_network_and_resolver=\"true\" # if system administrator disable ICMP protocol, set this any content but not null # Setting how many days do you want save old releases, default is 10 days save_old_releases_for_days=10 # end define variables # pretreatment test -z ${user_defined_project_clone_depends} || project_clone_target_depends_1=\"`echo ${user_defined_project_clone_depends} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_target=\"`echo ${user_defined_project_clone} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_repository_name=${project_clone_target} # end pretreatment # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi function command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } function check_command_can_be_execute(){ [ $# -ne 1 ] && return 1 command_exists $1 } function check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" fi } function check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" return 0 fi } function check_other_dependencies() { echo_b \"Checking other dependencies for deploy procedure... \" echo_b \"\\tChecking user customized variables...\" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z ${user_defined_project_clone} ]]; then echo_r \"Error: user_defined_project_clone is undefined! \" exit 1 elif [[ -z ${user_defined_deploy_target_host_ip} ]]; then echo_r \"Error: user_defined_deploy_target_host_ip is undefined! \" exit 1 elif [[ -z ${user_defined_project_top_directory_to_target_host} ]]; then echo_r \"Error: user_defined_project_top_directory_to_target_host is undefined! \" exit 1 fi echo_g \"\\tChecking user customized variables passed! \" echo_b \"\\tChecking disk space available...\" disk_space_available=`df ${WORKDIR} | tail -n1 | awk '{print $(NF-2)}'` if [[ ${disk_space_available} -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 else echo_g \"\\tChecking disk space available passed! \" fi echo_g \"All required dependencies check passed! \" } function setDirectoryStructureOnLocalHost() { if [ -f ${WORKDIR}/.capistrano_ds_lock ];then echo_g \"Set directory structure has been done, skipping. \" return fi echo_b \"Setting directory structure... \" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branch names or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy [ ! -d ${WORKDIR}/release ] && mkdir ${WORKDIR}/release [ ! -d ${WORKDIR}/repository ] && mkdir ${WORKDIR}/repository [ ! -d ${WORKDIR}/share ] && mkdir ${WORKDIR}/share # end directories structure # Additional directories structure for full deploy operation # for backup remote host config file [ ! -d ${WORKDIR}/backup ] && mkdir ${WORKDIR}/backup # set a directories structure lock touch ${WORKDIR}/.capistrano_ds_lock echo_g \"Set directory structure successfully! \" } function clean_old_releases(){ echo_b \"Clean old releases... \" save_days=${save_old_releases_for_days:-10} if [ ! -d ${WORKDIR}/release ]; then echo_b \"Can NOT find release directory, skipping . \" return fi need_clean=$(find ${WORKDIR}/release -mtime +${save_days} -exec ls '{}' \\;) if [ ! -z ${need_clean} ]; then echo_g \"Expired releases found and will be removed from project! \" find ${WORKDIR}/release -mtime +${save_days} -exec rm -rf '{}' \\; if [ $? -eq 0 ]; then echo_g \"Expired releases have removed from project! \" else echo_r \"Can NOT remove expired releases, please feel free to alter to administrators. \" fi else echo_g \"All releases are not expired, skipping. \" fi } function clean_old_logs(){ echo_b \"Clean old logs... \" save_days=${save_old_releases_for_days:-10} need_clean=$(find ${WORKDIR}/ -name \"*.log\" -mtime +${save_days} -exec ls '{}' \\;) if [ ! -z ${need_clean} ]; then echo_g \"Expired releases found and will be removed from project! \" find -L ${WORKDIR}/ -maxdepth 1 -name \"*.log\" -mtime +${save_days} -exec rm -rf '{}' \\; if [ $? -eq 0 ]; then echo_g \"Expired logs have removed from project! \" else echo_r \"Can NOT remove expired logs, please feel free to alter to administrators. \" fi else echo_g \"All logs are not expired, skipping. \" fi } # git_project_clone repository branch function git_project_clone(){ set -o errexit [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} if test -n $2; then branch=\"$2\" else branch=\"develop\" fi if test ! -d ${project_clone_directory}; then echo_b \"git clone from $project_clone_repository\" # git clone git@github.com:name/app.git -b master git clone ${project_clone_repository} ${project_clone_directory} >>${WORKDIR}/git_$(date +%Y%m%d)_$$.log 2>&1 # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd ${project_clone_directory} git checkout ${branch} >>${WORKDIR}/git_$(date +%Y%m%d)_$$.log 2>&1 cd .. echo_g \"git clone from $project_clone_repository successfully! \" else echo_b \"git pull from $project_clone_repository\" cd ${project_clone_directory} git pull >>${WORKDIR}/git_$(date +%Y%m%d)_$$.log 2>&1 git checkout ${branch} >>${WORKDIR}/git_$(date +%Y%m%d)_$$.log 2>&1 # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd .. echo_g \"git pull from $project_clone_repository successfully! \" fi set +o errexit } function maven_build_project_deprecated(){ set -o errexit echo_b \"Do mvn build java project... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log 2>&1 mvn clean package >>${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log 2>&1 cd .. echo_g \"Do mvn build java project finished with exit code 0! \" set +o errexit } function maven_build_project(){ echo_b \"Do mvn build java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi mvn clean package >>${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd .. echo_g \"Do mvn build java project finished for ${project_clone_repository_name} with exit code 0! \" } function check_ssh_can_be_connect(){ [ $# -ne 1 ] && return 1 echo_b \"Check if can ssh to remote host $1 ... \" check_command_can_be_execute ssh || return 1 # TODO(Guodong Ding) ssh can connect to remote host by using /etc/ssh/ssh_host_rsa_key or ~/.ssh/id_rsa ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"uname -a >/dev/null 2>&1\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"Check ssh to remote host $1 failed! \" exit 1 else echo_g \"Check ssh to remote host $1 successfully! \" fi } # ssh_execute_command_on_remote_host hostname command function ssh_execute_command_on_remote_host(){ [ $# -ne 2 ] && return 1 ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"$2\" >>${WORKDIR}/ssh_command_$(date +%Y%m%d)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"ssh execute command on remote host $2 failed! \" test -s ${WORKDIR}/ssh_command_$(date +%Y%m%d)_$$.log && echo_r \"\\tMore details refer to ${WORKDIR}/ssh_command_$(date +%Y%m%d)_$$.log\" return 1 else echo_g \"ssh execute command on remote host $2 successfully! \" return 0 fi } function restart_docker_container(){ echo_b \"Restarting docker container...\" [ $# -ne 1 ] && return 1 # TODO(Guodong Ding) if we need restart more related docker container local user_defined_docker_container_name=\"\" test -n $1 && user_defined_docker_container_name=\"$1\" ssh_execute_command_on_remote_host \"docker restart $user_defined_docker_container_name\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"restart docker container for $user_defined_docker_container_name failed! \" exit 1 else echo_g \"restart docker container for $user_defined_docker_container_name successfully! \" return 0 fi } # scp_local_files_to_remote_host local_path remote_hostname remote_path function scp_local_files_to_remote_host(){ [ $# -ne 3 ] && return 1 [ ! -d $1 -a ! -f $1 ] && return 1 check_ssh_can_be_connect $2 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp local files to remote host failed! \" exit 1 else echo_g \"scp local files to remote host successfully! \" fi } # scp_remote_files_to_local_host remote_hostname remote_path local_path function scp_remote_files_to_local_host(){ [ $# -ne 3 ] && return 1 check_ssh_can_be_connect $1 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp root@$1:$2 $3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp remote files to local host failed! \" exit 1 else echo_g \"scp remote files to local host successfully! \" fi } function backup_remote_host_config_files(){ echo_b \"backup remote host config files...\" # TODO(Guodong Ding) if $user_defined_project_conf_directory is empty and remote host target directory is empty(first deploy), will cause exit with 1 ssh_execute_command_on_remote_host $user_defined_deploy_target_host_ip \"test \\\"\\$(ls -A $user_defined_project_top_directory_to_target_host 2>/dev/null)\\\"\" if test $? -eq 0; then scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host}/* ${WORKDIR}/backup # get config files [ \"$(ls -A ${WORKDIR}/backup)\" ] && find ${WORKDIR}/backup/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/backup/. -empty -type d -delete # TODO(Guodong Ding) improvements here echo_g \"backup remote host config files finished.\" else echo_y \"This maybe first time to deploy or variable 'user_defined_project_conf_directory' is not defined! \" fi } function rollback_remote_host_config_files(){ echo_b \"rollback remote host config files...\" #scp_local_files_to_remote_host ${WORKDIR}/backup ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/backup/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # TODO(Guodong Ding) if save remote host config files, if there are no changes on config files # some ops # TODO(Guodong Ding) improvements here echo_g \"rollback remote host config files finished.\" } function deploy() { [ -n \"$header\" ] && echo \"$header\" # check a directories lock, Note: this is redundant if [[ ! -f ${WORKDIR}/.lock ]]; then setDirectoryStructureOnLocalHost fi clean_old_releases clean_old_logs # do dependencies checking if test ! -z $user_defined_skip_check_network_and_resolver; then echo_g \"skipping checking network connectivity and name resolve.\" else check_network_connectivity check_name_resolve fi check_other_dependencies check_ssh_can_be_connect ${user_defined_deploy_target_host_ip} # do core job # TODO(Guodong Ding) if we need a git_project_clone \"$user_defined_project_clone_depends\" here using auto judgment statement test -z ${user_defined_project_clone_depends} || git_project_clone \"$user_defined_project_clone_depends\" git_project_clone \"$user_defined_project_clone\" test -z ${user_defined_project_clone_depends} || maven_build_project \"$user_defined_project_clone_depends\" maven_build_project \"$user_defined_project_clone\" cd ${WORKDIR} # links_target_directory_to_current # Make directory to release directory if test ! -d ${WORKDIR}/release -o ! -d ${WORKDIR}/share; then echo_r \"capistrano directory structure is broken, make sure the file .capistrano_ds_lock is deleted before a new deploy! \" exit 1 # test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock fi new_release_just_created=\"$WORKDIR/release/$(date +%Y%m%d%H%M%S)\" [ ! -d ${new_release_just_created} ] && mkdir ${new_release_just_created} [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/ ] && \\ \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/* ${new_release_just_created} # Make source code symbolic link to current ( [ -f ${WORKDIR}/current ] || [ -d ${WORKDIR}/current ] ) && rm -rf ${WORKDIR}/current ln -s ${new_release_just_created} ${WORKDIR}/current # Move conf and logs directives from release to share if found [ -d ${WORKDIR}/release/conf ] && mv ${WORKDIR}/release/conf ${WORKDIR}/share/conf [ -d ${WORKDIR}/release/logs ] && mv ${WORKDIR}/release/logs ${WORKDIR}/share/logs # Make conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current/conf [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current/logs # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if [ ! -z ${user_defined_project_conf_directory} ]; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh start ssh_execute_command_on_remote_host $user_defined_deploy_target_host_ip \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy successfully! \" echo_g \"current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" # ls --color=auto -l ${WORKDIR}/current # ls --color=auto -l ${WORKDIR}/current/ else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollback fi } # Rollback to last right configuration function rollback() { [ -n \"$header\" ] && echo \"$header\" echo_b \"Rollback to last right configuration... \" # The key is find last files which can work WORKABLE_PROGRAM=`cat ${WORKDIR}/share/workable_program.log` if [[ -z ${WORKABLE_PROGRAM} ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # Stop service if we have # test ! -z $user_defined_docker_container_name && docker stop $user_defined_docker_container_name if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ${WORKDIR}/current/bin/startup.sh stop fi # Remove failed deploy rm -rf ${WORKDIR}/current # Remake source code symbolic link to current ln -s ${WORKABLE_PROGRAM} ${WORKDIR}/current # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if [ ! -z ${user_defined_project_conf_directory} ]; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ${WORKDIR}/current/bin/startup.sh restart RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $WORKABLE_PROGRAM\" # ls --color=auto -l ${WORKDIR}/current fi } # rollback to any workable version which user wished by manually function rollback_manual(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit.\" if test -d $WORKDIR/release -a \"$(ls -A $WORKDIR/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Top 5 ) are here: \" # ls -d -1 $WORKDIR/release/* ls -u -1 -d $WORKDIR/release/* | head -n5 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d $user_input_release_to_rollback; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if [ ! -z ${user_defined_project_conf_directory} ]; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ${WORKDIR}/current/bin/startup.sh restart RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $user_defined_docker_container_name\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } function destroy() { [ -n \"$header\" ] && echo \"$header\" # echo a Warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" user_input_answer_want_do_destroy=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" user_input_answer_want_do_destroy case \"$user_input_answer_want_do_destroy\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"filename\" | xargs rm -rf find -L ${WORKDIR} -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf '{}' \\; if [ $? -eq 0 ];then test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } function main(){ lock_filename=\"lock_$$_$RANDOM\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT # Just a test for call itself, comment it if [[ $# -ne 1 ]]; then # $0 deploy [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` ${WORKDIR}/`basename $0` deploy exit 0 fi case $1 in deploy) deploy ;; rollback) rollback ;; rollback_manual) rollback_manual ;; destroy) destroy ;; help|*) echo \"Usage: $0 {deploy|rollback|rollback_manual|destroy} with $0 itself\" exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option if $DEBUG ; then export PS4=$old_PS4 ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_435.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\file_435.sh",
            "content": "#!/bin/bash # Name: doDeploy.sh #Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. # debug option DEBUG=false #DEBUG=true if ${DEBUG} ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi # define user friendly messages header=\" Function: Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. License: Open source software \" # set an empty function using for location this line quickly in PyCharm editor on purpose. function _empty() { return; } # user defined variables # Where to get source code user_defined_project_clone_depends=\"ssh://git@git.example.com:18082/core/business-service-base.git\" user_defined_project_clone=\"ssh://git@git.example.com:18082/core/business-service-core.git\" user_defined_deploy_target_host_ip=\"10.6.28.125\" # this is a mandatory field, and must be same as the first ip in $user_defined_deploy_targets_host_ip_list user_defined_deploy_targets_host_ip_list=\"10.6.28.125\" # deploy to multi-hosts setting here, using space as delimiter user_defined_project_top_directory_to_target_host=\"/data/docker/business-service/bs-core-02\" user_defined_docker_container_name=\"bs-core-02\" # if you using a docker container other than a startup script located in sourcecode/bin/startup.sh, then set this to docker container name user_defined_project_conf_directory=\"config_backup\" # if you do NOT want to use configurations from deploy target, you should set this variable to where pointed to config files user_defined_skip_check_network_and_resolver=\"true\" # if system administrator disable ICMP protocol, set this any content but not null # Setting how many days do you want save old releases, default is 10 days save_old_releases_for_days=10 # end define variables # pretreatment predefined variables # TODO(Guodong Ding) project_clone_target_depends_1 is not used for git clone because git has done for us test -z ${user_defined_project_clone_depends} || project_clone_target_depends_1=\"`echo ${user_defined_project_clone_depends} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_target=\"`echo ${user_defined_project_clone} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_repository_name=${project_clone_target} deployment_mode=\"\" # end pretreatment predefined variables # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi function command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } function check_command_can_be_execute(){ [ $# -ne 1 ] && return 1 command_exists $1 } function check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once time! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" echo fi } function check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" echo return 0 fi } function check_ssh_can_be_connect(){ [ $# -ne 1 ] && return 1 echo_b \"Check if can ssh to remote host $1 ... \" check_command_can_be_execute ssh || return 1 # TODO(Guodong Ding) ssh can connect to remote host by using /etc/ssh/ssh_host_rsa_key or ~/.ssh/id_rsa ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"uname -a >/dev/null 2>&1\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"Check ssh to remote host $1 failed! \" exit 1 else echo_g \"Check ssh to remote host $1 successfully! \" fi } function check_other_dependencies() { echo_b \"Checking other dependencies for deploy procedure... \" echo_b \"\\tChecking user customized variables...\" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z ${user_defined_project_clone} ]]; then echo_r \"Error: user_defined_project_clone is undefined! \" exit 1 fi # Note: test command is strongly typed, can recognize string type and integer type if test ! -z \"$user_defined_deploy_target_host_ip\" -a ! -z \"$user_defined_deploy_targets_host_ip_list\" ; then user_defined_deploy_targets_host_first_ip_in_list=\"`echo \"$user_defined_deploy_targets_host_ip_list\" | awk -F ' ' '{ print $1 }'`\" if test \"$user_defined_deploy_target_host_ip\" = \"$user_defined_deploy_targets_host_first_ip_in_list\" -a \"$deployment_mode\" = \"0\" ; then echo_g \"Run this shell script in multi-deployment mode, deploy to a group of hosts.\" saved_IFS=$IFS IFS=' ' for ipaddress in ${user_defined_deploy_targets_host_ip_list}; do check_ssh_can_be_connect ${ipaddress} done IFS=${saved_IFS} elif test \"$user_defined_deploy_target_host_ip\" != \"$user_defined_deploy_targets_host_first_ip_in_list\"; then echo_r \"\\\"$user_defined_deploy_targets_host_ip_list\\\" is not equal to \\\"$user_defined_deploy_target_host_ip\\\", this is a must! \" exit 1 fi elif test ! -z \"$user_defined_deploy_target_host_ip\" -a -z \"$user_defined_deploy_targets_host_ip_list\" -a \"$deployment_mode\" = \"1\" ;then echo_g \"Run this shell script in standalone-deployment mode, deploy to single host.\" elif test -z \"$user_defined_deploy_target_host_ip\" -a -z \"$user_defined_deploy_targets_host_ip_list\" ;then echo_r \"Error: both user_defined_deploy_target_host_ip and user_defined_deploy_targets_host_ip_list is undefined! \" exit 1 else echo_r \"Error: bad user defined parameters, please fix it and try again! \" exit 1 fi if [[ -z ${user_defined_project_top_directory_to_target_host} ]]; then echo_r \"Error: user_defined_project_top_directory_to_target_host is undefined! \" exit 1 fi if test -z ${user_defined_project_conf_directory}; then # TODO(Guodong Ding) check directory if exist if test -d ${WORKDIR}/${user_defined_project_conf_directory}; then echo_y \"Warning: ${WORKDIR}/${user_defined_project_conf_directory} is not exist!\" fi echo_y \"Warning: user defined project conf directory is not defined! \" fi echo_g \"\\tChecking user customized and defined variables passed! \" echo_b \"\\tChecking disk space available...\" disk_space_available=`df ${WORKDIR} | tail -n1 | awk '{print $(NF-2)}'` if [[ ${disk_space_available} -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 else echo_g \"\\tChecking disk space available passed! \" fi echo_g \"All required dependencies check passed! \" echo } function setDirectoryStructureOnLocalHost() { set -o errexit if [ -f ${WORKDIR}/.capistrano_ds_lock ];then echo_g \"Set directory structure has been done, skipping. \" return fi echo_b \"Setting directory structure... \" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branch names or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy [ ! -d ${WORKDIR}/release ] && mkdir ${WORKDIR}/release [ ! -d ${WORKDIR}/repository ] && mkdir ${WORKDIR}/repository [ ! -d ${WORKDIR}/share ] && mkdir ${WORKDIR}/share # end directories structure # Additional directories structure for full deploy operation # for backup remote host config file [ ! -d ${WORKDIR}/${user_defined_project_conf_directory} ] && mkdir ${WORKDIR}/${user_defined_project_conf_directory} # deploy logs for git/mvn/ssh [ ! -d ${WORKDIR}/logs ] && mkdir ${WORKDIR}/logs # set a directories structure lock touch ${WORKDIR}/.capistrano_ds_lock echo_g \"Set directory structure successfully! \" echo set +o errexit } function clean_old_releases(){ echo_b \"Clean old releases... \" save_days=${save_old_releases_for_days:-10} if [ ! -d ${WORKDIR}/release ]; then echo_b \"Can NOT find release directory, skipping . \" return fi need_clean=$(find ${WORKDIR}/release -mtime +${save_days} -exec ls '{}' \\;) if [ ! -z ${need_clean} ]; then echo_c \"Expired releases found and will be removed from project! \" find ${WORKDIR}/release -mtime +${save_days} -exec rm -rf '{}' \\; if [ $? -eq 0 ]; then echo_g \"Expired releases have removed from project! \" else echo_r \"Can NOT remove expired releases, please feel free to alter to administrators. \" fi else echo_g \"All releases are not expired, skipping. \" fi } function clean_old_logs(){ echo_b \"Clean old logs... \" save_days=${save_old_releases_for_days:-10} need_clean=$(find ${WORKDIR}/ -name \"*.log\" -mtime +${save_days} -exec ls '{}' \\;) if [ ! -z ${need_clean} ]; then echo_c \"Expired releases found and will be removed from project! \" find -L ${WORKDIR}/ -maxdepth 1 -name \"*.log\" -a ! -name \"^.\" -mtime +${save_days} -exec rm -rf '{}' \\; if [ $? -eq 0 ]; then echo_g \"Expired logs have removed from project! \" else echo_r \"Can NOT remove expired logs, please feel free to alter to administrators. \" fi else echo_g \"All logs are not expired, skipping. \" fi } # git_project_clone repository branch # Note: # git checkout <branch name>, change current branch to another branch # git checkout -b <branch name>, create current branch to new branch function git_project_clone(){ set -o errexit [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} # TODO(Guodong Ding) let user set this variable(\"branch\") branch=\"develop\" if test -n \"$2\"; then branch=\"$2\" else branch=\"develop\" fi if test ! -d ${project_clone_directory}; then echo_b \"git clone from $project_clone_repository\" # git clone git@github.com:name/app.git -b master git clone ${project_clone_repository} ${project_clone_directory} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd ${project_clone_directory} git checkout ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 git pull origin ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log cd ${WORKDIR} echo_g \"git clone from $project_clone_repository successfully! \" else echo_b \"git pull from $project_clone_repository\" cd ${project_clone_directory} git pull origin ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log else git checkout ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log fi # TODO(Guodong Ding) get branch names or revision numbers from VCS data # git rev-parse HEAD # git rev-parse --verify HEAD # git rev-parse HEAD | cut -c1-10 # git show-ref # git for-each-ref # git log --pretty=format:'%h' -n 1 # git log -1 --format=\"%H\" # git rev-list --max-count=1 HEAD # git show --pretty=%h cd ${WORKDIR} echo_g \"git pull from $project_clone_repository successfully! \" fi set +o errexit } function maven_build_project_deprecated(){ set -o errexit echo_b \"Do mvn build java project... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 mvn clean package >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 cd ${WORKDIR} echo_g \"Do mvn build java project finished with exit code 0! \" set +o errexit } function maven_build_project(){ echo_b \"Do mvn build java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi mvn clean package >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn build java project finished for ${project_clone_repository_name} with exit code 0! \" echo } function maven_install(){ echo_b \"Do mvn install java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_install_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/logs/mvn_install_$(date +%Y%m%d%H%M%S)_$$.log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn install java project finished for ${project_clone_repository_name} with exit code 0! \" echo } function maven_clean_package(){ echo_b \"Do mvn clean package java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn clean package >>${WORKDIR}/logs/mvn_clean_package_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/logs/mvn_clean_package_$(date +%Y%m%d%H%M%S)_$$.log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn clean package java project finished for ${project_clone_repository_name} with exit code 0! \" echo } # ssh_execute_command_on_remote_host hostname command function ssh_execute_command_on_remote_host(){ [ $# -ne 2 ] && return 1 ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"$2\" >>${WORKDIR}/logs/ssh_command_$(date +%Y%m%d)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"ssh execute command on remote host $2 failed! \" test -s ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d)_$$.log && echo_r \"\\tMore details refer to ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d)_$$.log\" return 1 else echo_g \"ssh execute command on remote host $2 successfully! \" return 0 fi } function restart_docker_container(){ echo_b \"Restarting docker container...\" [ $# -ne 2 ] && return 1 # TODO(Guodong Ding) if we need restart more related docker container local user_defined_docker_container_name=\"\" local remote_host_ip=\"\" test -n $1 && remote_host_ip=\"$1\" test -n $2 && user_defined_docker_container_name=\"$2\" ssh_execute_command_on_remote_host \"$remote_host_ip\" \"docker restart $user_defined_docker_container_name\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"restart docker container for $user_defined_docker_container_name on $remote_host_ip failed! \" exit 1 else echo_g \"restart docker container for $user_defined_docker_container_name on $remote_host_ip successfully! \" return 0 fi } # scp_local_files_to_remote_host local_path remote_hostname remote_path function scp_local_files_to_remote_host(){ [ $# -ne 3 ] && return 1 [ ! -d $1 -a ! -f $1 ] && return 1 # check_ssh_can_be_connect $2 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp local files to remote host failed! \" echo_r \"scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1\" exit 1 else echo_g \"scp local files to remote host successfully! \" fi } # scp_remote_files_to_local_host remote_hostname remote_path local_path function scp_remote_files_to_local_host(){ [ $# -ne 3 ] && return 1 # check_ssh_can_be_connect $1 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp root@$1:$2 $3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp remote files to local host failed! \" exit 1 else echo_g \"scp remote files to local host successfully! \" fi } function backup_single_file(){ set -o errexit if [ \"$#\" -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=\"`date +\"%Y%m%d%H%M%S\"`\" backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f ${backup_filename_origin} && cp ${backup_filename_origin} ${backup_filename_target} set +o errexit } # Function description: backup files # Note: accept $@ parameters function backup_files(){ # TODO(Guodong Ding) improvements here set -o errexit if [ $# -eq 0 ]; then return 1 fi file_list=$@ operation_date_time=\"_`date +\"%Y%m%d%H%M%S\"`\" log_filename=\".log_$$_${RANDOM}\" log_filename_full_path=/tmp/${log_filename} touch ${log_filename_full_path} old_IFS=$IFS IFS=\" \" for file in ${file_list};do real_file=$(realpath ${file}) [ -f ${real_file} ] && cp ${real_file} ${file}${operation_date_time}~ [ -f ${log_filename_full_path} ] && echo \"\\mv -f $file$operation_date_time~ $file\" >>${log_filename_full_path} done IFS=\"$old_IFS\" set +o errexit return 0 } # Function description: function rollback_files(){ # TODO(Guodong Ding) improvements here [ -f ${log_filename_full_path} ] && . ${log_filename_full_path} \\rm -f ${log_filename_full_path} exit 2 } # backup directories locally function backup_directories(){ # TODO(Guodong Ding) continue here if [ $# -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=\"`date +\"%Y%m%d%H%M%S\"`\" backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f ${backup_filename_origin} && cp -r ${backup_filename_origin} ${backup_filename_target} } function rollback_directories(){ # TODO(Guodong Ding) continue here return } # function backup_remote_host_config_files(){ # TODO(Guodong Ding) did not throw a exception when first deploy and test -z \"$user_defined_project_conf_directory\" echo_b \"backup remote host config files...\" # backup operation only executed once time, using '$0 backup_manual' backup new configuration files. # if ${WORKDIR}/${user_defined_project_conf_directory} is not empty then return 0 to exit if [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ]; then [ -f ${WORKDIR}/${user_defined_project_conf_directory}.backup_operation_once.log ] && backup_operation=\"`cat ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log`\" echo_g \"Backup remote host config files operation had been done, $backup_operation, now skipping ... \" return 0 fi # TODO(Guodong Ding) if $user_defined_project_conf_directory is empty and remote host target directory is empty(first deploy), will cause exit with 1 ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"test \\\"\\$(ls -A $user_defined_project_top_directory_to_target_host 2>/dev/null)\\\"\" if test $? -eq 0; then scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host}/* ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log else echo_y \"This maybe first time to deploy or variable 'user_defined_project_conf_directory' is not defined! \" fi } function rollback_remote_host_config_files(){ echo_b \"rollback remote host config files...\" #scp_local_files_to_remote_host ${WORKDIR}/${user_defined_project_conf_directory} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -r ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} # TODO(Guodong Ding) if save remote host config files, if there are no changes on config files # some ops # TODO(Guodong Ding) improvements here echo_g \"rollback remote host config files finished.\" } function make_current_workable_source(){ # check a directories lock, Note: this is redundant if [[ ! -f ${WORKDIR}/.capistrano_ds_lock ]]; then setDirectoryStructureOnLocalHost fi clean_old_releases clean_old_logs # do dependencies checking if test ! -z ${user_defined_skip_check_network_and_resolver}; then echo_g \"skipping checking network connectivity and name resolve.\" else check_network_connectivity check_name_resolve fi check_other_dependencies # do core job # TODO(Guodong Ding) if we need a git_project_clone \"$user_defined_project_clone_depends\" here using auto judgment statement test -z ${user_defined_project_clone_depends} || git_project_clone \"$user_defined_project_clone_depends\" git_project_clone \"$user_defined_project_clone\" test -z ${user_defined_project_clone_depends} || maven_install \"$user_defined_project_clone_depends\" maven_clean_package \"$user_defined_project_clone\" cd ${WORKDIR} # links_target_directory_to_current # Make directory to release directory if test ! -d ${WORKDIR}/release -o ! -d ${WORKDIR}/share; then echo_r \"capistrano directory structure is broken, make sure the file .capistrano_ds_lock is deleted before a new deploy! \" # test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock exit 1 fi new_release_just_created=\"$WORKDIR/release/$(date +%Y%m%d%H%M%S)\" [ ! -d ${new_release_just_created} ] && mkdir ${new_release_just_created} # for special project, such as a project have different name from its git repository name, for example here, \"chatter\" # TODO(Guodong Ding) find more this foreseeable exception here if [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/ ]; then \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/* ${new_release_just_created} elif [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/chatter ]; then \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/chatter/* ${new_release_just_created} else echo_r \"A foreseeable error occurred, please alter to Developer & Administrator. \" exit 1 fi # Make source code symbolic link to current ( [ -f ${WORKDIR}/current ] || [ -d ${WORKDIR}/current ] ) && rm -rf ${WORKDIR}/current ln -s ${new_release_just_created} ${WORKDIR}/current # for some bash scripts in the ${WORKDIR}/current find ${WORKDIR}/current/ -type f -name \"*.sh\" -exec chmod +x '{}' \\; # Move conf and logs directives from release to share if found [ -d ${WORKDIR}/release/conf ] && mv ${WORKDIR}/release/conf ${WORKDIR}/share/conf [ -d ${WORKDIR}/release/logs ] && mv ${WORKDIR}/release/logs ${WORKDIR}/share/logs # Make conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current/conf [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current/logs } # distribute current workable files to remote host function deploy() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_target_host_ip ...\" # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # remove all file in remote host target directories and files, if target is not exist, then create it. ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"if test -d $user_defined_project_top_directory_to_target_host; then find -L $user_defined_project_top_directory_to_target_host -maxdepth 1 ! -name \"logs\" ! -wholename \"${user_defined_project_top_directory_to_target_host}\" -exec rm -rf {} \\; ; else mkdir -p $user_defined_project_top_directory_to_target_host; fi\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory} ; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi # backup remote host config files to local again for next using [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy successfully for $user_defined_deploy_target_host_ip! \" echo_g \"Current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollback fi } # Rollback to last right configuration function rollback() { echo_b \"Rollback to last right configuration... \" # The key point is find last files which can work WORKABLE_PROGRAM=`cat ${WORKDIR}/share/workable_program.log` if [[ -z ${WORKABLE_PROGRAM} ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # Stop service if we have if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh stop\" fi # Remove failed deploy rm -rf ${WORKDIR}/current # Remake source code symbolic link to current ln -s ${WORKABLE_PROGRAM} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $WORKABLE_PROGRAM\" fi } # rollback to any workable version which user wished by manually function rollback_manual(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something go wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # Alternative implementation: ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | sed -n '1,4p' ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | head -n4 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # # rollback remote host config files # [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do # TODO(Guodong Ding) scp timeout scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } # backup remote hosts config files only, # use this function when you modify some config files on remote host function backup_manual(){ set -o errexit # Bug fixed: check config backup directory(directories) if exist, useful when execute backup_manual function before other functions. if test ! -d ${WORKDIR}/${user_defined_project_conf_directory}; then mkdir -p ${WORKDIR}/${user_defined_project_conf_directory} fi echo_b \"backup remote host config files...\" scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} \"${user_defined_project_top_directory_to_target_host}/*\" ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log set +o errexit } # distribute current workable files to remote hosts function deploys() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_targets_host_ip_list ...\" for remote_host_ip in ${user_defined_deploy_targets_host_ip_list};do echo_b \"Do deploy on $remote_host_ip ...\" # remove all file in remote host target directories and files ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"if test -d $user_defined_project_top_directory_to_target_host; then cd $user_defined_project_top_directory_to_target_host && rm $user_defined_project_top_directory_to_target_host/*; else mkdir -p $user_defined_project_top_directory_to_target_host; fi\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${remote_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${remote_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh start ssh_execute_command_on_remote_host ${remote_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${remote_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Deploy successfully on $remote_host_ip! \" else echo_r \"Error: Deploy failed! on $remote_host_ip! \" echo_p \"Try modify $user_defined_deploy_target_host_ip and using standalone deployment mode\" exit 1 fi done # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy finished! on $user_defined_deploy_targets_host_ip_list \" echo_g \"current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" # ls --color=auto -l ${WORKDIR}/current # ls --color=auto -l ${WORKDIR}/current/ else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollbacks fi } function rollbacks(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something go wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit. Enter 'reset' command to reset terminal when something go wrong.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # ls -d -1 ${WORKDIR}/release/* ls -u -1 -d ${WORKDIR}/release/* | tail -n5 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for host_ip in ${user_defined_deploy_targets_host_ip_list};do for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully on $user_defined_deploy_targets_host_ip_list! \" echo_g \"Current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } function destroy() { # echo a Warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" user_input_answer_want_do_destroy=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" user_input_answer_want_do_destroy case \"$user_input_answer_want_do_destroy\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"filename\" | xargs rm -rf find -L ${WORKDIR} -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf '{}' \\; if [ $? -eq 0 ];then test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } function usage(){ cat - << eof \"${WORKDIR}/`basename $0` deploy new deploy/ update one remote target host \"${WORKDIR}/`basename $0` rollback_manual rollback to any workable version to one remote target host by manual \"${WORKDIR}/`basename $0` deploys new deploy/ update more then one remote target host \"${WORKDIR}/`basename $0` rollbacks rollback to any workable version to more than one remote target host by manual \"${WORKDIR}/`basename $0` backup_manual| backup backup conf files to local by manual when you add/delete/update conf files on remote target host eof } function main(){ lock_filename=\"lock_$$_${RANDOM}\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` [ -n \"$header\" ] && echo \"$header\" # # if exist file '.capistrano_ds_lock', then this is not first deployment, and unset # if test -f ${WORKDIR}/.capistrano_ds_lock; then # unset user_defined_project_conf_directory # user_defined_project_conf_directory=\"\" # fi if [[ $# -lt 1 ]]; then ${WORKDIR}/`basename $0` help exit 0 fi case $1 in deploy) deployment_mode=\"1\" deploy ;; rollback) rollback ;; rollback_manual|rollbackup_manual) rollback_manual ;; backup_manual|backup) backup_manual ;; deploys) deployment_mode=\"0\" deploys; ;; rollbacks|rollbackups) rollbacks ;; destroy) destroy ;; help|*) echo \"Usage: $0 {deploy|rollback_manual|deploys|backup_manual} with $0 itself\" usage exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_436.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\file_436.sh",
            "content": "#!/bin/bash # Name: doDeploy.sh #Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. # About V2 # Improvements: TODO(Guodong Ding) continue here # 1.backup remote host deploy target if target is not empty # 2.let user choose if restart docker container, if true then restart container, else load global restart script(Name:global_restart_containers_script.sh) # 3.whenever do backup operation, save every backup to a .zip file. # Bug fix: # 1.adding here # 2.adding here # 3.adding here # debug option DEBUG=false #DEBUG=true if ${DEBUG} ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi # define user friendly messages header=\" Function: Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. License: Open source software \" # set an empty function using for location this line quickly in PyCharm editor on purpose. function _empty() { return; } # user defined variables # Where to get source code user_defined_project_clone_depends=\"ssh://git@git.example.com:18082/core/business-service-base.git\" user_defined_project_clone=\"ssh://git@git.example.com:18082/core/business-service-core.git\" user_defined_deploy_target_host_ip=\"10.6.28.125\" # this is a mandatory field, and must be same as the first ip in $user_defined_deploy_targets_host_ip_list user_defined_deploy_targets_host_ip_list=\"10.6.28.125\" # deploy to multi-hosts setting here, using space as delimiter user_defined_project_top_directory_to_target_host=\"/data/docker/business-service/bs-core-02\" user_defined_docker_container_name=\"bs-core-02\" # if you using a docker container other than a startup script located in sourcecode/bin/startup.sh, then set this to docker container name user_defined_project_conf_directory=\"config_backup\" # if you do NOT want to use configurations from deploy target, you should set this variable to where pointed to config files user_defined_skip_check_network_and_resolver=\"true\" # if system administrator disable ICMP protocol, set this any content but not null user_defined_global_restart_containers_script=\"/root/autodeploy/deploy_to_uat/global_restart_containers_script.sh\" # external shell script path should be full(absolute path) user_defined_remote_host_target_backup_directory=\"target_backup\" # Setting how many days do you want save old releases, default is 10 days save_old_releases_for_days=10 # end define variables # pretreatment predefined variables # TODO(Guodong Ding) project_clone_target_depends_1 is not used for git clone because git has done for us test -z ${user_defined_project_clone_depends} || project_clone_target_depends_1=\"`echo ${user_defined_project_clone_depends} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_target=\"`echo ${user_defined_project_clone} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_repository_name=${project_clone_target} deployment_mode=\"\" # end pretreatment predefined variables # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi function command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } function check_command_can_be_execute(){ [ $# -ne 1 ] && return 1 command_exists $1 } function check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" echo fi } function check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" echo return 0 fi } function check_ssh_can_be_connect(){ [ $# -ne 1 ] && return 1 echo_b \"Check if can ssh to remote host $1 ... \" check_command_can_be_execute ssh || return 1 # TODO(Guodong Ding) ssh can connect to remote host by using /etc/ssh/ssh_host_rsa_key or ~/.ssh/id_rsa ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"uname -a >/dev/null 2>&1\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"Check ssh to remote host $1 failed! \" exit 1 else echo_g \"Check ssh to remote host $1 successfully! \" fi } function check_other_dependencies() { echo_b \"Checking other dependencies for deploy procedure... \" echo_b \"\\tChecking user customized variables...\" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z ${user_defined_project_clone} ]]; then echo_r \"Error: user_defined_project_clone is undefined! \" exit 1 fi # Note: test command is strongly typed, can recognize string type and integer type if test ! -z \"$user_defined_deploy_target_host_ip\" -a ! -z \"$user_defined_deploy_targets_host_ip_list\" ; then user_defined_deploy_targets_host_first_ip_in_list=\"`echo \"$user_defined_deploy_targets_host_ip_list\" | awk -F ' ' '{ print $1 }'`\" if test \"$user_defined_deploy_target_host_ip\" = \"$user_defined_deploy_targets_host_first_ip_in_list\" -a \"$deployment_mode\" = \"0\" ; then echo_g \"Run this shell script in multi-deployment mode, deploy to a group of hosts.\" saved_IFS=$IFS IFS=' ' for ipaddress in ${user_defined_deploy_targets_host_ip_list}; do check_ssh_can_be_connect ${ipaddress} done IFS=${saved_IFS} elif test \"$user_defined_deploy_target_host_ip\" != \"$user_defined_deploy_targets_host_first_ip_in_list\"; then echo_r \"\\\"$user_defined_deploy_targets_host_ip_list\\\" is not equal to \\\"$user_defined_deploy_target_host_ip\\\", this is a must! \" exit 1 fi elif test ! -z \"$user_defined_deploy_target_host_ip\" -a -z \"$user_defined_deploy_targets_host_ip_list\" -a \"$deployment_mode\" = \"1\" ;then echo_g \"Run this shell script in standalone-deployment mode, deploy to single host.\" elif test -z \"$user_defined_deploy_target_host_ip\" -a -z \"$user_defined_deploy_targets_host_ip_list\" ;then echo_r \"Error: both user_defined_deploy_target_host_ip and user_defined_deploy_targets_host_ip_list is undefined! \" exit 1 else echo_r \"Error: bad user defined parameters, please fix it and try again! \" exit 1 fi if [[ -z ${user_defined_project_top_directory_to_target_host} ]]; then echo_r \"Error: user_defined_project_top_directory_to_target_host is undefined! \" exit 1 fi if test -z ${user_defined_project_conf_directory}; then if test -d ${WORKDIR}/${user_defined_project_conf_directory}; then echo_y \"Warning: ${WORKDIR}/${user_defined_project_conf_directory} is not exist!\" fi echo_y \"Warning: user defined project conf directory is not defined! \" fi if test -z ${user_defined_remote_host_target_backup_directory}; then if test -d ${WORKDIR}/${user_defined_remote_host_target_backup_directory}; then echo_y \"Warning: ${WORKDIR}/${user_defined_remote_host_target_backup_directory} is not exist!\" fi echo_y \"Warning: user defined remote host backup directory is not defined! \" fi echo_g \"\\tChecking user customized and defined variables passed! \" echo_b \"\\tChecking disk space available...\" disk_space_available=`df ${WORKDIR} | tail -n1 | awk '{print $(NF-2)}'` if [[ ${disk_space_available} -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 else echo_g \"\\tChecking disk space available passed! \" fi echo_g \"All required dependencies check passed! \" echo } function setDirectoryStructureOnLocalHost() { set -o errexit if [ -f ${WORKDIR}/.capistrano_ds_lock ];then echo_g \"Set capistrano directory structure has been done, skipping. \" return fi echo_b \"Setting capistrano directory structure... \" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branch names or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy [ ! -d ${WORKDIR}/release ] && mkdir ${WORKDIR}/release [ ! -d ${WORKDIR}/repository ] && mkdir ${WORKDIR}/repository [ ! -d ${WORKDIR}/shared ] && mkdir ${WORKDIR}/shared # end directories structure # Additional directories structure for full deploy operation # for backup remote host config file [ ! -d ${WORKDIR}/${user_defined_project_conf_directory} ] && mkdir ${WORKDIR}/${user_defined_project_conf_directory} [ ! -d ${WORKDIR}/${user_defined_remote_host_target_backup_directory} ] && mkdir ${WORKDIR}/${user_defined_remote_host_target_backup_directory} # set a directories structure lock touch ${WORKDIR}/.capistrano_ds_lock echo_g \"Set capistrano directory structure successfully! \" echo set +o errexit } function clean_old_releases(){ echo_b \"Clean old releases... \" save_days=${save_old_releases_for_days:-10} if [ ! -d ${WORKDIR}/release ]; then echo_b \"Can NOT find release directory, skipping . \" return fi need_clean=$(find ${WORKDIR}/release -mtime +${save_days} -exec ls '{}' \\;) if [ ! -z ${need_clean} ]; then echo_c \"Expired releases found and will be removed from project! \" find ${WORKDIR}/release -mtime +${save_days} -exec rm -rf '{}' \\; if [ $? -eq 0 ]; then echo_g \"Expired releases have removed from project! \" else echo_r \"Can NOT remove expired releases, please feel free to alter to administrators. \" fi else echo_g \"All releases are not expired, skipping. \" fi } function clean_old_logs(){ echo_b \"Clean old logs... \" save_days=${save_old_releases_for_days:-10} need_clean=$(find ${WORKDIR}/ -name \"*.log\" -mtime +${save_days} -exec ls '{}' \\;) if [ ! -z ${need_clean} ]; then echo_c \"Expired releases found and will be removed from project! \" find -L ${WORKDIR}/ -maxdepth 1 -name \"*.log\" -a ! -name \"^.\" -mtime +${save_days} -exec rm -rf '{}' \\; if [ $? -eq 0 ]; then echo_g \"Expired logs have removed from project! \" else echo_r \"Can NOT remove expired logs, please feel free to alter to administrators. \" fi else echo_g \"All logs are not expired, skipping. \" fi } function clean_old_files_older_than_day(){ save_days=10 files_ops=\"/data/docker/logs/myApp/\" need_clean=$(find ${files_ops} -name \"*.log\" -mtime +${save_days} -exec ls '{}' \\;) if [ ! -z ${need_clean} ]; then echo \"Old logs have been found, clean old logs now. \" find -L ${files_ops} -maxdepth 1 -name \"*.log\" -a ! -name \"^.\" -mtime +${save_days} -exec rm -rf '{}' \\; else echo \"All logs are not expired, skipping. \" fi } function keep_some_newest_files(){ num_save=10 files_ops=\"/data/backup/db/mysql/\" num_files=$(find ${files_ops} -type d -printf \"%C@ %p\\n\" | sort -n | wc -l) if test ${num_files} -gt ${num_save};then echo \"total number of files is $num_files.\" num_ops=$(expr ${num_files} - ${num_save}) echo \"$num_ops files are going to be handled.\" list_ops=$(find ${files_ops} -type d -printf \"%C@ %p\\n\" | sort -n | head -n${num_ops} | awk -F '[ ]+' '{print $2}') # IFS=' '$'\\t'$'\\n', IFS=$' \\t\\n', If IFS is unset, or its value is exactly <space><tab><newline> old_IFS=$IFS IFS=\" \" for file_ops in ${list_ops};do echo \"$file_ops\" test -d ${file_ops} && rm -rf ${file_ops} done IFS=\"$old_IFS\" else echo \"total number of files is $num_files.\" echo \"0 files are going to be handled, skipping.\" fi } # git_project_clone repository branch # Note: # git checkout <branch name>, change current branch to another branch # git checkout -b <branch name>, create current branch to new branch function git_project_clone(){ set -o errexit [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} # TODO(Guodong Ding) let user set this variable(\"branch\") branch=\"develop\" if test -n \"$2\"; then branch=\"$2\" else branch=\"develop\" fi if test ! -d ${project_clone_directory}; then echo_b \"git clone from $project_clone_repository\" # git clone git@github.com:name/app.git -b master # git clone --depth=50 --branch=master https://github.com/racaljk/hosts.git racaljk/hosts git clone ${project_clone_repository} ${project_clone_directory} >>${WORKDIR}/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd ${project_clone_directory} git checkout ${branch} >>${WORKDIR}/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 git status 2>&1 | tee ${WORKDIR}/git_$(date +%Y%m%d%H%M%S)_$$.log cd ${WORKDIR} echo_g \"git clone from $project_clone_repository successfully! \" else echo_b \"git pull from $project_clone_repository\" cd ${project_clone_directory} git pull origin ${branch} >>${WORKDIR}/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/git_$(date +%Y%m%d%H%M%S)_$$.log else git checkout ${branch} >>${WORKDIR}/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 git status 2>&1 | tee ${WORKDIR}/git_$(date +%Y%m%d%H%M%S)_$$.log fi # TODO(Guodong Ding) get branch names or revision numbers from VCS data # git rev-parse HEAD # git rev-parse --verify HEAD # git rev-parse HEAD | cut -c1-10 # git show-ref # git for-each-ref # git log --pretty=format:'%h' -n 1 # git log -1 --format=\"%H\" # git rev-list --max-count=1 HEAD # git show --pretty=%h cd ${WORKDIR} echo_g \"git pull from $project_clone_repository successfully! \" fi set +o errexit } function maven_build_project(){ echo_b \"Do mvn build java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi mvn clean package >>${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/mvn_build_$(date +%Y%m%d)_$$.log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn build java project finished for ${project_clone_repository_name} with exit code 0! \" echo } # ssh_execute_command_on_remote_host hostname command function ssh_execute_command_on_remote_host(){ [ $# -ne 2 ] && return 1 ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"$2\" >>${WORKDIR}/ssh_command_$(date +%Y%m%d)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"ssh execute command on remote host $2 failed! \" test -s ${WORKDIR}/ssh_command_$(date +%Y%m%d)_$$.log && echo_r \"\\tMore details refer to ${WORKDIR}/ssh_command_$(date +%Y%m%d)_$$.log\" return 1 else echo_g \"ssh execute command on remote host $2 successfully! \" return 0 fi } function restart_docker_container(){ echo_b \"Restarting docker container...\" [ $# -ne 2 ] && return 1 # TODO(Guodong Ding) if we need restart more related docker container local user_defined_docker_container_name=\"\" local remote_host_ip=\"\" test -n $1 && remote_host_ip=\"$1\" test -n $2 && user_defined_docker_container_name=\"$2\" ssh_execute_command_on_remote_host \"$remote_host_ip\" \"docker restart $user_defined_docker_container_name\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"restart docker container for $user_defined_docker_container_name on $remote_host_ip failed! \" exit 1 else echo_g \"restart docker container for $user_defined_docker_container_name on $remote_host_ip successfully! \" return 0 fi } function restart_docker_containers(){ echo_b \"Restarting docker containers...\" echo_y \"Which way do you want to restart docker container? \" user_input_answer_want_do_restart=\"n\" read -p \"(If you want to restart global please input: y ,if not please press the enter button):\" user_input_answer_want_do_restart case \"$user_input_answer_want_do_restart\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) if test -f ${user_defined_global_restart_containers_script}; then if file ${user_defined_global_restart_containers_script} | grep 'shell script' >/dev/null; then bash ${user_defined_global_restart_containers_script} else ${user_defined_global_restart_containers_script} fi else echo_r \"$user_defined_global_restart_containers_script can NOT be executed, please check it.\" exit 1 fi ;; n|N|No|NO|no|nO) restart_docker_container $@ ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } # scp_local_files_to_remote_host local_path remote_hostname remote_path function scp_local_files_to_remote_host(){ [ $# -ne 3 ] && return 1 [ ! -d $1 -a ! -f $1 ] && return 1 # check_ssh_can_be_connect $2 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp local files to remote host failed! \" echo_r \"scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1\" exit 1 else echo_g \"scp local files to remote host successfully! \" fi } # scp_remote_files_to_local_host remote_hostname remote_path local_path function scp_remote_files_to_local_host(){ [ $# -ne 3 ] && return 1 # check_ssh_can_be_connect $1 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp root@$1:$2 $3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp remote files to local host failed! \" exit 1 else echo_g \"scp remote files to local host successfully! \" fi } function backup_single_file(){ set -o errexit if [ \"$#\" -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=\"`date +\"%Y%m%d%H%M%S\"`\" backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f ${backup_filename_origin} && cp ${backup_filename_origin} ${backup_filename_target} set +o errexit } # Function description: backup files # Note: accept $@ parameters function backup_files(){ # TODO(Guodong Ding) improvements here set -o errexit if [ $# -eq 0 ]; then return 1 fi file_list=$@ operation_date_time=\"_`date +\"%Y%m%d%H%M%S\"`\" log_filename=\".log_$$_${RANDOM}\" log_filename_full_path=/tmp/${log_filename} touch ${log_filename_full_path} old_IFS=$IFS IFS=\" \" for file in ${file_list};do real_file=$(realpath ${file}) [ -f ${real_file} ] && cp ${real_file} ${file}${operation_date_time}~ [ -f ${log_filename_full_path} ] && echo \"\\mv -f $file$operation_date_time~ $file\" >>${log_filename_full_path} done IFS=\"$old_IFS\" set +o errexit return 0 } # Function description: function rollback_files(){ # TODO(Guodong Ding) improvements here [ -f ${log_filename_full_path} ] && . ${log_filename_full_path} \\rm -f ${log_filename_full_path} exit 2 } # backup directories locally function backup_directories(){ # TODO(Guodong Ding) continue here if [ $# -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=\"`date +\"%Y%m%d%H%M%S\"`\" backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f ${backup_filename_origin} && cp -r ${backup_filename_origin} ${backup_filename_target} } function rollback_directories(){ # TODO(Guodong Ding) continue here return } # backup remote host target, only exec this function when first deploy # after first deploy, new backups will be found in \"release\" directory. function backup_remote_host_target_files(){ # TODO(Guodong Ding) continue here echo_b \"Do backup operation before first deployment for the case which host target has been deployed by manual! \" # only exec this function when first deploy. After first deploy, new backups will be found in \"${WORKDIR}/release\" directory. test -f ${WORKDIR}/shared/workable_program.log && return 0 [ $# -ne 1 ] && return 1 ssh_execute_command_on_remote_host \"$1\" \"tar czf $user_defined_project_top_directory_to_target_host /tmp/$(date +%Y%m%d).tar.gz\" if test ! -d ${WORKDIR}/${user_defined_remote_host_target_backup_directory}; then echo_r \"$WORKDIR/$user_defined_remote_host_target_backup_directory can NOT be found! \" exit 1 fi scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no root@$1:/tmp/$(date +%Y%m%d).tar.gz ${WORKDIR}/${user_defined_remote_host_target_backup_directory}/backup-$(date +%Y%m%d%H%M%S).tar.gz if [ $? -eq 0 ];then echo_g \"Backup this project successfully! Now will return with status 0. \" ssh_execute_command_on_remote_host \"$1\" \"test -f /tmp/$(date +%Y%m%d).tar.gz && rm -rf /tmp/$(date +%Y%m%d).tar.gz\" return 0 else echo_r \"Error: something is wrong! Please check or alter to Admin user! \" exit 1 fi } # function backup_remote_host_config_files(){ # TODO(Guodong Ding) did not throw a exception when first deploy and test -z \"$user_defined_project_conf_directory\" echo_b \"backup remote host config files...\" # backup operation only executed once time, using '$0 backup_manual' backup new configuration files. # if ${WORKDIR}/${user_defined_project_conf_directory} is not empty then return 0 to exit if [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ]; then [ -f ${WORKDIR}/${user_defined_project_conf_directory}.backup_operation_once.log ] && backup_operation=\"`cat ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log`\" echo_g \"Backup remote host config files operation had been done, $backup_operation, now skipping ... \" return 0 fi # TODO(Guodong Ding) if $user_defined_project_conf_directory is empty and remote host target directory is empty(first deploy), will cause exit with 1 ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"test \\\"\\$(ls -A $user_defined_project_top_directory_to_target_host 2>/dev/null)\\\"\" if test $? -eq 0; then scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host}/* ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log else echo_y \"This maybe first time to deploy or variable 'user_defined_project_conf_directory' is not defined! \" fi } function rollback_remote_host_config_files(){ echo_b \"rollback remote host config files...\" #scp_local_files_to_remote_host ${WORKDIR}/${user_defined_project_conf_directory} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -r ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} # TODO(Guodong Ding) if save remote host config files, if there are no changes on config files # some ops # TODO(Guodong Ding) improvements here echo_g \"rollback remote host config files finished.\" } function make_current_workable_source(){ # check a directories lock, Note: this is redundant if [[ ! -f ${WORKDIR}/.capistrano_ds_lock ]]; then setDirectoryStructureOnLocalHost fi clean_old_releases clean_old_logs # do dependencies checking if test ! -z ${user_defined_skip_check_network_and_resolver}; then echo_g \"skipping checking network connectivity and name resolve.\" else check_network_connectivity check_name_resolve fi check_other_dependencies # do core job # TODO(Guodong Ding) if we need a git_project_clone \"$user_defined_project_clone_depends\" here using auto judgment statement test -z ${user_defined_project_clone_depends} || git_project_clone \"$user_defined_project_clone_depends\" git_project_clone \"$user_defined_project_clone\" test -z ${user_defined_project_clone_depends} || maven_build_project \"$user_defined_project_clone_depends\" maven_build_project \"$user_defined_project_clone\" cd ${WORKDIR} # links_target_directory_to_current # Make directory to release directory if test ! -d ${WORKDIR}/release -o ! -d ${WORKDIR}/shared; then echo_r \"capistrano directory structure is broken, make sure the file .capistrano_ds_lock is deleted before a new deploy! \" # test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock exit 1 fi new_release_just_created=\"$WORKDIR/release/$(date +%Y%m%d%H%M%S)\" [ ! -d ${new_release_just_created} ] && mkdir ${new_release_just_created} [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/ ] && \\ \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/* ${new_release_just_created} # Make source code symbolic link to current ( [ -f ${WORKDIR}/current ] || [ -d ${WORKDIR}/current ] ) && rm -rf ${WORKDIR}/current ln -s ${new_release_just_created} ${WORKDIR}/current # Move conf and logs directives from release to share if found [ -d ${WORKDIR}/release/conf ] && mv ${WORKDIR}/release/conf ${WORKDIR}/shared/conf [ -d ${WORKDIR}/release/logs ] && mv ${WORKDIR}/release/logs ${WORKDIR}/shared/logs # Make conf and logs symbolic link to current [ -d ${WORKDIR}/shared/conf ] && ln -s ${WORKDIR}/shared/conf ${WORKDIR}/current/conf [ -d ${WORKDIR}/shared/logs ] && ln -s ${WORKDIR}/shared/logs ${WORKDIR}/current/logs } # distribute current workable files to remote host function deploy() { # do make_current_workable_source before deploy every time make_current_workable_source # do single backup operation before deploy in case of there is a present deploy by manual backup_remote_host_target_files \"$user_defined_deploy_target_host_ip\" echo_b \"Do deploy on $user_defined_deploy_target_host_ip ...\" # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # remove all file in remote host target directories and files ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"cd $user_defined_project_top_directory_to_target_host && rm -rf ./*\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory} ; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi # backup remote host config files to local again for next using [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_containers ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/shared/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy successfully for $user_defined_deploy_target_host_ip! \" echo_g \"Current workable version is $(cat ${WORKDIR}/shared/workable_program.log)\" else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollback fi } # Rollback to last right configuration function rollback() { echo_b \"Rollback to last right configuration... \" # The key point is find last files which can work WORKABLE_PROGRAM=`cat ${WORKDIR}/shared/workable_program.log` if [[ -z ${WORKABLE_PROGRAM} ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # Stop service if we have if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh stop\" fi # Remove failed deploy rm -rf ${WORKDIR}/current # Remake source code symbolic link to current ln -s ${WORKABLE_PROGRAM} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/shared/conf ] && ln -s ${WORKDIR}/shared/conf ${WORKDIR}/current [ -d ${WORKDIR}/shared/logs ] && ln -s ${WORKDIR}/shared/logs ${WORKDIR}/current # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_containers ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $WORKABLE_PROGRAM\" fi } # rollback to any workable version which user wished by manually function rollback_manual(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something is wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # Alternative implementation: ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | sed -n '1,4p' ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | head -n4 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/shared/conf ] && ln -s ${WORKDIR}/shared/conf ${WORKDIR}/current [ -d ${WORKDIR}/shared/logs ] && ln -s ${WORKDIR}/shared/logs ${WORKDIR}/current # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # # rollback remote host config files # [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do # TODO(Guodong Ding) scp timeout scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_containers ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/shared/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } # backup remote hosts config files only, # use this function when you modify some config files on remote host function backup_manual(){ set -o errexit # Bug fixed: check config backup directory(directories) if exist, useful when execute backup_manual function before other functions. if test ! -d ${WORKDIR}/${user_defined_project_conf_directory}; then mkdir -p ${WORKDIR}/${user_defined_project_conf_directory} fi echo_b \"backup remote host config files...\" scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} \"${user_defined_project_top_directory_to_target_host}/*\" ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log set +o errexit } # distribute current workable files to remote hosts function deploys() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_targets_host_ip_list ...\" for remote_host_ip in ${user_defined_deploy_targets_host_ip_list};do # do single backup operation before deploy in case of there is a present deploy by manual backup_remote_host_target_files \"$remote_host_ip\" echo_b \"Do deploy on $remote_host_ip ...\" # remove all file in remote host target directories and files ssh_execute_command_on_remote_host \"$remote_host_ip\" \"cd $user_defined_project_top_directory_to_target_host && rm -rf ./*\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${remote_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${remote_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh start ssh_execute_command_on_remote_host ${remote_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_containers ${remote_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Deploy successfully on $remote_host_ip! \" else echo_r \"Error: Deploy failed! on $remote_host_ip! \" echo_p \"Try modify $user_defined_deploy_target_host_ip and using standalone deployment mode\" exit 1 fi done # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/shared/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy finished! on $user_defined_deploy_targets_host_ip_list \" echo_g \"current workable version is $(cat ${WORKDIR}/shared/workable_program.log)\" # ls --color=auto -l ${WORKDIR}/current # ls --color=auto -l ${WORKDIR}/current/ else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollbacks fi } function rollbacks(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something is wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit. Enter 'reset' command to reset terminal when something is wrong.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # ls -d -1 ${WORKDIR}/release/* ls -u -1 -d ${WORKDIR}/release/* | tail -n5 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/shared/conf ] && ln -s ${WORKDIR}/shared/conf ${WORKDIR}/current [ -d ${WORKDIR}/shared/logs ] && ln -s ${WORKDIR}/shared/logs ${WORKDIR}/current # backup remote host config files [ -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for host_ip in ${user_defined_deploy_targets_host_ip_list};do for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_containers ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully on $user_defined_deploy_targets_host_ip_list! \" echo_g \"Current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/shared/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } function destroy() { # echo a Warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" user_input_answer_want_do_destroy=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" user_input_answer_want_do_destroy case \"$user_input_answer_want_do_destroy\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"filename\" | xargs rm -rf find -L ${WORKDIR} -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf '{}' \\; if [ $? -eq 0 ];then test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something is wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } function usage(){ cat - << eof \"${WORKDIR}/`basename $0` deploy new deploy/ update one remote target host \"${WORKDIR}/`basename $0` rollback_manual rollback to any workable version to one remote target host by manual \"${WORKDIR}/`basename $0` deploys new deploy/ update more then one remote target host \"${WORKDIR}/`basename $0` rollbacks rollback to any workable version to more than one remote target host by manual \"${WORKDIR}/`basename $0` backup_manual| backup backup conf files to local by manual when you add/delete/update conf files on remote target host eof } function main(){ lock_filename=\"lock_$$_${RANDOM}\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` [ -n \"$header\" ] && echo \"$header\" # # if exist file '.capistrano_ds_lock', then this is not first deployment, and unset # if test -f ${WORKDIR}/.capistrano_ds_lock; then # unset user_defined_project_conf_directory # user_defined_project_conf_directory=\"\" # fi if [[ $# -lt 1 ]]; then ${WORKDIR}/`basename $0` help exit 0 fi case $1 in deploy) deployment_mode=\"1\" deploy ;; rollback) rollback ;; rollback_manual|rollbackup_manual) rollback_manual ;; backup_manual|backup) backup_manual ;; deploys) deployment_mode=\"0\" deploys; ;; rollbacks|rollbackups) rollbacks ;; destroy) destroy ;; restart) restart_docker_containers ;; help|*) echo \"Usage: $0 {deploy|rollback_manual|deploys|backup_manual} with $0 itself\" usage exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_437.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\doDeploy_with_config_and_procedure_separate\\file_437.sh",
            "content": "#!/bin/bash # Name: doDeploy.sh #Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. # debug option DEBUG=false #DEBUG=true if ${DEBUG} ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi # define user friendly messages header=\" Function: Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. License: Open source software \" # set an empty function using for location this line quickly in PyCharm editor on purpose. function _empty() { return; } # load user defined variables # Where to get source code # TODO(Guodong Ding) using with `basename $0` if test -f doDeploy_userConfig.sh ; then source doDeploy_userConfig.sh fi # end define variables # pretreatment predefined variables # TODO(Guodong Ding) project_clone_target_depends_1 is not used for git clone because git has done for us test -z ${user_defined_project_clone_depends} || project_clone_target_depends_1=\"`echo ${user_defined_project_clone_depends} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_target=\"`echo ${user_defined_project_clone} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_repository_name=${project_clone_target} deployment_mode=\"\" # end pretreatment predefined variables # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi function command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } function check_command_can_be_execute(){ [ $# -ne 1 ] && return 1 command_exists $1 } function check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once time! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" echo fi } function check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" echo return 0 fi } function check_ssh_can_be_connect(){ [ $# -ne 1 ] && return 1 echo_b \"Check if can ssh to remote host $1 ... \" check_command_can_be_execute ssh || return 1 # TODO(Guodong Ding) ssh can connect to remote host by using /etc/ssh/ssh_host_rsa_key or ~/.ssh/id_rsa ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"uname -a >/dev/null 2>&1\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"Check ssh to remote host $1 failed! \" exit 1 else echo_g \"Check ssh to remote host $1 successfully! \" fi } function check_other_dependencies() { echo_b \"Checking other dependencies for deploy procedure... \" echo_b \"\\tChecking user customized variables...\" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z ${user_defined_project_clone} ]]; then echo_r \"Error: user_defined_project_clone is undefined! \" exit 1 fi # Note: test command is strongly typed, can recognize string type and integer type if test ! -z \"$user_defined_deploy_target_host_ip\" -a ! -z \"$user_defined_deploy_targets_host_ip_list\" ; then user_defined_deploy_targets_host_first_ip_in_list=\"`echo \"$user_defined_deploy_targets_host_ip_list\" | awk -F ' ' '{ print $1 }'`\" if test \"$user_defined_deploy_target_host_ip\" = \"$user_defined_deploy_targets_host_first_ip_in_list\" -a \"$deployment_mode\" = \"0\" ; then echo_g \"Run this shell script in multi-deployment mode, deploy to a group of hosts.\" saved_IFS=$IFS IFS=' ' for ipaddress in ${user_defined_deploy_targets_host_ip_list}; do check_ssh_can_be_connect ${ipaddress} done IFS=${saved_IFS} elif test \"$user_defined_deploy_target_host_ip\" != \"$user_defined_deploy_targets_host_first_ip_in_list\"; then echo_r \"\\\"$user_defined_deploy_targets_host_ip_list\\\" is not equal to \\\"$user_defined_deploy_target_host_ip\\\", this is a must! \" exit 1 fi elif test ! -z \"$user_defined_deploy_target_host_ip\" -a -z \"$user_defined_deploy_targets_host_ip_list\" -a \"$deployment_mode\" = \"1\" ;then echo_g \"Run this shell script in standalone-deployment mode, deploy to single host.\" elif test -z \"$user_defined_deploy_target_host_ip\" -a -z \"$user_defined_deploy_targets_host_ip_list\" ;then echo_r \"Error: both user_defined_deploy_target_host_ip and user_defined_deploy_targets_host_ip_list is undefined! \" exit 1 else echo_r \"Error: bad user defined parameters, please fix it and try again! \" exit 1 fi if [[ -z ${user_defined_project_top_directory_to_target_host} ]]; then echo_r \"Error: user_defined_project_top_directory_to_target_host is undefined! \" exit 1 fi if test -z ${user_defined_project_conf_directory}; then # TODO(Guodong Ding) check directory if exist if test -d ${WORKDIR}/${user_defined_project_conf_directory}; then echo_y \"Warning: ${WORKDIR}/${user_defined_project_conf_directory} is not exist!\" fi echo_y \"Warning: user defined project conf directory is not defined! \" fi echo_g \"\\tChecking user customized and defined variables passed! \" echo_b \"\\tChecking disk space available...\" disk_space_available=`df ${WORKDIR} | tail -n1 | awk '{print $(NF-2)}'` if [[ ${disk_space_available} -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 else echo_g \"\\tChecking disk space available passed! \" fi echo_g \"All required dependencies check passed! \" echo } function setDirectoryStructureOnLocalHost() { set -o errexit if [ -f ${WORKDIR}/.capistrano_ds_lock ];then echo_g \"Set directory structure has been done, skipping. \" return fi echo_b \"Setting directory structure... \" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branch names or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy [ ! -d ${WORKDIR}/release ] && mkdir ${WORKDIR}/release [ ! -d ${WORKDIR}/repository ] && mkdir ${WORKDIR}/repository [ ! -d ${WORKDIR}/share ] && mkdir ${WORKDIR}/share # end directories structure # Additional directories structure for full deploy operation # for backup remote host config file [ ! -d ${WORKDIR}/${user_defined_project_conf_directory} ] && mkdir ${WORKDIR}/${user_defined_project_conf_directory} # deploy logs for git/mvn/ssh [ ! -d ${WORKDIR}/logs ] && mkdir ${WORKDIR}/logs # set a directories structure lock touch ${WORKDIR}/.capistrano_ds_lock echo_g \"Set directory structure successfully! \" echo set +o errexit } function clean_old_releases_discarded(){ echo_b \"Clean old releases... \" save_days=${save_old_releases_for_days:-10} if [ ! -d ${WORKDIR}/release ]; then echo_b \"Can NOT find release directory, skipping . \" return fi need_clean=$(find ${WORKDIR}/release -mtime +${save_days} -exec ls '{}' \\; | wc -l) if [ ${need_clean} -gt 0 ]; then echo_c \"Expired releases found and will be removed from project! \" find ${WORKDIR}/release -mtime +${save_days} -exec rm -rf '{}' \\; >/dev/null 2>&1 if [ $? -eq 0 ]; then echo_g \"Expired releases have removed from project! \" else echo_r \"Can NOT remove expired releases, please feel free to alter to administrators. \" fi else echo_g \"All releases are not expired, skipping. \" fi } function clean_old_releases(){ echo_b \"Clean old releases... \" num_save=${save_old_releases_for_numbers:-10} files_ops=${WORKDIR}/release num_files=$(find ${files_ops} -maxdepth 1 -type d -a ! -wholename \".\" -a ! -wholename \"..\" -a -wholename \"$files_ops\" -printf \"%C@ %p\\n\" | sort -n | wc -l) if test ${num_files} -gt ${num_save};then echo_c \"Extra releases found and will be removed from project! \" num_ops=$(expr ${num_files} - ${num_save}) list_ops=$(find ${files_ops} -maxdepth 1 -type d -a ! -wholename \".\" -a ! -wholename \"..\" -a -wholename \"$files_ops\" -printf \"%C@ %p\\n\" | sort -n | head -n${num_ops} | awk -F '[ ]+' '{print $2}') # IFS=' '$'\\t'$'\\n', If IFS is unset, or its value is exactly <space><tab><newline> old_IFS=$IFS IFS=' '$'\\t'$'\\n' # \\n is a must for file_ops in ${list_ops};do echo \"$file_ops\" test -d ${file_ops} && rm -rf ${file_ops} done IFS=\"$old_IFS\" echo_g \"Extra releases have been removed from project! \" else echo_g \"All releases are essential, skipping. \" fi } function clean_old_logs(){ echo_b \"Clean old logs... \" save_days=${save_old_releases_for_days:-10} need_clean=$(find ${WORKDIR}/logs -name \"*.log\" -mtime +${save_days} -exec ls '{}' \\; | wc -l) if [ ${need_clean} -gt 0 ]; then echo_c \"Expired releases found and will be removed from project! \" find -L ${WORKDIR}/logs -maxdepth 1 -name \"*.log\" -a ! -name \"^.\" -mtime +${save_days} -exec rm -rf '{}' \\; >/dev/null 2>&1 if [ $? -eq 0 ]; then echo_g \"Expired logs have removed from project! \" else echo_r \"Can NOT remove expired logs, please feel free to alter to administrators. \" fi else echo_g \"All logs are not expired, skipping. \" fi } # git_project_clone repository branch # Note: # git checkout <branch name>, change current branch to another branch # git checkout -b <branch name>, create current branch to new branch function git_project_clone(){ set -o errexit [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} # TODO(Guodong Ding) let user set this variable(\"branch\") branch=\"develop\" if test -n \"$2\"; then branch=\"$2\" else branch=\"develop\" fi if test ! -d ${project_clone_directory}; then echo_b \"git clone from $project_clone_repository\" # git clone git@github.com:name/app.git -b master git clone ${project_clone_repository} ${project_clone_directory} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd ${project_clone_directory} current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log else git checkout ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log fi cd ${WORKDIR} echo_g \"git clone from $project_clone_repository successfully! \" else echo_b \"git pull from $project_clone_repository\" cd ${project_clone_directory} git pull origin ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log else git checkout ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M%S)_$$.log fi # TODO(Guodong Ding) get branch names or revision numbers from VCS data # git rev-parse HEAD # git rev-parse --verify HEAD # git rev-parse HEAD | cut -c1-10 # git show-ref # git for-each-ref # git log --pretty=format:'%h' -n 1 # git log -1 --format=\"%H\" # git rev-list --max-count=1 HEAD # git show --pretty=%h cd ${WORKDIR} echo_g \"git pull from $project_clone_repository successfully! \" fi set +o errexit } function maven_build_project_deprecated(){ set -o errexit echo_b \"Do mvn build java project... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 mvn clean package >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 cd ${WORKDIR} echo_g \"Do mvn build java project finished with exit code 0! \" set +o errexit } function maven_build_project(){ echo_b \"Do mvn build java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi mvn clean package >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M%S)_$$.log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn build java project finished for ${project_clone_repository_name} with exit code 0! \" echo } function maven_install(){ echo_b \"Do mvn install java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_install_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/logs/mvn_install_$(date +%Y%m%d%H%M%S)_$$.log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn install java project finished for ${project_clone_repository_name} with exit code 0! \" echo } function maven_clean_package(){ echo_b \"Do mvn clean package java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn clean package >>${WORKDIR}/logs/mvn_clean_package_$(date +%Y%m%d%H%M%S)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/logs/mvn_clean_package_$(date +%Y%m%d%H%M%S)_$$.log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn clean package java project finished for ${project_clone_repository_name} with exit code 0! \" echo } # ssh_execute_command_on_remote_host hostname command function ssh_execute_command_on_remote_host(){ [ $# -ne 2 ] && return 1 ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"$2\" >>${WORKDIR}/logs/ssh_command_$(date +%Y%m%d)_$$.log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"ssh execute command on remote host $2 failed! \" test -s ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d)_$$.log && echo_r \"\\tMore details refer to ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d)_$$.log\" return 1 else echo_g \"ssh execute command on remote host $2 successfully! \" return 0 fi } function restart_docker_container(){ echo_b \"Restarting docker container...\" [ $# -ne 2 ] && return 1 # TODO(Guodong Ding) if we need restart more related docker container local user_defined_docker_container_name=\"\" local remote_host_ip=\"\" test -n $1 && remote_host_ip=\"$1\" test -n $2 && user_defined_docker_container_name=\"$2\" ssh_execute_command_on_remote_host \"$remote_host_ip\" \"docker restart $user_defined_docker_container_name\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"restart docker container for $user_defined_docker_container_name on $remote_host_ip failed! \" exit 1 else echo_g \"restart docker container for $user_defined_docker_container_name on $remote_host_ip successfully! \" return 0 fi } # scp_local_files_to_remote_host local_path remote_hostname remote_path function scp_local_files_to_remote_host(){ [ $# -ne 3 ] && return 1 [ ! -d $1 -a ! -f $1 ] && return 1 # check_ssh_can_be_connect $2 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp local files to remote host failed! \" echo_r \"scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1\" exit 1 else echo_g \"scp local files to remote host successfully! \" fi } # scp_remote_files_to_local_host remote_hostname remote_path local_path function scp_remote_files_to_local_host(){ [ $# -ne 3 ] && return 1 # check_ssh_can_be_connect $1 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp root@$1:$2 $3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp remote files to local host failed! \" exit 1 else echo_g \"scp remote files to local host successfully! \" fi } function backup_single_file(){ set -o errexit if [ \"$#\" -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=\"`date +\"%Y%m%d%H%M%S\"`\" backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f ${backup_filename_origin} && cp ${backup_filename_origin} ${backup_filename_target} set +o errexit } # Function description: backup files # Note: accept $@ parameters function backup_files(){ # TODO(Guodong Ding) improvements here set -o errexit if [ $# -eq 0 ]; then return 1 fi file_list=$@ operation_date_time=\"_`date +\"%Y%m%d%H%M%S\"`\" log_filename=\".log_$$_${RANDOM}\" log_filename_full_path=/tmp/${log_filename} touch ${log_filename_full_path} old_IFS=$IFS IFS=\" \" for file in ${file_list};do real_file=$(realpath ${file}) [ -f ${real_file} ] && cp ${real_file} ${file}${operation_date_time}~ [ -f ${log_filename_full_path} ] && echo \"\\mv -f $file$operation_date_time~ $file\" >>${log_filename_full_path} done IFS=\"$old_IFS\" set +o errexit return 0 } # Function description: function rollback_files(){ # TODO(Guodong Ding) improvements here [ -f ${log_filename_full_path} ] && . ${log_filename_full_path} \\rm -f ${log_filename_full_path} exit 2 } # backup directories locally function backup_directories(){ # TODO(Guodong Ding) continue here if [ $# -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=\"`date +\"%Y%m%d%H%M%S\"`\" backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f ${backup_filename_origin} && cp -r ${backup_filename_origin} ${backup_filename_target} } function rollback_directories(){ # TODO(Guodong Ding) continue here return } # function backup_remote_host_config_files(){ # TODO(Guodong Ding) did not throw a exception when first deploy and test -z \"$user_defined_project_conf_directory\" echo_b \"backup remote host config files...\" # backup operation only executed once time, using '$0 backup_manual' backup new configuration files. # if ${WORKDIR}/${user_defined_project_conf_directory} is not empty then return 0 to exit if [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ]; then [ -f ${WORKDIR}/${user_defined_project_conf_directory}.backup_operation_once.log ] && backup_operation=\"`cat ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log`\" echo_g \"Backup remote host config files operation had been done, $backup_operation, now skipping ... \" return 0 fi # TODO(Guodong Ding) if $user_defined_project_conf_directory is empty and remote host target directory is empty(first deploy), will cause exit with 1 ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"test \\\"\\$(ls -A $user_defined_project_top_directory_to_target_host 2>/dev/null)\\\"\" if test $? -eq 0; then scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host}/* ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here test ! -z ${user_defined_project_conf_directory} -a -d ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com && rm -rf ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log else echo_y \"This maybe first time to deploy or variable 'user_defined_project_conf_directory' is not defined! \" fi } function rollback_remote_host_config_files(){ echo_b \"rollback remote host config files...\" #scp_local_files_to_remote_host ${WORKDIR}/${user_defined_project_conf_directory} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -r ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} # TODO(Guodong Ding) if save remote host config files, if there are no changes on config files # some ops # TODO(Guodong Ding) improvements here echo_g \"rollback remote host config files finished.\" } function make_current_workable_source(){ # check a directories lock, Note: this is redundant if [[ ! -f ${WORKDIR}/.capistrano_ds_lock ]]; then setDirectoryStructureOnLocalHost fi clean_old_releases clean_old_logs # do dependencies checking if test ! -z ${user_defined_skip_check_network_and_resolver}; then echo_g \"skipping checking network connectivity and name resolve.\" else check_network_connectivity check_name_resolve fi check_other_dependencies # do core job # TODO(Guodong Ding) if we need a git_project_clone \"$user_defined_project_clone_depends\" here using auto judgment statement test -z ${user_defined_project_clone_depends} || git_project_clone \"$user_defined_project_clone_depends\" git_project_clone \"$user_defined_project_clone\" test -z ${user_defined_project_clone_depends} || maven_install \"$user_defined_project_clone_depends\" maven_clean_package \"$user_defined_project_clone\" cd ${WORKDIR} # links_target_directory_to_current # Make directory to release directory if test ! -d ${WORKDIR}/release -o ! -d ${WORKDIR}/share; then echo_r \"capistrano directory structure is broken, make sure the file .capistrano_ds_lock is deleted before a new deploy! \" # test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock exit 1 fi new_release_just_created=\"$WORKDIR/release/$(date +%Y%m%d%H%M%S)\" [ ! -d ${new_release_just_created} ] && mkdir ${new_release_just_created} # for special project, such as a project have different name from its git repository name, for example here, \"chatter\" # TODO(Guodong Ding) find more this foreseeable exception here if [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/ ]; then \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/* ${new_release_just_created} elif [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/chatter ]; then \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/chatter/* ${new_release_just_created} else echo_r \"A foreseeable error occurred, please alter to Developer & Administrator. \" exit 1 fi # Make source code symbolic link to current ( [ -f ${WORKDIR}/current ] || [ -d ${WORKDIR}/current ] ) && rm -rf ${WORKDIR}/current ln -s ${new_release_just_created} ${WORKDIR}/current # for some bash scripts in the ${WORKDIR}/current find ${WORKDIR}/current/ -type f -name \"*.sh\" -exec chmod +x '{}' \\; # Move conf and logs directives from release to share if found [ -d ${WORKDIR}/release/conf ] && mv ${WORKDIR}/release/conf ${WORKDIR}/share/conf [ -d ${WORKDIR}/release/logs ] && mv ${WORKDIR}/release/logs ${WORKDIR}/share/logs # Make conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current/conf [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current/logs } # distribute current workable files to remote host function deploy() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_target_host_ip ...\" # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # remove all file in remote host target directories and files, if target is not exist, then create it. ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"if test -d $user_defined_project_top_directory_to_target_host; then find -L $user_defined_project_top_directory_to_target_host -maxdepth 1 ! -name \"logs\" ! -wholename \"${user_defined_project_top_directory_to_target_host}\" -exec rm -rf {} \\; ; else mkdir -p $user_defined_project_top_directory_to_target_host; fi\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory} ; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi # backup remote host config files to local again for next using [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy successfully for $user_defined_deploy_target_host_ip! \" echo_g \"Current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollback fi } # Rollback to last right configuration function rollback() { echo_b \"Rollback to last right configuration... \" # The key point is find last files which can work WORKABLE_PROGRAM=`cat ${WORKDIR}/share/workable_program.log` if [[ -z ${WORKABLE_PROGRAM} ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # Stop service if we have if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh stop\" fi # Remove failed deploy rm -rf ${WORKDIR}/current # Remake source code symbolic link to current ln -s ${WORKABLE_PROGRAM} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $WORKABLE_PROGRAM\" fi } # rollback to any workable version which user wished by manually function rollback_manual(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something go wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # Alternative implementation: ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | sed -n '1,4p' ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | head -n4 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # # rollback remote host config files # [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do # TODO(Guodong Ding) scp timeout scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } # backup remote hosts config files only, # use this function when you modify some config files on remote host function backup_manual(){ set -o errexit # Bug fixed: check config backup directory(directories) if exist, useful when execute backup_manual function before other functions. if test ! -d ${WORKDIR}/${user_defined_project_conf_directory}; then mkdir -p ${WORKDIR}/${user_defined_project_conf_directory} fi echo_b \"backup remote host config files...\" scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} \"${user_defined_project_top_directory_to_target_host}/*\" ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here test ! -z ${user_defined_project_conf_directory} -a -d ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com && rm -rf ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log set +o errexit } # distribute current workable files to remote hosts function deploys() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_targets_host_ip_list ...\" for remote_host_ip in ${user_defined_deploy_targets_host_ip_list};do echo_b \"Do deploy on $remote_host_ip ...\" # remove all file in remote host target directories and files ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"if test -d $user_defined_project_top_directory_to_target_host; then cd $user_defined_project_top_directory_to_target_host && rm $user_defined_project_top_directory_to_target_host/*; else mkdir -p $user_defined_project_top_directory_to_target_host; fi\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${remote_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${remote_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh start ssh_execute_command_on_remote_host ${remote_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${remote_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Deploy successfully on $remote_host_ip! \" else echo_r \"Error: Deploy failed! on $remote_host_ip! \" echo_p \"Try modify $user_defined_deploy_target_host_ip and using standalone deployment mode\" exit 1 fi done # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy finished! on $user_defined_deploy_targets_host_ip_list \" echo_g \"current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" # ls --color=auto -l ${WORKDIR}/current # ls --color=auto -l ${WORKDIR}/current/ else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollbacks fi } function rollbacks(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something go wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit. Enter 'reset' command to reset terminal when something go wrong.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # ls -d -1 ${WORKDIR}/release/* ls -u -1 -d ${WORKDIR}/release/* | tail -n5 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for host_ip in ${user_defined_deploy_targets_host_ip_list};do for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully on $user_defined_deploy_targets_host_ip_list! \" echo_g \"Current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } function destroy() { # echo a Warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" user_input_answer_want_do_destroy=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" user_input_answer_want_do_destroy case \"$user_input_answer_want_do_destroy\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"filename\" | xargs rm -rf find -L ${WORKDIR} -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf '{}' \\; if [ $? -eq 0 ];then test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } function usage(){ cat - << eof \"${WORKDIR}/`basename $0` deploy new deploy/ update one remote target host \"${WORKDIR}/`basename $0` rollback_manual rollback to any workable version to one remote target host by manual \"${WORKDIR}/`basename $0` deploys new deploy/ update more then one remote target host \"${WORKDIR}/`basename $0` rollbacks rollback to any workable version to more than one remote target host by manual \"${WORKDIR}/`basename $0` backup_manual| backup backup conf files to local by manual when you add/delete/update conf files on remote target host eof } function main(){ lock_filename=\"lock_$$_${RANDOM}\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` [ -n \"$header\" ] && echo \"$header\" # # if exist file '.capistrano_ds_lock', then this is not first deployment, and unset # if test -f ${WORKDIR}/.capistrano_ds_lock; then # unset user_defined_project_conf_directory # user_defined_project_conf_directory=\"\" # fi if [[ $# -lt 1 ]]; then ${WORKDIR}/`basename $0` help exit 0 fi case $1 in deploy) deployment_mode=\"1\" deploy ;; rollback) rollback ;; rollback_manual|rollbackup_manual) rollback_manual ;; backup_manual|backup) backup_manual ;; deploys) deployment_mode=\"0\" deploys; ;; rollbacks|rollbackups) rollbacks ;; destroy) destroy ;; help|*) echo \"Usage: $0 {deploy|rollback_manual|deploys|backup_manual} with $0 itself\" usage exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_438.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\doDeploy_with_config_and_procedure_separate\\file_438.sh",
            "content": "#!/bin/bash # user defined variables # Where to get source code user_defined_project_clone_depends=\"ssh://git@git.example.com:18082/core/business-service-base.git\" user_defined_project_clone=\"ssh://git@git.example.com:18082/core/business-service-core.git\" user_defined_deploy_target_host_ip=\"10.6.28.125\" # this is a mandatory field, and must be same as the first ip in $user_defined_deploy_targets_host_ip_list user_defined_deploy_targets_host_ip_list=\"10.6.28.125\" # deploy to multi-hosts setting here, using space as delimiter user_defined_project_top_directory_to_target_host=\"/data/docker/business-service/bs-core-02\" user_defined_docker_container_name=\"bs-core-02\" # if you using a docker container other than a startup script located in sourcecode/bin/startup.sh, then set this to docker container name user_defined_project_conf_directory=\"config_backup\" # if you do NOT want to use configurations from deploy target, you should set this variable to where pointed to config files user_defined_skip_check_network_and_resolver=\"true\" # if system administrator disable ICMP protocol, set this any content but not null # Setting how many days do you want save old releases, default is 10 days save_old_releases_for_days=10 save_old_releases_for_numbers=10 # end define variables"
        },
        {
            "filename": "file_439.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\doDeploy_with_config_and_procedure_separate\\autodeployv3\\file_439.sh",
            "content": "#!/bin/bash # Name: doDeploy.sh #Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. # debug option DEBUG=false #DEBUG=true if ${DEBUG} ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi # define user friendly messages header=\" Function: Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. License: Open source software \" # set an empty function using for location this line quickly in PyCharm editor on purpose. function _empty() { return; } # load user defined variables # Where to get source code # TODO(Guodong Ding) using with `basename $0` if test -f deploy_conf ; then source deploy_conf else echo \"Fatal error: can NOT found file: deploy_conf \" exit 1 fi # end define variables # pretreatment predefined variables # TODO(Guodong Ding) project_clone_target_depends_1 is not used for git clone because git has done for us test -z ${user_defined_project_clone_depends} || project_clone_target_depends_1=\"`echo ${user_defined_project_clone_depends} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_target=\"`echo ${user_defined_project_clone} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_repository_name=${project_clone_target} deployment_mode=\"\" # end pretreatment predefined variables # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi function command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } function check_command_can_be_execute(){ [ $# -ne 1 ] && return 1 command_exists $1 } function check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once time! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" echo fi } function check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" echo return 0 fi } function check_ssh_can_be_connect(){ [ $# -ne 1 ] && return 1 echo_b \"Check if can ssh to remote host $1 ... \" check_command_can_be_execute ssh || return 1 # TODO(Guodong Ding) ssh can connect to remote host by using /etc/ssh/ssh_host_rsa_key or ~/.ssh/id_rsa ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"uname -a >/dev/null 2>&1\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"Check ssh to remote host $1 failed! \" exit 1 else echo_g \"Check ssh to remote host $1 successfully! \" fi } function check_other_dependencies() { echo_b \"Checking other dependencies for deploy procedure... \" echo_b \"\\tChecking user customized variables...\" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z ${user_defined_project_clone} ]]; then echo_r \"Error: user_defined_project_clone is undefined! \" exit 1 fi # Note: test command is strongly typed, can recognize string type and integer type if test ! -z \"$user_defined_deploy_target_host_ip\" -a ! -z \"$user_defined_deploy_targets_host_ip_list\" ; then user_defined_deploy_targets_host_first_ip_in_list=\"`echo \"$user_defined_deploy_targets_host_ip_list\" | awk -F ' ' '{ print $1 }'`\" if test \"$user_defined_deploy_target_host_ip\" = \"$user_defined_deploy_targets_host_first_ip_in_list\" -a \"$deployment_mode\" = \"0\" ; then echo_g \"Run this shell script in multi-deployment mode, deploy to a group of hosts.\" saved_IFS=$IFS IFS=' ' for ipaddress in ${user_defined_deploy_targets_host_ip_list}; do check_ssh_can_be_connect ${ipaddress} done IFS=${saved_IFS} elif test \"$user_defined_deploy_target_host_ip\" != \"$user_defined_deploy_targets_host_first_ip_in_list\"; then echo_r \"\\\"$user_defined_deploy_targets_host_ip_list\\\" is not equal to \\\"$user_defined_deploy_target_host_ip\\\", this is a must! \" exit 1 fi elif test ! -z \"$user_defined_deploy_target_host_ip\" -a -z \"$user_defined_deploy_targets_host_ip_list\" -a \"$deployment_mode\" = \"1\" ;then echo_g \"Run this shell script in standalone-deployment mode, deploy to single host.\" elif test -z \"$user_defined_deploy_target_host_ip\" -a -z \"$user_defined_deploy_targets_host_ip_list\" ;then echo_r \"Error: both user_defined_deploy_target_host_ip and user_defined_deploy_targets_host_ip_list is undefined! \" exit 1 else echo_r \"Error: bad user defined parameters, please fix it and try again! \" exit 1 fi if [[ -z ${user_defined_project_top_directory_to_target_host} ]]; then echo_r \"Error: user_defined_project_top_directory_to_target_host is undefined! \" exit 1 fi if test -z ${user_defined_project_conf_directory}; then # TODO(Guodong Ding) check directory if exist if test -d ${WORKDIR}/${user_defined_project_conf_directory}; then echo_y \"Warning: ${WORKDIR}/${user_defined_project_conf_directory} is not exist!\" fi echo_y \"Warning: user defined project conf directory is not defined! \" fi echo_g \"\\tChecking user customized and defined variables passed! \" echo_b \"\\tChecking disk space available...\" disk_space_available=`df ${WORKDIR} | tail -n1 | awk '{print $(NF-2)}'` if [[ ${disk_space_available} -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 else echo_g \"\\tChecking disk space available passed! \" fi echo_g \"All required dependencies check passed! \" echo } function setDirectoryStructureOnLocalHost() { set -o errexit if [ -f ${WORKDIR}/.capistrano_ds_lock ];then echo_g \"Set directory structure has been done, skipping. \" return fi echo_b \"Setting directory structure... \" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branch names or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy [ ! -d ${WORKDIR}/release ] && mkdir ${WORKDIR}/release [ ! -d ${WORKDIR}/repository ] && mkdir ${WORKDIR}/repository [ ! -d ${WORKDIR}/share ] && mkdir ${WORKDIR}/share # end directories structure # Additional directories structure for full deploy operation # for backup remote host config file [ ! -d ${WORKDIR}/${user_defined_project_conf_directory} ] && mkdir ${WORKDIR}/${user_defined_project_conf_directory} # deploy logs for git/mvn/ssh [ ! -d ${WORKDIR}/logs ] && mkdir ${WORKDIR}/logs # set a directories structure lock touch ${WORKDIR}/.capistrano_ds_lock echo_g \"Set directory structure successfully! \" echo set +o errexit } function clean_old_releases_discarded(){ echo_b \"Clean old releases... \" save_days=${save_old_releases_for_days:-10} if [ ! -d ${WORKDIR}/release ]; then echo_b \"Can NOT find release directory, skipping . \" return fi need_clean=$(find ${WORKDIR}/release -mtime +${save_days} -exec ls '{}' \\; | wc -l) if [ ${need_clean} -gt 0 ]; then echo_c \"Expired releases found and will be removed from project! \" find ${WORKDIR}/release -mtime +${save_days} -exec rm -rf '{}' \\; >/dev/null 2>&1 if [ $? -eq 0 ]; then echo_g \"Expired releases have removed from project! \" else echo_r \"Can NOT remove expired releases, please feel free to alter to administrators. \" fi else echo_g \"All releases are not expired, skipping. \" fi } function clean_old_releases(){ echo_b \"Clean old releases... \" num_save=${save_old_releases_for_numbers:-10} files_ops=${WORKDIR}/release num_files=$(find ${files_ops} -maxdepth 1 -type d -a ! -wholename \".\" -a ! -wholename \"..\" -a ! -wholename \"$files_ops\" -printf \"%C@ %p\\n\" | sort -n | wc -l) if test ${num_files} -gt ${num_save};then echo_c \"Extra releases found and will be removed from project! \" num_ops=$(expr ${num_files} - ${num_save}) list_ops=$(find ${files_ops} -maxdepth 1 -type d -a ! -wholename \".\" -a ! -wholename \"..\" -a ! -wholename \"$files_ops\" -printf \"%C@ %p\\n\" | sort -n | head -n${num_ops} | awk -F '[ ]+' '{print $2}') # IFS=' '$'\\t'$'\\n', If IFS is unset, or its value is exactly <space><tab><newline> old_IFS=$IFS IFS=' '$'\\t'$'\\n' for file_ops in ${list_ops};do test -d ${file_ops} && rm -rf ${file_ops} done IFS=\"$old_IFS\" echo_g \"Extra releases have been removed from project! \" else echo_g \"All releases are essential, skipping. \" fi } function clean_old_logs(){ echo_b \"Clean old logs... \" save_days=${save_old_releases_for_days:-10} need_clean=$(find ${WORKDIR}/logs -name \"*.log\" -mtime +${save_days} -exec ls '{}' \\; | wc -l) if [ ${need_clean} -gt 0 ]; then echo_c \"Expired releases found and will be removed from project! \" find -L ${WORKDIR}/logs -maxdepth 1 -name \"*.log\" -a ! -name \"^.\" -mtime +${save_days} -exec rm -rf '{}' \\; >/dev/null 2>&1 if [ $? -eq 0 ]; then echo_g \"Expired logs have removed from project! \" else echo_r \"Can NOT remove expired logs, please feel free to alter to administrators. \" fi else echo_g \"All logs are not expired, skipping. \" fi } # git_project_clone repository branch function git_project_clone(){ set -o errexit [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} # TODO(Guodong Ding) let user set this variable(\"branch\") # Note: branch is equal to tag, so using tag as branch or using branch as a tag if [[ \"x$branch_or_tag\" != \"x\" ]]; then branch=${branch_or_tag} else branch=\"\" fi if test -n \"$2\"; then branch=\"$2\" fi if [[ \"x$branch\" == \"x\" ]]; then echo_r \"get branch name or tag name failed!\" exit 1 fi if test ! -d ${project_clone_directory}; then echo_b \"git clone from $project_clone_repository\" # git clone git@github.com:name/app.git -b master git clone ${project_clone_repository} ${project_clone_directory} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log 2>&1 echo_g \"git clone from $project_clone_repository successfully! \" # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd ${project_clone_directory} current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log else git checkout ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log 2>&1 git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log fi echo_b \"git pull from $project_clone_repository with branch or tag name $branch.\" git pull origin ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log 2>&1 git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log cd ${WORKDIR} echo_g \"git pull from $project_clone_repository with branch or tag name $branch successfully! \" else echo_b \"git pull from $project_clone_repository with branch or tag name $branch.\" cd ${project_clone_directory} current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log else git checkout ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log 2>&1 git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log fi git pull origin ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log 2>&1 echo_g \"git pull from $project_clone_repository with branch or tag name $branch successfully! \" # TODO(Guodong Ding) get branch names or revision numbers from VCS data # git rev-parse HEAD # git rev-parse --verify HEAD # git rev-parse HEAD | cut -c1-10 # git show-ref # git for-each-ref # git log --pretty=format:'%h' -n 1 # git log -1 --format=\"%H\" # git rev-list --max-count=1 HEAD # git show --pretty=%h cd ${WORKDIR} fi set +o errexit } function maven_build_project_deprecated(){ set -o errexit echo_b \"Do mvn build java project... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log 2>&1 mvn clean package >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log 2>&1 cd ${WORKDIR} echo_g \"Do mvn build java project finished with exit code 0! \" set +o errexit } function maven_build_project(){ echo_b \"Do mvn build java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi mvn clean package >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn build java project finished for ${project_clone_repository_name} with exit code 0! \" echo } function maven_install(){ echo_b \"Do mvn install java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_install_$(date +%Y%m%d%H%M).log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/logs/mvn_install_$(date +%Y%m%d%H%M).log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn install java project finished for ${project_clone_repository_name} with exit code 0! \" echo } function maven_clean_package(){ echo_b \"Do mvn clean package java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn clean package >>${WORKDIR}/logs/mvn_clean_package_$(date +%Y%m%d%H%M).log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/logs/mvn_clean_package_$(date +%Y%m%d%H%M).log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn clean package java project finished for ${project_clone_repository_name} with exit code 0! \" echo } # ssh_execute_command_on_remote_host hostname command function ssh_execute_command_on_remote_host(){ [ $# -ne 2 ] && return 1 ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"$2\" >>${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"ssh execute command on remote host $2 failed! \" test -s ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log && echo_r \"\\tMore details refer to ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log\" return 1 else echo_g \"ssh execute command on remote host $2 successfully! \" return 0 fi } function restart_docker_container(){ echo_b \"Restarting docker container...\" [ $# -ne 2 ] && return 1 # TODO(Guodong Ding) if we need restart more related docker container local user_defined_docker_container_name=\"\" local remote_host_ip=\"\" test -n $1 && remote_host_ip=\"$1\" test -n $2 && user_defined_docker_container_name=\"$2\" ssh_execute_command_on_remote_host \"$remote_host_ip\" \"docker restart $user_defined_docker_container_name\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"restart docker container for $user_defined_docker_container_name on $remote_host_ip failed! \" exit 1 else echo_g \"restart docker container for $user_defined_docker_container_name on $remote_host_ip successfully! \" return 0 fi } # scp_local_files_to_remote_host local_path remote_hostname remote_path function scp_local_files_to_remote_host(){ [ $# -ne 3 ] && return 1 [ ! -d $1 -a ! -f $1 ] && return 1 # check_ssh_can_be_connect $2 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp local files to remote host failed! \" echo_r \"scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1\" exit 1 else echo_g \"scp local files to remote host successfully! \" fi } # scp_remote_files_to_local_host remote_hostname remote_path local_path function scp_remote_files_to_local_host(){ [ $# -ne 3 ] && return 1 # check_ssh_can_be_connect $1 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp root@$1:$2 $3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp remote files to local host failed! \" exit 1 else echo_g \"scp remote files to local host successfully! \" fi } function backup_single_file(){ set -o errexit if [ \"$#\" -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=\"`date +\"%Y%m%d%H%M%S\"`\" backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f ${backup_filename_origin} && cp ${backup_filename_origin} ${backup_filename_target} set +o errexit } # Function description: backup files # Note: accept $@ parameters function backup_files(){ # TODO(Guodong Ding) improvements here set -o errexit if [ $# -eq 0 ]; then return 1 fi file_list=$@ operation_date_time=\"_`date +\"%Y%m%d%H%M%S\"`\" log_filename=\".log_$$_${RANDOM}\" log_filename_full_path=/tmp/${log_filename} touch ${log_filename_full_path} old_IFS=$IFS IFS=\" \" for file in ${file_list};do real_file=$(realpath ${file}) [ -f ${real_file} ] && cp ${real_file} ${file}${operation_date_time}~ [ -f ${log_filename_full_path} ] && echo \"\\mv -f $file$operation_date_time~ $file\" >>${log_filename_full_path} done IFS=\"$old_IFS\" set +o errexit return 0 } # Function description: function rollback_files(){ # TODO(Guodong Ding) improvements here [ -f ${log_filename_full_path} ] && . ${log_filename_full_path} \\rm -f ${log_filename_full_path} exit 2 } # backup directories locally function backup_directories(){ # TODO(Guodong Ding) continue here if [ $# -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=\"`date +\"%Y%m%d%H%M%S\"`\" backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f ${backup_filename_origin} && cp -r ${backup_filename_origin} ${backup_filename_target} } function rollback_directories(){ # TODO(Guodong Ding) continue here return } # function backup_remote_host_config_files(){ # TODO(Guodong Ding) did not throw a exception when first deploy and test -z \"$user_defined_project_conf_directory\" echo_b \"backup remote host config files...\" # backup operation only executed once time, using '$0 backup_manual' backup new configuration files. # if ${WORKDIR}/${user_defined_project_conf_directory} is not empty then return 0 to exit if [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ]; then [ -f ${WORKDIR}/${user_defined_project_conf_directory}.backup_operation_once.log ] && backup_operation=\"`cat ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log`\" echo_g \"Backup remote host config files operation had been done, $backup_operation, now skipping ... \" return 0 fi # TODO(Guodong Ding) if $user_defined_project_conf_directory is empty and remote host target directory is empty(first deploy), will cause exit with 1 ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"test \\\"\\$(ls -A $user_defined_project_top_directory_to_target_host 2>/dev/null)\\\"\" if test $? -eq 0; then scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host}/* ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here test ! -z ${user_defined_project_conf_directory} -a -d ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com && rm -rf ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log else echo_y \"This maybe first time to deploy or variable 'user_defined_project_conf_directory' is not defined! \" fi } function rollback_remote_host_config_files(){ echo_b \"rollback remote host config files...\" #scp_local_files_to_remote_host ${WORKDIR}/${user_defined_project_conf_directory} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -r ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} # TODO(Guodong Ding) if save remote host config files, if there are no changes on config files # some ops # TODO(Guodong Ding) improvements here echo_g \"rollback remote host config files finished.\" } function make_current_workable_source(){ # check a directories lock, Note: this is redundant if [[ ! -f ${WORKDIR}/.capistrano_ds_lock ]]; then setDirectoryStructureOnLocalHost fi clean_old_releases clean_old_logs # do dependencies checking if test ! -z ${user_defined_skip_check_network_and_resolver}; then echo_g \"skipping checking network connectivity and name resolve.\" else check_network_connectivity check_name_resolve fi check_other_dependencies # do core job # TODO(Guodong Ding) if we need a git_project_clone \"$user_defined_project_clone_depends\" here using auto judgment statement test -z ${user_defined_project_clone_depends} || git_project_clone \"$user_defined_project_clone_depends\" ${user_defined_project_clone_depends_branch_or_tag} git_project_clone \"$user_defined_project_clone\" test -z ${user_defined_project_clone_depends} || maven_install \"$user_defined_project_clone_depends\" maven_clean_package \"$user_defined_project_clone\" cd ${WORKDIR} # links_target_directory_to_current # Make directory to release directory if test ! -d ${WORKDIR}/release -o ! -d ${WORKDIR}/share; then echo_r \"capistrano directory structure is broken, make sure the file .capistrano_ds_lock is deleted before a new deploy! \" # test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock exit 1 fi new_release_just_created=\"$WORKDIR/release/$(date +%Y%m%d%H%M%S)\" [ ! -d ${new_release_just_created} ] && mkdir ${new_release_just_created} # for special project, such as a project have different name from its git repository name, for example here, \"chatter\" # TODO(Guodong Ding) find more this foreseeable exception here if [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/ ]; then \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/* ${new_release_just_created} elif [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/chatter ]; then \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/chatter/* ${new_release_just_created} else echo_r \"A foreseeable error occurred, please alter to Developer & Administrator. \" exit 1 fi # Make source code symbolic link to current ( [ -f ${WORKDIR}/current ] || [ -d ${WORKDIR}/current ] ) && rm -rf ${WORKDIR}/current ln -s ${new_release_just_created} ${WORKDIR}/current # for some bash scripts in the ${WORKDIR}/current find ${WORKDIR}/current/ -type f -name \"*.sh\" -exec chmod +x '{}' \\; # Move conf and logs directives from release to share if found [ -d ${WORKDIR}/release/conf ] && mv ${WORKDIR}/release/conf ${WORKDIR}/share/conf [ -d ${WORKDIR}/release/logs ] && mv ${WORKDIR}/release/logs ${WORKDIR}/share/logs # Make conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current/conf [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current/logs } # distribute current workable files to remote host function deploy() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_target_host_ip ...\" # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # remove all file in remote host target directories and files, if target is not exist, then create it. ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"if test -d $user_defined_project_top_directory_to_target_host; then find -L $user_defined_project_top_directory_to_target_host -maxdepth 1 ! -name \"logs\" ! -wholename \"${user_defined_project_top_directory_to_target_host}\" -exec rm -rf {} \\; ; else mkdir -p $user_defined_project_top_directory_to_target_host; fi\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory} ; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi # backup remote host config files to local again for next using [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy successfully for $user_defined_deploy_target_host_ip! \" echo_g \"Current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollback fi } # Rollback to last right configuration function rollback() { echo_b \"Rollback to last right configuration... \" # The key point is find last files which can work WORKABLE_PROGRAM=`cat ${WORKDIR}/share/workable_program.log` if [[ -z ${WORKABLE_PROGRAM} ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # Stop service if we have if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh stop\" fi # Remove failed deploy rm -rf ${WORKDIR}/current # Remake source code symbolic link to current ln -s ${WORKABLE_PROGRAM} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $WORKABLE_PROGRAM\" fi } # rollback to any workable version which user wished by manually function rollback_manual(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something go wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # Alternative implementation: ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | sed -n '1,4p' ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | head -n4 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # # rollback remote host config files # [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do # TODO(Guodong Ding) scp timeout scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } # backup remote hosts config files only, # use this function when you modify some config files on remote host function backup_manual(){ set -o errexit # Bug fixed: check config backup directory(directories) if exist, useful when execute backup_manual function before other functions. if test ! -d ${WORKDIR}/${user_defined_project_conf_directory}; then mkdir -p ${WORKDIR}/${user_defined_project_conf_directory} fi echo_b \"backup remote host config files...\" scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} \"${user_defined_project_top_directory_to_target_host}/*\" ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here test ! -z ${user_defined_project_conf_directory} -a -d ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com && rm -rf ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log set +o errexit } # distribute current workable files to remote hosts function deploys() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_targets_host_ip_list ...\" for remote_host_ip in ${user_defined_deploy_targets_host_ip_list};do echo_b \"Do deploy on $remote_host_ip ...\" # remove all file in remote host target directories and files ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"if test -d $user_defined_project_top_directory_to_target_host; then cd $user_defined_project_top_directory_to_target_host && rm $user_defined_project_top_directory_to_target_host/*; else mkdir -p $user_defined_project_top_directory_to_target_host; fi\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${remote_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${remote_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh start ssh_execute_command_on_remote_host ${remote_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${remote_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Deploy successfully on $remote_host_ip! \" else echo_r \"Error: Deploy failed! on $remote_host_ip! \" echo_p \"Try modify $user_defined_deploy_target_host_ip and using standalone deployment mode\" exit 1 fi done # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy finished! on $user_defined_deploy_targets_host_ip_list \" echo_g \"current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" # ls --color=auto -l ${WORKDIR}/current # ls --color=auto -l ${WORKDIR}/current/ else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollbacks fi } function rollbacks(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something go wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit. Enter 'reset' command to reset terminal when something go wrong.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # ls -d -1 ${WORKDIR}/release/* ls -u -1 -d ${WORKDIR}/release/* | tail -n5 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for host_ip in ${user_defined_deploy_targets_host_ip_list};do for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully on $user_defined_deploy_targets_host_ip_list! \" echo_g \"Current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } function destroy() { # echo a Warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" user_input_answer_want_do_destroy=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" user_input_answer_want_do_destroy case \"$user_input_answer_want_do_destroy\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"filename\" | xargs rm -rf find -L ${WORKDIR} -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf '{}' \\; if [ $? -eq 0 ];then test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } function usage(){ cat - << eof \"${WORKDIR}/`basename $0` deploy new deploy/ update one remote target host \"${WORKDIR}/`basename $0` rollback_manual rollback to any workable version to one remote target host by manual \"${WORKDIR}/`basename $0` deploys new deploy/ update more then one remote target host \"${WORKDIR}/`basename $0` rollbacks rollback to any workable version to more than one remote target host by manual \"${WORKDIR}/`basename $0` backup_manual| backup backup conf files to local by manual when you add/delete/update conf files on remote target host eof } function main(){ lock_filename=\"lock_$$_${RANDOM}\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` [ -n \"$header\" ] && echo \"$header\" # # if exist file '.capistrano_ds_lock', then this is not first deployment, and unset # if test -f ${WORKDIR}/.capistrano_ds_lock; then # unset user_defined_project_conf_directory # user_defined_project_conf_directory=\"\" # fi branch_from_cli=\"\" tag_from_cli=\"\" while getopts 'b:t:' opt; do case ${opt}$OPTARG in b*) branch_from_cli=\"$OPTARG\" ;; t*) tag_from_cli=\"$OPTARG\" ;; h|?|*) echo \"$0 -b <branch name> -t <tag name> <parameter>...\" echo \"$0 -b <branch name> <parameter>...\" echo \"$0 -t <tag name> <parameter>...\" exit 1 ;; esac done shift `expr $OPTIND - 1` if [[ \"x$branch_from_cli\" != \"x\" ]];then branch_or_tag=${branch_from_cli} elif [[ \"x$tag_from_cli\" != \"x\" ]];then branch_or_tag=${tag_from_cli} else echo_y \"missing parameter -b <branch name> or -t <tag name>, this para for deploy func is required!\" # echo_r \"missing parameter -b <branch name> or -t <tag name>\" # exit 1 ## branch_or_tag=${user_defined_project_clone_branch_or_tag} fi if [[ $# -lt 1 ]]; then ${WORKDIR}/`basename $0` help exit 0 fi case $1 in deploy) deployment_mode=\"1\" deploy ;; rollback) rollback ;; rollback_manual|rollbackup_manual) rollback_manual ;; backup_manual|backup) backup_manual ;; deploys) deployment_mode=\"0\" deploys; ;; rollbacks|rollbackups) rollbacks ;; destroy) destroy ;; help|*) echo \"Usage: $0 -b <branch name> {deploy|rollback_manual|deploys|backup_manual} with $0 itself\" echo \"Usage: $0 -t <tag name> {deploy|rollback_manual|deploys|backup_manual} with $0 itself\" echo \"Usage: $0 {deploy|rollback_manual|deploys|backup_manual} with $0 itself\" usage exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_440.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\doDeploy_with_config_and_procedure_separate\\autodeployv3\\file_440.sh",
            "content": "#!/bin/bash # Name: doDeploy.sh #Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. # debug option DEBUG=false #DEBUG=true if ${DEBUG} ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi # define user friendly messages header=\" Function: Execute this shell script to deploy Java projects built by Maven automatically on remote hosts. License: Open source software \" # set an empty function using for location this line quickly in PyCharm editor on purpose. function _empty() { return; } # load user defined variables # Where to get source code # TODO(Guodong Ding) using with `basename $0` if test -f deploy_conf ; then source deploy_conf fi # end define variables # pretreatment predefined variables # TODO(Guodong Ding) project_clone_target_depends_1 is not used for git clone because git has done for us test -z ${user_defined_project_clone_depends} || project_clone_target_depends_1=\"`echo ${user_defined_project_clone_depends} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_target=\"`echo ${user_defined_project_clone} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_repository_name=${project_clone_target} deployment_mode=\"\" # end pretreatment predefined variables # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi function command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } function check_command_can_be_execute(){ [ $# -ne 1 ] && return 1 command_exists $1 } function check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once time! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" echo fi } function check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" echo return 0 fi } function check_ssh_can_be_connect(){ [ $# -ne 1 ] && return 1 echo_b \"Check if can ssh to remote host $1 ... \" check_command_can_be_execute ssh || return 1 # TODO(Guodong Ding) ssh can connect to remote host by using /etc/ssh/ssh_host_rsa_key or ~/.ssh/id_rsa ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"uname -a >/dev/null 2>&1\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"Check ssh to remote host $1 failed! \" exit 1 else echo_g \"Check ssh to remote host $1 successfully! \" fi } function check_other_dependencies() { echo_b \"Checking other dependencies for deploy procedure... \" echo_b \"\\tChecking user customized variables...\" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z ${user_defined_project_clone} ]]; then echo_r \"Error: user_defined_project_clone is undefined! \" exit 1 fi # Note: test command is strongly typed, can recognize string type and integer type if test ! -z \"$user_defined_deploy_target_host_ip\" -a ! -z \"$user_defined_deploy_targets_host_ip_list\" ; then user_defined_deploy_targets_host_first_ip_in_list=\"`echo \"$user_defined_deploy_targets_host_ip_list\" | awk -F ' ' '{ print $1 }'`\" if test \"$user_defined_deploy_target_host_ip\" = \"$user_defined_deploy_targets_host_first_ip_in_list\" -a \"$deployment_mode\" = \"0\" ; then echo_g \"Run this shell script in multi-deployment mode, deploy to a group of hosts.\" saved_IFS=$IFS IFS=' ' for ipaddress in ${user_defined_deploy_targets_host_ip_list}; do check_ssh_can_be_connect ${ipaddress} done IFS=${saved_IFS} elif test \"$user_defined_deploy_target_host_ip\" != \"$user_defined_deploy_targets_host_first_ip_in_list\"; then echo_r \"\\\"$user_defined_deploy_targets_host_ip_list\\\" is not equal to \\\"$user_defined_deploy_target_host_ip\\\", this is a must! \" exit 1 fi elif test ! -z \"$user_defined_deploy_target_host_ip\" -a -z \"$user_defined_deploy_targets_host_ip_list\" -a \"$deployment_mode\" = \"1\" ;then echo_g \"Run this shell script in standalone-deployment mode, deploy to single host.\" elif test -z \"$user_defined_deploy_target_host_ip\" -a -z \"$user_defined_deploy_targets_host_ip_list\" ;then echo_r \"Error: both user_defined_deploy_target_host_ip and user_defined_deploy_targets_host_ip_list is undefined! \" exit 1 else echo_r \"Error: bad user defined parameters, please fix it and try again! \" exit 1 fi if [[ -z ${user_defined_project_top_directory_to_target_host} ]]; then echo_r \"Error: user_defined_project_top_directory_to_target_host is undefined! \" exit 1 fi if test -z ${user_defined_project_conf_directory}; then # TODO(Guodong Ding) check directory if exist if test -d ${WORKDIR}/${user_defined_project_conf_directory}; then echo_y \"Warning: ${WORKDIR}/${user_defined_project_conf_directory} is not exist!\" fi echo_y \"Warning: user defined project conf directory is not defined! \" fi echo_g \"\\tChecking user customized and defined variables passed! \" echo_b \"\\tChecking disk space available...\" disk_space_available=`df ${WORKDIR} | tail -n1 | awk '{print $(NF-2)}'` if [[ ${disk_space_available} -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 else echo_g \"\\tChecking disk space available passed! \" fi echo_g \"All required dependencies check passed! \" echo } function setDirectoryStructureOnLocalHost() { set -o errexit if [ -f ${WORKDIR}/.capistrano_ds_lock ];then echo_g \"Set directory structure has been done, skipping. \" return fi echo_b \"Setting directory structure... \" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branch names or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy [ ! -d ${WORKDIR}/release ] && mkdir ${WORKDIR}/release [ ! -d ${WORKDIR}/repository ] && mkdir ${WORKDIR}/repository [ ! -d ${WORKDIR}/share ] && mkdir ${WORKDIR}/share # end directories structure # Additional directories structure for full deploy operation # for backup remote host config file [ ! -d ${WORKDIR}/${user_defined_project_conf_directory} ] && mkdir ${WORKDIR}/${user_defined_project_conf_directory} # deploy logs for git/mvn/ssh [ ! -d ${WORKDIR}/logs ] && mkdir ${WORKDIR}/logs # set a directories structure lock touch ${WORKDIR}/.capistrano_ds_lock echo_g \"Set directory structure successfully! \" echo set +o errexit } function clean_old_releases_discarded(){ echo_b \"Clean old releases... \" save_days=${save_old_releases_for_days:-10} if [ ! -d ${WORKDIR}/release ]; then echo_b \"Can NOT find release directory, skipping . \" return fi need_clean=$(find ${WORKDIR}/release -mtime +${save_days} -exec ls '{}' \\; | wc -l) if [ ${need_clean} -gt 0 ]; then echo_c \"Expired releases found and will be removed from project! \" find ${WORKDIR}/release -mtime +${save_days} -exec rm -rf '{}' \\; >/dev/null 2>&1 if [ $? -eq 0 ]; then echo_g \"Expired releases have removed from project! \" else echo_r \"Can NOT remove expired releases, please feel free to alter to administrators. \" fi else echo_g \"All releases are not expired, skipping. \" fi } function clean_old_releases(){ echo_b \"Clean old releases... \" num_save=${save_old_releases_for_numbers:-10} files_ops=${WORKDIR}/release num_files=$(find ${files_ops} -maxdepth 1 -type d -a ! -wholename \".\" -a ! -wholename \"..\" -a ! -wholename \"$files_ops\" -printf \"%C@ %p\\n\" | sort -n | wc -l) if test ${num_files} -gt ${num_save};then echo_c \"Extra releases found and will be removed from project! \" num_ops=$(expr ${num_files} - ${num_save}) list_ops=$(find ${files_ops} -maxdepth 1 -type d -a ! -wholename \".\" -a ! -wholename \"..\" -a ! -wholename \"$files_ops\" -printf \"%C@ %p\\n\" | sort -n | head -n${num_ops} | awk -F '[ ]+' '{print $2}') # IFS=' '$'\\t'$'\\n', If IFS is unset, or its value is exactly <space><tab><newline> old_IFS=$IFS IFS=' '$'\\t'$'\\n' for file_ops in ${list_ops};do test -d ${file_ops} && rm -rf ${file_ops} done IFS=\"$old_IFS\" echo_g \"Extra releases have been removed from project! \" else echo_g \"All releases are essential, skipping. \" fi } function clean_old_logs(){ echo_b \"Clean old logs... \" save_days=${save_old_releases_for_days:-10} need_clean=$(find ${WORKDIR}/logs -name \"*.log\" -mtime +${save_days} -exec ls '{}' \\; | wc -l) if [ ${need_clean} -gt 0 ]; then echo_c \"Expired releases found and will be removed from project! \" find -L ${WORKDIR}/logs -maxdepth 1 -name \"*.log\" -a ! -name \"^.\" -mtime +${save_days} -exec rm -rf '{}' \\; >/dev/null 2>&1 if [ $? -eq 0 ]; then echo_g \"Expired logs have removed from project! \" else echo_r \"Can NOT remove expired logs, please feel free to alter to administrators. \" fi else echo_g \"All logs are not expired, skipping. \" fi } # git_project_clone repository branch function git_project_clone(){ set -o errexit [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} # TODO(Guodong Ding) let user set this variable(\"branch\") # Note: branch is equal to tag, so using tag as branch or using branch as a tag if [[ \"x$branch_or_tag\" != \"x\" ]]; then branch=${branch_or_tag} else branch=\"\" fi if test -n \"$2\"; then branch=\"$2\" fi if [[ \"x$branch\" == \"x\" ]]; then echo_r \"get branch name or tag name failed!\" exit 1 fi if test ! -d ${project_clone_directory}; then echo_b \"git clone from $project_clone_repository\" # git clone git@github.com:name/app.git -b master git clone ${project_clone_repository} ${project_clone_directory} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log 2>&1 echo_g \"git clone from $project_clone_repository successfully! \" # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd ${project_clone_directory} current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log else git checkout ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log 2>&1 git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log fi echo_b \"git pull from $project_clone_repository with branch or tag name $branch.\" git pull origin ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log 2>&1 git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log cd ${WORKDIR} echo_g \"git pull from $project_clone_repository with branch or tag name $branch successfully! \" else echo_b \"git pull from $project_clone_repository with branch or tag name $branch.\" cd ${project_clone_directory} current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log else git checkout ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log 2>&1 git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log fi git pull origin ${branch} >>${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log 2>&1 # TODO(Guodong Ding) get branch names or revision numbers from VCS data # git rev-parse HEAD # git rev-parse --verify HEAD # git rev-parse HEAD | cut -c1-10 # git show-ref # git for-each-ref # git log --pretty=format:'%h' -n 1 # git log -1 --format=\"%H\" # git rev-list --max-count=1 HEAD # git show --pretty=%h cd ${WORKDIR} echo_g \"git pull from $project_clone_repository with branch or tag name $branch successfully! \" fi set +o errexit } function maven_build_project_deprecated(){ set -o errexit echo_b \"Do mvn build java project... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log 2>&1 mvn clean package >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log 2>&1 cd ${WORKDIR} echo_g \"Do mvn build java project finished with exit code 0! \" set +o errexit } function maven_build_project(){ echo_b \"Do mvn build java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi mvn clean package >>${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/logs/mvn_build_$(date +%Y%m%d%H%M).log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn build java project finished for ${project_clone_repository_name} with exit code 0! \" echo } function maven_install(){ echo_b \"Do mvn install java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn install >>${WORKDIR}/logs/mvn_install_$(date +%Y%m%d%H%M).log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn install failed! More details refer to ${WORKDIR}/logs/mvn_install_$(date +%Y%m%d%H%M).log\" exit 1 else echo_g \"mvn install for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn install java project finished for ${project_clone_repository_name} with exit code 0! \" echo } function maven_clean_package(){ echo_b \"Do mvn clean package java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn clean package >>${WORKDIR}/logs/mvn_clean_package_$(date +%Y%m%d%H%M).log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/logs/mvn_clean_package_$(date +%Y%m%d%H%M).log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi cd ${WORKDIR} echo_g \"Do mvn clean package java project finished for ${project_clone_repository_name} with exit code 0! \" echo } # ssh_execute_command_on_remote_host hostname command function ssh_execute_command_on_remote_host(){ [ $# -ne 2 ] && return 1 ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"$2\" >>${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"ssh execute command on remote host $2 failed! \" test -s ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log && echo_r \"\\tMore details refer to ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log\" return 1 else echo_g \"ssh execute command on remote host $2 successfully! \" return 0 fi } function restart_docker_container(){ echo_b \"Restarting docker container...\" [ $# -ne 2 ] && return 1 # TODO(Guodong Ding) if we need restart more related docker container local user_defined_docker_container_name=\"\" local remote_host_ip=\"\" test -n $1 && remote_host_ip=\"$1\" test -n $2 && user_defined_docker_container_name=\"$2\" ssh_execute_command_on_remote_host \"$remote_host_ip\" \"docker restart $user_defined_docker_container_name\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"restart docker container for $user_defined_docker_container_name on $remote_host_ip failed! \" exit 1 else echo_g \"restart docker container for $user_defined_docker_container_name on $remote_host_ip successfully! \" return 0 fi } # scp_local_files_to_remote_host local_path remote_hostname remote_path function scp_local_files_to_remote_host(){ [ $# -ne 3 ] && return 1 [ ! -d $1 -a ! -f $1 ] && return 1 # check_ssh_can_be_connect $2 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp local files to remote host failed! \" echo_r \"scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1\" exit 1 else echo_g \"scp local files to remote host successfully! \" fi } # scp_remote_files_to_local_host remote_hostname remote_path local_path function scp_remote_files_to_local_host(){ [ $# -ne 3 ] && return 1 # check_ssh_can_be_connect $1 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp root@$1:$2 $3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp remote files to local host failed! \" exit 1 else echo_g \"scp remote files to local host successfully! \" fi } function backup_single_file(){ set -o errexit if [ \"$#\" -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=\"`date +\"%Y%m%d%H%M%S\"`\" backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f ${backup_filename_origin} && cp ${backup_filename_origin} ${backup_filename_target} set +o errexit } # Function description: backup files # Note: accept $@ parameters function backup_files(){ # TODO(Guodong Ding) improvements here set -o errexit if [ $# -eq 0 ]; then return 1 fi file_list=$@ operation_date_time=\"_`date +\"%Y%m%d%H%M%S\"`\" log_filename=\".log_$$_${RANDOM}\" log_filename_full_path=/tmp/${log_filename} touch ${log_filename_full_path} old_IFS=$IFS IFS=\" \" for file in ${file_list};do real_file=$(realpath ${file}) [ -f ${real_file} ] && cp ${real_file} ${file}${operation_date_time}~ [ -f ${log_filename_full_path} ] && echo \"\\mv -f $file$operation_date_time~ $file\" >>${log_filename_full_path} done IFS=\"$old_IFS\" set +o errexit return 0 } # Function description: function rollback_files(){ # TODO(Guodong Ding) improvements here [ -f ${log_filename_full_path} ] && . ${log_filename_full_path} \\rm -f ${log_filename_full_path} exit 2 } # backup directories locally function backup_directories(){ # TODO(Guodong Ding) continue here if [ $# -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=\"`date +\"%Y%m%d%H%M%S\"`\" backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f ${backup_filename_origin} && cp -r ${backup_filename_origin} ${backup_filename_target} } function rollback_directories(){ # TODO(Guodong Ding) continue here return } # function backup_remote_host_config_files(){ # TODO(Guodong Ding) did not throw a exception when first deploy and test -z \"$user_defined_project_conf_directory\" echo_b \"backup remote host config files...\" # backup operation only executed once time, using '$0 backup_manual' backup new configuration files. # if ${WORKDIR}/${user_defined_project_conf_directory} is not empty then return 0 to exit if [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ]; then [ -f ${WORKDIR}/${user_defined_project_conf_directory}.backup_operation_once.log ] && backup_operation=\"`cat ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log`\" echo_g \"Backup remote host config files operation had been done, $backup_operation, now skipping ... \" return 0 fi # TODO(Guodong Ding) if $user_defined_project_conf_directory is empty and remote host target directory is empty(first deploy), will cause exit with 1 ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"test \\\"\\$(ls -A $user_defined_project_top_directory_to_target_host 2>/dev/null)\\\"\" if test $? -eq 0; then scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host}/* ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here test ! -z ${user_defined_project_conf_directory} -a -d ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com && rm -rf ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log else echo_y \"This maybe first time to deploy or variable 'user_defined_project_conf_directory' is not defined! \" fi } function rollback_remote_host_config_files(){ echo_b \"rollback remote host config files...\" #scp_local_files_to_remote_host ${WORKDIR}/${user_defined_project_conf_directory} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -r ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} # TODO(Guodong Ding) if save remote host config files, if there are no changes on config files # some ops # TODO(Guodong Ding) improvements here echo_g \"rollback remote host config files finished.\" } function make_current_workable_source(){ # check a directories lock, Note: this is redundant if [[ ! -f ${WORKDIR}/.capistrano_ds_lock ]]; then setDirectoryStructureOnLocalHost fi clean_old_releases clean_old_logs # do dependencies checking if test ! -z ${user_defined_skip_check_network_and_resolver}; then echo_g \"skipping checking network connectivity and name resolve.\" else check_network_connectivity check_name_resolve fi check_other_dependencies # do core job # TODO(Guodong Ding) if we need a git_project_clone \"$user_defined_project_clone_depends\" here using auto judgment statement test -z ${user_defined_project_clone_depends} || git_project_clone \"$user_defined_project_clone_depends\" ${user_defined_project_clone_depends_branch_or_tag} git_project_clone \"$user_defined_project_clone\" test -z ${user_defined_project_clone_depends} || maven_install \"$user_defined_project_clone_depends\" maven_clean_package \"$user_defined_project_clone\" cd ${WORKDIR} # links_target_directory_to_current # Make directory to release directory if test ! -d ${WORKDIR}/release -o ! -d ${WORKDIR}/share; then echo_r \"capistrano directory structure is broken, make sure the file .capistrano_ds_lock is deleted before a new deploy! \" # test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock exit 1 fi new_release_just_created=\"$WORKDIR/release/$(date +%Y%m%d%H%M%S)\" [ ! -d ${new_release_just_created} ] && mkdir ${new_release_just_created} # for special project, such as a project have different name from its git repository name, for example here, \"chatter\" # TODO(Guodong Ding) find more this foreseeable exception here if [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/ ]; then \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/${project_clone_repository_name}/* ${new_release_just_created} elif [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target/chatter ]; then \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/chatter/* ${new_release_just_created} else echo_r \"A foreseeable error occurred, please alter to Developer & Administrator. \" exit 1 fi # Make source code symbolic link to current ( [ -f ${WORKDIR}/current ] || [ -d ${WORKDIR}/current ] ) && rm -rf ${WORKDIR}/current ln -s ${new_release_just_created} ${WORKDIR}/current # for some bash scripts in the ${WORKDIR}/current find ${WORKDIR}/current/ -type f -name \"*.sh\" -exec chmod +x '{}' \\; # Move conf and logs directives from release to share if found [ -d ${WORKDIR}/release/conf ] && mv ${WORKDIR}/release/conf ${WORKDIR}/share/conf [ -d ${WORKDIR}/release/logs ] && mv ${WORKDIR}/release/logs ${WORKDIR}/share/logs # Make conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current/conf [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current/logs } # distribute current workable files to remote host function deploy() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_target_host_ip ...\" # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # remove all file in remote host target directories and files, if target is not exist, then create it. ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"if test -d $user_defined_project_top_directory_to_target_host; then find -L $user_defined_project_top_directory_to_target_host -maxdepth 1 ! -name \"logs\" ! -wholename \"${user_defined_project_top_directory_to_target_host}\" -exec rm -rf {} \\; ; else mkdir -p $user_defined_project_top_directory_to_target_host; fi\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory} ; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi # backup remote host config files to local again for next using [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy successfully for $user_defined_deploy_target_host_ip! \" echo_g \"Current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollback fi } # Rollback to last right configuration function rollback() { echo_b \"Rollback to last right configuration... \" # The key point is find last files which can work WORKABLE_PROGRAM=`cat ${WORKDIR}/share/workable_program.log` if [[ -z ${WORKABLE_PROGRAM} ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # Stop service if we have if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh stop\" fi # Remove failed deploy rm -rf ${WORKDIR}/current # Remake source code symbolic link to current ln -s ${WORKABLE_PROGRAM} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $WORKABLE_PROGRAM\" fi } # rollback to any workable version which user wished by manually function rollback_manual(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something go wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # Alternative implementation: ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | sed -n '1,4p' ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | head -n4 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # # rollback remote host config files # [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do # TODO(Guodong Ding) scp timeout scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } # backup remote hosts config files only, # use this function when you modify some config files on remote host function backup_manual(){ set -o errexit # Bug fixed: check config backup directory(directories) if exist, useful when execute backup_manual function before other functions. if test ! -d ${WORKDIR}/${user_defined_project_conf_directory}; then mkdir -p ${WORKDIR}/${user_defined_project_conf_directory} fi echo_b \"backup remote host config files...\" scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} \"${user_defined_project_top_directory_to_target_host}/*\" ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here test ! -z ${user_defined_project_conf_directory} -a -d ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com && rm -rf ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log set +o errexit } # distribute current workable files to remote hosts function deploys() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_targets_host_ip_list ...\" for remote_host_ip in ${user_defined_deploy_targets_host_ip_list};do echo_b \"Do deploy on $remote_host_ip ...\" # remove all file in remote host target directories and files ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"if test -d $user_defined_project_top_directory_to_target_host; then cd $user_defined_project_top_directory_to_target_host && rm $user_defined_project_top_directory_to_target_host/*; else mkdir -p $user_defined_project_top_directory_to_target_host; fi\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${remote_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${remote_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh start ssh_execute_command_on_remote_host ${remote_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${remote_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Deploy successfully on $remote_host_ip! \" else echo_r \"Error: Deploy failed! on $remote_host_ip! \" echo_p \"Try modify $user_defined_deploy_target_host_ip and using standalone deployment mode\" exit 1 fi done # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy finished! on $user_defined_deploy_targets_host_ip_list \" echo_g \"current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" # ls --color=auto -l ${WORKDIR}/current # ls --color=auto -l ${WORKDIR}/current/ else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollbacks fi } function rollbacks(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something go wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit. Enter 'reset' command to reset terminal when something go wrong.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # ls -d -1 ${WORKDIR}/release/* ls -u -1 -d ${WORKDIR}/release/* | tail -n5 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # scp_local_files_to_remote_host ${WORKDIR}/current/ ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for host_ip in ${user_defined_deploy_targets_host_ip_list};do for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully on $user_defined_deploy_targets_host_ip_list! \" echo_g \"Current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } function destroy() { # echo a Warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" user_input_answer_want_do_destroy=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" user_input_answer_want_do_destroy case \"$user_input_answer_want_do_destroy\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"filename\" | xargs rm -rf find -L ${WORKDIR} -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf '{}' \\; if [ $? -eq 0 ];then test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } function usage(){ cat - << eof \"${WORKDIR}/`basename $0` deploy new deploy/ update one remote target host \"${WORKDIR}/`basename $0` rollback_manual rollback to any workable version to one remote target host by manual \"${WORKDIR}/`basename $0` deploys new deploy/ update more then one remote target host \"${WORKDIR}/`basename $0` rollbacks rollback to any workable version to more than one remote target host by manual \"${WORKDIR}/`basename $0` backup_manual| backup backup conf files to local by manual when you add/delete/update conf files on remote target host eof } function main(){ lock_filename=\"lock_$$_${RANDOM}\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` [ -n \"$header\" ] && echo \"$header\" # # if exist file '.capistrano_ds_lock', then this is not first deployment, and unset # if test -f ${WORKDIR}/.capistrano_ds_lock; then # unset user_defined_project_conf_directory # user_defined_project_conf_directory=\"\" # fi branch_from_cli=\"\" tag_from_cli=\"\" while getopts 'b:t:' opt; do case ${opt}$OPTARG in b*) branch_from_cli=\"$OPTARG\" ;; t*) tag_from_cli=\"$OPTARG\" ;; h|?|*) echo \"$0 -b <branch name> -t <tag name> <parameter>...\" echo \"$0 -b <branch name> <parameter>...\" echo \"$0 -t <tag name> <parameter>...\" exit 1 ;; esac done shift `expr $OPTIND - 1` if [[ \"x$branch_from_cli\" != \"x\" ]];then branch_or_tag=${branch_from_cli} elif [[ \"x$tag_from_cli\" != \"x\" ]];then branch_or_tag=${tag_from_cli} else echo_y \"missing parameter -b <branch name> or -t <tag name>, this para for deploy func is required!\" # echo_r \"missing parameter -b <branch name> or -t <tag name>\" # exit 1 # branch_or_tag=${user_defined_project_clone_branch_or_tag} fi if [[ $# -lt 1 ]]; then ${WORKDIR}/`basename $0` help exit 0 fi case $1 in deploy) deployment_mode=\"1\" deploy ;; rollback) rollback ;; rollback_manual|rollbackup_manual) rollback_manual ;; backup_manual|backup) backup_manual ;; deploys) deployment_mode=\"0\" deploys; ;; rollbacks|rollbackups) rollbacks ;; destroy) destroy ;; help|*) echo \"Usage: $0 -b <branch name> {deploy|rollback_manual|deploys|backup_manual} with $0 itself\" echo \"Usage: $0 -t <tag name> {deploy|rollback_manual|deploys|backup_manual} with $0 itself\" echo \"Usage: $0 {deploy|rollback_manual|deploys|backup_manual} with $0 itself\" usage exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_441.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\gitlab-ci\\bash\\scripts\\file_441.sh",
            "content": "#!/bin/bash ENVIRONMENT=\"$1\" CURRENT_APP_ROOT=\"$APP_ROOT/$APP_NAME\" POST_DEPLOY_SCRIPT=\"$CURRENT_APP_ROOT/scripts/post_deploy.sh\" DEPLOY_HOSTS_CONF_FILE=\"scripts/\"\"$ENVIRONMENT\"\"_deploy_host.conf\" function do_deploy() { local DEST_HOST_IP local DEST_HOST_PORT local DEST_HOST_USER DEST_HOST_IP=$(echo \"$1\" | awk -F\":\" '{print $1}') DEST_HOST_PORT=$(echo \"$1\" | awk -F\":\" '{print $2}') DEST_HOST_USER=$(echo \"$1\" | awk -F\":\" '{print $3}') DEST_HOST_EXTERNAL_IP=$(echo \"$1\" | awk -F\":\" '{print $NF}') if [[ \"x$DEST_HOST_EXTERNAL_IP\" != \"x\" ]]; then DEST_HOST_IP=\"$DEST_HOST_EXTERNAL_IP\" fi if [[ \"$DEST_HOST_USER\" == \"\" ]]; then DEST_HOST_USER=\"$APP_USER\" fi ssh -p \"$DEST_HOST_PORT\" \"$DEST_HOST_USER@$DEST_HOST_IP\" \"mkdir -p $APP_ROOT/$APP_NAME\" rsync -e \"ssh -p $DEST_HOST_PORT\" -r --del . \"$DEST_HOST_USER@$DEST_HOST_IP:$APP_ROOT/$APP_NAME\" ssh -p \"$DEST_HOST_PORT\" \"$DEST_HOST_USER@$DEST_HOST_IP\" \" cd $CURRENT_APP_ROOT && \\ chmod +x $POST_DEPLOY_SCRIPT \\ && $POST_DEPLOY_SCRIPT \\ \" } function deploy() { # shellcheck disable=SC2013 for DEPLOY_HOST in $(cat \"$DEPLOY_HOSTS_CONF_FILE\"); do echo \"deploying $DEPLOY_HOST\" # deploy project do_deploy \"$DEPLOY_HOST\" http_code_status=1 # check project status if [ \"$HEALTHY_CHECK_OFF\" == \"true\" ]; then do_sleep 10 \"waiting service to startup\" continue else return 0 fi check_healthy 0 http_code_status=$? if [ $http_code_status == 0 ]; then continue else echo \"fail to deploy $DEPLOY_HOST\" return $http_code_status fi done } function do_sleep() { SECOND=$1 REASON=$2 [ \"$SECOND\" -lt 1 ] && return echo \"Sleeping $SECOND for $REASON\" sleep 1 do_sleep $((SECOND - 1)) \"${REASON}\" } function check_healthy() { retry_time=$1 retry_time=$((1 + retry_time)) status_code=000 RETRY_SLEEP_TIMES=6 RETRY_SLEEP_SECOND=10 echo \"================ HEALTHY_CHECK_URL : $HEALTHY_CHECK_URL =========================\" if [ \"$HEALTHY_CHECK_URL\" == \"\" ]; then status_code=$(curl -I -m 10 -o /dev/null -s -w \"%{http_code}\" \"http://127.0.0.1:8091/healthy_check\") else status_code=$(curl -I -m 10 -o /dev/null -s -w \"%{http_code}\" \"${HEALTHY_CHECK_URL/hostip/$DEST_HOST_IP}\") fi if [[ \"$status_code\" == 200 ]]; then echo \"connection is ok!!!\" return 0 else if [[ $retry_time -le $RETRY_SLEEP_TIMES ]]; then do_sleep $RETRY_SLEEP_SECOND \"waiting to do next healthy check\" check_healthy $retry_time else echo \"disconnected after $RETRY_SLEEP_TIMES retry...\" return 1 fi fi } set -e echo '----deploy begin ----' deploy echo '----deploy end ----'"
        },
        {
            "filename": "file_442.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\gitlab-ci\\bash\\scripts\\file_442.sh",
            "content": "#!/bin/bash echo -e \"\\nemm...,executed this.\\n\" exit 0"
        },
        {
            "filename": "file_443.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\VersionRelease\\file_443.sh",
            "content": "#!/bin/bash # Name: release_vux2_backend.sh # Execute this shell script to deploy vux2 project(backend, java servlet) built by npm automatically on remote hosts. # debug option DEBUG=false #DEBUG=true if ${DEBUG} ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi # define user friendly messages header=\" Function: Execute this shell script to deploy vux2 project(backend, java servlet) built by npm automatically on remote hosts. License: Open source software \" # set an empty function using for location this line quickly in PyCharm editor on purpose. function _empty() { return; } # user defined variables # Where to get source code user_defined_project_clone=\"ssh://git@git.example.com:18082/sino-agri/mscrm-service.git\" user_defined_project_clone_branch_or_tag=\"develop\" # this parameter can be replaced by option -b <branch name> or -t <tag name> user_defined_deploy_target_host_ip=\"10.6.28.46\" # this is a mandatory field, and must be same as the first ip in $user_defined_deploy_targets_host_ip_list user_defined_project_top_directory_to_target_host=\"/data/docker/mscrm-service/data\" user_defined_docker_container_name=\"mscrm-service\" # if you using a docker container other than a startup script located in sourcecode/bin/startup.sh, then set this to docker container name user_defined_project_conf_directory=\"config_backup\" # if you do NOT want to use configurations from deploy target, you should set this variable to where pointed to config files user_defined_skip_check_network_and_resolver=\"true\" # if system administrator disable ICMP protocol, set this any content but not null # Setting how many days do you want save old releases, default is 10 days save_old_releases_for_days=10 save_old_releases_for_numbers=10 # default branch or tag name for project to clone branch_or_tag=${user_defined_project_clone_branch_or_tag} # end define variables ## load user defined variables from file ## Where to get source code ## TODO(Guodong Ding) using with `basename $0` #if test -f deploy_conf ; then # source deploy_conf #else # echo \"Fatal error: can NOT found file: deploy_conf \" # exit 1 #fi ## end define variables from file # pretreatment predefined variables # TODO(Guodong Ding) project_clone_target_depends_1 is not used for git clone because git has done for us project_clone_target=\"`echo ${user_defined_project_clone} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_repository_name=${project_clone_target} deployment_mode=\"\" # end pretreatment predefined variables # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi function command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } function check_command_can_be_execute(){ [ $# -ne 1 ] && return 1 command_exists $1 } function check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once time! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" echo fi } function check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" echo return 0 fi } function check_ssh_can_be_connect(){ [ $# -ne 1 ] && return 1 echo_b \"Check if can ssh to remote host $1 ... \" check_command_can_be_execute ssh || return 1 # TODO(Guodong Ding) ssh can connect to remote host by using /etc/ssh/ssh_host_rsa_key or ~/.ssh/id_rsa ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"uname -a >/dev/null 2>&1\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"Check ssh to remote host $1 failed! \" exit 1 else echo_g \"Check ssh to remote host $1 successfully! \" fi } function check_other_dependencies() { echo_b \"Checking other dependencies for deploy procedure... \" echo_b \"\\tChecking user customized variables...\" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z ${user_defined_project_clone} ]]; then echo_r \"Error: user_defined_project_clone is undefined! \" exit 1 fi if [[ -z ${user_defined_project_top_directory_to_target_host} ]]; then echo_r \"Error: user_defined_project_top_directory_to_target_host is undefined! \" exit 1 fi if test -z ${user_defined_project_conf_directory}; then # TODO(Guodong Ding) check directory if exist if test -d ${WORKDIR}/${user_defined_project_conf_directory}; then echo_y \"Warning: ${WORKDIR}/${user_defined_project_conf_directory} is not exist!\" fi echo_y \"Warning: user defined project conf directory is not defined! \" fi echo_g \"\\tChecking user customized and defined variables passed! \" echo_b \"\\tChecking disk space available...\" disk_space_available=`df ${WORKDIR} | tail -n1 | awk '{print $(NF-2)}'` if [[ ${disk_space_available} -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 else echo_g \"\\tChecking disk space available passed! \" fi echo_g \"All required dependencies check passed! \" echo } function make_capistrano_directory_structure() { set -o errexit if [ -f ${WORKDIR}/.capistrano_ds_lock ];then echo_g \"Set directory structure has been done, skipping. \" return fi echo_b \"Setting directory structure... \" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branch names or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy [ ! -d ${WORKDIR}/release ] && mkdir ${WORKDIR}/release [ ! -d ${WORKDIR}/repository ] && mkdir ${WORKDIR}/repository [ ! -d ${WORKDIR}/share ] && mkdir ${WORKDIR}/share # end directories structure # Additional directories structure for full deploy operation # for backup remote host config file [ ! -d ${WORKDIR}/${user_defined_project_conf_directory} ] && mkdir ${WORKDIR}/${user_defined_project_conf_directory} # deploy logs for git/npm/ssh [ ! -d ${WORKDIR}/logs ] && mkdir ${WORKDIR}/logs # set a directories structure lock touch ${WORKDIR}/.capistrano_ds_lock echo_g \"Set directory structure successfully! \" echo set +o errexit } function clean_old_releases(){ echo_b \"Clean old releases... \" num_save=${save_old_releases_for_numbers:-10} files_ops=${WORKDIR}/release num_files=$(find ${files_ops} -maxdepth 1 -type d -a ! -wholename \".\" -a ! -wholename \"..\" -a ! -wholename \"$files_ops\" -printf \"%C@ %p\\n\" | sort -n | wc -l) if test ${num_files} -gt ${num_save};then echo_c \"Extra releases found and will be removed from project! \" num_ops=$(expr ${num_files} - ${num_save}) list_ops=$(find ${files_ops} -maxdepth 1 -type d -a ! -wholename \".\" -a ! -wholename \"..\" -a ! -wholename \"$files_ops\" -printf \"%C@ %p\\n\" | sort -n | head -n${num_ops} | awk -F '[ ]+' '{print $2}') # IFS=' '$'\\t'$'\\n', If IFS is unset, or its value is exactly <space><tab><newline> old_IFS=$IFS IFS=' '$'\\t'$'\\n' for file_ops in ${list_ops};do test -d ${file_ops} && rm -rf ${file_ops} done IFS=\"$old_IFS\" echo_g \"Extra releases have been removed from project! \" else echo_g \"All releases are essential, skipping. \" fi echo } function clean_old_logs(){ echo_b \"Clean old logs... \" save_days=${save_old_releases_for_days:-10} need_clean=$(find ${WORKDIR}/logs -name \"*.log\" -mtime +${save_days} -exec ls '{}' \\; | wc -l) if [ ${need_clean} -gt 0 ]; then echo_c \"Expired releases found and will be removed from project! \" find -L ${WORKDIR}/logs -maxdepth 1 -name \"*.log\" -a ! -name \"^.\" -mtime +${save_days} -exec rm -rf '{}' \\; >/dev/null 2>&1 if [ $? -eq 0 ]; then echo_g \"Expired logs have removed from project! \" else echo_r \"Can NOT remove expired logs, please feel free to alter to administrators. \" fi else echo_g \"All logs are not expired, skipping. \" fi echo } # git_project_clone repository branch function git_project_clone(){ set -o errexit [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} # TODO(Guodong Ding) let user set this variable(\"branch\") # Note: branch is equal to tag, so using tag as branch or using branch as a tag if [[ \"x$branch_or_tag\" != \"x\" ]]; then branch=${branch_or_tag} else branch=\"\" fi if test -n \"$2\"; then branch=\"$2\" fi if [[ \"x$branch\" == \"x\" ]]; then echo_r \"get branch name or tag name failed!\" exit 1 fi if test ! -d ${project_clone_directory}; then echo_b \"git clone from $project_clone_repository\" # git clone git@github.com:name/app.git -b master git clone ${project_clone_repository} ${project_clone_directory} 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log echo_g \"git clone from $project_clone_repository successfully! \" # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd ${project_clone_directory} current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log else git checkout ${branch} 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log fi echo_b \"git pull from $project_clone_repository with branch or tag name $branch.\" git pull origin ${branch} 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log cd ${WORKDIR} echo_g \"git pull from $project_clone_repository with branch or tag name $branch successfully! \" else echo_b \"git pull from $project_clone_repository with branch or tag name $branch.\" cd ${project_clone_directory} current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log else git checkout ${branch} 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log fi git pull origin ${branch} 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log echo_g \"git pull from $project_clone_repository with branch or tag name $branch successfully! \" # TODO(Guodong Ding) get branch names or revision numbers from VCS data # git rev-parse HEAD # git rev-parse --verify HEAD # git rev-parse HEAD | cut -c1-10 # git show-ref # git for-each-ref # git log --pretty=format:'%h' -n 1 # git log -1 --format=\"%H\" # git rev-list --max-count=1 HEAD # git show --pretty=%h cd ${WORKDIR} fi set +o errexit echo } function maven_clean_package(){ echo_b \"Do mvn clean package java project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute mvn [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} mvn clean package 2>&1 | tee ${WORKDIR}/logs/mvn_clean_package_$(date +%Y%m%d%H%M).log retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"mvn clean package for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/logs/mvn_clean_package_$(date +%Y%m%d%H%M).log\" exit 1 else echo_g \"mvn clean package for ${project_clone_repository_name} successfully! \" fi # Make workable java servlet cp target/mscrm-service-1.0-SNAPSHOT.jar target/mscrm-service.jar cd ${WORKDIR} echo_g \"Do mvn clean package java project finished for ${project_clone_repository_name} with exit code 0! \" echo } # ssh_execute_command_on_remote_host hostname command function ssh_execute_command_on_remote_host(){ [ $# -ne 2 ] && return 1 ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"$2\" 2>&1 | tee ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"ssh execute command on remote host $2 failed! \" test -s ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log && echo_r \"\\tMore details refer to ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log\" return 1 else echo_g \"ssh execute command on remote host $2 successfully! \" return 0 fi } # scp_local_files_to_remote_host local_path remote_hostname remote_path function scp_local_files_to_remote_host(){ [ $# -ne 3 ] && return 1 [ ! -d $1 -a ! -f $1 ] && return 1 # check_ssh_can_be_connect $2 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp local files to remote host failed! \" echo_r \"scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1\" exit 1 else echo_g \"scp local files to remote host successfully! \" fi } # scp_remote_files_to_local_host remote_hostname remote_path local_path function scp_remote_files_to_local_host(){ [ $# -ne 3 ] && return 1 # check_ssh_can_be_connect $1 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp root@$1:$2 $3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp remote files to local host failed! \" exit 1 else echo_g \"scp remote files to local host successfully! \" fi } # function backup_remote_host_config_files(){ # TODO(Guodong Ding) did not throw a exception when first deploy and test -z \"$user_defined_project_conf_directory\" echo_b \"backup remote host config files...\" # backup operation only executed once time, using '$0 backup_manual' backup new configuration files. # if ${WORKDIR}/${user_defined_project_conf_directory} is not empty then return 0 to exit if [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ]; then [ -f ${WORKDIR}/${user_defined_project_conf_directory}.backup_operation_once.log ] && backup_operation=\"`cat ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log`\" echo_g \"Backup remote host config files operation had been done, $backup_operation, now skipping ... \" return 0 fi # TODO(Guodong Ding) if $user_defined_project_conf_directory is empty and remote host target directory is empty(first deploy), will cause exit with 1 ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"test \\\"\\$(ls -A $user_defined_project_top_directory_to_target_host 2>/dev/null)\\\"\" if test $? -eq 0; then scp_remote_files_to_local_host ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host}/* ${WORKDIR}/${user_defined_project_conf_directory} # get config files [ \"$(ls -A ${WORKDIR}/${user_defined_project_conf_directory})\" ] && find ${WORKDIR}/${user_defined_project_conf_directory}/. -type f ! -name . -a ! -name '*.xml*' -a ! -name '*.properties*' -a ! -name '*.version*' -exec rm -f -- '{}' \\; # remove empty directory, 'for + rmdir' find ${WORKDIR}/${user_defined_project_conf_directory}/. -empty -type d -delete # TODO(Guodong Ding) improvements here test ! -z ${user_defined_project_conf_directory} -a -d ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com && rm -rf ${WORKDIR}/${user_defined_project_conf_directory}/WEB-INF/classes/com echo_g \"backup remote host config files finished.\" echo \"`date +%Y%m%d`\" > ${WORKDIR}/${user_defined_project_conf_directory}/.backup_operation_once.log else echo_y \"This maybe first time to deploy or variable 'user_defined_project_conf_directory' is not defined! \" fi } function rollback_remote_host_config_files(){ echo_b \"rollback remote host config files...\" #scp_local_files_to_remote_host ${WORKDIR}/${user_defined_project_conf_directory} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} # override all configuration files to current \\cp -r ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} # TODO(Guodong Ding) if save remote host config files, if there are no changes on config files # some ops # TODO(Guodong Ding) improvements here echo_g \"rollback remote host config files finished.\" } function make_current_workable_source(){ # check a directories lock, Note: this is redundant if [[ ! -f ${WORKDIR}/.capistrano_ds_lock ]]; then make_capistrano_directory_structure fi clean_old_releases clean_old_logs # do dependencies checking if test ! -z ${user_defined_skip_check_network_and_resolver}; then echo_g \"skipping checking network connectivity and name resolve.\" else check_network_connectivity check_name_resolve fi check_other_dependencies # do core job # TODO(Guodong Ding) if we need a git_project_clone \"$user_defined_project_clone_depends\" here using auto judgment statement git_project_clone \"$user_defined_project_clone\" maven_clean_package \"$user_defined_project_clone\" cd ${WORKDIR} # links_target_directory_to_current # Make directory to release directory if test ! -d ${WORKDIR}/release -o ! -d ${WORKDIR}/share; then echo_r \"capistrano directory structure is broken, make sure the file .capistrano_ds_lock is deleted before a new deploy! \" # test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock exit 1 fi new_release_just_created=\"$WORKDIR/release/$(date +%Y%m%d%H%M%S)\" [ ! -d ${new_release_just_created} ] && mkdir ${new_release_just_created} # TODO(Guodong Ding) find more this foreseeable exception here if [ -d ${WORKDIR}/repository/${project_clone_repository_name}/target ]; then \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/target/* ${new_release_just_created} else echo_r \"A foreseeable error occurred, please alter to Developer & Administrator. \" exit 1 fi # Make source code symbolic link to current ( [ -f ${WORKDIR}/current ] || [ -d ${WORKDIR}/current ] ) && rm -rf ${WORKDIR}/current ln -s ${new_release_just_created} ${WORKDIR}/current # for some bash scripts in the ${WORKDIR}/current find ${WORKDIR}/current/ -type f -name \"*.sh\" -exec chmod +x '{}' \\; # Move conf and logs directives from release to share if found [ -d ${WORKDIR}/release/conf ] && mv ${WORKDIR}/release/conf ${WORKDIR}/share/conf [ -d ${WORKDIR}/release/logs ] && mv ${WORKDIR}/release/logs ${WORKDIR}/share/logs # Make conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current/conf [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current/logs } function restart_docker_container(){ echo_b \"Restarting docker container...\" [ $# -ne 2 ] && return 1 # TODO(Guodong Ding) if we need restart more related docker container local user_defined_docker_container_name=\"\" local remote_host_ip=\"\" test -n $1 && remote_host_ip=\"$1\" test -n $2 && user_defined_docker_container_name=\"$2\" ssh_execute_command_on_remote_host \"$remote_host_ip\" \"docker restart $user_defined_docker_container_name\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"restart docker container for $user_defined_docker_container_name on $remote_host_ip failed! \" exit 1 else echo_g \"restart docker container for $user_defined_docker_container_name on $remote_host_ip successfully! \" return 0 fi } # distribute current workable files to remote host function deploy() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_target_host_ip ...\" # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files # remove all file in remote host target directories and files, if target is not exist, then create it. ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"if test -d $user_defined_project_top_directory_to_target_host; then find -L $user_defined_project_top_directory_to_target_host -maxdepth 1 ! -name \"logs\" ! -wholename \"${user_defined_project_top_directory_to_target_host}\" -exec rm -rf {} \\; ; else mkdir -p $user_defined_project_top_directory_to_target_host; fi\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files # Start service or validate status on remote host if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh start\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy successfully for $user_defined_deploy_target_host_ip! \" echo_g \"Current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" else echo_r \"Error: Deploy failed! \" ${WORKDIR}/`basename $0` rollback fi } # Rollback to last right configuration function rollback() { echo_b \"Rollback to last right configuration... \" # The key point is find last files which can work if [[ -f ${WORKDIR}/share/workable_program.log ]]; then WORKABLE_PROGRAM=`cat ${WORKDIR}/share/workable_program.log` else echo_r \"Error: Can NOT find workable release version log file! Please consider to retry with 'rollback_manual'\" exit 1 fi if [[ -z ${WORKABLE_PROGRAM} ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # Stop service if we have if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh stop\" fi # Remove failed deploy rm -rf ${WORKDIR}/current # Remake source code symbolic link to current ln -s ${WORKABLE_PROGRAM} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current # backup remote host config files [ ! -z ${user_defined_project_conf_directory} ] && backup_remote_host_config_files saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # rollback remote host config files [ -z ${user_defined_project_conf_directory} ] && rollback_remote_host_config_files if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} fi # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $WORKABLE_PROGRAM\" fi } # rollback to any workable version which user wished by manually function rollback_manual(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something go wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # Alternative implementation: ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | sed -n '1,4p' ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | head -n4 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do # TODO(Guodong Ding) scp timeout scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # Start service or validate status if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then # ${WORKDIR}/current/bin/startup.sh restart ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh restart\" RETVAL=$? else test -z ${user_defined_docker_container_name} || restart_docker_container ${user_defined_deploy_target_host_ip} ${user_defined_docker_container_name} # TODO(Guodong Ding) external health check RETVAL=$? fi # if started ok, then create a workable program to a file if [[ ${RETVAL} -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof fi else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } function destroy() { # echo a Warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" user_input_answer_want_do_destroy=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" user_input_answer_want_do_destroy case \"$user_input_answer_want_do_destroy\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"filename\" | xargs rm -rf find -L ${WORKDIR} -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf '{}' \\; if [ $? -eq 0 ];then test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } function usage(){ cat - << eof ${WORKDIR}/`basename $0` deploy new deploy/ update one remote target host ${WORKDIR}/`basename $0` rollback_manual rollback to any workable version to one remote target host by manual eof } function main(){ lock_filename=\"lock_$$_${RANDOM}\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` [ -n \"$header\" ] && echo \"$header\" if [[ $# -lt 1 ]]; then ${WORKDIR}/`basename $0` help exit 0 fi case $1 in deploy) deployment_mode=\"1\" deploy ;; rollback) rollback ;; rollback_manual) rollback_manual ;; destroy) destroy ;; help|*) usage exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_444.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\autodeployOps\\VersionRelease\\file_444.sh",
            "content": "#!/bin/bash # Name: release_vux2_frontend.sh # Execute this shell script to deploy vux2 project(frontend, web static file) built by npm automatically on remote hosts. # debug option DEBUG=false #DEBUG=true if ${DEBUG} ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi # define user friendly messages header=\" Function: Execute this shell script to deploy vux2 project(frontend, web static file) built by npm automatically on remote hosts. License: Open source software \" # set an empty function using for location this line quickly in PyCharm editor on purpose. function _empty() { return; } # user defined variables # Where to get source code user_defined_project_clone=\"ssh://git@git.example.com:18082/sino-agri/mscrm-front.git\" user_defined_project_clone_branch_or_tag=\"develop-vux2\" # this parameter can be replaced by option -b <branch name> or -t <tag name> user_defined_deploy_target_host_ip=\"10.6.28.46\" # this is a mandatory field, and must be same as the first ip in $user_defined_deploy_targets_host_ip_list user_defined_project_top_directory_to_target_host=\"/data/docker/mscrm-front/htdocs\" user_defined_docker_container_name=\"\" # if you using a docker container other than a startup script located in sourcecode/bin/startup.sh, then set this to docker container name user_defined_project_conf_directory=\"config_backup\" # if you do NOT want to use configurations from deploy target, you should set this variable to where pointed to config files user_defined_skip_check_network_and_resolver=\"true\" # if system administrator disable ICMP protocol, set this any content but not null # Setting how many days do you want save old releases, default is 10 days save_old_releases_for_days=10 save_old_releases_for_numbers=10 # default branch or tag name for project to clone branch_or_tag=${user_defined_project_clone_branch_or_tag} # end define variables ## load user defined variables from file ## Where to get source code ## TODO(Guodong Ding) using with `basename $0` #if test -f deploy_conf ; then # source deploy_conf #else # echo \"Fatal error: can NOT found file: deploy_conf \" # exit 1 #fi ## end define variables from file # pretreatment predefined variables # TODO(Guodong Ding) project_clone_target_depends_1 is not used for git clone because git has done for us project_clone_target=\"`echo ${user_defined_project_clone} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_repository_name=${project_clone_target} deployment_mode=\"\" # end pretreatment predefined variables # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi function command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } function check_command_can_be_execute(){ [ $# -ne 1 ] && return 1 command_exists $1 } function check_network_connectivity(){ echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ] ; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null;then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once time! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 $(ip route | awk '/default/ {print $3}') >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" echo fi } function check_name_resolve(){ echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"`md5sum /etc/resolv.conf | awk '{ print $1 }'`\" if test ${eval_md5sum_of_nameserver_config} = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf /etc/resolv.conf_$(date +%Y%m%d%H%M%S)~ cat >/etc/resolv.conf<<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" echo return 0 fi } function check_ssh_can_be_connect(){ [ $# -ne 1 ] && return 1 echo_b \"Check if can ssh to remote host $1 ... \" check_command_can_be_execute ssh || return 1 # TODO(Guodong Ding) ssh can connect to remote host by using /etc/ssh/ssh_host_rsa_key or ~/.ssh/id_rsa ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"uname -a >/dev/null 2>&1\" retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"Check ssh to remote host $1 failed! \" exit 1 else echo_g \"Check ssh to remote host $1 successfully! \" fi } function check_other_dependencies() { echo_b \"Checking other dependencies for deploy procedure... \" echo_b \"\\tChecking user customized variables...\" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z ${user_defined_project_clone} ]]; then echo_r \"Error: user_defined_project_clone is undefined! \" exit 1 fi if [[ -z ${user_defined_project_top_directory_to_target_host} ]]; then echo_r \"Error: user_defined_project_top_directory_to_target_host is undefined! \" exit 1 fi if test -z ${user_defined_project_conf_directory}; then # TODO(Guodong Ding) check directory if exist if test -d ${WORKDIR}/${user_defined_project_conf_directory}; then echo_y \"Warning: ${WORKDIR}/${user_defined_project_conf_directory} is not exist!\" fi echo_y \"Warning: user defined project conf directory is not defined! \" fi echo_g \"\\tChecking user customized and defined variables passed! \" echo_b \"\\tChecking disk space available...\" disk_space_available=`df ${WORKDIR} | tail -n1 | awk '{print $(NF-2)}'` if [[ ${disk_space_available} -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 else echo_g \"\\tChecking disk space available passed! \" fi echo_g \"All required dependencies check passed! \" echo } function make_capistrano_directory_structure() { set -o errexit if [ -f ${WORKDIR}/.capistrano_ds_lock ];then echo_g \"Set directory structure has been done, skipping. \" return fi echo_b \"Setting directory structure... \" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branch names or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy [ ! -d ${WORKDIR}/release ] && mkdir ${WORKDIR}/release [ ! -d ${WORKDIR}/repository ] && mkdir ${WORKDIR}/repository [ ! -d ${WORKDIR}/share ] && mkdir ${WORKDIR}/share # end directories structure # Additional directories structure for full deploy operation # for backup remote host config file [ ! -d ${WORKDIR}/${user_defined_project_conf_directory} ] && mkdir ${WORKDIR}/${user_defined_project_conf_directory} # deploy logs for git/npm/ssh [ ! -d ${WORKDIR}/logs ] && mkdir ${WORKDIR}/logs # set a directories structure lock touch ${WORKDIR}/.capistrano_ds_lock echo_g \"Set directory structure successfully! \" echo set +o errexit } function clean_old_releases(){ echo_b \"Clean old releases... \" num_save=${save_old_releases_for_numbers:-10} files_ops=${WORKDIR}/release num_files=$(find ${files_ops} -maxdepth 1 -type d -a ! -wholename \".\" -a ! -wholename \"..\" -a ! -wholename \"$files_ops\" -printf \"%C@ %p\\n\" | sort -n | wc -l) if test ${num_files} -gt ${num_save};then echo_c \"Extra releases found and will be removed from project! \" num_ops=$(expr ${num_files} - ${num_save}) list_ops=$(find ${files_ops} -maxdepth 1 -type d -a ! -wholename \".\" -a ! -wholename \"..\" -a ! -wholename \"$files_ops\" -printf \"%C@ %p\\n\" | sort -n | head -n${num_ops} | awk -F '[ ]+' '{print $2}') # IFS=' '$'\\t'$'\\n', If IFS is unset, or its value is exactly <space><tab><newline> old_IFS=$IFS IFS=' '$'\\t'$'\\n' for file_ops in ${list_ops};do test -d ${file_ops} && rm -rf ${file_ops} done IFS=\"$old_IFS\" echo_g \"Extra releases have been removed from project! \" else echo_g \"All releases are essential, skipping. \" fi echo } function clean_old_logs(){ echo_b \"Clean old logs... \" save_days=${save_old_releases_for_days:-10} need_clean=$(find ${WORKDIR}/logs -name \"*.log\" -mtime +${save_days} -exec ls '{}' \\; | wc -l) if [ ${need_clean} -gt 0 ]; then echo_c \"Expired releases found and will be removed from project! \" find -L ${WORKDIR}/logs -maxdepth 1 -name \"*.log\" -a ! -name \"^.\" -mtime +${save_days} -exec rm -rf '{}' \\; >/dev/null 2>&1 if [ $? -eq 0 ]; then echo_g \"Expired logs have removed from project! \" else echo_r \"Can NOT remove expired logs, please feel free to alter to administrators. \" fi else echo_g \"All logs are not expired, skipping. \" fi echo } # git_project_clone repository branch function git_project_clone(){ set -o errexit [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} # TODO(Guodong Ding) let user set this variable(\"branch\") # Note: branch is equal to tag, so using tag as branch or using branch as a tag if [[ \"x$branch_or_tag\" != \"x\" ]]; then branch=${branch_or_tag} else branch=\"\" fi if test -n \"$2\"; then branch=\"$2\" fi if [[ \"x$branch\" == \"x\" ]]; then echo_r \"get branch name or tag name failed!\" exit 1 fi if test ! -d ${project_clone_directory}; then echo_b \"git clone from $project_clone_repository\" # git clone git@github.com:name/app.git -b master git clone ${project_clone_repository} ${project_clone_directory} 2>&1 | tee -a ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log echo_g \"git clone from $project_clone_repository successfully! \" # TODO(Guodong Ding) get branch names or revision numbers from VCS data cd ${project_clone_directory} current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log else git checkout ${branch} 2>&1 | tee -a ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log fi echo_b \"git pull from $project_clone_repository with branch or tag name $branch.\" git pull origin ${branch} 2>&1 | tee -a ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log cd ${WORKDIR} echo_g \"git pull from $project_clone_repository with branch or tag name $branch successfully! \" else echo_b \"git pull from $project_clone_repository with branch or tag name $branch.\" cd ${project_clone_directory} current_branch_name=\"`git rev-parse --abbrev-ref HEAD`\" if test \"$current_branch_name\" == \"$branch\"; then git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log else git checkout ${branch} 2>&1 | tee -a ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log git status 2>&1 | tee ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log fi git pull origin ${branch} 2>&1 | tee -a ${WORKDIR}/logs/git_$(date +%Y%m%d%H%M).log echo_g \"git pull from $project_clone_repository with branch or tag name $branch successfully! \" # TODO(Guodong Ding) get branch names or revision numbers from VCS data # git rev-parse HEAD # git rev-parse --verify HEAD # git rev-parse HEAD | cut -c1-10 # git show-ref # git for-each-ref # git log --pretty=format:'%h' -n 1 # git log -1 --format=\"%H\" # git rev-list --max-count=1 HEAD # git show --pretty=%h cd ${WORKDIR} fi echo set +o errexit } function npm_install(){ echo_b \"Do npm install vux2 project... \" check_command_can_be_execute cnpm [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} cnpm install 2>&1 | tee -a ${WORKDIR}/logs/npm_install_$(date +%Y%m%d%H%M).log retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"npm install failed! More details refer to $WORKDIR/logs/npm_install_$(date +%Y%m%d%H%M).log\" exit 1 else cd ${WORKDIR} echo_g \"Do npm install vux2 project finished for $project_clone_repository_name with exit code $retval. \" echo fi } function npm_build_project(){ echo_b \"Do npm build vux2 project for `echo $1 | awk -F '[/.]+' '{ print $(NF-1)}'`... \" check_command_can_be_execute cnpm [ $# -ge 1 ] && project_clone_repository=\"$1\" project_clone_repository_name=\"`echo ${project_clone_repository} | awk -F '[/.]+' '{ print $(NF-1)}'`\" project_clone_directory=${WORKDIR}/repository/${project_clone_repository_name} cd ${project_clone_directory} cnpm run build 2>&1 | tee -a ${WORKDIR}/logs/npm_build_$(date +%Y%m%d%H%M).log retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"npm run build for ${project_clone_repository_name} failed! More details refer to ${WORKDIR}/logs/npm_build_$(date +%Y%m%d%H%M).log\" exit 1 else cd ${WORKDIR} echo_g \"Do npm run build project finished for ${project_clone_repository_name} with exit code $retval. \" echo fi } # ssh_execute_command_on_remote_host hostname command function ssh_execute_command_on_remote_host(){ [ $# -ne 2 ] && return 1 ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no root@$1 \"$2\" 2>&1 | tee -a ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"ssh execute command on remote host $2 failed! \" test -s ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log && echo_r \"\\tMore details refer to ${WORKDIR}/logs/ssh_command_$(date +%Y%m%d).log\" return 1 else echo_g \"ssh execute command on remote host $2 successfully! \" return 0 fi } # scp_local_files_to_remote_host local_path remote_hostname remote_path function scp_local_files_to_remote_host(){ [ $# -ne 3 ] && return 1 [ ! -d $1 -a ! -f $1 ] && return 1 # check_ssh_can_be_connect $2 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp local files to remote host failed! \" echo_r \"scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp $1 root@$2:$3 >/dev/null 2>&1\" exit 1 else echo_g \"scp local files to remote host successfully! \" fi } # scp_remote_files_to_local_host remote_hostname remote_path local_path function scp_remote_files_to_local_host(){ [ $# -ne 3 ] && return 1 # check_ssh_can_be_connect $1 scp -i /etc/ssh/ssh_host_rsa_key -P 22 -oStrictHostKeyChecking=no -rp root@$1:$2 $3 >/dev/null 2>&1 retval=$? if [ ${retval} -ne 0 ] ; then echo_r \"scp remote files to local host failed! \" exit 1 else echo_g \"scp remote files to local host successfully! \" fi } function make_current_workable_source(){ # check a directories lock, Note: this is redundant if [[ ! -f ${WORKDIR}/.capistrano_ds_lock ]]; then make_capistrano_directory_structure fi clean_old_releases clean_old_logs # do dependencies checking if test ! -z ${user_defined_skip_check_network_and_resolver}; then echo_g \"skipping checking network connectivity and name resolve.\" else check_network_connectivity check_name_resolve fi check_other_dependencies # do core job # TODO(Guodong Ding) if we need a git_project_clone \"$user_defined_project_clone_depends\" here using auto judgment statement git_project_clone \"$user_defined_project_clone\" npm_install npm_build_project \"$user_defined_project_clone\" cd ${WORKDIR} # links_target_directory_to_current # Make directory to release directory if test ! -d ${WORKDIR}/release -o ! -d ${WORKDIR}/share; then echo_r \"capistrano directory structure is broken, make sure the file .capistrano_ds_lock is deleted before a new deploy! \" # test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock exit 1 fi new_release_just_created=\"$WORKDIR/release/$(date +%Y%m%d%H%M%S)\" [ ! -d ${new_release_just_created} ] && mkdir ${new_release_just_created} # TODO(Guodong Ding) find more this foreseeable exception here if [ -d ${WORKDIR}/repository/${project_clone_repository_name}/dist ]; then \\cp -rf ${WORKDIR}/repository/${project_clone_repository_name}/dist/* ${new_release_just_created} else echo_r \"A foreseeable error occurred, please alter to Developer & Administrator. \" exit 1 fi # Make source code symbolic link to current ( [ -f ${WORKDIR}/current ] || [ -d ${WORKDIR}/current ] ) && rm -rf ${WORKDIR}/current ln -s ${new_release_just_created} ${WORKDIR}/current # for some bash scripts in the ${WORKDIR}/current find ${WORKDIR}/current/ -type f -name \"*.sh\" -exec chmod +x '{}' \\; # Move conf and logs directives from release to share if found [ -d ${WORKDIR}/release/conf ] && mv ${WORKDIR}/release/conf ${WORKDIR}/share/conf [ -d ${WORKDIR}/release/logs ] && mv ${WORKDIR}/release/logs ${WORKDIR}/share/logs # Make conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current/conf [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current/logs } # distribute current workable files to remote host function deploy() { # do make_current_workable_source before deploy every time make_current_workable_source echo_b \"Do deploy on $user_defined_deploy_target_host_ip ...\" # remove all file in remote host target directories and files, if target is not exist, then create it. ssh_execute_command_on_remote_host \"$user_defined_deploy_target_host_ip\" \"if test -d $user_defined_project_top_directory_to_target_host; then find -L $user_defined_project_top_directory_to_target_host -maxdepth 1 ! -name \"logs\" ! -wholename \"${user_defined_project_top_directory_to_target_host}\" -exec rm -rf {} \\; ; else mkdir -p $user_defined_project_top_directory_to_target_host; fi\" saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >${WORKDIR}/share/workable_program.log <<eof ${new_release_just_created} eof echo_g \"Deploy successfully for $user_defined_deploy_target_host_ip! \" echo_g \"Current workable version is $(cat ${WORKDIR}/share/workable_program.log)\" } # Rollback to last right configuration function rollback() { echo_b \"Rollback to last right configuration... \" # The key point is find last files which can work if [[ -f ${WORKDIR}/share/workable_program.log ]]; then WORKABLE_PROGRAM=`cat ${WORKDIR}/share/workable_program.log` else echo_r \"Error: Can NOT find workable release version log file! Please consider to retry with 'rollback_manual'\" exit 1 fi if [[ -z ${WORKABLE_PROGRAM} ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # Stop service if we have if [[ -e ${WORKDIR}/current/bin/startup.sh ]]; then ssh_execute_command_on_remote_host ${user_defined_deploy_target_host_ip} \"$user_defined_project_top_directory_to_target_host/bin/startup.sh stop\" fi # Remove failed deploy rm -rf ${WORKDIR}/current # Remake source code symbolic link to current ln -s ${WORKABLE_PROGRAM} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} echo_g \"Rollback successfully! \" } # rollback to any workable version which user wished by manually function rollback_manual(){ echo_b \"This function will rollback to any workable version which user wished by manually.\" # TODO(Guodong Ding) linux shell trap command several ctrl+c echo_p \"Enter 'reset' command to reset terminal when something go wrong.\" read -e -s -n 1 -p \"Press any key to continue or Press 'Ctrl+C' exit.\" if test -d ${WORKDIR}/release -a \"$(ls -A ${WORKDIR}/release 2>/dev/null)\" ;then # judge a directory if is empty echo_b \"Current workable releases( Latest 5 ) are here: \" # Alternative implementation: ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | sed -n '1,4p' ls -u -1 -d ${WORKDIR}/release/* | tail -n6 | head -n4 read -p \"Which release do you want rollback? Press Enter after input. \" user_input_release_to_rollback if test -d ${user_input_release_to_rollback}; then rm -rf ${WORKDIR}/current ln -s ${user_input_release_to_rollback} ${WORKDIR}/current # Remake conf and logs symbolic link to current [ -d ${WORKDIR}/share/conf ] && ln -s ${WORKDIR}/share/conf ${WORKDIR}/current [ -d ${WORKDIR}/share/logs ] && ln -s ${WORKDIR}/share/logs ${WORKDIR}/current if test ! -z \"${user_defined_project_conf_directory}\" -a -d ${WORKDIR}/${user_defined_project_conf_directory}; then saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/${user_defined_project_conf_directory}/*;do \\cp -rf ${file} ${WORKDIR}/current done cd ${WORKDIR} IFS=${saved_IFS} fi saved_IFS=$IFS IFS=' ' cd ${WORKDIR}/current for file in ${WORKDIR}/current/*;do # TODO(Guodong Ding) scp timeout scp_local_files_to_remote_host ${file} ${user_defined_deploy_target_host_ip} ${user_defined_project_top_directory_to_target_host} done cd ${WORKDIR} IFS=${saved_IFS} echo_g \"Rollback successfully! \" echo_g \"current workable version is $user_input_release_to_rollback\" cat >${WORKDIR}/share/workable_program.log <<eof ${user_input_release_to_rollback} eof else echo_r \"The release you want to rollback is not present, Please try again! \" fi else echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi } function destroy() { # echo a Warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" user_input_answer_want_do_destroy=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" user_input_answer_want_do_destroy case \"$user_input_answer_want_do_destroy\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"filename\" | xargs rm -rf find -L ${WORKDIR} -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf '{}' \\; if [ $? -eq 0 ];then test -f ${WORKDIR}/.capistrano_ds_lock && \\rm -rf ${WORKDIR}/.capistrano_ds_lock echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } function usage(){ cat - << eof ${WORKDIR}/`basename $0` deploy new deploy/ update one remote target host ${WORKDIR}/`basename $0` rollback_manual rollback to any workable version to one remote target host by manual eof } function main(){ lock_filename=\"lock_$$_${RANDOM}\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` [ -n \"$header\" ] && echo \"$header\" if [[ $# -lt 1 ]]; then ${WORKDIR}/`basename $0` help exit 0 fi case $1 in deploy) deployment_mode=\"1\" deploy ;; rollback) rollback ;; rollback_manual) rollback_manual ;; destroy) destroy ;; help|*) usage exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_445.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\backupOps\\FileSystem\\file_445.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File Name: LinuxBashShellScriptForOps:backup-remote-files-to-local.sh # Version: 0.0.1 # Author: dgden # Author Email: dgdenterprise@gmail.com # URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps # Download URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps/tarball/master # Create Date: 2019/6/26 # Create Time: 16:40 # Description: rsync remote files to local # Long Description: # Usage: 30 21 * * * /root/backup-gitlab-repos.sh >>/tmp/backup-gitlab-repos.log # References: # Prerequisites: [] # Development Status: 3 - Alpha, 5 - Production/Stable # Environment: Console # Intended Audience: System Administrators, Developers, End Users/Desktop # License: Freeware, Freely Distributable # Natural Language: English, Chinese (Simplified) # Operating System: POSIX :: Linux # Programming Language: GNU bash :: 4+ # Topic: Utilities # remote host setting backup_host=\"10.27.15.12\" backup_ssh_port=22 backup_ssh_user=\"root\" backup_ssh_private_key=\"$HOME/.ssh/id_rsa\" backup_data_dir=\"/data\" backup_data_dirname=\"gitlab_repos\" backup_log=\"/tmp/backupGitLabByClone.log\" # local host setting local_data_dir=\"/data/backup/gitlab_repos\" RSYNC_LOG_FILE=\"/tmp/gitlab_repos_rsync.log\" save_days=5 function run() { SSH_OPTION=\"-oStrictHostKeyChecking=no\" # ssh ${SSH_OPTION} -p ${backup_ssh_port} -i \"${backup_ssh_private_key}\" ${backup_ssh_user}@${backup_host} bash -c \\\"$*\\\" ssh ${SSH_OPTION} -p ${backup_ssh_port} -i \"${backup_ssh_private_key}\" ${backup_ssh_user}@${backup_host} \"$*\" } function is_backup_finished(){ is_backup_finished=1 max_try_times=6 goon=1 while test ${goon} -eq 1; do is_all_true=0 for _ in $(seq ${max_try_times}); do md5sum_1=$(run md5sum ${backup_log}) sleep 5 md5sum_2=$(run md5sum ${backup_log}) if test \"${md5sum_1}\" == \"${md5sum_2}\"; then is_all_true=$((is_all_true + 1)) is_backup_finished=0 fi done if test ${is_all_true} -eq ${max_try_times}; then goon=0 else continue fi done return ${is_backup_finished} } function do_archive_files(){ run \"cd ${backup_data_dir} && tar zcfP ${backup_data_dirname}.tgz ${backup_data_dirname}\" } function do_rm_archive_files(){ run \"cd ${backup_data_dir} && rm -f ${backup_data_dirname}.tgz\" } function do_clean_local_files(){ find ${local_data_dir} -mtime +${save_days} -exec rm -rf '{}' \\; } echo \"$(date +%s) check backup finished or not ...\" is_backup_finished res=$? if test ${res} -eq 0 ; then echo \"$(date +%s) archive backup files ...\" do_archive_files else echo \"ERR: transfer remote files to local failed, please transfer by manual after few minutes or change crontab job\" fi echo \"$(date +%s) rsync remote files to local ...\" test ! -d ${local_data_dir}/\"$(date -I)\" && mkdir -p ${local_data_dir}/\"$(date -I)\" rsync -azurR \\ -e \"ssh ${SSH_OPTION}\" \\ --delete --delete-excluded \\ --log-file=${RSYNC_LOG_FILE} \\ ${backup_ssh_user}@${backup_host}:${backup_data_dir}/${backup_data_dirname}.tgz ${local_data_dir}/\"$(date -I)\" res=$? if test ${res} -ne 0 ; then echo \"ERR: rsync failed\" fi echo \"$(date +%s) remove used archived files ...\" do_rm_archive_files echo \"$(date +%s) clean old backups in local ...\" do_clean_local_files echo \"$(date +%s) SUCCESS\""
        },
        {
            "filename": "file_446.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\backupOps\\FileSystem\\file_446.sh",
            "content": "#!/bin/bash # Created by PyCharm. # File Name: LinuxBashShellScriptForOps:backupFilesUsingInotifyAndRsync.sh # Version: 0.0.1 # Author: Guodong # Author Email: dgdenterprise@gmail.com # URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps # Download URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps/tarball/master # Create Date: 2018/4/9 # Create Time: 15:14 # Description: backup files using inotify-tools and rsync # Long Description: If there are a lot of files to rsync, more CPU and memory is required, CPU is sensitive # In this case, I think use \"rsync + crontab\" is better than \"inotify + rsync\" # Before use this script, you should run rsync singly in console to check system load. # Usage: nohup bash ./backupFilesUsingInotifyAndRsync.sh >/dev/null 2>&1 & # References: # Prerequisites: [] # Development Status: 3 - Alpha, 5 - Production/Stable # Environment: Console # Intended Audience: System Administrators, Developers, End Users/Desktop # License: Freeware, Freely Distributable # Natural Language: English, Chinese (Simplified) # Operating System: POSIX :: Linux # Topic: Utilities # setting ################ HOST=\"192.168.88.151\" SRC=\"/data\" DEST=\"/data/backup/from_$HOSTNAME\" USER=\"root\" SSH_OPTION=\"-p 22 -oStrictHostKeyChecking=no\" RSYNC_LOG_FILE=\"/tmp/rsync.log\" ################ if test ${UID} -ne 0; then echo \"ROOT ACCESS IS REQUIRED\" echo \"Only root can do that, but current user is '$USER', please use 'sudo $0' or run as root\" exit 1 fi ssh \"${SSH_OPTION}\" ${USER}@${HOST} \"mkdir -p ${DEST}\" # run once time via check if log file exist test -f ${RSYNC_LOG_FILE} || /usr/bin/rsync -azurR \\ -e \"ssh ${SSH_OPTION}\" \\ --delete --delete-excluded \\ --log-file=${RSYNC_LOG_FILE} \\ ${SRC} ${USER}@${HOST}:\"${DEST}\" # fs.inotify.max_user_watches = 8192 sysctl -w fs.inotify.max_user_watches=999999 # echo 999999 > /proc/sys/fs/inotify/max_user_watches /usr/bin/inotifywait \\ -mrq \\ --format '%w%f' \\ -e modify,delete,create,attrib \\ ${SRC} \\ | while read -r file; do test -e \"${file}\" && /usr/bin/rsync -azurR \\ -e \"ssh ${SSH_OPTION}\" \\ --delete --delete-excluded \\ --log-file=${RSYNC_LOG_FILE} \\ \"${file}\" ${USER}@${HOST}:\"${DEST}\" done"
        },
        {
            "filename": "file_447.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\backupOps\\FileSystem\\file_447.sh",
            "content": "#!/usr/bin/env bash # Function description: # Backup filesystem using rsync # Usage: # bash backup.sh # Birth Time: # 2016-07-15 16:13:43.895515929 +0800 # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong # Others: # crontabs -- configuration and scripts for running periodical jobs # SHELL=/bin/bash # PATH=/sbin:/bin:/usr/sbin:/usr/bin # MAILTO=root # HOME=/ # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed # m h dom mon dow command # execute on 11:59 per sunday # 59 11 * * */0 bash /path/to/backup.sh >/tmp/log_backup_fs_crontab_$(date +\"\\%Y\\%m\\%d\\%H\\%M\\%S\").log # or # execute on 23:59 per day # 59 23 * * * bash /path/to/backup.sh >/tmp/log_backup_fs_crontab_$(date +\"\\%Y\\%m\\%d\\%H\\%M\\%S\").log USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi old_PATH=$PATH declare -x PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\" # Snapshot backup script # Refer: https://github.com/gregrs-uk/snapshot-backup/ # directories to backup, separated by spaces datadir_to_backup=\"/data/docker\" # backup location on remote server # This path should not contain spaces, even if they are escaped remote_destination=\"/data/backup/filesystem/10.6.28.135\" # ssh login to remote server backup_server=\"root@10.6.28.28\" # set ssh options for backup server ssh_option=\"-i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no\" # log dir on local machine #log_directory=\"/tmp/backup-filesystem-10.6.28.135\" log_directory=\"/tmp/\" # exclude file on local machine exclude=\"\" # ------ END OF CONFIGURATION VARIABLES ------ # the following two variables should not need modification datetime=`date +%Y%m%d%H%M%S` date=`date +%Y%m%d` # set log_directory for local backup logs test -d ${log_directory} || mkdir -p ${log_directory} # check directories exist and are accessible ssh ${ssh_option} ${backup_server} \"test -e $remote_destination || mkdir -p $remote_destination\" # make directory for this snapshot ssh ${ssh_option} ${backup_server} \"mkdir $remote_destination/$datetime-incomplete\" || { echo \"Could not create snapshot directory\"; exit 1; } # Refer: #rsync -u -r -v -e ssh --progress --delete --chmod=D775 /path/to/documents/* your_server_name@your_domain:~/public_html/documents/ --exclude=.htaccess --exclude=.htaccess~ #rsync -azurR -e \"ssh -i /etc/ssh/ssh_host_rsa_key -p 22 -oStrictHostKeyChecking=no\" --log-file=/tmp/rsync.log --delete --delete-excluded testdir 10.6.28.28:/data/backup/filesystem/10.6.28.135 # do the rsync # -a, --archive archive mode; equals -rlptgoD (no -H,-A,-X) # -r, --recursive recurse into directories # -R, --relative use relative path names # -u, --update skip files that are newer on the receiver # -z, --compress compress file data during the transfer rsync -azurR \\ -e \"ssh $ssh_option\" \\ --log-file=${log_directory}/backup_filesystem_rsync_${datetime}.log \\ --delete --delete-excluded \\ ${datadir_to_backup} \\ ${backup_server}:${remote_destination}/${datetime}-incomplete/ # change name of directory once rsync is complete ssh ${ssh_option} ${backup_server} \"mv $remote_destination/$datetime-incomplete $remote_destination/$datetime\" || { echo \"Could not rename directory after rsync\"; exit 1; } # link current to this backup ssh ${ssh_option} ${backup_server} \"test ! -d $remote_destination/current || rm -f $remote_destination/current\" || { echo \"Could not remove current backup link\"; exit 1; } ssh ${ssh_option} ${backup_server} \"ln -s $remote_destination/$datetime $remote_destination/current\" || { echo \"Could not create current backup link\"; exit 1; } # remove backups older than 10 days ssh ${ssh_option} ${backup_server} \"find $remote_destination/* -maxdepth 0 -type d -mtime +10 -exec rm -rf {} \\;\" || { echo \"Could not remove old backups\"; exit 1; } # remove local log files older than 10 days find ${log_directory}/* -maxdepth 0 -type f -name *.log -mtime +10 -exec rm -rf '{}' \\; || { echo \"Could not remove old log files\"; exit 1; } declare -x PATH=${old_PATH}"
        },
        {
            "filename": "file_448.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\backupOps\\MySQL\\file_448.sh",
            "content": "#!/usr/bin/env bash # Function description: # Backup MySQL databases for each, backup schema and schema with data in one action. # Usage: # bash backup-mysql-using-mysqldump.sh # Birth Time: # 2020-06-29 18:02:43.895515929 +0800 # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong # Others: # crontabs -- configuration and scripts for running periodical jobs # SHELL=/bin/bash # PATH=/sbin:/bin:/usr/sbin:/usr/bin # MAILTO=root # HOME=/ # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed # m h dom mon dow command # execute on 11:59 per sunday # 59 11 * * */0 /path/to/BackupMysqlByDate.sh >/tmp/log_backup_mysql_$(date +\"\\%Y\\%m\\%d\\%H\\%M\\%S\").log # or # execute on 23:59 per day # 59 23 * * * /path/to/BackupMysqlByDate.sh >/tmp/log_backup_mysql_$(date +\"\\%Y\\%m\\%d\\%H\\%M\\%S\").log USER=\"$(id -un)\" LOGNAME=\"$USER\" if [[ ${UID} -ne 0 ]]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi old_PATH=$PATH declare -x PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\" using_socket=true # change this on demand mysql_host=127.0.0.1 mysql_port=3306 mysql_username=root mysql_password=dev mysql_socket_file=/var/run/mysqld/mysqld.sock mysql_backup_remote=false mysql_basedir=/var/lib/mysql save_old_backups_for_days=5 mysql_bin_mysql=/usr/bin/mysql mysql_bin_mysqldump=/usr/bin/mysqldump mysql_backup_dir=/backup/db/mysql date_format_type_dir=$(date +%Y-%m-%d) date_format_type_file=$(date +%Y%m%d%H%M%S) # TODO(DingGuodong) we can send backups to oss(object store service) # do this ONLY once lock_file=$mysql_basedir/.backup_lock_file # do NOT set to $DEST, make sure $DEST (backup disk) exist if [[ ! -f $lock_file ]]; then mkdir -p $mysql_backup_dir touch $lock_file fi test ! -d $mysql_backup_dir && echo \"backup dir not exist, disk is down? exit now.\" && exit 1 echo \"------------------------------------------------------------------------\" echo \"=> do backup scheduler start at $(date +%Y%m%d%H%M%S)\" # TODO, check user privileges # check user if have 'RELOAD,EVENT' privileges,etc # backup role # GRANT ALTER,ALTER ROUTINE,CREATE,CREATE ROUTINE,CREATE TEMPORARY TABLES,CREATE VIEW,DELETE,DROP,EXECUTE,INDEX,INSERT,LOCK TABLES,SELECT,UPDATE,SHOW VIEW,RELOAD,EVENT ON *.* TO 'dev'@\"%\"; # FLUSH PRIVILEGES; [[ -d ${mysql_basedir} ]] && mysql_datadir=${mysql_basedir}/data || mysql_datadir=\"/var/lib/mysql\" [[ -x ${mysql_bin_mysql} ]] || mysql_bin_mysql=\"mysql\" [[ -x ${mysql_bin_mysqldump} ]] || mysql_bin_mysqldump=\"mysqldump\" if [[ ! -d ${mysql_datadir} ]]; then mysql_datadir=\"/var/lib/mysql\" # in case basedir is right, but datadir is wrong if [[ ! -d ${mysql_datadir} ]]; then echo \"WARNING: mysql datadir is not standard(this maybe a mistake) or mysql server is not installed on local filesystem.\" fi fi if [[ ! -x ${mysql_bin_mysql} ]]; then echo \"mysql: command not found \" exit 1 fi if [[ ! -x ${mysql_bin_mysqldump} ]]; then echo \"mysqldump: command not found \" exit 1 fi if [ $using_socket == \"true\" ]; then if [ ! -S $mysql_socket_file ]; then echo \"ERROR 2002 (HY000): Can't connect to local MySQL server through socket '$mysql_socket_file' (2)\" exit 1 fi mysqldump_option_auth=\"-u${mysql_username} -S${mysql_socket_file}\" else # --host=${mysql_host} --port=${mysql_port} --user=${mysql_username} --password=${mysql_password} mysqldump_option_auth=\"-h${mysql_host} -P${mysql_port} -u${mysql_username} -p${mysql_password}\" fi [[ -d ${mysql_backup_dir}/${date_format_type_dir} ]] || mkdir -p \"${mysql_backup_dir}/${date_format_type_dir}\" mysql_databases_list=\"\" if [[ -d ${mysql_datadir} ]] || [[ \"x${mysql_backup_remote}\" != \"xtrue\" ]]; then # mysql_databases_list=$(find /var/lib/mysql -maxdepth 1 -type d -exec basename {} \\; | sort | uniq) mysql_databases_list=$(find /var/lib/mysql -mindepth 1 -maxdepth 1 -type d -exec basename {} \\;) else # shellcheck disable=SC2086 mysql_databases_list=$(${mysql_bin_mysql} $mysqldump_option_auth \\ --show-warnings=FALSE -e \"show databases;\" 2>/dev/null | grep -Eiv '(^database$|information_schema|performance_schema|^mysql$)') fi if [[ \"x${mysql_databases_list}\" == \"x\" ]]; then echo \"no database is found to backup, aborted! \" exit 1 fi saved_IFS=$IFS IFS=' '$'\\t'$'\\n' for mysql_database in ${mysql_databases_list}; do # shellcheck disable=SC2086 ${mysql_bin_mysqldump} $mysqldump_option_auth \\ --routines --events --triggers --single-transaction --flush-logs \\ --ignore-table=mysql.event --databases \"${mysql_database}\" 2>/dev/null | gzip >\"${mysql_backup_dir}/${date_format_type_dir}/${mysql_database}-backup-${date_format_type_file}.sql.gz\" # shellcheck disable=SC2181 [[ $? -eq 0 ]] && echo \"${mysql_database} backup successfully! \" || echo \"${mysql_database} backup failed! \" /bin/sleep 1 # shellcheck disable=SC2086 ${mysql_bin_mysqldump} $mysqldump_option_auth \\ --routines --events --triggers --single-transaction --flush-logs \\ --ignore-table=mysql.event --databases \"${mysql_database}\" --no-data 2>/dev/null | gzip >\"${mysql_backup_dir}/${date_format_type_dir}/${mysql_database}-backup-${date_format_type_file}_schema.sql.gz\" # shellcheck disable=SC2181 [[ $? -eq 0 ]] && echo \"${mysql_database} schema backup successfully! \" || echo \"${mysql_database} schema backup failed! \" /bin/sleep 1 done IFS=${saved_IFS} save_days=${save_old_backups_for_days:-10} need_clean=$(find ${mysql_backup_dir} -maxdepth 1 -ctime +${save_days} -exec ls '{}' \\;) # if [[ ! -z ${need_clean} ]]; then if [[ \"x${need_clean}\" != \"x\" ]]; then find ${mysql_backup_dir} -maxdepth 1 -ctime +${save_days} -exec rm -rf '{}' \\; echo \"old backups have been cleaned! \" else echo \"nothing can be cleaned, skipped! \" fi echo \"=> do backup scheduler finished at $(date +%Y%m%d%H%M%S)\" echo -e \"\\n\\n\\n\" declare -x PATH=${old_PATH}"
        },
        {
            "filename": "file_449.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\backupOps\\MySQL\\file_449.sh",
            "content": "#!/bin/bash # learn from https://docs.openstack.org/ops-guide/ops-backup-recovery.html#database-backups backup_dir=\"/var/lib/backups/mysql\" filename=\"${backup_dir}/mysql-$(hostname)-$(date +%Y%m%d).sql.gz\" # Dump the entire MySQL database /usr/bin/mysqldump --opt --all-databases | gzip >\"${filename}\" # Delete backups older than 7 days find ${backup_dir} -ctime +7 -type f -delete"
        },
        {
            "filename": "file_450.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\backupOps\\MySQL\\file_450.sh",
            "content": "#!/usr/bin/env bash # Function description: # Backup MySQL databases for each, backup schema and schema with data in one action. # Usage: # bash BackupMysqlByDate.sh # Birth Time: # 2016-06-24 17:44:43.895515929 +0800 # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong # Others: # crontabs -- configuration and scripts for running periodical jobs # SHELL=/bin/bash # PATH=/sbin:/bin:/usr/sbin:/usr/bin # MAILTO=root # HOME=/ # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed # m h dom mon dow command # execute on 11:59 per sunday # 59 11 * * */0 /path/to/BackupMysqlByDate.sh >/tmp/log_backup_mysql_$(date +\"\\%Y\\%m\\%d\\%H\\%M\\%S\").log # or # execute on 23:59 per day # 59 23 * * * /path/to/BackupMysqlByDate.sh >/tmp/log_backup_mysql_$(date +\"\\%Y\\%m\\%d\\%H\\%M\\%S\").log USER=\"`id -un`\" # $USER is also available LOGNAME=\"$USER\" if [[ ${UID} -ne 0 ]]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi old_PATH=$PATH declare -x PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\" mysql_host=127.0.0.1 mysql_port=3306 mysql_username=dev mysql_password=dev mysql_backup_remote=true mysql_basedir=/usr/local/mysql save_old_backups_for_days=5 mysql_bin_mysql=${mysql_basedir}/bin/mysql mysql_bin_mysqldump=${mysql_basedir}/bin/mysqldump mysql_backup_dir=/data/backup/db/mysql date_format_type_dir=$(date +%Y-%m-%d) date_format_type_file=$(date +%Y%m%d%H%M%S) echo \"------------------------------------------------------------------------\" echo \"=> do backup scheduler start at $(date +%Y%m%d%H%M%S)\" # TODO, check user privileges # check user if have 'RELOAD,EVENT' privileges,etc # backup role # GRANT ALTER,ALTER ROUTINE,CREATE,CREATE ROUTINE,CREATE TEMPORARY TABLES,CREATE VIEW,DELETE,DROP,EXECUTE,INDEX,INSERT,LOCK TABLES,SELECT,UPDATE,SHOW VIEW,RELOAD,EVENT ON *.* TO 'dev'@\"%\"; # FLUSH PRIVILEGES; [[ -d ${mysql_basedir} ]] && mysql_datadir=${mysql_basedir}/data || mysql_datadir=/var/lib/mysql [[ -x ${mysql_bin_mysql} ]] || mysql_bin_mysql=mysql [[ -x ${mysql_bin_mysqldump} ]] || mysql_bin_mysqldump=mysqldump if [[ ! -d ${mysql_datadir} ]] ; then echo \"WARNING: mysql datadir is not standard(this maybe a mistake) or mysql server is not installed on local filesystem.\" fi if [[ ! -x ${mysql_bin_mysql} ]] ;then echo \"mysql: command not found \" exit 1 fi if [[ ! -x ${mysql_bin_mysqldump} ]]; then echo \"mysqldump: command not found \" exit 1 fi [[ -d ${mysql_backup_dir}/${date_format_type_dir} ]] || mkdir -p ${mysql_backup_dir}/${date_format_type_dir} mysql_databases_list=\"\" if [[ -d ${mysql_datadir} ]] && [[ \"x${mysql_backup_remote}\" != \"xtrue\" ]]; then mysql_databases_list=`ls -p ${mysql_datadir} | grep / |tr -d /` else mysql_databases_list=$(${mysql_bin_mysql} -h${mysql_host} -P${mysql_port} -u${mysql_username} -p${mysql_password} \\ --show-warnings=FALSE -e \"show databases;\" 2>/dev/null | grep -Eiv '(^database$|information_schema|performance_schema|^mysql$)') fi if [[ \"x${mysql_databases_list}\" == \"x\" ]]; then echo \"no database is found to backup, aborted! \" exit 1 fi saved_IFS=$IFS IFS=' '$'\\t'$'\\n' for mysql_database in ${mysql_databases_list};do ${mysql_bin_mysqldump} --host=${mysql_host} --port=${mysql_port} --user=${mysql_username} --password=${mysql_password}\\ --routines --events --triggers --single-transaction --flush-logs \\ --ignore-table=mysql.event --databases ${mysql_database} 2>/dev/null | \\ gzip > ${mysql_backup_dir}/${date_format_type_dir}/${mysql_database}-backup-${date_format_type_file}.sql.gz [[ $? -eq 0 ]] && echo \"${mysql_database} backup successfully! \" || \\ echo \"${mysql_database} backup failed! \" /bin/sleep 1 ${mysql_bin_mysqldump} --host=${mysql_host} --port=${mysql_port} --user=${mysql_username} --password=${mysql_password} \\ --routines --events --triggers --single-transaction --flush-logs \\ --ignore-table=mysql.event --databases ${mysql_database} --no-data 2>/dev/null | \\ gzip > ${mysql_backup_dir}/${date_format_type_dir}/${mysql_database}-backup-${date_format_type_file}_schema.sql.gz [[ $? -eq 0 ]] && echo \"${mysql_database} schema backup successfully! \" || \\ echo \"${mysql_database} schema backup failed! \" /bin/sleep 1 done IFS=${saved_IFS} save_days=${save_old_backups_for_days:-10} need_clean=$(find ${mysql_backup_dir} -maxdepth 1 -ctime +${save_days} -exec ls '{}' \\;) # if [[ ! -z ${need_clean} ]]; then if [[ \"x${need_clean}\" != \"x\" ]]; then find ${mysql_backup_dir} -maxdepth 1 -ctime +${save_days} -exec rm -rf '{}' \\; echo \"old backups have been cleaned! \" else echo \"nothing can be cleaned, skipped! \" fi echo \"=> do backup scheduler finished at $(date +%Y%m%d%H%M%S)\" echo -e \"\\n\\n\\n\" declare -x PATH=${old_PATH}"
        },
        {
            "filename": "file_451.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\backupOps\\MySQL\\file_451.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File: LinuxBashShellScriptForOps:backupMySQLOnAliyunRDS.sh # User: Guodong # Create Date: 2017/7/3 # Create Time: 15:29 # Function: backup Aliyun RDS MySQL using mysqldump # Note: # Prerequisite: # Description: # Reference: https://github.com/amalucelli/aws-rds-backup # crontab -e # 59 23 * * * /root/backupMySQLOnAliyunRDS.sh >/tmp/log_backup_mysql_$(date +\"\\%Y-\\%m\").log function log() { local msg=${1?} echo -ne $(date +['%Y-%m-%d %H:%M:%S'])\" $msg\\n\" } function removeOldBackup() { local instanceID=$(echo ${mysqlHost} | cut -f1-2 -d.) local backupDir=\"${backupBaseDir}/${backupType}/${backupDB}/${instanceID}\" log \"Removing local backup files older than ${backupRetentionDays} days\" for f in $(find ${backupDir} -mindepth 1 -mtime +${backupRetentionDays}); do log \"${f}\" done; find ${backupDir} -mindepth 1 -mtime +${backupRetentionDays} -delete } function doBackup() { local instanceID=$(echo ${mysqlHost} | cut -f1-2 -d.) local localDate=$(date +%Y-%m-%d) local backupDir=\"${backupBaseDir}/${backupType}/${backupDB}/${instanceID}/${localDate}\" if [[ ! -d ${backupDir} ]]; then log \"Creating local backup folder \\\"${backupDir}\\\"\" mkdir -p ${backupDir} fi saved_IFS=$IFS IFS=' '$'\\t'$'\\n' for db in ${dbList}; do log \"Dumping \\\"${db}\\\" into \\\"${backupDir}/${db}-$(date +%d-%m-%Y-%H-%M).sql.gz\\\"\" mysqldump -u ${mysqlUser} -p${mysqlPwd} -h ${mysqlHost} -P${mysqlPort} --force \\ --routines --events --triggers --single-transaction \\ --databases \"${db}\" 2>/dev/null | gzip -c > ${backupDir}/${db}-$(date +%d-%m-%Y-%H-%M).sql.gz mysqldump -u ${mysqlUser} -p${mysqlPwd} -h ${mysqlHost} -P${mysqlPort} --force \\ --routines --events --triggers --single-transaction \\ --no-data --databases \"${db}\" 2>/dev/null | gzip -c > ${backupDir}/${db}-$(date +%d-%m-%Y-%H-%M)_schema.sql.gz done; IFS=${saved_IFS} removeOldBackup } # backup settings backupType=\"rds\" backupDB=\"mysql\" backupRetentionDays=5 backupBaseDir=\"/data/backup\" # mysql settings mysqlHost=\"rm-xxx.mysql.rds.aliyuncs.com\" mysqlPort=3306 mysqlUser=\"\" mysqlPwd='' dbList=\"db1 db2 db3\" doBackup"
        },
        {
            "filename": "file_452.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\backupOps\\MySQL\\file_452.sh",
            "content": "#!/usr/bin/env bash mysql_backup_dir=/data/backup/db/mysql save_old_backups_for_days=5 save_days=${save_old_backups_for_days:-10} # use -ctime to replace -mtime, replace -mtime with -ctime option need_clean=$(find ${mysql_backup_dir} -maxdepth 1 -ctime +${save_days} -exec ls '{}' \\;) if [ \"x${need_clean}\" != \"x\" ]; then find ${mysql_backup_dir} -maxdepth 1 -ctime +${save_days} -exec rm -rf '{}' \\; echo \"old backups have been cleaned! \" else echo \"nothing can be cleaned, skipped! \" fi"
        },
        {
            "filename": "file_453.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\containers\\nodejs\\file_453.sh",
            "content": "#!/usr/bin/env bash # Usage: bash $0 # Author: dgden # Create Date: 2020/12/29 # Create Time: 11:30 # Description: #!/bin/sh set -e if [ \"${1#-}\" != \"${1}\" ] || [ -z \"$(command -v \"${1}\")\" ]; then set -- node \"$@\" fi exec \"$@\""
        },
        {
            "filename": "file_454.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\GitWebHooksAutoDeployScript\\file_454.sh",
            "content": "#!/bin/bash # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function function cecho { # Usage: # cecho -red sometext #Error, Failed # cecho -green sometext # Success # cecho -yellow sometext # Warning # cecho -blue sometext # Debug # cecho -white sometext # info # cecho -n # new line # end while [ \"$1\" ]; do case \"$1\" in -normal) color=\"\\033[00m\" ;; # -black) color=\"\\033[30;01m\" ;; -red) color=\"\\033[31;01m\" ;; -green) color=\"\\033[32;01m\" ;; -yellow) color=\"\\033[33;01m\" ;; -blue) color=\"\\033[34;01m\" ;; # -magenta) color=\"\\033[35;01m\" ;; # -cyan) color=\"\\033[36;01m\" ;; -white) color=\"\\033[37;01m\" ;; -n) one_line=1; shift ; continue ;; *) echo -n \"$1\"; shift ; continue ;; esac shift echo -en \"$color\" echo -en \"$1\" echo -en \"\\033[00m\" shift done if [ ! $one_line ]; then echo fi } # end echo color function # echo color function, smarter function echo_r () { #Error, Failed [ $# -ne 1 ] && return 0 echo -e \"\\033[31m$1\\033[0m\" } function echo_g () { # Success [ $# -ne 1 ] && return 0 echo -e \"\\033[32m$1\\033[0m\" } function echo_y () { # Warning [ $# -ne 1 ] && return 0 echo -e \"\\033[33m$1\\033[0m\" } function echo_b () {\\ # Debug [ $# -ne 1 ] && return 0 echo -e \"\\033[34m$1\\033[0m\" } # end echo color function, smarter WORKDIR=$PRGDIR # end public header # ============================================================================================================================= # Where to get source code SOURCEURL=https://github.com/DingGuodong/GitOSCAutoDeploy.git # Setting how many days do you want save old releases, default is 10 days save_old_releases_for_days=10 function setDirectoryStructure() { if [ -f $WORKDIR/.lock ];then echo_g \"Set directory structure has been done, skipping. \" return fi echo_b \"Setting directory structure.\" # learn from capistrano # Refer: http://capistranorb.com/documentation/getting-started/structure/ # Refer: http://capistranorb.com/documentation/getting-started/structure/# # \u251c\u2500\u2500 current -> /var/www/my_app_name/releases/20150120114500/ # \u251c\u2500\u2500 releases # \u2502 \u251c\u2500\u2500 20150080072500 # \u2502 \u251c\u2500\u2500 20150090083000 # \u2502 \u251c\u2500\u2500 20150100093500 # \u2502 \u251c\u2500\u2500 20150110104000 # \u2502 \u2514\u2500\u2500 20150120114500 # \u251c\u2500\u2500 repo # \u2502 \u2514\u2500\u2500 <VCS related data> # \u251c\u2500\u2500 revisions.log # \u2514\u2500\u2500 shared # \u2514\u2500\u2500 <linked_files and linked_dirs> # current is a symlink pointing to the latest release. This symlink is updated at the end of a successful deployment. If the deployment fails in any step the current symlink still points to the old release. # releases holds all deployments in a timestamped folder. These folders are the target of the current symlink. # repo holds the version control system configured. In case of a git repository the content will be a raw git repository (e.g. objects, refs, etc.). # revisions.log is used to log every deploy or rollback. Each entry is timestamped and the executing user (username from local machine) is listed. Depending on your VCS data like branchnames or revision numbers are listed as well. # shared contains the linked_files and linked_dirs which are symlinked into each release. This data persists across deployments and releases. It should be used for things like database configuration files and static and persistent user storage handed over from one release to the next. # The application is completely contained within the path of :deploy_to. If you plan on deploying multiple applications to the same server, simply choose a different :deploy_to path. # Check directories for deploy # [ ! -d $WORKDIR/current ] && mkdir $WORKDIR/current [ ! -d $WORKDIR/release ] && mkdir $WORKDIR/release [ ! -d $WORKDIR/repository ] && mkdir $WORKDIR/repository [ ! -d $WORKDIR/share ] && mkdir $WORKDIR/share # end directories structure touch $WORKDIR/.lock echo_g \"Set directory structure successfully! \" } function checkDependencies() { echo_b \"Checking dependencies for deploy procedure. \" # Refer: # if [ -z ${var+x} ]; then # echo \"var is unset\"; else echo \"var is set to '$var'\" # fi # if [ \"$var x\" = \" x\" ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi # if [ -z $var ]; then # echo \"var is empty\"; else echo \"var is set to '$var'\" # fi if [[ -z $SOURCEURL ]]; then echo_r \"Error: SOURCEURL is undefined! \" exit 1 fi DISKSPACE=`df $WORKDIR | tail -n1 | awk '{print $(NF -2)}'` if [[ $DISKSPACE -lt 2097152 ]]; then echo_y \"Warning: Disk space of $WORKDIR is smaller than 2GB\" #exit 1 fi echo_g \"All required dependencies check pass! \" } function cleanOldReleases(){ save_days=${save_old_releases_for_days:-10} if [ ! -d $WORKDIR/release ]; then echo_b \"Can NOT find release directory, skipping . \" return fi need_clean=$(find $WORKDIR/release -mtime +$save_days -exec ls {} \\;) if [ ! -z $need_clean ]; then echo_g \"Expired releases found and will be removed from project! \" find $WORKDIR/release -mtime +$save_days -exec rm -rf {} \\; if [ $? -eq 0 ]; then echo_g \"Expired releases have removed from project! \" else echo_r \"Can NOT remove expired releases, please alter to Admin users. \" fi else echo_g \"All releases are not expired, skipping. \" fi } function deploy() { # check a directories lock, Note: this is redundant if [[ ! -f $WORKDIR/.lock ]]; then setDirectoryStructure fi cleanOldReleases checkDependencies # Make directory to release directory SOURCEDIR=\"$WORKDIR/release/$(date +%Y%m%d%H%M%S)\" [ ! -d $SOURCEDIR ] && mkdir $SOURCEDIR # Get files from source code repository git clone $SOURCEURL $SOURCEDIR # svn co http://$SOURCEURL $WORKDIR/repository # TODO # get branch names or revision numbers from VCS data # Remove .git or .svn [ -d $SOURCEDIR/.git ] && rm -rf $SOURCEDIR/.git [ -d $SOURCEDIR/.svn ] && rm -rf $SOURCEDIR/.svn # ifdef Complie # endif # Make source code symbolic link to current ( [ -f $WORKDIR/current ] || [ -d $WORKDIR/current ] ) && rm -rf $WORKDIR/current ln -s $SOURCEDIR $WORKDIR/current # Move conf and logs directives from release to share [ -d $WORKDIR/release/conf ] && mv $WORKDIR/release/conf $WORKDIR/share/conf [ -d $WORKDIR/release/logs ] && mv $WORKDIR/release/logs $WORKDIR/share/logs # Make conf and logs symbolic link to current [ -d $WORKDIR/share/conf ] && ln -s $WORKDIR/share/conf $WORKDIR/current/conf [ -d $WORKDIR/share/logs ] && ln -s $WORKDIR/share/logs $WORKDIR/current/logs # Start service or validate status if [[ -e $WORKDIR/current/bin/startup.sh ]]; then $WORKDIR/current/bin/startup.sh start RETVAL=$? else # TODO # external health check RETVAL=0 fi RETVAL=$? # if started ok, then create a workable program to a file if [[ $RETVAL -eq 0 ]]; then # Note cat with eof must start at row 0, and with eof end only, such as no blank spaces, etc cat >$WORKDIR/share/workable_program.log <<eof $SOURCEDIR eof echo_g \"Deploy successfully! \" echo_g \"current workable version is $(cat $WORKDIR/share/workable_program.log)\" ls --color=auto -l $WORKDIR/current else echo_r \"Error: Deploy failed! \" $0 rollback fi } # Rollback to last right configuration function rollback() { # The key is find last files which can work WORKABLE_PROGRAM=`cat $WORKDIR/share/workable_program.log` if [[ -z WORKABLE_PROGRAM ]]; then echo_r \"Error: Can NOT find workable release version! Please check if it is first deployment! \" exit 1 fi # # Stop service if [[ -e $WORKDIR/current/bin/startup.sh ]]; then $WORKDIR/current/bin/startup.sh stop fi # Remove failed deploy rm -rf $WORKDIR/current # Remake source code symbolic link to current ln -s $WORKABLE_PROGRAM $WORKDIR/current # Remake conf and logs symbolic link to current [ -d $WORKDIR/share/conf ] && ln -s $WORKDIR/share/conf $WORKDIR/current [ -d $WORKDIR/share/logs ] && ln -s $WORKDIR/share/logs $WORKDIR/current # Start service or validate status if [[ -e $WORKDIR/current/bin/startup.sh ]]; then $WORKDIR/current/bin/startup.sh start RETVAL=$? else # TODO # external health check RETVAL=0 fi RETVAL=$? # if started ok, then create a workable program to a file if [[ $RETVAL -eq 0 ]]; then echo_g \"Rollback successfully! \" echo_g \"current workable version is $WORKABLE_PROGRAM\" ls --color=auto -l $WORKDIR/current fi } function destroy() { # echo a Warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" answer=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" answer case \"$answer\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"filename\" |xargs rm -rf find -L $WORKDIR -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf {} \\; if [ $? -eq 0 ];then echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } # Just a test for call itself, comment it # if [[ $# -lt 1 ]]; then # $0 help # exit # fi case $1 in deploy) deploy ;; rollback) rollback ;; destroy) destroy ;; help|*) echo \"Usage: $0 {deploy|rollback|destroy} with $0 itself\" exit 1 ;; esac # This is not essential with 'case .. esac' handled no args executions # replace \"exit 0\" with \":\" #exit 0 :"
        },
        {
            "filename": "file_455.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\GitWebHooksAutoDeployScript\\file_455.sh",
            "content": "#!/usr/bin/env bash # Public header # ============================================================================================================================= # Check that we are root ... so non-root users stop here [ `id -u` -eq \"0\" ] || exit 4 # resolve links - $0 may be a symbolic link PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function function cecho { # Usage: # cecho -red sometext #Error, Failed # cecho -green sometext # Success # cecho -yellow sometext # Warning # cecho -blue sometext # Debug # cecho -white sometext # info # cecho -n # new line # end while [ \"$1\" ]; do case \"$1\" in -normal) color=\"\\033[00m\" ;; # -black) color=\"\\033[30;01m\" ;; -red) color=\"\\033[31;01m\" ;; -green) color=\"\\033[32;01m\" ;; -yellow) color=\"\\033[33;01m\" ;; -blue) color=\"\\033[34;01m\" ;; # -magenta) color=\"\\033[35;01m\" ;; # -cyan) color=\"\\033[36;01m\" ;; -white) color=\"\\033[37;01m\" ;; -n) one_line=1; shift ; continue ;; *) echo -n \"$1\"; shift ; continue ;; esac shift echo -en \"$color\" echo -en \"$1\" echo -en \"\\033[00m\" shift done if [ ! $one_line ]; then echo fi } # end echo color function # echo color function, smarter function echo_r () { #Error, Failed [ $# -ne 1 ] && return 0 echo -e \"\\033[31m$1\\033[0m\" } function echo_g () { # Success [ $# -ne 1 ] && return 0 echo -e \"\\033[32m$1\\033[0m\" } function echo_y () { # Warning [ $# -ne 1 ] && return 0 echo -e \"\\033[33m$1\\033[0m\" } function echo_b () {\\ # Debug [ $# -ne 1 ] && return 0 echo -e \"\\033[34m$1\\033[0m\" } # end echo color function, smarter WORKDIR=$PRGDIR # end public header # ============================================================================================================================= # begin customization for special case # ============================================================================= # project directory to waiting for update config_project_dir=example_projects # resources directory which contains config file and update files config_resources_dir=example_resources # backup directory which to contains backup of whole project config_backup_dir=example_backup_dir # remote options, \"y\" can be supported, \"-\" not supported #config_remote_execution=yes|no [y] #config_remote_execution=true|false [y] #config_remote_execution=enable|disable [-], conflicted to bash #config_remote_execution=1|0 [y] config_remote_execution=no # TODO # not ready for remote execution # if config_remote_execution set to true, then blew is a must config_remote_backup_server= config_remote_backup_directory= # end customization for special case # ============================================================================= # this is can NOT be edited. config_config_file=$config_resources_dir/config_update.conf # log options, set a log file to record backup log for restore use, this is can NOT be edited. config_this_logfile=$WORKDIR/.update_backup.log identity_file=~/.ssh/id_rsa.pub # end # check if user want to execute on remote clients function parse_config_remote_execution() { if [ -z \"`eval $config_remote_execution`\" ]; then echo_r \"Error: config_remote_execution is NOT set, if you want execute it local, set it no, else set it yes. \" exit 1 elif [ x$config_remote_execution != x ];then case $config_remote_execution in yes|true|1) config_remote_execution=1 ;; no|false|0) config_remote_execution=0 ;; *) echo_r \"Error: config_remote_execution has a bad set, please check and correct it. \" exit 1 ;; esac else echo_y \"Can NOT find config_remote_execution, is it unset? Setting a default value for config_remote_execution. \" config_remote_execution=0 fi } function test_self(){ # How to use this function: # First execute \"$0 test_self\", then execute \"$0 update\" echo_b \"Test purpose begin. \" # clean old test example echo_b \"Clean old test example. \" [ -d $WORKDIR/example_projects ] && rm -rf $WORKDIR/example_projects [ -d $WORKDIR/example_resources ] && rm -rf $WORKDIR/example_resources [ -d $WORKDIR/example_backup_dir ] && rm -rf $WORKDIR/example_backup_dir # make an example project directory if [ -z $config_project_dir -o ! -d $config_project_dir ]; then echo_b \"Making an example project directory. \" mkdir $WORKDIR/example_projects config_project_dir=example_projects # Padding example_projects directory touch $config_project_dir/example_filename mkdir $config_project_dir/example_directory fi # make an example resources directory if [ -z $config_resources_dir -o ! -d $config_resources_dir ]; then echo_b \"Making an example resources directory. \" mkdir $WORKDIR/example_resources config_resources_dir=$WORKDIR/example_resources fi # make an example config_update.conf if [ -z $config_config_file -o ! -f $config_config_file ]; then echo_b \"Making an example config_update.conf file. \" touch $config_resources_dir/config_update.conf config_config_file=$config_resources_dir/config_update.conf # Padding config_update.conf file cat >$config_config_file <<eof file filename1 add file filename2 remove file filename3 update file filename4 add config cleancachea enable config cleancacheb disable config restartservicea enable config restartserviceb disable target 192.168.1.241 ssh 22 root yiCxVyW2DydhE target 192.168.1.242 ssh 22 root yiCxVyW2DydhE target 192.168.1.243 ssh 22 root yiCxVyW2DydhE target 192.168.1.244 ssh 22 root yiCxVyW2DydhE eof files=`awk -F '[ ]+' '/^file/ { print $2 }' $config_config_file` echo_b \"Making an example files(patches) refer to $config_config_file. \" for names in $files; do [ ! -f $config_resources_dir/$names ] && touch $config_resources_dir/$names done fi # TODO # not ready for remote execution # test network and ssh for remote call # make an example backup directory if [ -z $config_backup_dir -o ! -d $config_backup_dir ]; then echo_b \"Making an example backup directory\" mkdir $WORKDIR/example_backup_dir config_backup_dir=$WORKDIR/example_backup_dir fi echo_g \"Test purpose is finished and successfully! \" } #function parse_config_file(){ # # unbanned action # files=`awk -F '[ ]+' '/^file/ { print $2 }' $config_config_file` # configs=`awk -F '[ ]+' '/^config/ { print $2 }' $config_config_file` #} function ssh_keygen(){ echo_b \"generate SSH key and related files for itself.\" cd # Improvement # ssh-keygen parameters ssh-keygen -N \"\" -f /root/.ssh/id_rsa if [ $? -ne 0 ]; then echo_r \"Error: generate SSH key and related files for itself failed! \" exit 1 fi cd ~/.ssh/ [[ ! -e ~/.ssh/authorized_keys ]] && cp id_rsa.pub authorized_keys cd identity_file=~/.ssh/id_rsa.pub } # this action can NOT be replaced with check_ssh_connection function function inject_ssh_key(){ # ssh-copy-id Line:41 which sshpass >/dev/null 2>&1 || yum -q -y install sshpass if [ $? -ne 0 -a ! -f /etc/yum.repos.d/epel.repo ]; then echo_y \"sshpass can NOT install on system with yum repolist, install epel first. \" yum -q -y install http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm yum -q -y install sshpass if ! which sshpass >/dev/null 2>&1; then echo_r \"Error: sshpass is can NOT install on system, please install it manually. \" exit 1 fi fi # inject ssh key for each host found in config files hostname_list=$(awk -F '[ ]+' '/target/ {print $2}' $config_config_file) for hostname in $hostname_list; do port=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$4}\") user=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$5}\") password=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$6}\") # echo issue but it is less than ssh issue(It will report \"Pseudo-terminal will not be allocated because stdin is not a terminal.\" when use stdin to ssh command.) sshpass -p $password ssh -p $port -oStrictHostKeyChecking=no $user@$hostname \"exec sh -c 'echo $(cat ~/.ssh/id_rsa.pub) >> ~/.ssh/authorized_keys && (test -x /sbin/restorecon && /sbin/restorecon ~/.ssh ~/.ssh/authorized_keys >/dev/null 2>&1 || true)'\" # sshpass issue: Pseudo-terminal will not be allocated because stdin is not a terminal. # to resolve this issue, do NOT give ssh command any stdin, sometimes \"known host\" maybe worked with this issue # Refer: http://unix.stackexchange.com/questions/151757/script-to-ssh-and-run-a-command-doesnt-work # Refer: http://stackoverflow.com/questions/305035/how-to-use-ssh-to-run-shell-script-on-a-remote-machine # comment this line #sshpass -p $password cat ~/.ssh/id_rsa.pub | ssh -T -p $port -oStrictHostKeyChecking=no $user@$hostname \"exec sh -c 'cat >> ~/.ssh/authorized_keys && (test -x /sbin/restorecon && /sbin/restorecon ~/.ssh ~/.ssh/authorized_keys >/dev/null 2>&1 || true)'\" if [ $? -eq 0 ]; then echo_g \"SSH key inject to $hostname successfully! \" else echo_r \"SSH key inject to $hostname failed! \" exit 1 fi done } # this action has some duplicates to inject_ssh_key function function check_ssh_connection(){ hostname_list=$(awk -F '[ ]+' '/target/ {print $2}' $config_config_file) for hostname in $hostname_list; do port=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$4}\") user=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$5}\") password=$(cat $config_config_file | awk -F '[ ]+' \"/^target/ && /$hostname/ {print \\$6}\") if ! ssh -i ~/.ssh/id_rsa -p $port -oPasswordAuthentication=no $user@$hostname \"exec sh -c 'true'\" >/dev/null 2>&1; then echo_b \"Can NOT login $hostname through SSH key ~/.ssh/id_rsa, retry to inject SSH keys. \" sshpass -p $password ssh -p $port -oStrictHostKeyChecking=no $user@$hostname \"exec sh -c 'echo $(cat ~/.ssh/id_rsa.pub) >> ~/.ssh/authorized_keys && (test -x /sbin/restorecon && /sbin/restorecon ~/.ssh ~/.ssh/authorized_keys >/dev/null 2>&1 || true)'\" if [ $? -ne 0 ]; then echo_r \"Error: SSH key inject to $hostname failed! \" exit 1 else echo_g \"SSH key inject to $hostname successfully! \" if ssh -p $port -oStrictHostKeyChecking=no $user@$hostname \"exec sh -c 'cat ~/.ssh/authorized_keys | sort | uniq --repeated | grep ssh'\"; then echo_y \"Duplicate lines found in ~/.ssh/authorized_keys, remove them. \" ssh -p $port -oStrictHostKeyChecking=no $user@$hostname \"exec sh -c 'cat ~/.ssh/authorized_keys | sort | uniq > ~/.ssh/authorized_keys~;\\mv ~/.ssh/authorized_keys~ ~/.ssh/authorized_keys'\" if [ $? -eq 0 ]; then echo_g \"Duplicate lines found in ~/.ssh/authorized_keys removed successfully! \" else echo_y \"Duplicate lines found in ~/.ssh/authorized_keys removed failed! \" fi else echo_g \"SSH connection to $hostname is ok! \" fi fi else echo_g \"SSH connection to $hostname is ok! \" fi done } function do_cp(){ SOURCE=$1 # echo \"var: $SOURCE\" # echo \"result: $(dirname $SOURCE | grep ^\\/ | awk '{print substr($1,1,1)}' )\" # exit 0 if test \"$(dirname $SOURCE | grep ^\\/ | awk '{print substr($1,1,1)}')\" == \"\"; then echo_b \"Execute copy action. \" DEST=$config_project_dir/$SOURCE \\cp $SOURCE $DEST else echo_y \"Self test purpose found! But we can do this action! \" [ ! -d $config_project_dir/$(dirname $SOURCE) ] && mkdir -p $config_project_dir/$(dirname $SOURCE) \\cp $SOURCE $config_project_dir/$(dirname $SOURCE) fi } function do_remove(){ FILE=$1 if test \"$(dirname $SOURCE | awk -F '/' '{print $1}')\" == \"\"; then rm -rf $config_project_dir/$FILE else echo_y \"Self test purpose found! This can NOT do remove action on self test purpose, skipping...\" return fi } # TODO # not ready for remote execution # for remote call #function do_remote_cp(){} #function fo_remote_remove(){} function file_operation(){ echo_b \"Begin files operations\" files=`awk -F '[ ]+' '/^file/ { print $2 }' $config_config_file` for names in $files; do if grep $names $config_config_file | grep add >/dev/null 2>&1 ; then # do_cp do_cp $names elif grep $names $config_config_file | grep update >/dev/null 2>&1 ;then # do_cp do_cp $names elif grep $names $config_config_file | grep remove >/dev/null 2>&1 ;then # do_remove do_remove $names else exit 1 fi done echo_g \"Files operations finished successfully! \" } # TODO # no example here, please refer to your real production environment #function do_clean_cache(){} #function do_restart_service(){} function service_operation(){ echo_b \"Begin services operations\" configs=`awk -F '[ ]+' '/^config/ { print $2 }' $config_config_file` for names in $configs; do if grep $names $config_config_file | grep cleancache | grep enable >/dev/null 2>&1 ; then # do_clean_cache echo do_clean_cache $names elif grep $names $config_config_file | grep cleancache | grep disable >/dev/null 2>&1 ; then # echo a warning echo_y \"Warning: disable action is NOT recommended, $names skipped.\" elif grep $names $config_config_file | grep restartservice | grep enable >/dev/null 2>&1 ; then # do_restart_service echo do_restart_service $names elif grep $names $config_config_file | grep restartservice | grep disable >/dev/null 2>&1 ; then # echo a warning echo_y \"Warning: disable action is NOT recommended, $names skipped.\" else echo $names echo_r \"Error: Wrong config file $config_config_file, please check it. \" exit 1 fi done echo_g \"Services operations finished successfully! \" } function check_remote_server_status(){ # TODO # not ready for remote execution # for remote call echo } function backup(){ echo_b \"Backup files before update\" # backup_filename=backup_$(date +%F_%H_%M_%S).tgz backup_filename=backup_$(date +%Y_%m_%d_%H_%M_%S).tgz # tar directory cd $config_project_dir/.. tar --create --gzip --absolute-names --file=$config_backup_dir/$backup_filename $config_project_dir if [ $? -eq 0 ]; then echo_g \"Backup files before update finished and successfully! \" echo \"restore_least_file=$config_backup_dir/$backup_filename\" > $config_this_logfile else echo_r \"Error: Backup files before update failed! Please alter to administrator. \" exit 1 fi } function restore(){ echo_b \"Restore files for rollback\" if [ -f $config_this_logfile ]; then . $config_this_logfile fi restore_least_file=${restore_least_file:-1} if [ -s $restore_least_file ]; then tar -C $config_project_dir/.. -zxf $restore_least_file if [ $? -eq 0 ]; then echo_g \"Restore files finished and successfully! \" else echo_r \"Restore files failed! Please alter to administrator. \" exit 1 fi else echo_r \"Can NOT find backup files in $config_backup_dir, backup once indeed? \" exit 1 fi } # TODO # not ready for remote execution # for remote call # function remote_backup(){} # function remote_restore(){} function rollback(){ echo_b \"rollback after update failed\" $0 restore echo_g \"rollback finished and successfully! \" } function update_status(){ # TODO # no example here, please refer to your real production environment # check if update success or failure echo update_status # if failure, do rollback action # service_operation } # Put check_dependencies in front of update function function check_dependencies(){ echo_b \"Checking dependencies for update procedure. \" if [ -z $config_project_dir ]; then echo_r \"Error: config_project_dir is undefined! \" exit 1 fi if [ ! -d $config_resources_dir ]; then echo_r \"Error: config_resources_dir is undefined! \" fi if [ -z $config_config_file ]; then echo_r \"Error: config_config_file is undefined! \" exit 1 fi left_disk_space=`df $config_backup_dir | tail -n1 | awk '{print $(NF -2)}'` # set 2097152 to project directory size if [ -z $config_project_dir -o ! -d $config_project_dir ]; then project_file_space_usage=$(du -s /root | awk '{print $1}') required_size=$(expr $project_file_space_usage \\* 2) fi if [[ $left_disk_space -lt $required_size ]]; then echo_r \"Disk space of $config_backup_dir is smaller than $required_size. \" exit 1 fi if [ ! -f /root/.ssh/id_rsa ]; then ssh_keygen fi echo_g \"All required dependencies check pass! \" } function update(){ # TODO # thinking carefully with all exit status, which is not good for automatic update check_dependencies backup file_operation service_operation update_status } function destroy() { # echo a warning message echo_y \"Warning: This action will destroy all this project, and this is unrecoverable! \" answer=\"n\" echo_y \"Do you want to destroy this project? \" read -p \"(Default no,if you want please input: y ,if not please press the enter button):\" answer case \"$answer\" in y|Y|Yes|YES|yes|yES|yEs|YeS|yeS ) # delete all file expect for this script self # find: warning: Unix filenames usually don't contain slashes (though pathnames do). That means that '-name `./deploy.sh'' will probably evaluate to false all the time on this system. You might find the '-wholename' test more useful, or perhaps '-samefile'. Alternatively, if you are using GNU grep, you could use 'find ... -print0 | grep -FzZ `./deploy.sh''. # echo $WORKDIR/ #find -L $WORKDIR -type f ! -name \"$(basename $0)\" -exec ls --color=auto -al {} \\; # find -L . -type f ! -name \"deploy.sh\" -exec ls --color=auto -al {} \\; # find -L . -type d -exec ls --color=auto -al {} \\; # find -L ./ -maxdepth 1 ! -name \"deploy.sh\" ! -wholename \"./\" # ls | grep -v \"fielname\" |xargs rm -rf find -L $WORKDIR -maxdepth 1 ! -name \"$(basename $0)\" ! -wholename \"$WORKDIR\" -exec rm -rf '{}' \\; if [ $? -eq 0 ];then echo_g \"Destroy this project successfully! Now will exit with status 0. \" exit 0 else echo_r \"Error: something go wrong! Please check or alter to Admin user! \" exit 1 fi ;; n|N|No|NO|no|nO) echo_g \"destroy action is cancel\" exit 0 ;; *) echo_r \"Are you kidding me? You are a bad kid! \" exit 1 ;; esac } case $1 in update) update ;; backup) backup ;; restore) restore ;; rollback) rollback ;; destroy) destroy ;; help|*) echo \"Usage: $0 {update|backup|restore|rollback|destroy} with $0 itself\" exit 1 ;; esac # This is not essential with 'case .. esac' handled no args excutions # replace \"exit 0\" with \":\" #exit 0 :"
        },
        {
            "filename": "file_456.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\HappyBashForHappyLife\\file_456.sh",
            "content": "#!/bin/bash # What it can be done? # If you work with fixed hours, you can use this script find out # when you can go home or go shopping with your friends. # Please feel free to using it and share to your friends. # :) # Note: # binary command 'bc' is required. # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function function cecho { # Usage: # cecho -red sometext #Error, Failed # cecho -green sometext # Success # cecho -yellow sometext # Warnning # cecho -blue sometext # Debug # cecho -white sometext # info # cecho -n # new line # end while [ \"$1\" ]; do case \"$1\" in -normal) color=\"\\033[00m\" ;; # -black) color=\"\\033[30;01m\" ;; -red) color=\"\\033[31;01m\" ;; -green) color=\"\\033[32;01m\" ;; -yellow) color=\"\\033[33;01m\" ;; -blue) color=\"\\033[34;01m\" ;; # -magenta) color=\"\\033[35;01m\" ;; # -cyan) color=\"\\033[36;01m\" ;; -white) color=\"\\033[37;01m\" ;; -n) one_line=1; shift ; continue ;; *) echo -n \"$1\"; shift ; continue ;; esac shift echo -en \"$color\" echo -en \"$1\" echo -en \"\\033[00m\" shift done if [ ! ${one_line} ]; then echo fi } # end echo color function # echo color function, smarter function echo_r () { #Error, Failed [ $# -ne 1 ] && return 0 echo -e \"\\033[31m$1\\033[0m\" } function echo_g () { # Success [ $# -ne 1 ] && return 0 echo -e \"\\033[32m$1\\033[0m\" } function echo_y () { # Warning [ $# -ne 1 ] && return 0 echo -e \"\\033[33m$1\\033[0m\" } function echo_b () {\\ # Debug [ $# -ne 1 ] && return 0 echo -e \"\\033[34m$1\\033[0m\" } # end echo color function, smarter WORKDIR=${PRGDIR} # end public header # ============================================================================================================================= # define open_time=11:08 work_time=9.5 close_time=18:38 least_time=06:00 last_time=23:59 late_time=10:00 worked_time=2.4 # end define function validate_input_time(){ if [[ $# -ne 1 ]]; then echo \"Bad line, need 1 parameter at least! \" exit 1 fi input_time=$1 echo ${input_time} | grep -E \"^([0-9]|0[0-9]|1[0-9]|2[0-3]):([0-5][0-9])$\" >/dev/null 2>&1 rc=$? if [[ ${rc} -ne 0 ]]; then echo \"Bad input time\" exit 1 fi return ${rc} } function minutes_to_seconds(){ if [[ $# -ne 1 ]]; then echo \"Bad line, need 1 parameter at least! \" exit 1 fi return 0 } function hours_to_minutes(){ if [[ $# -ne 1 ]]; then echo \"Bad line, need 1 parameter at least! \" exit 1 fi hours=`echo $1 | awk -F ':' '{print $1}'` minutes=`echo $1 | awk -F ':' '{print $2}'` total_minutes=`echo \"$hours * 60 + $minutes\" | bc` if [[ $? -eq 0 && ${total_minutes} != \"\" && ${total_minutes} -ge 0 ]]; then # here can NOT use a return echo ${total_minutes} else echo \"Exception occurs! \" exit 1 fi } function validate_late_to_work(){ least_minutes=$(hours_to_minutes ${least_time}) last_minutes=`hours_to_minutes ${last_time}` late_minutes=`hours_to_minutes ${late_time}` open_minutes=`hours_to_minutes ${open_time}` if [ ${open_minutes} -lt ${least_minutes} ] || [ ${open_minutes} -gt ${late_minutes} ]; then echo \"You are late! \" exit 1 fi } function computing_close_time(){ open_minutes=`hours_to_minutes ${open_time}` close_minutes=`echo \"$work_time * 60 + $open_minutes\" | bc` close_hours=`echo \"$close_minutes / 60\" | bc` close_minutes=`echo \"$close_minutes % 60\" | bc | awk -F '.' '{print $1}'` close_time=\"$close_hours:$close_minutes\" echo ${close_time} } function computing_worked_hours(){ open_minutes=`hours_to_minutes ${open_time}` now_time=$(date +%H:%M) now_minutes=`hours_to_minutes ${now_time}` worked_minutes=`echo \"$now_minutes - $open_minutes\" | bc` worked_hours=`echo \"$worked_minutes / 60\" | bc` echo ${worked_hours} } function computing_worked_minutes(){ open_minutes=`hours_to_minutes ${open_time}` now_time=$(date +%H:%M) now_minutes=`hours_to_minutes ${now_time}` worked_minutes=`echo \"$now_minutes - $open_minutes\" | bc` worked_minutes=`echo \"$worked_minutes % 60\" | bc | awk -F '.' '{print $1}'` echo ${worked_minutes} } function work_report(){ echo \"================================================================\" echo -e \"You start work at \\033[32m$open_time\\033[0m.\" echo -e \"You need work \\033[32m$work_time\\033[0m hours for your salary.\" echo -e \"You can leave at \\033[32m$(computing_close_time)\\033[0m.\" echo -e \"now time is \\033[32m$(date +%H:%M)\\033[0m.\" echo -e \"You have worked \\033[32m$(computing_worked_hours)\\033[0m hours and \\033[32m$(computing_worked_minutes)\\033[0m minutes.\" echo \"================================================================\" } function read_user_input(){ read -p \"please input your open time, such as 09:00(default): \" open_time if [[ \"$open_time\" == \"\" ]]; then open_time=\"09:00\" fi } function main(){ read_user_input validate_input_time ${open_time} validate_late_to_work work_report } main"
        },
        {
            "filename": "file_457.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Filesystem\\file_457.sh",
            "content": "#!/usr/bin/env bash # Description: # inotify-tools is a set of command-line programs for Linux providing # a simple interface to inotify. These programs can be used to monitor # and act upon filesystem events. # References: # https://www.infoq.com/articles/inotify-linux-file-system-event-monitoring # Python version: # [inotify 0.2.9](https://pypi.python.org/pypi/inotify) # [inotifyx 0.2.2](https://pypi.python.org/pypi/inotifyx/0.2.2) # [pyinotify 0.9.6](https://pypi.python.org/pypi/pyinotify/) # Ubuntu, sudo apt install -y inotify-tools # CentOS: epel, yum makecache; yum install -y epel-release; yum install -y inotify-tools grep INOTIFY_USER /boot/config-$(uname -r) >/dev/null || exit 1 inotifywait --exclude '^/data/app/(large|ignore)/' -rme modify,attrib,move,close_write,create,delete,delete_self /data/app/"
        },
        {
            "filename": "file_458.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Filesystem\\file_458.sh",
            "content": "#!/usr/bin/env bash # filename: remove_old_app.sh # remove old apps, not restrict # 59 17 * * * /bin/bash --login /opt/ebt/apps/remove_old_apps.sh >>/tmp/remove_old_apps.log # 59 17 * * 1-5 /bin/bash --login /opt/ebt/apps/remove_old_apps.sh >>/tmp/remove_old_apps.log #set -o errexit #set -o xtrace echo \"================================================================\" # printf \"%.s=\" {1..64};echo echo \"Info: Clean Started! $(date --rfc-2822)\" echo apps_dir=\"/opt/ebt/apps\" # apps dir to clear app_list=\" agent-management agent-stats canal-to-kafka car cashier customer dataexchange ebtdatres erisk erp insiap insure-validation jetty-docbase message policy proposal resource risk-market sms user zyj-touch \" [ -d ${apps_dir} ] || exit 5 current_pwd=$(pwd) # crontab maybe can not recognize $PWD or `pwd` if without 'bash --login', need a test if [[ ${current_pwd} != \"${apps_dir}\" ]]; then cd ${apps_dir} || exit fi current_app_list=$(ls -1 .) # IFS=' '$'\\t'$'\\n', IFS=$' \\t\\n', If IFS is unset, or its value is exactly <space><tab><newline> old_IFS=$IFS IFS=' '$'\\t'$'\\n' for app in ${app_list};do all_app_count=0 old_app_count=0 if echo \"$current_app_list\" | grep \"${app}\" >/dev/null 2>&1; then #if [[ ${current_app_list} =~ ${app} ]]; then all_app_count=$(ls -t . | grep -c \"${app}\") if [[ ${all_app_count} -gt 2 ]]; then # Note: do NOT use '>', use '-gt' in '[[ EXPRESSION ]]' instead old_app_count=$((all_app_count - 2)) # old_app_count=$((all_app_count-2)) echo \"Info: Found:$app, Total files count: $all_app_count, Old files count: $old_app_count, clean them\" # ls -dt ./* | grep ${app} | tail -${old_app_count} | xargs ls -dl ls -dt ./* | grep ${app} | tail -${old_app_count} | xargs rm -rf else echo \"Warning: Found:$app, Total files count: $all_app_count, pass\" fi else echo \"Error: $app not found! \" fi done IFS=\"$old_IFS\" echo \"Info: Clean Finished! $(date --rfc-2822)\" echo \"================================================================\" echo"
        },
        {
            "filename": "file_459.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Filesystem\\file_459.sh",
            "content": "#!/usr/bin/env bash # filename: remove_old_app_files.sh # remove old app files, not restrict # 57 17 * * * /bin/bash --login /opt/ebt/apps/app-files/remove_old_app_files.sh >>/tmp/remove_old_app_files.log # 57 17 * * 1-5 /bin/bash --login /opt/ebt/apps/app-files/remove_old_app_files.sh >>/tmp/remove_old_app_files.log #set -o errexit #set -o xtrace echo \"================================================================\" echo \"Info: Clean Started! $(date --rfc-2822)\" echo apps_dir=\"/opt/ebt/apps/app-files\" # app files dir to clear app_list=\" agent-management agent-stats canal-to-kafka car cashier customer dataexchange ebtdatres erisk erp insiap insure-validation jetty-docbase message policy proposal resource risk-market sms user zyj-touch \" [ -d ${apps_dir} ] || exit 5 current_pwd=$(pwd) # crontab maybe can not recognize $PWD or `pwd` if without 'bash --login', need a test if [[ ${current_pwd} != \"${apps_dir}\" ]]; then cd ${apps_dir} || exit fi current_app_list=$(ls -1 .) # IFS=' '$'\\t'$'\\n', IFS=$' \\t\\n', If IFS is unset, or its value is exactly <space><tab><newline> old_IFS=$IFS IFS=' '$'\\t'$'\\n' for app in ${app_list};do all_app_count=0 old_app_count=0 if echo \"$current_app_list\" | grep \"${app}\" >/dev/null 2>&1; then #if [[ ${current_app_list} =~ ${app} ]]; then all_app_count=$(ls -t . | grep -c \"${app}\") if [[ ${all_app_count} -gt 2 ]]; then # Note: do NOT use '>', use '-gt' in '[[ EXPRESSION ]]' instead old_app_count=$((all_app_count - 2)) # old_app_count=$((all_app_count-2)) echo \"Info: Found:$app, Old files count: $old_app_count, clean them\" ls -t . | grep \"${app}\" | tail -${old_app_count} | xargs rm -f else echo \"Warning: Found:$app, Total files count: $all_app_count, pass\" fi else echo \"Error: $app not found! \" fi done IFS=\"$old_IFS\" echo \"Info: Clean Finished! $(date --rfc-2822)\" echo \"================================================================\" echo"
        },
        {
            "filename": "file_460.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Filesystem\\file_460.sh",
            "content": "#!/usr/bin/env bash # Usage: bash $0 # Author: dgden # Create Date: 2021/4/25 # Create Time: 13:57 # Description: remove files or directories safely on Linux if [[ -f \"$HOME\"/.bashrc ]]; then bash_rc_path=\"$HOME\"/.bashrc elif [[ -f \"$HOME\"/.bash_profile ]]; then bash_rc_path=\"$HOME\"/.bash_profile fi \\cp \"$bash_rc_path\" \"${bash_rc_path}_$(date +%Y%m%d%H%M%S)~\" cat >>\"$bash_rc_path\" <<'eof' # enable trash bin for bash if [ ! -d ~/.trash ]; then mkdir -p ~/.trash fi alias rm=trash alias r=trash alias rl='ls ~/.trash' alias ur=undelete_file alias cr=clear_trash undelete_file() { mv -i ~/.trash/\"$*\" ./ } trash() { mv \"$@\" ~/.trash/ } clear_trash() { read -pr \"clear sure?[n]\" confirm [ \"$confirm\" == 'y' ] || [ \"$confirm\" == 'Y' ] && /usr/bin/rm -rf ~/.trash/* } # end eof # shellcheck source=$HOME/.bashrc source \"$HOME\"/.bashrc echo \"Tips: use a separate disk or mount point to serve the important files, so you can use extundelete easily.\" # shellcheck disable=SC2028 echo 'You can use \"\\rm -rf path\" to delete directly.'"
        },
        {
            "filename": "file_461.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Filesystem\\file_461.sh",
            "content": "#!/usr/bin/env bash # a command or alias to replace 'rm' with a safe and easy to use, safe remove files or directories # See also: # safe-rm - wrapper around the rm command to prevent accidental deletions - https://github.com/kaelzhang/shell-safe-rm # trash-cli - Command line interface to FreeDesktop.org Trash - https://pypi.python.org/pypi/trash-cli/ # debug option DEBUG=false # DEBUG=true if ${DEBUG} ; then old_PS4=$PS4 # export PS4='+${BASH_SOURCE}:${LINENO}:${FUNCNAME[0]}: ' export PS4='+${LINENO}: ${FUNCNAME[0]}: ' # if there is only one bash script, do not display ${BASH_SOURCE} _XTRACE_FUNCTIONS=$(set +o | grep xtrace) set -o xtrace fi # set an empty function using for location this line quickly in PyCharm editor on purpose. function _empty() { return; } # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= real_rm='/bin/rm' trash_dir=\"$HOME/.trash\" # if do not use \"$HOME\" or \"~\" to resolve permission problem, should use \"chmod o+t $trash_dir\" .chmod --help: Each MODE is of the form `[ugoa]*([-+=]([rwxXst]*|[ugo]))+'. log_dir=\"$trash_dir\" log_file=\"$log_dir/operation.log\" trash_save_days=3 function real_rm() { if [[ ! -f ${real_rm} ]]; then echo 'safe-rm cannot find the real \"rm\" binary' exit 1 fi save_days=${trash_save_days:-10} test $(find -L /tmp/.delete/ -type d ! -name \"^.\" -a ! -wholename \"/tmp/.delete/\" -mtime +${save_days} -exec echo '{}' \\; | wc -l ) -gt 0 found_old_files=$? if [[ ${found_old_files} -eq 0 ]]; then echo_b \"old files found, cleaning\" #find -L ${trash_dir}/ -maxdepth 1 -type d ! -name \"^.\" -mtime +${save_days} -exec rm -rf '{}' \\; find -L ${trash_dir}/ -maxdepth 1 -type d ! -wholename \"$trash_dir/\" ! -name \"^.\" -mtime +${save_days} -exec rm -rf '{}' \\; echo_g \"old files cleaned successfully\" else echo_g \"old files in standby state, passed\" fi } function safe_rm() { if [[ \"$1x\" = 'x' ]]; then ${real_rm} --help exit 1 fi if [[ ! -d ${trash_dir} ]]; then mkdir -p ${trash_dir} fi # date +%Y%m%d%H%M%S.%N | shasum | awk '{print $1}' | cat - -A uniq_trash_dir=\"$trash_dir/$(date +%Y%m%d%H%M%S.%N | shasum | awk '{print $1}')\" mkdir -p ${uniq_trash_dir} if [[ $# -eq 1 ]];then if [[ -f $1 ]] || [[ -d $1 ]]; then # ignore rm -f|-r|-rf|-fr, etc mv $1 ${uniq_trash_dir} retval=$? fi else # alternative impl of 'rm FILE...' parameter_array=\"$@\" # IFS=' '$'\\t'$'\\n', IFS=$' \\t\\n', If IFS is unset, or its value is exactly <space><tab><newline> old_IFS=$IFS IFS=' '$'\\t'$'\\n' for parameter in ${parameter_array}; do if [[ -f ${parameter} ]] || [[ -d ${parameter} ]]; then # ignore rm -f|-r|-rf|-fr, etc mv ${parameter} ${uniq_trash_dir} fi done retval=$? IFS=\"$old_IFS\" fi log_operation $@ exit ${retval} } function log_operation(){ tee -a ${log_file}<<-eof # debug purpose or notify mode { \"date_human\": \"$(date +'%Y-%m-%d %H:%M:%S.%N')\", \"date\": \"$(date)\", \"user\": \"$USER\", \"ssh_client\": \"$SSH_CLIENT\", \"ssh_connection\": \"$SSH_CONNECTION\", \"ssh_tty\": \"$SSH_TTY\", \"trash_dir\": \"${uniq_trash_dir}\" \"log_file\":\"${log_file}\", \"pwd\": \"$PWD\", \"operation\": \"$0 $@\", \"parameter\": \"$@\" } eof } function usage(){ cat - << eof ${WORKDIR}/`basename $0` help show help message ${WORKDIR}/`basename $0` clean clean old deleted files eof } function main(){ lock_filename=\"lock_$$_${RANDOM}\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` if [[ $# -lt 1 ]]; then ${WORKDIR}/`basename $0` help exit 0 fi if [ -f $1 ]; then safe_rm $@ else parameter_array=\"$@\" # IFS=' '$'\\t'$'\\n', IFS=$' \\t\\n', If IFS is unset, or its value is exactly <space><tab><newline> old_IFS=$IFS IFS=' '$'\\t'$'\\n' for parameter in ${parameter_array}; do if [[ -f ${parameter} ]] || [[ -d ${parameter} ]]; then # ignore rm -f|-r|-rf|-fr, etc safe_rm $@ fi done IFS=\"$old_IFS\" fi case $1 in clean) real_rm ;; help|*) usage exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option if ${DEBUG} ; then export PS4=${old_PS4} ${_XTRACE_FUNCTIONS} fi"
        },
        {
            "filename": "file_462.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Filesystem\\file_462.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File Name: LinuxBashShellScriptForOps:rsync-and-backup-atlassian-files.sh # Version: 0.0.1 # Author: Guodong # Author Email: dgdenterprise@gmail.com # URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps # Download URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps/tarball/master # Create Date: 2018/4/25 # Create Time: 10:26 # Description: use rsync to sync files on local # Long Description: see `man rsync`: rsync - a fast, versatile, remote (and local) file-copying tool # Rsync is a fast and extraordinarily versatile file copying tool. # It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon. # Usage: bash rsync-and-backup-atlassian-files.sh # References: [lsyncd](https://github.com/axkibe/lsyncd) # Prerequisites: rsync # Development Status: 3 - Alpha, 5 - Production/Stable # Environment: Console # Intended Audience: System Administrators, Developers, End Users/Desktop # License: Freeware, Freely Distributable # Natural Language: English, Chinese (Simplified) # Operating System: POSIX :: Linux # Programming Language: GNU bash :: 4+ # Topic: Utilities # note: for vim --> :set paste # crontab setting # */30 * * * * /bin/bash /root/rsync-directory-with-crontab.sh # 30 19 * * * /bin/bash /root/rsync-directory-with-crontab.sh # 0 */2 * * * /bin/bash /root/rsync-directory-with-crontab.sh # wrong way: * */2 * * * # rsync task config ################ SRC=\"/opt/atlassian\" DEST=\"/backup/my-atlassian-data\" # mount backup disk to /backup RSYNC_LOG_FILE=\"/var/log/corn-atlassian-rsync.log\" # create unified log dir for log file ################ # TODO(DingGuodong) we can send backups to oss(object store service) # do this ONLY once lock_file=$SRC/.backup_lock_file # do NOT set to $DEST, make sure $DEST (backup disk) exist if [[ ! -f $lock_file ]]; then mkdir -p $DEST touch $lock_file fi test ! -d $DEST && echo \"backup dir not exist, disk is down? exit now.\" && exit 1 #SHELL=/bin/bash #PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin if test ${UID} -ne 0; then echo \"ROOT ACCESS IS REQUIRED\" echo \"Only root can do that, but current user is '$USER', please use 'sudo $0' or run as root\" exit 1 fi # -a --> archive mode; equals -rlptgoD (no -H,-A,-X) # -c --> skip based on checksum, not mod-time & size # -q --> suppress non-error messages # -u --> skip files that are newer on the receiver # -v --> increase verbosity # -z --> compress file data during the transfer (remote only) /usr/bin/rsync -a \\ --delete --delete-excluded \\ --log-file=${RSYNC_LOG_FILE} \\ ${SRC} \"${DEST}\""
        },
        {
            "filename": "file_463.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Filesystem\\file_463.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File Name: LinuxBashShellScriptForOps:rsync-directory-with-crontab.sh # Version: 0.0.1 # Author: Guodong # Author Email: dgdenterprise@gmail.com # URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps # Download URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps/tarball/master # Create Date: 2018/4/25 # Create Time: 10:26 # Description: # Long Description: see `man rsync`: rsync - a fast, versatile, remote (and local) file-copying tool # Rsync is a fast and extraordinarily versatile file copying tool. # It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon. # Usage: # References: # Prerequisites: [] # Development Status: 3 - Alpha, 5 - Production/Stable # Environment: Console # Intended Audience: System Administrators, Developers, End Users/Desktop # License: Freeware, Freely Distributable # Natural Language: English, Chinese (Simplified) # Operating System: POSIX :: Linux # Programming Language: GNU bash :: 4+ # Topic: Utilities # crontab setting # */30 * * * * /bin/bash /root/rsync-directory-with-crontab.sh # 30 19 * * * /bin/bash /root/rsync-directory-with-crontab.sh # rsync task config ################ HOST=\"192.168.88.151\" SRC=\"/data\" DEST=\"/data/backup/from_$HOSTNAME\" USER=\"root\" SSH_OPTION=\"-p 22 -oStrictHostKeyChecking=no\" RSYNC_LOG_FILE=\"/tmp/rsync.log\" ################ #SHELL=/bin/bash #PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin if test ${UID} -ne 0; then echo \"ROOT ACCESS IS REQUIRED\" echo \"Only root can do that, but current user is '$USER', please use 'sudo $0' or run as root\" exit 1 fi # shellcheck disable=SC2029 ssh \"${SSH_OPTION}\" ${USER}@${HOST} \"mkdir -p ${DEST}\" # -a --> archive mode; equals -rlptgoD (no -H,-A,-X) # -c --> skip based on checksum, not mod-time & size # -q --> suppress non-error messages # -u --> skip files that are newer on the receiver # -v --> increase verbosity # -z --> compress file data during the transfer /usr/bin/rsync -az \\ -e \"ssh ${SSH_OPTION}\" \\ --delete --delete-excluded \\ --log-file=${RSYNC_LOG_FILE} \\ ${SRC} ${USER}@${HOST}:\"${DEST}\""
        },
        {
            "filename": "file_464.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Security\\firewall\\file_464.sh",
            "content": "#!/usr/bin/env bash # Usage: bash $0 # Author: dgden # Create Date: 2021/3/19 # Create Time: 14:10 # Description: allow the login ip access a port on this host function remove_an_old_fw_rich_rule() { wanted_rich_rule=$(firewall-cmd --list-all | awk '/fw_temp_kw_internal/','$1=$1') if [[ $wanted_rich_rule != \"\" ]]; then firewall-cmd --permanent --zone=public --remove-rich-rule=\"$wanted_rich_rule\" firewall-cmd --reload fi } function add_a_fw_rich_rule() { from_ip=$(bash -c \"w -h | awk '/w -h/ {print \\$3}'\") firewall-cmd --permanent --zone=public --add-rich-rule=\"rule family=\"ipv4\" source address=\"$from_ip\" port protocol=\"tcp\" port=\"50009\" log prefix=\"fw_temp_kw_internal\" level=\"info\" accept\" firewall-cmd --reload } function main() { remove_an_old_fw_rich_rule add_a_fw_rich_rule firewall-cmd --list-all --zone=public } main"
        },
        {
            "filename": "file_465.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Security\\login\\file_465.sh",
            "content": "#!/usr/bin/env bash # # Function description: # # About Interactive and non-interactive shells and scripts # Interactive script to be one that requires input from the user, # usually with read statements or positional parameters # Non-interactive shells run without human intervention. # Many administrative and system maintenance scripts are likewise non-interactive. # # Usage: # bash check_who_login_and_record.sh # # Create Time: # 2016-04-22 10:41:00.956620365 +0800 #date +'%Y-%m-%d %H:%M:%S.%N %z' # # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong # # Print the commands being run so that we can see the command that triggers # an error. It is also useful for following along as the install occurs. # same as set -u # Save trace setting #_XTRACE_FUNCTIONS=$(set +o | grep xtrace) #set -o xtrace # Check if a command already exists function command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } parameters_restrict_more_then_one() { # More Info: http://www.gnu.org/software/bash/manual/bashref.html#Shell Parameter Expansion if [ \"$#\" -eq 0 ]; then return 1 fi } check_ip_manipulation_tool_if_exist() { if command_exists ipcalc; then return 0 else apt-get -qq -y install ipcalc || yum install -y ipcalc local retval=$? if test \"$retval\" -eq 0; then command_exists ipcalc && echo \"Install ipcalc successfully, $(command -v ipcalc) is found! \" return 0 else return ${retval} fi fi } # /etc/sysconfig/network-scripts/network-functions-ipv6 (CentOS Linux release 7.2.1511 (Core)) ## Test a given IPv6 address for validity # $1: <IPv6 address> # return code: 0=ok 1=not valid ipv6_test_ipv6_addr_valid() { ipcalc -cs6 \"$1\" } ## Test a given IPv4 address for validity # $1: <IPv4 address> # return code: 0=ok 1=not valid ipv6_test_ipv4_addr_valid() { ipcalc -cs4 \"$1\" } ## Test a given IPv4 address for not a private but unicast one # $1: <IPv4 address> # return code: 0=ok 1=argument error 10=private or not unicast ipv6_test_ipv4_addr_global_usable() { local testipv4addr_globalusable=$1 if [ -z \"$testipv4addr_globalusable\" ]; then return 1 fi # Test for a globally usable IPv4 address now # test 0.0.0.0/8 ipcalc --network \"$testipv4addr_globalusable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=0\\.0\\.0\\.0\" && return 10 # test 10.0.0.0/8 (RFC 1918 / private) ipcalc --network \"$testipv4addr_globalusable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=10\\.0\\.0\\.0\" && return 10 # test 127.0.0.0/8 (loopback) ipcalc --network \"$testipv4addr_globalusable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=127\\.0\\.0\\.0\" && return 10 # test 169.254.0.0/16 (APIPA / DHCP link local) ipcalc --network \"$testipv4addr_globalusable\" 255.255.0.0 | LC_ALL=C grep -q \"NETWORK=169\\.254\\.0\\.0\" && return 10 # test 172.16.0.0/12 (RFC 1918 / private) ipcalc --network \"$testipv4addr_globalusable\" 255.240.0.0 | LC_ALL=C grep -q \"NETWORK=172\\.16\\.0\\.0\" && return 10 # test 192.168.0.0/16 (RFC 1918 / private) ipcalc --network \"$testipv4addr_globalusable\" 255.255.0.0 | LC_ALL=C grep -q \"NETWORK=192\\.168\\.0\\.0\" && return 10 # test 224.0.0.0/3 (multicast and reserved, broadcast) ipcalc --network \"$testipv4addr_globalusable\" 224.0.0.0 | LC_ALL=C grep -q \"NETWORK=224\\.0\\.0\\.0\" && return 10 return 0 } function is_reserved_ip_address() { # Refer to: https://en.wikipedia.org/wiki/Reserved_IP_addresses # /etc/sysconfig/network-scripts/network-functions-ipv6 (CentOS Linux release 7.2.1511 (Core)) test_ipv4_addr_global_usable=$1 ipcalc -cs4 \"$test_ipv4_addr_global_usable\" ipcalc -cs6 \"$test_ipv4_addr_global_usable\" /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=0\\.0\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=10\\.0\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.0.0.0 | LC_ALL=C grep -q \"NETWORK=127\\.0\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.255.0.0 | LC_ALL=C grep -q \"NETWORK=169\\.254\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.240.0.0 | LC_ALL=C grep -q \"NETWORK=172\\.16\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 255.255.0.0 | LC_ALL=C grep -q \"NETWORK=192\\.168\\.0\\.0\" && return 10 /bin/ipcalc --network \"$test_ipv4_addr_global_usable\" 224.0.0.0 | LC_ALL=C grep -q \"NETWORK=224\\.0\\.0\\.0\" && return 10 } function return_ip_addr_if_is_global_usable() { ipv6_test_ipv4_addr_global_usable \"$1\" local retval=$? if test \"$retval\" -eq 0; then return 0 else return ${retval} fi } function get_current_login_users_ipaddress() { # return a single result or a list old_IFS=$IFS IFS=\" \" original_ip_list=\"$(w -h | awk '/[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}/ {print $3}')\" ignore_reduplicate_ip_list=\"$(echo \"$original_ip_list\" | tr ' ' '\\n' | sort | uniq)\" IFS=\"$old_IFS\" if test ! -z \"$ignore_reduplicate_ip_list\"; then for ip in $ignore_reduplicate_ip_list; do echo \"$ip\" done else return 1 fi } function get_current_login_users_ipaddress_and_times() { # AI: who -q # show all login names and number of users logged on echo -e \"\\t- Total count of users is: $(w -h | wc -l)\" command_exists w && w -h | awk '/[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}/ {a[$3]++}END{for (i in a) print \"\\t- Still logged in IP address : \"i\", count is: \"a[i]}' } show_current_logged_in_users_ip_address() { echo \"Current logged in users from ip address are: \" get_current_login_users_ipaddress_and_times echo current_logged_in_users_ipaddress=$(get_current_login_users_ipaddress) echo \"Current logged in users from ip address are:\" for ip in ${current_logged_in_users_ipaddress}; do echo -e \"\\t- $ip\" done echo } show_current_logged_in_users_ip_address_from_public_network() { some_user_logged_in_from_public_network=0 for ip in ${current_logged_in_users_ipaddress}; do if return_ip_addr_if_is_global_usable \"$ip\"; then some_user_logged_in_from_public_network=1 echo -n \"Current logged in users ip address from public network are:\" echo -e \"\\t- $ip\" fi done if test ${some_user_logged_in_from_public_network} -eq 0; then echo \"NO logged in users ip address from public network.\" fi echo } show_extra_information_from_sys_call() { echo \"Show who is logged on and what they are doing by \\\"w\\\" : \" command_exists w && w echo echo \"Show a list of last logged in users, top 10 users show by \\\"last\\\" : \" command_exists last && last | head -n10 } function main() { lock_filename=\"lock_$$_$RANDOM\" lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" if ( set -o noclobber echo \"$$\" >\"$lock_filename_full_path\" ) 2>/dev/null; then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT # do check_ip_manipulation_tool_if_exist show_current_logged_in_users_ip_address show_current_logged_in_users_ip_address_from_public_network show_extra_information_from_sys_call # done rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main"
        },
        {
            "filename": "file_466.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Security\\ssh\\file_466.sh",
            "content": "#!/usr/bin/env bash # change ssh service port and restart it # change ssh service port to a random and unused port between 1001 and 65534 function change_sshd_port() { sshd_port=$RANDOM netstat -lt | grep :$sshd_port ret_value=$? while [[ $sshd_port -lt 1000 && $sshd_port -gt 65535 && $ret_value != 0 ]]; do sshd_port=$RANDOM done intranet_ip=$(ip addr show scope global \"$(ip route | awk '/^default/ {print $5}')\" | awk -F '[ /]+' '/global/ {print $3}') echo -e \"\\033[01;34mwait for getting ip info from internet...\\033[0m\" echo -e \"current internet ip address is: \\033[01;32m$(curl -s https://ifconfig.io)\\033[0m\" echo -e \"current intranet ip address is: \\033[01;32m$intranet_ip\\033[0m\" if test \"$(awk '/^Port 22/' /etc/ssh/sshd_config)\" == \"Port 22\"; then cp /etc/ssh/sshd_config /etc/ssh/sshd_config\"$(date +%Y%m%d%H%M%S)\"~ sed -i \"s/^Port 22/Port $sshd_port/g\" /etc/ssh/sshd_config echo -e \"new sshd port is: \\033[01;31m$sshd_port\\033[0m\" elif grep ^Port /etc/ssh/sshd_config >&/dev/null; then echo -e \"skipped, sshd port in not 22, current sshd port is: \\033[01;31m$(sed -n '/^Port/p' /etc/ssh/sshd_config | awk '{print $2}')\\033[0m\" else cp /etc/ssh/sshd_config /etc/ssh/sshd_config\"$(date +%Y%m%d%H%M%S)\"~ sed -i \"$ a Port $sshd_port\" /etc/ssh/sshd_config echo -e \"new sshd port is: \\033[01;31m$sshd_port\\033[0m\" fi } # restart ssh servie with service manager function restart_ssh_service() { echo -e \"\\033[01;34mwait for ssh service restart...\\033[0m\" if [[ -f /etc/init.d/ssh ]]; then /etc/init.d/ssh restart || systemctl restart ssh.service elif [[ -f /etc/init.d/sshd ]]; then /etc/init.d/sshd restart || systemctl restart sshd.service fi if netstat -lnt | grep :$sshd_port >&/dev/null; then echo -e \"\\033[01;32mssh service restarted successfully.\\033[0m\" echo -e \"\\033[01;33mit will take effect after you next login.\\033[0m\" else echo -e \"\\033[01;31mError: ssh service restarted failed.\\033[0m\" pgrep sshd /etc/init.d/sshd status || systemctl status sshd.service fi } function todo(){ register_to_configration_center } # Check that we are root ... so non-root users stop here [[ $(id -u) -eq \"0\" ]] || echo -e \"\\033[01;31myou would have to be root to run it.\\033[0m\" && exit 1 change_sshd_port restart_ssh_service"
        },
        {
            "filename": "file_467.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Security\\ssh\\file_467.sh",
            "content": "#!/usr/bin/env bash # code snippets for SSH security enhancement # deprecated function check_and_set_for_nonroots() { find /home -name authorized_keys -type f -print0 | xargs -i chmod 400 {} find /home -name .ssh -type d -print0 | xargs -i chmod 500 {} } function check_and_set_for_common_users() { awk -F: '{if($3>500)print$6}' /etc/passwd | while IFS= read -r line; do # 500 is UID_MIN value in /etc/login.defs, and it maybe different in various LInux distribution, such as 1000 in Debian if test -d \"$line\"; then chmod 400 \"$line/.ssh/authorized_keys\" chmod 500 \"$line/.ssh\" fi done } function check_and_set_for_root() { chmod 400 /root/.ssh/authorized_keys } # Check that we are root ... so non-root users stop here [[ $(id -u) -eq \"0\" ]] || exit 1 check_and_set_for_common_users check_and_set_for_root"
        },
        {
            "filename": "file_468.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Services\\file_468.sh",
            "content": "#!/usr/bin/env bash # restart java service by pid pid=$1 app_user=\"ebt\" app_subpath=\"scripts/post_deploy.sh\" if [[ \"pid$pid\" == \"pid\" ]]; then echo \"pid is missing\" exit 1 fi function show_current_running() { current_running=$(su - ${app_user} -c \"jps -l\" | grep \"^${pid}\") retvar=\"$?\" if [[ $retvar != 0 ]]; then echo \"java pid is not found\" exit 1 fi current_service=$(echo \"$current_running\" | awk '{print $2}') echo \"$current_running\" } function show_service_health() { pgrep -f \"$current_service\" >&/dev/null retvar=\"$?\" if [[ $retvar != 0 ]]; then return $retvar else return $retvar fi } function do_sleep() { local seconds=$1 local msg=$2 [ \"$seconds\" -lt 1 ] && return echo \"sleep $seconds for $msg\" sleep 1 do_sleep $((seconds - 1)) \"${msg}\" } function keep_waiting_until_service_up() { used_seconds=0 max_try_times=10 sleep_seconds=3 while [[ $max_try_times -gt 0 ]]; do show_service_health retvar=\"$?\" if [[ $retvar != 0 ]]; then echo \"waiting $sleep_seconds seconds for service startup\" sleep $sleep_seconds max_try_times=$((max_try_times - 1)) used_seconds=$((used_seconds + sleep_seconds)) else echo \"service startup in $used_seconds seconds\" return $retvar fi done } show_current_running app_path=$(lsof -p \"${pid}\" | awk '$4==\"cwd\"{print $NF}') restart_script_path=\"${app_path}/${app_subpath}\" echo \"$restart_script_path\" # why cd? because: JAVA_ARGS in $restart_script_path: -cp 'classes/:lib/*' # e.g.: exec /application/jdk/bin/java -server -Dfile.encoding=UTF-8 -Dsun.jnu.encoding=UTF-8 -Djava.io.tmpdir=/tmp -Djava.net.preferIPv6Addresses=false -Dlog.path=/opt/ebt/logs/dataexchange -Xmx1g -Xms1g -XX:SurvivorRatio=8 -XX:+HeapDumpOnOutOfMemoryError -XX:ReservedCodeCacheSize=128m -XX:InitialCodeCacheSize=128m -XX:+DisableExplicitGC -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintTenuringDistribution -XX:+UseConcMarkSweepGC -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:CMSInitiatingOccupancyFraction=80 -Xloggc:/opt/ebt/logs/dataexchange/dataexchange.gc.log -XX:ErrorFile=/opt/ebt/logs/dataexchange/dataexchange.vmerr.log -XX:HeapDumpPath=/opt/ebt/logs/dataexchange/dataexchange.heaperr.log -cp 'classes/:lib/*' com.ebt.platform.dataexchange.Application su - ${app_user} -c \"cd $app_path && bash $restart_script_path\" keep_waiting_until_service_up"
        },
        {
            "filename": "file_469.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Services\\file_469.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File Name: LinuxBashShellScriptForOps:watch-dog-for-service.sh # Version: 0.0.1 # Author: dgden # Author Email: dgdenterprise@gmail.com # URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps # Download URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps/tarball/master # Create Date: 2019/7/24 # Create Time: 12:01 # Description: a watch dog for a service written in bash shell script # Long Description: check service running status, bring it up when service fail upto n times # Usage: */1 * * * * /root/watch-dog-for-service.sh # References: Tips: \u5199\u4ee3\u7801\u5c3d\u91cf\u5199\u5f97\u4f18\u96c5\uff0c\u4f46\u4f18\u96c5\u7684\u524d\u63d0\u662f\u8ba9\u4ed6\u4eba\u66f4\u5bb9\u6613\u8bfb\u61c2\u548c\u7ef4\u62a4\u3002 # follow suggestions on https://github.com/koalaman/shellcheck # Prerequisites: [] # Development Status: 3 - Alpha, 5 - Production/Stable # Environment: Console # Intended Audience: System Administrators, Developers, End Users/Desktop # License: Freeware, Freely Distributable # Natural Language: English, Chinese (Simplified) # Operating System: POSIX :: Linux # Programming Language: GNU bash :: 4+ # Topic: Utilities WDFS_DB_FILE=\"/tmp/.watch-dog-for-service.db\" # WDFS is stand for watch-dog-for-service. WDFS_LOG_FILE=\"/tmp/watch-dog-for-service.log\" MAX_TRY_TIMES=1 # 1 means restart service after 2 times failure ENABLE_DEBUG=1 function log_message(){ if [[ -n \"${1:-}\" ]]; then [[ \"$ENABLE_DEBUG\" == 1 ]] && echo \"$(date +%Y%m%d%H%M%S,%s) $*\" | tee -a ${WDFS_LOG_FILE} fi } function check_service_status(){ status=\"0\" pgrep -f \"app_name\" || status=\"$?\" # RETURN=\"${?}\", retval=$? if [[ \"$status\" = 0 ]]; then return 0 else return ${status} fi } function get_db_value(){ value_in_db=$(cat ${WDFS_DB_FILE}) echo \"${value_in_db}\" # `echo` is more better than `cat` because of it is more easy to understand } function db_value_increase_one(){ value_in_db=$(get_db_value) echo \"$((value_in_db + 1))\" > ${WDFS_DB_FILE} } function set_db_value_to_zero(){ echo 0 > ${WDFS_DB_FILE} } function bring_up_service(){ sudo -u ebt -i bash -c \"cd /opt/corp_name/apps/app_name && /usr/bin/nohup /opt/tools/node-v6.9.5-linux-x64/bin/npm run start --app.name app_name >> /opt/corp_name/logs/app_name/app.log 2>&1 &\" } function watch_dog(){ status=\"0\" check_service_status || status=\"$?\" if [[ \"$status\" = 0 ]]; then set_db_value_to_zero log_message \"ok: process is running\" return 0 else value_in_db=$(get_db_value) if [[ \"$value_in_db\" == \"$MAX_TRY_TIMES\" ]]; then log_message \"err: process is not found upto max times, try to start it\" bring_up_service return 0 else db_value_increase_one fi value_in_db=$(get_db_value) log_message \"warn: process is not found, current times is $value_in_db\" fi } function main(){ watch_dog } main"
        },
        {
            "filename": "file_470.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\Services\\SysV\\CentOS\\file_470.sh",
            "content": "#!/bin/bash # # Wrapper to close properly redis and sentinel test x\"$REDIS_DEBUG\" != x && set -x REDIS_CLI=/usr/bin/redis-cli # Retrieve service name SERVICE_NAME=\"$1\" if [ -z \"$SERVICE_NAME\" ]; then SERVICE_NAME=redis fi # Get the proper config file based on service name CONFIG_FILE=\"/etc/$SERVICE_NAME.conf\" # Use awk to retrieve host, port from config file HOST=`awk '/^[[:blank:]]*bind/ { print $2 }' $CONFIG_FILE | tail -n1` PORT=`awk '/^[[:blank:]]*port/ { print $2 }' $CONFIG_FILE | tail -n1` PASS=`awk '/^[[:blank:]]*requirepass/ { print $2 }' $CONFIG_FILE | tail -n1` SOCK=`awk '/^[[:blank:]]*unixsocket\\s/ { print $2 }' $CONFIG_FILE | tail -n1` # Just in case, use default host, port HOST=${HOST:-127.0.0.1} if [ \"$SERVICE_NAME\" = redis ]; then PORT=${PORT:-6379} else PORT=${PORT:-26739} fi # Setup additional parameters # e.g password-protected redis instances [ -z \"$PASS\" ] || ADDITIONAL_PARAMS=\"-a $PASS\" # shutdown the service properly if [ -e \"$SOCK\" ] ; then $REDIS_CLI -s $SOCK $ADDITIONAL_PARAMS shutdown else $REDIS_CLI -h $HOST -p $PORT $ADDITIONAL_PARAMS shutdown fi"
        },
        {
            "filename": "file_471.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\SoftwareManagement\\crontab\\file_471.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File: LinuxBashShellScriptForOps:${NAME}.sh # User: Guodong # Create Date: 2017/7/21 # Create Time: 9:11 # Function: # Note: # Prerequisite: # Description: clean logs in /tmp directory, # replace big log file(log files to clean) with small log file($log_file) # Reference: log_format=\"clean_log.log\" log_path=\"$HOME\" log_file=\"$log_path/$log_format\" save_days=10 log_path_clean=\"/tmp\" find ${log_path_clean} -type f -name \"*.log\" -maxdepth 1 -ctime ${save_days} -execdir rm -f '{}' \\; rc=$? # return code always is 0 so far if [ ${rc} -eq 0 ]; then logger -s \"log clean successfully!\" cat >>${log_file}<<eof \"date\": $(date +%Y%m%d%H%M%S), \"operation\": \"find ${log_path_clean} -type f -name \"*.log\" -maxdepth 1 -ctime ${save_days} -execdir rm -f '{}' \\;\", \"msg\": \"clean ok\", eof else echo \"log clean failed!\" exit 1 fi if test -s ${log_file}; then find ${log_path} -type f -name \"*.log\" -maxdepth 1 -ctime ${save_days} -execdir rm -f '{}' \\; fi"
        },
        {
            "filename": "file_472.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\SoftwareManagement\\docker\\file_472.sh",
            "content": "#!/usr/bin/env bash # https://docs.docker.com/engine/install/ubuntu/ # install docker-ce docker engine with overlay2 storage diver support on Ubuntu(16.04 <= VER <=20.04 LTS) using the repository # must succeed or die set -e # The contents of /var/lib/docker/, including images, containers, volumes, and networks, are preserved. # The Docker Engine package is now called docker-ce. sudo apt-get remove -y docker docker-engine docker.io containerd runc sudo apt-get update -y sudo apt-get install -y \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" sudo apt-get update -y sudo apt-get install -y docker-ce docker-ce-cli containerd.io sudo docker version # https://docs.docker.com/engine/install/linux-postinstall/ sudo usermod -aG docker \"$USER\" sudo systemctl enable docker sudo docker pull hello-world sudo docker run --rm -it alpine ping -c4 google.com set +e"
        },
        {
            "filename": "file_473.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\SoftwareManagement\\docker\\utils\\file_473.sh",
            "content": "# Notes: save this script into `~/.bashrc_docker` # put this line `[ -f ~/.bashrc_docker ] && . ~/.bashrc_docker` into ~/.bashrc # Some useful commands to use docker. # Author: yeasy@github # Created:2014-09-25 alias docker-pid=\"sudo docker inspect --format '{{.State.Pid}}'\" alias docker-ip=\"sudo docker inspect --format '{{ .NetworkSettings.IPAddress }}'\" #the implementation refs from https://github.com/jpetazzo/nsenter/blob/master/docker-enter function docker-enter() { #if [ -e $(dirname \"$0\")/nsenter ]; then #Change for centos bash running if [ -e \"$(dirname \"$0\")\"/nsenter ]; then # with boot2docker, nsenter is not in the PATH but it is in the same folder NSENTER=$(dirname \"$0\")/nsenter else # if nsenter has already been installed with path notified, here will be clarified NSENTER=$(which nsenter) #NSENTER=nsenter fi [ -z \"$NSENTER\" ] && echo \"WARN Cannot find nsenter\" && return if [ -z \"$1\" ]; then echo \"Usage: $(basename \"$0\") CONTAINER [COMMAND [ARG]...]\" echo \"\" echo \"Enters the Docker CONTAINER and executes the specified COMMAND.\" echo \"If COMMAND is not specified, runs an interactive shell in CONTAINER.\" else PID=$(sudo docker inspect --format \"{{.State.Pid}}\" \"$1\") if [ -z \"$PID\" ]; then echo \"WARN Cannot find the given container\" return fi shift # OPTS=\"--target $PID --mount --uts --ipc --net --pid\" if [ -z \"$1\" ]; then # No command given. # Use su to clear all host environment variables except for TERM, # initialize the environment variables HOME, SHELL, USER, LOGNAME, PATH, # and start a login shell. #sudo $NSENTER \"$OPTS\" su - root sudo \"$NSENTER\" --target \"$PID\" --mount --uts --ipc --net --pid su - root else # Use env to clear all host environment variables. sudo \"$NSENTER\" --target \"$PID\" --mount --uts --ipc --net --pid env -i \"$@\" fi fi }"
        },
        {
            "filename": "file_474.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\SoftwareManagement\\nginx\\file_474.sh",
            "content": "#!/bin/bash # Created by PyCharm. # File Name: LinuxBashShellScriptForOps:nginx-install-update.sh # Version: 0.0.1 # Author: Guodong # Author Email: dgdenterprise@gmail.com # URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps # Download URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps/tarball/master # Create Date: 2018/11/15 # Create Time: 15:54 # Description: install or update nginx server with Bash Shell Scripting # Long Description: The reason for writing this script in bash shell language instead of writing it in Python is # because it is not pythonic at all # Usage: sudo bash $0 # References: https://www.nginx.com/resources/wiki/start/topics/examples/full/ # Prerequisites: [] # Development Status: 3 - Alpha, 5 - Production/Stable # Environment: Console # Intended Audience: System Administrators, Developers, End Users/Desktop # License: Freeware, Freely Distributable # Natural Language: English, Chinese (Simplified) # Operating System: POSIX :: Linux # Programming Language: GNU bash :: 4+ # Topic: Utilities #set -e NGINX_SOURCE_LATEST_VERSION=\"nginx-1.16.1\" PCRE_SOURCE_LATEST_VERSION=\"pcre-8.43\" ZLIB_SOURCE_LATEST_VERSION=\"zlib-1.2.11\" OPENSSL_SOURCE_LATEST_VERSION=\"openssl-1.1.1d\" function echo_r (){ # Color red: Error, Failed [[ $# -ne 1 ]] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [[ $# -ne 1 ]] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [[ $# -ne 1 ]] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[36m$1\\033[0m\" } function confirm_continue(){ echo \"Is this ok? \" read -n 1 -r -p \"Enter the y or Y to continue:\" user_answer # read -n1 -r -p \"Press any key to continue...\" key if [[ \"${user_answer}\" != \"y\" ]] && [[ \"${user_answer}\" != \"Y\" ]]; then echo -e \"\\n\\nExiting on user cancel.\" # exiting because \"Download Only\" specified exit 1 else echo fi } WORKDIR=\"/tmp/.install_nginx_from_source\" [[ ! -d ${WORKDIR} ]] && mkdir ${WORKDIR} [[ -d ${WORKDIR} ]] && cd ${WORKDIR} || exit 1 function check_ports(){ if netstat -ntl | awk '{if($4 ~ /:80$/ ) print}' | grep ':80'; then echo_y \"$(date '+%Y-%m-%d %H:%M:%S.%N') WARNING: port 80 in use\" confirm_continue elif netstat -ntl | awk '{if($4 ~ /:443/ ) print}' | grep ':443'; then echo_y \"$(date '+%Y-%m-%d %H:%M:%S.%N') WARNING: port 443 in use\" confirm_continue else echo_g \"$(date '+%Y-%m-%d %H:%M:%S.%N') Passed: port 80/443 not in use\" fi } function compare_version(){ # Compare the version number with `sort -V` or directly remove the dot before comparison if test \"$(echo \"$*\" | tr \" \" \"\\n\"| sort -rV | head -1)\" == \"$1\"; then return 0 else return 1 fi } function can_install_update(){ if command -v nginx >/dev/null 2>&1; then current_version=$(/usr/sbin/nginx -V |& grep \"nginx\\ version\" | awk -F\"/\" '{print$NF}') latest_version=$(echo ${NGINX_SOURCE_LATEST_VERSION}| awk -F\"-\" '{print$NF}') if compare_version \"${current_version}\" \"${latest_version}\"; then echo_g \"$(date '+%Y-%m-%d %H:%M:%S.%N') check passed and skipped!\" exit 0 else echo_c \"$(date '+%Y-%m-%d %H:%M:%S.%N') nginx can be upgrade!\" check_ports return 1 fi else echo_c \"$(date '+%Y-%m-%d %H:%M:%S.%N') nginx can be install!\" check_ports return 0 fi } function add_users(){ if ! grep ^www: /etc/passwd >/dev/null 2>&1; then echo_b \"$(date '+%Y-%m-%d %H:%M:%S.%N') adding group and user ...\" groupadd -r www useradd -r -g www www -c \"Web user\" -d /dev/null -s /sbin/nologin fi } function is_nginx_installed(){ if test -d /usr/local/nginx && test -x /usr/local/nginx/sbin/nginx || test -f \"${HOME}/.nginx_installed\"; then # installed return 0 # return will save result to $? else # not installed by source or not installed retrun 1 # numeric argument can be 0, 1, 2, ... fi } function download_source_packages(){ echo_b \"$(date '+%Y-%m-%d %H:%M:%S.%N') downloading packages ...\" # http://nchc.dl.sourceforge.net/project/pcre/pcre/8.39/pcre-8.39.tar.gz [[ ! -f ${WORKDIR}/${NGINX_SOURCE_LATEST_VERSION}.tar.gz ]] && wget -c http://nginx.org/download/${NGINX_SOURCE_LATEST_VERSION}.tar.gz >/dev/null 2>&1 # http://nginx.org/en/download.html [[ ! -f ${WORKDIR}/${PCRE_SOURCE_LATEST_VERSION}.tar.gz ]] && wget -c https://ftp.pcre.org/pub/pcre/${PCRE_SOURCE_LATEST_VERSION}.tar.gz >/dev/null 2>&1 # ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/ [[ ! -f ${WORKDIR}/${ZLIB_SOURCE_LATEST_VERSION}.tar.gz ]] && wget -c http://zlib.net/${ZLIB_SOURCE_LATEST_VERSION}.tar.gz >/dev/null 2>&1 # http://zlib.net/ [[ ! -f ${WORKDIR}/${OPENSSL_SOURCE_LATEST_VERSION}.tar.gz ]] && wget -c https://www.openssl.org/source/${OPENSSL_SOURCE_LATEST_VERSION}.tar.gz >/dev/null 2>&1 # https://www.openssl.org/source/ } function install_base(){ # Completing Preinstallation Tasks echo_b \"$(date '+%Y-%m-%d %H:%M:%S.%N') install base packages ...\" apt-get -y update >/dev/null 2>&1 || yum makecache >/dev/null 2>&1 apt-get -y install gcc g++ make >/dev/null 2>&1 || yum install -y gcc gcc-c++ make >/dev/null 2>&1 } function compile_nginx_source(){ echo_b \"$(date '+%Y-%m-%d %H:%M:%S.%N') compile nginx and install nginx ...\" tar zxf ${NGINX_SOURCE_LATEST_VERSION}.tar.gz tar zxf ${PCRE_SOURCE_LATEST_VERSION}.tar.gz tar zxf ${ZLIB_SOURCE_LATEST_VERSION}.tar.gz tar zxf ${OPENSSL_SOURCE_LATEST_VERSION}.tar.gz cd ${WORKDIR}/${NGINX_SOURCE_LATEST_VERSION} || exit 1 ./configure --prefix=/usr/local/nginx \\ --with-http_ssl_module \\ --with-http_v2_module \\ --with-http_realip_module \\ --with-stream \\ --with-stream_ssl_module \\ --with-stream_realip_module \\ --user=www --group=www \\ --with-pcre-jit \\ --with-pcre=${WORKDIR}/${PCRE_SOURCE_LATEST_VERSION} \\ --with-zlib=${WORKDIR}/${ZLIB_SOURCE_LATEST_VERSION} \\ --with-openssl=${WORKDIR}/${OPENSSL_SOURCE_LATEST_VERSION} >/dev/null 2>&1 make >/dev/null 2>&1 && make install >/dev/null 2>&1 cd || exit 1 } function post_install(){ echo_b \"$(date '+%Y-%m-%d %H:%M:%S.%N') pos-install nginx ...\" [[ -h /usr/sbin/nginx ]] || ln -s /usr/local/nginx/sbin/nginx /usr/sbin/nginx nginx -V nginx -t >/dev/null 2>&1 if [[ -f /usr/local/nginx/logs/nginx.pid ]] && kill -0 \"$(cat /usr/local/nginx/logs/nginx.pid)\" >/dev/null 2>&1 ; then nginx -s stop && nginx else nginx fi netstat -lnpt | grep nginx } function optimize_security_rules(){ # Checking Resource Limits # https://docs.oracle.com/cd/B28359_01/install.111/b32002/pre_install.htm#LADBI246 # https://docs.oracle.com/en/database/oracle/oracle-database/18/ladbi/checking-resource-limits-for-oracle-software-installation-users.html#GUID-293874BD-8069-470F-BEBF-A77C06618D5A cp /etc/security/limits.d/www.conf \"/etc/security/limits.d/www.conf$(date +%Y%m%d%H%M%S)~\" tee /etc/security/limits.d/www.conf<<'eof' www soft nproc 2047 www hard nproc 16384 www soft nofile 1024 www hard nofile 65536 eof #ulimit -Sn # Check the soft and hard limits for the file descriptor setting. #ulimit -Hn #ulimit -Su # Check the soft and hard limits for the number of processes available to a user. #ulimit -Hu #ulimit -Ss # Check the soft limit for the stack setting. #ulimit -Hs } function optimize_kernel_parameters(){ # Configuring Kernel Parameters for Linux # http://docs.oracle.com/cd/B28359_01/install.111/b32002/pre_install.htm#LADBI246 # https://docs.oracle.com/en/database/oracle/oracle-database/18/ladbi/minimum-parameter-settings-for-installation.html#GUID-CDEB89D1-4D48-41D9-9AC2-6AD9B0E944E3 # https://docs.oracle.com/en/database/oracle/oracle-database/18/ladbi/changing-kernel-parameter-values.html#GUID-FB0CC366-61C9-4AA2-9BE7-233EB6810A31 cp /etc/sysctl.conf \"/etc/sysctl.conf$(date +%Y%m%d%H%M%S)~\" cat >/etc/sysctl.conf<<eof # http://docs.oracle.com/cd/B28359_01/install.111/b32002/pre_install.htm#LADBI246 fs.aio-max-nr = 1048576 fs.file-max = 6815744 kernel.core_uses_pid = 1 kernel.hung_task_timeout_secs = 0 kernel.msgmax = 65536 kernel.msgmnb = 65536 kernel.sem = 250 32000 100 128 kernel.shmall gc_stale_time= 4294967295 kernel.shmmax = 68719476736 kernel.shmmni = 4096 kernel.sysrq = 0 net.core.netdev_max_backlog = 262144 net.core.rmem_default = 8388608 net.core.rmem_max = 16777216 net.core.somaxconn = 262144 net.core.wmem_default = 8388608 net.core.wmem_max = 16777216 net.ipv4.conf.default.accept_source_route = 0 net.ipv4.conf.default.rp_filter = 1 net.ipv4.ip_forward = 0 net.ipv4.ip_local_port_range = 9000 65500 net.ipv4.tcp_fin_timeout = 1 net.ipv4.tcp_keepalive_time = 1200 net.ipv4.tcp_max_orphans = 3276800 net.ipv4.tcp_max_syn_backlog = 262144 net.ipv4.tcp_max_tw_buckets = 6000 net.ipv4.tcp_mem = 94500000 915000000 927000000 net.ipv4.tcp_rmem = 4096 87380 4194304 net.ipv4.tcp_sack = 1 net.ipv4.tcp_synack_retries = 5 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_syn_retries = 5 net.ipv4.tcp_timestamps = 0 net.ipv4.tcp_tw_recycle = 0 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_window_scaling = 1 net.ipv4.tcp_wmem = 4096 16384 4194304 vm.swappiness = 0 vm.max_map_count=262144 vm.overcommit_memory = 1 eof sysctl -p test -x /etc/init.d/procps && (service procps start || systemctl start systemd-sysctl.service) if test \"$(uname -r | awk -F'.' '{print$1}')\" -gt 3; then # https://www.bufferbloat.net/projects/codel/wiki/ echo_y \"if your kernel version >3, net.core.default_qdisc maybe need to configured.\" fi } function generate_config_file(){ echo_b \"$(date '+%Y-%m-%d %H:%M:%S.%N') generating nginx config file ...\" # /var/lib/python/python3.5_installed if [[ ! -f ${HOME}/.nginx_installed ]]; then tee /usr/local/nginx/conf/nginx.conf<<-'eof' user www; worker_processes auto; worker_rlimit_nofile 200000; error_log logs/error.log notice; pid logs/nginx.pid; events { use epoll; worker_connections 51200; multi_accept on; } http { include mime.types; client_body_timeout 10s; client_max_body_size 128M; default_type application/octet-stream; sendfile on; send_timeout 2s; tcp_nodelay on; tcp_nopush on; keepalive_timeout 65; keepalive_requests 200000; reset_timedout_connection on; server_tokens off; gzip on; gzip_min_length 10240; gzip_proxied expired no-cache no-store private auth; gzip_types text/plain text/css text/xml text/javascript application/x-javascript application/xml; gzip_disable \"MSIE [1-6]\\.\"; gzip_vary on; access_log off; open_file_cache max=200000 inactive=20s; open_file_cache_valid 30s; open_file_cache_min_uses 2; open_file_cache_errors on; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; include conf.d/*.conf; } eof test -d /usr/local/nginx/conf/conf.d && test ! -h /usr/local/nginx/conf/conf.d && rm -r /usr/local/nginx/conf/conf.d/ mkdir -p /usr/local/nginx/conf/vhost ln -s /usr/local/nginx/conf/vhost /usr/local/nginx/conf/conf.d tee /usr/local/nginx/conf/vhost/default.conf<<-eof server { listen 80; server_name localhost; access_log logs/http_default.access.log main; error_log logs/http_default.error.log warn; location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } eof wget http://nginx.org/favicon.ico -O /usr/local/nginx/html/favicon.ico nginx -t && sudo nginx -s reload fi } function clean(){ echo_b \"$(date '+%Y-%m-%d %H:%M:%S.%N') clean installation ...\" test ! -f \"${HOME}/.nginx_installed\" && touch \"${HOME}/.nginx_installed\" # cd && rm -rf ${WORKDIR} echo_g \"$(date '+%Y-%m-%d %H:%M:%S.%N') nginx installation or update finished successfully!\" } function install_nginx(){ if can_install_update; then # install echo_c \"$(date '+%Y-%m-%d %H:%M:%S.%N') begin install nginx ...\" install_base add_users download_source_packages compile_nginx_source post_install generate_config_file clean else # update echo_c \"$(date '+%Y-%m-%d %H:%M:%S.%N') begin update nginx ...\" download_source_packages compile_nginx_source post_install clean fi } function main(){ install_nginx } main #set +e"
        },
        {
            "filename": "file_475.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\SoftwareManagement\\others\\file_475.sh",
            "content": "#!/bin/bash # Created by PyCharm. # File Name: LinuxBashShellScriptForOps:install_python27_centos6.sh # Version: 0.0.1 # Author: Guodong # Author Email: dgdenterprise@gmail.com # URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps # Download URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps/tarball/master # Create Date: 2018/11/7 # Create Time: 16:35 # Description: install python2.7 into CentOS 6.x # Long Description: # Usage: # References: # Prerequisites: [] # Development Status: 3 - Alpha, 5 - Production/Stable # Environment: Console # Intended Audience: System Administrators, Developers, End Users/Desktop # License: Freeware, Freely Distributable # Natural Language: English, Chinese (Simplified) # Operating System: POSIX :: Linux # Programming Language: GNU bash :: 4+ # Topic: Utilities set -e PYTHON_VERSION=2.7.15 # current latest release version python -V ls -l `which python` which python v=`python -V |& grep -i py` [[ ${v:7:3} == 2.7 ]] && echo \"nothing need to do. now exit\" && exit 0 test -f /usr/bin/yum~ || cp -f /usr/bin/yum /usr/bin/yum~ sed -i '1 s/python$/python2.6/g' /usr/bin/yum wget -c https://www.python.org/ftp/python/${PYTHON_VERSION}/Python-${PYTHON_VERSION}.tgz wget -c https://www.python.org/ftp/python/${PYTHON_VERSION}/Python-${PYTHON_VERSION}.tgz.asc wget -c https://www.python.org/static/files/pubkeys.txt gpg --import pubkeys.txt gpg --recv-keys 6A45C816 36580288 7D9DC8D2 18ADD4FF A4135B38 A74B06BF EA5BBD71 ED9D77D5 E6DF025C AA65421D 6F5E1540 F73C700D 487034E5 gpg --verify Python-${PYTHON_VERSION}.tgz.asc tar zxf Python-${PYTHON_VERSION}.tgz cd Python-${PYTHON_VERSION}/ yum install -y gcc gcc-c++ openssl-devel ./configure --enable-shared make && make install # default installation path is '/usr/local' echo '/usr/local/lib' > /etc/ld.so.conf.d/libpython2.7.conf ldconfig /usr/local/bin/python --version ls /usr/local/bin/python* wget -c https://bootstrap.pypa.io/ez_setup.py /usr/local/bin/python ez_setup.py /usr/local/bin/easy_install --version wget -c https://bootstrap.pypa.io/get-pip.py /usr/local/bin/python get-pip.py /usr/local/bin/pip --version echo \"ATTENTIONS: default python will not take effect unless user logout current session then login again\" echo \"OK: finished.\" set +e"
        },
        {
            "filename": "file_476.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\SoftwareManagement\\php\\file_476.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File Name: LinuxBashShellScriptForOps:php7-install-update.sh # Version: 0.0.1 # Author: Guodong # Author Email: dgdenterprise@gmail.com # URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps # Download URL: https://github.com/DingGuodong/LinuxBashShellScriptForOps/tarball/master # Create Date: 2018/11/19 # Create Time: 14:04 # Description: # Long Description: # Usage: # References: # Prerequisites: [] # Development Status: 3 - Alpha, 5 - Production/Stable # Environment: Console # Intended Audience: System Administrators, Developers, End Users/Desktop # License: Freeware, Freely Distributable # Natural Language: English, Chinese (Simplified) # Operating System: POSIX :: Linux # Programming Language: GNU bash :: 4+ # Topic: Utilities set -e PHP7_VERSION=7.2.12 PHP7_SOURCE_LATEST_VERSION=php-${PHP7_VERSION} function echo_r (){ # Color red: Error, Failed [[ $# -ne 1 ]] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [[ $# -ne 1 ]] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [[ $# -ne 1 ]] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple,magenta: Debug Level 2 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [[ $# -ne 1 ]] && return 1 echo -e \"\\033[36m$1\\033[0m\" } WORKDIR=\"/tmp/.install_php7_from_source\" [[ ! -d ${WORKDIR} ]] && mkdir ${WORKDIR} [[ -d ${WORKDIR} ]] && cd ${WORKDIR} function compare_version(){ # Compare the version number with `sort -V` or directly remove the dot before comparison if test $(echo $@ | tr \" \" \"\\n\"| sort -rV | head -1) == $1; then return 0 else return 1 fi } function can_install_update(){ pass } function add_users(){ if ! grep ^www: /etc/passwd >/dev/null 2>&1; then groupadd -r www useradd -r -g www www -c \"Web user\" -d /dev/null -s /sbin/nologin fi } function is_php7_installed(){ if test -d /usr/local/nginx && test -x /usr/local/nginx/sbin/nginx || test -f ${HOME}/.nginx_installed; then # installed return 0 # return will save result to $? else # not installed by source or not installed retrun 1 # numeric argument can be 0, 1, 2, ... fi } function download_source_packages(){ [[ ! -f ${WORKDIR}/php-${PHP7_VERSION}.tar.gz ]] && wget -c http://cn.php.net/distributions/php-${PHP7_VERSION}.tar.gz } function install_base(){ # Completing Preinstallation Tasks sudo apt install -y build-essential autoconf libjpeg-turbo8-dev libpng-dev libfreetype6-dev libxslt1-dev libsystemd-dev libldap2-dev } function compile_php7_source(){ tar zxf php-${PHP7_VERSION}.tar.gz cd ${WORKDIR}/${PHP7_SOURCE_LATEST_VERSION} ./configure --prefix=/usr/local/php7 --with-config-file-path=/usr/local/php7/etc --with-config-file-scan-dir=/usr/local/php7/conf.d --enable-fpm --with-fpm-user=www --with-fpm-group=www --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-iconv-dir --with-freetype-dir --with-jpeg-dir --with-png-dir --with-zlib --with-libxml-dir --enable-xml --disable-rpath --enable-bcmath --enable-shmop --enable-sysvsem --with-fpm-systemd --enable-inline-optimization --with-curl --enable-mbregex --enable-mbstring --enable-ftp --with-gd --with-openssl --with-mhash --enable-pcntl --enable-sockets --with-xmlrpc --with-libzip --enable-soap --with-gettext --enable-fileinfo --enable-opcache --enable-intl --with-xsl --with-ldap make >/dev/null sudo make install >/dev/null } function post_install(){ sudo cp php.ini-production /usr/local/php7/etc/php.ini grep include_path /usr/local/php7/etc/php.ini sudo sed -i 's@;include_path = \".:/php/includes\"@include_path = \".:/usr/local/php7/lib/php\"@g' /usr/local/php7/etc/php.ini # sudo cp sapi/fpm/init.d.php-fpm /etc/init.d/php7-fpm # sudo chmod +x /etc/init.d/php7-fpm ls sapi/fpm/php-fpm.service sudo cp sapi/fpm/php-fpm.service /lib/systemd/system/php7-fpm.service sudo systemctl enable php7-fpm.service sudo systemctl daemon-reload sudo cp sapi/fpm/php-fpm.conf /usr/local/php7/etc/php-fpm.conf grep -v \\; /usr/local/php7/etc/php-fpm.conf | grep -v ^$ grep -v \\; /usr/local/php7/etc/php-fpm.d/www.conf.default | grep -v ^$ grep -v \\; /usr/local/php7/etc/php-fpm.d/www.conf.default | grep -v ^$ | sudo tee /usr/local/php7/etc/php-fpm.d/www.conf cat /usr/local/php7/etc/php-fpm.d/www.conf sudo sed -i 's/listen = 127.0.0.1:9000/listen = 127.0.0.1:9001/g' /usr/local/php7/etc/php-fpm.d/www.conf cat /usr/local/php7/etc/php-fpm.d/www.conf sudo systemctl start php7-fpm.service systemctl status php7-fpm.service netstat -anop | grep 9001 } function optimize_security_rules(){ # Checking Resource Limits # https://docs.oracle.com/cd/B28359_01/install.111/b32002/pre_install.htm#LADBI246 # https://docs.oracle.com/en/database/oracle/oracle-database/18/ladbi/checking-resource-limits-for-oracle-software-installation-users.html#GUID-293874BD-8069-470F-BEBF-A77C06618D5A cp /etc/security/limits.d/www.conf /etc/security/limits.d/www.conf$(date +%Y%m%d%H%M%S)~ tee /etc/security/limits.d/www.conf<<'eof' www soft nproc 16384 www hard nproc 16384 www soft nofile 65536 www hard nofile 65536 eof #ulimit -Sn # Check the soft and hard limits for the file descriptor setting. #ulimit -Hn #ulimit -Su # Check the soft and hard limits for the number of processes available to a user. #ulimit -Hu #ulimit -Ss # Check the soft limit for the stack setting. #ulimit -Hs } function optimize_kernel_parameters(){ # Configuring Kernel Parameters for Linux # http://docs.oracle.com/cd/B28359_01/install.111/b32002/pre_install.htm#LADBI246 # https://docs.oracle.com/en/database/oracle/oracle-database/18/ladbi/minimum-parameter-settings-for-installation.html#GUID-CDEB89D1-4D48-41D9-9AC2-6AD9B0E944E3 # https://docs.oracle.com/en/database/oracle/oracle-database/18/ladbi/changing-kernel-parameter-values.html#GUID-FB0CC366-61C9-4AA2-9BE7-233EB6810A31 cp /etc/sysctl.conf /etc/sysctl.conf$(date +%Y%m%d%H%M%S)~ cat >/etc/sysctl.conf<<eof # http://docs.oracle.com/cd/B28359_01/install.111/b32002/pre_install.htm#LADBI246 fs.aio-max-nr = 1048576 fs.file-max = 6815744 kernel.core_uses_pid = 1 kernel.hung_task_timeout_secs = 0 kernel.msgmax = 65536 kernel.msgmnb = 65536 kernel.sem = 250 32000 100 128 kernel.shmall gc_stale_time= 4294967295 kernel.shmmax = 68719476736 kernel.shmmni = 4096 kernel.sysrq = 0 net.core.netdev_max_backlog = 262144 net.core.rmem_default = 8388608 net.core.rmem_max = 16777216 net.core.somaxconn = 262144 net.core.wmem_default = 8388608 net.core.wmem_max = 16777216 net.ipv4.conf.default.accept_source_route = 0 net.ipv4.conf.default.rp_filter = 1 net.ipv4.ip_forward = 0 net.ipv4.ip_local_port_range = 9000 65500 net.ipv4.tcp_fin_timeout = 1 net.ipv4.tcp_keepalive_time = 1200 net.ipv4.tcp_max_orphans = 3276800 net.ipv4.tcp_max_syn_backlog = 262144 net.ipv4.tcp_max_tw_buckets = 6000 net.ipv4.tcp_mem = 94500000 915000000 927000000 net.ipv4.tcp_rmem = 4096 87380 4194304 net.ipv4.tcp_sack = 1 net.ipv4.tcp_synack_retries = 5 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_syn_retries = 5 net.ipv4.tcp_timestamps = 0 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_window_scaling = 1 net.ipv4.tcp_wmem = 4096 16384 4194304 vm.swappiness = 0 m.max_map_count=262144 eof sysctl -p test -x /etc/init.d/procps && (service procps start || systemctl start systemd-sysctl.service) if test $(uname -r | awk -F'.' '{print$1}') -gt 3; then # https://www.bufferbloat.net/projects/codel/wiki/ echo_y \"if your kernel version >3, net.core.default_qdisc maybe need to configured.\" fi } function generate_config_file(){ grep post_max_size /usr/local/php7/etc/php.ini grep max_input_time /usr/local/php7/etc/php.ini grep date.timezone /usr/local/php7/etc/php.ini grep max_execution_time /usr/local/php7/etc/php.ini sudo sed -i 's/post_max_size = 8M/post_max_size = 16M/g' /usr/local/php7/etc/php.ini sudo sed -i 's/max_input_time = 60/max_input_time = 300/g' /usr/local/php7/etc/php.ini sudo sed -i 's@;date.timezone =@date.timezone = Asia/Shanghai@g' /usr/local/php7/etc/php.ini sudo sed -i 's/max_execution_time = 30/max_execution_time = 300/g' /usr/local/php7/etc/php.ini sudo sed -i 's/;always_populate_raw_post_data = -1/always_populate_raw_post_data = -1/g' /usr/local/php7/etc/php.ini sudo systemctl restart php7-fpm.service systemctl status php7-fpm.service } function clean(){ test ! -f ${HOME}/.php7_installed && touch ${HOME}/.php7_installed cd && rm -rf ${WORKDIR} echo_g \"PHP7 installation or update finished successfully!\" } function install_php7(){ can_install_update install_base add_users download_source_packages compile_php7_source post_install if ! is_php7_installed; then generate_config_file fi clean } function main(){ install_php7 } main set +e"
        },
        {
            "filename": "file_477.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\SoftwareManagement\\yum\\file_477.sh",
            "content": "#!/usr/bin/env bash # Created by PyCharm. # File: LinuxBashShellScriptForOps:yum_update_packages_safely.sh # User: Guodong # Create Date: 2017/8/11 # Create Time: 18:23 # Function: # Note: # Prerequisite: # Description: we can NOT use 'yum update -y' to update all packages on production environment, # Reference: ## yum repolist #Loaded plugins: langpacks #repo id repo name status #base/7/x86_64 CentOS-7 - Base 9,363 #docker-main-repo Docker main Repository 110 #epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 11,785 #extras/7/x86_64 CentOS-7 - Extras 449 #gitlab-ce gitlab-ce 285 #gitlab_gitlab-ce/x86_64 gitlab_gitlab-ce 285 #gitlab_gitlab-ce-source gitlab_gitlab-ce-source 0 #runner_gitlab-ci-multi-runner/x86_64 runner_gitlab-ci-multi-runner 101 #runner_gitlab-ci-multi-runner-source runner_gitlab-ci-multi-runner-source 0 #updates/7/x86_64 CentOS-7 - Updates 2,146 #repolist: 24,524 repo_list=\"`yum repolist | sed '1,3d;$d' | awk '{print $1}' | xargs | sed 's/\\ /,/g'`\" packages_list=\"`yum check-update | sed '1,3d' | awk '{print $1}'| xargs`\" wanted_repo_list=\"base,epel,extras,updates\" unwanted_packages_list=\"gitlab-ce,gitlab-ci-multi-runner,docker-engine,docker-engine-selinux\" # TODO(Guodong Ding) NO QA yum update --enablerepo=${wanted_repo_list} || yum update --exclude=${unwanted_packages_list}"
        },
        {
            "filename": "file_478.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\SoftwareManagement\\zabbix\\zabbix-database-partition\\Zabbix-MySQL-Partitioning\\file_478.sh",
            "content": "#!/bin/bash echo \"Partitioned table maintenance tasks begin at $(date +%Y%m%d%H%M%S).\" >/tmp/partition_maintenance_all_mail.tmp # shellcheck disable=SC2129 echo '' >>/tmp/partition_maintenance_all_mail.tmp mysql -D zabbix -e 'CALL partition_maintenance_all(\"zabbix\");' >>/tmp/partition_maintenance_all_mail.tmp 2>&1 echo '' >>/tmp/partition_maintenance_all_mail.tmp echo \"Partitioned table maintenance tasks finish at $(date +%Y%m%d%H%M%S).\" >>/tmp/partition_maintenance_all_mail.tmp #cat /tmp/partition_maintenance_all_mail.tmp | mailx -r 'ITmonitor@didichuxing.com' -s 'Partitioned table maintenance' gaoyuebruce@didiglobal.com CURL_DATA=\"{ \\\"content\\\": \\\"$(sed \":a;N;s/\\n/<br \\/>/;s/\\t/ /g;ta\" /tmp/partition_maintenance_all_mail.tmp)\\\", \\\"sender\\\": \\\"erpmonitor@didiglobal.com\\\", \\\"subject\\\": \\\"Partitioned table maintenance\\\", \\\"tos\\\": [ \\\"gaoyuebruce@didiglobal.com\\\" ] } \" curl -X POST --header \"Content-Type: application/json\" --header \"Accept: */*\" -d \"$CURL_DATA\" \"http://10.89.139.46:8088/api/v2/notification/email/send?token=\u3010token\u503c\u3011\""
        },
        {
            "filename": "file_479.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\System\\file_479.sh",
            "content": "#!/usr/bin/env bash echo \"create Swap which has same size of Memory\" free -b DATA_PARTITION=\"/opt\" time dd if=/dev/zero of=$DATA_PARTITION/swap bs=512 count=$(($(free -b|awk '/Mem:/{print$2}') / 512)) chmod 600 $DATA_PARTITION/swap mkswap $DATA_PARTITION/swap sysctl -w vm.swappiness=10 swapon $DATA_PARTITION/swap cp /etc/fstab /etc/fstab\"$(date +%Y%m%d%H%M%S)\"~ echo \"$DATA_PARTITION/swap swap swap defaults 0 0\" >> /etc/fstab free -b"
        },
        {
            "filename": "file_480.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\System\\systemOsInit\\file_480.sh",
            "content": "#!/usr/bin/env bash # # Function description: # Use this script to initialize system after full refresh installation # Do NOT modify anything expect for \"user defined variables\" unless you know what it means and what are you doing. # Try most best to refer to more general and minimal principle, UNIX philosophy # # Usage: # bash centos6-init.sh # # Birth Time: # 2016-05-17 10:19:33.005064327 +0800 # # Author: # Open Source Software written by 'Guodong Ding <dgdenterprise@gmail.com>' # Blog: http://dgd2010.blog.51cto.com/ # Github: https://github.com/DingGuodong # # debug option #_XTRACE_FUNCTIONS=$(set +o | grep xtrace) #set -o xtrace # define user friendly messages header=\" Use this script to initialize system after full refresh installation \" # user defined variables user_defined_hostname=\"\" user_defined_username=\"\" user_defined_user_can_run_sudo=true # true or false user_defined_log_absolute_path=\"\" # end user defined variables # pretreatment # end pretreatment # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=$(ls -ld \"$PRG\") link=$(expr \"$ls\" : '.*-> \\(.*\\)$') if expr \"$link\" : '/.*' >/dev/null; then PRG=\"$link\" else PRG=$(dirname \"$PRG\")/\"$link\" fi done # Get standard environment variables PRGDIR=$(dirname \"$PRG\") # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r() { # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g() { # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y() { # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b() { # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p() { # Color purple: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c() { # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=$(readlink -f \"${PRGDIR}\") # end public header # ============================================================================================================================= USER=\"$(id -un)\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo_y \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options.\" echo_y \"Retry to using \\\"sudo bash $0 $*\\\".\" fi command_exists() { # which \"$@\" >/dev/null 2>&1 command -v \"$@\" >/dev/null 2>&1 } check_command_can_be_execute() { [ $# -ne 1 ] && return 1 command_exists \"$1\" } function check_user_defined_variables() { test -z ${user_defined_hostname} test -z ${user_defined_username} test -z ${user_defined_user_can_run_sudo} test -z ${user_defined_log_absolute_path} } function backup_single_file() { set -o errexit if [ \"$#\" -ne 1 ]; then return 1 fi backup_filename_origin=\"$1\" operation_date_time=$(date +\"%Y%m%d%H%M%S\") backup_filename_prefix=\".backup_\" backup_filename_suffix=\"_origin_$operation_date_time~\" backup_filename_target=\"$backup_filename_prefix$backup_filename_origin$backup_filename_suffix\" test -f \"${backup_filename_origin}\" && cp \"${backup_filename_origin}\" \"${backup_filename_target}\" set +o errexit } # Function description: backup files without directory support # Note: accept $@ parameters, such as '$0 file1 file2 file3' # Usage: backup_files $@ || rollback_files backup_files() { set -o errexit if [ \"$#\" -eq 0 ]; then return 1 fi file_list=$* operation_date_time=\"_$(date +\"%Y%m%d%H%M%S\")\" log_filename=\".log_$0_$$_$RANDOM\" if test -z ${user_defined_log_absolute_path}; then log_filename_full_path=/tmp/${log_filename} else log_filename_full_path=${user_defined_log_absolute_path} fi touch ${log_filename_full_path} old_IFS=$IFS IFS=\" \" for file in ${file_list}; do # is there a bin named 'realpath' ? real_file=$(readlink -f \"${file}\") [ -f \"${real_file}\" ] && cp \"${real_file}\" \"${file}${operation_date_time}~\" [ -f ${log_filename_full_path} ] && echo \"\\mv -f $file$operation_date_time~ $file\" >>${log_filename_full_path} done IFS=\"$old_IFS\" set +o errexit return 0 } # Function description: rollback files rollback_files() { # shellcheck source=/tmp/some.sh [ -f ${log_filename_full_path} ] && . ${log_filename_full_path} \\rm -f ${log_filename_full_path} exit 2 } check_network_connectivity() { echo_b \"checking network connectivity ... \" network_address_to_check=8.8.4.4 stable_network_address_to_check=114.114.114.114 ping_count=2 ping -c ${ping_count} ${network_address_to_check} >/dev/null retval=$? if [ ${retval} -ne 0 ]; then if ping -c ${ping_count} ${stable_network_address_to_check} >/dev/null; then echo_g \"Network to $stable_network_address_to_check succeed! \" echo_y \"Note: network to $network_address_to_check failed once! maybe just some packages loss.\" elif ! ip route | grep default >/dev/null; then echo_r \"Network is unreachable, gateway is not set.\" exit 1 elif ! ping -c2 \"$(ip route | awk '/default/ {print $3}')\" >/dev/null; then echo_r \"Network is unreachable, gateway is unreachable.\" exit 1 else echo_r \"Network is blocked! \" exit 1 fi elif [ ${retval} -eq 0 ]; then echo_g \"Check network connectivity passed! \" fi } check_name_resolve() { echo_b \"checking DNS name resolve ... \" target_name_to_resolve=\"github.com\" stable_target_name_to_resolve=\"www.aliyun.com\" ping_count=1 if ! ping -c${ping_count} ${target_name_to_resolve} >/dev/null; then echo_y \"Name lookup failed for $target_name_to_resolve with $ping_count times \" if ping -c${ping_count} ${stable_target_name_to_resolve} >/dev/null; then echo_g \"Name lookup success for $stable_target_name_to_resolve with $ping_count times \" fi eval_md5sum_of_nameserver_config=\"$(md5sum /etc/resolv.conf | awk '{ print $1 }')\" if test \"${eval_md5sum_of_nameserver_config}\" = \"674ea91675cdfac353bffbf49dc593c3\"; then echo_y \"Nameserver config file is validated, but name lookup failed for $target_name_to_resolve with $ping_count times\" return 0 fi [ -f /etc/resolv.conf ] && cp /etc/resolv.conf \"/etc/resolv.conf_$(date +%Y%m%d%H%M%S)~\" cat >/etc/resolv.conf <<eof nameserver 114.114.114.114 nameserver 8.8.4.4 eof check_name_resolve else echo_g \"Check DNS name resolve passed! \" return 0 fi } function set_hosts_file() { hosts_url=\"https://raw.githubusercontent.com/racaljk/hosts/master/hosts\" http_code=$(curl -o /dev/null -m 10 --connect-timeout 10 -s -w \"%{http_code}\" ${hosts_url}) if test \"${http_code}\" -ne 200; then hosts_url=\"https://coding.net/u/scaffrey/p/hosts/git/raw/master/hosts\" fi backup_single_file /etc/hosts bash -c 'wget ${hosts_url} -qO /tmp/hosts && mv -f /tmp/hosts /etc/hosts' # TODO(Guodong Ding) dos2unix # if cat -A /etc/hosts | grep '\\^M\\\\\\$' >/dev/null || file /etc/hosts | grep \"with CRLF line terminators\" >/dev/null ; then # which dos2unix >/dev/null 2>&1 || yum -q -y install dos2unix || apt-get -qq -y install dos2unix # dos2unix /etc/hosts >/dev/null # fi # check if able to resolve host `hostname -f`, if not, sudo will throw a exception 'sudo: unable to resolve host xxx' echo \"127.0.0.1 $(hostname) $(hostname -f)\" >>/etc/hosts echo \"$(ip addr show scope global \"$(ip route | awk '/^default/ {print $NF}')\" | awk -F '[ /]+' '/global/ {print $3}') $(hostname) $(hostname -f)\" >>/etc/hosts SELINUX_STATE=$(cat \"/selinux/enforce\") [ -n \"$SELINUX_STATE\" ] && [ -x /sbin/restorecon ] && /sbin/restorecon /etc/hosts } function set_hostname_fqdn_format() { current_hostname_fqdn=\"$(hostname -A)\" dot_appear_times_to_match_fqdn_rule=$(echo \"$current_hostname_fqdn\" | grep -o '\\.' | wc -l) if test \"${dot_appear_times_to_match_fqdn_rule}\" -gt 1; then echo_g \"current hostname $current_hostname_fqdn is a fqdn name, check passed! \" else if test ! -z ${user_defined_hostname}; then new_hostname_to_set=\"$user_defined_hostname\" else read -rp 'Input hostname you want, then press Enter ' user_input_hostname new_hostname_to_set=\"$user_input_hostname\" fi test -f /etc/hostname && echo \"$new_hostname_to_set\" >/etc/hostname (test -f /etc/hostname && hostname -b -F /etc/hostname) || hostname \"$new_hostname_to_set\" test -f /etc/sysconfig/network && sed -i \"s/^HOSTNAME=.*.$/HOSTNAME=$new_hostname_to_set/g\" /etc/sysconfig/network fi ipaddress_global_routing=\"$(ip addr show scope global \"$(ip route | awk '/^default/ {print $NF}')\" | awk -F '[ /]+' '/global/ {print $3}')\" grep -v -E \"($ipaddress_global_routing|$new_hostname_to_set)\" /etc/hosts >/dev/null 2>&1 && echo \"$ipaddress_global_routing $new_hostname_to_set\" >>/etc/hosts } function yum_install_base_packages() { yum -y install vim wget curl perl unzip man man-pages man-pages-overrides bind-utils net-tools >/dev/null 2>&1 } function yum_repository_config() { yum -y install http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm >/dev/null 2>&1 } function yum_install_extra_packages() { # Programmable completion for Bash yum info bash-completion >/dev/null 2>&1 && yum -y install bash-completion >/dev/null 2>&1 # Ask the user to install command line programs automatically yum info PackageKit-command-not-found >/dev/null 2>&1 && yum -y install PackageKit-command-not-found >/dev/null 2>&1 # Bash tab completion for argparse yum info python-argcomplete >/dev/null 2>&1 && yum -y install python-argcomplete >/dev/null 2>&1 yum -y update } function set_limits() { backup_single_file /etc/security/limits.conf cat >>/etc/security/limits.conf <<eof # refer to the free inodes number, by \"df -i\" commands * soft nofile 200000 * hard nofile 200000 * soft nproc 16384 * hard nproc 16384 eof if [[ -f /etc/security/limits.d/90-nproc.conf ]]; then mv /etc/security/limits.d/90-nproc.conf /etc/security/limits.d/90-nproc.conf~ fi } function customized_commands() { # customized commands, alternatively, echo into .bashrc file as a function or alias cat >/usr/local/bin/delsc <<'eof' #!/bin/bash # delete all spaces and comments of specialized file [[ \"$1\" == \"\" ]] && echo \"usage: delete all spaces and comments of specialized file, using with \\\"$0 filename\\\"\" && exit 1 if cat -A \"$1\" | grep '\\^M\\$' >/dev/null || file \"$1\" | grep \"with CRLF line terminators\" >/dev/null ; then command -v dos2unix >/dev/null 2>&1 || yum -q -y install dos2unix || apt-get -qq -y install dos2unix dos2unix \"$1\" >/dev/null fi if test -f \"$1\" && file \"$1\" | grep \"XML\" >/dev/null; then command -v tidy >/dev/null 2>&1 || yum -q -y install tidy || apt-get -qq -y install tidy tidy -quiet -asxml -xml -indent -wrap 1024 --hide-comments 1 \"$1\" elif test -f \"$1\"; then grep -v \\# \"$1\" | grep -v ^\\; |grep -v ^$ | grep -v \"^\\ *$\" fi # Others: # sed -e '/^#/d;/^$/d' # Refer: https://github.com/mysfitt/nocomment/blob/master/nocomment.sh # grep -Ev '^\\s*#|^//|^\\s\\*|^/\\*|^\\*/' | grep -Ev '^$|^\\s+$' eof chmod +x /usr/local/bin/delsc SELINUX_STATE=$(cat \"/selinux/enforce\") [ -n \"$SELINUX_STATE\" ] && [ -x /sbin/restorecon ] && /sbin/restorecon -r /usr/local/bin } function inject_ssh_key_for_root() { ## Allow us to SSH passwordless to localhost # ssh-keygen -f ~/.ssh/id_rsa -N \"\" # cp ~/.ssh/{id_rsa.pub,authorized_keys} ## Creation of an SSH agent for testing forwarding # eval $(ssh-agent) # ssh-add test ! -d /root/.ssh && ssh-keygen -N \"\" -f /root/.ssh/id_rsa test ! -f /root/.ssh/authorized_keys && cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys cat >>/root/.ssh/authorized_keys <<eof ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCawuOgQup3Qc1OILytyH+u3S9te85ctEKTvzPtRjHfnEEOjpRS6v6/PsuDHplHO1PAm8cKbEZmqR9tg4mWSweosBYW7blUUB4yWfBu6cHAnJOZ7ADNWHHJHAYi8QFZd4SLAAKbf9J12Xrkw2qZkdUyTBVbm+Y8Ay9bHqGX7KKLhjt0FIqQHRizcvncBFHXbCTJWsAduj2i7GQ5vJ507+MgFl2ZTKD2BGX5m0Jq9z3NTJD7fEb2J6RxC9PypYjayXyQBhgACxaBrPXRdYVXmy3f3zRQ4/OmJvkgoSodB7fYL8tcUZWSoXFa33vdPlVlBYx91uuA6onvOXDnryo3frN1 ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAIEAumQ2srRwd9slaeYTdr/dGd0H4NzJ3uQdBQABTe/nhJsUFWVG3titj7JiOYjCb54dmpHoi4rAYIElwrolQttZSCDKTVjamnzXfbV8HvJapLLLJTdKraSXhiUkdS4D004uleMpaqhmgNxCLu7onesCCWQzsNw9Hgpx5Hicpko6Xh0= eof SELINUX_STATE=$(cat \"/selinux/enforce\") ([ -n \"$SELINUX_STATE\" ] && [ -x /sbin/restorecon ] && /sbin/restorecon -r /root/.ssh) || chcon --user=system_u --role=object_r --type=net_conf_t --range=s0 /etc/hosts } function bashrc_setting() { backup_single_file ~/.bashrc # history related # HISTTIMEFORMAT # PROMPT_COMMAND # Refer: http://dl528888.blog.51cto.com/2382721/1703059 # Refer: http://www.tldp.org/HOWTO/Bash-Prompt-HOWTO/x264.html # TODO(Guodong Ding) a known issue, it will make user confused when a command line include a double quotes(\"), because is not a valid json any more # like this \"{\"TIME\":\"2016-05-18 15:43:14\", \"HOSTNAME\":\"chris.51devops.com\", \"IP\":\"10.20.0.1\", \"LOGIN\":\"root\", \"USER\":\"root\", \"CMD\":\"export PROMPT_COMMAND='history 1|tail -1|sed \"s/^[ ]\\+[0-9]\\+ //\"|sed \"s/^/{/\"|sed \"s/$/\\\"}/\">> /var/log/command.log'\"}\" if ! grep HISTTIMEFORMAT ~/.bashrc && ! grep PROMPT_COMMAND; then cat >>~/.bashrc <<eof export HISTTIMEFORMAT=\"\\\"TIME\\\":\\\"%F %T\\\", \\\"HOSTNAME\\\":\\\"$HOSTNAME\\\", \\\"IP\\\":\\\"\\$(who -u am i 2>/dev/null| awk '{print \\$NF}'|sed -e 's/[()]//g')\\\", \\\"LOGIN\\\":\\\"\\$(who am i|awk '{print \\$1}')\\\", \\\"USER\\\":\\\"\\${USER}\\\", \\\"CMD\\\":\\\"\" export PROMPT_COMMAND='history 1|tail -1|sed \"s/^[ ]\\+[0-9]\\+ //\"|sed \"s/^/{/\"|sed \"s/$/\\\"}/\">> /var/log/.command_history.log' eof fi } function update_local_time() { if ! grep -qa CST-8 /etc/localtime || ! diff /etc/localtime /usr/share/zoneinfo/Asia/Shanghai >/dev/null 2>&1; then rm -rf /etc/localtime ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime fi ntpdate -u pool.ntp.org >/dev/null 2>&1 || ntpdate -u time.nist.gov >/dev/null 2>&1 || ntpdate -u time-nw.nist.gov >/dev/null 2>&1 date cat >>/etc/rc.local <<eof ntpdate -u pool.ntp.org || ntpdate -u time.nist.gov || ntpdate -u time-nw.nist.gov hwclock -w eof # Recommended do touch /etc/cron.daily/ntpdate chown -R --reference=/etc/cron.daily/logrotate /etc/cron.daily/ntpdate chmod -R --reference=/etc/cron.daily/logrotate /etc/cron.daily/ntpdate chcon -R --reference=/etc/cron.daily/logrotate /etc/cron.daily/ntpdate >/dev/null 2>&1 cat >>/etc/cron.daily/ntpdate <<eof ntpdate -u pool.ntp.org >/dev/null 2>&1 || ntpdate -u time.nist.gov >/dev/null 2>&1 || ntpdate -u time-nw.nist.gov >/dev/null 2>&1 hwclock -w eof } function system_performance_tuning() { cp /etc/security/limits.conf \"/etc/security/limits.conf_origin_$(date +%Y%m%d%H%M%S)~\" cat >>/etc/security/limits.conf <<eof # refer to the free inodes number, by \"df -i\" commands * soft nofile 200000 * hard nofile 200000 eof cp /etc/sysctl.conf \"/etc/sysctl.conf_origin_$(date +%Y%m%d%H%M%S)~\" cat >/etc/sysctl.conf <<eof fs.file-max = 808127 kernel.core_uses_pid = 1 kernel.hung_task_timeout_secs = 0 kernel.msgmax = 65536 kernel.msgmnb = 65536 kernel.sem = 250 32000 100 128 kernel.shmall = 4294967296 kernel.shmmax = 536870912 kernel.shmmax = 68719476736 kernel.shmmni = 4096 kernel.sysrq = 0 net.core.netdev_max_backlog = 262144 net.core.rmem_default = 8388608 net.core.rmem_max = 16777216 net.core.somaxconn = 262144 net.core.wmem_default = 8388608 net.core.wmem_max = 16777216 net.ipv4.conf.default.accept_source_route = 0 net.ipv4.conf.default.rp_filter = 1 net.ipv4.ip_forward = 0 net.ipv4.ip_local_port_range = 1024 65535 net.ipv4.tcp_fin_timeout = 1 net.ipv4.tcp_keepalive_time = 1200 net.ipv4.tcp_max_orphans = 3276800 net.ipv4.tcp_max_syn_backlog = 262144 net.ipv4.tcp_max_tw_buckets = 6000 net.ipv4.tcp_mem = 94500000 915000000 927000000 net.ipv4.tcp_rmem = 4096 87380 4194304 net.ipv4.tcp_sack = 1 net.ipv4.tcp_synack_retries = 5 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_syn_retries = 5 net.ipv4.tcp_timestamps = 0 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_window_scaling = 1 net.ipv4.tcp_wmem = 4096 16384 4194304 vm.swappiness = 30 eof # TODO(Guodong Ding) OOM(sysctl -a | grep oom) # TODO(Guodong Ding) 5% reserved-blocks-percentage(tune2fs, dump2fs, man tune2fs) # TODO(Guodong Ding) Forward & redirects #net.ipv4.ip_forward = 1 #net.ipv4.ip_forward_use_pmtu = 0 #net.ipv4.conf.default.accept_source_route = 0 #net.ipv4.conf.all.rp_filter = 2 #net.ipv4.conf.default.rp_filter = 2 #net.ipv4.conf.all.accept_redirects = 1 #net.ipv4.conf.default.accept_redirects = 1 #net.ipv4.conf.all.secure_redirects = 1 #net.ipv4.conf.default.secure_redirects = 1 #net.ipv4.conf.all.send_redirects = 1 #net.ipv4.conf.default.send_redirects = 1 sysctl -p >/dev/null 2>&1 } # TODO(Guodong Ding) noatime(man mount), fstab is only read by programs, and not written; it is the duty of the system \\ # administrator to properly create and maintain this file. # rw, suid, dev, exec, auto, nouser, async, and noatime # TODO(Guodong Ding) more points function ssh_config() { if grep \"^#UseDNS\" /etc/ssh/sshd_config >/dev/null 2>&1 && ! grep \"UseDNS no\" /etc/ssh/sshd_config >/dev/null 2>&1; then cp /etc/ssh/sshd_config \"/etc/ssh/sshd_config_origin_$(date +%Y%m%d%H%M%S)~\" sed -i \"s/^#UseDNS.*.$/UseDNS no/g\" /etc/ssh/sshd_config # sed -i 's/GSSAPIAuthentication yes/GSSAPIAuthentication no/' /etc/ssh/sshd_config service sshd restart fi } # TODO(Guodong Ding) Reducing Disk IO By Mounting Partitions With noatime # Refer: https://www.howtoforge.com/reducing-disk-io-by-mounting-partitions-with-noatime # Refer: man 8 mount function add_user_as_user_defined() { if test -z ${user_defined_username}; then return 0 else useradd ${user_defined_username} test -d /etc/sudoers.d && echo \"$user_defined_username ALL=(ALL) NOPASSWD: ALL\" >/etc/sudoers.d/user_${user_defined_username}.conf fi } function initialize() { check_network_connectivity check_name_resolve set_hostname_fqdn_format yum_install_base_packages yum_repository_config yum_install_extra_packages customized_commands inject_ssh_key_for_root bashrc_setting update_local_time system_performance_tuning ssh_config } function main() { lock_filename=\"lock_$$_$RANDOM\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber echo \"$$\" >\"$lock_filename_full_path\" ) 2>/dev/null; then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT # Just a test for call itself, comment it if [[ $# -ne 1 ]]; then [ ! -x \"${WORKDIR}\"/\"$(basename \"$0\")\" ] && chmod +x \"${WORKDIR}\"/\"$(basename \"$0\")\" test -z \"${header}\" || echo_b \"$header\" \"${WORKDIR}\"/\"$(basename \"$0\")\" initialize exit 0 fi case $1 in initialize) initialize ;; help | *) test -z \"${header}\" || echo_b \"$header\" echo \"Usage: $0 {initialize} with $0 itself\" exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main \"$*\" # debug option #${_XTRACE_FUNCTIONS}"
        },
        {
            "filename": "file_481.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\LinuxSystemOps\\System\\systemOsInit\\file_481.sh",
            "content": "#!/usr/bin/env bash # Usage: bash $0 # Author: dgden # Create Date: 2020/9/14 # Create Time: 15:41 # Description: using sudo without input password if [[ \"$USER\" == \"root\" ]]; then echo \"FATAL ERROR: do NOT use root or sudo to execute $0\" exit 1 else # https://www.quora.com/Who-wrote-the-message-that-comes-up-when-you-use-sudo-for-the-first-time echo \" \\\"\\\"\\\" We trust you have received the usual lecture from the local System Administrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility. \\\"\\\"\\\" \" fi sudo tee /etc/sudoers.d/\"$USER\" <<eof $USER ALL=(ALL) NOPASSWD: ALL eof sudo visudo -cf /etc/sudoers.d/\"$USER\""
        },
        {
            "filename": "file_482.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\others\\file_482.sh",
            "content": "#!/bin/bash # Name: startDockerContainersFirstTime.sh # Execute this shell script to start Docker containers first time, useful for system normal or exception to shut down or outage # Do NOT modify anything expect for \"user defined variables\" unless you know what it means and what are you doing. # debug option #_XTRACE_FUNCTIONS=$(set +o | grep xtrace) #set -o xtrace # define user friendly messages header=\" Execute this shell script to start Docker containers first time, useful for system normal or exception to shut down or outage. \" # user defined variables docker_interconnection_network_name=\"\" # end user defined variables # pretreatment # end pretreatment # Public header # ============================================================================================================================= # resolve links - $0 may be a symbolic link # learn from apache-tomcat-6.x.xx/bin/catalina.sh PRG=\"$0\" while [ -h \"$PRG\" ]; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*-> \\(.*\\)$'` if expr \"$link\" : '/.*' > /dev/null; then PRG=\"$link\" else PRG=`dirname \"$PRG\"`/\"$link\" fi done # Get standard environment variables PRGDIR=`dirname \"$PRG\"` # echo color function, smarter, learn from lnmp.org lnmp install.sh function echo_r (){ # Color red: Error, Failed [ $# -ne 1 ] && return 1 echo -e \"\\033[31m$1\\033[0m\" } function echo_g (){ # Color green: Success [ $# -ne 1 ] && return 1 echo -e \"\\033[32m$1\\033[0m\" } function echo_y (){ # Color yellow: Warning [ $# -ne 1 ] && return 1 echo -e \"\\033[33m$1\\033[0m\" } function echo_b (){ # Color blue: Debug Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[34m$1\\033[0m\" } function echo_p (){ # Color purple: Debug Level 2 [ $# -ne 1 ] && return 1 echo -e \"\\033[35m$1\\033[0m\" } function echo_c (){ # Color cyan: friendly prompt, Level 1 [ $# -ne 1 ] && return 1 echo -e \"\\033[36m$1\\033[0m\" } # end echo color function, smarter #WORKDIR=\"`realpath ${WORKDIR}`\" WORKDIR=\"`readlink -f ${PRGDIR}`\" # end public header # ============================================================================================================================= USER=\"`id -un`\" LOGNAME=\"$USER\" if [ $UID -ne 0 ]; then echo \"WARNING: Running as a non-root user, \\\"$LOGNAME\\\". Functionality may be unavailable. Only root can use some commands or options\" fi function startDockerService(){ docker_pid=\"`ps -ef | grep '[d]ocker daemon' | awk '{print $2}'`\" if test -z ${docker_pid} ; then test -x /etc/init.d/docker && service docker start || /etc/init.d/docker start if test $? -ne 0 ; then if test ! -f /var/log/docker; then echo_r \"Error: Docker engine service start failed! \" echo_b \"try to use \\\"docker daemon\\\" see what failure occurs during start Docker engine service.\" docker daemon else echo_r \"Error: Docker engine service start failed! \" echo_b \"see file \\\"/var/log/docker\\\" for more details\" fi else docker_pid=\"`ps -ef | grep '[d]ocker daemon' | awk '{print $2}'`\" echo_g \"Docker engine service is running, process $docker_pid\" fi else echo_g \"Docker engine service is already running, process $docker_pid.\" fi } function checkDockerServiceStatus(){ docker_pid=\"`ps -ef | grep '[d]ocker daemon' | awk '{print $2}'`\" if test -z ${docker_pid} ; then echo_g \"Docker engine service is running, process $docker_pid\" else echo_r \"Docker engine service is outage, try start it if we can\" startDockerService fi } function checkDockerNetworkStatus(){ test -z ${docker_interconnection_network_name} || docker_interconnection_network_name=\"docker_connection\" docker network inspect ${docker_interconnection_network_name} >/dev/null 2>&1 if test $? -ne 0 ; then docker network create ${docker_interconnection_network_name} checkDockerNetworkStatus else echo_g \"Docker network check passed! \" fi } function startDockerContainersMemcached(){ docker run --restart=\"always\" -d -v /etc/localtime:/etc/localtime --name memcached-os-static memcached docker run --restart=\"always\" -d -v /etc/localtime:/etc/localtime --name memcached-os-dynamic memcached memcached -m 128 docker run --restart=\"always\" -d -v /etc/localtime:/etc/localtime --name memcached-bs-static memcached docker run --restart=\"always\" -d -v /etc/localtime:/etc/localtime --name memcached-bs-dynamic memcached memcached -m 128 docker run --restart=\"always\" -d -v /etc/localtime:/etc/localtime --name memcached-activity memcached memcached -m 128 docker run --restart=\"always\" -d -v /etc/localtime:/etc/localtime --name memcached-envelope memcached memcached docker network connect docker_connection memcached-os-static docker network connect docker_connection memcached-os-dynamic docker network connect docker_connection memcached-bs-static docker network connect docker_connection memcached-bs-dynamic docker network connect docker_connection memcached-activity docker network connect docker_connection memcached-envelope } function startDockerContainersActiveMQ(){ docker run --restart=\"always\" -d --name amq-server \\ -e 'ACTIVEMQ_MIN_MEMORY=512' \\ -e 'ACTIVEMQ_MAX_MEMORY=2048' \\ -e 'ACTIVEMQ_NAME=amqp-srv1' \\ -e 'ACTIVEMQ_ADMIN_LOGIN=my_username' \\ -e 'ACTIVEMQ_ADMIN_PASSWORD=my_password' \\ -e 'ACTIVEMQ_ENABLED_SCHEDULER=true' \\ -v /data/docker/amq-server/data:/data/activemq \\ -v /data/docker/amq-server/logs:/var/log/activemq \\ -v /etc/localtime:/etc/localtime \\ -p 10201:8161 \\ -p 10202:61616 \\ -p 10203:61613 \\ webcenter/activemq docker network connect docker_connection amq-server } function startDockerContainersRedis(){ docker run -d --restart=\"always\" --name redis-os \\ -v /data/docker/redis-os/data:/data \\ -v /etc/localtime:/etc/localtime \\ -p 10302:6379 redis redis-server --appendonly yes docker run -d --restart=\"always\" --name redis-bs \\ -v /data/docker/redis-bs/data:/data \\ -v /etc/localtime:/etc/localtime \\ -p 10301:6379 redis redis-server --appendonly yes docker network connect docker_connection redis-os docker network connect docker_connection redis-bs } function startDockerContainersEnvelope(){ docker run -dit --restart=\"always\" -p 10059:8080 --name \"envelope-01\" \\ -v /data/docker/envelope-01:/data/tomcat-8.0.21/webapps/Envelope \\ -v /data/docker/logs/envelope-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection envelope-01 } function startDockerContainersOS(){ #os-gateway docker run -dit --restart=\"always\" -p 10401:8080 -p 10402:8000 --name \"os-gw-01\" \\ -v /data/docker/opensocial/os-gw-01:/data/tomcat-8.0.21/webapps/opensocial-gateway \\ -v /data/docker/logs/os-gw-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection os-gw-01 #os-msg docker run -dit --restart=\"always\" -p 10403:8080 -p 10404:8000 --name \"os-msg-01\" \\ -v /data/docker/opensocial/os-msg-01:/data/tomcat-8.0.21/webapps/opensocial-message \\ -v /data/docker/logs/os-msg-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection os-msg-01 #os-inte docker run -dit --restart=\"always\" -p 10405:8080 -p 10406:8000 --name \"os-inte-01\" \\ -v /data/docker/opensocial/os-inte-01:/data/tomcat-8.0.21/webapps/opensocial-integration \\ -v /data/docker/logs/os-inte-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection os-inte-01 #os-dsp docker run -dit --restart=\"always\" -p 10407:8080 -p 10408:8000 --name \"os-dsp-01\" \\ -v /data/docker/opensocial/os-dsp-01:/data/tomcat-8.0.21/webapps/opensocial-dsp \\ -v /data/docker/logs/os-dsp-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection os-dsp-01 #os-web docker run -dit --restart=\"always\" -p 10409:8080 -p 10410:8000 --name \"os-web-01\" \\ -v /data/docker/opensocial/os-web-01:/data/tomcat-8.0.21/webapps/opensocial-wechat-web \\ -v /data/docker/logs/os-web-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection os-web-01 } function startDockerContainersBS(){ # bs-core docker run -dit --restart=\"always\" -p 10501:8080 -p 10502:8000 --name \"bs-core-01\" \\ -v /data/docker/business-service/bs-core-01:/data/tomcat-8.0.21/webapps/business-service-core \\ -v /data/docker/logs/bs-core-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection bs-core-01 # bs-mobile docker run -dit --restart=\"always\" -p 10503:8080 -p 10504:8000 --name \"bs-mobile-01\" \\ -v /data/docker/business-service/bs-mobile-01:/data/tomcat-8.0.21/webapps/business-service-mobile \\ -v /data/docker/logs/bs-mobile-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection bs-mobile-01 # bs-dsp docker run -dit --restart=\"always\" -p 10505:8080 -p 10506:8000 --name \"bs-dsp-01\" \\ -v /data/docker/business-service/bs-dsp-01:/data/tomcat-8.0.21/webapps/business-service-dsp \\ -v /data/docker/logs/bs-dsp-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection bs-dsp-01 # bs-message docker run -dit --restart=\"always\" -p 10507:8080 -p 10508:8000 --name \"bs-message-01\" \\ -v /data/docker/business-service/bs-message-01:/data/tomcat-8.0.21/webapps/business-service-message \\ -v /data/docker/logs/bs-message-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection bs-message-01 # bs-chatter docker run -dit --restart=\"always\" -p 10509:29092 -p 10510:8000 --name \"bs-chatter-01\" \\ -v /data/docker/business-service/bs-chatter-01:/data/chatter \\ -v /data/docker/logs/bs-chatter-01:/data/chatter/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-chatter docker network connect docker_connection bs-chatter-01 # bs-publish docker run -dit --restart=\"always\" -p 10513:8080 -p 10514:8000 --name \"bs-publish-01\" \\ -v /data/docker/business-service/bs-publish-01:/data/tomcat-8.0.21/webapps/business-service-publish \\ -v /data/docker/logs/bs-publish-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection bs-publish-01 # bs-serviceorder docker run -dit --restart=\"always\" -p 10517:8080 -p 10518:8000 --name \"bs-serviceorder-01\" \\ -v /data/docker/business-service/bs-serviceorder-01:/data/tomcat-8.0.21/webapps/business-service-serviceorder \\ -v /data/docker/logs/bs-serviceorder-01:/data/tomcat-8.0.21/logs \\ -v /etc/localtime:/etc/localtime \\ docker.example.com/jdk8-tomcat8 docker network connect docker_connection bs-serviceorder-01 } function start(){ checkDockerServiceStatus checkDockerNetworkStatus set -o errexit startDockerContainersMemcached startDockerContainersActiveMQ startDockerContainersRedis startDockerContainersEnvelope startDockerContainersOS startDockerContainersBS set +o errexit } function main(){ lock_filename=\"lock_$$_$RANDOM\" # lock_filename_full_path=\"/var/lock/subsys/$lock_filename\" lock_filename_full_path=\"/var/lock/$lock_filename\" if ( set -o noclobber; echo \"$$\" > \"$lock_filename_full_path\") 2> /dev/null;then trap 'rm -f \"$lock_filename_full_path\"; exit $?' INT TERM EXIT # Just a test for call itself, comment it if [[ $# -ne 1 ]]; then [ ! -x ${WORKDIR}/`basename $0` ] && chmod +x ${WORKDIR}/`basename $0` ${WORKDIR}/`basename $0` start exit 0 fi case $1 in start) start ;; help|*) echo \"Usage: $0 {start} with $0 itself\" exit 1 ;; esac rm -f \"$lock_filename_full_path\" trap - INT TERM EXIT else echo \"Failed to acquire lock: $lock_filename_full_path\" echo \"held by $(cat ${lock_filename_full_path})\" fi } main $@ # debug option #${_XTRACE_FUNCTIONS}"
        },
        {
            "filename": "file_483.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\performances\\Linux\\debian-ubuntu\\file_483.sh",
            "content": "#!/usr/bin/env bash # Usage: sudo bash $0 # Author: dgden # Create Date: 2020/9/23 # Create Time: 10:00 # Description: disable some motd scripts to improve login performance [ -r /etc/os-release ] && . /etc/os-release if [[ $ID != \"ubuntu\" ]]; then echo \"for Debian dist like use only.\" exit 2 fi printf \"Welcome to %s (%s %s %s)\\n\" \"$VERSION\" \"$(uname -o)\" \"$(uname -r)\" \"$(uname -m)\" chmod -x /etc/update-motd.d/10-help-text chmod -x /etc/update-motd.d/50-motd-news chmod -x /etc/update-motd.d/95-hwe-eol"
        },
        {
            "filename": "file_484.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\LinuxBashShellScriptForOps\\projects\\processOps\\file_484.sh",
            "content": "#!/bin/bash # Stopping process abruptly using kill COMMAND=$1 USER=$2 if [[ -z \"$COMMAND\" ]]; then echo \"Fatal error, list of command names must follow $0\" exit 1 fi if [[ \"$1\" == \"-h\" || \"$1\" == \"--help\" ]]; then echo \"Func: This shell script will find the process you want to kill with signal 9, process name support regular expression with 'grep'\" echo \"Usage: $0 command [username]\" echo \"Example: $0 command, this will kill all process which match 'command'\" exit 0 fi if [[ -z \"$USER\" ]]; then USER=root fi pid=\"`ps aux | grep \"$COMMAND\" | grep \"$USER\" | grep -v grep | awk '{print $2}'`\" if [[ -z \"$pid\" ]]; then echo \":( , can NOT find $COMMAND running by $USER\" exit 1 fi kill -9 \"$pid\" >/dev/null 2>&1 retval=$? pid=`ps aux | grep \"$COMMAND\" | grep \"$USER\" | grep -v grep | awk '{print $2}'` if [[ -z \"$vpid\" && \"$retval\" -eq 0 ]]; then echo \":( , Failed, I can NOT kill $COMMAND running by $USER, got an error code $retval\" else echo \":) , Successfully killed $COMMAND running by $USER\" fi"
        },
        {
            "filename": "file_485.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\PowerShell-Scripts\\Munki\\file_485.sh",
            "content": "log=\"/tmp/softwareupdate.log\" if [ ! -e $log ] then touch $log fi crontab=\"/etc/crontab\" if [ -e $crontab ] then if grep /usr/sbin/softwareupdate $crontab then echo entry exist waiting for cron to run. else echo \"30 * * * * root /usr/sbin/softwareupdate -l &> $log\" >> $crontab fi else echo \"SHELL=/bin/sh\" > $crontab echo \"PATH=/bin:/sbin:/usr/bin:/usr/sbin\" >> $crontab echo \"30 * * * * root /usr/sbin/softwareupdate -l &> $log\" >> $crontab fi /usr/bin/tail -1 $log"
        },
        {
            "filename": "file_486.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shc\\file_486.sh",
            "content": "#!/bin/sh autoreconf --force --install"
        },
        {
            "filename": "file_487.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shc\\test\\file_487.sh",
            "content": "#!/bin/sh -x echo \"$0\" \"$@\" ps $$ ps wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww $$ cat /proc/$$/cmdline touch $0.kk read ENTER"
        },
        {
            "filename": "file_488.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shc\\test\\file_488.sh",
            "content": "#!/bin/bash shells=('/bin/sh' '/bin/dash' '/bin/bash' '/bin/ash' '/bin/ksh' '/bin/zsh' '/usr/bin/tcsh' '/bin/csh' '/usr/bin/rc') ## Install: sudo apt install dash bash ash ksh zsh tcsh csh rc check_opts=('' '-r' '-v' '-D' '-S') shc=${1-shc} txtred='\\e[0;31m' # Red txtgrn='\\e[0;32m' # Green txtrst='\\e[0m' # Text Reset stat=0 pc=0 fc=0 echo echo \"== Running tests ...\" for shell in ${shells[@]}; do for opt in \"${check_opts[@]}\"; do tmpd=$(mktemp -d) tmpf=\"$tmpd/test.$(basename $shell)\" echo '#!'\"$shell echo 'Hello World fp:'\\$1 sp:\\$2 \" > \"$tmpf\" \"$shc\" $opt -f \"$tmpf\" -o \"$tmpd/a.out\" out=$(\"$tmpd/a.out\" first second) #~ echo \" Output: $out\" if [[ \"$out\" = 'Hello World fp:first sp:second' ]]; then echo \"====================================================\" echo -e \"=== $shell [with shc $opt]: ${txtgrn}PASSED${txtrst}\" echo \"====================================================\" ((pc++)) else echo \"====================================================\" echo -e \"=== $shell [with shc $opt]: ${txtred}FAILED${txtrst}\" echo \"====================================================\" stat=1 ((fc++)) fi rm -r \"$tmpd\" done done echo echo \"Test Summary\" echo \"------------\" if ((pc>0)); then pt=\"${txtgrn}PASSED${txtrst}\" else pt=\"PASSED\" fi if ((fc>0)); then ft=\"${txtred}FAILED${txtrst}\" else ft=\"FAILED\" fi echo -e \"$pt: $pc\" echo -e \"$ft: $fc\" echo \"------------\" echo exit $stat"
        },
        {
            "filename": "file_489.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\Linux\\Apps\\1Password\\file_489.sh",
            "content": "#!/bin/bash ############################################################################################ ## ## Script to install the latest version of 1Password for Linux ## ## VER 1.1.0 ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Check if running with root privileges if [[ $EUID -ne 0 ]]; then echo \"This script must be run with root privileges. Please use sudo or run as root.\" exit 1 fi # Variables # Logging log_file=\"/var/log/em_1Password_install.log\" error_log_file=\"/var/log/em_1Password_install_error.log\" # Functions # Function to log messages function log_message() { echo -e \"$(date +\"%Y-%m-%d %H:%M:%S\") - $1\" >> \"$log_file\" } # Function to log errors function log_error() { echo -e \"$(date +\"%Y-%m-%d %H:%M:%S\") - ERROR: $1\" >> \"$error_log_file\" } # Function to handle errors function handle_error() { log_error \"$1\" log_message \"An error occurred. Exiting.\" exit 1 } # Main # Create log files if they don't exist touch \"$log_file\" touch \"$error_log_file\" log_message \"Starting the script.\" # Check if 1Password is already installed log_message \"Checking 1Password install status...\" install_status=$(dpkg --status \"1password\" | grep -Po \"^Status:\\s+\\K(\\S+)\") if [ $install_status == \"install\" ]; then log_message \"1Password is already installed. Skipping installation.\" exit 0 else log_message \"1Password is not installed. Installing...\" # Update the system log_message \"Updating the system\" sudo apt-get update >> \"$log_file\" || log_error \"Failed to update the system. \\n\\n $? \\n\" # Check if curl is installed if ! command -v curl &> /dev/null; then log_message \"curl is not installed. Installing...\" sudo apt-get install curl --download -y >> \"$log_file\" || handle_error \"Failed to install curl. \\n\\n $? \\n\" log_message \"curl installation complete.\" else log_message \"curl is already installed.\" fi # Check if gnupg is installed gnupg_status=$(dpkg --status gnupg | grep -Po \"^Status:\\s+\\K(\\S+)\") if [ $gnupg_status == \"install\" ]; then log_message \"gnupg is already installed. Skipping installation.\" else log_message \"gnupg is not installed. Installing...\" sudo apt-get install gnupg --download -y || handle_error \"Failed to install gnupg. \\n\\n $? \\n\" log_message \"gnupg installation complete.\" fi # Validate if the package signing key is already in place if [ -f \"/etc/apt/trusted.gpg.d/1password-archive-keyring.gpg\" ]; then log_message \"1Password GPG key is already installed. Skipping installation.\" else log_message \"1Password GPG key is not installed. Installing...\" # Import the 1Password repository key log_message \"Importing the 1Password gpg key\" curl -sS https://downloads.1password.com/linux/keys/1password.asc | sudo gpg --dearmor --output /etc/apt/trusted.gpg.d/1password-archive-keyring.gpg &>> \"$log_file\" || handle_error \"Failed to import the 1Password repository key. \\n\\n $? \\n\" log_message \"1Password GPG key installed successfully.\" fi # Append 1Password repository log_message \"Appending the 1Password repository\" echo 'deb [arch=amd64 signed-by=/etc/apt/trusted.gpg.d/1password-archive-keyring.gpg] https://downloads.1password.com/linux/debian/amd64 stable main' | sudo tee /etc/apt/sources.list.d/1password.list >> \"$log_file\" || handle_error \"Unable to add the update repository. \\n\\n $? \\n\" # Install the debsig-verify policy sudo mkdir -p /etc/debsig/policies/AC2D62742012EA22/ curl -sS https://downloads.1password.com/linux/debian/debsig/1password.pol | sudo tee /etc/debsig/policies/AC2D62742012EA22/1password.pol sudo mkdir -p /usr/share/debsig/keyrings/AC2D62742012EA22 curl -sS https://downloads.1password.com/linux/keys/1password.asc | sudo gpg --dearmor --output /usr/share/debsig/keyrings/AC2D62742012EA22/debsig.gpg # Update package lists log_message \"Updating package lists...\" sudo apt-get update &>> \"$log_file\" || log_error \"Failed to update package lists. \\n\\n $? \\n\" # Install 1Password log_message \"Installing 1Password\" sudo apt-get install \"1password\" --download -y &>> \"$log_file\" || handle_error \"Unable to install TeamViewer. \\n\\n $? \\n\" # Verify installation install_status=$(dpkg --status \"1password\" | grep -Po \"^Status:\\s+\\K(\\S+)\") if [ $install_status == \"install\" ]; then log_message \"1Password installation completed successfully.\" exit 0 else handle_error \"1Password installation failed. \\n\\n $? \\n\" fi fi"
        },
        {
            "filename": "file_490.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\Linux\\Apps\\Google Chrome\\file_490.sh",
            "content": "#!/bin/bash ############################################################################################ ## ## Script to install the latest version of Google Chrome on Linux ## ## VER 1.2.0 ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Check if running with root privileges if [[ $EUID -ne 0 ]]; then echo \"This script must be run with root privileges. Please use sudo or run as root.\" exit 1 fi # Variables log_file=\"/var/log/em_google_chrome_install.log\" error_log_file=\"/var/log/em_google_chrome_install_error.log\" # Functions # Function to log messages function log_message() { echo -e \"$(date +\"%Y-%m-%d %H:%M:%S\") - $1\" >> \"$log_file\" } # Function to log errors function log_error() { echo -e \"$(date +\"%Y-%m-%d %H:%M:%S\") - ERROR: $1\" >> \"$error_log_file\" } # Function to handle errors function handle_error() { log_error \"$1\" log_message \"An error occurred. Exiting.\" exit 1 } # Main # Create log files if they don't exist touch \"$log_file\" touch \"$error_log_file\" log_message \"Starting the script.\" # Check if Google Chrome is already installed log_message \"Checking Google Chrome install status...\" install_status=$(dpkg --status google-chrome-stable | grep -Po \"^Status:\\s+\\K(\\S+)\") if [ $install_status == \"install\" ]; then log_message \"Google Chrome is already installed. Skipping installation.\" exit 0 else log_message \"Google Chrome is not installed. Installing...\" # Update the system log_message \"Updating the system\" sudo apt-get update >> \"$log_file\" || log_error \"Failed to update the system. \\n\\n $? \\n\" # Check if curl is installed if ! command -v curl &> /dev/null; then log_message \"curl is not installed. Installing...\" sudo apt-get install curl -y >> \"$log_file\" || handle_error \"Failed to install curl. \\n\\n $? \\n\" log_message \"curl installation complete.\" else log_message \"curl is already installed.\" fi # Check if gnupg is installed gnupg_status=$(dpkg --status gnupg | grep -Po \"^Status:\\s+\\K(\\S+)\") if [ $gnupg_status == \"install\" ]; then log_message \"gnupg is not installed. Installing...\" sudo apt-get install gnupg -y >> \"$log_file\" || handle_error \"Failed to install gnupg. \\n\\n $? \\n\" log_message \"gnupg installation complete.\" else log_message \"gnupg is already installed.\" fi # Download Google Chrome repository key log_message \"Adding Google Chrome repository key\" curl -sS https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo gpg --dearmor --yes -o /usr/share/keyrings/google-chrome-archive-keyring.gpg || handle_error \"Unable to add the Google Chrome repository key. \\n\\n $? \\n\" log_message \"Google Chrome repository key imported.\" # Append the Google Chrome repository log_message \"Adding Google Chrome repository\" echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/google-chrome-archive-keyring.gpg] http://dl.google.com/linux/chrome/deb/ stable main\" | sudo tee /etc/apt/sources.list.d/google-chrome.list &>> \"$log_file\" || handle_error \"Unable to add update repository. \\n\\n $? \\n\" log_message \"Google Chrome repository added.\" # Update package lists log_message \"Updating package lists...\" sudo apt-get update &>> \"$log_file\" || log_error \"Failed to update package lists. \\n\\n $? \\n\" # Install Google Chrome log_message \"Installing Google Chrome\" sudo apt-get install google-chrome-stable -y &>> \"$log_file\" || handle_error \"Unable to install Google Chrome. \\n\\n $? \\n\" # Exit script log_message \"Google Chrome installation completed.\" exit 0 fi"
        },
        {
            "filename": "file_491.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\Linux\\Custom Compliance\\Running Process Example\\file_491.sh",
            "content": "#!/bin/dash log=\"$HOME/compliance.log\" echo \"$(date) | Starting compliance script\" >> $log processes=\"msedge gnome-shell\" numProcesses=$(echo \"$processes\" | awk -F\" \" '{print NF-1}') numProcesses=$((numProcesses+1)) iteration=0 echo -n \"{\" echo \"$processes\" | tr ' ' '\\n' | while read process; do echo -n \"$(date) | + Working on process [$process]...\" >> $log iteration=$((iteration+1)) if pgrep -l \"$process\" > /dev/null; then echo -n \"\\\"$process\\\": \\\"Running\\\"\" echo \"Running\" >> $log else echo -n \"\\\"$process\\\": \\\"NotRunning\\\"\" echo \"NotRunning\" >> $log fi if [ $iteration -lt $numProcesses ];then echo -n \",\" fi done echo \"}\" echo \"$(date) | Ending compliance script\" >> $log"
        },
        {
            "filename": "file_492.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\Linux\\Misc\\Azure VM\\file_492.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install Ubuntu Desktop and XRDP on Azure Ubuntu Server instance ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: anders ahl # Update all existing packages sudo apt update -y && sudo apt upgrade -y # Install ubuntu desktop sudo apt install ubuntu-desktop -y # Install XRDP sudo apt install xrdp -y sudo systemctl enable xrdp sudo adduser xrdp ssl-cert"
        },
        {
            "filename": "file_493.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\Linux\\Misc\\Enrollment Prep Script\\file_493.sh",
            "content": "#!/bin/bash ############################################################################################ ## ## Script to install Intune Prerequisites for Linux Enrollment ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: Anders Ahl if [ \"$EUID\" -ne 0 ] then echo \"Please run this script as root\" exit 1 fi # Start of a bash \"try-catch loop\" that will safely exit the script if a command fails or causes an error. ( # Set the error status set -e # Install pre-requisite packages apt install -y wget apt-transport-https software-properties-common # Download the Microsoft repository and GPG keys wget -q \"https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/packages-microsoft-prod.deb\" # Register the Microsoft repository and GPG keys dpkg -i packages-microsoft-prod.deb # Update the list of packages after we have added packages.microsoft.com apt update # Remove the repository & GPG key package (as we imported it above) rm packages-microsoft-prod.deb # Install the Intune portal apt install -y intune-portal # Enable the Edge browser repository add-apt-repository \"deb [arch=amd64] https://packages.microsoft.com/repos/edge stable main\" # Install Microsoft Edge # apt install -y microsoft-edge-dev # apt install -y microsoft-edge-beta apt install -y microsoft-edge-stable # Enable the Microsoft Teams repository # add-apt-repository \"deb [arch=amd64] https://packages.microsoft.com/repos/ms-teams stable main\" # Install Microsoft Teams # Note, Teams is no longer being developed and has been replaced with PWA version of the app #apt install -y teams # Install Microsoft Defender for Endpoint #apt install -y mdatp ) # Catch any necessary errors to prevent the program from improperly exiting. ERROR_CODE=$? if [ $ERROR_CODE -ne 0 ]; then echo \"There was an error. Please restart the script or contact your admin if the error persists.\" exit $ERROR_CODE fi"
        },
        {
            "filename": "file_494.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\AdobeAcrobatReaderDC\\file_494.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [APPNAME] ## ## VER 3.0.1 ## ## Change Log ## ## 2022-01-05 - Updated Rosetta detection code ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## 2021-12-06 - Added --compressed to curl cli ## - Fixed DMGPKG detection ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables currentVersion=$(curl -LSs \"https://armmf.adobe.com/arm-manifests/mac/AcrobatDC/acrobat/current_version.txt\" | sed 's/\\.//g') weburl=\"https://ardownload2.adobe.com/pub/adobe/reader/mac/AcrobatDC/${currentVersion}/AcroRdrDC_${currentVersion}_MUI.dmg\" appname=\"Adobe Acrobat Reader DC\" # The name of our App deployment script (also used for Octory monitor) app=\"Adobe Acrobat Reader DC.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/Adobe Acrobat Reader DC\" # The location of our logs and last updated data processpath=\"/Applications/Adobe Acrobat Reader DC.app/Contents/MacOS/AdobeReader\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname [$weburl]\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Mounted succesfully to [$volume]\" else echo \"$(date) | Failed to mount [$tempfile]\" fi if [[ $(ls \"$volume\" | grep -i .app) ]] && [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected both APP and PKG in same DMG, exiting gracefully\" else if [[ $(ls \"$volume\" | grep -i .app) ]]; then echo \"$(date) | Detected APP, setting PackageType to DMG\" packageType=\"DMG\" fi if [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_495.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Cisco AMP\\file_495.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install Cisco AMP ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com ## ## Note: This application requires that the following system extensions are allowed ## ## ## 2 extension(s) ## --- com.apple.system_extension.network_extension ## enabled active teamID bundleID (version) name [state] ## * * DE8Y96K9QP com.cisco.endpoint.svc.networkextension (1.15.5/837) AMP Network Extension [activated enabled] ## --- com.apple.system_extension.endpoint_security ## enabled active teamID bundleID (version) name [state] ## * * DE8Y96K9QP com.cisco.endpoint.svc.securityextension (1.15.5/837) AMP Security Extension [activated enabled] # User Defined variables weburl=\"Enter Your Azure Blob Storage URL Here\" # What is the Azure Blob Storage URL? appname=\"Cisco AMP\" # The name of our App deployment script (also used for Octory monitor) app=\"Cisco AMP for Endpoints.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/CiscoAMP\" # The location of our logs and last updated data processpath=\"/Applications/Cisco AMP for Endpoints/AMP for Endpoints Connector.app/Contents/MacOS/AMP for Endpoints Connector\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. #waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" #echo \"$(date) | Installing [$appname]\" #updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # This is a PKG, so we need to call the installer installer -pkg \"$volume\"/ciscoampmac_connector.pkg -target /Applications # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully #if [[ -a \"/Applications/$app\" ]]; then # echo \"$(date) | [$appname] Installed\" # echo \"$(date) | Cleaning Up\" # rm -rf \"$tempfile\" #echo \"$(date) | Fixing up permissions\" #sudo chown -R root:wheel \"/Applications/$app\" #echo \"$(date) | Application [$appname] succesfully installed\" #fetchLastModifiedDate update #updateOctory installed #exit 0 #else # echo \"$(date) | Failed to install [$appname]\" # rm -rf \"$tempdir\" # updateOctory failed # exit 1 #fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Wait for Desktop waitForDesktop # Download app downloadApp # Install DMG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_496.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Citrix Workspace\\file_496.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [APPNAME] ## ## VER 3.0.3 ## ## Change Log ## ## 2022-02-28 - Updated file type detection logic where we can't tell what the file is by filename in downloadApp function ## 2022-02-23 - Added detection support for bz2 and tbz2 ## 2022-02-11 - Added detection support for mpkg ## 2022-01-05 - Updated Rosetta detection code ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## 2021-12-06 - Added --compressed to curl cli ## - Fixed DMGPKG detection ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables latestver=`curl -s -L https://www.citrix.com/downloads/workspace-app/mac/workspace-app-for-mac-latest.html#ctx-dl-eula-external | grep \"<h1>Citrix \" | awk '{print $4}'` CRCurrVersNormalized=$( echo $latestver | sed -e 's/[.]//g' ) url1=\"https:\" url2=`curl -s -L https://www.citrix.com/downloads/workspace-app/mac/workspace-app-for-mac-latest.html#ctx-dl-eula-external | grep dmg | sed -n 's/.*rel=\"//;s/\".*//p' | head -n2 | tail -n1` weburl=`echo \"${url1}${url2}\"` appname=\"Citrix Workspace\" # The name of our App deployment script (also used for Octory monitor) app=\"Citrix Workspace.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/Applications/$app/Contents/MacOS/Citrix Workspace\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate -install-rosetta -agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname [$weburl]\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG|*.mpkg|*.MPKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.tbz2|*.TBZ2|*.bz2|*.BZ2) packageType=\"BZ2\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Mounted succesfully to [$volume]\" else echo \"$(date) | Failed to mount [$tempfile]\" fi if [[ $(ls \"$volume\" | grep -i .app) ]] && [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected both APP and PKG in same DMG (this is normal for Citrix Workspace)\" packageType=\"DMGPKG\" else if [[ $(ls \"$volume\" | grep -i .app) ]]; then echo \"$(date) | Detected APP, setting PackageType to DMG\" packageType=\"DMG\" fi if [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi if [[ $(ls \"$volume\" | grep -i .mpkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file -z \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"DOS/MBR boot sector, extended partition table\"* ]] || [[ \"$metadata\" == *\"Apple Driver Map\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi if [[ \"$metadata\" == *\"POSIX tar archive (bzip2 compressed data\"* ]]; then packageType=\"BZ2\" mv \"$tempfile\" \"$tempdir/install.tar.bz2\" tempfile=\"$tempdir/install.tar.bz2\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done for file in \"$volume\"/*.mpkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } ## Install BZ2 Function function installBZ2 () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir tar -jxf \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile uncompressed\" else echo \"$(date) | failed to uncompress $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"BZ2\" ]]; then installBZ2 fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_497.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Company Portal\\file_497.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest Intune Company Portal client ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables mauurl=\"https://go.microsoft.com/fwlink/?linkid=830196\" # URL to fetch latest MAU weburl=\"https://go.microsoft.com/fwlink/?linkid=853070\" # What is the Azure Blob Storage URL? appname=\"Company Portal\" # The name of our App deployment script (also used for Octory monitor) app=\"Company Portal.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installCompanyPortal\" # The location of our logs and last updated data processpath=\"/Applications/Company Portal.app/Contents/MacOS/Company Portal\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) function updateMAU () { ################################################################################################################# ################################################################################################################# ## ## This function downloads and installs the latest Microsoft Audo Update (MAU) tool ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [MAU]\" cd \"$tempdir\" curl -o \"$tempdir/mau.pkg\" -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$mauurl\" if [ $? == 0 ]; then echo \"$(date) | Downloaded [$mauurl] to [$tempdir/mau.pkg]\" echo \"$(date) | Starting installation of latest MAU\" installer -pkg \"$tempdir/mau.pkg\" -target / # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | MAU Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir/mau.pkg\" else echo \"$(date) | Failed to install [MAU]\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir/mau.pkg\" fi else echo \"$(date) | Failure to download [MAU] to [$tempfile]\" exit 1 fi } # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Update MAU updateMAU # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_498.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Defender\\file_498.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest Microsoft Defender ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://aka.ms/MacDefender\" # What is the APP Storage URL appname=\"Microsoft Defender\" # The name of our App deployment script (also used for Octory monitor) app=\"Microsoft Defender.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installDefender\" # The location of our logs and last updated data processpath=\"/Applications/Microsoft Defender.app/Contents/MacOS/Microsoft Defender.app/Contents/MacOS/Microsoft Defender\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # If true, application updates itself and we should not attempt to update waitForTheseApps=( \"/Applications/Microsoft Edge.app\" \"/Applications/Microsoft Outlook.app\" \"/Applications/Microsoft Word.app\" \"/Applications/Microsoft Excel.app\" \"/Applications/Microsoft PowerPoint.app\" \"/Applications/Microsoft OneNote.app\" \"/Applications/Microsoft Teams.app\" \"/Applications/Company Portal.app\") # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # Function to pause installation until we've finished installing other apps waitForOtherApps() { ################################################################################################################# ################################################################################################################# ## ## Function to wait until all dependent apps are installed. This is required for Defender since it will hang ## any running TCP connections when it's network extension is loaded. ## ## Functions used ## ## None ## ## Variables used ## ## $waitForTheseApps = Array of apps to wait for ## ############################################################### ############################################################### echo \"Looking for required applications before we install\" while [[ $ready -ne 1 ]];do missingappcount=0 for i in \"${waitForTheseApps[@]}\"; do if [[ ! -a \"$i\" ]]; then echo \" $(date) | waiting for installation of [$i]\" let missingappcount=$missingappcount+1 fi done if [[ $missingappcount -eq 0 ]]; then ready=1 echo \" $(date) | All apps installed, safe to continue\" else echo \" $(date) | [$missingappcount] application missing\" echo \" $(date) | Waiting for 60 seconds\" sleep 60 fi done } # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 60 + 1 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # If lastmodified isn't already generated if [[ -z $lastmodified ]]; then # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" --retry 5 --retry-delay 60 | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') fi # Check if it was it successfully got the last modified date if [[ -z $lastmodified ]]; then echo \"$(date) | Failed to get lastmodified from [$weburl]\" updateOctory failed exit 1 fi if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" # Second wait for Curl, we'll hang any downloads once we begin installing Defender waitForProcess \"curl -f\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Don't start install until our other apps have finished, otherwise we will terminate their download waitForOtherApps # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_499.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Edge\\file_499.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest Edge stable channel from Microsoft CDN Servers ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define variables weburl=\"https://go.microsoft.com/fwlink/?linkid=2093504\" # What is the Azure Blob Storage URL? appname=\"Microsoft Edge\" # The name of our App deployment script app=\"Microsoft Edge.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installEdge\" # The location of our logs and last updated data processpath=\"/Applications/Microsoft Edge.app/Contents/MacOS/Microsoft Edge\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # If true, application updates itself and we should not attempt to update # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -o \"edge.pkg\" \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_500.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\FileZilla\\file_500.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [FileZilla] ## ## VER 3.0.3 ## ## Change Log ## ## 2022-02-23 - Added detection support for bz2 and tbz2 ## 2022-02-11 - Added detection support for mpkg ## 2022-01-05 - Updated Rosetta detection code ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## 2021-12-06 - Added --compressed to curl cli ## - Fixed DMGPKG detection ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://dl3.cdn.filezilla-project.org/client/FileZilla_3.58.0_macosx-x86.tar.bz2?h=SZgBP-QNYQxJtPn8uo_kBw&x=1646051403\" # What is the Azure Blob Storage URL? appname=\"FileZilla\" # The name of our App deployment script (also used for Octory monitor) app=\"FileZilla.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/Applications/FileZilla.app/Contents/MacOS/filezilla\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname [$weburl]\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG|*.mpkg|*.MPKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.tbz2|*.TBZ2|*.bz2|*.BZ2) packageType=\"BZ2\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Mounted succesfully to [$volume]\" else echo \"$(date) | Failed to mount [$tempfile]\" fi if [[ $(ls \"$volume\" | grep -i .app) ]] && [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected both APP and PKG in same DMG, exiting gracefully\" else if [[ $(ls \"$volume\" | grep -i .app) ]]; then echo \"$(date) | Detected APP, setting PackageType to DMG\" packageType=\"DMG\" fi if [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi if [[ $(ls \"$volume\" | grep -i .mpkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file -z \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"DOS/MBR boot sector, extended partition table\"* ]] || [[ \"$metadata\" == *\"Apple Driver Map\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi if [[ \"$metadata\" == *\"POSIX tar archive (bzip2 compressed data\"* ]]; then packageType=\"BZ2\" mv \"$tempfile\" \"$tempdir/install.tar.bz2\" tempfile=\"$tempdir/install.tar.bz2\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done for file in \"$volume\"/*.mpkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } ## Install BZ2 Function function installBZ2 () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir tar -jxf \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile uncompressed\" else echo \"$(date) | failed to uncompress $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"BZ2\" ]]; then installBZ2 fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_501.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Gimp\\file_501.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest GNU Imagine Manipulation client ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://download.gimp.org/mirror/pub/gimp/v2.10/osx/gimp-2.10.22-x86_64-3.dmg\" # What is the Azure Blob Storage URL? appname=\"Gimp\" # The name of our App deployment script (also used for Octory monitor) app=\"Gimp.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installGimp\" # The location of our logs and last updated data processpath=\"/Applications/Gimp.app/Contents/MacOS/gimp\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0 fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_502.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\gitHub Desktop\\file_502.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to download latest gitHub Desktop for macOS ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define variables # Pick correct URL for the CPU architecture if [[ $(uname -m) == 'arm64' ]]; then # This is Apple Silicon URL weburl=\"https://central.github.com/deployments/desktop/desktop/latest/darwin-arm64\" else # This is x64 URL weburl=\"https://central.github.com/deployments/desktop/desktop/latest/darwin\" fi appname=\"GitHub Desktop\" # The name of our App deployment script app=\"GitHub Desktop.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installGitHubDesktop\" # The location of our logs and last updated data processpath=\"/Applications/GitHub Desktop.app/Contents/MacOS/GitHub Desktop\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # If true, application updates itself and we should not attempt to update # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" dot_clean \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_503.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Google Chrome\\file_503.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [Google Chrome] ## ## VER 3.0.1 ## ## Change Log ## ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://dl.google.com/dl/chrome/mac/universal/stable/gcea/googlechrome.dmg\" # What is the Azure Blob Storage URL? appname=\"Google Chrome\" # The name of our App deployment script (also used for Octory monitor) app=\"Google Chrome.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/GoogleChrome\" # The location of our logs and last updated data processpath=\"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) if [[ \"$processor\" == *\"Intel\"* ]]; then echo \"$(date) | [$processor] found, Rosetta not needed\" else echo \"$(date) | [$processor] found, is Rosetta already installed?\" # Check Rosetta LaunchDaemon. If no LaunchDaemon is found, # perform a non-interactive install of Rosetta. if [[ ! -f \"/Library/Apple/System/Library/LaunchDaemons/com.apple.oahd.plist\" ]]; then /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" return else echo \"$(date) | Rosetta installation failed!\" fi else echo \"$(date) | Rosetta is already installed. Nothing to do.\" fi fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if ls \"$volume\"/*.app 1> /dev/null 2>&1; then echo \"$(date) | Detected APP, setting PakageType to DMG\" packageType=\"DMG\" else if ls \"$volume\"/*.pkg 1> /dev/null 2>&1; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_504.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Google Drive\\file_504.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [Google Drive] ## ## VER 3.0.1 ## ## Change Log ## ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://dl.google.com/drive-file-stream/GoogleDrive.dmg\" # What is the Azure Blob Storage URL? appname=\"Google Drive\" # The name of our App deployment script (also used for Octory monitor) app=\"Google Drive.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/GoogleDrive\" # The location of our logs and last updated data processpath=\"/Applications/Google Drive.app/Contents/MacOS/Google Drive\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) if [[ \"$processor\" == *\"Intel\"* ]]; then echo \"$(date) | [$processor] found, Rosetta not needed\" else echo \"$(date) | [$processor] found, is Rosetta already installed?\" # Check Rosetta LaunchDaemon. If no LaunchDaemon is found, # perform a non-interactive install of Rosetta. if [[ ! -f \"/Library/Apple/System/Library/LaunchDaemons/com.apple.oahd.plist\" ]]; then /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" return else echo \"$(date) | Rosetta installation failed!\" fi else echo \"$(date) | Rosetta is already installed. Nothing to do.\" fi fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if ls \"$volume\"/*.app 1> /dev/null 2>&1; then echo \"$(date) | Detected APP, setting PakageType to DMG\" packageType=\"DMG\" else if ls \"$volume\"/*.pkg 1> /dev/null 2>&1; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_505.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Illumio VEN\\file_505.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Illumio VEN Registration Installer ## ########################################### ## Copyright (c) 2023 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com ## ## Notes ## ## This script will install Illumio VEN Registration to Mac-devices that already have Illumio VEN installed. ## # User Defined variables appname=\"IllumioVENRegistrationInstaller\" # The name of our App deployment script (also used for Octory monitor) app=\"Illumio-ven-ctl\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/opt/Illumio_ven/Illumio-ven-ctl\" # The process name of the App we are installing apppath=\"/opt/Illumio_ven/Illumio-ven-ctl\" # The location of the app abmcheck=true # Apply this registration only if this device is ABM managed. activationcode=000000000000000000000000000000000000000000000000000000000000000000000000000000000 # Illumio activation code from pairing script managementserver=eu-scp13.illum.io:443 # Management server url from pairing script profileid=000000000000000000 # Profile ID for pairing script # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec > >(tee -a \"$log\") 2>&1 } # Checks if Illumio VEN is installed. If yes, we can proceed. Otherwise, we will close this script function checkIllumioVENInstallation() { if test -f \"$apppath\"; then echo \"$(date) | Illumio VEN is installed. Let's continue...\" else echo \"$(date) | Illumio VEN is not installed. We cannot apply Registration. Closing script...\" exit 1 fi } # Function that apply Illumio VEN Registration. function IllumioVENRegistration () { echo \"$(date) | Applying Illumio VEN Registration...\" rm -fr /opt/illumio_ven_data/tmp && umask 026 && mkdir -p /opt/illumio_ven_data/tmp && curl --tlsv1 \"https://$managementserver/api/v25/software/ven/image?pair_script=pair.sh&profile_id=$profileid\" -o /opt/illumio_ven_data/tmp/pair.sh && chmod +x /opt/illumio_ven_data/tmp/pair.sh && /opt/illumio_ven_data/tmp/pair.sh --management-server $managementserver --activation-code $activationcode echo \"$(date) | Illumio VEN Registration applied. Closing script...\" exit 0 } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Is this a ABM DEP device? if [ \"$abmcheck\" = true ]; then echo \"$(date) | Checking MDM Profile Type\" profiles status -type enrollment | grep \"Enrolled via DEP: Yes\" if [ ! $? == 0 ]; then echo \"$(date) | This device is not ABM managed\" exit 0; else echo \"$(date) | Device is ABM Managed\" fi fi # Checks if Illumio VEN is installed checkIllumioVENInstallation # Apply Illumio VEN Registration IllumioVENRegistration"
        },
        {
            "filename": "file_506.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Illumio VEN\\file_506.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest Illumio VEN to Superviced ## ## VER 4.0.1 ## ## Change Log ## ## 2023-09-26 - Script customized for Illumio VEN installation ## 2022-06-24 - First re-write in ZSH ## 2022-06-20 - Fixed terminate process function bugs ## 2022-02-28 - Updated file type detection logic where we can't tell what the file is by filename in downloadApp function ## 2022-02-23 - Added detection support for bz2 and tbz2 ## 2022-02-11 - Added detection support for mpkg ## 2022-01-05 - Updated Rosetta detection code ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## 2021-12-06 - Added --compressed to curl cli ## - Fixed DMGPKG detection ## ############################################################################################ ## Copyright (c) 2023 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://catlab.blob.core.windows.net/apps/IllumioVEN.pkg?sp=r&st=2022-08-25T12:37:30Z&se=2099-08-25T20:37:30Z&spr=https&sv=2021-06-08&sr=b&sig=4HnMlm3dA9dJICxnpadFGNXZE8RuyRDCdXyMb1Xt9G0%3D\" # What is the Azure Blob Storage URL? appname=\"IllumioVEN\" # The name of our App deployment script (also used for Octory monitor) app=\"illumio-ven-ctl\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/opt/illumio_ven/illumio-ven-ctl\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit abmcheck=true # Install this application if this device is ABM managed # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then pid=$(ps -fe | grep \"$processName\" | grep -v grep | awk '{print $2}') echo \"$(date) | + [$appname] running, terminating [$processName] at pid [$pid]...\" kill -9 $pid return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [[ $? == 0 ]]; then # We have downloaded a file, we need to know what the file is called and what type of file it is cd \"$tempdir\" for f in *; do tempfile=$f echo \"$(date) | Found downloaded tempfile [$tempfile]\" done case $tempfile in *.pkg|*.PKG|*.mpkg|*.MPKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.tbz2|*.TBZ2|*.bz2|*.BZ2) packageType=\"BZ2\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file -z \"$tempfile\") echo \"$(date) | [DEBUG] File metadata [$metadata]\" if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"DOS/MBR boot sector, extended partition table\"* ]] || [[ \"$metadata\" == *\"Apple Driver Map\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi if [[ \"$metadata\" == *\"POSIX tar archive (bzip2 compressed data\"* ]]; then packageType=\"BZ2\" mv \"$tempfile\" \"$tempdir/install.tar.bz2\" tempfile=\"$tempdir/install.tar.bz2\" fi ;; esac if [[ \"$packageType\" == \"DMG\" ]]; then # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG or ZIP # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if [[ \"$?\" = \"0\" ]]; then echo \"$(date) | Mounted succesfully to [$volume]\" else echo \"$(date) | Failed to mount [$tempfile]\" fi if [[ $(ls \"$volume\" | grep -i .app) ]] && [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected both APP and PKG in same DMG, exiting gracefully\" else if [[ $(ls \"$volume\" | grep -i .app) ]]; then echo \"$(date) | Detected APP, setting PackageType to DMG\" packageType=\"DMG\" fi if [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi if [[ $(ls \"$volume\" | grep -i .mpkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" fi if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /opt/illumio_ven ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -f \"/opt/illumio_ven/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /opt/illumio_ven ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/opt/illumio_ven/$app\" ]]; then /opt/illumio_ven/illumio-ven-ctl unpair saved fi installer -pkg \"$tempfile\" -target /. # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /opt/illumio_ven ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /opt/illumio_ven ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/opt/illumio_ven/$app\" ]]; then echo \"$(date) | Removing existing files\" /opt/illumio_ven/illumio-ven-ctl unpair saved fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /. done for file in \"$volume\"/*.mpkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /. done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/opt/illumio_ven/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/opt/illumio_ven/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /opt/illumio_ven ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /opt/illumio_ven ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/opt/illumio_ven/$app\" ]]; then echo \"$(date) | Removing existing files\" /opt/illumio_ven/illumio-ven-ctl unpair saved fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /opt/illumio_ven/$app\" rsync -a \"$volume\"/*.app/ \"/opt/illumio_ven/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/opt/illumio_ven/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/opt/illumio_ven/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /opt/illumio_ven ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /opt/illumio_ven ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [[ \"$?\" = \"0\" ]]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [[ -d \"$tempdir\" ]]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [[ \"$?\" = \"0\" ]]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [[ -d \"$tempdir\" ]]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/opt/illumio_ven/$app\" ]]; then echo \"$(date) | Removing old installation at /opt/illumio_ven/$app\" /opt/illumio_ven/illumio-ven-ctl unpair saved fi # Copy over new files rsync -a \"$app/\" \"/opt/illumio_ven/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /opt/illumio_ven\" else echo \"$(date) | failed to move $appname to /opt/illumio_ven\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/opt/illumio_ven/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/opt/illumio_ven/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/opt/illumio_ven/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } ## Install BZ2 Function function installBZ2 () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /opt/illumio_ven ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /opt/illumio_ven ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir tar -jxf \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile uncompressed\" else echo \"$(date) | failed to uncompress $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/opt/illumio_ven/$app\" ]]; then echo \"$(date) | Removing old installation at /opt/illumio_ven/$app\" /opt/illumio_ven/illumio-ven-ctl unpair saved fi # Copy over new files rsync -a \"$app/\" \"/opt/illumio_ven/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /opt/illumio_ven\" else echo \"$(date) | failed to move $appname to /opt/illumio_ven\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/opt/illumio_ven/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/opt/illumio_ven/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/opt/illumio_ven/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec > >(tee -a \"$log\") 2>&1 } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Is this a ABM DEP device? if [ \"$abmcheck\" = true ]; then echo \"$(date) | Checking MDM Profile Type\" profiles status -type enrollment | grep \"Enrolled via DEP: Yes\" if [ ! $? == 0 ]; then echo \"$(date) | This device is not ABM managed\" exit 0; else echo \"$(date) | Device is ABM Managed\" fi fi # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"BZ2\" ]]; then installBZ2 fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_507.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\ImageOptim\\file_507.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [APPNAME] ## ## VER 3.0.3 ## ## Change Log ## ## 2022-02-23 - Added detection support for bz2 and tbz2 ## 2022-02-11 - Added detection support for mpkg ## 2022-01-05 - Updated Rosetta detection code ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## 2021-12-06 - Added --compressed to curl cli ## - Fixed DMGPKG detection ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://imageoptim.com/ImageOptim.tbz2\" # What is the Azure Blob Storage URL? appname=\"ImageOptim\" # The name of our App deployment script (also used for Octory monitor) app=\"ImageOptim.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/Applications/ImageOptim.app/Contents/MacOS/ImageOptim\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname [$weburl]\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG|*.mpkg|*.MPKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.tbz2|*.TBZ2|*.bz2|*.BZ2) packageType=\"BZ2\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Mounted succesfully to [$volume]\" else echo \"$(date) | Failed to mount [$tempfile]\" fi if [[ $(ls \"$volume\" | grep -i .app) ]] && [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected both APP and PKG in same DMG, exiting gracefully\" else if [[ $(ls \"$volume\" | grep -i .app) ]]; then echo \"$(date) | Detected APP, setting PackageType to DMG\" packageType=\"DMG\" fi if [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi if [[ $(ls \"$volume\" | grep -i .mpkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done for file in \"$volume\"/*.mpkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } ## Install BZ2 Function function installBZ2 () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir tar -jxf \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile uncompressed\" else echo \"$(date) | failed to uncompress $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"BZ2\" ]]; then installBZ2 fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_508.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\LatestSampleScript\\file_508.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [APPNAME] ## ## VER 3.0.6 ## ## Change Log ## ## 2022-02-28 - Updated file type detection logic where we can't tell what the file is by filename in downloadApp function ## 2022-02-23 - Added detection support for bz2 and tbz2 ## 2022-02-11 - Added detection support for mpkg ## 2022-01-05 - Updated Rosetta detection code ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## 2021-12-06 - Added --compressed to curl cli ## - Fixed DMGPKG detection ## ############################################################################################ ## Copyright (c) 2022 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https:xxx.yyy.zzz/filename.file\" # What is the Azure Blob Storage URL? appname=\"APPNAME\" # The name of our App deployment script (also used for Octory monitor) app=\"APP NAME.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/Applications/$app/Contents/MacOS/APPEXE\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname [$weburl]\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG|*.mpkg|*.MPKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.tbz2|*.TBZ2|*.bz2|*.BZ2) packageType=\"BZ2\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Mounted succesfully to [$volume]\" else echo \"$(date) | Failed to mount [$tempfile]\" fi if [[ $(ls \"$volume\" | grep -i .app) ]] && [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected both APP and PKG in same DMG, exiting gracefully\" else if [[ $(ls \"$volume\" | grep -i .app) ]]; then echo \"$(date) | Detected APP, setting PackageType to DMG\" packageType=\"DMG\" fi if [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi if [[ $(ls \"$volume\" | grep -i .mpkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file -z \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"DOS/MBR boot sector, extended partition table\"* ]] || [[ \"$metadata\" == *\"Apple Driver Map\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi if [[ \"$metadata\" == *\"POSIX tar archive (bzip2 compressed data\"* ]]; then packageType=\"BZ2\" mv \"$tempfile\" \"$tempdir/install.tar.bz2\" tempfile=\"$tempdir/install.tar.bz2\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done for file in \"$volume\"/*.mpkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } ## Install BZ2 Function function installBZ2 () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir tar -jxf \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile uncompressed\" else echo \"$(date) | failed to uncompress $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"BZ2\" ]]; then installBZ2 fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_509.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\LatestSampleScript\\file_509.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [APPNAME] ## ## VER 3.0.7 ## ## Change Log ## ## 2022-06-20 - Fixed terminate process function bugs ## 2022-02-28 - Updated file type detection logic where we can't tell what the file is by filename in downloadApp function ## 2022-02-23 - Added detection support for bz2 and tbz2 ## 2022-02-11 - Added detection support for mpkg ## 2022-01-05 - Updated Rosetta detection code ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## 2021-12-06 - Added --compressed to curl cli ## - Fixed DMGPKG detection ## ############################################################################################ ## Copyright (c) 2022 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https:xxx.yyy.zzz/filename.file\" # What is the Azure Blob Storage URL? appname=\"APPNAME\" # The name of our App deployment script (also used for Octory monitor) app=\"APP NAME.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/Applications/$app/Contents/MacOS/APPEXE\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then pid=$(ps -fe | grep \"$processName\" | grep -v grep | awk '{print $2}') echo \"$(date) | + [$appname] running, terminating [$processName] at pid [$pid]...\" kill -9 $pid return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname [$weburl]\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG|*.mpkg|*.MPKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.tbz2|*.TBZ2|*.bz2|*.BZ2) packageType=\"BZ2\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Mounted succesfully to [$volume]\" else echo \"$(date) | Failed to mount [$tempfile]\" fi if [[ $(ls \"$volume\" | grep -i .app) ]] && [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected both APP and PKG in same DMG, exiting gracefully\" else if [[ $(ls \"$volume\" | grep -i .app) ]]; then echo \"$(date) | Detected APP, setting PackageType to DMG\" packageType=\"DMG\" fi if [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi if [[ $(ls \"$volume\" | grep -i .mpkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file -z \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"DOS/MBR boot sector, extended partition table\"* ]] || [[ \"$metadata\" == *\"Apple Driver Map\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi if [[ \"$metadata\" == *\"POSIX tar archive (bzip2 compressed data\"* ]]; then packageType=\"BZ2\" mv \"$tempfile\" \"$tempdir/install.tar.bz2\" tempfile=\"$tempdir/install.tar.bz2\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done for file in \"$volume\"/*.mpkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } ## Install BZ2 Function function installBZ2 () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir tar -jxf \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile uncompressed\" else echo \"$(date) | failed to uncompress $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"BZ2\" ]]; then installBZ2 fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_510.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Minecraft Education Edition\\file_510.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest Minecraft for Education ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://aka.ms/meeclientmacos\" appname=\"Minecraft EE\" app=\"Minecraft EE.app\" logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installMinecraftEE\" processpath=\"minecraftpe\" terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_511.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Office for Mac\\file_511.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest Office 365 Pro ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://go.microsoft.com/fwlink/?linkid=2009112\" # What is the Azure Blob Storage URL? appname=\"Microsoft Office\" # The name of our App deployment script (also used for Octory monitor) logandmetadir=\"/Library/Application Support/Microsoft/IntuneScripts/installOffice\" # The location of our logs and last updated data terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit waitForSplashScreen=true # Should we hold the script until an onboard splashscreen is running? SplashScreenProcess=\"Dialog\" # If we do wait for a splash screen, what's the process name? Octory | Dialog # Generated variables tempdir=$(mktemp -d) tempfile=\"$appname.pkg\" log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # Function to change the download URL to an older version if the current version isn't supported on this Mac function OfficeURLCheck() { # Download location for latest version of Office for Mac 2019 weburl=\"https://go.microsoft.com/fwlink/?linkid=2009112\" echo \"$(date) | Checking that the version of Office we have will work on this Mac\" os_ver=$(sw_vers -productVersion) case $os_ver in 10.10.*) echo \"$(date) | + macOS 10.10 Yosemite detected, setting install to Office 2016 v16.16\" weburl=\"https://officecdn-microsoft-com.akamaized.net/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.16.20091400_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 10.11.*) echo \"$(date) | + macOS 10.11 El Capitan detected, setting install to Office 2016 v16.16\" weburl=\"https://officecdn-microsoft-com.akamaized.net/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.16.20091400_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 10.12.*) echo \"$(date) | + macOS 10.12 Sierra detected, setting install to Office 2016 v16.30\" weburl=\"https://officecdn-microsoft-com.akamaized.net/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.30.19101301_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 10.13.*) echo \"$(date) | + macOS 10.13 High Sierra detected, setting install to Office 2019 v16.43\" weburl=\"https://officecdn-microsoft-com.akamaized.net/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.43.20110804_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 10.14.*) echo \"$(date) | + macOS 10.14 Mojave detected, setting install to Office 2019 v16.54\" weburl=\"https://officecdnmac.microsoft.com/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.54.21101001_BusinessPro_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 10.15.*) echo \"$(date) | + macOS 10.15 Catalina detected, setting install to Office 2019 v16.66\" weburl=\"https://officecdnmac.microsoft.com/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.66.22101101_BusinessPro_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 11.*) echo \"$(date) | + macOS 11.x Big Sur detected, installing latest available version\" ;; 12.*) echo \"$(date) | + macOS 12.x Monteray detected, installing latest available version\" ;; 13.*) echo \"$(date) | + macOS 13.x Ventura detected, installing latest available version\" ;; *) echo \"$(date) | + Unknown OS $os_ver\" ;; esac } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # Check download location to see if we can handle the latest version of Office OfficeURLCheck # If local copy is defined, let's try and download it... if [ \"$localcopy\" ]; then #updateSplashScreen installing # Octory updateSplashScreen wait Downloading # Swift Dialog # Check to see if we can access our local copy of Office echo \"$(date) | Downloading [$localcopy] to [$tempfile]\" rm -rf \"$tempfile\" > /dev/null 2>&1 curl -f -s -L -o \"$tempdir/$tempfile\" \"$localcopy\" if [ $? == 0 ]; then echo \"$(date) | Local copy of $appname downloaded at $tempfile\" downloadcomplete=\"true\" else echo \"$(date) | Failed to download Local copy [$localcopy] to [$tempfile]\" fi fi # If we failed to download the local copy, or it wasn't defined then try to download from CDN if [[ \"$downloadcomplete\" != \"true\" ]]; then updateSplashScreen wait Downloading # Swift Dialog rm -rf \"$tempfile\" > /dev/null 2>&1 echo \"$(date) | Downloading [$weburl] to [$tempfile]\" curl -f -s --connect-timeout 60 --retry 10 --retry-delay 30 -L -o \"$tempdir/$tempfile\" \"$weburl\" if [ $? == 0 ]; then echo \"$(date) | Downloaded $weburl to $tempdir/$tempfile\" else echo \"$(date) | Failure to download $weburl to $tempdir/$tempfile\" updateSplashScreen fail Download failed # Swift Dialog exit 1 fi fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" # App Array for Office 365 Apps for Mac OfficeApps=( \"/Applications/Microsoft Excel.app\" \"/Applications/Microsoft OneNote.app\" \"/Applications/Microsoft Outlook.app\" \"/Applications/Microsoft PowerPoint.app\" \"/Applications/Microsoft Teams.app\" \"/Applications/Microsoft Word.app\") for i in \"${OfficeApps[@]}\"; do if [[ ! -e \"$i\" ]]; then echo \"$(date) | [$i] not installed, need to perform full installation\" let missingappcount=$missingappcount+1 fi done if [[ ! \"$missingappcount\" ]]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" updateSplashScreen success Installed # Swift Dialog exit 0; fi fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" updateSplashScreen success Installed # Swift Dialog echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Installing [$appname]\" updateSplashScreen wait Installing # Swift Dialog installer -pkg \"$tempdir/$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then # Cleanup echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" # Update metadata in files echo \"$(date) | Writing last modifieddate $lastmodified to $metafile\" echo \"$lastmodified\" > \"$metafile\" # Update Swift Dialog echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateSplashScreen success Installed # Swift Dialog exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" #updateSplashScreen failed # Octory updateSplashScreen fail Failed # Swift Dialog exit 1 fi } function updateSplashScreen () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update the Splash Screen status (if required) ## ## ## Parameters (updateSplashScreen parameter1 parameter2 ## ## Octory ## ## Param 1 = State ## ## Swift Dialog ## ## Param 1 = Status ## Param 2 = Status Text ## ############################################################### ############################################################### # Is Swift Dialog present if [[ -a \"/Library/Application Support/Dialog/Dialog.app/Contents/MacOS/Dialog\" ]]; then echo \"$(date) | Updating Swift Dialog monitor for [$appname] to [$1]\" echo listitem: title: $appname, status: $1, statustext: $2 >> /var/tmp/dialog.log # Supported status: wait, success, fail, error, pending or progress:xx fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file installPKG"
        },
        {
            "filename": "file_512.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Office for Mac\\file_512.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to remove Microsoft Office for Mac ## includes - Outlook, Word, Excel, PowerPoint, OneDrive, OneNote and Teams ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define variables ############################## ## ## Note: This script will not do anything until the following lines are modified ## ## Line 50 - Uncommenting this will kill all Microsoft apps running on the Mac ## Line 97,98,99 - Uncommenting these will remove the users entire local Outlook data ## Line 109 - Uncommenting this will remove all folders defined in the folders variable ## Line 132 - Uncommenting this will remove any left over icons in the dock appname=\"Office Business Pro for Mac\" log=\"/var/log/uninstallofficebusinesspro.log\" # start logging exec 1>> $log 2>&1 echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting Removal of $appname\" echo \"############################################################\" echo \"\" consoleuser=$(ls -l /dev/console | awk '{ print $3 }') echo \"$(date) | logged in user is\" $consoleuser #pkill -f Microsoft dockitems=( \"/Applications/Microsoft Teams.app\" \"/Applications/Microsoft OneNote.app\" \"/Applications/Microsoft PowerPoint.app\" \"/Applications/Microsoft Excel.app\" \"/Applications/Microsoft Word.app\" \"/Applications/Microsoft Outlook.app\" \"/Applications/OneDrive.app\" ) icons=( \"Microsoft Excel\" \"Microsoft OneNote\" \"Microsoft Outlook\" \"Microsoft PowerPoint\" \"Microsoft Word\" \"Microsoft Teams\" \"OneDrive\" ) folders=( \"/Applications/Microsoft Excel.app\" \"/Applications/Microsoft OneNote.app\" \"/Applications/Microsoft Outlook.app\" \"/Applications/Microsoft PowerPoint.app\" \"/Applications/Microsoft Word.app\" \"/Applications/Microsoft Teams.app\" \"/Applications/OneDrive.app\" # \"/Users/$consoleuser/Library/Containers/com.microsoft.errorreporting\" \"/Users/$consoleuser/Library/Containers/com.microsoft.Excel\" \"/Users/$consoleuser/Library/Containers/com.microsoft.netlib.shipassertprocess\" \"/Users/$consoleuser/Library/Containers/com.microsoft.Office365ServiceV2\" \"/Users/$consoleuser/Library/Containers/com.microsoft.Outlook\" \"/Users/$consoleuser/Library/Containers/com.microsoft.Powerpoint\" \"/Users/$consoleuser/Library/Containers/com.microsoft.RMS-XPCService\" \"/Users/$consoleuser/Library/Containers/com.microsoft.Word\" \"/Users/$consoleuser/Library/Containers/com.microsoft.onenote.mac\" # # #### WARNING: Outlook data will be removed when you move the three folders listed below. #### You should back up these folders before you delete them. #### #### Uncomment to remove Outlook data # #\"/Users/$consoleuser/Library/Group Containers/UBF8T346G9.ms\" #\"/Users/$consoleuser/Library/Group Containers/UBF8T346G9.Office\" #\"/Users/$consoleuser/Library/Group Containers/UBF8T346G9.OfficeOsfWebHost\" # ) search=\"*\" for i in \"${folders[@]}\" do echo \"$(date) | removing folder ${i}\" #rm -rf \"${i}\" done if [ $? == 0 ]; then echo \"$(date) | Success\" else echo \"$(date) | Failure\" exit 1 fi echo \"$(date) | Removing Dock Items\" sudo rm -rf /tmp/dockutil git clone https://github.com/kcrawford/dockutil /tmp/dockutil if [ $? == 0 ]; then echo \"$(date) | Success\" else echo \"$(date) | Failured to install dockutil\" fi for i in \"${icons[@]}\" do echo \"$(date) | removing icon ${i}\" #/tmp/dockutil/scripts/dockutil --remove \"${i}\" --allhomes done"
        },
        {
            "filename": "file_513.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Office for Mac\\Outlook\\file_513.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to download and install OutlookResetPreferences app ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Set script variables appname=\"OutlookResetPreferences\" tempdir=\"/tmp\" targetapp=\"/Applications/Utilities/OutlookResetPreferences.app\" # function to check if softwareupdate is running to prevent us from installing Rosetta at the same time as another script isSoftwareUpdateRunning () { while ps aux | grep \"/usr/sbin/softwareupdate\" | grep -v grep; do echo \"$(date) | [/usr/sbin/softwareupdate] running, waiting...\" sleep 60 done echo \"$(date) | [/usr/sbin/softwareupdate] isn't running, lets carry on\" } # function to check if we need Rosetta 2 checkForRosetta2 () { # Wait here if software update is already running isSoftwareUpdateRunning echo \"$(date) | Checking if we need Rosetta 2 or not\" processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) if [[ \"$processor\" == *\"Intel\"* ]]; then echo \"$(date) | $processor processor detected, no need to install Rosetta.\" else echo \"$(date) | $processor processor detected, lets see if Rosetta 2 already installed\" # Check Rosetta LaunchDaemon. If no LaunchDaemon is found, # perform a non-interactive install of Rosetta. if [[ ! -f \"/Library/Apple/System/Library/LaunchDaemons/com.apple.oahd.plist\" ]]; then /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exit 1 fi else echo \"$(date) | Rosetta is already installed. Nothing to do.\" fi fi } checkForRosetta2 # Let's check to see if SetDefaultMailApp is already installed... if [[ -a $targetapp ]]; then echo \"$appname already installed, nothing to do here\" exit 0 else echo \"Downloading $appname\" curl -L -o \"$tempdir/$appname.zip\" 'https://download.microsoft.com/download/6/C/3/6C3CF698-61C1-4A6D-9F15-104BE03BC303/OutlookResetPreferences.zip' cd \"$tempdir\" unzip -o \"$appname.zip\" echo \"Moving $appname to Applications folder\" mv -f \"$tempdir/$appname.app\" $targetapp echo \"Fix up permissions\" sudo chown -R root:wheel \"$targetapp\" echo \"Cleaning up tmp files\" rm -rf \"$tempdir/$appname.zip\" fi"
        },
        {
            "filename": "file_514.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Office for Mac\\Outlook\\file_514.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to download and install OutlookResetRecentAddresses app ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Set script variables appname=\"OutlookResetRecentAddresses\" tempdir=\"/tmp\" targetapp=\"/Applications/Utilities/OutlookResetRecentAddresses.app\" # function to check if softwareupdate is running to prevent us from installing Rosetta at the same time as another script isSoftwareUpdateRunning () { while ps aux | grep \"/usr/sbin/softwareupdate\" | grep -v grep; do echo \"$(date) | [/usr/sbin/softwareupdate] running, waiting...\" sleep 60 done echo \"$(date) | [/usr/sbin/softwareupdate] isn't running, lets carry on\" } # function to check if we need Rosetta 2 checkForRosetta2 () { # Wait here if software update is already running isSoftwareUpdateRunning echo \"$(date) | Checking if we need Rosetta 2 or not\" processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) if [[ \"$processor\" == *\"Intel\"* ]]; then echo \"$(date) | $processor processor detected, no need to install Rosetta.\" else echo \"$(date) | $processor processor detected, lets see if Rosetta 2 already installed\" # Check Rosetta LaunchDaemon. If no LaunchDaemon is found, # perform a non-interactive install of Rosetta. if [[ ! -f \"/Library/Apple/System/Library/LaunchDaemons/com.apple.oahd.plist\" ]]; then /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exit 1 fi else echo \"$(date) | Rosetta is already installed. Nothing to do.\" fi fi } checkForRosetta2 # Let's check to see if SetDefaultMailApp is already installed... if [[ -a $targetapp ]]; then echo \"$appname already installed, nothing to do here\" exit 0 else echo \"Downloading $appname\" curl -L -o \"$tempdir/$appname.zip\" 'https://download.microsoft.com/download/D/B/D/DBDE37DD-7955-47A6-8E1A-C993F91C5753/OutlookResetRecentAddresses.zip' cd \"$tempdir\" unzip -o \"$appname.zip\" echo \"Moving $appname to Applications folder\" mv -f \"$tempdir/$appname.app\" $targetapp echo \"Fix up permissions\" sudo chown -R root:wheel \"$targetapp\" echo \"Cleaning up tmp files\" rm -rf \"$tempdir/$appname.zip\" fi"
        },
        {
            "filename": "file_515.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Office for Mac\\Outlook\\file_515.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to download and run Paul Bowdens MailtoOutlook tool ## this will change the default e-Mail client on the Mac to Outlook ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define variables tempdir=\"/tmp\" tempfile=\"/tmp/MailToOutlook.pkg\" weburl=\"https://macadmins.software/tools/MailToOutlook_2.1.pkg\" appname=\"MailToOutlook\" log=\"/var/log/MailToOutlook.log\" # function to check if softwareupdate is running to prevent us from installing Rosetta at the same time as another script isSoftwareUpdateRunning () { while ps aux | grep \"/usr/sbin/softwareupdate\" | grep -v grep; do echo \"$(date) | [/usr/sbin/softwareupdate] running, waiting...\" sleep 60 done echo \"$(date) | [/usr/sbin/softwareupdate] isn't running, lets carry on\" } # function to check if we need Rosetta 2 checkForRosetta2 () { # Wait here if software update is already running isSoftwareUpdateRunning echo \"$(date) | Checking if we need Rosetta 2 or not\" processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) if [[ \"$processor\" == *\"Intel\"* ]]; then echo \"$(date) | $processor processor detected, no need to install Rosetta.\" else echo \"$(date) | $processor processor detected, lets see if Rosetta 2 already installed\" # Check Rosetta LaunchDaemon. If no LaunchDaemon is found, # perform a non-interactive install of Rosetta. if [[ ! -f \"/Library/Apple/System/Library/LaunchDaemons/com.apple.oahd.plist\" ]]; then /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exit 1 fi else echo \"$(date) | Rosetta is already installed. Nothing to do.\" fi fi } # start logging exec 1>> $log 2>&1 # Begin Script Body echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting install of $appname\" echo \"############################################################\" echo \"\" # See if we need Rosetta checkForRosetta2 echo \"$(date) | Downloading $appname\" curl -L -f -o $tempfile $weburl if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname downloaded to $tempfile\" else echo \"$(date) | Failed to download from $weburl\" exit 1 fi echo \"$(date) | Running $appname\" installer -pkg $tempfile -target /Applications if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 2 fi"
        },
        {
            "filename": "file_516.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Python\\file_516.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [Python3] ## ## VER 3.0.3 ## ## Change Log ## ## 2022-02-11 - Added detection support for mpkg ## 2022-01-05 - Updated Rosetta detection code ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## 2021-12-06 - Added --compressed to curl cli ## - Fixed DMGPKG detection ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://www.python.org/ftp/python/3.9.10/python-3.9.10-macos11.pkg\" # What is the download URL? appname=\"Python3.9\" # The name of our App deployment script (also used for Octory monitor) app=\"/Python 3.9/IDLE.app \" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/Applications/Python 3.9/IDLE.app/Contents/MacOS/IDLE \" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname [$weburl]\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG|*.mpkg|*.MPKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Mounted succesfully to [$volume]\" else echo \"$(date) | Failed to mount [$tempfile]\" fi if [[ $(ls \"$volume\" | grep -i .app) ]] && [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected both APP and PKG in same DMG, exiting gracefully\" else if [[ $(ls \"$volume\" | grep -i .app) ]]; then echo \"$(date) | Detected APP, setting PackageType to DMG\" packageType=\"DMG\" fi if [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi if [[ $(ls \"$volume\" | grep -i .mpkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed echo \"$(date) | Setting default python version\" sudo rm -f /usr/local/bin/python sudo ln -s -f /usr/local/bin/python3 /usr/local/bin/python exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done for file in \"$volume\"/*.mpkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_517.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Remote Desktop\\file_517.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to download latest Microsoft Remote Desktop ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://go.microsoft.com/fwlink/?linkid=868963\" # What is the Azure Blob Storage URL? appname=\"Remote Desktop\" # The name of our App deployment script (also used for Octory monitor) app=\"Microsoft Remote Desktop.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installRemoteDesktop\" # The location of our logs and last updated data processpath=\"/Applications/Microsoft Remote Desktop.app/Contents/MacOS/Microsoft Remote Desktop\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # If true, application updates itself and we should not attempt to update # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_518.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Skype for Business\\file_518.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to download latest Microsoft Skype for Business app for macOS ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://go.microsoft.com/fwlink/?linkid=832978\" # What is the Azure Blob Storage URL? appname=\"Skype for Business\" # The name of our App deployment script (also used for Octory monitor) app=\"Skype for Business.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installSkypeForBusiness\" # The location of our logs and last updated data processpath=\"/Applications/Skype for Business.app/Contents/MacOS/Skype for Business\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # If true, application updates itself and we should not attempt to update # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_519.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Slack\\file_519.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [Slack] ## ## VER 3.0.1 ## ## Change Log ## ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://slack.com/ssb/download-osx-universal\" # What is the Azure Blob Storage URL? appname=\"Slack\" # The name of our App deployment script (also used for Octory monitor) app=\"Slack.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/Slack\" # The location of our logs and last updated data processpath=\"/Applications/Slack.app/Contents/MacOS/Slack\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) if [[ \"$processor\" == *\"Intel\"* ]]; then echo \"$(date) | [$processor] found, Rosetta not needed\" else echo \"$(date) | [$processor] found, is Rosetta already installed?\" # Check Rosetta LaunchDaemon. If no LaunchDaemon is found, # perform a non-interactive install of Rosetta. if [[ ! -f \"/Library/Apple/System/Library/LaunchDaemons/com.apple.oahd.plist\" ]]; then /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" return else echo \"$(date) | Rosetta installation failed!\" fi else echo \"$(date) | Rosetta is already installed. Nothing to do.\" fi fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if ls \"$volume\"/*.app 1> /dev/null 2>&1; then echo \"$(date) | Detected APP, setting PakageType to DMG\" packageType=\"DMG\" else if ls \"$volume\"/*.pkg 1> /dev/null 2>&1; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_520.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Sonos S2\\file_520.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [APPNAME] ## ## VER 3.0.6 ## ## Change Log ## ## 2022-02-28 - Updated file type detection logic where we can't tell what the file is by filename in downloadApp function ## 2022-02-23 - Added detection support for bz2 and tbz2 ## 2022-02-11 - Added detection support for mpkg ## 2022-01-05 - Updated Rosetta detection code ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## 2021-12-06 - Added --compressed to curl cli ## - Fixed DMGPKG detection ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://www.sonos.com/redir/controller_software_mac2\" # What is the Azure Blob Storage URL? appname=\"Sonos\" # The name of our App deployment script (also used for Octory monitor) app=\"$appname.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/Applications/Sonos.app/Contents/MacOS/Sonos\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then pid=$(ps -fe | grep \"$processName\" | grep -v grep | awk '{print $2}') echo \"$(date) | + [$appname] running, terminating [$processName] at pid [$pid]...\" kill -9 $pid return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname [$weburl]\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG|*.mpkg|*.MPKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.tbz2|*.TBZ2|*.bz2|*.BZ2) packageType=\"BZ2\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Mounted succesfully to [$volume]\" else echo \"$(date) | Failed to mount [$tempfile]\" fi if [[ $(ls \"$volume\" | grep -i .app) ]] && [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected both APP and PKG in same DMG, exiting gracefully\" else if [[ $(ls \"$volume\" | grep -i .app) ]]; then echo \"$(date) | Detected APP, setting PackageType to DMG\" packageType=\"DMG\" fi if [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi if [[ $(ls \"$volume\" | grep -i .mpkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file -z \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"DOS/MBR boot sector, extended partition table\"* ]] || [[ \"$metadata\" == *\"Apple Driver Map\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi if [[ \"$metadata\" == *\"POSIX tar archive (bzip2 compressed data\"* ]]; then packageType=\"BZ2\" mv \"$tempfile\" \"$tempdir/install.tar.bz2\" tempfile=\"$tempdir/install.tar.bz2\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we either need to wait or terminate waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done for file in \"$volume\"/*.mpkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } ## Install BZ2 Function function installBZ2 () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir tar -jxf \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile uncompressed\" else echo \"$(date) | failed to uncompress $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"BZ2\" ]]; then installBZ2 fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_521.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\TeamViewer\\file_521.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [TeamViewerHost] ## ## VER 3.0.1 ## ## Change Log ## ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://download.teamviewer.com/download/TeamViewerHost.dmg?utm_source=google&utm_medium=cpc&utm_campaign=restofeurope%7Cb%7Cpr%7C22%7Caug%7Ctv-core-download-sn%7Cnew%7Ct0%7C0&utm_content=Download&utm_term=teamviewer%20download%20for%20pc&gclid=CjwKCAjw3POhBhBQEiwAqTCuBoH6vpRkT_XoZfZBmZnCDObFZCUUWOdwk2K4AtCeNaRtZ4ygRPLV9RoCTioQAvD_BwE\" # What is the Azure Blob Storage URL? appname=\"TeamViewerHost\" # The name of our App deployment script (also used for Octory monitor) app=\"TeamViewerHost.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/TeamViewerHost\" # The location of our logs and last updated data processpath=\"/Applications/TeamViewerHost.app/Contents/MacOS/TeamViewerHost\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) if [[ \"$processor\" == *\"Intel\"* ]]; then echo \"$(date) | [$processor] found, Rosetta not needed\" else echo \"$(date) | [$processor] found, is Rosetta already installed?\" # Check Rosetta LaunchDaemon. If no LaunchDaemon is found, # perform a non-interactive install of Rosetta. if [[ ! -f \"/Library/Apple/System/Library/LaunchDaemons/com.apple.oahd.plist\" ]]; then /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" return else echo \"$(date) | Rosetta installation failed!\" fi else echo \"$(date) | Rosetta is already installed. Nothing to do.\" fi fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if ls \"$volume\"/*.app 1> /dev/null 2>&1; then echo \"$(date) | Detected APP, setting PakageType to DMG\" packageType=\"DMG\" else if ls \"$volume\"/*.pkg 1> /dev/null 2>&1; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_522.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\TeamViewer\\file_522.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [TeamViewer] ## ## VER 3.0.1 ## ## Change Log ## ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://download.teamviewer.com/download/TeamViewer.dmg?utm_source=google&utm_medium=cpc&utm_campaign=restofeurope%7Cb%7Cpr%7C22%7Caug%7Ctv-core-download-sn%7Cnew%7Ct0%7C0&utm_content=Download&utm_term=teamviewer%20download%20for%20pc&gclid=CjwKCAjw3POhBhBQEiwAqTCuBoH6vpRkT_XoZfZBmZnCDObFZCUUWOdwk2K4AtCeNaRtZ4ygRPLV9RoCTioQAvD_BwE\" # What is the Azure Blob Storage URL? appname=\"TeamViewer\" # The name of our App deployment script (also used for Octory monitor) app=\"TeamViewer.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/TeamViewer\" # The location of our logs and last updated data processpath=\"/Applications/TeamViewer.app/Contents/MacOS/TeamViewer\" # The process name of the App we are installing terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) if [[ \"$processor\" == *\"Intel\"* ]]; then echo \"$(date) | [$processor] found, Rosetta not needed\" else echo \"$(date) | [$processor] found, is Rosetta already installed?\" # Check Rosetta LaunchDaemon. If no LaunchDaemon is found, # perform a non-interactive install of Rosetta. if [[ ! -f \"/Library/Apple/System/Library/LaunchDaemons/com.apple.oahd.plist\" ]]; then /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" return else echo \"$(date) | Rosetta installation failed!\" fi else echo \"$(date) | Rosetta is already installed. Nothing to do.\" fi fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if ls \"$volume\"/*.app 1> /dev/null 2>&1; then echo \"$(date) | Detected APP, setting PakageType to DMG\" packageType=\"DMG\" else if ls \"$volume\"/*.pkg 1> /dev/null 2>&1; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_523.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Visual Studio Code\\file_523.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest Visual Studio Code ## ## VER 1.0.1 ## ## Change Log ## ## 2022-12-15 - Changed to use Universal Binary ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define variables weburl=\"https://code.visualstudio.com/sha/download?build=stable&os=darwin-universal\" # What is the Azure Blob Storage URL? appname=\"Visual Studio Code\" # The name of our App deployment script app=\"Visual Studio Code.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installVSCode\" # The location of our logs and last updated data processpath=\"/Applications/Visual Studio Code.app/Contents/MacOS/Electron\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # If true, application updates itself and we should not attempt to update # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_524.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\VMware Horizon Client\\file_524.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to download VMware Horizon Client app for macOS ## ########################################### ## Copyright (c) 2022 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. # User Defined variables weburl=\"https://download3.vmware.com/software/CART23FQ3_MAC_2209/VMware-Horizon-Client-2209-8.7.0-20615470.dmg\" appname=\"VMware Horizon Client\" # The name of our App deployment script (also used for Octory monitor) app=\"VMware Horizon Client.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installHorizonClient\" # The location of our logs and last updated data processpath=\"/Applications/VMware Horizon Client.app/Contents/MacOS/vmware-view\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # If true, application updates itself and we should not attempt to update # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_525.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\WhatsApp\\file_525.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest [WhatsApp] ## ## VER 3.0.6 ## ## Change Log ## ## 2022-02-28 - Updated file type detection logic where we can't tell what the file is by filename in downloadApp function ## 2022-02-23 - Added detection support for bz2 and tbz2 ## 2022-02-11 - Added detection support for mpkg ## 2022-01-05 - Updated Rosetta detection code ## 2021-11-19 - Added logic to handle both APP and PKG inside DMG file. New function DMGPKG ## 2021-12-06 - Added --compressed to curl cli ## - Fixed DMGPKG detection ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://web.whatsapp.com/desktop/mac/files/WhatsApp.dmg\" # What is the Azure Blob Storage URL? appname=\"WhatsApp\" # The name of our App deployment script (also used for Octory monitor) app=\"WhatsApp.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/Applications/$app/Contents/MacOS/WhatsApp\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname [$weburl]\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG|*.mpkg|*.MPKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.tbz2|*.TBZ2|*.bz2|*.BZ2) packageType=\"BZ2\" ;; *.dmg|*.DMG) # We have what we think is a DMG, but we don't know what is inside it yet, could be an APP or PKG # Let's mount it and try to guess what we're dealing with... echo \"$(date) | Found DMG, looking inside...\" # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image [$volume] [$tempfile]\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Mounted succesfully to [$volume]\" else echo \"$(date) | Failed to mount [$tempfile]\" fi if [[ $(ls \"$volume\" | grep -i .app) ]] && [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected both APP and PKG in same DMG, exiting gracefully\" else if [[ $(ls \"$volume\" | grep -i .app) ]]; then echo \"$(date) | Detected APP, setting PackageType to DMG\" packageType=\"DMG\" fi if [[ $(ls \"$volume\" | grep -i .pkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi if [[ $(ls \"$volume\" | grep -i .mpkg) ]]; then echo \"$(date) | Detected PKG, setting PackageType to DMGPKG\" packageType=\"DMGPKG\" fi fi # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file -z \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"DOS/MBR boot sector, extended partition table\"* ]] || [[ \"$metadata\" == *\"Apple Driver Map\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi if [[ \"$metadata\" == *\"POSIX tar archive (bzip2 compressed data\"* ]]; then packageType=\"BZ2\" mv \"$tempfile\" \"$tempdir/install.tar.bz2\" tempfile=\"$tempdir/install.tar.bz2\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMGPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi for file in \"$volume\"/*.pkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done for file in \"$volume\"/*.mpkg do echo \"$(date) | Starting installer for [$file]\" installer -pkg \"$file\" -target /Applications done # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } ## Install BZ2 Function function installBZ2 () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir tar -jxf \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile uncompressed\" else echo \"$(date) | failed to uncompress $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"BZ2\" ]]; then installBZ2 fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi # Install DMGPKG file if [[ $packageType == \"DMGPKG\" ]]; then installDMGPKG fi"
        },
        {
            "filename": "file_526.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Zoom\\file_526.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest Zoom client ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://zoom.us/client/latest/ZoomInstallerIT.pkg\" # What is the Azure Blob Storage URL (universal binary) appname=\"Zoom\" # The name of our App deployment script (also used for Octory monitor) app=\"zoom.us.app\" # The actual name of our App once installed logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/installZoom\" # The location of our logs and last updated data processpath=\"/Applications/zoom.us.app/Contents/MacOS/zoom.us\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"false\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" # Update Octory monitor updateOctory installing # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi installer -pkg \"$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateOctory installing # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateOctory installed exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_527.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Apps\\Zscaler\\file_527.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install Zscaler from Zscaler's CDN ## ## Based on https://github.com/microsoft/shell-intune-samples/tree/master/Apps/LatestSampleScript ## ## Download is always a zip; other methods removed for clarity ## ## Addidtional variables added to suit the installation $appdir, $installversion, $installerapp and $installargs ## ## Zscaler is unusual in that it installs to /Applications/Zscaler/Zscaler.app, and other oddities ## ## Use for fresh installs only. Script has NOT been tested to update the app as Zscaler autoupdate is preferred ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables installversion=\"3.6.1.19\" # Which version do we want? installerapp=\"Zscaler-osx-$installversion-installer.app\" # Name of the installer app that unzips weburl=\"https://d32a6ru7mhaq0c.cloudfront.net/$installerapp.zip\" # What is the Zscaler CDN URL? appname=\"Zscaler\" # The name of our App deployment script (also used for Octory monitor) app=\"Zscaler.app\" # The actual name of our App once installed appdir=\"Zscaler\" # Folder within /Applications where the App installs to logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" # The location of our logs and last updated data processpath=\"/Applications/$appdir/$app/Contents/MacOS/$appname\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit installargs=\"--unattendedmodeui none \\ --userDomain YOUR.DOMAIN.NAME \\ --cloudName YOUR_ZSCALER_CLOUD_NAME \\ --mode unattended\" # Arguments to pass to the installer. See https://community.zscaler.com/t/guide-deploy-zscaler-client-connector-with-intune-windows-macos/9121 # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate -install-rosetta -agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # wait for other downloads to complete waitForProcess \"curl -f\" #download the file updateOctory installing echo \"$(date) | Downloading $appname [$weburl]\" cd \"$tempdir\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 --compressed -L -J -O \"$weburl\" if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done packageType=\"ZIP\" else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateOctory failed exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateOctory installing # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$appdir/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$appdir/$app\" fi # Install the application sudo $installerapp/Contents/MacOS/installbuilder.sh $installargs if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname installed into /Applications/$appdir\" else echo \"$(date) | failed to install $appname to /Applications/$appdir\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$appdir/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateOctory failed exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$appdir/$app\" ]]; then echo \"$(date) | $appname Installed\" updateOctory installed echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$appdir/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateOctory () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update Octory status (if required) ## ## ## Parameters (updateOctory parameter) ## ## notInstalled ## installing ## installed ## ############################################################### ############################################################### # Is Octory present if [[ -a \"/Library/Application Support/Octory\" ]]; then # Octory is installed, but is it running? if [[ $(ps aux | grep -i \"Octory\" | grep -v grep) ]]; then echo \"$(date) | Updating Octory monitor for [$appname] to [$1]\" /usr/local/bin/octo-notifier monitor \"$appname\" --state $1 >/dev/null fi fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Check whether a version of Zscaler is already installed if [ -d \"/Applications/$appdir/$app\" ] then echo \"$(date) | Zscaler already installed at /Applications/$appdir/$app\" exit 0 fi # Install Rosetta if we need it checkForRosetta2 # Wait for Desktop waitForDesktop # Download app downloadApp # Install ZIP file installZIP"
        },
        {
            "filename": "file_528.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Bootstrap Token\\file_528.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to automatically re-escrow a macOS bootstrap token ## ############################################################################################ ## Copyright (c) 2023 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define variables ADMIN_USERNAME=\"<local admin username>\" ADMIN_PASSWORD=\"<local admin password>\" logdir=\"/Library/Application Support/Microsoft/IntuneScripts/checkBootstrapEscrow\" if [[ ! -d \"$logdir\" ]]; then ## Creating Log Directory echo \"$(date) | Creating [$logdir] to store logs\" mkdir -p \"$logdir\" fi exec &> >(tee -a \"$logdir/checkBootstrapEscrow.log\") # Function to print command output and status function print_status { echo \"$(date) | Command Output: $1\" if [ $2 -eq 0 ]; then echo \"$(date) | + Command succeeded.\" else echo \"$(date) | + Command failed.\" fi } # Check if the boostrap token was ever escrowed. If not, stop early as success. if echo \"profiles status -type bootstraptoken\" | grep -q \"Bootstrap Token escrowed to server: NO\"; then exit 0 fi # Check if we escrowed successfully in the past. If so, stop early as success. if cat \"$logdir/checkBootstrapEscrow.log\" | grep -q \"Bootstrap Token validated.\"; then exit 0 fi # Fail early if the account provided does not have secure token enabled if echo \"$SECURE_TOKEN_STATUS\" | grep -q \"Secure token is DISABLED\"; then echo \"$(date) | Secure token is disabled for $ADMIN_USERNAME. Not proceeding.\" exit 1 fi # Fail early if the account provided is not a valid username if echo \"$SECURE_TOKEN_STATUS\" | grep -q \"Unknown user\"; then echo \"$(date) | Unknown user $ADMIN_USERNAME. Not proceeding.\" exit 1 fi # Check Bootstrap Token status BOOTSTRAP_TOKEN_STATUS=$(profiles validate -type bootstraptoken -user $ADMIN_USERNAME -password $ADMIN_PASSWORD 2>&1) print_status \"$BOOTSTRAP_TOKEN_STATUS\" $? # Specifically check for \"escrowed: YES\" in the output if echo \"$BOOTSTRAP_TOKEN_STATUS\" | grep -q \"Bootstrap Token validated.\"; then echo \"$(date) | Bootstrap Token validation succeeded. Not proceeding with re-escrow.\" exit 0 else echo \"$(date) | Bootstrap Token validation failed. Re-escrowing token...\" # Attempt to escrow the Bootstrap Token ESCROW_RESULT=$(profiles install -type bootstraptoken -user $ADMIN_USERNAME -password $ADMIN_PASSWORD 2>&1) print_status \"$ESCROW_RESULT\" $? # Check status again after attempting to escrow sleep 10 # Wait for the server to process the request BOOTSTRAP_TOKEN_STATUS=$(profiles validate -type bootstraptoken -user $ADMIN_USERNAME -password $ADMIN_PASSWORD 2>&1) print_status \"$BOOTSTRAP_TOKEN_STATUS\" $? if echo \"$BOOTSTRAP_TOKEN_STATUS\" | grep -q \"Bootstrap Token validated.\"; then echo \"$(date) | Bootstrap Token escrowed successfully.\" else echo \"$(date) | Failed to escrow Bootstrap Token. Please check the MDM server or configuration.\" exit 1 fi fi"
        },
        {
            "filename": "file_529.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Bootstrap Token\\file_529.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to interactively re-escrow a macOS bootstrap token ## ############################################################################################ ## Copyright (c) 2023 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com logdir=\"/Library/Application Support/Microsoft/IntuneScripts/checkBootstrapEscrow\" if [[ ! -d \"$logdir\" ]]; then ## Creating Log Directory echo \"$(date) | Creating [$logdir] to store logs\" mkdir -p \"$logdir\" fi exec &> >(tee -a \"$logdir/checkBootstrapEscrow.log\") # Function to print command output and status function print_status { echo \"$(date) | Command Output: $1\" if [ $2 -eq 0 ]; then echo \"$(date) | + Command succeeded.\" else echo \"$(date) | + Command failed.\" fi } # Check if the boostrap token was ever escrowed. If not, stop early as success. if echo \"profiles status -type bootstraptoken\" | grep -q \"Bootstrap Token escrowed to server: NO\"; then exit 0 fi # Check if we escrowed successfully in the past. If so, stop early as success. if cat \"$logdir/checkBootstrapEscrow.log\" | grep -q \"Bootstrap Token validated.\"; then exit 0 fi DIALOG_ICON=\"/Library/Intune/Microsoft Intune Agent.app/Contents/Resources/AppIcon.icns\" # Prompt the user for an admin username ADMIN_USERNAME=$(osascript -e \"set T to text returned of (display dialog \\\"Your organization requires an update. Please provide the username for your local admin account.\\\" default answer \\\"\\\" with icon POSIX file \\\"$DIALOG_ICON\\\")\") # If no username was provided, fail the operation. if [ -z \"$ADMIN_USERNAME\" ]; then echo \"$(date) | Username not provided. Not proceeding.\" exit 1 fi # Check if the admin account has secure token enabled. If not, display an error message to the user and fail the operation. SECURE_TOKEN_STATUS=$(sysadminctl -secureTokenStatus $ADMIN_USERNAME 2>&1) print_status \"$SECURE_TOKEN_STATUS\" $? # Fail early if the account provided does not have secure token enabled if echo \"$SECURE_TOKEN_STATUS\" | grep -q \"Secure token is DISABLED\"; then echo \"$(date) | Secure token is disabled for $ADMIN_USERNAME. Not proceeding.\" osascript -e \"display dialog Error: user $ADMIN_USERNAME is not authorized to perform this operation. Please reach out to your IT administrator for assistance.\\\" buttons {\\\"OK\\\"} default button \\\"OK\\\" with icon POSIX file \\\"$DIALOG_ICON\\\"\" exit 1 fi # Fail early if the account provided is not a valid username if echo \"$SECURE_TOKEN_STATUS\" | grep -q \"Unknown user\"; then echo \"$(date) | Unknown user $ADMIN_USERNAME. Not proceeding.\" osascript -e \"display dialog \\\"Error: user $ADMIN_USERNAME is not authorized to perform this operation. Please reach out to your IT administrator for assistance.\\\" buttons {\\\"OK\\\"} default button \\\"OK\\\" with icon POSIX file \\\"$DIALOG_ICON\\\"\" exit 1 fi # Prompt the user for an admin password ADMIN_PASSWORD=$(osascript -e \"set T to text returned of (display dialog \\\"Enter the password for $ADMIN_USERNAME.\\\" with hidden answer default answer \\\"\\\" with icon POSIX file \\\"$DIALOG_ICON\\\")\") # If no password was provided, fail the operation. if [ -z \"${ADMIN_PASSWORD}\" ]; then echo \"$(date) | Password not provided. Not proceeding.\" exit 1 fi # Check Bootstrap Token status BOOTSTRAP_TOKEN_STATUS=$(profiles validate -type bootstraptoken -user $ADMIN_USERNAME -password $ADMIN_PASSWORD 2>&1) print_status \"$BOOTSTRAP_TOKEN_STATUS\" $? # Specifically check for \"escrowed: YES\" in the output if echo \"$BOOTSTRAP_TOKEN_STATUS\" | grep -q \"Bootstrap Token validated.\"; then echo \"$(date) | Bootstrap Token validation succeeded. Not proceeding with re-escrow.\" exit 0 else echo \"$(date) | Bootstrap Token validation failed. Re-escrowing token...\" # Attempt to escrow the Bootstrap Token ESCROW_RESULT=$(profiles install -type bootstraptoken -user $ADMIN_USERNAME -password $ADMIN_PASSWORD 2>&1) print_status \"$ESCROW_RESULT\" $? # Check status again after attempting to escrow sleep 10 # Wait for the server to process the request BOOTSTRAP_TOKEN_STATUS=$(profiles validate -type bootstraptoken -user $ADMIN_USERNAME -password $ADMIN_PASSWORD 2>&1) print_status \"$BOOTSTRAP_TOKEN_STATUS\" $? if echo \"$BOOTSTRAP_TOKEN_STATUS\" | grep -q \"Bootstrap Token validated.\"; then echo \"$(date) | Bootstrap Token escrowed successfully.\" else echo \"$(date) | Failed to escrow Bootstrap Token. Please check the MDM server or configuration.\" osascript -e \"display dialog \\\"An error occurred while attempting to perform this operation. Please reach out to your IT administrator for assistance.\\\" buttons {\\\"OK\\\"} default button \\\"OK\\\" with icon POSIX file \\\"$DIALOG_ICON\\\"\" exit 1 fi fi"
        },
        {
            "filename": "file_530.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\DeviceRename\\file_530.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to rename a Mac based on device type and serial number ## ############################################################################################ ## Copyright (c) 2021 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: paoloma@microsoft.com ## Define variables appname=\"DeviceRename\" logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" log=\"$logandmetadir/$appname.log\" CorporatePrefix=\"CO\" PersonalPrefix=\"BYO\" ABMOnly=\"false\" EnforceBYOD=\"false\" ## Check if the log directory has been created if [ -d $logandmetadir ]; then ## Already created echo \"# $(date) | Log directory already exists - $logandmetadir\" else ## Creating Metadirectory echo \"# $(date) | creating log directory - $logandmetadir\" mkdir -p $logandmetadir firstrun=\"true\" fi # start logging exec &> >(tee -a \"$log\") # Begin Script Body echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting $appname\" echo \"############################################################\" echo \"Writing log output to [$log]\" echo \"\" echo \" $(date) | Checking if renaming is necessary\" SerialNum=$(system_profiler SPHardwareDataType | awk '/Serial/ {print $4}' | cut -d ':' -f2- | xargs) if [ \"$?\" = \"0\" ]; then echo \" $(date) | Serial detected as $SerialNum\" else echo \"$(date) | Unable to determine serial number\" exit 1 fi CurrentNameCheck=$(scutil --get ComputerName) if [ \"$?\" = \"0\" ]; then echo \" $(date) | Current computername detected as $CurrentNameCheck\" else echo \"$(date) | Unable to determine current name\" exit 1 fi echo \" $(date) | Old Name: $CurrentNameCheck\" ModelName=$(system_profiler SPHardwareDataType | awk /'Model Name: '/ | cut -d ':' -f2- | xargs) if [ \"$?\" = \"0\" ]; then echo \" $(date) | Retrieved model name: $ModelName\" else echo \"$(date) | Unable to determine modelname\" exit 1 fi profiles status -type enrollment | grep \"Enrolled via DEP: Yes\" if [ \"$?\" = \"0\" ]; then echo \" $(date) | This device is enrolled by ABM\" OwnerPrefix=$CorporatePrefix elif [ \"$ABMOnly\" = \"false\" ]; then if [[ \"$firstrun\" = \"true\" || \"$EnforceBYOD\" = \"true\" ]]; then echo \" $(date) | This device is enrolled manually, assuming BYOD scenario.\" OwnerPrefix=$PersonalPrefix else echo \" $(date) | This device was enrolled manually. Device name will not be enforced after initial change.\" exit 0 fi else echo \" $(date) | This device is not enrolled by ABM, device name will not be changed.\" exit 0 fi ## What is our public IP echo \" $(date) | Looking up public IP\" myip=$(dig +short myip.opendns.com @resolver1.opendns.com) Country=$(curl -s 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69' https://ipapi.co/$myip/country) echo \" $(date) | Generating four characters code based on retrieved model name $ModelName\" case $ModelName in MacBook\\ Air*) ModelCode=MBA;; MacBook\\ Pro*) ModelCode=MBP;; MacBook*) ModelCode=MB;; iMac*) ModelCode=IMAC;; Mac\\ Pro*) ModelCode=PRO;; Mac\\ mini*) ModelCode=MINI;; Mac\\ Studio*) ModelCode=MS;; Apple\\ Virtual\\ Machine*) ModelCode=VM;; *) ModelCode=$(echo $ModelName | tr -d ' ' | cut -c1-4);; esac echo \" $(date) | OwnerPrefix variable set to $OwnerPrefix\" echo \" $(date) | ModelCode variable set to $ModelCode\" echo \" $(date) | Retrieved serial number: $SerialNum\" echo \" $(date) | Detected country as: $Country\" echo \" $(date) | Building the new name...\" NewName=\"\" if [[ -n \"$OwnerPrefix\" ]]; then NewName+=\"$OwnerPrefix\" fi if [[ -n \"$ModelCode\" && ! \"$ModelCode\" == *\"error\"* ]]; then if [[ -n \"$NewName\" ]]; then NewName+=\"-$ModelCode\" else NewName+=\"$ModelCode\" fi fi if [[ -n \"$SerialNum\" && ! \"$SerialNum\" == *\"error\"* ]]; then if [[ -n \"$NewName\" ]]; then NewName+=\"-$SerialNum\" else NewName+=\"$SerialNum\" fi fi if [[ -n \"$Country\" && ! \"$Country\" == *\"error\"* ]]; then if [[ -n \"$NewName\" ]]; then NewName+=\"-$Country\" fi fi echo \" $(date) | Generated Name: $NewName\" if [[ \"$CurrentNameCheck\" == \"$NewName\" ]] then echo \" $(date) | Rename not required already set to [$CurrentNameCheck]\" exit 0 fi #Setting ComputerName scutil --set ComputerName $NewName if [ \"$?\" = \"0\" ]; then echo \" $(date) | Computername changed from $CurrentNameCheck to $NewName\" else echo \" $(date) | Failed to rename the device from $CurrentNameCheck to $NewName\" exit 1 fi #Setting HostName scutil --set HostName $NewName if [ \"$?\" = \"0\" ]; then echo \" $(date) | HostName changed from $CurrentNameCheck to $NewName\" else echo \" $(date) | Failed to rename the device from $CurrentNameCheck to $NewName\" exit 1 fi #Setting LocalHostName scutil --set LocalHostName $NewName if [ \"$?\" = \"0\" ]; then echo \" $(date) | LocalHostName changed from $CurrentNameCheck to $NewName\" else echo \" $(date) | Failed to rename the device from $CurrentNameCheck to $NewName\" exit 1 fi"
        },
        {
            "filename": "file_531.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\DeviceRename\\file_531.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to rename a Mac based on Country Code and Serial Number ## ############################################################################################ ## Copyright (c) 2023 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: paoloma@microsoft.com ## Define variables appname=\"DeviceRename\" logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" log=\"$logandmetadir/$appname.log\" CountryCode=\"FI\" UAMDMStatus=$(profiles status -type enrollment | grep \"Enrolled via DEP: No\") ## Check if the log directory has been created if [ -d $logandmetadir ]; then ## Already created echo \"# $(date) | Log directory already exists - $logandmetadir\" else ## Creating Metadirectory echo \"# $(date) | creating log directory - $logandmetadir\" mkdir -p $logandmetadir fi # start logging exec &> >(tee -a \"$log\") # Begin Script Body echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting $appname\" echo \"############################################################\" echo \"Writing log output to [$log]\" echo \"\" ## Check if device is not enrolled to Apple Business Manager (ABM). If so, we will terminate this script immediately. Otherwise, we will continue. echo \" $(date) | Checking if this macOS-device is enrolled by ABM or not...\" if [ \"$UAMDMStatus\" == \"Enrolled via DEP: No\" ]; then echo \" $(date) | This device is not enrolled by ABM, device name will not be changed.\" exit 0 else echo \" $(date) | This device is enrolled by ABM\" fi echo \" $(date) | Checking if renaming is necessary\" SerialNum=$(system_profiler SPHardwareDataType | awk '/Serial/ {print $4}' | cut -d ':' -f2- | xargs) if [ \"$?\" = \"0\" ]; then echo \" $(date) | Serial detected as $SerialNum\" else echo \"$(date) | Unable to determine serial number\" exit 1 fi CurrentNameCheck=$(scutil --get ComputerName) if [ \"$?\" = \"0\" ]; then echo \" $(date) | Current computername detected as $CurrentNameCheck\" else echo \"$(date) | Unable to determine current name\" exit 1 fi echo \" $(date) | Retrieved serial number: $SerialNum\" echo \" $(date) | Detected country as: $CountryCode\" echo \" $(date) | Building the new name...\" NewName=$CountryCode-$SerialNum echo \" $(date) | Generated Name: $NewName\" if [[ \"$CurrentNameCheck\" == \"$NewName\" ]] then echo \" $(date) | Rename not required already set to [$CurrentNameCheck]\" exit 0 fi # Setting ComputerName scutil --set ComputerName $NewName if [ \"$?\" = \"0\" ]; then echo \" $(date) | Computername changed from $CurrentNameCheck to $NewName\" else echo \" $(date) | Failed to rename the device from $CurrentNameCheck to $NewName\" exit 1 fi # Setting HostName scutil --set HostName $NewName if [ \"$?\" = \"0\" ]; then echo \" $(date) | HostName changed from $CurrentNameCheck to $NewName\" else echo \" $(date) | Failed to rename the device from $CurrentNameCheck to $NewName\" exit 1 fi # Setting LocalHostName scutil --set LocalHostName $NewName if [ \"$?\" = \"0\" ]; then echo \" $(date) | LocalHostName changed from $CurrentNameCheck to $NewName\" else echo \" $(date) | Failed to rename the device from $CurrentNameCheck to $NewName\" exit 1 fi"
        },
        {
            "filename": "file_532.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Dock\\file_532.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to wait for apps to be installed and then configure the Mac Dock ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com useDockUtil=false waitForApps=true # Hold script until Dock is running, otherwise we might run under _mbsetupuser which would be bad until pgrep -x \"Dock\" &>/dev/null; do sleep 10 done currentUser=$( scutil <<< \"show State:/Users/ConsoleUser\" | awk '/Name :/ { print $3 }' ) # Get uid logged in user uid=$(id -u \"${currentUser}\") # Current User home folder - do it this way in case the folder isn't in /Users userHome=$(dscl . -read /users/${currentUser} NFSHomeDirectory | cut -d \" \" -f 2) # Logging folder and files logFolder=\"/Library/Logs/Microsoft/IntuneScripts/addAppstoDock\" log=${logFolder}/addAppstoDock.log mkdir -p \"$logFolder\" exec &> >(tee -a \"$log\") # Path to plist plist=\"${userHome}/Library/Preferences/com.apple.dock.plist\" # Determine the correct settings app if [[ -e \"/System/Applications/System Settings.app\" ]]; then settingsApp=\"System Settings.app\" else settingsApp=\"System Preferences.app\" fi dockapps=( \"/System/Applications/Launchpad.app\" \"/Applications/Microsoft Edge.app\" \"/Applications/Microsoft Outlook.app\" \"/Applications/Microsoft Word.app\" \"/Applications/Microsoft Excel.app\" \"/Applications/Microsoft PowerPoint.app\" \"/Applications/Microsoft OneNote.app\" \"/Applications/Microsoft Teams.app\" \"/Applications/Visual Studio Code.app\" \"/Applications/Company Portal.app\" \"/Library/Application Support/Microsoft/MAU2.0/Microsoft AutoUpdate.app\" \"/System/Applications/App Store.app\" \"/System/Applications/Utilities/Terminal.app\" \"/System/Applications/$settingsApp\") install_dockutil_if_missing() { # Check if dockutil is installed if [[ ! -e \"/usr/local/bin/dockutil\" ]]; then echo \"$(date) | dockutil is not present, installing\" # Download dockutil package if curl -L \"https://github.com/kcrawford/dockutil/releases/download/3.1.3/dockutil-3.1.3.pkg\" -o /var/tmp/dockutil.pkg; then echo \"$(date) | Successfully downloaded dockutil.pkg\" else echo \"$(date) | Failed to download dockutil.pkg\" return 1 fi # Install dockutil package if sudo installer -pkg /var/tmp/dockutil.pkg -target /; then echo \"$(date) | Successfully installed dockutil\" else echo \"$(date) | Failed to install dockutil\" return 1 fi else echo \"$(date) | dockutil is already present\" fi } # Convienience function to handle swiftDialog status updates # usage: updateSplashScreen \"status\" \"message\" function update_swift_dialog () { if [[ -e \"/Library/Application Support/Dialog/Dialog.app/Contents/MacOS/Dialog\" ]]; then # Supported status: wait, success, fail, error, pending or progress:xx echo \"$(date) | Updating Swift Dialog monitor for Dock to [$1]\" echo listitem: title: Dock, status: $1, statustext: $2 >> /var/tmp/dialog.log fi } # Convenience function to run a command as the current user # usage: run_as_user command arguments... run_as_user() { if [[ \"${currentUser}\" != \"loginwindow\" ]]; then launchctl asuser \"$uid\" sudo -u \"${currentUser}\" \"$@\" else echo \"no user logged in\" exit 1 fi } configure_dock_with_dockutil () { # Update Swift Dialog update_swift_dialog wait \"Configuring dock...\" dockutil=\"/usr/local/bin/dockutil\" # Clear Dock run_as_user \"${dockutil}\" --remove all --no-restart ${plist} # Add Apps to Dock in order for app in \"${dockapps[@]}\"; do if [[ -e \"$app\" ]]; then echo \"$(date) | Adding ${app} to Dock...\" run_as_user \"${dockutil}\" --add \"${app}\" --section apps --no-restart ${plist} > /dev/null 2>&1 else echo \"$(date) | ${app} not installed, skipping...\" fi done # Add Downloads Folder run_as_user \"${dockutil}\" --add \"${userHome}/Downloads\" --section others --no-restart ${plist} > /dev/null 2>&1 killall -KILL Dock touch \"/Users/$currentUser/Library/Preferences/.dockconfigured\" update_swift_dialog success \"Configured dock...\" } configure_dock_via_plist () { # Update Swift Dialog update_swift_dialog wait \"Configuring dock...\" # Clearing Dock echo \"$(date) | Removing Dock Persistent Apps\" #run_as_user defaults delete com.apple.dock run_as_user defaults delete com.apple.dock persistent-apps run_as_user defaults delete com.apple.dock persistent-others echo \"$(date) | Adding Apps to Dock\" for i in \"${dockapps[@]}\"; do if [[ -a \"$i\" ]] ; then echo \"$(date) | Adding [$i] to Dock\" run_as_user defaults write com.apple.dock persistent-apps -array-add \"<dict><key>tile-data</key><dict><key>file-data</key><dict><key>_CFURLString</key><string>$i</string><key>_CFURLStringType</key><integer>0</integer></dict></dict></dict>\" update_swift_dialog wait \"Adding $i to Dock\" fi done echo \"$(date) | Adding Downloads Stack\" downloadfolder=\"${userHome}/Downloads\" run_as_user defaults write com.apple.dock persistent-others -array-add \"<dict><key>tile-data</key><dict><key>file-data</key><dict><key>_CFURLString</key><string>$downloadfolder</string><key>_CFURLStringType</key><integer>0</integer></dict><key>file-label</key><string>Downloads</string><key>file-type</key><string>2</string></dict><key>tile-type</key><string>directory-tile</string></dict>\" #echo \"$(date) | Enabling Magnification\" #defaults write com.apple.dock magnification -boolean YES #echo \"$(date) | Enable Dim Hidden Apps in Dock\" #defaults write com.apple.dock showhidden -bool true #echo \"$(date) | Enable Auto Hide dock\" #defaults write com.apple.dock autohide -bool true #echo \"$(date) | Disable show recent items\" #defaults write com.apple.dock show-recents -bool FALSE #echo \"$(date) | Enable Minimise Icons into Dock Icons\" #defaults write com.apple.dock minimize-to-application -bool yes echo \"$(date) | Restarting Dock\" killall -KILL Dock touch \"/Users/$currentUser/Library/Preferences/.dockconfigured\" update_swift_dialog success \"Configured dock...\" } wait_for_apps_installation() { local timeout=$1 local start_time=$(date +%s) update_swift_dialog wait \"Waiting for apps...\" while true; do all_installed=true for app in \"${dockapps[@]}\"; do if [[ ! -e \"$app\" ]]; then all_installed=false break fi done if [[ \"$all_installed\" = true ]]; then echo \"$(date) | All apps are installed\" return 0 fi current_time=$(date +%s) elapsed_time=$(( current_time - start_time )) if [[ $elapsed_time -ge $timeout ]]; then echo \"$(date) | Timeout reached. Not all apps are installed.\" return 1 fi sleep 5 # Sleep for a few seconds before checking again done } ## Script Begins Here # Check if apps are installed if [[ \"$waitForApps\" == true ]]; then echo \"$(date) | Waiting for apps to be installed...\" wait_for_apps_installation 900 # Wait 900 seconds for apps to be installed fi # if useDockUtil is true, use dockutil to configure the dock if [[ \"$useDockUtil\" == true ]]; then echo \"$(date) | Configuring dock with dockutil\" install_dockutil_if_missing configure_dock_with_dockutil else echo \"$(date) | Configuring dock with plist\" configure_dock_via_plist fi"
        },
        {
            "filename": "file_533.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\EnableOneDriveFinderSync\\file_533.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to enable the Finder Extension for OneDrive ## ############################################################################################ # # NOTE # Script must run in user credentials # ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: scbree@microsoft.com Application=\"/Applications/OneDrive.app\" logandmetadir=\"/tmp/EnableOneDriveFinderSync\" log=\"$logandmetadir/Script-EnableOneDriveFinderSync.log\" ## Check if the log directory has been created if [ -d $logandmetadir ]; then ## Already created echo \"# $(date) | Log directory already exists - $logandmetadir\" else ## Creating Metadirectory echo \"# $(date) | creating log directory - $logandmetadir\" mkdir -p $logandmetadir fi exec 1>> $log 2>&1 echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting config of $Application\" echo \"############################################################\" echo \"\" echo \"$(date) | OneDrive config: Looking for required applications... \" #wait for OneDrive to be installed while [[ $ready -ne 1 ]];do if [[ -a \"$Application\" ]]; then ready=1 echo \"$(date) | $Application found!\" else echo \"$(date) | OneDrive config: $i not installed yet\" echo \"$(date) | OneDrive config: Waiting for 60 seconds\" sleep 60 fi done ## Get Extension Name (differs between standalone and VPP version) echo \"$(date) | Finding installed OneDrive type (VPP or standalone)\" if pluginkit -m | grep \"com.microsoft.OneDrive-mac.FinderSync\"; then echo \"$(date) | OneDrive installed via VPP. Extension name is com.microsoft.OneDrive-mac.FinderSync\" ExtensionName=\"com.microsoft.OneDrive-mac.FinderSync\" fi if pluginkit -m | grep \"com.microsoft.OneDrive.FinderSync\"; then echo \"$(date) | OneDrive installed standalone. Extension name is com.microsoft.OneDrive.FinderSync\" ExtensionName=\"com.microsoft.OneDrive.FinderSync\" fi ## check if the extension is already enabled and enable it echo \"$(date) | Checking extension status\" if pluginkit -m | grep \"+ $ExtensionName\"; then echo \"$(date) | OneDrive FinderSync already enabled\" else echo \"$(date) | OneDrive config: Enabling FinderSync\" echo \"$(date) | running pluginkit -e use -i $ExtensionName\" pluginkit -e use -i $ExtensionName echo \"$(date) | Script finished\" fi"
        },
        {
            "filename": "file_534.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\enableScreenSharing\\file_534.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to enable Remote Screen Sharing ## ############################################################################################ ## Copyright (c) 2021 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: paoloma@microsoft.com ## ## This script will enable remote screen sharing on the Mac so that an Administrator can connecta via the Remote Screen Sharing App ## # User Defined variables appname=\"EnableScreenSharing\" # The name of our App deployment script (also used for Octory monitor) logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/EnableScreenSharing\" # The location of our logs and last updated data # Generated variables log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) # Function to start logging function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging configuration of [$appname] to [$log]\" echo \"############################################################\" echo \"\" echo \"$(date) | Writing to /var/db/launchd.db/com.apple.launchd/overrides.plist\" sudo defaults write /var/db/launchd.db/com.apple.launchd/overrides.plist com.apple.screensharing -dict Disabled -bool false echo \"$(date) | Launching com.apple.screensharing Launch Daemon\" sudo launchctl load -w /System/Library/LaunchDaemons/com.apple.screensharing.plist # # Note: If you don't do this, the remote client will just see a black screen with the vnc client or screen sharing app won't connect. # however, by resetting the Screen Capture permissions, anything that has previously been granted the permission will need to be re-added # this includes things like Teams, Zoom, Snagit etc. # # On an ADE enrolled Mac this probably isn't a problem, but for a user initiated enrollment it probably is something you'll want to think about # before deploying widely. echo \"$(date) | Reset Screen Capture Permissions\" sudo tccutil reset ScreenCapture"
        },
        {
            "filename": "file_535.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Escrow Buddy\\file_535.sh",
            "content": "#!/bin/bash #set -x # Script Name: installEB.sh # Description: This script downloads and installs the latest release of Escrow Buddy, a security agent plugin for macOS. # The script checks if the log directory has been created and creates it if necessary. # It also defines several functions for downloading and updating Escrow Buddy, as well as checking if the Escrow Buddy authorizationdb entry is configured. # The logger function is used to log messages to stdout and a log file. # Version: 1.0.2 # Author: Tobias Alm\u00e9n # Date: 2024-06-14 # Manual version override version=\"\" # Only configure this if you want to control the version of Escrow Buddy that is installed, otherwise leave it blank. Example: version=\"1.0.0\" # Set the path to the installed Escrow Buddy bundle install_path=\"/Library/Security/SecurityAgentPlugins/Escrow Buddy.bundle\" # Set the path to the log directory logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/EscrowBuddy\" # File to store last updatedtime lastupdated=\"$logandmetadir/lastupdated\" # Set the API URL for the latest release of Escrow Buddy eb_url=\"https://api.github.com/repos/macadmins/escrow-buddy/releases/latest\" # Set the path to the installed Escrow Buddy bundle install_path=\"/Library/Security/SecurityAgentPlugins/Escrow Buddy.bundle\" # Curl the API URL for the latest release and download url of Escrow Buddy response=$(curl --silent \"$eb_url\") # Get the latest release of Escrow Buddy latest_release=$(echo \"$response\" | grep -o '\"tag_name\": \"[^\"]*' | grep -o '[^\"]*$') # Get the numerical version of the latest release of Escrow Buddy latest_version=$(echo \"$latest_release\" | cut -c 2-) # Get FDE status FDE_STATUS=$(fdesetup status) # Get FDE profile status FDE_PROFILE=\"/Library/Managed Preferences/com.apple.security.FDERecoveryKeyEscrow.plist\" # Path to FileVaultPRK PRK=\"/var/db/FileVaultPRK.dat\" ## Check if the log directory has been created if [ -d $logandmetadir ]; then ## Already created echo \"[$(date +\"%Y-%m-%d %H:%M:%S\")] [INFO] Log directory already exists - $logandmetadir\" else ## Creating Metadirectory echo \"[$(date +\"%Y-%m-%d %H:%M:%S\")] [INFO] creating log directory - $logandmetadir\" mkdir -p $logandmetadir fi # Function to log messages to stdout function logger() { # Function to log messages to stdout and a log file # # Arguments: # $1: The log level (e.g. INFO, WARNING, ERROR) # $2: The message to log level=$1 message=$2 # Log the message with the current date and time and the specified log level date=$(date +\"%Y-%m-%d %H:%M:%S\") echo \"[$date] [$level] $message\" echo \"[$date] [$level] $message\" >> \"$logandmetadir/installeb.log\" } function remediate() { # Function to remediate missing FV key # # Arguments: # None # Returns: # None # Variables: # $FDE_STATUS: The status of FileVault # $FDE_PROFILE: FDE profile path # $PRK: The path to the FileVaultPRK # If FileVault is not enabled, exit if [ \"FileVault is On.\" != \"$FDE_STATUS\" ]; then exit 0 fi # If the escrow plist exists, check for the recovery key file if [ -f \"$FDE_PROFILE\" ]; then # If the key has been escrowed, exit if [ -f \"$PRK\" ]; then logger \"INFO\" \"Key has been escrowed\" # If the key has not been escrowed, set GenerateNewKey to true else logger \"INFO\" \"Key has not been escrowed\" defaults write /Library/Preferences/com.netflix.Escrow-Buddy.plist GenerateNewKey -bool true fi # If the escrow plist does not exist, do nothing else logger \"INFO\" \"No FileVault profile has been applied\" fi } function getVersion() { # Convert a version string in the format x.y.z.w to an integer # Nabbed from Matt's WS1 example and slightly modified # # Arguments: # $1: The version string to convert # Returns: # The integer representation of the version string # Variables: # None echo \"$1\" | awk -F. '{ printf(\"%d%d%d%d\\n\", $1,$2,$3,$4); }' } # Function to download the latest release of Escrow Buddy function downloadEscrowBuddy() { # Download the latest release of Escrow Buddy # # Arguments: # None # Returns: # None # Variables: # $response: The response from the API URL for the latest release of Escrow Buddy # $download_url: The download URL for the latest release of Escrow Buddy # Get the download URL for the latest release download_url=$(echo \"$response\" | grep -o '\"browser_download_url\": \"[^\"]*' | grep -o '[^\"]*$' | grep -i '\\.pkg$') # Download the latest release of Escrow Buddy logger \"INFO\" \"Downloading Escrow Buddy $latest_release\" curl -L -s \"$download_url\" -o \"/tmp/Escrow.Buddy.pkg\" # Check if the download was successful if [ $? -eq 0 ]; then logger \"INFO\" \"Escrow Buddy $latest_release downloaded successfully\" else logger \"ERROR\" \"Escrow Buddy $latest_release download failed\" exit 1 fi } # Function to update Escrow Buddy if a new version is available function updateEscrowBuddy() { # Update Escrow Buddy if a new version is available # # Arguments: # input_version: The highest version of Escrow Buddy to install # Returns: # None # Variables: # $response: The response from the API URL for the latest release of Escrow Buddy # $download_url: The download URL for the latest release of Escrow Buddy # $lastmodified: The last modified date of the latest release of Escrow Buddy # $previouslastmodifieddate: The last modified date of the previously installed release of Escrow Buddy # $lastupdated: The path to the file containing the last modified date of the previously installed release of Escrow Buddy # Manual version override input_version=$1 # If the input version is set, check if an update is available if [ \"$input_version\" ]; then # Check if Escrow Buddy is installed if [ -d \"$install_path\" ]; then # If the input version is not the same as the latest version, log a warning if [ $(getVersion $input_version) != $(getVersion $latest_version) ]; then logger \"WARNING\" \"Input version [$input_version] does not match latest version [$latest_version]\" # If the input version and the latest version are the same, check if an update is available else # Get the version of the currently installed release of Escrow Buddy installed_version=$(defaults read \"$install_path\"/Contents/Info.plist CFBundleShortVersionString) if [ $(getVersion $input_version) -gt $(getVersion $installed_version) ]; then logger \"INFO\" \"Update found, input version [$input_version] and current [$installed_version]\" # Install the latest release of Escrow Buddy installEscrowBuddy else logger \"INFO\" \"No update found, input version [$input_version] and current [$installed_version]\" fi fi else logger \"INFO\" \"Unable to check for updates, Escrow Buddy is not installed, installing\" # Install the latest release of Escrow Buddy installEscrowBuddy fi else # Get the download URL for the latest release download_url=$(echo \"$response\" | grep -o '\"browser_download_url\": \"[^\"]*' | grep -o '[^\"]*$' | grep -i '\\.pkg$') # Get the last modified date for the latest release lastmodified=$(curl -sIL \"$download_url\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') # Check if the last modified date of the latest release is different to the last modified date of the previously installed release if [ -f \"$lastupdated\" ]; then previouslastmodifieddate=$(cat \"$lastupdated\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then logger \"INFO\" \"Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" # Install the latest release of Escrow Buddy installEscrowBuddy # If the last modified date of the latest release is the same as the last modified date of the previously installed release, do nothing else logger \"INFO\" \"No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" fi # If the last modified date of the previously installed release is not found, install the latest release of Escrow Buddy else logger \"INFO\" \"Meta file [$lastupdated] not found\" logger \"INFO\" \"Unable to determine if update required so updating anyway\" # Install the latest release of Escrow Buddy installEscrowBuddy fi fi } # Function to install Escrow Buddy function installEscrowBuddy() { # Install the latest release of Escrow Buddy # # Arguments: # None # Returns: # None # Variables: # None # Install Escrow Buddy downloadEscrowBuddy logger \"INFO\" \"Installing Escrow Buddy\" sudo installer -pkg \"/tmp/Escrow.Buddy.pkg\" -target \"/\" > /dev/null 2>&1 exitcode=$? # Clean up rm -f \"/tmp/Escrow.Buddy.pkg\" # Check if the installation was successful if [ $exitcode -eq 0 ]; then logger \"INFO\" \"Escrow Buddy installed successfully\" lastmodified=$(curl -sIL \"$download_url\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') logger \"INFO\" \"Writing last update information to [$lastupdated]\" echo $lastmodified >\"$lastupdated\" else logger \"ERROR\" \"Escrow Buddy installation failed\" exit 1 fi } # Check if Escrow Buddy is already installed if [ -d \"$install_path\" ]; then # If Escrow Buddy is already installed, check if an update is required logger \"INFO\" \"Escrow Buddy already installed, checking for update\" updateEscrowBuddy $version else # If Escrow Buddy is not installed, install it logger \"INFO\" \"Escrow Buddy not installed, installing\" installEscrowBuddy fi # Check if Escrow Buddy authorizationdb entry is configured \"$install_path\"/Contents/Resources/AuthDBSetup.sh | while read line; do logger \"INFO\" \"$line\" done # Run remediation remediate"
        },
        {
            "filename": "file_536.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\M365 Profile Photo Sync\\file_536.sh",
            "content": "#!/bin/bash Ver=\"2309.27\" #set -x ############################################################################################ ## ## Script to download the profile photo from entraID ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: marc.nahum@microsoft.com # User Defined variables clientID=\"\" secretValue=\"\" tenantID=\"\" # Standard Variables userName=$(ls -l /dev/console | awk '{ print $3 }') headers=(-H \"Content-Type: application/x-www-form-urlencoded\") logDir=\"/Library/logs/Microsoft/IntuneScripts/PhotoID\" log=$logDir\"/PhotoID.log\" file=\"PhotoID.jpg\" # Generated Variables url=\"https://login.microsoftonline.com/$tenantID/oauth2/v2.0/token\" #data=\"client_id=$clientID&scope=https%3A%2F%2Fgraph.microsoft.com%2F.default&client_secret=$secretValue&grant_type=client_credentials\" data=\"client_id=$clientID&scope=https://graph.microsoft.com/.default&client_secret=$secretValue&grant_type=client_credentials\" ## Check if the log directory has been created if [ -d $logDir ]; then ## Already created echo \"$(date) | log directory already exists - $logDir\" else ## Creating Metadirectory echo \"$(date) | creating log directory - $logDir\" mkdir -p $logDir fi # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } # start logging exec &> >(tee -a \"$log\") # Begin Script Body echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting run PhotoID ([$Ver])\" echo \"############################################################\" echo \"\" # We don't want to interrupt setup assistant waitForDesktop # Attempt to read UPN from OfficeActivationEmailAddress officePlistPath=\"/Library/Managed Preferences/com.microsoft.office.plist\" # Set Max Retries max_retries=10 retries=0 until [ -e \"$officePlistPath\" ]; do # Check if the current time has exceeded the end time echo \"$(date) | Looking for Office Plist File [$officePlistPath]\" if [ \"$retries\" -ge \"$max_retries\" ]; then echo \"$(date) | Office plist file not found [$officePlistPath]\" exit 1 fi # If the file is not found, sleep for the specified interval ((retries++)) sleep 30 done echo \"$(date) | Office plist file found [$officePlistPath]\" echo \"$(date) | Trying to determine UPN from OfficeActivationEmailAddress\" UPN=$(defaults read /Library/Managed\\ Preferences/com.microsoft.office.plist OfficeActivationEmailAddress) if [ $? == 0 ]; then echo \"$(date) | + UPN found as [$UPN]\" else echo \"$(date) | + UPN not found, exiting (did you set Office Activation e-Mail is Settings Picker?)\" exit 1 fi # Attempt to get a token from Entra echo \"$(date) | Getting the Token\" token=$(curl -s -X POST \"${headers[@]}\" -d \"$data\" \"$url\" | sed -E 's/.*\"access_token\":\"([^\"]+)\".*/\\1/') #Use the Token to download the photo photoURL=\"https://graph.microsoft.com/beta/users/$UPN/photo/\\$value\" headers2=\"Authorization: Bearer $token\" pathPhoto=\"/Users/$userName/$file\" echo \"$(date) | getting the Photo [$file]\" curl -s --location --request GET \"$photoURL\" --header \"${headers2[@]}\" --output $pathPhoto # Check if image was written to disk if [ ! -f $pathPhoto ]; then echo \"$(date) | Failed to write image to disk [$pathPhoto]]\" exit 1 else echo \"$(date) | Image written to disk [$pathPhoto]\" fi # Set the user photo echo \"$(date) | Setting the user photo from [$pathPhoto]\" TF=$(mktemp) ER=0x0A # `0x0A` (Hex) = `10` (ASCII) = `LF` EC=0x5C # `0x5C` (Hex) = `92` (ASCII) = `\\` FS=0x3A # `0x3A` (Hex) = `58` (ASCII) = `:` VS=0x2C # `0x2C` (Hex) = `44` (ASCII) = `,` # Write a record description (header line) to the import file echo \"$(date) | Write a record description (header line) to the import file\" echo \"$ER $EC $FS $VS dsRecTypeStandard:Users 2 RecordName externalbinary:JPEGPhoto\" > $TF # Write the record to the import file echo \"$(date) | Write the record to the import file\" echo \"$userName:$pathPhoto\" >> $TF # Delete the existing `JPEGPhoto` attribute for the user echo \"$(date) | Delete the existing photo for [$userName]\" dscl . delete /Users/$userName JPEGPhoto # Quit System Settings (previously System Preferences prior to macOS Ventura 13) SETTINGS=\"System Settings\" if [[ $(system_profiler SPSoftwareDataType | awk '/System Version/ {print $4}' | cut -d . -f 1) -lt 13 ]]; then SETTINGS=\"System Preferences\" fi killall \"$SETTINGS\" 2> /dev/null # Write STDERR to /dev/null to supress message if process isn't running # Import the record updating the `JPEGPhoto` attribute for the user echo \"$(date) | Import new photo for [$userName]\" dsimport $TF /Local/Default M # Clean up rm $TF"
        },
        {
            "filename": "file_537.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Manage Accounts\\file_537.sh",
            "content": "#!/usr/bin/env bash #set -x ############################################################################################ ## ## Script to create Local Admin Account for IT Use ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com ## ## Notes ## ## This script creates a new Admin account for temporary IT Admin purposes ## The Admin password is a super simple cipher + base64 of the device serial number. ## i.e. ABCDEF000009 becomes S0xNTk9QNDQ0NDQzCg== ## ## WARNING: It is strongly recommended to change the cipher on line 54 before deploying into production, this is shown for example purposes only # Define variables adminaccountname=\"localadmin\" # This is the accountname of the new admin adminaccountfullname=\"Local Admin\" # This is the full name of the new admin user scriptname=\"Create Local Admin Account\" logandmetadir=\"/Library/IntuneScripts/createLocalAdminAccount\" log=\"$logandmetadir/createLocalAdminAccount.log\" # function to delay until the user has finished setup assistant. waitforSetupAssistant () { until [[ -f /var/db/.AppleSetupDone ]]; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Setup Assistant not done, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Setup Assistant is done, lets carry on\" } ## Check if the log directory has been created and start logging if [ -d $logandmetadir ]; then ## Already created echo \"# $(date) | Log directory already exists - $logandmetadir\" else ## Creating Metadirectory echo \"# $(date) | creating log directory - $logandmetadir\" mkdir -p $logandmetadir fi # start logging exec 1>> $log 2>&1 # Begin Script Body echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting $scriptname\" echo \"############################################################\" echo \"\" echo \"Creating new local admin account [$adminaccountname]\" p=`system_profiler SPHardwareDataType | awk '/Serial/ {print $4}' | tr '[A-Z]' '[K-ZA-J]' | tr 0-9 4-90-3 | base64` waitforSetupAssistant echo \"Adding $adminaccountname to hidden users list\" sudo defaults write /Library/Preferences/com.apple.loginwindow HiddenUsersList -array-add \"$adminaccountname\" sudo sysadminctl -deleteUser \"$adminaccountname\" # Remove existing admin account if it exists sudo sysadminctl -adminUser \"$adminaccountname\" -adminPassword \"$p\" -addUser \"$adminaccountname\" -fullName \"$adminaccountfullname\" -password \"$p\" -admin"
        },
        {
            "filename": "file_538.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Manage Accounts\\file_538.sh",
            "content": "#!/bin/zsh #set -x ############################################################################################ ## ## Script to downgrade all users to Standard Users ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com ## ## Notes ## ## This script can set all existing Admin accounts to be standard user accounts. The account specified in adminaccountname will not be downgraded if it is found ## ## WARNING: This script could leave your Mac will no Admin accounts configured at all # Define variables scriptname=\"Downgrade Admin Users to Standard\" log=\"/var/log/downgradeadminusers.log\" abmcheck=true # Only downgrade users if this device is ABM managed downgrade=true # If set to false, script will not do anything logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/downgradeAdminUsers\" log=\"$logandmetadir/downgradeAdminUsers.log\" function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi echo \"$(date) | Starting logging to [$log]\" exec > >(tee -a \"$log\") 2>&1 } startLog # Begin Script Body echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting $scriptname\" echo \"############################################################\" echo \"\" # Is this a ABM DEP device? if [[ \"$abmcheck\" = true ]]; then downgrade=false echo \"Checking MDM Profile Type\" profiles status -type enrollment | grep \"Enrolled via DEP: Yes\" if [[ ! $? == 0 ]]; then echo \"This device is not ABM managed\" exit 0; else echo \"Device is ABM Managed\" downgrade=true fi fi if [[ $downgrade = true ]]; then while read useraccount; do if [[ \"$useraccount\" == \"admin\" ]]; then echo \"Leaving admin account as Admin\" else echo \"Making $useraccount a normal user\" #/usr/sbin/dseditgroup -o edit -d $useraccount -t user admin fi done < <(dscl . list /Users UniqueID | awk '$2 >= 501 {print $1}') fi"
        },
        {
            "filename": "file_539.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Manage Accounts\\file_539.sh",
            "content": "#!/usr/bin/env bash #set -x ############################################################################################ ## ## Script to remove Local Admin Account for IT Use ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com ## ## Notes ## ## This script removes the specific account account # Define variables adminaccountname=\"localadmin\" # This is the accountname of the new admin adminaccountfullname=\"Local Admin\" # This is the full name of the new admin user scriptname=\"Remove Local Admin Account\" logandmetadir=\"/Library/IntuneScripts/removeLocalAdminUser\" log=\"$logandmetadir/removeLocalAdminUser.log\" ## Check if the log directory has been created and start logging if [ -d $logandmetadir ]; then ## Already created echo \"# $(date) | Log directory already exists - $logandmetadir\" else ## Creating Metadirectory echo \"# $(date) | creating log directory - $logandmetadir\" mkdir -p $logandmetadir fi # start logging exec 1>> $log 2>&1 # Begin Script Body echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting $scriptname\" echo \"############################################################\" echo \"\" echo \"Removing Admin Account [$adminaccountname]\" sudo sysadminctl -deleteUser $adminaccountname"
        },
        {
            "filename": "file_540.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Manage Accounts\\file_540.sh",
            "content": "#!/usr/bin/env bash #set -x ############################################################################################ ## ## Script to generate Admin Password from Serial Number ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com ## ## Notes ## ## This script is to support createAdminAccount.sh the cipher used in that script must match the cipher used here to generate the correct password ## i.e. ABCDEF000009 becomes S0xNTk9QNDQ0NDQzCg== ## ## WARNING: It is strongly recommended to change the cipher on line 45 before deploying into production echo -ne \"Enter device serial number :\" read serial password=`echo $serial | tr '[A-Z]' '[K-ZA-J]' | tr 0-9 4-90-3 | base64` echo \"Password: $password\""
        },
        {
            "filename": "file_541.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\MDATP\\file_541.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install LaunchDaemon to schedule a MDATP Quick Scan ## ## Note: Edit plist to change time/date. ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define variables log=\"/var/log/schedquickscan.log\" plistname=\"com.microsoft.wdav.schedquickscan\" plistfile=\"/Library/LaunchDaemons/com.microsoft.wdav.schedquickscan.plist\" exec 1>> $log 2>&1 if test -f \"$plistfile\"; then echo \"$(date) - Found existing $plistfile\" echo \"$(date) - Unloading $plistname\" launchctl unload $plistfile echo \"$(date) - Removing $plistfile\" rm -rf $plistfile fi echo \"$(date) - Installing new $plistfile\" cat > $plistfile <<EOF <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE plist PUBLIC \"-//Apple Computer//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"> <plist version=\"1.0\"> <dict> <key>Label</key> <string>com.microsoft.wdav.schedquickscan</string> <key>ProgramArguments</key> <array> <string>sh</string> <string>-c</string> <string>/usr/local/bin/mdatp scan quick</string> </array> <key>RootDirectory</key> <string>/usr/local/bin</string> <key>StartCalendarInterval</key> <dict> <key>Hour</key> <integer>3</integer> <key>Minute</key> <integer>0</integer> </dict> <key>WorkingDirectory</key> <string>/usr/local/bin</string> </dict> </plist> EOF echo \"$(date) - Loading $plistfile\" launchctl load $plistfile echo \"$(date) - Starting $plistname\" launchctl start $plistname exit 0"
        },
        {
            "filename": "file_542.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\MDATP\\file_542.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to trigger scheduled MDATP scan ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define variables log=\"/var/log/mdatpscheduledscan.log\" appname=\"Scheduled MDATP Scan\" exec 1>> $log 2>&1 echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting $appname\" echo \"############################################################\" echo \"\" /usr/local/bin/mdatp scan quick >/dev/null exit 0"
        },
        {
            "filename": "file_543.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\mdmDiagnose\\file_543.sh",
            "content": "#!/bin/bash #set -x OUTPUT='/Library/Logs/Microsoft/Intune/mdmDiagnose' # Clean up and re-create output directory sudo rm -r $OUTPUT mkdir -p \"$OUTPUT\" exec &> >(tee -a \"${OUTPUT}/mdmDiagnose.log\") # Collect sysdiagnose logs # Prerequsites to collecting sysdiagnose logs for Apple: # Download ManagedClient debug mode mobileconfig - https://developer.apple.com/services-account/download?path=/OS_X/OS_X_Logs/ManagedClient.mobileconfig # sudo touch /var/db/MDM_LogConnectionDetails # sysdiagnose logs cannot be collected from Intune Agent Log upload because the output will exceed the limit of 62914560 bytes # sudo sysdiagnose -u -f $OUTPUT -A sysdiagnose # Run mdmclient commands to gather MDM command outputs echo \"$(date) | Gathering QueryDeviceInformation Logs\" sudo /usr/libexec/mdmclient QueryDeviceInformation > ${OUTPUT}/DeviceInformation.txt echo \"$(date) | Gathering QueryInstalledProfiles Logs\" sudo /usr/libexec/mdmclient QueryInstalledProfiles > ${OUTPUT}/InstalledProfiles.txt echo \"$(date) | Gathering QueryCertificates Logs\" sudo /usr/libexec/mdmclient QueryCertificates > ${OUTPUT}/InstalledCerts.txt echo \"$(date) | Gathering QueryInstalledApps Logs\" sudo /usr/libexec/mdmclient QueryInstalledApps > ${OUTPUT}/InstalledApps.txt echo \"$(date) | Gathering QuerySecurityInfo Logs\" sudo /usr/libexec/mdmclient QuerySecurityInfo > ${OUTPUT}/SecurityInfo.txt # Gather information from enrollment profile echo \"$(date) | Gathering Profiles Logs\" sudo /usr/bin/profiles status -type enrollment > ${OUTPUT}/enrollmentProfileInfo.txt # Use 'log show' to gather mdmclient logs for the past 30 days echo \"$(date) | Gathering mdmclient Logs\" log show --last 30d --predicate 'process == \"mdmclient\" OR subsystem == \"com.apple.ManagedClient\" OR processImagePath contains \"mdmclient\"' > ${OUTPUT}/mdmclientLogs.txt # Use 'log show' to gather app install logs for the past 30 days echo \"$(date) | Gathering StoreDownloadd Logs\" log show --last 30d --predicate 'processImagePath contains \"storedownloadd\" OR processImagePath contains \"appstored\"' > ${OUTPUT}/appInstallLogs.txt # Copy ManagedClient logs for mdm logs echo \"$(date) | Gathering ManagedClient Logs\" cp /Library/Logs/ManagedClient/ManagedClient.log ${OUTPUT} # Copy install.log for app install failures echo \"$(date) | Gathering install Logs\" cp /var/log/install.log ${OUTPUT} # Copy system.log for past week. Major errors will be logged here echo \"$(date) | Gathering system Logs\" cp /var/log/system.log ${OUTPUT} cp /var/log/system.log.0.gz ${OUTPUT} cp /var/log/system.log.1.gz ${OUTPUT} cp /var/log/system.log.2.gz ${OUTPUT} cp /var/log/system.log.3.gz ${OUTPUT} cp /var/log/system.log.4.gz ${OUTPUT} cp /var/log/system.log.5.gz ${OUTPUT} # Copy Intune Company Portal Logs from Users homedirectory echo \"$(date) | Gathering Company Portal Logs\" consoleuser=$(ls -l /dev/console | awk '{ print $3 }') if [[ $consoleuser ]]; then find \"/Users/$consoleuser/Library/Logs/Company Portal/\" -name '*.log' -exec cp \"{}\" ${OUTPUT} \\; else echo \"Couldn't determine logged on user\" fi # Output log files created echo \"#######################################\" echo \"##\" echo \"## The following logs were created\" echo \"##\" echo \"#######################\" echo \"\" find \"$OUTPUT\" -type f | tr '\\n' ';'"
        },
        {
            "filename": "file_544.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Octory\\file_544.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to download and run Octory splash screen ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"\" # Enter blob URL for Octory archive # Standard Variables targetdir=\"/Library/Application Support/Octory\" # Installation directory appname=\"Octory\" # Name of application to display in the logs logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/Octory\" # Log file directory # Generated variables tempdir=$(mktemp -d) # Temp directory tempfile=\"/$tempdir/octory.zip\" # Temp file log=\"$logandmetadir/$appname.log\" # Log file name consoleuser=$(ls -l /dev/console | awk '{ print $3 }') # Current user ## Check if the log directory has been created if [ -d $logandmetadir ]; then ## Already created echo \"$(date) | Log directory already exists - $logandmetadir\" else ## Creating Metadirectory echo \"$(date) | creating log directory - $logandmetadir\" mkdir -p $logandmetadir fi # function to check if softwareupdate is running to prevent us from installing Rosetta at the same time as another script isSoftwareUpdateRunning () { while ps aux | grep \"/usr/sbin/softwareupdate\" | grep -v grep; do echo \"$(date) | [/usr/sbin/softwareupdate] running, waiting...\" sleep 10 done echo \"$(date) | [/usr/sbin/softwareupdate] isn't running, lets carry on\" } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep; do echo \"$(date) | + Dock not running, waiting...\" sleep 5 done echo \"$(date) | Desktop is here, lets carry on\" } # function to remove Octory after user finishes onboarding cleanup() { cd \"$HOME\" if [ -d \"$tempdir\" ]; then echo \"$(date) | Cleanup - Removing temp directory [$tempdir]\" rm -rf \"$tempdir\" fi if [ -d \"$targetdir\" ]; then ## Octory directory already exists, we need to remove it echo \"$(date) | Cleanup - Removing target directory [$targetdir]\" rm -rf \"$targetdir\" fi ## Remove octo-notifier rm -rf /usr/bin/local/octo-notifier } # function to check if we need Rosetta 2 checkForRosetta2 () { # Wait here if software update is already running isSoftwareUpdateRunning echo \"$(date) | Checking if we need Rosetta 2 or not\" processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) if [[ \"$processor\" == *\"Intel\"* ]]; then echo \"$(date) | $processor processor detected, no need to install Rosetta.\" else echo \"$(date) | $processor processor detected, lets see if Rosetta 2 already installed\" # Check Rosetta LaunchDaemon. If no LaunchDaemon is found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"Rosetta 2 is installed\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exit 1 fi fi fi } # start logging exec &> >(tee -a \"$log\") # Begin Script Body echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting install of $appname\" echo \"############################################################\" echo \"\" # Exit if machine has already been deployed and Company Portal plist detected if [[ -f \"/Users/$consoleuser/Library/Preferences/com.microsoft.CompanyPortalMac.plist\" ]]; then echo \"$(date) | Skipping Octory launch for user [$consoleuser], Company Portal already Launched.\" exit 0 fi # Check if we need Rosetta 2 checkForRosetta2 ######################### ## ## Download, unzip and move application and resources into correct locations ## ############## # Download Octory echo \"$(date) | Downloading [$appname] from [$weburl]\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -o \"$tempfile\" \"$weburl\" cd \"$tempdir\" # Unzip files echo \"$(date) | Unzipping binary and resource files\" unzip -q octory.zip # Remove previous Octory files if they exist if [ -d \"$targetdir\" ]; then ## Octory directory already exists, we need to remove it echo \"$(date) | Removing previous Octory files from [$targetdir]\" rm -rf \"$targetdir\" fi # Install octo-notifier sudo installer -pkg \"$tempdir/Octory/Octory notifier.pkg\" -target / if [[ $? -eq 0 ]]; then echo \"$(date) | octo-notifier succesfully installed\" else echo \"$(date) | octo-notifier installation failed\" fi # Move files into correct location echo \"$(date) | Copying to /Application Support/Octory\" mv Octory/ /Library/Application\\ Support/ cd /Library/Application\\ Support/Octory # Ensure correct permissions are set echo \"$(date) | Setting Permissions on [$targetdir]\" sudo chown -R root:wheel \"$targetdir\" sudo chmod -R 755 \"$targetdir\" sudo chmod 644 \"$targetdir/onboarding.plist\" # We don't want to interrupt setup assistant waitForDesktop # Launch Octory splash screen to show the end user how app installation progress is doing echo \"$(date) | Launching Octory\" sudo Octory.app/Contents/MacOS/Octory -c onboarding.plist if [[ $? -eq 0 ]]; then echo \"$(date) | Octory succesfully launched\" #cleanup exit 0 else echo \"$(date) | Octory failed to launch, let's try one more time\" sleep 10 sudo Octory.app/Contents/MacOS/Octory -c onboarding.plist if [[ $? -eq 0 ]]; then echo \"$(date) | Octory succesfully launched\" #cleanup exit 0 else echo \"$(date) | Octory failed on 2nd launch\" #cleanup exit 1 fi fi"
        },
        {
            "filename": "file_545.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Rosetta2\\file_545.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to check if we need Rosetta 2 and install if required ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## ## ## Credit: Initial idea and example commands taken from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ ## ## Feedback: neiljohn@microsoft.com # Define variables appname=\"Rosetta2\" logandmetadir=\"/Library/Logs/Microsoft/IntuneScripts/$appname\" log=\"$logandmetadir/$appname.log\" ## Check if the log directory has been created if [ -d $logandmetadir ]; then ## Already created echo \"$(date) | Log directory already exists - $logandmetadir\" else ## Creating Metadirectory echo \"$(date) | creating log directory - $logandmetadir\" mkdir -p $logandmetadir fi # function to check if softwareupdate is running to prevent us from installing Rosetta at the same time as another script isSoftwareUpdateRunning () { while ps aux | grep \"/usr/sbin/softwareupdate\" | grep -v grep; do echo \"$(date) | [/usr/sbin/softwareupdate] running, waiting...\" sleep 60 done echo \"$(date) | [/usr/sbin/softwareupdate] isn't running, lets carry on\" } # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # start logging exec &> >(tee -a \"$log\") # Begin Script Body echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting install of $appname\" echo \"############################################################\" echo \"\" # If another softwareupdate process is running, we should wait isSoftwareUpdateRunning # Let's check to see if we need Rosetta 2 checkForRosetta2"
        },
        {
            "filename": "file_546.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\setTimeZone\\file_546.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to guess timezone based on public IP address and then set the timezone of the Mac ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com ## Define variables log=\"/var/log/setTimezone.log\" appname=\"Set Timezone\" exec > >(tee -a \"$log\") 2>&1 function updateSplashScreen () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update the Splash Screen status (if required) ## ############################################################### ############################################################### # Is Swift Dialog present if [[ -a \"/Library/Application Support/Dialog/Dialog.app/Contents/MacOS/Dialog\" ]]; then echo \"$(date) | Updating Swift Dialog monitor for [$appname] to [$1]\" echo listitem: title: $appname, status: $1, statustext: $2 >> /var/tmp/dialog.log # Supported status: wait, success, fail, error, pending or progress:xx fi } echo \"\" echo \"##############################################################\" echo \"# $(date) | Beginning $appname\" echo \"############################################################\" echo \"\" ## What is our public IP echo \"$(date) | Looking up public IP\" myip=$(dig +short myip.opendns.com @resolver1.opendns.com) if [ \"$?\" = \"0\" ]; then echo \"$(date) | Public IP is $myip\" else echo \"$(date) | Unable to determine public IP address\" updateSplashScreen fail \"Unable to determine public IP address\" exit 1 fi ## What is our TZ ## Note: See https://ipapi.co/api/ for documentation on this api max_attempts=20 for ((attempt=1; attempt<=max_attempts; attempt++)); do # Run the curl command and store the output in a variable echo \"$(date) | Looking up TZ from IPAPI\" tz=$(curl -s 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.69' \"https://ipapi.co/$myip/timezone\") updateSplashScreen wait \"Looking up TZ...\" # Check if the response contains 'error' if [[ \"$tz\" != *\"error\"* ]]; then echo \"$(date) | Timezone detected as $tz\" updateSplashScreen wait \"Timezone detected as $tz\" break else echo \"$(date) | IPAPI returned an error. Attempt $attempt of $max_attempts\" updateSplashScreen wait \"Retrying $attempt of $max_attempts\" # Add a sleep to wait before the next attempt (optional) sleep 5 fi done # # Ok, we know the timezone, let's set it # currentTZ=$(sudo systemsetup -gettimezone | awk '{print $3}' | xargs) if [ \"$tz\" = \"$currentTZ\" ]; then echo \"$(date) | TimeZone is already set to $tz\" updateSplashScreen success \"TimeZone is already set to $tz\" else echo \"$(date) | TimeZone is currently set to $currentTZ. Setting to $tz\" sudo systemsetup -settimezone $tz $currentTZ=$(sudo systemsetup -gettimezone | awk '{print $3}' | xargs) if [ \"$tz\" != \"$currentTZ\" ]; then echo \"$(date) | Failed to change $currentTZ to $tz\" updateSplashScreen fail \"Failed to change $currentTZ to $tz\" fi fi"
        },
        {
            "filename": "file_547.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Swift Dialog\\onboarding_scripts\\scripts\\file_547.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest Office 365 Pro ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables weburl=\"https://go.microsoft.com/fwlink/?linkid=2009112\" # What is the Azure Blob Storage URL? appname=\"Microsoft Office\" # The name of our App deployment script (also used for splash screen monitor) logandmetadir=\"/Library/Application Support/Microsoft/IntuneScripts/installOffice\" # The location of our logs and last updated data terminateprocess=\"true\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # Application updates itself, if already installed we should exit # Generated variables tempdir=$(mktemp -d) tempfile=\"$appname.pkg\" log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) function installAria2c () { ##################################### ## Aria2c installation ##################### ARIA2=\"/usr/local/aria2/bin/aria2c\" aria2Url=\"https://github.com/aria2/aria2/releases/download/release-1.35.0/aria2-1.35.0-osx-darwin.dmg\" if [[ -f $ARIA2 ]]; then echo \"$(date) | Aria2 already installed, nothing to do\" else echo \"$(date) | Aria2 missing, lets download and install\" filename=$(basename \"$aria2Url\") output=\"$tempdir/$filename\" #curl -L -o \"$output\" \"$aria2Url\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -o \"$output\" \"$aria2Url\" if [ $? -ne 0 ]; then echo \"$(date) | Aria download failed\" echo \"$(date) | Output: [$output]\" echo \"$(date) | URL [$aria2Url]\" exit 1 else echo \"$(date) | Downloaded aria2\" fi # Mount aria2 DMG mountpoint=\"$tempdir/aria2\" echo \"$(date) | Mounting Aria DMG...\" hdiutil attach -quiet -nobrowse -mountpoint \"$mountpoint\" \"$output\" if [ $? -ne 0 ]; then echo \"$(date) | Aria mount failed\" echo \"$(date) | Mount: [$mountpoint]\" echo \"$(date) | Temp File [$output]\" exit 1 else echo \"$(date) | Mounted DMG\" fi # Install aria2 PKG from inside the DMG sudo installer -pkg \"$mountpoint/aria2.pkg\" -target / if [ $? -ne 0 ]; then echo \"$(date) | Install failed\" echo \"$(date) | PKG: [$mountpoint/aria2.pkg]\" exit 1 else echo \"$(date) | Aria2 installed\" hdiutil detach -quiet \"$mountpoint\" fi rm -rf \"$output\" fi } # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # Function to change the download URL to an older version if the current version isn't supported on this Mac function OfficeURLCheck() { # Download location for latest version of Office for Mac 2019 weburl=\"https://go.microsoft.com/fwlink/?linkid=2009112\" echo \"$(date) | Checking that the version of Office we have will work on this Mac\" os_ver=$(sw_vers -productVersion) case $os_ver in 10.10.*) echo \"$(date) | + macOS 10.10 Yosemite detected, setting install to Office 2016 v16.16\" weburl=\"https://officecdn-microsoft-com.akamaized.net/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.16.20091400_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 10.11.*) echo \"$(date) | + macOS 10.11 El Capitan detected, setting install to Office 2016 v16.16\" weburl=\"https://officecdn-microsoft-com.akamaized.net/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.16.20091400_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 10.12.*) echo \"$(date) | + macOS 10.12 Sierra detected, setting install to Office 2016 v16.30\" weburl=\"https://officecdn-microsoft-com.akamaized.net/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.30.19101301_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 10.13.*) echo \"$(date) | + macOS 10.13 High Sierra detected, setting install to Office 2019 v16.43\" weburl=\"https://officecdn-microsoft-com.akamaized.net/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.43.20110804_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 10.14.*) echo \"$(date) | + macOS 10.14 Mojave detected, setting install to Office 2019 v16.54\" weburl=\"https://officecdnmac.microsoft.com/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.54.21101001_BusinessPro_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 10.15.*) echo \"$(date) | + macOS 10.15 Catalina detected, setting install to Office 2019 v16.66\" weburl=\"https://officecdnmac.microsoft.com/pr/C1297A47-86C4-4C1F-97FA-950631F94777/MacAutoupdate/Microsoft_Office_16.66.22101101_BusinessPro_Installer.pkg\" unset localcopy # Note, enter your own localcopy URL if you have one here ;; 11.*) echo \"$(date) | + macOS 11.x Big Sur detected, installing latest available version\" ;; 12.*) echo \"$(date) | + macOS 12.x Monteray detected, installing latest available version\" ;; 13.*) echo \"$(date) | + macOS 13.x Ventura detected, installing latest available version\" ;; *) echo \"$(date) | + Unknown OS $os_ver\" ;; esac } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" # Check download location to see if we can handle the latest version of Office OfficeURLCheck # If local copy is defined, let's try and download it... if [ \"$localcopy\" ]; then updateSplashScreen wait Downloading # Swift Dialog # Check to see if we can access our local copy of Office echo \"$(date) | Downloading [$localcopy] to [$tempfile]\" rm -rf \"$tempfile\" > /dev/null 2>&1 curl -f -s -L -o \"$tempfile\" \"$localcopy\" if [ $? == 0 ]; then echo \"$(date) | Local copy of $appname downloaded at $tempfile\" downloadcomplete=\"true\" else echo \"$(date) | Failed to download Local copy [$localcopy] to [$tempfile]\" fi fi # If we failed to download the local copy, or it wasn't defined then try to download from CDN if [[ \"$downloadcomplete\" != \"true\" ]]; then updateSplashScreen wait Downloading # Swift Dialog rm -rf \"$tempfile\" > /dev/null 2>&1 echo \"$(date) | Downloading [$weburl] to [$tempfile]\" #curl -f -s --connect-timeout 60 --retry 10 --retry-delay 30 -L -o \"$tempfile\" \"$weburl\" $ARIA2 -q -x16 -s16 -d \"$tempdir\" -o \"$tempfile\" \"$weburl\" --download-result=hide --summary-interval=0 if [ $? == 0 ]; then echo \"$(date) | Downloaded $weburl to $tempdir/$tempfile\" else echo \"$(date) | Failure to download $weburl to $tempdir/$tempfile\" updateSplashScreen fail Download failed # Swift Dialog exit 1 fi fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" # App Array for Office 365 Apps for Mac OfficeApps=( \"/Applications/Microsoft Excel.app\" \"/Applications/Microsoft OneNote.app\" \"/Applications/Microsoft Outlook.app\" \"/Applications/Microsoft PowerPoint.app\" \"/Applications/Microsoft Teams.app\" \"/Applications/Microsoft Word.app\") for i in \"${OfficeApps[@]}\"; do if [[ ! -e \"$i\" ]]; then echo \"$(date) | [$i] not installed, need to perform full installation\" let missingappcount=$missingappcount+1 fi done if [[ ! \"$missingappcount\" ]]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" updateSplashScreen success Installed # Swift Dialog exit 0; fi fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" updateSplashScreen success Installed # Swift Dialog echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Installing [$appname]\" updateSplashScreen wait Installing # Swift Dialog installer -pkg \"$tempdir/$tempfile\" -target /Applications # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Writing last modifieddate $lastmodified to $metafile\" echo \"$lastmodified\" > \"$metafile\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateSplashScreen success Installed # Swift Dialog exit 0 else echo \"$(date) | Failed to install $appname\" rm -rf \"$tempdir\" updateSplashScreen fail Failed # Swift Dialog exit 1 fi } function updateSplashScreen () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update the Splash Screen status (if required) ## ## ## Parameters (updateSplashScreen parameter1 parameter2 ## Swift Dialog ## ## Param 1 = Status ## Param 2 = Status Text ## ############################################################### ############################################################### # Is Swift Dialog present if [[ -a \"/Library/Application Support/Dialog/Dialog.app/Contents/MacOS/Dialog\" ]]; then echo \"$(date) | Updating Swift Dialog monitor for [$appname] to [$1]\" echo listitem: title: $appname, status: $1, statustext: $2 >> /var/tmp/dialog.log # Supported status: wait, success, fail, error, pending or progress:xx fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Aria2c if we don't already have it installAria2c # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file installPKG"
        },
        {
            "filename": "file_548.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Swift Dialog\\onboarding_scripts\\scripts\\file_548.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to install the latest Edge stable channel from Microsoft CDN Servers ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define variables weburl=\"https://go.microsoft.com/fwlink/?linkid=2093504\" # What is the Azure Blob Storage URL? appname=\"Microsoft Edge\" # The name of our App deployment script app=\"Microsoft Edge.app\" # The actual name of our App once installed logandmetadir=\"/Library/Application Support/Microsoft/IntuneScripts/installEdge\" # The location of our logs and last updated data processpath=\"/Applications/Microsoft Edge.app/Contents/MacOS/Microsoft Edge\" # The process name of the App we are installing terminateprocess=\"false\" # Do we want to terminate the running process? If false we'll wait until its not running autoUpdate=\"true\" # If true, application updates itself and we should not attempt to update # Generated variables tempdir=$(mktemp -d) log=\"$logandmetadir/$appname.log\" # The location of the script log file metafile=\"$logandmetadir/$appname.meta\" # The location of our meta file (for updates) function installAria2c () { ##################################### ## Aria2c installation ##################### ARIA2=\"/usr/local/aria2/bin/aria2c\" aria2Url=\"https://github.com/aria2/aria2/releases/download/release-1.35.0/aria2-1.35.0-osx-darwin.dmg\" if [[ -f $ARIA2 ]]; then echo \"$(date) | Aria2 already installed, nothing to do\" else echo \"$(date) | Aria2 missing, lets download and install\" filename=$(basename \"$aria2Url\") output=\"$tempdir/$filename\" curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -o \"$output\" \"$aria2Url\" if [ $? -ne 0 ]; then echo \"$(date) | Aria download failed\" echo \"$(date) | Output: [$output]\" echo \"$(date) | URL [$aria2Url]\" exit 1 else echo \"$(date) | Downloaded aria2\" fi # Mount aria2 DMG mountpoint=\"$tempdir/aria2\" echo \"$(date) | Mounting Aria DMG...\" hdiutil attach -quiet -nobrowse -mountpoint \"$mountpoint\" \"$output\" if [ $? -ne 0 ]; then echo \"$(date) | Aria mount failed\" echo \"$(date) | Mount: [$mountpoint]\" echo \"$(date) | Temp File [$output]\" exit 1 else echo \"$(date) | Mounted DMG\" fi # Install aria2 PKG from inside the DMG sudo installer -pkg \"$mountpoint/aria2.pkg\" -target / if [ $? -ne 0 ]; then echo \"$(date) | Install failed\" echo \"$(date) | PKG: [$mountpoint/aria2.pkg]\" exit 1 else echo \"$(date) | Aria2 installed\" hdiutil detach -quiet \"$mountpoint\" fi rm -rf \"$output\" fi } # function to delay script if the specified process is running waitForProcess () { ################################################################################################################# ################################################################################################################# ## ## Function to pause while a specified process is running ## ## Functions used ## ## None ## ## Variables used ## ## $1 = name of process to check for ## $2 = length of delay (if missing, function to generate random delay between 10 and 60s) ## $3 = true/false if = \"true\" terminate process, if \"false\" wait for it to close ## ############################################################### ############################################################### processName=$1 fixedDelay=$2 terminate=$3 echo \"$(date) | Waiting for other [$processName] processes to end\" while ps aux | grep \"$processName\" | grep -v grep &>/dev/null; do if [[ $terminate == \"true\" ]]; then echo \"$(date) | + [$appname] running, terminating [$processpath]...\" pkill -f \"$processName\" return fi # If we've been passed a delay we should use it, otherwise we'll create a random delay each run if [[ ! $fixedDelay ]]; then delay=$(( $RANDOM % 50 + 10 )) else delay=$fixedDelay fi echo \"$(date) | + Another instance of $processName is running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | No instances of [$processName] found, safe to proceed\" } # function to check if we need Rosetta 2 checkForRosetta2 () { ################################################################################################################# ################################################################################################################# ## ## Simple function to install Rosetta 2 if needed. ## ## Functions ## ## waitForProcess (used to pause script if another instance of softwareupdate is running) ## ## Variables ## ## None ## ############################################################### ############################################################### echo \"$(date) | Checking if we need Rosetta 2 or not\" # if Software update is already running, we need to wait... waitForProcess \"/usr/sbin/softwareupdate\" ## Note, Rosetta detection code from https://derflounder.wordpress.com/2020/11/17/installing-rosetta-2-on-apple-silicon-macs/ OLDIFS=$IFS IFS='.' read osvers_major osvers_minor osvers_dot_version <<< \"$(/usr/bin/sw_vers -productVersion)\" IFS=$OLDIFS if [[ ${osvers_major} -ge 11 ]]; then # Check to see if the Mac needs Rosetta installed by testing the processor processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string | grep -o \"Intel\") if [[ -n \"$processor\" ]]; then echo \"$(date) | $processor processor installed. No need to install Rosetta.\" else # Check for Rosetta \"oahd\" process. If not found, # perform a non-interactive install of Rosetta. if /usr/bin/pgrep oahd >/dev/null 2>&1; then echo \"$(date) | Rosetta is already installed and running. Nothing to do.\" else /usr/sbin/softwareupdate --install-rosetta --agree-to-license if [[ $? -eq 0 ]]; then echo \"$(date) | Rosetta has been successfully installed.\" else echo \"$(date) | Rosetta installation failed!\" exitcode=1 fi fi fi else echo \"$(date) | Mac is running macOS $osvers_major.$osvers_minor.$osvers_dot_version.\" echo \"$(date) | No need to install Rosetta on this version of macOS.\" fi } # Function to update the last modified date for this app fetchLastModifiedDate() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## none ## ## Variables ## ## $logandmetadir = Directory to read nand write meta data to ## $metafile = Location of meta file (used to store last update time) ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## $lastmodified = Generated by the function as the last-modified http header from the curl request ## ## Notes ## ## If called with \"fetchLastModifiedDate update\" the function will overwrite the current lastmodified date into metafile ## ############################################################### ############################################################### ## Check if the log directory has been created if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store metadata\" mkdir -p \"$logandmetadir\" fi # generate the last modified date of the file we need to download lastmodified=$(curl -sIL \"$weburl\" | grep -i \"last-modified\" | awk '{$1=\"\"; print $0}' | awk '{ sub(/^[ \\t]+/, \"\"); print }' | tr -d '\\r') if [[ $1 == \"update\" ]]; then echo \"$(date) | Writing last modifieddate [$lastmodified] to [$metafile]\" echo \"$lastmodified\" > \"$metafile\" fi } function downloadApp () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and downloads the URL provided to a temporary location ## ## Functions ## ## waitForCurl (Pauses download until all other instances of Curl have finished) ## downloadSize (Generates human readable size of the download for the logs) ## ## Variables ## ## $appname = Description of the App we are installing ## $weburl = URL of download location ## $tempfile = location of temporary DMG file downloaded ## ############################################################### ############################################################### echo \"$(date) | Starting downlading of [$appname]\" #download the file updateSplashScreen wait Downloading # Swift Dialog echo \"$(date) | Downloading $appname\" cd \"$tempdir\" #curl -f -s --connect-timeout 30 --retry 5 --retry-delay 60 -L -J -o \"edge.pkg\" \"$weburl\" $ARIA2 -q -x16 -s16 -d \"$tempdir\" \"$weburl\" --download-result=hide --summary-interval=0 if [ $? == 0 ]; then # We have downloaded a file, we need to know what the file is called and what type of file it is tempSearchPath=\"$tempdir/*\" for f in $tempSearchPath; do tempfile=$f done case $tempfile in *.pkg|*.PKG) packageType=\"PKG\" ;; *.zip|*.ZIP) packageType=\"ZIP\" ;; *.dmg|*.DMG) packageType=\"DMG\" ;; *) # We can't tell what this is by the file name, lets look at the metadata echo \"$(date) | Unknown file type [$f], analysing metadata\" metadata=$(file \"$tempfile\") if [[ \"$metadata\" == *\"Zip archive data\"* ]]; then packageType=\"ZIP\" mv \"$tempfile\" \"$tempdir/install.zip\" tempfile=\"$tempdir/install.zip\" fi if [[ \"$metadata\" == *\"xar archive\"* ]]; then packageType=\"PKG\" mv \"$tempfile\" \"$tempdir/install.pkg\" tempfile=\"$tempdir/install.pkg\" fi if [[ \"$metadata\" == *\"bzip2 compressed data\"* ]] || [[ \"$metadata\" == *\"zlib compressed data\"* ]] ; then packageType=\"DMG\" mv \"$tempfile\" \"$tempdir/install.dmg\" tempfile=\"$tempdir/install.dmg\" fi ;; esac if [[ ! $packageType ]]; then echo \"Failed to determine temp file type [$metadata]\" rm -rf \"$tempdir\" else echo \"$(date) | Downloaded [$app] to [$tempfile]\" echo \"$(date) | Detected install type as [$packageType]\" fi else echo \"$(date) | Failure to download [$weburl] to [$tempfile]\" updateSplashScreen fail Failed # Swift Dialog exit 1 fi } # Function to check if we need to update or not function updateCheck() { ################################################################################################################# ################################################################################################################# ## ## This function takes the following dependencies and variables and exits if no update is required ## ## Functions ## ## fetchLastModifiedDate ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### echo \"$(date) | Checking if we need to install or update [$appname]\" ## Is the app already installed? if [ -d \"/Applications/$app\" ]; then # App is installed, if it's updates are handled by MAU we should quietly exit if [[ $autoUpdate == \"true\" ]]; then echo \"$(date) | [$appname] is already installed and handles updates itself, exiting\" updateSplashScreen success Installed # Swift Dialog exit 0; fi # App is already installed, we need to determine if it requires updating or not echo \"$(date) | [$appname] already installed, let's see if we need to update\" fetchLastModifiedDate ## Did we store the last modified date last time we installed/updated? if [[ -d \"$logandmetadir\" ]]; then if [ -f \"$metafile\" ]; then previouslastmodifieddate=$(cat \"$metafile\") if [[ \"$previouslastmodifieddate\" != \"$lastmodified\" ]]; then echo \"$(date) | Update found, previous [$previouslastmodifieddate] and current [$lastmodified]\" update=\"update\" else echo \"$(date) | No update between previous [$previouslastmodifieddate] and current [$lastmodified]\" updateSplashScreen success Installed # Swift Dialog echo \"$(date) | Exiting, nothing to do\" exit 0 fi else echo \"$(date) | Meta file [$metafile] not found\" echo \"$(date) | Unable to determine if update required, updating [$appname] anyway\" fi fi else echo \"$(date) | [$appname] not installed, need to download and install\" fi } ## Install PKG Function function installPKG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the PKG file ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateSplashScreen wait Installing # Swift Dialog # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then rm -rf \"/Applications/$app\" fi # Attempting Installation max_attempts=5 attempt=1 while [ $attempt -le $max_attempts ]; do echo \"$(date) | Attempting installation (Attempt $attempt)...\" # Run the installer command installer -pkg \"$tempfile\" -target / # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempdir\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateSplashScreen success Installed # Swift Dialog break else echo \"$(date) | Failed to install $appname, trying $attempt of $max_attempts\" updateSplashScreen error \"Failed, retrying $attempt of $max_attempts\" attempt=$((attempt + 1)) # Increment the attempt counter sleep 5 fi done if [ $attempt -gt $max_attempts ]; then echo \"$(date) | Installation failed after $max_attempts attempts. Exiting the script.\" updateSplashScreen fail \"Failed, after $max_attempts retries\" rm -rf \"$tempdir\" exit 1 fi } ## Install DMG Function function installDMG () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing [$appname]\" updateSplashScreen wait Installing # Swift Dialog # Mount the dmg file... volume=\"$tempdir/$appname\" echo \"$(date) | Mounting Image\" hdiutil attach -quiet -nobrowse -mountpoint \"$volume\" \"$tempfile\" # Remove existing files if present if [[ -d \"/Applications/$app\" ]]; then echo \"$(date) | Removing existing files\" rm -rf \"/Applications/$app\" fi # Sync the application and unmount once complete echo \"$(date) | Copying app files to /Applications/$app\" rsync -a \"$volume\"/*.app/ \"/Applications/$app\" # Unmount the dmg echo \"$(date) | Un-mounting [$volume]\" hdiutil detach -quiet \"$volume\" # Checking if the app was installed successfully if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | [$appname] Installed\" echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" fetchLastModifiedDate update updateSplashScreen success Installed # Swift Dialog exit 0 else echo \"$(date) | Failed to install [$appname]\" rm -rf \"$tempdir\" updateSplashScreen fail Failed # Swift Dialog exit 1 fi } ## Install ZIP Function function installZIP () { ################################################################################################################# ################################################################################################################# ## ## This function takes the following global variables and installs the DMG file into /Applications ## ## Functions ## ## isAppRunning (Pauses installation if the process defined in global variable $processpath is running ) ## fetchLastModifiedDate (Called with update flag which causes the function to write the new lastmodified date to the metadata file) ## ## Variables ## ## $appname = Description of the App we are installing ## $tempfile = location of temporary DMG file downloaded ## $volume = name of volume mount point ## $app = name of Application directory under /Applications ## ############################################################### ############################################################### # Check if app is running, if it is we need to wait. waitForProcess \"$processpath\" \"300\" \"$terminateprocess\" echo \"$(date) | Installing $appname\" updateSplashScreen wait Installing # Swift Dialog # Change into temp dir cd \"$tempdir\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | Changed current directory to $tempdir\" else echo \"$(date) | failed to change to $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateSplashScreen fail Failed # Swift Dialog exit 1 fi # Unzip files in temp dir unzip -qq -o \"$tempfile\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $tempfile unzipped\" else echo \"$(date) | failed to unzip $tempfile\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateSplashScreen fail Failed # Swift Dialog exit 1 fi # If app is already installed, remove all old files if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | Removing old installation at /Applications/$app\" rm -rf \"/Applications/$app\" fi # Copy over new files rsync -a \"$app/\" \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | $appname moved into /Applications\" else echo \"$(date) | failed to move $appname to /Applications\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateSplashScreen fail Failed # Swift Dialog exit 1 fi # Make sure permissions are correct echo \"$(date) | Fix up permissions\" sudo chown -R root:wheel \"/Applications/$app\" if [ \"$?\" = \"0\" ]; then echo \"$(date) | correctly applied permissions to $appname\" else echo \"$(date) | failed to apply permissions to $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi updateSplashScreen fail Failed # Swift Dialog exit 1 fi # Checking if the app was installed successfully if [ \"$?\" = \"0\" ]; then if [[ -a \"/Applications/$app\" ]]; then echo \"$(date) | $appname Installed\" updateSplashScreen success Installed # Swift Dialog echo \"$(date) | Cleaning Up\" rm -rf \"$tempfile\" # Update metadata fetchLastModifiedDate update echo \"$(date) | Fixing up permissions\" sudo chown -R root:wheel \"/Applications/$app\" echo \"$(date) | Application [$appname] succesfully installed\" exit 0 else echo \"$(date) | Failed to install $appname\" exit 1 fi else # Something went wrong here, either the download failed or the install Failed # intune will pick up the exit status and the IT Pro can use that to determine what went wrong. # Intune can also return the log file if requested by the admin echo \"$(date) | Failed to install $appname\" if [ -d \"$tempdir\" ]; then rm -rf $tempdir; fi exit 1 fi } function updateSplashScreen () { ################################################################################################################# ################################################################################################################# ## ## This function is designed to update the Splash Screen status (if required) ## ## ## Parameters (updateSplashScreen parameter1 parameter2 ## ## ## Param 1 = State ## ## Swift Dialog ## ## Param 1 = Status ## Param 2 = Status Text ## ############################################################### ############################################################### # Is Swift Dialog present if [[ -a \"/Library/Application Support/Dialog/Dialog.app/Contents/MacOS/Dialog\" ]]; then echo \"$(date) | Updating Swift Dialog monitor for [$appname] to [$1]\" echo listitem: title: $appname, status: $1, statustext: $2 >> /var/tmp/dialog.log # Supported status: wait, success, fail, error, pending or progress:xx fi } function startLog() { ################################################### ################################################### ## ## start logging - Output to log file and STDOUT ## #################### #################### if [[ ! -d \"$logandmetadir\" ]]; then ## Creating Metadirectory echo \"$(date) | Creating [$logandmetadir] to store logs\" mkdir -p \"$logandmetadir\" fi exec &> >(tee -a \"$log\") } # function to delay until the user has finished setup assistant. waitForDesktop () { until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do delay=$(( $RANDOM % 50 + 10 )) echo \"$(date) | + Dock not running, waiting [$delay] seconds\" sleep $delay done echo \"$(date) | Dock is here, lets carry on\" } ################################################################################### ################################################################################### ## ## Begin Script Body ## ##################################### ##################################### # Initiate logging startLog echo \"\" echo \"##############################################################\" echo \"# $(date) | Logging install of [$appname] to [$log]\" echo \"############################################################\" echo \"\" # Install Aria2c if we don't already have it installAria2c # Install Rosetta if we need it checkForRosetta2 # Test if we need to install or update updateCheck # Wait for Desktop waitForDesktop # Download app downloadApp # Install PKG file if [[ $packageType == \"PKG\" ]]; then installPKG fi # Install PKG file if [[ $packageType == \"ZIP\" ]]; then installZIP fi # Install PKG file if [[ $packageType == \"DMG\" ]]; then installDMG fi"
        },
        {
            "filename": "file_549.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Swift Dialog (PKG)\\IntuneScripts\\file_549.sh",
            "content": "#!/bin/bash ############################################################################################ ## ## Post-install Script for Swift Dialog ## ## VER 1.0.0 ## ############################################################################################ # Define any variables we need here: logDir=\"/Library/Application Support/Microsoft/IntuneScripts/Swift Dialog\" DIALOG_BIN=\"/usr/local/bin/dialog\" PKG_PATH=\"/var/tmp/dialog-2.5.2-4777.pkg\" # Start Logging mkdir -p \"$logDir\" exec > >(tee -a \"$logDir/postinstall.log\") 2>&1 # Check if we've run before #if [[ -f \"$logDir/onboardingComplete\" ]]; then # echo \"$(date) | POST | We've already completed onboarding, let's exit quietly\" # exit 1 #fi # Check if SwiftDialog is installed if [[ ! -f \"$DIALOG_BIN\" ]]; then echo \"$(date) | POST | Swift Dialog is not installed [$DIALOG_BIN]. Installing now...\" # Install SwiftDialog from the .pkg file if [[ -f \"$PKG_PATH\" ]]; then sudo installer -pkg \"$PKG_PATH\" -target / if [[ $? -eq 0 ]]; then echo \"$(date) | POST | Swift Dialog has been installed successfully.\" else echo \"$(date) | ERROR | Swift Dialog installation failed.\" exit 1 fi else echo \"$(date) | ERROR | Package file not found at $PKG_PATH. Exiting.\" exit 1 fi else echo \"$(date) | POST | Swift Dialog is already installed.\" fi # Wait for Desktop until ps aux | grep /System/Library/CoreServices/Dock.app/Contents/MacOS/Dock | grep -v grep &>/dev/null; do echo \"$(date) | + Dock not running, waiting [1] seconds\" sleep 1 done echo \"$(date) | Dock is here, lets carry on\" # Run Swift Dialog /usr/local/bin/dialog --jsonfile \"/Library/Application Support/SwiftDialogResources/swiftdialog.json\" --width 1280 --height 670 --blurscreen --ontop & # Wait for Swift Dialog to start START=$(date +%s) # Set the start time so we can calculate how long we've been waiting echo \"$(date) | POST | Waiting for Swift Dialog to Start...\" # Loop for 1 minutes (60 seconds) until ps aux | grep /usr/local/bin/dialog | grep -v grep &>/dev/null; do # Check if the 60 seconds have passed if [[ $(($(date +%s) - $START)) -ge 60 ]]; then echo \"$(date) | POST | Failed: Swift Dialog did not start within 60 seconds\" exit 1 fi echo -n \".\" sleep 1 done echo \"OK\" echo \"$(date) | POST | Processing scripts...\" for script in /Library/Application\\ Support/SwiftdialogResources/scripts/*.*; do echo \"$(date) | POST | Executing [$script]\" xattr -d com.apple.quarantine \"$script\" >/dev/null 2>&1 chmod +x \"$script\" >/dev/null 2>&1 nice -n 20 \"$script\" done # Once we're done, we should write a flag file out so that we don't run again sudo touch \"$logDir/onboardingComplete\" exit 0"
        },
        {
            "filename": "file_550.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Swift Dialog (PKG)\\IntuneScripts\\file_550.sh",
            "content": "#!/bin/bash ############################################################################################ ## ## Pre-install Script for Swift Dialog ## ## VER 1.0.0 ## ############################################################################################ # Define any variables we need here: logDir=\"/Library/Application Support/Microsoft/IntuneScripts/Swift Dialog\" DIALOG_BIN=\"/path/to/SwiftDialog\" # Set this to the path where SwiftDialog is expected to be installed PKG_PATH=\"/var/tmp/dialog.pkg\" PKG_URL=\"https://github.com/swiftDialog/swiftDialog/releases/download/v2.5.2/dialog-2.5.2-4777.pkg\" # Start Logging mkdir -p \"$logDir\" exec > >(tee -a \"$logDir/preinstall.log\") 2>&1 if [ -e \"/Library/Application Support/Dialog\" ]; then echo \"$(date) | PRE | Removing previous installation\" rm -rf \"/Library/Application Support/Dialog\" rm -rf \"/Library/Application Support/SwiftDialogResources\" rm -rf \"/usr/local/bin/dialog\" fi # Download the SwiftDialog .pkg curl -L -o \"$PKG_PATH\" \"$PKG_URL\" # Install SwiftDialog from the downloaded .pkg file sudo installer -pkg \"$PKG_PATH\" -target / if [[ $? -eq 0 ]]; then echo \"$(date) | POST | Swift Dialog has been installed successfully.\" else echo \"$(date) | ERROR | Swift Dialog installation failed.\" exit 1 fi echo \"$(date) | PRE | Completed Pre-install script\" exit 0"
        },
        {
            "filename": "file_551.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Config\\Wallpaper\\file_551.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Script to download Desktop Wallpaper ## ########################################### ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define variables usebingwallpaper=true # Set to true to have script fetch wallpaper from Bing wallpaperurl=\"https://catlab.blob.core.windows.net/public/win11.jpg?sp=r&st=2023-03-17T20:49:42Z&se=2099-03-18T04:49:42Z&spr=https&sv=2021-12-02&sr=b&sig=ZPpGEOoIoA0lpflLee3G71MT4rtwQ07nAPvrFBOMvUA%3D\" wallpaperdir=\"/Users/Shared/\" wallpaperfile=\"Wallpaper.jpg\" log=\"/var/log/fetchdesktopwallpaper.log\" # start logging exec 1>> $log 2>&1 echo \"\" echo \"##############################################################\" echo \"# $(date) | Starting download of Desktop Wallpaper\" echo \"############################################################\" echo \"\" ## ## Checking if Wallpaper directory exists and create it if it's missing ## if [ -d $wallpaperdir ] then echo \"$(date) | Wallpaper dir [$wallpaperdir] already exists\" else echo \"$(date) | Creating [$wallpaperdir]\" mkdir -p $wallpaperdir fi ## ## Attempt to download the image file. No point checking if it already exists since we want to overwrite it anyway ## if [ \"$usebingwallpaper\" = true ]; then echo \"$(date) | Attempting to dertermine URL of today's Bing Wallpaper\" bingfileurl=( $(curl -sL https://www.bing.com | grep -Eo \"th\\?id=.*?.jpg\" | head -n 1| sed -e \"s/tmb/UHD/\")) wallpaperurl=\"https://bing.com/$bingfileurl\" echo \"$(date) | Setting wallpaperurl to todays Bing Desktop [$wallpaperurl]\" fi echo \"$(date) | Downloading Wallpaper from [$wallpaperurl] to [$wallpaperdir/$wallpaperfile]\" curl -L -o $wallpaperdir/$wallpaperfile $wallpaperurl if [ \"$?\" = \"0\" ]; then echo \"$(date) | Wallpaper [$wallpaperurl] downloaded to [$wallpaperdir/$wallpaperfile]\" #killall Dock exit 0 else echo \"$(date) | Failed to download wallpaper image from [$wallpaperurl]\" exit 1 fi"
        },
        {
            "filename": "file_552.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Battery Condition\\file_552.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to return the macOS Battery Condition ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com batteryCondition=$(system_profiler SPPowerDataType | grep \"Condition:\" | sed 's/.*Condition: //') echo $batteryCondition"
        },
        {
            "filename": "file_553.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Check bootstrap token escrow status\\file_553.sh",
            "content": "#!/bin/zsh #set -x ############################################################################################ ## ## Extension Attribute script to return the bootstrap token escrow status ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. result=$(profiles status -type bootstraptoken) if [[ \"$result\" == *\"Bootstrap Token escrowed to server: YES\"* ]]; then echo \"Yes\" else echo \"No\" fi"
        },
        {
            "filename": "file_554.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\checkDefenderRunning\\file_554.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to check if Defender is running ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # Define list of processes that should be running for this app processes=( \"wdavdaemon_enterprise\" \"wdavdaemon_unprivileged\" \"wdavdaemon\") for proc in \"${processes[@]}\"; do if ! pgrep -x \"$proc\" >/dev/null; then echo \"$(date) | [$proc] is not running\" let missingProcCount=$missingProcCount+1 fi done if [[ $missingProcCount -gt 0 ]]; then echo \"Defender missing [$missingProcCount] processes\" else echo \"Defender running\" fi"
        },
        {
            "filename": "file_555.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\CPU Architecture\\file_555.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to return the processor type ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) echo $processor"
        },
        {
            "filename": "file_556.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Fetch Defender Version\\file_556.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to return the version of an installed App ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables app=\"Microsoft Defender.app\" # Fixed Variables attribute=\"CFBundleShortVersionString\" InfoPlistPath=\"/Applications/$app/Contents/Info.plist\" # Attempt to read CFBundleStringShortVersionString and return it if [[ -f \"$InfoPlistPath\" ]]; then ver=$(plutil -p \"$InfoPlistPath\" | grep \"$attribute\" | awk -F'\"' '{ print $4 }') echo $ver else echo \"not installed\" fi"
        },
        {
            "filename": "file_557.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Fetch Firefox Version\\file_557.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to return the version of an installed App ## ############################################################################################ ## Copyright (c) 2023 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables app=\"Firefox.app\" # Fixed Variables attribute=\"CFBundleShortVersionString\" InfoPlistPath=\"/Applications/$app/Contents/Info.plist\" # Attempt to read CFBundleStringShortVersionString and return it if [[ -f \"$InfoPlistPath\" ]]; then ver=$(plutil -p \"$InfoPlistPath\" | grep \"$attribute\" | awk -F'\"' '{ print $4 }') echo $ver else echo \"Not installed\" fi"
        },
        {
            "filename": "file_558.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Fetch Google Chrome Version\\file_558.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to return the version of an installed App ## ############################################################################################ ## Copyright (c) 2023 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables app=\"Google Chrome.app\" # Fixed Variables attribute=\"CFBundleShortVersionString\" InfoPlistPath=\"/Applications/$app/Contents/Info.plist\" # Attempt to read CFBundleStringShortVersionString and return it if [[ -f \"$InfoPlistPath\" ]]; then ver=$(plutil -p \"$InfoPlistPath\" | grep \"$attribute\" | awk -F'\"' '{ print $4 }') echo $ver else echo \"Not installed\" fi"
        },
        {
            "filename": "file_559.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Fetch Illumio VEN Version\\file_559.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to return the version of an installed App ## ############################################################################################ ## Copyright (c) 2023 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables ver=\"$(/opt/illumio_ven/illumio-ven-ctl version)\" # Fixed Variables app=\"/opt/illumio_ven/illumio-ven-ctl\" # If Illumio VEN is installed, return installed version number. if [[ -f \"$app\" ]]; then echo $ver else echo \"Not installed\" fi"
        },
        {
            "filename": "file_560.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Fetch Microsoft Edge Version\\file_560.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to return the version of an installed App ## ############################################################################################ ## Copyright (c) 2023 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables app=\"Microsoft Edge.app\" # Fixed Variables attribute=\"CFBundleShortVersionString\" InfoPlistPath=\"/Applications/$app/Contents/Info.plist\" # Attempt to read CFBundleStringShortVersionString and return it if [[ -f \"$InfoPlistPath\" ]]; then ver=$(plutil -p \"$InfoPlistPath\" | grep \"$attribute\" | awk -F'\"' '{ print $4 }') echo $ver else echo \"Not installed\" fi"
        },
        {
            "filename": "file_561.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Fetch OneDrive Version\\file_561.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to return the version of an installed App ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables app=\"OneDrive.app\" # Fixed Variables attribute=\"CFBundleShortVersionString\" InfoPlistPath=\"/Applications/$app/Contents/Info.plist\" # Attempt to read CFBundleStringShortVersionString and return it if [[ -f \"$InfoPlistPath\" ]]; then ver=$(plutil -p \"$InfoPlistPath\" | grep \"$attribute\" | awk -F'\"' '{ print $4 }') echo $ver else echo \"not installed\" fi"
        },
        {
            "filename": "file_562.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Fetch Sidecar Version\\file_562.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to return the version of an installed App ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables # Fixed Variables attribute=\"CFBundleShortVersionString\" InfoPlistPath=\"/Library/Intune/Microsoft Intune Agent.app/Contents/Info.plist\" # Attempt to read CFBundleStringShortVersionString and return it if [[ -f \"$InfoPlistPath\" ]]; then ver=$(plutil -p \"$InfoPlistPath\" | grep \"$attribute\" | awk -F'\"' '{ print $4 }') echo $ver else echo \"not installed\" fi"
        },
        {
            "filename": "file_563.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Gimp\\file_563.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to return the version of an installed App ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com # User Defined variables app=\"Gimp.app\" # Fixed Variables attribute=\"CFBundleShortVersionString\" InfoPlistPath=\"/Applications/$app/Contents/Info.plist\" # Attempt to read CFBundleStringShortVersionString and return it if [[ -f \"$InfoPlistPath\" ]]; then ver=$(plutil -p \"$InfoPlistPath\" | grep \"$attribute\" | awk -F'\"' '{ print $4 }') echo $ver else echo \"not installed\" fi"
        },
        {
            "filename": "file_564.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-intune-samples\\macOS\\Custom Attributes\\Hackintosh\\file_564.sh",
            "content": "#!/bin/bash #set -x ############################################################################################ ## ## Extension Attribute script to try and test if this is a hackintosh or not ## ############################################################################################ ## Copyright (c) 2020 Microsoft Corp. All rights reserved. ## Scripts are not supported under any Microsoft standard support program or service. The scripts are provided AS IS without warranty of any kind. ## Microsoft disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a ## particular purpose. The entire risk arising out of the use or performance of the scripts and documentation remains with you. In no event shall ## Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever ## (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary ## loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility ## of such damages. ## Feedback: neiljohn@microsoft.com exec &>/dev/null #Let's check for a few things.. # If we're running on AMD We're almost certainly on a Hack Mac processor=$(/usr/sbin/sysctl -n machdep.cpu.brand_string) if [[ \"$processor\" == *\"AMD\"* ]]; then hackintosh=true CPU=\"AMD\" echo \"this is probably a hackintosh - AMB\" echo \"$(date) | [$processor] found, Rosetta not needed\" fi # If com.apple.drive.AppleSMC isn't loaded, we're likely on a Hack Mac if [[ ! $(kextstat -b com.apple.driver.AppleSMC | grep \"com.apple.driver.AppleSMC\" | grep -v grep) ]]; then hackintosh=true AppleSMCMissing=\"AppleSMCMissing\" fi # If FakeSMC.kext is in our kext list, we're likely on a Hack Mac if [[ $(kextstat -b FakeSMC.kext | grep \"FakeSMC.kext\" | grep -v grep) ]]; then hackintosh=true FakeSMC=\"FakeSMC\" fi exec > /dev/tty if [[ $hackintosh == \"true\" ]]; then echo \"Hackintosh ($CPU $AppleSMCMissing $FakeSMC)\" else echo \"Real Mac\" fi"
        },
        {
            "filename": "file_565.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-for-beginners-course\\docs\\05-Project-E-Commerce-Application\\file_565.sh",
            "content": "#!/bin/bash # # Automate ECommerce Application Deployment # Author: Mumshad Mannambeth ####################################### # Print a message in a given color. # Arguments: # Color. eg: green, red ####################################### function print_color(){ NC='\\033[0m' # No Color case $1 in \"green\") COLOR='\\033[0;32m' ;; \"red\") COLOR='\\033[0;31m' ;; \"*\") COLOR='\\033[0m' ;; esac echo -e \"${COLOR} $2 ${NC}\" } ####################################### # Check the status of a given service. If not active exit script # Arguments: # Service Name. eg: firewalld, mariadb ####################################### function check_service_status(){ service_is_active=$(sudo systemctl is-active $1) if [ $service_is_active = \"active\" ] then echo \"$1 is active and running\" else echo \"$1 is not active/running\" exit 1 fi } ####################################### # Check the status of a firewalld rule. If not configured exit. # Arguments: # Port Number. eg: 3306, 80 ####################################### function is_firewalld_rule_configured(){ firewalld_ports=$(sudo firewall-cmd --list-all --zone=public | grep ports) if [[ $firewalld_ports == *$1* ]] then echo \"FirewallD has port $1 configured\" else echo \"FirewallD port $1 is not configured\" exit 1 fi } ####################################### # Check if a given item is present in an output # Arguments: # 1 - Output # 2 - Item ####################################### function check_item(){ if [[ $1 = *$2* ]] then print_color \"green\" \"Item $2 is present on the web page\" else print_color \"red\" \"Item $2 is not present on the web page\" fi } echo \"---------------- Setup Database Server ------------------\" # Install and configure firewalld print_color \"green\" \"Installing FirewallD.. \" sudo yum install -y firewalld print_color \"green\" \"Installing FirewallD.. \" sudo service firewalld start sudo systemctl enable firewalld # Check FirewallD Service is running check_service_status firewalld # Install and configure Maria-DB print_color \"green\" \"Installing MariaDB Server..\" sudo yum install -y mariadb-server print_color \"green\" \"Starting MariaDB Server..\" sudo service mariadb start sudo systemctl enable mariadb # Check FirewallD Service is running check_service_status mariadb # Configure Firewall rules for Database print_color \"green\" \"Configuring FirewallD rules for database..\" sudo firewall-cmd --permanent --zone=public --add-port=3306/tcp sudo firewall-cmd --reload is_firewalld_rule_configured 3306 # Configuring Database print_color \"green\" \"Setting up database..\" cat > setup-db.sql <<-EOF CREATE DATABASE ecomdb; CREATE USER 'ecomuser'@'localhost' IDENTIFIED BY 'ecompassword'; GRANT ALL PRIVILEGES ON *.* TO 'ecomuser'@'localhost'; FLUSH PRIVILEGES; EOF sudo mysql < setup-db.sql # Loading inventory into Database print_color \"green\" \"Loading inventory data into database\" cat > db-load-script.sql <<-EOF USE ecomdb; CREATE TABLE products (id mediumint(8) unsigned NOT NULL auto_increment,Name varchar(255) default NULL,Price varchar(255) default NULL, ImageUrl varchar(255) default NULL,PRIMARY KEY (id)) AUTO_INCREMENT=1; INSERT INTO products (Name,Price,ImageUrl) VALUES (\"Laptop\",\"100\",\"c-1.png\"),(\"Drone\",\"200\",\"c-2.png\"),(\"VR\",\"300\",\"c-3.png\"),(\"Tablet\",\"50\",\"c-5.png\"),(\"Watch\",\"90\",\"c-6.png\"),(\"Phone Covers\",\"20\",\"c-7.png\"),(\"Phone\",\"80\",\"c-8.png\"),(\"Laptop\",\"150\",\"c-4.png\"); EOF sudo mysql < db-load-script.sql mysql_db_results=$(sudo mysql -e \"use ecomdb; select * from products;\") if [[ $mysql_db_results == *Laptop* ]] then print_color \"green\" \"Inventory data loaded into MySQl\" else print_color \"green\" \"Inventory data not loaded into MySQl\" exit 1 fi print_color \"green\" \"---------------- Setup Database Server - Finished ------------------\" print_color \"green\" \"---------------- Setup Web Server ------------------\" # Install web server packages print_color \"green\" \"Installing Web Server Packages ..\" sudo yum install -y httpd php php-mysql # Configure firewalld rules print_color \"green\" \"Configuring FirewallD rules..\" sudo firewall-cmd --permanent --zone=public --add-port=80/tcp sudo firewall-cmd --reload is_firewalld_rule_configured 80 # Update index.php sudo sed -i 's/index.html/index.php/g' /etc/httpd/conf/httpd.conf # Start httpd service print_color \"green\" \"Start httpd service..\" sudo service httpd start sudo systemctl enable httpd # Check FirewallD Service is running check_service_status httpd # Download code print_color \"green\" \"Install GIT..\" sudo yum install -y git sudo git clone https://github.com/kodekloudhub/learning-app-ecommerce.git /var/www/html/ print_color \"green\" \"Updating index.php..\" sudo sed -i 's/172.20.1.101/localhost/g' /var/www/html/index.php print_color \"green\" \"---------------- Setup Web Server - Finished ------------------\" # Test Script web_page=$(curl http://localhost) for item in Laptop Drone VR Watch Phone do check_item \"$web_page\" $item done"
        },
        {
            "filename": "file_566.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-projects\\aws-event-triggering\\file_566.sh",
            "content": "#!/bin/bash set -x # Store the AWS account ID in a variable aws_account_id=$(aws sts get-caller-identity --query 'Account' --output text) # Print the AWS account ID from the variable echo \"AWS Account ID: $aws_account_id\" # Set AWS region and bucket name aws_region=\"us-east-1\" bucket_name=\"abhishek-ultimate-bucket\" lambda_func_name=\"s3-lambda-function\" role_name=\"s3-lambda-sns\" email_address=\"zyz@gmail.com\" # Create IAM Role for the project role_response=$(aws iam create-role --role-name s3-lambda-sns --assume-role-policy-document '{ \"Version\": \"2012-10-17\", \"Statement\": [{ \"Action\": \"sts:AssumeRole\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": [ \"lambda.amazonaws.com\", \"s3.amazonaws.com\", \"sns.amazonaws.com\" ] } }] }') # Extract the role ARN from the JSON response and store it in a variable role_arn=$(echo \"$role_response\" | jq -r '.Role.Arn') # Print the role ARN echo \"Role ARN: $role_arn\" # Attach Permissions to the Role aws iam attach-role-policy --role-name $role_name --policy-arn arn:aws:iam::aws:policy/AWSLambda_FullAccess aws iam attach-role-policy --role-name $role_name --policy-arn arn:aws:iam::aws:policy/AmazonSNSFullAccess # Create the S3 bucket and capture the output in a variable bucket_output=$(aws s3api create-bucket --bucket \"$bucket_name\" --region \"$aws_region\") # Print the output from the variable echo \"Bucket creation output: $bucket_output\" # Upload a file to the bucket aws s3 cp ./example_file.txt s3://\"$bucket_name\"/example_file.txt # Create a Zip file to upload Lambda Function zip -r s3-lambda-function.zip ./s3-lambda-function sleep 5 # Create a Lambda function aws lambda create-function \\ --region \"$aws_region\" \\ --function-name $lambda_func_name \\ --runtime \"python3.8\" \\ --handler \"s3-lambda-function/s3-lambda-function.lambda_handler\" \\ --memory-size 128 \\ --timeout 30 \\ --role \"arn:aws:iam::$aws_account_id:role/$role_name\" \\ --zip-file \"fileb://./s3-lambda-function.zip\" # Add Permissions to S3 Bucket to invoke Lambda aws lambda add-permission \\ --function-name \"$lambda_func_name\" \\ --statement-id \"s3-lambda-sns\" \\ --action \"lambda:InvokeFunction\" \\ --principal s3.amazonaws.com \\ --source-arn \"arn:aws:s3:::$bucket_name\" # Create an S3 event trigger for the Lambda function LambdaFunctionArn=\"arn:aws:lambda:us-east-1:$aws_account_id:function:s3-lambda-function\" aws s3api put-bucket-notification-configuration \\ --region \"$aws_region\" \\ --bucket \"$bucket_name\" \\ --notification-configuration '{ \"LambdaFunctionConfigurations\": [{ \"LambdaFunctionArn\": \"'\"$LambdaFunctionArn\"'\", \"Events\": [\"s3:ObjectCreated:*\"] }] }' # Create an SNS topic and save the topic ARN to a variable topic_arn=$(aws sns create-topic --name s3-lambda-sns --output json | jq -r '.TopicArn') # Print the TopicArn echo \"SNS Topic ARN: $topic_arn\" # Trigger SNS Topic using Lambda Function # Add SNS publish permission to the Lambda Function aws sns subscribe \\ --topic-arn \"$topic_arn\" \\ --protocol email \\ --notification-endpoint \"$email_address\" # Publish SNS aws sns publish \\ --topic-arn \"$topic_arn\" \\ --subject \"A new object created in s3 bucket\" \\ --message \"Hello from Abhishek.Veeramalla YouTube channel, Learn DevOps Zero to Hero for Free\""
        },
        {
            "filename": "file_567.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-projects\\github-api\\file_567.sh",
            "content": "#!/bin/bash # GitHub API URL API_URL=\"https://api.github.com\" # GitHub username and personal access token USERNAME=$username TOKEN=$token # User and Repository information REPO_OWNER=$1 REPO_NAME=$2 # Function to make a GET request to the GitHub API function github_api_get { local endpoint=\"$1\" local url=\"${API_URL}/${endpoint}\" # Send a GET request to the GitHub API with authentication curl -s -u \"${USERNAME}:${TOKEN}\" \"$url\" } # Function to list users with read access to the repository function list_users_with_read_access { local endpoint=\"repos/${REPO_OWNER}/${REPO_NAME}/collaborators\" # Fetch the list of collaborators on the repository collaborators=\"$(github_api_get \"$endpoint\" | jq -r '.[] | select(.permissions.pull == true) | .login')\" # Display the list of collaborators with read access if [[ -z \"$collaborators\" ]]; then echo \"No users with read access found for ${REPO_OWNER}/${REPO_NAME}.\" else echo \"Users with read access to ${REPO_OWNER}/${REPO_NAME}:\" echo \"$collaborators\" fi } # Main script echo \"Listing users with read access to ${REPO_OWNER}/${REPO_NAME}...\" list_users_with_read_access"
        },
        {
            "filename": "file_568.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-templates\\file_568.sh",
            "content": "#!/usr/bin/env bash # shellcheck source-path=SCRIPTDIR/../shell-scripting-templates/utilities # shellcheck source-path=SCRIPTDIR/../../shell-scripting-templates/utilities _mainScript_() { # Replace everything in _mainScript_() with your script's code header \"Showing alert colors\" debug \"This is debug text\" info \"This is info text\" notice \"This is notice text\" dryrun \"This is dryrun text\" warning \"This is warning text\" error \"This is error text\" success \"This is success text\" input \"This is input text\" } #/_mainsScript_() # ################################## Flags and defaults # # Required variables LOGFILE=\"${HOME}/logs/$(basename \"$0\").log\" QUIET=false LOGLEVEL=ERROR VERBOSE=false FORCE=false DRYRUN=false declare -a ARGS=() # Script specific # ################################## Functions required for this template to work _trapCleanup_() { # DESC: # Log errors and cleanup from script when an error is trapped. Called by 'trap' # ARGS: # $1: Line number where error was trapped # $2: Line number in function # $3: Command executing at the time of the trap # $4: Names of all shell functions currently in the execution call stack # $5: Scriptname # $6: $BASH_SOURCE # USAGE: # trap '_trapCleanup_ ${LINENO} ${BASH_LINENO} \"${BASH_COMMAND}\" \"${FUNCNAME[*]}\" \"${0}\" \"${BASH_SOURCE[0]}\"' EXIT INT TERM SIGINT SIGQUIT SIGTERM ERR # OUTS: # Exits script with error code 1 local _line=${1:-} # LINENO local _linecallfunc=${2:-} local _command=\"${3:-}\" local _funcstack=\"${4:-}\" local _script=\"${5:-}\" local _sourced=\"${6:-}\" # Replace the cursor in-case 'tput civis' has been used tput cnorm if declare -f \"fatal\" &>/dev/null && declare -f \"_printFuncStack_\" &>/dev/null; then _funcstack=\"'$(printf \"%s\" \"${_funcstack}\" | sed -E 's/ / < /g')'\" if [[ ${_script##*/} == \"${_sourced##*/}\" ]]; then fatal \"${7:-} command: '${_command}' (line: ${_line}) [func: $(_printFuncStack_)]\" else fatal \"${7:-} command: '${_command}' (func: ${_funcstack} called at line ${_linecallfunc} of '${_script##*/}') (line: ${_line} of '${_sourced##*/}') \" fi else printf \"%s\\n\" \"Fatal error trapped. Exiting...\" fi if declare -f _safeExit_ &>/dev/null; then _safeExit_ 1 else exit 1 fi } _findBaseDir_() { # DESC: # Locates the real directory of the script being run. Similar to GNU readlink -n # ARGS: # None # OUTS: # stdout: prints result # USAGE: # baseDir=\"$(_findBaseDir_)\" # cp \"$(_findBaseDir_ \"somefile.txt\")\" \"other_file.txt\" local _source local _dir # Is file sourced? if [[ ${_} != \"${0}\" ]]; then _source=\"${BASH_SOURCE[1]}\" else _source=\"${BASH_SOURCE[0]}\" fi while [ -h \"${_source}\" ]; do # Resolve $SOURCE until the file is no longer a symlink _dir=\"$(cd -P \"$(dirname \"${_source}\")\" && pwd)\" _source=\"$(readlink \"${_source}\")\" [[ ${_source} != /* ]] && _source=\"${_dir}/${_source}\" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located done printf \"%s\\n\" \"$(cd -P \"$(dirname \"${_source}\")\" && pwd)\" } _sourceUtilities_() { # DESC: # Sources utility functions. Absolute paths are required for shellcheck to correctly # parse the sourced files # ARGS: # $1 (Required): Absolute path to the directory containing the utilities # OUTS: # 0: Success # 1: Failure # USAGE: # _sourceUtilities_ \"$(_findBaseDir_)/../../shell-scripting-templates/utilities\" local _utilsPath _utilsPath=\"${1}\" if [ -f \"${_utilsPath}/alerts.bash\" ]; then source \"${_utilsPath}/alerts.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/alerts.bash not found\" exit 1 fi if [ -f \"${_utilsPath}/arrays.bash\" ]; then source \"${_utilsPath}/arrays.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/arrays.bash not found\" exit 1 fi if [ -f \"${_utilsPath}/checks.bash\" ]; then source \"${_utilsPath}/checks.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/checks.bash not found\" exit 1 fi if [ -f \"${_utilsPath}/dates.bash\" ]; then source \"${_utilsPath}/dates.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/dates.bash not found\" exit 1 fi if [ -f \"${_utilsPath}/debug.bash\" ]; then source \"${_utilsPath}/debug.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/debug.bash not found\" exit 1 fi if [ -f \"${_utilsPath}/files.bash\" ]; then source \"${_utilsPath}/files.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/files.bash not found\" exit 1 fi if [ -f \"${_utilsPath}/macOS.bash\" ]; then source \"${_utilsPath}/macOS.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/macOS.bash not found\" exit 1 fi if [ -f \"${_utilsPath}/misc.bash\" ]; then source \"${_utilsPath}/misc.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/misc.bash not found\" exit 1 fi if [ -f \"${_utilsPath}/services.bash\" ]; then source \"${_utilsPath}/services.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/services.bash not found\" exit 1 fi if [ -f \"${_utilsPath}/strings.bash\" ]; then source \"${_utilsPath}/strings.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/strings.bash not found\" exit 1 fi if [ -f \"${_utilsPath}/template_utils.bash\" ]; then source \"${_utilsPath}/template_utils.bash\" else printf \"%s\\n\" \"ERROR: ${_utilsPath}/template_utils.bash not found\" exit 1 fi } _parseOptions_() { # DESC: # Iterates through options passed to script and sets variables. Will break -ab into -a -b # when needed and --foo=bar into --foo bar # ARGS: # $@ from command line # OUTS: # Sets array 'ARGS' containing all arguments passed to script that were not parsed as options # USAGE: # _parseOptions_ \"$@\" # Iterate over options local _optstring=h declare -a _options local _c local i while (($#)); do case $1 in # If option is of type -ab -[!-]?*) # Loop over each character starting with the second for ((i = 1; i < ${#1}; i++)); do _c=${1:i:1} _options+=(\"-${_c}\") # Add current char to options # If option takes a required argument, and it's not the last char make # the rest of the string its argument if [[ ${_optstring} == *\"${_c}:\"* && -n ${1:i+1} ]]; then _options+=(\"${1:i+1}\") break fi done ;; # If option is of type --foo=bar --?*=*) _options+=(\"${1%%=*}\" \"${1#*=}\") ;; # add --endopts for -- --) _options+=(--endopts) ;; # Otherwise, nothing special *) _options+=(\"$1\") ;; esac shift done set -- \"${_options[@]:-}\" unset _options # Read the options and set stuff # shellcheck disable=SC2034 while [[ ${1:-} == -?* ]]; do case $1 in # Custom options # Common options -h | --help) _usage_ _safeExit_ ;; --loglevel) shift LOGLEVEL=${1} ;; --logfile) shift LOGFILE=\"${1}\" ;; -n | --dryrun) DRYRUN=true ;; -v | --verbose) VERBOSE=true ;; -q | --quiet) QUIET=true ;; --force) FORCE=true ;; --endopts) shift break ;; *) if declare -f _safeExit_ &>/dev/null; then fatal \"invalid option: $1\" else printf \"%s\\n\" \"ERROR: Invalid option: $1\" exit 1 fi ;; esac shift done if [[ -z ${*} || ${*} == null ]]; then ARGS=() else ARGS+=(\"$@\") # Store the remaining user input as arguments. fi } _usage_() { cat <<USAGE_TEXT ${bold}$(basename \"$0\") [OPTION]... [FILE]...${reset} This is a script template. Edit this description to print help to users. ${bold}${underline}Options:${reset} $(_columns_ -b -- '-h, --help' \"Display this help and exit\" 2) $(_columns_ -b -- \"--loglevel [LEVEL]\" \"One of: FATAL, ERROR (default), WARN, INFO, NOTICE, DEBUG, ALL, OFF\" 2) $(_columns_ -b -- \"--logfile [FILE]\" \"Full PATH to logfile. (Default is '\\${HOME}/logs/$(basename \"$0\").log')\" 2) $(_columns_ -b -- \"-n, --dryrun\" \"Non-destructive. Makes no permanent changes.\" 2) $(_columns_ -b -- \"-q, --quiet\" \"Quiet (no output)\" 2) $(_columns_ -b -- \"-v, --verbose\" \"Output more information. (Items echoed to 'verbose')\" 2) $(_columns_ -b -- \"--force\" \"Skip all user interaction. Implied 'Yes' to all actions.\" 2) ${bold}${underline}Example Usage:${reset} ${gray}# Run the script and specify log level and log file.${reset} $(basename \"$0\") -vn --logfile \"/path/to/file.log\" --loglevel 'WARN' USAGE_TEXT } # ################################## INITIALIZE AND RUN THE SCRIPT # (Comment or uncomment the lines below to customize script behavior) trap '_trapCleanup_ ${LINENO} ${BASH_LINENO} \"${BASH_COMMAND}\" \"${FUNCNAME[*]}\" \"${0}\" \"${BASH_SOURCE[0]}\"' EXIT INT TERM SIGINT SIGQUIT SIGTERM # Trap errors in subshells and functions set -o errtrace # Exit on error. Append '||true' if you expect an error set -o errexit # Use last non-zero exit code in a pipeline set -o pipefail # Confirm we have BASH greater than v4 [ \"${BASH_VERSINFO:-0}\" -ge 4 ] || { printf \"%s\\n\" \"ERROR: BASH_VERSINFO is '${BASH_VERSINFO:-0}'. This script requires BASH v4 or greater.\" exit 1 } # Make `for f in *.txt` work when `*.txt` matches zero files shopt -s nullglob globstar # Set IFS to preferred implementation IFS=$' \\n\\t' # Run in debug mode # set -o xtrace # Source utility functions _sourceUtilities_ \"$(_findBaseDir_)/../shell-scripting-templates/utilities\" # Initialize color constants _setColors_ # Disallow expansion of unset variables set -o nounset # Force arguments when invoking the script # [[ $# -eq 0 ]] && _parseOptions_ \"-h\" # Parse arguments passed to script _parseOptions_ \"$@\" # Create a temp directory '$TMP_DIR' # _makeTempDir_ \"$(basename \"$0\")\" # Acquire script lock # _acquireScriptLock_ # Add Homebrew bin directory to PATH (MacOS) # _homebrewPath_ # Source GNU utilities from Homebrew (MacOS) # _useGNUutils_ # Run the main logic script _mainScript_ # Exit cleanly _safeExit_"
        },
        {
            "filename": "file_569.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-templates\\file_569.sh",
            "content": "#!/usr/bin/env bash _mainScript_() { # Replace everything in _mainScript_() with your script's code header \"Showing alert colors\" debug \"This is debug text\" info \"This is info text\" notice \"This is notice text\" dryrun \"This is dryrun text\" warning \"This is warning text\" error \"This is error text\" success \"This is success text\" input \"This is input text\" } # end _mainScript_ # ################################## Flags and defaults # Required variables LOGFILE=\"${HOME}/logs/$(basename \"$0\").log\" QUIET=false LOGLEVEL=ERROR VERBOSE=false FORCE=false DRYRUN=false declare -a ARGS=() # Script specific # ################################## Custom utility functions (Pasted from repository) # ################################## Functions required for this template to work _setColors_() { # DESC: # Sets colors use for alerts. # ARGS: # None # OUTS: # None # USAGE: # printf \"%s\\n\" \"${blue}Some text${reset}\" if tput setaf 1 >/dev/null 2>&1; then bold=$(tput bold) underline=$(tput smul) reverse=$(tput rev) reset=$(tput sgr0) if [[ $(tput colors) -ge 256 ]] >/dev/null 2>&1; then white=$(tput setaf 231) blue=$(tput setaf 38) yellow=$(tput setaf 11) green=$(tput setaf 82) red=$(tput setaf 9) purple=$(tput setaf 171) gray=$(tput setaf 250) else white=$(tput setaf 7) blue=$(tput setaf 38) yellow=$(tput setaf 3) green=$(tput setaf 2) red=$(tput setaf 9) purple=$(tput setaf 13) gray=$(tput setaf 7) fi else bold=\"\\033[4;37m\" reset=\"\\033[0m\" underline=\"\\033[4;37m\" # shellcheck disable=SC2034 reverse=\"\" white=\"\\033[0;37m\" blue=\"\\033[0;34m\" yellow=\"\\033[0;33m\" green=\"\\033[1;32m\" red=\"\\033[0;31m\" purple=\"\\033[0;35m\" gray=\"\\033[0;37m\" fi } _alert_() { # DESC: # Controls all printing of messages to log files and stdout. # ARGS: # $1 (required) - The type of alert to print # (success, header, notice, dryrun, debug, warning, error, # fatal, info, input) # $2 (required) - The message to be printed to stdout and/or a log file # $3 (optional) - Pass '${LINENO}' to print the line number where the _alert_ was triggered # OUTS: # stdout: The message is printed to stdout # log file: The message is printed to a log file # USAGE: # [_alertType] \"[MESSAGE]\" \"${LINENO}\" # NOTES: # - The colors of each alert type are set in this function # - For specified alert types, the funcstac will be printed local _color local _alertType=\"${1}\" local _message=\"${2}\" local _line=\"${3:-}\" # Optional line number [[ $# -lt 2 ]] && fatal 'Missing required argument to _alert_' if [[ -n ${_line} && ${_alertType} =~ ^(fatal|error) && ${FUNCNAME[2]} != \"_trapCleanup_\" ]]; then _message=\"${_message} ${gray}(line: ${_line}) $(_printFuncStack_)\" elif [[ -n ${_line} && ${FUNCNAME[2]} != \"_trapCleanup_\" ]]; then _message=\"${_message} ${gray}(line: ${_line})\" elif [[ -z ${_line} && ${_alertType} =~ ^(fatal|error) && ${FUNCNAME[2]} != \"_trapCleanup_\" ]]; then _message=\"${_message} ${gray}$(_printFuncStack_)\" fi if [[ ${_alertType} =~ ^(error|fatal) ]]; then _color=\"${bold}${red}\" elif [ \"${_alertType}\" == \"info\" ]; then _color=\"${gray}\" elif [ \"${_alertType}\" == \"warning\" ]; then _color=\"${red}\" elif [ \"${_alertType}\" == \"success\" ]; then _color=\"${green}\" elif [ \"${_alertType}\" == \"debug\" ]; then _color=\"${purple}\" elif [ \"${_alertType}\" == \"header\" ]; then _color=\"${bold}${white}${underline}\" elif [ \"${_alertType}\" == \"notice\" ]; then _color=\"${bold}\" elif [ \"${_alertType}\" == \"input\" ]; then _color=\"${bold}${underline}\" elif [ \"${_alertType}\" = \"dryrun\" ]; then _color=\"${blue}\" else _color=\"\" fi _writeToScreen_() { (\"${QUIET}\") && return 0 # Print to console when script is not 'quiet' [[ ${VERBOSE} == false && ${_alertType} =~ ^(debug|verbose) ]] && return 0 if ! [[ -t 1 || -z ${TERM:-} ]]; then # Don't use colors on non-recognized terminals _color=\"\" reset=\"\" fi if [[ ${_alertType} == header ]]; then printf \"${_color}%s${reset}\\n\" \"${_message}\" else printf \"${_color}[%7s] %s${reset}\\n\" \"${_alertType}\" \"${_message}\" fi } _writeToScreen_ _writeToLog_() { [[ ${_alertType} == \"input\" ]] && return 0 [[ ${LOGLEVEL} =~ (off|OFF|Off) ]] && return 0 if [ -z \"${LOGFILE:-}\" ]; then LOGFILE=\"$(pwd)/$(basename \"$0\").log\" fi [ ! -d \"$(dirname \"${LOGFILE}\")\" ] && mkdir -p \"$(dirname \"${LOGFILE}\")\" [[ ! -f ${LOGFILE} ]] && touch \"${LOGFILE}\" # Don't use colors in logs local _cleanmessage _cleanmessage=\"$(printf \"%s\" \"${_message}\" | sed -E 's/(\\x1b)?\\[(([0-9]{1,2})(;[0-9]{1,3}){0,2})?[mGK]//g')\" # Print message to log file printf \"%s [%7s] %s %s\\n\" \"$(date +\"%b %d %R:%S\")\" \"${_alertType}\" \"[$(/bin/hostname)]\" \"${_cleanmessage}\" >>\"${LOGFILE}\" } # Write specified log level data to logfile case \"${LOGLEVEL:-ERROR}\" in ALL | all | All) _writeToLog_ ;; DEBUG | debug | Debug) _writeToLog_ ;; INFO | info | Info) if [[ ${_alertType} =~ ^(error|fatal|warning|info|notice|success) ]]; then _writeToLog_ fi ;; NOTICE | notice | Notice) if [[ ${_alertType} =~ ^(error|fatal|warning|notice|success) ]]; then _writeToLog_ fi ;; WARN | warn | Warn) if [[ ${_alertType} =~ ^(error|fatal|warning) ]]; then _writeToLog_ fi ;; ERROR | error | Error) if [[ ${_alertType} =~ ^(error|fatal) ]]; then _writeToLog_ fi ;; FATAL | fatal | Fatal) if [[ ${_alertType} =~ ^fatal ]]; then _writeToLog_ fi ;; OFF | off) return 0 ;; *) if [[ ${_alertType} =~ ^(error|fatal) ]]; then _writeToLog_ fi ;; esac } # /_alert_ error() { _alert_ error \"${1}\" \"${2:-}\"; } warning() { _alert_ warning \"${1}\" \"${2:-}\"; } notice() { _alert_ notice \"${1}\" \"${2:-}\"; } info() { _alert_ info \"${1}\" \"${2:-}\"; } success() { _alert_ success \"${1}\" \"${2:-}\"; } dryrun() { _alert_ dryrun \"${1}\" \"${2:-}\"; } input() { _alert_ input \"${1}\" \"${2:-}\"; } header() { _alert_ header \"${1}\" \"${2:-}\"; } debug() { _alert_ debug \"${1}\" \"${2:-}\"; } fatal() { _alert_ fatal \"${1}\" \"${2:-}\" _safeExit_ \"1\" } _printFuncStack_() { # DESC: # Prints the function stack in use. Used for debugging, and error reporting. # ARGS: # None # OUTS: # stdout: Prints [function]:[file]:[line] # NOTE: # Does not print functions from the alert class local _i declare -a _funcStackResponse=() for ((_i = 1; _i < ${#BASH_SOURCE[@]}; _i++)); do case \"${FUNCNAME[${_i}]}\" in _alert_ | _trapCleanup_ | fatal | error | warning | notice | info | debug | dryrun | header | success) continue ;; *) _funcStackResponse+=(\"${FUNCNAME[${_i}]}:$(basename \"${BASH_SOURCE[${_i}]}\"):${BASH_LINENO[_i - 1]}\") ;; esac done printf \"( \" printf %s \"${_funcStackResponse[0]}\" printf ' < %s' \"${_funcStackResponse[@]:1}\" printf ' )\\n' } _safeExit_() { # DESC: # Cleanup and exit from a script # ARGS: # $1 (optional) - Exit code (defaults to 0) # OUTS: # None if [[ -d ${SCRIPT_LOCK:-} ]]; then if command rm -rf \"${SCRIPT_LOCK}\"; then debug \"Removing script lock\" else warning \"Script lock could not be removed. Try manually deleting ${yellow}'${SCRIPT_LOCK}'\" fi fi if [[ -n ${TMP_DIR:-} && -d ${TMP_DIR:-} ]]; then if [[ ${1:-} == 1 && -n \"$(ls \"${TMP_DIR}\")\" ]]; then command rm -r \"${TMP_DIR}\" else command rm -r \"${TMP_DIR}\" debug \"Removing temp directory\" fi fi trap - INT TERM EXIT exit \"${1:-0}\" } _trapCleanup_() { # DESC: # Log errors and cleanup from script when an error is trapped. Called by 'trap' # ARGS: # $1: Line number where error was trapped # $2: Line number in function # $3: Command executing at the time of the trap # $4: Names of all shell functions currently in the execution call stack # $5: Scriptname # $6: $BASH_SOURCE # USAGE: # trap '_trapCleanup_ ${LINENO} ${BASH_LINENO} \"${BASH_COMMAND}\" \"${FUNCNAME[*]}\" \"${0}\" \"${BASH_SOURCE[0]}\"' EXIT INT TERM SIGINT SIGQUIT SIGTERM ERR # OUTS: # Exits script with error code 1 local _line=${1:-} # LINENO local _linecallfunc=${2:-} local _command=\"${3:-}\" local _funcstack=\"${4:-}\" local _script=\"${5:-}\" local _sourced=\"${6:-}\" # Replace the cursor in-case 'tput civis' has been used tput cnorm if declare -f \"fatal\" &>/dev/null && declare -f \"_printFuncStack_\" &>/dev/null; then _funcstack=\"'$(printf \"%s\" \"${_funcstack}\" | sed -E 's/ / < /g')'\" if [[ ${_script##*/} == \"${_sourced##*/}\" ]]; then fatal \"${7:-} command: '${_command}' (line: ${_line}) [func: $(_printFuncStack_)]\" else fatal \"${7:-} command: '${_command}' (func: ${_funcstack} called at line ${_linecallfunc} of '${_script##*/}') (line: ${_line} of '${_sourced##*/}') \" fi else printf \"%s\\n\" \"Fatal error trapped. Exiting...\" fi if declare -f _safeExit_ &>/dev/null; then _safeExit_ 1 else exit 1 fi } _makeTempDir_() { # DESC: # Creates a temp directory to house temporary files # ARGS: # $1 (Optional) - First characters/word of directory name # OUTS: # Sets $TMP_DIR variable to the path of the temp directory # USAGE: # _makeTempDir_ \"$(basename \"$0\")\" [ -d \"${TMP_DIR:-}\" ] && return 0 if [ -n \"${1:-}\" ]; then TMP_DIR=\"${TMPDIR:-/tmp/}${1}.${RANDOM}.${RANDOM}.$$\" else TMP_DIR=\"${TMPDIR:-/tmp/}$(basename \"$0\").${RANDOM}.${RANDOM}.${RANDOM}.$$\" fi (umask 077 && mkdir \"${TMP_DIR}\") || { fatal \"Could not create temporary directory! Exiting.\" } debug \"\\$TMP_DIR=${TMP_DIR}\" } # shellcheck disable=SC2120 _acquireScriptLock_() { # DESC: # Acquire script lock to prevent running the same script a second time before the # first instance exits # ARGS: # $1 (optional) - Scope of script execution lock (system or user) # OUTS: # exports $SCRIPT_LOCK - Path to the directory indicating we have the script lock # Exits script if lock cannot be acquired # NOTE: # If the lock was acquired it's automatically released in _safeExit_() local _lockDir if [[ ${1:-} == 'system' ]]; then _lockDir=\"${TMPDIR:-/tmp/}$(basename \"$0\").lock\" else _lockDir=\"${TMPDIR:-/tmp/}$(basename \"$0\").${UID}.lock\" fi if command mkdir \"${_lockDir}\" 2>/dev/null; then readonly SCRIPT_LOCK=\"${_lockDir}\" debug \"Acquired script lock: ${yellow}${SCRIPT_LOCK}${purple}\" else if declare -f \"_safeExit_\" &>/dev/null; then error \"Unable to acquire script lock: ${yellow}${_lockDir}${red}\" fatal \"If you trust the script isn't running, delete the lock dir\" else printf \"%s\\n\" \"ERROR: Could not acquire script lock. If you trust the script isn't running, delete: ${_lockDir}\" exit 1 fi fi } _setPATH_() { # DESC: # Add directories to $PATH so script can find executables # ARGS: # $@ - One or more paths # OPTS: # -x - Fail if directories are not found # OUTS: # 0: Success # 1: Failure # Adds items to $PATH # USAGE: # _setPATH_ \"/usr/local/bin\" \"${HOME}/bin\" \"$(npm bin)\" [[ $# == 0 ]] && fatal \"Missing required argument to ${FUNCNAME[0]}\" local opt local OPTIND=1 local _failIfNotFound=false while getopts \":xX\" opt; do case ${opt} in x | X) _failIfNotFound=true ;; *) { error \"Unrecognized option '${1}' passed to _backupFile_\" \"${LINENO}\" return 1 } ;; esac done shift $((OPTIND - 1)) local _newPath for _newPath in \"$@\"; do if [ -d \"${_newPath}\" ]; then if ! printf \"%s\" \"${PATH}\" | grep -Eq \"(^|:)${_newPath}($|:)\"; then if PATH=\"${_newPath}:${PATH}\"; then debug \"Added '${_newPath}' to PATH\" else debug \"'${_newPath}' already in PATH\" fi else debug \"_setPATH_: '${_newPath}' already exists in PATH\" fi else debug \"_setPATH_: can not find: ${_newPath}\" if [[ ${_failIfNotFound} == true ]]; then return 1 fi continue fi done return 0 } _useGNUutils_() { # DESC: # Add GNU utilities to PATH to allow consistent use of sed/grep/tar/etc. on MacOS # ARGS: # None # OUTS: # 0 if successful # 1 if unsuccessful # PATH: Adds GNU utilities to the path # USAGE: # # if ! _useGNUUtils_; then exit 1; fi # NOTES: # GNU utilities can be added to MacOS using Homebrew ! declare -f \"_setPATH_\" &>/dev/null && fatal \"${FUNCNAME[0]} needs function _setPATH_\" if _setPATH_ \\ \"/usr/local/opt/gnu-tar/libexec/gnubin\" \\ \"/usr/local/opt/coreutils/libexec/gnubin\" \\ \"/usr/local/opt/gnu-sed/libexec/gnubin\" \\ \"/usr/local/opt/grep/libexec/gnubin\" \\ \"/usr/local/opt/findutils/libexec/gnubin\" \\ \"/opt/homebrew/opt/findutils/libexec/gnubin\" \\ \"/opt/homebrew/opt/gnu-sed/libexec/gnubin\" \\ \"/opt/homebrew/opt/grep/libexec/gnubin\" \\ \"/opt/homebrew/opt/coreutils/libexec/gnubin\" \\ \"/opt/homebrew/opt/gnu-tar/libexec/gnubin\"; then return 0 else return 1 fi } _homebrewPath_() { # DESC: # Add homebrew bin dir to PATH # ARGS: # None # OUTS: # 0 if successful # 1 if unsuccessful # PATH: Adds homebrew bin directory to PATH # USAGE: # # if ! _homebrewPath_; then exit 1; fi ! declare -f \"_setPATH_\" &>/dev/null && fatal \"${FUNCNAME[0]} needs function _setPATH_\" if _uname=$(command -v uname); then if \"${_uname}\" | tr '[:upper:]' '[:lower:]' | grep -q 'darwin'; then if _setPATH_ \"/usr/local/bin\" \"/opt/homebrew/bin\"; then return 0 else return 1 fi fi else if _setPATH_ \"/usr/local/bin\" \"/opt/homebrew/bin\"; then return 0 else return 1 fi fi } _parseOptions_() { # DESC: # Iterates through options passed to script and sets variables. Will break -ab into -a -b # when needed and --foo=bar into --foo bar # ARGS: # $@ from command line # OUTS: # Sets array 'ARGS' containing all arguments passed to script that were not parsed as options # USAGE: # _parseOptions_ \"$@\" # Iterate over options local _optstring=h declare -a _options local _c local i while (($#)); do case $1 in # If option is of type -ab -[!-]?*) # Loop over each character starting with the second for ((i = 1; i < ${#1}; i++)); do _c=${1:i:1} _options+=(\"-${_c}\") # Add current char to options # If option takes a required argument, and it's not the last char make # the rest of the string its argument if [[ ${_optstring} == *\"${_c}:\"* && -n ${1:i+1} ]]; then _options+=(\"${1:i+1}\") break fi done ;; # If option is of type --foo=bar --?*=*) _options+=(\"${1%%=*}\" \"${1#*=}\") ;; # add --endopts for -- --) _options+=(--endopts) ;; # Otherwise, nothing special *) _options+=(\"$1\") ;; esac shift done set -- \"${_options[@]:-}\" unset _options # Read the options and set stuff # shellcheck disable=SC2034 while [[ ${1:-} == -?* ]]; do case $1 in # Custom options # Common options -h | --help) _usage_ _safeExit_ ;; --loglevel) shift LOGLEVEL=${1} ;; --logfile) shift LOGFILE=\"${1}\" ;; -n | --dryrun) DRYRUN=true ;; -v | --verbose) VERBOSE=true ;; -q | --quiet) QUIET=true ;; --force) FORCE=true ;; --endopts) shift break ;; *) if declare -f _safeExit_ &>/dev/null; then fatal \"invalid option: $1\" else printf \"%s\\n\" \"ERROR: Invalid option: $1\" exit 1 fi ;; esac shift done if [[ -z ${*} || ${*} == null ]]; then ARGS=() else ARGS+=(\"$@\") # Store the remaining user input as arguments. fi } _columns_() { # DESC: # Prints a two column output from a key/value pair. # Optionally pass a number of 2 space tabs to indent the output. # ARGS: # $1 (required): Key name (Left column text) # $2 (required): Long value (Right column text. Wraps around if too long) # $3 (optional): Number of 2 character tabs to indent the command (default 1) # OPTS: # -b Bold the left column # -u Underline the left column # -r Reverse background and foreground colors # OUTS: # stdout: Prints the output in columns # NOTE: # Long text or ANSI colors in the first column may create display issues # USAGE: # _columns_ \"Key\" \"Long value text\" [tab level] [[ $# -lt 2 ]] && fatal \"Missing required argument to ${FUNCNAME[0]}\" local opt local OPTIND=1 local _style=\"\" while getopts \":bBuUrR\" opt; do case ${opt} in b | B) _style=\"${_style}${bold}\" ;; u | U) _style=\"${_style}${underline}\" ;; r | R) _style=\"${_style}${reverse}\" ;; *) fatal \"Unrecognized option '${1}' passed to ${FUNCNAME[0]}. Exiting.\" ;; esac done shift $((OPTIND - 1)) local _key=\"${1}\" local _value=\"${2}\" local _tabLevel=\"${3-}\" local _tabSize=2 local _line local _rightIndent local _leftIndent if [[ -z ${3-} ]]; then _tabLevel=0 fi _leftIndent=\"$((_tabLevel * _tabSize))\" local _leftColumnWidth=\"$((30 + _leftIndent))\" if [ \"$(tput cols)\" -gt 180 ]; then _rightIndent=110 elif [ \"$(tput cols)\" -gt 160 ]; then _rightIndent=90 elif [ \"$(tput cols)\" -gt 130 ]; then _rightIndent=60 elif [ \"$(tput cols)\" -gt 120 ]; then _rightIndent=50 elif [ \"$(tput cols)\" -gt 110 ]; then _rightIndent=40 elif [ \"$(tput cols)\" -gt 100 ]; then _rightIndent=30 elif [ \"$(tput cols)\" -gt 90 ]; then _rightIndent=20 elif [ \"$(tput cols)\" -gt 80 ]; then _rightIndent=10 else _rightIndent=0 fi local _rightWrapLength=$(($(tput cols) - _leftColumnWidth - _leftIndent - _rightIndent)) local _first_line=0 while read -r _line; do if [[ ${_first_line} -eq 0 ]]; then _first_line=1 else _key=\" \" fi printf \"%-${_leftIndent}s${_style}%-${_leftColumnWidth}b${reset} %b\\n\" \"\" \"${_key}${reset}\" \"${_line}\" done <<<\"$(fold -w${_rightWrapLength} -s <<<\"${_value}\")\" } _usage_() { cat <<USAGE_TEXT ${bold}$(basename \"$0\") [OPTION]... [FILE]...${reset} This is a script template. Edit this description to print help to users. ${bold}${underline}Options:${reset} $(_columns_ -b -- '-h, --help' \"Display this help and exit\" 2) $(_columns_ -b -- \"--loglevel [LEVEL]\" \"One of: FATAL, ERROR (default), WARN, INFO, NOTICE, DEBUG, ALL, OFF\" 2) $(_columns_ -b -- \"--logfile [FILE]\" \"Full PATH to logfile. (Default is '\\${HOME}/logs/$(basename \"$0\").log')\" 2) $(_columns_ -b -- \"-n, --dryrun\" \"Non-destructive. Makes no permanent changes.\" 2) $(_columns_ -b -- \"-q, --quiet\" \"Quiet (no output)\" 2) $(_columns_ -b -- \"-v, --verbose\" \"Output more information. (Items echoed to 'verbose')\" 2) $(_columns_ -b -- \"--force\" \"Skip all user interaction. Implied 'Yes' to all actions.\" 2) ${bold}${underline}Example Usage:${reset} ${gray}# Run the script and specify log level and log file.${reset} $(basename \"$0\") -vn --logfile \"/path/to/file.log\" --loglevel 'WARN' USAGE_TEXT } # ################################## INITIALIZE AND RUN THE SCRIPT # (Comment or uncomment the lines below to customize script behavior) trap '_trapCleanup_ ${LINENO} ${BASH_LINENO} \"${BASH_COMMAND}\" \"${FUNCNAME[*]}\" \"${0}\" \"${BASH_SOURCE[0]}\"' EXIT INT TERM SIGINT SIGQUIT SIGTERM # Trap errors in subshells and functions set -o errtrace # Exit on error. Append '||true' if you expect an error set -o errexit # Use last non-zero exit code in a pipeline set -o pipefail # Confirm we have BASH greater than v4 [ \"${BASH_VERSINFO:-0}\" -ge 4 ] || { printf \"%s\\n\" \"ERROR: BASH_VERSINFO is '${BASH_VERSINFO:-0}'. This script requires BASH v4 or greater.\" exit 1 } # Make `for f in *.txt` work when `*.txt` matches zero files shopt -s nullglob globstar # Set IFS to preferred implementation IFS=$' \\n\\t' # Run in debug mode # set -o xtrace # Initialize color constants _setColors_ # Disallow expansion of unset variables set -o nounset # Force arguments when invoking the script # [[ $# -eq 0 ]] && _parseOptions_ \"-h\" # Parse arguments passed to script _parseOptions_ \"$@\" # Create a temp directory '$TMP_DIR' # _makeTempDir_ \"$(basename \"$0\")\" # Acquire script lock # _acquireScriptLock_ # Add Homebrew bin directory to PATH (MacOS) # _homebrewPath_ # Source GNU utilities from Homebrew (MacOS) # _useGNUutils_ # Run the main logic script _mainScript_ # Exit cleanly _safeExit_"
        },
        {
            "filename": "file_570.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_570.sh",
            "content": "#!/bin/bash ################################################## # Purpose: eval command Evaluating twice # Version:1.0 # Created Date: Wed Jun 13 22:09:59 IST 2018 # Modified Date: # WebSite: https://arkit.co.in # Author: Ankam Ravi Kumar ################################################## # START # echo \"addition of X+Y\" echo \"Enter X\" read X echo \"Enter Y\" read Y echo \"X+Y = $X+$Y = $[ X+Y ]\" # END #"
        },
        {
            "filename": "file_571.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_571.sh",
            "content": "#!/bin/bash #Purpose: eval command Evaluating twice #Version:1.0 #Created Date: Wed Jun 13 22:09:59 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo -e \"enter the a value: \\c\" read a echo -e \"enter the b value: \\c\" read b if test \"$a\" -gt \"$b\" ; then echo \"$a is greater than $b\" else echo \"$b is greater than $a\" fi # END #"
        },
        {
            "filename": "file_572.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_572.sh",
            "content": "#!/usr/bin/expect set timeout -1 spawn ./questions.sh expect \"Hi\\r\" send -- \"Hi\\r\" expect \"How are you?\\r\" send -- \"I am fine\\r\" expect \"Whats your Name?\\r\" send -- \"My name is Ravi\\r\" expect eof"
        },
        {
            "filename": "file_573.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_573.sh",
            "content": "#!/bin/bash #Purpose:Arthmetic operators using expr command #Version:1.0 #Created Date: Wed May 9 21:47:04 IST 2018 #Modified Date: #website: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo -e \"Enter value: \\c\" read -r a echo -e \"Enter value: \\c\" read -r b echo \"addition values `expr $a + $b`\" echo \"minus values `expr $a - $b`\" echo \"multiplied by values `expr $a \\* $b`\" echo \"devided by values `expr $a / $b`\" echo \"remainder values `expr $a % $b`\" echo \"addition values `expr $a + $b`\" echo \"Completed Sucessfully\" # END #"
        },
        {
            "filename": "file_574.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_574.sh",
            "content": "#!/bin/bash #Purpose: Array Example #Version:1.0 #Created Date: Mon May 28 22:59:22 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # fruits=( \"Apple\" \"Orange\" \"Banana\" \"Sapota\" ) fruits[3]='Green Apple' for fruit in ${fruits[@]} do echo \"Fruit Name is $fruit\" done echo \"Number of Fruits in Bucket is\" ${#fruits[@]} echo \"All Fruits ${fruits[@]}\" # END #"
        },
        {
            "filename": "file_575.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_575.sh",
            "content": "#!/bin/bash #Purpose: Arthemetic Operators #Version:1.0 #Created Date: Wed May 9 21:41:53 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # echo -e \"Please enter some value: \\c\" read -r a echo -e \"Please enter another value: \\c\" read -r b echo \"a+b value is $(($a+$b))\" #it will add both the values echo \"a-b value is $(($a-$b))\" #it will subtract b form a echo \"axb value is $(($a*$b))\" #it will multiply both a and b echo \"a/b value is $(($a/$b))\" #it will divide b from a echo \"a%b value is $(($a%$b))\" #it will give the remainder when a is divided by b echo \"Completed successfully\" # END #"
        },
        {
            "filename": "file_576.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_576.sh",
            "content": "#!/usr/bin/expect -f ## Testing expect command ## echo the test puts \"\\nGet HostName\\n\" ## execute ssh command to connect to remote host spawn ssh 192.168.175.130 \"hostname\" ## Look for password string expect \"password:\" ## Send the password send \"redhat\\r\" puts \"\\nGet df command output\\n\" spawn ssh 192.168.175.130 \"df -h\" expect \"password:\" send \"redhat\\r\" interact"
        },
        {
            "filename": "file_577.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_577.sh",
            "content": "#!/bin/bash #Purpose: Example for Case Statement #Version:1.0 #WebSite: https://arkit.co.in #Created Date: Mon May 21 20:37:59 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # echo -e \"Enter a number: \\c\" read -r a echo -e \"Enter b number: \\c\" read -r b echo \"1. Sum of values\" echo \"2. Substraction\" echo \"3. Multiplication\" echo \"4. Division\" echo \"5. Modulo division\" echo -e \"Enter Your Choice from above menu: \\c\" read -r ch case $ch in 1) echo \"Sum of $a + $b = \"`expr $a + $b`;; 2) echo \"Subsctraction = \"`expr $a - $b`;; 3) echo \"Multiplication = \"`expr $a \\* $b`;; 4) echo \"Division = \"`expr $a / $b`;; 5) echo \"Modulo Division = \"`expr $a % $b`;; *) echo \"Invalid Option provided\" esac # END #"
        },
        {
            "filename": "file_578.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_578.sh",
            "content": "#!/bin/bash ## Collect Root Commands History # Mailing List MAILLIST=\"YOUREMAIL@DOMAIN\" # Log path AUDLOG=\"/rootcommands\" cp /root/.bash_history /tmp/history sed -i 's/#//g' /tmp/history for i in `cat /tmp/history |grep ^[0-9]` do CONVT=`date -d @$i` sed -i \"s/$i/$CONVT/g\" /tmp/history done sed -i 'N;s/\\n/ /' /tmp/history sleep 10 /bin/touch ${AUDLOG}$HOSTNAME-root-hist.log.`date +%h%d%y` /bin/grep \"$DATE\" /tmp/history > ${AUDLOG}$HOSTNAME-root-hist.log.`date +%h%d%y` /bin/chmod 0440 ${AUDLOG}$HOSTNAME-root-hist.log.`date +%h%d%y` # Mail notification /bin/cat ${AUDLOG}$HOSTNAME-root-hist.log.`date +%h%d%y` |mail -s \"HOST: $HOSTNAME - `whoami` Daily root Commands Log\" ${MAILLIST}"
        },
        {
            "filename": "file_579.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_579.sh",
            "content": "#!/bin/bash #Purpose: While loop Continue Statement #Version:1.0 #Website: https://arkit.co.in #Created Date: Tue May 22 22:03:02 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # opt=y while [ $opt = y -o $opt = Y ] do echo -e \"Please enter the number: \\c\" read -r num if [ $num -le 50 ]; then sq=`expr $num \\* $num` echo \"Square of provided number $num: $sq\" else echo \"Number not in the given Range\" fi echo -e \"Do you want to continue [y/n]: \\c\" read -r wish if [ $wish = y -o $wish = Y ]; then continue else echo \"Thank You for Exiting..\" exit fi done # END #"
        },
        {
            "filename": "file_580.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_580.sh",
            "content": "#!/bin/bash n=1 until [ $n -gt 11196 ] do EXIRECORDS=$(mysql -u root -pPASSWORD -h 192.168.2.100 -e \"SELECT sn,tarsize from DATABASE.Table1 where sn='\"$n\"'\" |tail -n1 |grep $n) RECORDNUMBER=$(echo $EXIRECORDS |awk '{print $1}') FOLDERSIZE=$(echo $EXIRECORDS |awk '{print $2}') KB=$(echo $EXIRECORDS |awk '{print $2}' |grep K |wc -l) if [ $KB -ge 1 ]; then K=$(echo $EXIRECORDS |awk '{print $2}' |sed 's/K//g') BYTES=$($K * 1024 |bc |awk -F. '{print $1}') mysql -u root -pPASSWORD -h 192.168.2.100 -e \"UPDATE DATABASE.Table1 SET tarsize='\"$BYTES\"' where sn='\"$RECORDNUMBER\"'\" fi MB=$(echo $EXIRECORDS |awk '{print $2}' |grep M |wc -l) if [ $MB -ge 1 ]; then M=$(echo $EXIRECORDS |awk '{print $2}' |sed 's/M//g') BYTES=$(echo $M*1024*1024 |bc |awk -F. '{print $1}') mysql -u root -pPASSWORD -h 192.168.2.100 -e \"UPDATE DATABASE.Table1 SET tarsize='\"$BYTES\"' where sn='\"$RECORDNUMBER\"'\" fi GB=$(echo $EXIRECORDS |awk '{print $2}' |grep G |wc -l) if [ $GB -ge 1 ]; then G=$(echo $EXIRECORDS |awk '{print $2}' |sed 's/G//g') BYTES=$(echo $G*1024*1024*1024 |bc |awk -F. '{print $1}') mysql -u root -pPASSWORD -h 192.168.2.100 -e \"UPDATE DATABASE.Table1 SET tarsize='\"$BYTES\"' where sn='\"$RECORDNUMBER\"'\" fi TB=$(echo $EXIRECORDS |awk '{print $2}' |grep T |wc -l) if [ $TB -ge 1 ]; then T=$(echo $EXIRECORDS |awk '{print $2}' |sed 's/T//g') BYTES=$(echo $T*1024*1024*1024*1024 |bc |awk -F. '{print $1}') mysql -u root -pPASSWORD -h 192.168.2.100 -e \"UPDATE DATABASE.Table1 SET tarsize='\"$BYTES\"' where sn='\"$RECORDNUMBER\"'\" fi n=`expr \"$n\" + 1` done"
        },
        {
            "filename": "file_581.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_581.sh",
            "content": "#!/bin/bash ################################################## # Purpose: Counting given postional parameters. # Version:1.0 # Created Date: Mon May 7 21:55:05 IST 2018 # Modified Date: # Author: Ankam Ravi Kumar ################################################## # START # echo \"Your current given parameters are $#\" if [ $# -lt 1 ];then echo \"Program Usage is './scriptname.sh' options\" else echo \"Program executed successfully\" fi # END #"
        },
        {
            "filename": "file_582.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_582.sh",
            "content": "#!/bin/bash #Purpose: Real time CPU utilization Monitoring #Version:1.0 #Created Date: Tue Jun 5 21:33:38 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # PATHS=\"/\" HOSTNAME=$(hostname) CRITICAL=98 WARNING=90 CRITICALMail=\"YOUREMAILaddresS@Domain.com\" MAILWAR=\"YOUREMAIL@Domain.in\" mkdir -p /var/log/cputilhist LOGFILE=/var/log/cputilhist/cpusage-`date +%h%d%y`.log touch $LOGFILE for path in $PATHS do CPULOAD=`top -b -n 2 -d1 | grep \"Cpu(s)\" | tail -n1 | awk '{print $2}' |awk -F. '{print $1}'` if [ -n $WARNING -a -n $CRITICAL ]; then if [ \"$CPULOAD\" -ge \"$WARNING\" -a \"$CPULOAD\" -lt \"$CRITICAL\" ]; then echo \"`date \"+%F %H:%M:%S\"` WARNING - $CPULOAD on Host $HOSTNAME\" >> $LOGFILE echo \"Warning Cpuload $CPULOAD Host is $HOSTNAME\" | mail -s \"CPULOAD is Warning\" $MAILWAR exit 1 elif [ \"$CPULOAD\" -ge \"$CRITICAL\" ]; then echo \"`date \"+%F %H:%M:%S\"` CRITICAL - $CPULOAD on Host $HOSTNAME\" >> $LOGFILE echo \"CRITICAL Cpuload $CPULOAD Host is $HOSTNAME\" | mail -s \"CPULOAD is CRITICAL\" $CRITICALMail exit 2 else echo \"`date \"+%F %H:%M:%S\"` OK - $CPULOAD on $HOSTNAME\" >> $LOGFILE exit 0 fi fi done # END #"
        },
        {
            "filename": "file_583.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_583.sh",
            "content": "#!/bin/bash ## Collect Multiple Servers CPU, MEM and DISK Utilization and store in single file # Purpose: To Collect Multiple Servers CPU, MEM, DISK usage in single report # Version:1.0 # Created Date: 2019-05-02 # Modified Date: # WebSite: https://arkit.co.in # Author: Ankam Ravi Kumar HOSTNAME=$(hostname) DATET=$(date \"+%Y-%m-%d %H:%M:%S\") CPUUSAGE=$(top -b -n 2 -d1 | grep \"Cpu(s)\" | tail -n1 | awk '{print $2}' |awk -F. '{print $1}') MEMUSAGE=$(free | grep Mem | awk '{print $3/$2 * 100.0}') DISKUSAGE=$(df -h / | awk '{print $5}' |tail -n 1 |sed 's/%//g') echo 'HostName, Date&Time, CPU(%), MEM(%), DISK(%)' >> /opt/usagereport echo \"$HOSTNAME, $DATET, $CPUUSAGE, $MEMUSAGE, $DISKUSAGE\" >> /opt/usagereport for i in `cat /scripts/hostlist` do RHOST=$(ssh $i hostname) RDATET=$(ssh $i 'date \"+%Y-%m-%d %H:%M:%S\"') RCPUUSAGE=$(ssh $i top -b -n 2 -d1 | grep \"Cpu(s)\" | tail -n1 | awk '{print $2}' |awk -F. '{print $1}') RMEMUSAGE=$(ssh $i free | grep Mem | awk '{print $3/$2 * 100.0}') RDISKUSAGE=$(ssh $i df -P / |column -t | awk '{print $5}' |tail -n 1 |sed 's/%//g') echo \"$RHOST, $RDATET, $RCPUUSAGE, $RMEMUSAGE, $RDISKUSAGE\" >> /opt/usagereport done"
        },
        {
            "filename": "file_584.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_584.sh",
            "content": "#!/bin/bash #Purpose: eval command Evaluating twice #Version:1.0 #Created Date: Wed Jun 13 22:09:59 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo \"WEL COME TO $USERNAME\" echo \"Your present working directory is `pwd`\" echo \"current logged in users are `who`\" echo \"Today date is `date`\" # END #"
        },
        {
            "filename": "file_585.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_585.sh",
            "content": "#!/bin/bash #Purpose: Monitoring Disk Space Utilization and Send Email Alert #Version:1.0 #Created Date: Wed Jun 6 22:38:01 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # THRESHOULD=40 mailto=\"root\" HOSTNAME=$(hostname) for path in `/bin/df -h | grep -vE 'Filesystem|tmpfs' | awk '{print $5}' |sed 's/%//g'` do if [ $path -ge $THRESHOULD ]; then df -h | grep $path% >> /tmp/temp fi done VALUE=`cat /tmp/temp | wc -l` if [ $VALUE -ge 1 ]; then mail -s \"$HOSTNAME Disk Usage is Critical\" $mailto < /tmp/temp fi #rm -rf /tmp/temp # END #"
        },
        {
            "filename": "file_586.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_586.sh",
            "content": "#!/bin/bash #Purpose: eval command Evaluating twice #Version:1.0 #Created Date: Wed Jun 13 22:09:59 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo \"current location files are `ls`\" echo \"current working directory is `pwd`\" # END #"
        },
        {
            "filename": "file_587.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_587.sh",
            "content": "#!/bin/bash #Purpose: eval command Evaluating twice #Version:1.0 #Created Date: Wed Jun 13 22:09:59 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # COMMAND=\"ls -ltr /etc\" echo \"$COMMAND\" eval $COMMAND # END #"
        },
        {
            "filename": "file_588.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_588.sh",
            "content": "#!/bin/bash ## To find given number is Even number or Odd Number read -p \"Enter a number: \" number if [ $((number % 2)) -eq 0 ]; then echo \"$number is an even number.\" else echo \"$number is an odd number.\" fi"
        },
        {
            "filename": "file_589.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_589.sh",
            "content": "#!/bin/bash #Purpose: Validate and report Student subject marks #Version:1.0 #Created Date: 2024 sep #Modified Date: #Author: Ankam Ravi Kumar # START # echo -e \"Please Enter Maths Marks: \\c\" read -r m echo -e \"Please Enter Physics Marks: \\c\" read -r p echo -e \"Please Enter Chemistry Marks: \\c\" read -r c if [ $m -ge 35 -a $p -ge 35 -a $c -ge 35 ]; then total=`expr $m + $p + $c` avg=`expr $total / 3` echo \"Total Marks = $total\" echo \"Average Marks = $avg\" if [ $avg -ge 75 ]; then echo \"Congrats you got Distinction\" elif [ $avg -ge 60 -a $avg -lt 75 ]; then echo \"Congrats you got First Class\" elif [ $avg -ge 50 -a $avg -lt 60 ]; then echo \"You got second class\" elif [ $avg -ge 35 -a $avg -lt 50 ]; then echo \"You Got Third Class\" fi else echo \"Sorry You Failed\" fi # END #"
        },
        {
            "filename": "file_590.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_590.sh",
            "content": "#!/bin/bash #Purpose: For loop example #Version:1.0 #website: https://arkit.co.in #Created Date: Wed May 16 19:26:02 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # for server in `cat /scripts/servers` do ping -c 1 $server > /tmp/ping valid=`echo $?` if [ $valid -eq 0 ]; then echo \"$server is up\" else echo \"$server is Down\" fi done # END #"
        },
        {
            "filename": "file_591.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_591.sh",
            "content": "#!/bin/bash #Purpose: One more example for for loop #Version: #Created Date: Wed May 16 19:31:50 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # for i in 1 2 3 4 5 do echo $i done # END #"
        },
        {
            "filename": "file_592.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_592.sh",
            "content": "#!/bin/bash #Purpose: Function example. Taking Backup of Particular File #Version:1.0 #Created Date: 2024 Sep 21 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # function takebackup (){ if [ -f $1 ]; then BACKUP=\"/home/aravi/$(basename ${1}).$(date +%F).$$\" echo \"Backing up $1 to ${BACKUP}\" cp $1 $BACKUP fi } takebackup /etc/hosts if [ $? -eq 0 ]; then echo \"BAckup Success\" fi function testing (){ echo \"Just TEsting Function\" } testing # END #"
        },
        {
            "filename": "file_593.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_593.sh",
            "content": "#!/bin/bash #Purpose: Example for Functions #Version:1.0 #Created Date: Sat May 26 00:17:19 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # function takebackup (){ if [ -f $1 ]; then BACKUP=\"/tmp/$(basename ${1}).$(date +%F).$$\" echo \"Backing up $1 to ${BACKUP}\" cp $1 $BACKUP fi } takebackup /etc/hosts if [ $? -eq 0 ]; then echo \"Backup Success\" fi # END #"
        },
        {
            "filename": "file_594.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_594.sh",
            "content": "#!/bin/bash ## Purpose: To Generate Nagios Configuration files within minute of time. ## Author: Ankam Ravi Kumar mkdir -p /scripts/WinServers cat /scripts/serverlist.txt | while read LINE do HostIP=`echo $LINE | cut -d, -f1` HostName=`echo $LINE | cut -d, -f2` NSCLIENTSTATE=$(/usr/local/nagios/libexec/check_nt -H $HostIP -p 12489 -v CLIENTVERSION -s Password | echo $?) if [ $NSCLIENTSTATE -eq 0 ]; then sed -e \"s/XXXX/$HostName/g; s/ZZZZ/$HostIP/g\" /scripts/Template-Windows.cfg > /scripts/WinServers/$HostName.cfg for i in D E F G H I J K L M N O P Q R S T U V W X Y Z; do /usr/local/nagios/libexec/check_nt -H $HostIP -p 12489 -v USEDDISKSPACE -s Password -l $i -w 90 -c 95 COMMANDSTATUS=$(echo $?) if [ $COMMANDSTATUS -eq 0 ] || [ $COMMANDSTATUS -eq 2 ];then sed -e \"s/XXXX/$HostName/g; s/ZZZZ/$i/g\" /scripts/Drives.cfg >> /scripts/WinServers/$HostName.cfg fi done fi done"
        },
        {
            "filename": "file_595.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_595.sh",
            "content": "#!/bin/bash #Purpose: Getopts Examples working with arguments #Version:1.0 #Created Date: Wed May 30 22:30:51 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # while getopts :a:b: options; do case $options in a) ap=$OPTARG;; b) bo=$OPTARG;; ?) echo \"I Dont know What is $OPTARG is\" esac done echo \"Option A = $ap and Option B = $bo\" # END #"
        },
        {
            "filename": "file_596.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_596.sh",
            "content": "#!/bin/bash #Purpose: This is the Sample template File #Version: 1.0 #Created Date: Thu May 3 11:55:43 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # echo \"Testing template file\" # END #"
        },
        {
            "filename": "file_597.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_597.sh",
            "content": "#!/bin/bash #Purpose: Here Document Example #Version:1.0 #Created Date: Tue Jun 12 22:50:23 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # ftp -n <<- EOF 2> /dev/null open ftp.server.com user ftp ftp ascii cd uploadfolder mput file1 file1 file2 bye EOF"
        },
        {
            "filename": "file_598.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_598.sh",
            "content": "#!/bin/bash #Purpose: eval command Evaluating twice #Version:1.0 #Created Date: Wed Jun 13 22:09:59 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # tmp=`date | cut -c12-13` if [ $tmp -lt 11 ] ; then echo \"Good Mornind have a nice day $USERNAME\" elif [ $tmp -gt 11 -a $tmp -lt 16 ] ; then echo \"Good Ofter noon $USERNAME\" elif [ $tmp -gt 15 -a $tmp -lt 19 ] ; then echo \"Good Evening $USERNAME\" else echo \"Good Night Sweet dreams $USERNAME\" fi echo \"Now the time is `date |cut -c12-19`\" # END #"
        },
        {
            "filename": "file_599.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_599.sh",
            "content": "#!/bin/bash #Purpose: Find biggest Number among 4 digits #Version:1.0 #Created Date: Wed May 16 18:45:58 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # echo -e \"Please Enter a Value: \\c\" read -r a echo -e \"Please Enter b Value: \\c\" read -r b echo -e \"Please Enter c Value: \\c\" read -r c echo -e \"Please Enter d Value: \\c\" read -r d if [ $a -gt $b -a $a -gt $c -a $a -gt $d ]; then echo \"$a a is big\" elif [ $b -gt $c -a $b -gt $d ]; then echo \"$b b is big\" elif [ $c -gt $d ]; then echo \"$c c is big\" else echo \"$d d is big\" fi # END #"
        },
        {
            "filename": "file_600.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_600.sh",
            "content": "#!/bin/bash #Purpose: If else statement example #Version:1.0 #Created Date: Sat May 12 23:49:15 IST 2018 #Modified Date: #Website: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo -e \"Enter any value: \\c\" read -r a echo -e \"Enter any value: \\c\" read -r b if [ $a -gt $b ]; then echo \"$a is greater than $b\" else echo \"$b is greater than $a\" fi # END #"
        },
        {
            "filename": "file_601.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_601.sh",
            "content": "#!/bin/bash #Purpose: If statement example #Version:1.0 #Created Date: Sat May 12 23:41:50 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # echo -e \"Please provide Value below ten: \\c\" read -r value if [ $value -le 10 ] then echo \"You provided value is $value\" touch /tmp/test{1..100}.txt echo \"Script completed successfully\" fi # END #"
        },
        {
            "filename": "file_602.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_602.sh",
            "content": "#!/bin/bash #Purpose: Internal Field Seperator #Version:1.0 #Created Date: Wed Jun 13 21:58:18 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # LINE=`cat /etc/passwd |grep $1` IFS=: set $LINE echo \"User Name = $1\" echo \"Password = $2\" echo \"UID = $3\" echo \"GID = $4\" echo \"Description = $5\" echo \"Home Directory = $6 \" echo \" Current Shell = $7\" # END #"
        },
        {
            "filename": "file_603.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_603.sh",
            "content": "#!/bin/bash #Purpose: eval command Evaluating twice #Version:1.0 #Created Date: Wed Jun 13 22:09:59 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo \"Hi you there\" echo \"what is your name? (Type your name here and press Enter)\" read NM echo \"Hi $NM Good Morning\" echo \"your currently logged in as $USERNAME\" echo \"your present working directory is `pwd`\" # END #"
        },
        {
            "filename": "file_604.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_604.sh",
            "content": "#!/bin/bash #Purpose: Logical Operators/Boolean Operators. Student Marks Validation. #Version:1.0 #Created Date: Sat May 12 21:21:03 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # echo -e \"Enter Your Maths Subject Marks: \\c\" read -r m echo -e \"Enter Your Physics Subject Marks: \\c\" read -r p echo -e \"Enter Your Chemistry Subject Marks: \\c\" read -r c if test $m -ge 35 -a $p -ge 35 -a $c -ge 35 then echo \"Congratulations, You have passed in all subjects\" else echo \"Sorry You not upto mark in one of the subject\" fi # END #"
        },
        {
            "filename": "file_605.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_605.sh",
            "content": "#!/bin/bash ## Monitoring Memory usage of the server # Version:1.0 # Created Date: 2022-Jan-07 # WebSite: https://arkit.co.in # Author: Ankam Ravi Kumar HOSTNAME=$(hostname) DATED=$(date \"+%Y-%m-%d %H:%M:%S\") THRESHOLD=80 TOADDRESS=aravikumar48@gmail.com MEMUSAGE=$(free | grep Mem | awk '{print $3/$2 * 100.0}' |awk -F. '{print $1}') if [ $MEMUSAGE -ge $THRESHOLD ]; then echo \"$HOSTNAME, $DATED, %MEMUSAGE\" >> /var/log/memusage_history echo \"$HOSTNAME, $DATED, %MEMUSAGE\" > /tmp/memusage mail -s \"$HOSTNAME $DATED Mem Usage: $MEMUSAGE\" $TOADDRESS <<< /tmp/memusage fi"
        },
        {
            "filename": "file_606.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_606.sh",
            "content": "#!/bin/bash ## Delete the Directories older than 2 days based on directory name validation ## Refer YouTube Link for Explanation https://youtu.be/1Sh6PWcgXAA ls -ltr /fullbackup/archive/ | awk '{print $9}' > /scripts/dirs for i in `cat /scripts/dirs`; do STARTTIME=$(date +%s -d\"$i 00:00:00\") ENDTIME=$(date +%s) echo $((ENDTIME-STARTTIME)) | awk '{print int($1/60)}' > /scripts/value COUNT=`cat /scripts/value` if [ $COUNT -gt 2880 ]; then echo \"Directories are older than 2days $i\" >> /scripts/joblog rm -rf /fullbackup/archive/$i fi done"
        },
        {
            "filename": "file_607.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_607.sh",
            "content": "#!/bin/bash #Purpose: eval command Evaluating twice #Version:1.0 #Created Date: Wed Jun 13 22:09:59 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo \"multification of X*Y\" echo \"Enter X\" read X echo \"Enter Y\" read Y echo \"X*Y = $X*$Y = $[ X*Y ]\" # END #"
        },
        {
            "filename": "file_608.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_608.sh",
            "content": "#!/bin/bash #Purpose: This is my first script in this shell scripting video tutorial #Date: Wed May 2 17:10:13 IST 2018 #Author: Ankam Ravi Kumar #Version: 1.0 #Modified Date: #Modified by: # START echo \"Welcome $USERNAME\" echo \"Your present working directory is `pwd`\" echo \"Today date is `date`\" # END"
        },
        {
            "filename": "file_609.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_609.sh",
            "content": "#!/bin/bash #Purpose: Validate and report Student subject marks #Version:1.0 #Created Date: Wed May 16 19:00:52 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # echo -e \"Please Enter Maths Marks: \\c\" read -r m echo -e \"Please Enter Physics Marks: \\c\" read -r p echo -e \"Please Enter Chemistry Marks: \\c\" read -r c if [ $m -ge 35 -a $p -ge 35 -a $c -ge 35 ]; then total=`expr $m + $p + $c` avg=`expr $total / 3` echo \"Total Marks = $total\" echo \"Average Marks = $avg\" if [ $avg -ge 75 ]; then echo \"Congrats you got Distinction\" elif [ $avg -ge 60 -a $avg -lt 75 ]; then echo \"Congrats you got First Class\" elif [ $avg -ge 50 -a $avg -lt 60 ]; then echo \"You got second class\" elif [ $avg -ge 35 -a $avg -lt 50 ]; then echo \"You Got Third Class\" fi else echo \"Sorry You Failed\" fi # END #"
        },
        {
            "filename": "file_610.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_610.sh",
            "content": "#!/bin/bash #Purpose: OR operator example #Version:1.0 #Created Date: Sat May 12 21:26:51 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # echo -e \"Enter First Numeric Value: \\c\" read -r t echo -e \"Enter Second Numeric Value: \\c\" read -r b if [ $t -le 20 -o $b -ge 30 ]; then echo \"Statement is True\" else echo \"False Statement, Try Again.\" fi # END #"
        },
        {
            "filename": "file_611.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_611.sh",
            "content": "#!/bin/bash #Website: https://arkit.co.in if ! [[ $1 -lt 20 || $2 -ge 30 ]]; then echo \"Statement is True\" else echo \"Statment is False\" fi"
        },
        {
            "filename": "file_612.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_612.sh",
            "content": "#!/bin/bash ## Questions echo \"Hi\" read $REPLY echo \"How are you?\" read $REPLY echo \"Whats your Name?\" read $REPLY"
        },
        {
            "filename": "file_613.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_613.sh",
            "content": "#!/bin/bash #Purpose: Verifying Difference between quotation marks #Version: 1.0 #Created Date: Fri May 4 20:16:55 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # VAR1=123456 TEST=TechArkit # Double Quotes echo \"Execute double quotes $VAR1 $TEST\" # Single Quotes echo 'Excute Single Quotes $VAR1 $TEST' # Reverse Quotes echo \"This Hostname is: `cal`\" # END #"
        },
        {
            "filename": "file_614.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_614.sh",
            "content": "#!/bin/bash #Purpose: regex examples #Version: 1.0 #Create Date: Sun Nov 27 00:27:33 EST 2022 #Modified Date: # START # numString1=\"1234\" numString2=\"16789\" numString3=\"1579\" echo \"Example 1\" if [[ $numString1 =~ ^1 ]]; then echo \"String \\\"$numString1\\\" starts with a \\\"1\\\", and matches regex: ^1\" fi echo \"Example 2\" if [[ $numString2 =~ ^1 ]]; then echo \"String \\\"$numString2\\\" starts with a \\\"1\\\", and matches regex: ^1\" fi echo \"Example 3\" if [[ $numString3 =~ ^1.7 ]]; then echo \"String \\\"$numString2\\\" starts with a \\\"1\\\", followed by any character, and followed by a 7. \" echo \"This string matches the regex: ^1.7\" fi echo \"Example 4\" if [[ ! $numString1 =~ ^1.7 ]]; then echo \"String \\\"$numString1\\\" does not start with a \\\"1\\\", followed by any character, and followed by a 7. \" echo \"This string does not match the regex: ^1.7\" fi echo \"Example 5\" if [[ $numString2 =~ 9$ ]]; then echo \"String \\\"$numString2\\\" ends with a \\\"9\\\", and matches the regex: 9$\" fi"
        },
        {
            "filename": "file_615.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_615.sh",
            "content": "#!/bin/bash #Purpose: Relational Operators examples #Version:1.0 #Created Date: Thu May 10 22:43:16 IST 2018 #Modified Date: # Website: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo -e \"Please provide one number: \\c\" read -r h echo -e \"Please provide one number: \\c\" read -r g test $h -lt $g;echo \"$?\"; test $h -le $g;echo \"$?\"; test $h -gt $g;echo \"$?\"; test $h -ge $g;echo \"$?\"; test $h -eq $g;echo \"$?\"; test $h -ne $g;echo \"$?\"; # END #"
        },
        {
            "filename": "file_616.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_616.sh",
            "content": "#!/bin/bash ################################################## # # # Author: Ankam Ravi Kumar # # Website: server-computer.com # # Date: 23-02-2019 16:59:56 # # Purpose: Capture and Store System Load Average # # CPU Usage and Memory Usage # ################################################## # Log File Path LOGFILE=/var/log/systemload.log echo \"\" > /tmp/remotelog for i in `cat /opt/hostnames`; do cat /root/systemload.sh | ssh $i >> /tmp/remotelog done cat /tmp/remotelog |grep -vE \"^Last|^There\" >> $LOGFILE"
        },
        {
            "filename": "file_617.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_617.sh",
            "content": "#!/bin/bash mkdir -p /Inventory sudo chmod -R 777 /Inventory/ mkdir -p /tmp/asset touch /tmp/asset/hostname.txt if [ -f /tmp/asset/hostname.txt ];then echo \"File /tmp/asset/hostname.txt Exists\" else mkdir /tmp/asset touch /tmp/asset/hostname.txt fi touch /tmp/temptext TEMP=/tmp/temptext LOG=`ls /tmp/asset/hostname.txt` echo \"## Host Information\" > $LOG echo \"Host Name : `hostname` \" >> $LOG echo \"`sudo /sbin/ifconfig -a |grep \"inet\" | awk 'BEGIN { FS = \":\" } ; { print $2 }'`\" >> $TEMP echo \"IP Address : `egrep '^10' $TEMP |awk '{ print $1}'`\" >> $LOG echo \"IP Address: `hostname -I`\" >> $LOG echo \"ip a |grep inet |grep -v \"::\" |awk '{print $2}'\" >> $LOG echo \"iDrac Details: `racadm getniccfg |grep \"IP Address\" |grep -v \"::\"`\" >> $LOG echo \"Server Type: `servertype=$(lscpu | grep Hypervisor | wc -l); if [ $servertype -gt 0 ]; then echo \"VitualMachine\"; else echo \"Physical\"; fi`\" >> $LOG echo -en '\\n' >> $LOG ## Collecting Hardware Details ## echo \" \" >> $LOG echo \"## Hardware Information\" >> $LOG echo \" \" >> $LOG echo \"Serial Number : `sudo lshal |grep system.hardware.serial`\" >> $LOG echo \"Serial Number : `sudo /usr/sbin/dmidecode -s system-serial-number`\" >> $LOG echo \"Serial Number : `sudo cat /sys/class/dmi/id/product_serial`\" >> $LOG echo \"Model Number : `sudo lshal |grep system.hardware.product`\" >> $LOG echo \"Model Number : `sudo /usr/sbin/dmidecode |grep \"SKU Number\"`\" >> $LOG echo \"Model Number : `sudo cat /sys/class/dmi/id/product_name`\" >> $LOG echo \"Hardware Vendor : `sudo lshal |grep system.hardware.vendor`\" >> $LOG echo \"Hardware Vendor : `sudo cat /sys/class/dmi/id/chassis_vendor`\" >> $LOG echo \"Hardware Info : `sudo dmesg |grep DMI`\" >> $LOG ## Redhat Version ## echo \" \" >> $LOG echo \"## OS Version\" >> $LOG head -n1 /etc/issue >> $LOG cat /etc/redhat-release >> $LOG echo \"Kernel Version: `uname -r`\">> $LOG echo \"OS Version: `hostnamectl | egrep \"Operating System\" | cut -d ' ' -f5-`\" >> $LOG ## CPU Info ## echo \" \" >> $LOG echo \" \" >> $LOG echo \"## CPU Information\" >> $LOG grep \"model name\" /proc/cpuinfo |uniq >> $LOG COUNTT=$(cat /proc/cpuinfo |grep \"model name\" | wc -l) echo \"$COUNTT Cores\" >> $LOG ## RAM/MEMORY Info ## echo \" \" >> $LOG echo \" \" >> $LOG echo \"## Memory Information\" >> $LOG grep MemTotal /proc/meminfo >> $LOG y=`grep MemTotal /proc/meminfo |awk '{ print $2 }'` mb=\"$(( $y / 1024 ))\" gb=\"$(( $mb / 1024 ))\" echo \"RAM : $gb GB\" >> $LOG ## Swap Information ## echo \" \" >> $LOG echo \"## Swap Information\" >> $LOG y1=$(free -k |grep Swap |awk '{print $2}') mb1=\"$(( $y1 / 1024 ))\" gb1=\"$(( $mb1 / 1024 ))\" echo \"Swap Size: $gb1 GB\" >> $LOG ## Disk Information ## echo \" \" >> $LOG echo \"## Disk Information\" >> $LOG lsblk |grep -E 'part|disk' $LOG ## LVM Information ## echo \" \" >> $LOG echo \"## Physical Volumes\" >> $LOG pvs >> $LOG echo \" \" >> $LOG echo \"## Volume Groups\" >> $LOG vgs >> $LOG echo \" \" >> $LOG echo \"## Logical Volumes\" >> $LOG lvs >> $LOG echo \" \" >> $LOG ## Partition Information ## echo \"## DF Command Output\" >> $LOG echo \" \" >> $LOG df -Ph -x tmpfs -x devtmpfs| sed s/%//g | awk '{ if($5 > 0) print $0;}' >> $LOG echo \" \" >> $LOG echo \"## Port Information\" >> $LOG ss -alntup |column -t |grep -E 'tcp|udp' >> $LOG echo \" \" >> $LOG echo \"## Service Information\" >> $LOG systemctl list-units --type=service --state=running |grep -vE 'systemd|selinux' >> $LOG echo \" \" >> $LOG echo \"## Docker Containers\" >> $LOG sudo docker ps -a >> $LOG echo \" \" >> $LOG echo \"## DNS Server Details\" >> $LOG cat /etc/resolv.conf >> $LOG echo \"\" >> $LOG echo \"## Server Uptime\" >> $LOG uptime >> $LOG sudo cp /tmp/asset/`hostname`.txt /Inventory/`hostname`-`date \"+%Y-%m-%d\"`.txt"
        },
        {
            "filename": "file_618.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_618.sh",
            "content": "#!/bin/bash #Purpose: Set assigns its arguments to the positional parameters #Version:1.0 #website: https://arkit.co.in #Created Date: Tue May 22 23:10:17 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # set `date` echo \"Today is $1\" echo \"Month is $2\" echo \"Date is $3\" echo \"Time H:M:S $4\" echo \"TimeZone is $5\" echo \"Year is $6\" set -x # END #"
        },
        {
            "filename": "file_619.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_619.sh",
            "content": "#!/bin/bash #Purpose: Shifting positional parameters automatically #Version:1.0 #Website: https://arkit.co.in #Created Date: Tue May 22 22:55:50 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # set `date` echo \"Count $#\" echo \"$1 $2 $3 $4 $5\" shift 2 echo \"$1 $2 $3 $4 $5\" # END #"
        },
        {
            "filename": "file_620.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_620.sh",
            "content": "#!/bin/bash #Purpose: To learn special variables #Version:1.0 #Website: https://arkit.co.in #Created Date: Sun May 6 15:23:12 IST 2018 #Modified Date: #Author: Ankam Ravi Kumar # START # echo \"'$*' output is $*\" echo \"'$#' output is $#\" echo \"'$1 & $2' output $1 and $2\" echo \"'$@' output of $@\" echo \"'$?' output is $?\" echo \"'$$' output is $$\" sleep 400 & echo \"'$!' output is $!\" echo \"'$0' your current program name is $0\" # END #"
        },
        {
            "filename": "file_621.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_621.sh",
            "content": "#!/bin/bash ################################################## # # # Author: Ankam Ravi Kumar # # Website: server-computer.com # # Date: 23-02-2019 16:59:56 # # Purpose: Capture and Store System Load Average # # CPU Usage and Memory Usage # ################################################## # Log File Path LOGFILE=/var/log/systemload.log HOSTNAME=$(hostname) DATE=$(date \"+%d-%m-%Y %H:%M:%S\") SYSTEMLOAD=$(uptime | awk '{ print $8,$9,$10,$11,$12}') CPULOAD=$(top -b -n 2 -d1 | grep \"Cpu(s)\" | tail -n1 |awk '{print $2}') MEMORYUSAGE=$(free -m |grep Mem: |tail -n1 |awk '{print $2,$3}') echo \"$DATE $HOSTNAME LoadAverage: $SYSTEMLOAD CPU: $CPULOAD Memory: $MEMORYUSAGE\" >> $LOGFILE"
        },
        {
            "filename": "file_622.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_622.sh",
            "content": "#!/bin/bash #Purpose: eval command Evaluating twice #Version:1.0 #Created Date: Wed Jun 13 22:09:59 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo \"ecnter the user name $NM\" read NM echo \"`useradd -d /users/$NM $NM`\" # END #"
        },
        {
            "filename": "file_623.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_623.sh",
            "content": "#!/bin/bash #Purpose: eval command Evaluating twice #Version:1.0 #Created Date: Wed Jun 13 22:09:59 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo \"WEl COME TO $USER\" echo \" Your present Wroking Directory is `pwd`\" echo \"Present Processes are `ps -a`\" echo \"Now Time is `date`\" echo \"current logged in Details are `finger $USER`\" # END #"
        },
        {
            "filename": "file_624.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_624.sh",
            "content": "#!/bin/bash #Purpose: Until Loop Example for Host Ping #Version:1.0 #Created Date: Mon May 28 22:18:52 IST 2018 #Modified Date: #WebSite: https://arkit.co.in #Author: Ankam Ravi Kumar # START # echo -e \"Please Enter the IP Address to Ping: \\c\" read -r ip until ping -c 3 $ip do echo \"Host $ip is Still Down\" sleep 1 done echo \"Host $ip is Up Now\" # END #"
        },
        {
            "filename": "file_625.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_625.sh",
            "content": "#!/bin/bash # Script to add a user to Linux system if [ $(id -u) -eq 0 ]; then read -p \"Enter username : \" username read -s -p \"Enter password : \" password egrep \"^$username\" /etc/passwd >/dev/null if [ $? -eq 0 ]; then echo \"$username exists!\" exit 1 else pass=$(perl -e 'print crypt($ARGV[0], \"password\")' $password) useradd -m -p $pass $username [ $? -eq 0 ] && echo \"User has been added to system!\" || echo \"Failed to add a user!\" fi else echo \"Only root may add a user to the system\" exit 2 fi"
        },
        {
            "filename": "file_626.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_626.sh",
            "content": "#!/bin/bash ## Author: Ankam Ravi Kumar ## Date: 21st Sep 2024 ## Purpose: To Create a users in Linux check_command_success() { if [ $? -ne 0 ]; then echo \"Error: $1\" exit 1 fi } if [ $(id -u) -ne 0 ]; then echo \"Error: Only root may add a user to the system.\" exit 2 fi # Prompt for the username and password read -p \"Enter username: \" username read -s -p \"Enter password: \" password echo if id \"$username\" &>/dev/null; then echo \"Error: User '$username' already exists!\" exit 1 fi encrypted_password=$(perl -e 'print crypt($ARGV[0], \"password\")' \"$password\") check_command_success \"Failed to encrypt the password.\" useradd -m -p \"$encrypted_password\" \"$username\" check_command_success \"Failed to add the user.\" passwd -e \"$username\" check_command_success \"Failed to set password expiry.\" echo \"Success: User '$username' has been added to the system!\""
        },
        {
            "filename": "file_627.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_627.sh",
            "content": "#!/bin/bash ##Purpose: Check given user Exits Or Not ##Date: 27th Oct 2016 ##Author: Ankam Ravi Kumar ##WebSite: https://arkit.co.in ##Start echo -e \"Please Enter User name you want check: \\c\" read user grep $user /etc/passwd > /dev/null if [ $? -eq 0 ]; then grep $user /etc/passwd echo \"$user Exists in this Machine\" else echo \"$user does not exists\" fi ##END"
        },
        {
            "filename": "file_628.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_628.sh",
            "content": "#!/bin/bash #Purpose: What is variable.? How is help us in writing shell scripts #Version:1.0 #Created Date: Sat May 5 20:25:21 IST 2018 #Modified Date: #website: https://arkit.co.in #Author: Ankam Ravi Kumar # START # A=10 Ba=23 BA=45 HOSTNAME=$(hostname) DATE=`date` 1value=333 False@Var=False Hyphen_a=WrongValue echo \"Variable A Value: $A\" echo \"Variable Ba Vaule: $Ba\" echo \"Variable BA Vaule: $BA\" echo \"Variable HOST value: $HOSTNAME\" echo \"Variable DATE value: $DATE\" echo \"Wrong Variable 1value $1value\" echo 'False @ Variable' $False@Var echo \"hyphen-a Variable Value: $Hyphen_a\" # END #"
        },
        {
            "filename": "file_629.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_629.sh",
            "content": "#!/usr/bin/env bash ############################################################# # # # NOME: webserver_ubuntu.sh # # # # AUTOR: Amaury B. Souza (amaurybsouza@gmail.com) # # # # DESCRI\u00c7\u00c3O: O script faz a instala\u00e7\u00e3o da stack LAMP # # # # USO: ./webserver_ubuntu.sh # ############################################################# function menuprincipal () { clear echo \" \" echo LAMP Stack Ubuntu $0 echo \" \" echo \"Escolha uma op\u00e7\u00e3o abaixo para come\u00e7ar! 1 - Instalar Apache no sistema 2 - Instalar o banco de dados MariaDB no sistema 3 - Instalar o PHP7.2 no sistema 4 - Instalar a stack LAMP completa no sistema 0 - Sair do menu de instala\u00e7\u00e3o\" echo \" \" echo -n \"Op\u00e7\u00e3o escolhida: \" read opcao case $opcao in 1) function apache () { TIME=2 echo Atualizando seu sistema... sleep $TIME apt update && apt upgrade -y echo Iniciando a instala\u00e7\u00e3o do Apache no Ubuntu... sleep $TIME #sudo iptables -I INPUT -p tcp --dport 80 -j ACCEPT #sudo ufw allow http #sudo chown www-data:www-data /var/www/html/ -R apt install -y apache2 apache2-utils sudo systemctl start apache2 sudo systemctl enable apache2 echo \" \" if [ $? -eq 0 ] then echo O Apache foi instalado no seu sistema. else echo Ops, ocorreu algum erro, vamos tentar de novo! fi } apache read -n 1 -p \"<Enter> para menu principal\" menuprincipal ;; 2) function maria () { TIME=2 echo Iniciando a instala\u00e7\u00e3o do MariaDB... sleep $TIME sudo apt -y install mariadb-server mariadb-client sudo systemctl start mariadb sudo systemctl enable mariadb if [ $? -eq 0 ] then echo Agora vamos configurar o banco... sleep $TIME sudo mysql_secure_installation echo \" \" echo Opa, parab\u00e9ns, o banco foi instalado e configurado! sleep $TIME else echo Ops, vamos resolver isso? Acho que deu errado. fi } maria read -n 1 -p \"<Enter> para menu principal\" menuprincipal ;; 3) function php () { echo Iniciando a instala\u00e7\u00e3o do PHP... sudo apt install -y php7.2 libapache2-mod-php7.2 php7.2-mysql php-common php7.2-cli php7.2-common php7.2-json php7.2-opcache php7.2-readline sudo a2enmod php7.2 sudo systemctl restart apache2 echo \" \" echo O PHP 7.2 foi instalado, que legal! #Para testar o PHP instalado... #sudo vim /var/www/html/info.php <?php phpinfo(); ?> } php read -n 1 -p \"<Enter> para menu principal\" menuprincipal ;; 4) function lamp () { TIME=2 #apache echo Vamos iniciar a instala\u00e7\u00e3o da stack LAMP no seu sistema... sleep $TIME echo Instalando o Apache... sleep $TIME apt install -y apache2 apache2-utils sudo systemctl start apache2 sudo systemctl enable apache2 echo Instalando o banco de dados... sleep $TIME #banco de dados sudo apt -y install mariadb-server mariadb-client sudo systemctl start mariadb sudo systemctl enable mariadb #PHP echo Instalando o PHP... sleep $TIME sudo apt install -y php7.2 libapache2-mod-php7.2 php7.2-mysql php-common php7.2-cli php7.2-common php7.2-json php7.2-opcache php7.2-readline sudo a2enmod php7.2 sudo systemctl restart apache2 echo Instala\u00e7\u00e3o conclu\u00edda com \u00eaxito! sleep $TIME } lamp read -n 1 -p \"<Enter> para menu principal\" menuprincipal ;; 0) function sair () { TIME=2 echo \" \" echo Saindo do sistema... sleep $TIME exit 0 } sair ;; esac } menuprincipal"
        },
        {
            "filename": "file_630.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\file_630.sh",
            "content": "#!/bin/bash # While Loop Example with 2 table, print any given number table. # See Full Explanation of this above shell script [while loop](https://www.youtube.com/Techarkit?sub_confirmation=1) #START echo -e \"Please provide one value: \\c\" read -r c i=1 while [ $i -le 10 ] do b=`expr $c \\* $i` echo \"$c * $i = $b\" i=`expr $i + 1` done #END"
        },
        {
            "filename": "file_631.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripting-tutorial\\AWS\\file_631.sh",
            "content": "#!/bin/bash #Purpose: To Know S3 Bucket Size Shell Script #Version:1.0 #Created Date: 09-Jan-2019 #Modified Date: #WebSite: https://www.server-computer.com #Author: Ankam Ravi Kumar # START # echo -e \"Please Enter your Bucket Name: \\c\" read -r BUCKETNAME aws s3api list-objects --bucket $BUCKETNAME --output json --query \"[sum(Contents[].Size)]\" > $PWD/s3bucket sed -i 's/\\[//' $PWD/s3bucket sed -i 's/]//' $PWD/s3bucket sed -i 's/ //' $PWD/s3bucket cat $PWD/s3bucket |head -2 |tail -1 |awk '{print int($1/1024)\" KB\"}' cat $PWD/s3bucket |head -2 |tail -1 |awk '{print int($1/1024/1024)\" MB\"}' cat $PWD/s3bucket |head -2 |tail -1 |awk '{print int($1/1024/1024/1024)\" GB\"}' cat $PWD/s3bucket |head -2 |tail -1 |awk '{print int($1/1024/1024/1024/1024)\" TB\"}"
        },
        {
            "filename": "file_632.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripts\\kcptun\\file_632.sh",
            "content": "#!/bin/sh : <<-'EOF' Copyright 2017-2019 Xingwang Liao <kuoruan@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. EOF export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin # \u7248\u672c\u4fe1\u606f\uff0c\u8bf7\u52ff\u4fee\u6539 # ================= SHELL_VERSION=26 CONFIG_VERSION=7 INIT_VERSION=3 # ================= KCPTUN_INSTALL_DIR='/usr/local/kcptun' KCPTUN_LOG_DIR='/var/log/kcptun' KCPTUN_RELEASES_URL='https://api.github.com/repos/xtaci/kcptun/releases' KCPTUN_LATEST_RELEASE_URL=\"${KCPTUN_RELEASES_URL}/latest\" KCPTUN_TAGS_URL='https://github.com/xtaci/kcptun/tags' BASE_URL='https://github.com/kuoruan/shell-scripts/raw/master/kcptun' SHELL_VERSION_INFO_URL=\"${BASE_URL}/version.json\" JQ_DOWNLOAD_URL=\"https://github.com/stedolan/jq/releases/download/jq-1.5/\" JQ_LINUX32_URL=\"${JQ_DOWNLOAD_URL}/jq-linux32\" JQ_LINUX64_URL=\"${JQ_DOWNLOAD_URL}/jq-linux64\" JQ_LINUX32_HASH='ab440affb9e3f546cf0d794c0058543eeac920b0cd5dff660a2948b970beb632' JQ_LINUX64_HASH='c6b3a7d7d3e7b70c6f51b706a3b90bd01833846c54d32ca32f0027f00226ff6d' JQ_BIN=\"${KCPTUN_INSTALL_DIR}/bin/jq\" SUPERVISOR_SERVICE_FILE_DEBIAN_URL=\"${BASE_URL}/startup/supervisord.init.debain\" SUPERVISOR_SERVICE_FILE_REDHAT_URL=\"${BASE_URL}/startup/supervisord.init.redhat\" SUPERVISOR_SYSTEMD_FILE_URL=\"${BASE_URL}/startup/supervisord.systemd\" # \u9ed8\u8ba4\u53c2\u6570 # ======================= D_LISTEN_PORT=29900 D_TARGET_ADDR='127.0.0.1' D_TARGET_PORT=12984 D_KEY=\"very fast\" D_CRYPT='aes' D_MODE='fast' D_MTU=1350 D_SNDWND=512 D_RCVWND=512 D_DATASHARD=10 D_PARITYSHARD=3 D_DSCP=0 D_NOCOMP='true' D_QUIET='false' D_TCP='false' D_SNMPPERIOD=60 D_PPROF='false' # \u9690\u85cf\u53c2\u6570 D_ACKNODELAY='false' D_NODELAY=1 D_INTERVAL=20 D_RESEND=2 D_NC=1 # SMUX\u63d0\u9ad8\u523064M\u63d0\u9ad8SreamBuf\u6548\u679c D_SOCKBUF=67108868 D_SMUXBUF=67108868 D_KEEPALIVE=10 # KCP\u65b0\u7248\u652f\u6301\uff0cSMux\u9ed8\u8ba4\u4e3a2\uff0cBUF\u5927\u5c0f\u6539\u4e3a16M D_SMUXVER=2 D_STREAMBUF=16777217 # ====================== # \u5f53\u524d\u9009\u62e9\u7684\u5b9e\u4f8b ID current_instance_id=\"\" run_user='kcptun' clear cat >&1 <<-'EOF' ######################################################### # Kcptun \u670d\u52a1\u7aef\u4e00\u952e\u5b89\u88c5\u811a\u672c # # \u8be5\u811a\u672c\u652f\u6301 Kcptun \u670d\u52a1\u7aef\u7684\u5b89\u88c5\u3001\u66f4\u65b0\u3001\u5378\u8f7d\u53ca\u914d\u7f6e # # \u811a\u672c\u4f5c\u8005: Index <kuoruan@gmail.com> # # \u4f5c\u8005\u535a\u5ba2: https://blog.kuoruan.com/ # # Github: https://github.com/kuoruan/shell-scripts # # QQ\u4ea4\u6d41\u7fa4: 43391448, 68133628 # # 633945405 # ######################################################### EOF # \u6253\u5370\u5e2e\u52a9\u4fe1\u606f usage() { cat >&1 <<-EOF \u8bf7\u4f7f\u7528: $0 <option> \u53ef\u4f7f\u7528\u7684\u53c2\u6570 <option> \u5305\u62ec: install \u5b89\u88c5 uninstall \u5378\u8f7d update \u68c0\u67e5\u66f4\u65b0 manual \u81ea\u5b9a\u4e49 Kcptun \u7248\u672c\u5b89\u88c5 help \u67e5\u770b\u811a\u672c\u4f7f\u7528\u8bf4\u660e add \u6dfb\u52a0\u4e00\u4e2a\u5b9e\u4f8b, \u591a\u7aef\u53e3\u52a0\u901f reconfig <id> \u91cd\u65b0\u914d\u7f6e\u5b9e\u4f8b show <id> \u663e\u793a\u5b9e\u4f8b\u8be6\u7ec6\u914d\u7f6e log <id> \u663e\u793a\u5b9e\u4f8b\u65e5\u5fd7 del <id> \u5220\u9664\u4e00\u4e2a\u5b9e\u4f8b \u6ce8: \u4e0a\u8ff0\u53c2\u6570\u4e2d\u7684 <id> \u53ef\u9009, \u4ee3\u8868\u7684\u662f\u5b9e\u4f8b\u7684ID \u53ef\u4f7f\u7528 1, 2, 3 ... \u5206\u522b\u5bf9\u5e94\u5b9e\u4f8b kcptun, kcptun2, kcptun3 ... \u82e5\u4e0d\u6307\u5b9a <id>, \u5219\u9ed8\u8ba4\u4e3a 1 Supervisor \u547d\u4ee4: service supervisord {start|stop|restart|status} {\u542f\u52a8|\u5173\u95ed|\u91cd\u542f|\u67e5\u770b\u72b6\u6001} Kcptun \u76f8\u5173\u547d\u4ee4: supervisorctl {start|stop|restart|status} kcptun<id> {\u542f\u52a8|\u5173\u95ed|\u91cd\u542f|\u67e5\u770b\u72b6\u6001} EOF exit $1 } # \u5224\u65ad\u547d\u4ee4\u662f\u5426\u5b58\u5728 command_exists() { command -v \"$@\" >/dev/null 2>&1 } # \u5224\u65ad\u8f93\u5165\u5185\u5bb9\u662f\u5426\u4e3a\u6570\u5b57 is_number() { expr \"$1\" + 1 >/dev/null 2>&1 } # \u6309\u4efb\u610f\u952e\u7ee7\u7eed any_key_to_continue() { echo \"\u8bf7\u6309\u4efb\u610f\u952e\u7ee7\u7eed\u6216 Ctrl + C \u9000\u51fa\" local saved=\"\" saved=\"$(stty -g)\" stty -echo stty cbreak dd if=/dev/tty bs=1 count=1 2>/dev/null stty -raw stty echo stty $saved } first_character() { if [ -n \"$1\" ]; then echo \"$1\" | cut -c1 fi } # \u68c0\u67e5\u662f\u5426\u5177\u6709 root \u6743\u9650 check_root() { local user=\"\" user=\"$(id -un 2>/dev/null || true)\" if [ \"$user\" != \"root\" ]; then cat >&2 <<-'EOF' \u6743\u9650\u9519\u8bef, \u8bf7\u4f7f\u7528 root \u7528\u6237\u8fd0\u884c\u6b64\u811a\u672c! EOF exit 1 fi } # \u83b7\u53d6\u670d\u52a1\u5668\u7684IP\u5730\u5740 get_server_ip() { local server_ip=\"\" local interface_info=\"\" if command_exists ip; then interface_info=\"$(ip addr)\" elif command_exists ifconfig; then interface_info=\"$(ifconfig)\" fi server_ip=$(echo \"$interface_info\" | \\ grep -oE \"[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\" | \\ grep -vE \"^192\\.168|^172\\.1[6-9]\\.|^172\\.2[0-9]\\.|^172\\.3[0-2]\\.|^10\\.|^127\\.|^255\\.|^0\\.\" | \\ head -n 1) # \u81ea\u52a8\u83b7\u53d6\u5931\u8d25\u65f6\uff0c\u901a\u8fc7\u7f51\u7ad9\u63d0\u4f9b\u7684 API \u83b7\u53d6\u5916\u7f51\u5730\u5740 if [ -z \"$server_ip\" ]; then server_ip=\"$(wget -qO- --no-check-certificate https://ipv4.icanhazip.com)\" fi echo \"$server_ip\" } # \u7981\u7528 selinux disable_selinux() { local selinux_config='/etc/selinux/config' if [ -s \"$selinux_config\" ]; then if grep -q \"SELINUX=enforcing\" \"$selinux_config\"; then sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' \"$selinux_config\" setenforce 0 fi fi } # \u83b7\u53d6\u5f53\u524d\u64cd\u4f5c\u7cfb\u7edf\u4fe1\u606f get_os_info() { lsb_dist=\"\" dist_version=\"\" if command_exists lsb_release; then lsb_dist=\"$(lsb_release -si)\" fi if [ -z \"$lsb_dist\" ]; then [ -r /etc/lsb-release ] && lsb_dist=\"$(. /etc/lsb-release && echo \"$DISTRIB_ID\")\" [ -r /etc/debian_version ] && lsb_dist='debian' [ -r /etc/fedora-release ] && lsb_dist='fedora' [ -r /etc/oracle-release ] && lsb_dist='oracleserver' [ -r /etc/centos-release ] && lsb_dist='centos' [ -r /etc/redhat-release ] && lsb_dist='redhat' [ -r /etc/photon-release ] && lsb_dist='photon' [ -r /etc/os-release ] && lsb_dist=\"$(. /etc/os-release && echo \"$ID\")\" fi lsb_dist=\"$(echo \"$lsb_dist\" | tr '[:upper:]' '[:lower:]')\" if [ \"${lsb_dist}\" = \"redhatenterpriseserver\" ]; then lsb_dist='redhat' fi case \"$lsb_dist\" in ubuntu) if command_exists lsb_release; then dist_version=\"$(lsb_release --codename | cut -f2)\" fi if [ -z \"$dist_version\" ] && [ -r /etc/lsb-release ]; then dist_version=\"$(. /etc/lsb-release && echo \"$DISTRIB_CODENAME\")\" fi ;; debian|raspbian) dist_version=\"$(cat /etc/debian_version | sed 's/\\/.*//' | sed 's/\\..*//')\" case \"$dist_version\" in 9) dist_version=\"stretch\" ;; 8) dist_version=\"jessie\" ;; 7) dist_version=\"wheezy\" ;; esac ;; oracleserver) lsb_dist=\"oraclelinux\" dist_version=\"$(rpm -q --whatprovides redhat-release --queryformat \"%{VERSION}\\n\" | sed 's/\\/.*//' | sed 's/\\..*//' | sed 's/Server*//')\" ;; fedora|centos|redhat) dist_version=\"$(rpm -q --whatprovides ${lsb_dist}-release --queryformat \"%{VERSION}\\n\" | sed 's/\\/.*//' | sed 's/\\..*//' | sed 's/Server*//' | sort | tail -1)\" ;; \"vmware photon\") lsb_dist=\"photon\" dist_version=\"$(. /etc/os-release && echo \"$VERSION_ID\")\" ;; *) if command_exists lsb_release; then dist_version=\"$(lsb_release --codename | cut -f2)\" fi if [ -z \"$dist_version\" ] && [ -r /etc/os-release ]; then dist_version=\"$(. /etc/os-release && echo \"$VERSION_ID\")\" fi ;; esac if [ -z \"$lsb_dist\" ] || [ -z \"$dist_version\" ]; then cat >&2 <<-EOF \u65e0\u6cd5\u786e\u5b9a\u670d\u52a1\u5668\u7cfb\u7edf\u7248\u672c\u4fe1\u606f\u3002 \u8bf7\u8054\u7cfb\u811a\u672c\u4f5c\u8005\u3002 EOF exit 1 fi } # \u83b7\u53d6\u670d\u52a1\u5668\u67b6\u6784\u548c Kcptun \u670d\u52a1\u7aef\u6587\u4ef6\u540e\u7f00\u540d get_arch() { architecture=\"$(uname -m)\" case \"$architecture\" in amd64|x86_64) spruce_type='linux-amd64' file_suffix='linux_amd64' ;; i386|i486|i586|i686|x86) spruce_type='linux-386' file_suffix='linux_386' ;; *) cat 1>&2 <<-EOF \u5f53\u524d\u811a\u672c\u4ec5\u652f\u6301 32 \u4f4d \u548c 64 \u4f4d\u7cfb\u7edf \u4f60\u7684\u7cfb\u7edf\u4e3a: $architecture EOF exit 1 ;; esac } # \u83b7\u53d6 API \u5185\u5bb9 get_content() { local url=\"$1\" local retry=0 local content=\"\" get_network_content() { if [ $retry -ge 3 ]; then cat >&2 <<-EOF \u83b7\u53d6\u7f51\u7edc\u4fe1\u606f\u5931\u8d25! URL: ${url} \u5b89\u88c5\u811a\u672c\u9700\u8981\u80fd\u8bbf\u95ee\u5230 github.com\uff0c\u8bf7\u68c0\u67e5\u670d\u52a1\u5668\u7f51\u7edc\u3002 \u6ce8\u610f: \u4e00\u4e9b\u56fd\u5185\u670d\u52a1\u5668\u53ef\u80fd\u65e0\u6cd5\u6b63\u5e38\u8bbf\u95ee github.com\u3002 EOF exit 1 fi # \u5c06\u6240\u6709\u7684\u6362\u884c\u7b26\u66ff\u6362\u4e3a\u81ea\u5b9a\u4e49\u6807\u7b7e\uff0c\u9632\u6b62 jq \u89e3\u6790\u5931\u8d25 content=\"$(wget -qO- --no-check-certificate \"$url\" | sed -r 's/(\\\\r)?\\\\n/#br#/g')\" if [ \"$?\" != \"0\" ] || [ -z \"$content\" ]; then retry=$(expr $retry + 1) get_network_content fi } get_network_content echo \"$content\" } # \u4e0b\u8f7d\u6587\u4ef6\uff0c \u9ed8\u8ba4\u91cd\u8bd5 3 \u6b21 download_file() { local url=\"$1\" local file=\"$2\" local verify=\"$3\" local retry=0 local verify_cmd=\"\" verify_file() { if [ -z \"$verify_cmd\" ] && [ -n \"$verify\" ]; then if [ \"${#verify}\" = \"32\" ]; then verify_cmd=\"md5sum\" elif [ \"${#verify}\" = \"40\" ]; then verify_cmd=\"sha1sum\" elif [ \"${#verify}\" = \"64\" ]; then verify_cmd=\"sha256sum\" elif [ \"${#verify}\" = \"128\" ]; then verify_cmd=\"sha512sum\" fi if [ -n \"$verify_cmd\" ] && ! command_exists \"$verify_cmd\"; then verify_cmd=\"\" fi fi if [ -s \"$file\" ] && [ -n \"$verify_cmd\" ]; then ( set -x echo \"${verify} ${file}\" | $verify_cmd -c ) return $? fi return 1 } download_file_to_path() { if verify_file; then return 0 fi if [ $retry -ge 3 ]; then rm -f \"$file\" cat >&2 <<-EOF \u6587\u4ef6\u4e0b\u8f7d\u6216\u6821\u9a8c\u5931\u8d25! \u8bf7\u91cd\u8bd5\u3002 URL: ${url} EOF if [ -n \"$verify_cmd\" ]; then cat >&2 <<-EOF \u5982\u679c\u4e0b\u8f7d\u591a\u6b21\u5931\u8d25\uff0c\u4f60\u53ef\u4ee5\u624b\u52a8\u4e0b\u8f7d\u6587\u4ef6: 1. \u4e0b\u8f7d\u6587\u4ef6 ${url} 2. \u5c06\u6587\u4ef6\u91cd\u547d\u540d\u4e3a $(basename \"$file\") 3. \u4e0a\u4f20\u6587\u4ef6\u81f3\u76ee\u5f55 $(dirname \"$file\") 4. \u91cd\u65b0\u8fd0\u884c\u5b89\u88c5\u811a\u672c \u6ce8: \u6587\u4ef6\u76ee\u5f55 . \u8868\u793a\u5f53\u524d\u76ee\u5f55\uff0c.. \u8868\u793a\u5f53\u524d\u76ee\u5f55\u7684\u4e0a\u7ea7\u76ee\u5f55 EOF fi exit 1 fi ( set -x; wget -O \"$file\" --no-check-certificate \"$url\" ) if [ \"$?\" != \"0\" ] || [ -n \"$verify_cmd\" ] && ! verify_file; then retry=$(expr $retry + 1) download_file_to_path fi } download_file_to_path } # \u5b89\u88c5 jq \u7528\u4e8e\u89e3\u6790\u548c\u751f\u6210 json \u6587\u4ef6 # jq \u5df2\u8fdb\u5165\u5927\u90e8\u5206 Linux \u53d1\u884c\u7248\u7684\u8f6f\u4ef6\u4ed3\u5e93\uff0c # URL: https://stedolan.github.io/jq/download/ # \u4f46\u4e3a\u4e86\u9632\u6b62\u6709\u4e9b\u7cfb\u7edf\u5b89\u88c5\u5931\u8d25\uff0c\u8fd8\u662f\u901a\u8fc7\u811a\u672c\u6765\u63d0\u4f9b\u4e86\u3002 install_jq() { check_jq() { if [ ! -f \"$JQ_BIN\" ]; then return 1 fi [ ! -x \"$JQ_BIN\" ] && chmod a+x \"$JQ_BIN\" if ( $JQ_BIN --help 2>/dev/null | grep -q \"JSON\" ); then is_checked_jq=\"true\" return 0 else rm -f \"$JQ_BIN\" return 1 fi } if [ -z \"$is_checked_jq\" ] && ! check_jq; then local dir=\"\" dir=\"$(dirname \"$JQ_BIN\")\" if [ ! -d \"$dir\" ]; then ( set -x mkdir -p \"$dir\" ) fi if [ -z \"$architecture\" ]; then get_arch fi case \"$architecture\" in amd64|x86_64) download_file \"$JQ_LINUX64_URL\" \"$JQ_BIN\" \"$JQ_LINUX64_HASH\" ;; i386|i486|i586|i686|x86) download_file \"$JQ_LINUX32_URL\" \"$JQ_BIN\" \"$JQ_LINUX32_HASH\" ;; esac if ! check_jq; then cat >&2 <<-EOF \u672a\u627e\u5230\u9002\u7528\u4e8e\u5f53\u524d\u7cfb\u7edf\u7684 JSON \u89e3\u6790\u8f6f\u4ef6 jq EOF exit 1 fi return 0 fi } # \u8bfb\u53d6 json \u6587\u4ef6\u4e2d\u67d0\u4e00\u9879\u7684\u503c get_json_string() { install_jq local content=\"$1\" local selector=\"$2\" local regex=\"$3\" local str=\"\" if [ -n \"$content\" ]; then str=\"$(echo \"$content\" | $JQ_BIN -r \"$selector\" 2>/dev/null)\" if [ -n \"$str\" ] && [ -n \"$regex\" ]; then str=\"$(echo \"$str\" | grep -oE \"$regex\")\" fi fi echo \"$str\" } # \u83b7\u53d6\u5f53\u524d\u5b9e\u4f8b\u7684\u914d\u7f6e\u6587\u4ef6\u8def\u5f84\uff0c\u4f20\u5165\u53c2\u6570\uff1a # * config: kcptun \u670d\u52a1\u7aef\u914d\u7f6e\u6587\u4ef6 # * log: kcptun \u65e5\u5fd7\u6587\u4ef6\u8def\u5f84 # * snmp: kcptun snmp \u65e5\u5fd7\u6587\u4ef6\u8def\u5f84 # * supervisor: \u5b9e\u4f8b\u7684 supervisor \u6587\u4ef6\u8def\u5f84 get_current_file() { case \"$1\" in config) printf '%s/server-config%s.json' \"$KCPTUN_INSTALL_DIR\" \"$current_instance_id\" ;; log) printf '%s/server%s.log' \"$KCPTUN_LOG_DIR\" \"$current_instance_id\" ;; snmp) printf '%s/snmplog%s.log' \"$KCPTUN_LOG_DIR\" \"$current_instance_id\" ;; supervisor) printf '/etc/supervisor/conf.d/kcptun%s.conf' \"$current_instance_id\" ;; esac } # \u83b7\u53d6\u5b9e\u4f8b\u6570\u91cf get_instance_count() { if [ -d '/etc/supervisor/conf.d/' ]; then ls -l '/etc/supervisor/conf.d/' | grep \"^-\" | awk '{print $9}' | grep -cP \"^kcptun\\d*\\.conf$\" else echo \"0\" fi } # \u901a\u8fc7 API \u83b7\u53d6\u5bf9\u5e94\u7248\u672c\u53f7 Kcptun \u7684 release \u4fe1\u606f # \u4f20\u5165 Kcptun \u7248\u672c\u53f7 get_kcptun_version_info() { local request_version=\"$1\" local version_content=\"\" if [ -n \"$request_version\" ]; then local json_content=\"\" json_content=\"$(get_content \"$KCPTUN_RELEASES_URL\")\" local version_selector=\".[] | select(.tag_name == \\\"${request_version}\\\")\" version_content=\"$(get_json_string \"$json_content\" \"$version_selector\")\" else version_content=\"$(get_content \"$KCPTUN_LATEST_RELEASE_URL\")\" fi if [ -z \"$version_content\" ]; then return 1 fi if [ -z \"$spruce_type\" ]; then get_arch fi local url_selector=\".assets[] | select(.name | contains(\\\"${spruce_type}\\\")) | .browser_download_url\" kcptun_release_download_url=\"$(get_json_string \"$version_content\" \"$url_selector\")\" if [ -z \"$kcptun_release_download_url\" ]; then return 1 fi kcptun_release_tag_name=\"$(get_json_string \"$version_content\" '.tag_name')\" kcptun_release_name=\"$(get_json_string \"$version_content\" '.name')\" kcptun_release_prerelease=\"$(get_json_string \"$version_content\" '.prerelease')\" kcptun_release_publish_time=\"$(get_json_string \"$version_content\" '.published_at')\" kcptun_release_html_url=\"$(get_json_string \"$version_content\" '.html_url')\" local body_content=\"$(get_json_string \"$version_content\" '.body')\" local body=\"$(echo \"$body_content\" | sed 's/#br#/\\n/g' | grep -vE '(^```)|(^>)|(^[[:space:]]*$)|(SUM$)')\" kcptun_release_body=\"$(echo \"$body\" | grep -vE \"[0-9a-zA-Z]{32,}\")\" local file_verify=\"\" file_verify=\"$(echo \"$body\" | grep \"$spruce_type\")\" if [ -n \"$file_verify\" ]; then local i=\"1\" local split=\"\" while true do split=\"$(echo \"$file_verify\" | cut -d ' ' -f$i)\" if [ -n \"$split\" ] && ( echo \"$split\" | grep -qE \"^[0-9a-zA-Z]{32,}$\" ); then kcptun_release_verify=\"$split\" break elif [ -z \"$split\" ]; then break fi i=$(expr $i + 1) done fi return 0 } # \u83b7\u53d6\u811a\u672c\u7248\u672c\u4fe1\u606f get_shell_version_info() { local shell_version_content=\"\" shell_version_content=\"$(get_content \"$SHELL_VERSION_INFO_URL\")\" if [ -z \"$shell_version_content\" ]; then return 1 fi new_shell_version=\"$(get_json_string \"$shell_version_content\" '.shell_version' '[0-9]+')\" new_config_version=\"$(get_json_string \"$shell_version_content\" '.config_version' '[0-9]+')\" new_init_version=\"$(get_json_string \"$shell_version_content\" '.init_version' '[0-9]+')\" shell_change_log=\"$(get_json_string \"$shell_version_content\" '.change_log')\" config_change_log=\"$(get_json_string \"$shell_version_content\" '.config_change_log')\" init_change_log=\"$(get_json_string \"$shell_version_content\" '.init_change_log')\" new_shell_url=\"$(get_json_string \"$shell_version_content\" '.shell_url')\" if [ -z \"$new_shell_version\" ]; then new_shell_version=\"0\" fi if [ -z \"$new_config_version\" ]; then new_config_version=\"0\" fi if [ -z \"$new_init_version\" ]; then new_init_version=\"0\" fi return 0 } # \u4e0b\u8f7d\u5e76\u5b89\u88c5 Kcptun install_kcptun() { if [ -z \"$kcptun_release_download_url\" ]; then get_kcptun_version_info \"$1\" if [ \"$?\" != \"0\" ]; then cat >&2 <<-'EOF' \u83b7\u53d6 Kcptun \u7248\u672c\u4fe1\u606f\u6216\u4e0b\u8f7d\u5730\u5740\u5931\u8d25! \u53ef\u80fd\u662f GitHub \u6539\u7248\uff0c\u6216\u8005\u4ece\u7f51\u7edc\u83b7\u53d6\u5230\u7684\u5185\u5bb9\u4e0d\u6b63\u786e\u3002 \u8bf7\u8054\u7cfb\u811a\u672c\u4f5c\u8005\u3002 EOF exit 1 fi fi local kcptun_file_name=\"kcptun-${kcptun_release_tag_name}.tar.gz\" download_file \"$kcptun_release_download_url\" \"$kcptun_file_name\" \"$kcptun_release_verify\" if [ ! -d \"$KCPTUN_INSTALL_DIR\" ]; then ( set -x mkdir -p \"$KCPTUN_INSTALL_DIR\" ) fi if [ ! -d \"$KCPTUN_LOG_DIR\" ]; then ( set -x mkdir -p \"$KCPTUN_LOG_DIR\" chmod a+w \"$KCPTUN_LOG_DIR\" ) fi ( set -x tar -zxf \"$kcptun_file_name\" -C \"$KCPTUN_INSTALL_DIR\" sleep 3 ) local kcptun_server_file=\"\" kcptun_server_file=\"$(get_kcptun_server_file)\" if [ ! -f \"$kcptun_server_file\" ]; then cat >&2 <<-'EOF' \u672a\u5728\u89e3\u538b\u6587\u4ef6\u4e2d\u627e\u5230 Kcptun \u670d\u52a1\u7aef\u6267\u884c\u6587\u4ef6! \u901a\u5e38\u8fd9\u4e0d\u4f1a\u53d1\u751f\uff0c\u53ef\u80fd\u7684\u539f\u56e0\u662f Kcptun \u4f5c\u8005\u6253\u5305\u6587\u4ef6\u7684\u65f6\u5019\u66f4\u6539\u4e86\u6587\u4ef6\u540d\u3002 \u4f60\u53ef\u4ee5\u5c1d\u8bd5\u91cd\u65b0\u5b89\u88c5\uff0c\u6216\u8005\u8054\u7cfb\u811a\u672c\u4f5c\u8005\u3002 EOF exit 1 fi chmod a+x \"$kcptun_server_file\" if [ -z \"$(get_installed_version)\" ]; then cat >&2 <<-'EOF' \u65e0\u6cd5\u627e\u5230\u9002\u5408\u5f53\u524d\u670d\u52a1\u5668\u7684 kcptun \u53ef\u6267\u884c\u6587\u4ef6 \u4f60\u53ef\u4ee5\u5c1d\u8bd5\u4ece\u6e90\u7801\u7f16\u8bd1\u3002 EOF exit 1 fi rm -f \"$kcptun_file_name\" \"${KCPTUN_INSTALL_DIR}/client_$file_suffix\" } # \u5b89\u88c5\u4f9d\u8d56\u8f6f\u4ef6 install_deps() { if [ -z \"$lsb_dist\" ]; then get_os_info fi case \"$lsb_dist\" in ubuntu|debian|raspbian) local did_apt_get_update=\"\" apt_get_update() { if [ -z \"$did_apt_get_update\" ]; then ( set -x; sleep 3; apt-get update ) did_apt_get_update=1 fi } if ! command_exists wget; then apt_get_update ( set -x; sleep 3; apt-get install -y -q wget ca-certificates ) fi if ! command_exists awk; then apt_get_update ( set -x; sleep 3; apt-get install -y -q gawk ) fi if ! command_exists tar; then apt_get_update ( set -x; sleep 3; apt-get install -y -q tar ) fi if ! command_exists pip; then apt_get_update ( set -x; sleep 3; apt-get install -y -q python-pip || true ) fi if ! command_exists python; then apt_get_update ( set -x; sleep 3; apt-get install -y -q python ) fi ;; fedora|centos|redhat|oraclelinux|photon) if [ \"$lsb_dist\" = \"fedora\" ] && [ \"$dist_version\" -ge \"22\" ]; then if ! command_exists wget; then ( set -x; sleep 3; dnf -y -q install wget ca-certificates ) fi if ! command_exists awk; then ( set -x; sleep 3; dnf -y -q install gawk ) fi if ! command_exists tar; then ( set -x; sleep 3; dnf -y -q install tar ) fi if ! command_exists pip; then ( set -x; sleep 3; dnf -y -q install python-pip || true ) fi if ! command_exists python; then ( set -x; sleep 3; dnf -y -q install python ) fi elif [ \"$lsb_dist\" = \"photon\" ]; then if ! command_exists wget; then ( set -x; sleep 3; tdnf -y install wget ca-certificates ) fi if ! command_exists awk; then ( set -x; sleep 3; tdnf -y install gawk ) fi if ! command_exists tar; then ( set -x; sleep 3; tdnf -y install tar ) fi if ! command_exists pip; then ( set -x; sleep 3; tdnf -y install python-pip || true ) fi if ! command_exists python; then ( set -x; sleep 3; tdnf -y install python ) fi else if ! command_exists wget; then ( set -x; sleep 3; yum -y -q install wget ca-certificates ) fi if ! command_exists awk; then ( set -x; sleep 3; yum -y -q install gawk ) fi if ! command_exists tar; then ( set -x; sleep 3; yum -y -q install tar ) fi # CentOS \u7b49\u7ea2\u5e3d\u7cfb\u64cd\u4f5c\u7cfb\u7edf\u7684\u8f6f\u4ef6\u5e93\u4e2d\u53ef\u80fd\u4e0d\u5305\u62ec python-pip # \u53ef\u4ee5\u5148\u5b89\u88c5 epel-release if ! command_exists pip; then ( set -x; sleep 3; yum -y -q install python-pip || true ) fi # \u5982\u679c python-pip \u5b89\u88c5\u5931\u8d25\uff0c\u68c0\u6d4b\u662f\u5426\u5df2\u5b89\u88c5 python \u73af\u5883 if ! command_exists python; then ( set -x; sleep 3; yum -y -q install python ) fi fi ;; *) cat >&2 <<-EOF \u6682\u65f6\u4e0d\u652f\u6301\u5f53\u524d\u7cfb\u7edf\uff1a${lsb_dist} ${dist_version} EOF exit 1 ;; esac # \u8fd9\u91cc\u5224\u65ad\u4e86\u662f\u5426\u5b58\u5728\u5b89\u88c5\u5931\u8d25\u7684\u8f6f\u4ef6\u5305\uff0c\u4f46\u662f\u9ed8\u8ba4\u4e0d\u5904\u7406 python-pip \u7684\u5b89\u88c5\u5931\u8d25\uff0c # \u63a5\u4e0b\u6765\u4f1a\u7edf\u4e00\u68c0\u6d4b\u5e76\u518d\u6b21\u5b89\u88c5 pip \u547d\u4ee4 if [ \"$?\" != 0 ]; then cat >&2 <<-'EOF' \u4e00\u4e9b\u4f9d\u8d56\u8f6f\u4ef6\u5b89\u88c5\u5931\u8d25\uff0c \u8bf7\u67e5\u770b\u65e5\u5fd7\u68c0\u67e5\u9519\u8bef\u3002 EOF exit 1 fi install_jq } # \u5b89\u88c5 supervisor install_supervisor() { if [ -s /etc/supervisord.conf ] && command_exists supervisord; then cat >&2 <<-EOF \u68c0\u6d4b\u5230\u4f60\u66fe\u7ecf\u901a\u8fc7\u5176\u4ed6\u65b9\u5f0f\u5b89\u88c5\u8fc7 Supervisor , \u8fd9\u4f1a\u548c\u672c\u811a\u672c\u5b89\u88c5\u7684 Supervisor \u4ea7\u751f\u51b2\u7a81 \u63a8\u8350\u4f60\u5907\u4efd\u5f53\u524d Supervisor \u914d\u7f6e\u540e\u5378\u8f7d\u539f\u6709\u7248\u672c \u5df2\u5b89\u88c5\u7684 Supervisor \u914d\u7f6e\u6587\u4ef6\u8def\u5f84\u4e3a: /etc/supervisord.conf \u901a\u8fc7\u672c\u811a\u672c\u5b89\u88c5\u7684 Supervisor \u914d\u7f6e\u6587\u4ef6\u8def\u5f84\u4e3a: /etc/supervisor/supervisord.conf \u4f60\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u6765\u5907\u4efd\u539f\u6709\u914d\u7f6e\u6587\u4ef6: mv /etc/supervisord.conf /etc/supervisord.conf.bak EOF exit 1 fi if ! command_exists python; then cat >&2 <<-'EOF' python \u73af\u5883\u672a\u5b89\u88c5\uff0c\u5e76\u4e14\u81ea\u52a8\u5b89\u88c5\u5931\u8d25\uff0c\u8bf7\u624b\u52a8\u5b89\u88c5 python \u73af\u5883\u3002 EOF exit 1 fi local python_version=\"$(python -V 2>&1)\" if [ \"$?\" != \"0\" ] || [ -z \"$python_version\" ]; then cat >&2 <<-'EOF' python \u73af\u5883\u5df2\u635f\u574f\uff0c\u65e0\u6cd5\u901a\u8fc7 python -V \u6765\u83b7\u53d6\u7248\u672c\u53f7\u3002 \u8bf7\u624b\u52a8\u91cd\u88c5 python \u73af\u5883\u3002 EOF exit 1 fi local version_string=\"$(echo \"$python_version\" | cut -d' ' -f2 | head -n1)\" local major_version=\"$(echo \"$version_string\" | cut -d'.' -f1)\" local minor_version=\"$(echo \"$version_string\" | cut -d'.' -f2)\" if [ -z \"$major_version\" ] || [ -z \"$minor_version\" ] || \\ ! ( is_number \"$major_version\" ); then cat >&2 <<-EOF \u83b7\u53d6 python \u5927\u5c0f\u7248\u672c\u53f7\u5931\u8d25\uff1a${python_version} EOF exit 1 fi local is_python_26=\"false\" if [ \"$major_version\" -lt \"2\" ] || ( \\ [ \"$major_version\" = \"2\" ] && [ \"$minor_version\" -lt \"6\" ] ); then cat >&2 <<-EOF \u4e0d\u652f\u6301\u7684 python \u7248\u672c ${version_string}\uff0c\u5f53\u524d\u4ec5\u652f\u6301 python 2.6 \u53ca\u4ee5\u4e0a\u7248\u672c\u7684\u5b89\u88c5\u3002 EOF exit 1 elif [ \"$major_version\" = \"2\" ] && [ \"$minor_version\" = \"6\" ]; then is_python_26=\"true\" cat >&1 <<-EOF \u6ce8\u610f\uff1a\u5f53\u524d\u670d\u52a1\u5668\u7684 python \u7248\u672c\u4e3a ${version_string}, \u811a\u672c\u5bf9 python 2.6 \u53ca\u4ee5\u4e0b\u7248\u672c\u7684\u652f\u6301\u53ef\u80fd\u4f1a\u5931\u6548\uff0c \u8bf7\u5c3d\u5feb\u5347\u7ea7 python \u7248\u672c\u5230 >= 2.7.9 \u6216 >= 3.4\u3002 EOF any_key_to_continue fi if ! command_exists pip; then # \u5982\u679c\u6ca1\u6709\u76d1\u6d4b\u5230 pip \u547d\u4ee4\uff0c\u4f46\u5f53\u524d\u670d\u52a1\u5668\u5df2\u7ecf\u5b89\u88c5 python # \u4f7f\u7528 get-pip.py \u811a\u672c\u6765\u5b89\u88c5 pip \u547d\u4ee4 if [ \"$is_python_26\" = \"true\" ]; then ( set -x wget -qO- --no-check-certificate https://bootstrap.pypa.io/2.6/get-pip.py | python ) else ( set -x wget -qO- --no-check-certificate https://bootstrap.pypa.io/get-pip.py | python ) fi fi # \u5982\u679c\u4f7f\u7528\u811a\u672c\u5b89\u88c5\u4f9d\u7136\u5931\u8d25\uff0c\u63d0\u793a\u624b\u52a8\u5b89\u88c5 if ! command_exists pip; then cat >&2 <<-EOF \u672a\u627e\u5230\u5df2\u5b89\u88c5\u7684 pip \u547d\u4ee4\uff0c\u8bf7\u5148\u624b\u52a8\u5b89\u88c5 python-pip \u672c\u811a\u672c\u81ea v21 \u7248\u5f00\u59cb\u4f7f\u7528 pip \u6765\u5b89\u88c5 Supervisior\u3002 1. \u5bf9\u4e8e Debian \u7cfb\u7684 Linux \u7cfb\u7edf\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528\uff1a sudo apt-get install -y python-pip \u6765\u8fdb\u884c\u5b89\u88c5 2. \u5bf9\u4e8e Redhat \u7cfb\u7684 Linux \u7cfb\u7edf\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528\uff1a sudo yum install -y python-pip \u6765\u8fdb\u884c\u5b89\u88c5 * \u5982\u679c\u63d0\u793a\u672a\u627e\u5230\uff0c\u53ef\u4ee5\u5148\u5c1d\u8bd5\u5b89\u88c5\uff1aepel-release \u6269\u5c55\u8f6f\u4ef6\u5e93 3. \u5982\u679c\u4ee5\u4e0a\u65b9\u6cd5\u90fd\u5931\u8d25\u4e86\uff0c\u8bf7\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u6765\u624b\u52a8\u5b89\u88c5\uff1a wget -qO- --no-check-certificate https://bootstrap.pypa.io/get-pip.py | python * python 2.6 \u7684\u7528\u6237\u8bf7\u4f7f\u7528\uff1a wget -qO- --no-check-certificate https://bootstrap.pypa.io/2.6/get-pip.py | python 4. pip \u5b89\u88c5\u5b8c\u6bd5\u4e4b\u540e\uff0c\u5148\u8fd0\u884c\u4e00\u4e0b\u66f4\u65b0\u547d\u4ee4\uff1a pip install --upgrade pip \u518d\u68c0\u67e5\u4e00\u4e0b pip \u7684\u7248\u672c\uff1a pip -V \u4e00\u5207\u65e0\u8bef\u540e\uff0c\u8bf7\u91cd\u65b0\u8fd0\u884c\u5b89\u88c5\u811a\u672c\u3002 EOF exit 1 fi if ! ( pip --version >/dev/null 2>&1 ); then cat >&2 <<-EOF \u68c0\u6d4b\u5230\u5f53\u524d\u73af\u5883\u7684 pip \u547d\u4ee4\u5df2\u635f\u574f\uff0c \u8bf7\u68c0\u67e5\u4f60\u7684 python \u73af\u5883\u3002 EOF exit 1 fi if [ \"$is_python_26\" != \"true\" ]; then # \u5df2\u5b89\u88c5 pip \u65f6\u5148\u5c1d\u8bd5\u66f4\u65b0\u4e00\u4e0b\uff0c # \u5982\u679c\u662f python 2.6\uff0c\u5c31\u4e0d\u8981\u66f4\u65b0\u4e86\uff0c\u66f4\u65b0\u4f1a\u5bfc\u81f4 pip \u635f\u574f # pip \u53ea\u652f\u6301 python 2 >= 2.7.9 # https://pip.pypa.io/en/stable/installing/ ( set -x pip install --upgrade pip || true ) fi if [ \"$is_python_26\" = \"true\" ]; then ( set -x pip install 'supervisor>=3.0.0,<4.0.0' ) else ( set -x pip install --upgrade supervisor ) fi if [ \"$?\" != \"0\" ]; then cat >&2 <<-EOF \u9519\u8bef: \u5b89\u88c5 Supervisor \u5931\u8d25\uff0c \u8bf7\u5c1d\u8bd5\u4f7f\u7528 pip install supervisor \u6765\u624b\u52a8\u5b89\u88c5\u3002 Supervisor \u4ece 4.0 \u5f00\u59cb\u5df2\u4e0d\u652f\u6301 python 2.6 \u53ca\u4ee5\u4e0b\u7248\u672c python 2.6 \u7684\u7528\u6237\u8bf7\u4f7f\u7528\uff1a pip install 'supervisor>=3.0.0,<4.0.0' EOF exit 1 fi [ ! -d /etc/supervisor/conf.d ] && ( set -x mkdir -p /etc/supervisor/conf.d ) if [ ! -f '/usr/local/bin/supervisord' ]; then ( set -x ln -s \"$(command -v supervisord)\" '/usr/local/bin/supervisord' 2>/dev/null ) fi if [ ! -f '/usr/local/bin/supervisorctl' ]; then ( set -x ln -s \"$(command -v supervisorctl)\" '/usr/local/bin/supervisorctl' 2>/dev/null ) fi if [ ! -f '/usr/local/bin/pidproxy' ]; then ( set -x ln -s \"$(command -v pidproxy)\" '/usr/local/bin/pidproxy' 2>/dev/null ) fi local cfg_file='/etc/supervisor/supervisord.conf' local rvt=\"0\" if [ ! -s \"$cfg_file\" ]; then if ! command_exists echo_supervisord_conf; then cat >&2 <<-'EOF' \u672a\u627e\u5230 echo_supervisord_conf, \u65e0\u6cd5\u81ea\u52a8\u521b\u5efa Supervisor \u914d\u7f6e\u6587\u4ef6! \u53ef\u80fd\u662f\u5f53\u524d\u5b89\u88c5\u7684 supervisor \u7248\u672c\u8fc7\u4f4e\u3002 EOF exit 1 fi ( set -x echo_supervisord_conf >\"$cfg_file\" 2>&1 ) rvt=\"$?\" fi local cfg_content=\"$(cat \"$cfg_file\")\" # Error with supervisor config file if ( echo \"$cfg_content\" | grep -q \"Traceback (most recent call last)\" ) ; then rvt=\"1\" if ( echo \"$cfg_content\" | grep -q \"DistributionNotFound: meld3\" ); then # https://github.com/Supervisor/meld3/issues/23 ( set -x local temp=\"$(mktemp -d)\" local pwd=\"$(pwd)\" download_file 'https://pypi.python.org/packages/source/m/meld3/meld3-1.0.2.tar.gz' \\ \"$temp/meld3.tar.gz\" cd \"$temp\" tar -zxf \"$temp/meld3.tar.gz\" --strip=1 python setup.py install cd \"$pwd\" ) if [ \"$?\" = \"0\" ] ; then ( set -x echo_supervisord_conf >\"$cfg_file\" 2>/dev/null ) rvt=\"$?\" fi fi fi if [ \"$rvt\" != \"0\" ]; then rm -f \"$cfg_file\" echo \"\u521b\u5efa Supervisor \u914d\u7f6e\u6587\u4ef6\u5931\u8d25!\" exit 1 fi if ! grep -q '^files[[:space:]]*=[[:space:]]*/etc/supervisor/conf.d/\\*\\.conf$' \"$cfg_file\"; then if grep -q '^\\[include\\]$' \"$cfg_file\"; then sed -i '/^\\[include\\]$/a files = \\/etc\\/supervisor\\/conf.d\\/\\*\\.conf' \"$cfg_file\" else sed -i '$a [include]\\nfiles = /etc/supervisor/conf.d/*.conf' \"$cfg_file\" fi fi download_startup_file } download_startup_file() { local supervisor_startup_file=\"\" local supervisor_startup_file_url=\"\" if command_exists systemctl; then supervisor_startup_file=\"/etc/systemd/system/supervisord.service\" supervisor_startup_file_url=\"$SUPERVISOR_SYSTEMD_FILE_URL\" download_file \"$supervisor_startup_file_url\" \"$supervisor_startup_file\" ( set -x # \u5220\u9664\u65e7\u7248 service \u6587\u4ef6 local old_service_file=\"/lib/systemd/system/supervisord.service\" if [ -f \"$old_service_file\" ]; then rm -f \"$old_service_file\" fi systemctl daemon-reload >/dev/null 2>&1 ) elif command_exists service; then supervisor_startup_file='/etc/init.d/supervisord' if [ -z \"$lsb_dist\" ]; then get_os_info fi case \"$lsb_dist\" in ubuntu|debian|raspbian) supervisor_startup_file_url=\"$SUPERVISOR_SERVICE_FILE_DEBIAN_URL\" ;; fedora|centos|redhat|oraclelinux|photon) supervisor_startup_file_url=\"$SUPERVISOR_SERVICE_FILE_REDHAT_URL\" ;; *) echo \"\u6ca1\u6709\u9002\u5408\u5f53\u524d\u7cfb\u7edf\u7684\u670d\u52a1\u542f\u52a8\u811a\u672c\u6587\u4ef6\u3002\" exit 1 ;; esac download_file \"$supervisor_startup_file_url\" \"$supervisor_startup_file\" ( set -x chmod a+x \"$supervisor_startup_file\" ) else cat >&2 <<-'EOF' \u5f53\u524d\u670d\u52a1\u5668\u672a\u5b89\u88c5 systemctl \u6216\u8005 service \u547d\u4ee4\uff0c\u65e0\u6cd5\u914d\u7f6e\u670d\u52a1\u3002 \u8bf7\u5148\u624b\u52a8\u5b89\u88c5 systemd \u6216\u8005 service \u4e4b\u540e\u518d\u8fd0\u884c\u811a\u672c\u3002 EOF exit 1 fi } start_supervisor() { ( set -x; sleep 3 ) if command_exists systemctl; then if systemctl status supervisord.service >/dev/null 2>&1; then systemctl restart supervisord.service else systemctl start supervisord.service fi elif command_exists service; then if service supervisord status >/dev/null 2>&1; then service supervisord restart else service supervisord start fi fi if [ \"$?\" != \"0\" ]; then cat >&2 <<-'EOF' \u542f\u52a8 Supervisor \u5931\u8d25, Kcptun \u65e0\u6cd5\u6b63\u5e38\u5de5\u4f5c! \u8bf7\u53cd\u9988\u7ed9\u811a\u672c\u4f5c\u8005\u3002 EOF exit 1 fi } enable_supervisor() { if command_exists systemctl; then ( set -x systemctl enable \"supervisord.service\" ) elif command_exists service; then if [ -z \"$lsb_dist\" ]; then get_os_info fi case \"$lsb_dist\" in ubuntu|debian|raspbian) ( set -x update-rc.d -f supervisord defaults ) ;; fedora|centos|redhat|oraclelinux|photon) ( set -x chkconfig --add supervisord chkconfig supervisord on ) ;; esac fi } set_kcptun_config() { is_port() { local port=\"$1\" is_number \"$port\" && \\ [ $port -ge 1 ] && [ $port -le 65535 ] } port_using() { local port=\"$1\" if command_exists netstat; then ( netstat -ntul | grep -qE \"[0-9:*]:${port}\\s\" ) elif command_exists ss; then ( ss -ntul | grep -qE \"[0-9:*]:${port}\\s\" ) else return 0 fi return $? } local input=\"\" local yn=\"\" # \u8bbe\u7f6e\u670d\u52a1\u8fd0\u884c\u7aef\u53e3 [ -z \"$listen_port\" ] && listen_port=\"$D_LISTEN_PORT\" while true do cat >&1 <<-'EOF' \u8bf7\u8f93\u5165 Kcptun \u670d\u52a1\u7aef\u8fd0\u884c\u7aef\u53e3 [1~65535] \u8fd9\u4e2a\u7aef\u53e3\u5c31\u662f Kcptun \u5ba2\u6237\u7aef\u8fde\u63a5\u7684\u7aef\u53e3 \u65b0\u7248\u652f\u6301\u7aef\u53e3\u8303\u56f4\uff0c\u53ef\u8f93\u5165[30000-35000]\u6765\u5f00\u542f\u7aef\u53e3\u8303\u56f4 EOF read -p \"(\u9ed8\u8ba4: ${listen_port}): \" input if [ -n \"$input\" ]; then if echo \"$input\" | grep -qE '^[0-9]+-[0-9]+$'; then range_start=$(echo \"$input\" | cut -d'-' -f1) range_end=$(echo \"$input\" | cut -d'-' -f2) if [ \"$range_start\" -ge 1 ] && [ \"$range_start\" -le 65535 ] && \\ [ \"$range_end\" -ge 1 ] && [ \"$range_end\" -le 65535 ] && \\ [ \"$range_start\" -le \"$range_end\" ]; then if echo \"$current_listen_port\" | grep -qE '^[0-9]+-[0-9]+$'; then current_range_start=$(echo \"$current_listen_port\" | cut -d'-' -f1) current_range_end=$(echo \"$current_listen_port\" | cut -d'-' -f2) if [ \"$range_start\" -le \"$current_range_end\" ] && [ \"$range_end\" -ge \"$current_range_start\" ]; then listen_port=\"$input\" else echo \"\u5f53\u524d\u76d1\u542c\u7aef\u53e3\u8303\u56f4\u4e0d\u5728\u8f93\u5165\u7684\u8303\u56f4\u5185, \u8bf7\u91cd\u65b0\u8f93\u5165!\u5f53\u524d\u8303\u56f4\uff1a${current_listen_port}\" continue fi else listen_port=\"$input\" fi else echo \"\u7aef\u53e3\u8303\u56f4\u65e0\u6548, \u8bf7\u8f93\u5165\u7c7b\u4f3c 3000-5000 \u7684\u6709\u6548\u7aef\u53e3\u8303\u56f4!\" continue fi elif is_port \"$input\"; then if echo \"$current_listen_port\" | grep -qE '^[0-9]+-[0-9]+$'; then current_range_start=$(echo \"$current_listen_port\" | cut -d'-' -f1) current_range_end=$(echo \"$current_listen_port\" | cut -d'-' -f2) if [ \"$input\" -ge \"$current_range_start\" ] && [ \"$input\" -le \"$current_range_end\" ]; then listen_port=\"$input\" else echo \"\u8f93\u5165\u7684\u7aef\u53e3\u4e0d\u5728\u5f53\u524d\u76d1\u542c\u7aef\u53e3\u8303\u56f4\u5185, \u8bf7\u91cd\u65b0\u8f93\u5165!\u5f53\u524d\u8303\u56f4\uff1a${current_listen_port}\" continue fi else listen_port=\"$input\" fi else echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165 1~65535 \u4e4b\u95f4\u7684\u6570\u5b57\u6216\u6709\u6548\u7684\u7aef\u53e3\u8303\u56f4!\" continue fi fi if port_using \"$listen_port\" && [ \"$listen_port\" != \"$current_listen_port\" ]; then echo \"\u7aef\u53e3\u5df2\u88ab\u5360\u7528, \u8bf7\u91cd\u65b0\u8f93\u5165!\" continue fi break done input=\"\" cat >&1 <<-EOF --------------------------- \u7aef\u53e3 = ${listen_port} --------------------------- EOF [ -z \"$target_addr\" ] && target_addr=\"$D_TARGET_ADDR\" cat >&1 <<-'EOF' \u8bf7\u8f93\u5165\u9700\u8981\u52a0\u901f\u7684\u5730\u5740 \u53ef\u4ee5\u8f93\u5165\u4e3b\u673a\u540d\u79f0\u3001IPv4 \u5730\u5740\u6216\u8005 IPv6 \u5730\u5740 EOF read -p \"(\u9ed8\u8ba4: ${target_addr}): \" input if [ -n \"$input\" ]; then target_addr=\"$input\" fi input=\"\" cat >&1 <<-EOF --------------------------- \u52a0\u901f\u5730\u5740 = ${target_addr} --------------------------- EOF [ -z \"$target_port\" ] && target_port=\"$D_TARGET_PORT\" while true do cat >&1 <<-'EOF' \u8bf7\u8f93\u5165\u9700\u8981\u52a0\u901f\u7684\u7aef\u53e3 [1~65535] EOF read -p \"(\u9ed8\u8ba4: ${target_port}): \" input if [ -n \"$input\" ]; then if is_port \"$input\"; then if [ \"$input\" = \"$listen_port\" ]; then echo \"\u52a0\u901f\u7aef\u53e3\u4e0d\u80fd\u548c Kcptun \u7aef\u53e3\u4e00\u81f4!\" continue fi target_port=\"$input\" else echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165 1~65535 \u4e4b\u95f4\u7684\u6570\u5b57!\" continue fi fi if [ \"$target_addr\" = \"127.0.0.1\" ] && ! port_using \"$target_port\"; then read -p \"\u5f53\u524d\u6ca1\u6709\u8f6f\u4ef6\u4f7f\u7528\u6b64\u7aef\u53e3, \u786e\u5b9a\u52a0\u901f\u6b64\u7aef\u53e3? [y/n]: \" yn if [ -n \"$yn\" ]; then case \"$(first_character \"$yn\")\" in y|Y) ;; *) continue ;; esac fi fi break done input=\"\" yn=\"\" cat >&1 <<-EOF --------------------------- \u52a0\u901f\u7aef\u53e3 = ${target_port} --------------------------- EOF [ -z \"$key\" ] && key=\"$D_KEY\" cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e Kcptun \u5bc6\u7801(key) \u8be5\u53c2\u6570\u5fc5\u987b\u4e24\u7aef\u4e00\u81f4 EOF read -p \"(\u9ed8\u8ba4\u5bc6\u7801: ${key}): \" input [ -n \"$input\" ] && key=\"$input\" input=\"\" cat >&1 <<-EOF --------------------------- \u5bc6\u7801 = ${key} --------------------------- EOF [ -z \"$crypt\" ] && crypt=\"$D_CRYPT\" local crypt_list=\"aes aes-128 aes-192 salsa20 blowfish twofish cast5 3des tea xtea xor none\" local i=0 cat >&1 <<-'EOF' \u8bf7\u9009\u62e9\u52a0\u5bc6\u65b9\u5f0f(crypt) \u5f3a\u52a0\u5bc6\u5bf9 CPU \u8981\u6c42\u8f83\u9ad8\uff0c \u5982\u679c\u662f\u5728\u8def\u7531\u5668\u4e0a\u914d\u7f6e\u5ba2\u6237\u7aef\uff0c \u8bf7\u5c3d\u91cf\u9009\u62e9\u5f31\u52a0\u5bc6\u6216\u8005\u4e0d\u52a0\u5bc6\u3002 \u8be5\u53c2\u6570\u5fc5\u987b\u4e24\u7aef\u4e00\u81f4 EOF while true do for c in $crypt_list; do i=$(expr $i + 1) echo \"(${i}) ${c}\" done read -p \"(\u9ed8\u8ba4: ${crypt}) \u8bf7\u9009\u62e9 [1~$i]: \" input if [ -n \"$input\" ]; then if is_number \"$input\" && [ $input -ge 1 ] && [ $input -le $i ]; then crypt=$(echo \"$crypt_list\" | cut -d' ' -f ${input}) else echo \"\u8bf7\u8f93\u5165\u6709\u6548\u6570\u5b57 1~$i!\" i=0 continue fi fi break done input=\"\" i=0 cat >&1 <<-EOF ----------------------------- \u52a0\u5bc6\u65b9\u5f0f = ${crypt} ----------------------------- EOF [ -z \"$mode\" ] && mode=\"$D_MODE\" local mode_list=\"normal fast fast2 fast3 manual\" i=0 cat >&1 <<-'EOF' \u8bf7\u9009\u62e9\u52a0\u901f\u6a21\u5f0f(mode) \u52a0\u901f\u6a21\u5f0f\u548c\u53d1\u9001\u7a97\u53e3\u5927\u5c0f\u5171\u540c\u51b3\u5b9a\u4e86\u6d41\u91cf\u7684\u635f\u8017\u5927\u5c0f \u5982\u679c\u52a0\u901f\u6a21\u5f0f\u9009\u62e9\u201c\u624b\u52a8(manual)\u201d\uff0c \u5c06\u8fdb\u5165\u624b\u52a8\u6863\u9690\u85cf\u53c2\u6570\u7684\u8bbe\u7f6e\u3002 EOF while true do for m in $mode_list; do i=$(expr $i + 1) echo \"(${i}) ${m}\" done read -p \"(\u9ed8\u8ba4: ${mode}) \u8bf7\u9009\u62e9 [1~$i]: \" input if [ -n \"$input\" ]; then if is_number \"$input\" && [ $input -ge 1 ] && [ $input -le $i ]; then mode=$(echo \"$mode_list\" | cut -d ' ' -f ${input}) else echo \"\u8bf7\u8f93\u5165\u6709\u6548\u6570\u5b57 1~$i!\" i=0 continue fi fi break done input=\"\" i=0 cat >&1 <<-EOF --------------------------- \u52a0\u901f\u6a21\u5f0f = ${mode} --------------------------- EOF if [ \"$mode\" = \"manual\" ]; then set_manual_parameters else nodelay=\"\" interval=\"\" resend=\"\" nc=\"\" fi [ -z \"$mtu\" ] && mtu=\"$D_MTU\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e UDP \u6570\u636e\u5305\u7684 MTU (\u6700\u5927\u4f20\u8f93\u5355\u5143)\u503c EOF read -p \"(\u9ed8\u8ba4: ${mtu}): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -le 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e0\u7684\u6570\u5b57!\" continue fi mtu=$input fi break done input=\"\" cat >&1 <<-EOF --------------------------- MTU = ${mtu} --------------------------- EOF [ -z \"$sndwnd\" ] && sndwnd=\"$D_SNDWND\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e\u53d1\u9001\u7a97\u53e3\u5927\u5c0f(sndwnd) \u53d1\u9001\u7a97\u53e3\u8fc7\u5927\u4f1a\u6d6a\u8d39\u8fc7\u591a\u6d41\u91cf EOF read -p \"(\u6570\u636e\u5305\u6570\u91cf, \u9ed8\u8ba4: ${sndwnd}): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -le 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e0\u7684\u6570\u5b57!\" continue fi sndwnd=$input fi break done input=\"\" cat >&1 <<-EOF --------------------------- sndwnd = ${sndwnd} --------------------------- EOF [ -z \"$rcvwnd\" ] && rcvwnd=\"$D_RCVWND\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e\u63a5\u6536\u7a97\u53e3\u5927\u5c0f(rcvwnd) EOF read -p \"(\u6570\u636e\u5305\u6570\u91cf, \u9ed8\u8ba4: ${rcvwnd}): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -le 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e0\u7684\u6570\u5b57!\" continue fi rcvwnd=$input fi break done input=\"\" cat >&1 <<-EOF --------------------------- rcvwnd = ${rcvwnd} --------------------------- EOF [ -z \"$datashard\" ] && datashard=\"$D_DATASHARD\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e\u524d\u5411\u7ea0\u9519 datashard \u8be5\u53c2\u6570\u5fc5\u987b\u4e24\u7aef\u4e00\u81f4 EOF read -p \"(\u9ed8\u8ba4: ${datashard}): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -lt 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e\u7b49\u4e8e0\u7684\u6570\u5b57!\" continue fi datashard=$input fi break done input=\"\" cat >&1 <<-EOF --------------------------- datashard = ${datashard} --------------------------- EOF [ -z \"$parityshard\" ] && parityshard=\"$D_PARITYSHARD\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e\u524d\u5411\u7ea0\u9519 parityshard \u8be5\u53c2\u6570\u5fc5\u987b\u4e24\u7aef\u4e00\u81f4 EOF read -p \"(\u9ed8\u8ba4: ${parityshard}): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -lt 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e\u7b49\u4e8e0\u7684\u6570\u5b57!\" continue fi parityshard=$input fi break done input=\"\" cat >&1 <<-EOF --------------------------- parityshard = ${parityshard} --------------------------- EOF [ -z \"$dscp\" ] && dscp=\"$D_DSCP\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e\u5dee\u5206\u670d\u52a1\u4ee3\u7801\u70b9(DSCP) EOF read -p \"(\u9ed8\u8ba4: ${dscp}): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -lt 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e\u7b49\u4e8e0\u7684\u6570\u5b57!\" continue fi dscp=$input fi break done input=\"\" cat >&1 <<-EOF --------------------------- DSCP = ${dscp} --------------------------- EOF [ -z \"$nocomp\" ] && nocomp=\"$D_NOCOMP\" while true do cat >&1 <<-'EOF' \u662f\u5426\u5173\u95ed\u6570\u636e\u538b\u7f29? \u5bf9CPU\u6027\u80fd\u6709\u635f\u8017 \u5982\u679c\u662f\u6587\u672c\u7c7b\u6570\u636e\uff0c\u53ef\u8bbe\u624b\u52a8\u5f00\u542f \u5982\u679c\u662f\u6570\u636e\u5957\u58f3\uff0c\u5219\u9ed8\u8ba4\u4fdd\u6301\u5173\u95ed\u76f4\u63a5 EOF read -p \"(\u9ed8\u8ba4: ${nocomp}) [y/n]: \" yn if [ -n \"$yn\" ]; then case \"$(first_character \"$yn\")\" in y|Y) nocomp='true' ;; n|N) nocomp='false' ;; *) echo \"\u8f93\u5165\u6709\u8bef\uff0c\u8bf7\u91cd\u65b0\u8f93\u5165!\" continue ;; esac fi break done yn=\"\" cat >&1 <<-EOF --------------------------- nocomp = ${nocomp} --------------------------- EOF [ -z \"$quiet\" ] && quiet=\"$D_QUIET\" while true do cat >&1 <<-'EOF' \u662f\u5426\u5c4f\u853d open/close \u65e5\u5fd7\u8f93\u51fa? EOF read -p \"(\u9ed8\u8ba4: ${quiet}) [y/n]: \" yn if [ -n \"$yn\" ]; then case \"$(first_character \"$yn\")\" in y|Y) quiet='true' ;; n|N) quiet='false' ;; *) echo \"\u8f93\u5165\u6709\u8bef\uff0c\u8bf7\u91cd\u65b0\u8f93\u5165!\" continue ;; esac fi break done yn=\"\" cat >&1 <<-EOF --------------------------- quiet = ${quiet} --------------------------- EOF [ -z \"$tcp\" ] && tcp=\"$D_TCP\" while true do cat >&1 <<-'EOF' \u662f\u5426\u4f7f\u7528 TCP \u4f20\u8f93 EOF read -p \"(\u9ed8\u8ba4: ${tcp}) [y/n]: \" yn if [ -n \"$yn\" ]; then case \"$(first_character \"$yn\")\" in y|Y) tcp='true' ;; n|N) tcp='false' ;; *) echo \"\u8f93\u5165\u6709\u8bef\uff0c\u8bf7\u91cd\u65b0\u8f93\u5165!\" continue ;; esac fi break done if [ \"$tcp\" = \"true\" ]; then run_user=\"root\" fi yn=\"\" cat >&1 <<-EOF --------------------------- tcp = ${tcp} --------------------------- EOF unset_snmp() { snmplog=\"\" snmpperiod=\"\" cat >&1 <<-EOF --------------------------- \u4e0d\u8bb0\u5f55 SNMP \u65e5\u5fd7 --------------------------- EOF } cat >&1 <<-EOF \u662f\u5426\u8bb0\u5f55 SNMP \u65e5\u5fd7? EOF read -p \"(\u9ed8\u8ba4: \u5426) [y/n]: \" yn if [ -n \"$yn\" ]; then case \"$(first_character \"$yn\")\" in y|Y) set_snmp ;; n|N|*) unset_snmp ;; esac yn=\"\" else unset_snmp fi [ -z \"$pprof\" ] && pprof=\"$D_PPROF\" while true do cat >&1 <<-'EOF' \u662f\u5426\u5f00\u542f pprof \u6027\u80fd\u76d1\u63a7? \u5730\u5740: http://IP:6060/debug/pprof/ EOF read -p \"(\u9ed8\u8ba4: ${pprof}) [y/n]: \" yn if [ -n \"$yn\" ]; then case \"$(first_character \"$yn\")\" in y|Y) pprof='true' ;; n|N) pprof='false' ;; *) echo \"\u8f93\u5165\u6709\u8bef\uff0c\u8bf7\u91cd\u65b0\u8f93\u5165!\" continue ;; esac fi break done yn=\"\" cat >&1 <<-EOF --------------------------- pprof = ${pprof} --------------------------- EOF unset_hidden_parameters() { acknodelay=\"\" sockbuf=\"\" smuxbuf=\"\" keepalive=\"\" streambuf=\"\" smuxver=\"\" cat >&1 <<-EOF --------------------------- \u4e0d\u914d\u7f6e\u9690\u85cf\u53c2\u6570 --------------------------- EOF } cat >&1 <<-'EOF' \u57fa\u7840\u53c2\u6570\u8bbe\u7f6e\u5b8c\u6210\uff0c\u662f\u5426\u8bbe\u7f6e\u989d\u5916\u7684\u9690\u85cf\u53c2\u6570? \u901a\u5e38\u60c5\u51b5\u4e0b\u4fdd\u6301\u9ed8\u8ba4\u5373\u53ef\uff0c\u4e0d\u7528\u989d\u5916\u8bbe\u7f6e EOF read -p \"(\u9ed8\u8ba4: \u5426) [y/n]: \" yn if [ -n \"$yn\" ]; then case \"$(first_character \"$yn\")\" in y|Y) set_hidden_parameters ;; n|N|*) unset_hidden_parameters ;; esac else unset_hidden_parameters fi if echo \"$input\" | grep -qE '^[0-9]+-[0-9]+$'; then range_start=$(echo \"$input\" | cut -d'-' -f1) range_end=$(echo \"$input\" | cut -d'-' -f2) if [ \"$range_start\" -ge 1 ] && [ \"$range_start\" -le 65535 ] && \\ [ \"$range_end\" -ge 1 ] && [ \"$range_end\" -le 65535 ] && \\ [ \"$range_start\" -le \"$range_end\" ]; then # \u65b0\u589e\u7aef\u53e3\u6bb5\u68c0\u6d4b\u903b\u8f91 if [ \"$range_start\" -le 1024 ] || [ \"$range_end\" -le 1024 ]; then run_user=\"root\" fi fi elif is_port \"$input\"; then listen_port=\"$input\" # \u7aef\u53e3\u68c0\u6d4b\u903b\u8f91 if [ \"$listen_port\" -le 1024 ]; then run_user=\"root\" fi fi echo \"\u914d\u7f6e\u5b8c\u6210\u3002\" any_key_to_continue } set_snmp() { snmplog=\"$(get_current_file 'snmp')\" local input=\"\" [ -z \"$snmpperiod\" ] && snmpperiod=\"$D_SNMPPERIOD\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e SNMP \u8bb0\u5f55\u95f4\u9694\u65f6\u95f4 snmpperiod EOF read -p \"(\u9ed8\u8ba4: ${snmpperiod}): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -lt 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e\u7b49\u4e8e0\u7684\u6570\u5b57!\" continue fi snmpperiod=$input fi break done cat >&1 <<-EOF --------------------------- snmplog = ${snmplog} snmpperiod = ${snmpperiod} --------------------------- EOF } set_manual_parameters() { echo \"\u5f00\u59cb\u914d\u7f6e\u624b\u52a8\u53c2\u6570...\" local input=\"\" local yn=\"\" [ -z \"$nodelay\" ] && nodelay=\"$D_NODELAY\" while true do cat >&1 <<-'EOF' \u662f\u5426\u542f\u7528 nodelay \u6a21\u5f0f? (0) \u4e0d\u542f\u7528 (1) \u542f\u7528 EOF read -p \"(\u9ed8\u8ba4: ${nodelay}) [0/1]: \" input if [ -n \"$input\" ]; then case \"$(first_character \"$input\")\" in 1) nodelay=1 ;; 0|*) nodelay=0 ;; *) echo \"\u8f93\u5165\u6709\u8bef\uff0c\u8bf7\u91cd\u65b0\u8f93\u5165!\" continue ;; esac fi break done input=\"\" cat >&1 <<-EOF --------------------------- nodelay = ${nodelay} --------------------------- EOF [ -z \"$interval\" ] && interval=\"$D_INTERVAL\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e\u534f\u8bae\u5185\u90e8\u5de5\u4f5c\u7684 interval EOF read -p \"(\u5355\u4f4d: ms, \u9ed8\u8ba4: ${interval}): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -le 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e0\u7684\u6570\u5b57!\" continue fi interval=$input fi break done input=\"\" cat >&1 <<-EOF --------------------------- interval = ${interval} --------------------------- EOF [ -z \"$resend\" ] && resend=\"$D_RESEND\" while true do cat >&1 <<-'EOF' \u662f\u5426\u542f\u7528\u5feb\u901f\u91cd\u4f20\u6a21\u5f0f(resend)? (0) \u4e0d\u542f\u7528 (1) \u542f\u7528 (2) 2\u6b21ACK\u8de8\u8d8a\u5c06\u4f1a\u76f4\u63a5\u91cd\u4f20 EOF read -p \"(\u9ed8\u8ba4: ${resend}) \u8bf7\u9009\u62e9 [0~2]: \" input if [ -n \"$input\" ]; then case \"$(first_character \"$input\")\" in 0) resend=0 ;; 1) resend=1 ;; 2) resend=2 ;; *) echo \"\u8f93\u5165\u6709\u8bef\uff0c\u8bf7\u91cd\u65b0\u8f93\u5165!\" continue ;; esac fi break done input=\"\" cat >&1 <<-EOF --------------------------- resend = ${resend} --------------------------- EOF [ -z \"$nc\" ] && nc=\"$D_NC\" while true do cat >&1 <<-'EOF' \u662f\u5426\u5173\u95ed\u6d41\u63a7(nc)? (0) \u5173\u95ed (1) \u5f00\u542f EOF read -p \"(\u9ed8\u8ba4: ${nc}) [0/1]: \" input if [ -n \"$input\" ]; then case \"$(first_character \"$input\")\" in 0) nc=0 ;; 1) nc=1 ;; *) echo \"\u8f93\u5165\u6709\u8bef\uff0c\u8bf7\u91cd\u65b0\u8f93\u5165!\" continue ;; esac fi break done cat >&1 <<-EOF --------------------------- nc = ${nc} --------------------------- EOF } set_hidden_parameters() { echo \"\u5f00\u59cb\u8bbe\u7f6e\u9690\u85cf\u53c2\u6570...\" local input=\"\" local yn=\"\" [ -z \"$acknodelay\" ] && acknodelay=\"$D_ACKNODELAY\" while true do cat >&1 <<-'EOF' \u662f\u5426\u542f\u7528 acknodelay \u6a21\u5f0f? EOF read -p \"(\u9ed8\u8ba4: ${acknodelay}) [y/n]: \" yn if [ -n \"$yn\" ]; then case \"$(first_character \"$yn\")\" in y|Y) acknodelay=\"true\" ;; n|N) acknodelay=\"false\" ;; *) echo \"\u8f93\u5165\u6709\u8bef\uff0c\u8bf7\u91cd\u65b0\u8f93\u5165!\" continue ;; esac fi break done yn=\"\" cat >&1 <<-EOF --------------------------- acknodelay = ${acknodelay} --------------------------- EOF [ -z \"$sockbuf\" ] && sockbuf=\"$D_SOCKBUF\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e UDP \u6536\u53d1\u7f13\u51b2\u533a\u5927\u5c0f(sockbuf) EOF read -p \"(\u5355\u4f4d: MB, \u9ed8\u8ba4: $(expr ${sockbuf} / 1024 / 1024)): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -le 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e0\u7684\u6570\u5b57!\" continue fi sockbuf=$(expr $input \\* 1024 \\* 1024) fi break done input=\"\" cat >&1 <<-EOF --------------------------- sockbuf = ${sockbuf} --------------------------- EOF [ -z \"$smuxbuf\" ] && smuxbuf=\"$D_SMUXBUF\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e de-mux \u7f13\u51b2\u533a\u5927\u5c0f(smuxbuf) EOF read -p \"(\u5355\u4f4d: MB, \u9ed8\u8ba4: $(expr ${smuxbuf} / 1024 / 1024)): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -le 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e0\u7684\u6570\u5b57!\" continue fi smuxbuf=$(expr $input \\* 1024 \\* 1024) fi break done input=\"\" cat >&1 <<-EOF --------------------------- smuxbuf = ${smuxbuf} --------------------------- EOF [ -z \"$keepalive\" ] && keepalive=\"$D_KEEPALIVE\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e Keepalive \u7684\u95f4\u9694\u65f6\u95f4 EOF read -p \"(\u5355\u4f4d: s, \u9ed8\u8ba4\u503c: ${keepalive}, \u524d\u503c: 5): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -le 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e0\u7684\u6570\u5b57!\" continue fi keepalive=$input fi break done cat >&1 <<-EOF --------------------------- keepalive = ${keepalive} --------------------------- EOF [ -z \"$smuxver\" ] && smuxver=\"$D_SMUXVER\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e smux \u7684\u7248\u672c EOF read -p \"(1,2, \u9ed8\u8ba4\u503c: ${smuxver}, \u8001\u7248\u672c\u9ed8\u8ba41\uff0c\u65b0\u7248\u672c\u9ed8\u8ba42): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -le 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e0\u7684\u6570\u5b57!\" continue fi smuxver=$input fi break done cat >&1 <<-EOF --------------------------- $smuxver = ${smuxver} --------------------------- EOF [ -z \"$streambuf\" ] && streambuf=\"$D_STREAMBUF\" while true do cat >&1 <<-'EOF' \u8bf7\u8bbe\u7f6e streambuf \u5927\u5c0f\uff0c\u5b98\u65b9\u6587\u6863\u4ecb\u7ecd\u672c\u503c\u4e0d\u5b9c\u8fc7\u5927 EOF read -p \"(\u5355\u4f4d: MB, \u9ed8\u8ba4: $(expr ${streambuf} / 1024 / 1024)): \" input if [ -n \"$input\" ]; then if ! is_number \"$input\" || [ $input -le 0 ]; then echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u5927\u4e8e0\u7684\u6570\u5b57!\" continue fi streambuf=$(expr $input \\* 1024 \\* 1024) fi break done cat >&1 <<-EOF --------------------------- streambuf = ${streambuf} --------------------------- EOF } # \u751f\u6210 Kcptun \u670d\u52a1\u7aef\u914d\u7f6e\u6587\u4ef6 gen_kcptun_config() { mk_file_dir() { local dir=\"\" dir=\"$(dirname \"$1\")\" local mod=$2 if [ ! -d \"$dir\" ]; then ( set -x mkdir -p \"$dir\" ) fi if [ -n \"$mod\" ]; then chmod $mod \"$dir\" fi } local config_file=\"\" config_file=\"$(get_current_file 'config')\" local supervisor_config_file=\"\" supervisor_config_file=\"$(get_current_file 'supervisor')\" mk_file_dir \"$config_file\" mk_file_dir \"$supervisor_config_file\" if [ -n \"$snmplog\" ]; then mk_file_dir \"$snmplog\" '777' fi if ( echo \"$listen_addr\" | grep -q \":\" ); then listen_addr=\"[${listen_addr}]\" fi if ( echo \"$target_addr\" | grep -q \":\" ); then target_addr=\"[${target_addr}]\" fi cat > \"$config_file\"<<-EOF { \"listen\": \"${listen_addr}:${listen_port}\", \"target\": \"${target_addr}:${target_port}\", \"key\": \"${key}\", \"crypt\": \"${crypt}\", \"mode\": \"${mode}\", \"mtu\": ${mtu}, \"sndwnd\": ${sndwnd}, \"rcvwnd\": ${rcvwnd}, \"datashard\": ${datashard}, \"parityshard\": ${parityshard}, \"dscp\": ${dscp}, \"nocomp\": ${nocomp}, \"quiet\": ${quiet}, \"tcp\": ${tcp} } EOF write_configs_to_file() { install_jq local k; local v local json=\"\" json=\"$(cat \"$config_file\")\" for k in \"$@\"; do v=\"$(eval echo \"\\$$k\")\" if [ -n \"$v\" ]; then if is_number \"$v\" || [ \"$v\" = \"false\" ] || [ \"$v\" = \"true\" ]; then json=\"$(echo \"$json\" | $JQ_BIN \".$k=$v\")\" else json=\"$(echo \"$json\" | $JQ_BIN \".$k=\\\"$v\\\"\")\" fi fi done if [ -n \"$json\" ] && [ \"$json\" != \"$(cat \"$config_file\")\" ]; then echo \"$json\" >\"$config_file\" fi } write_configs_to_file \"snmplog\" \"snmpperiod\" \"pprof\" \"acknodelay\" \"nodelay\" \\ \"interval\" \"resend\" \"nc\" \"sockbuf\" \"smuxbuf\" \"keepalive\" \"streambuf\" \"smuxver\" if ! grep -q \"^${run_user}:\" '/etc/passwd'; then ( set -x useradd -U -s '/usr/sbin/nologin' -d '/nonexistent' \"$run_user\" 2>/dev/null ) fi cat > \"$supervisor_config_file\"<<-EOF [program:kcptun${current_instance_id}] user=${run_user} directory=${KCPTUN_INSTALL_DIR} command=$(get_kcptun_server_file) -c \"${config_file}\" process_name=%(program_name)s autostart=true redirect_stderr=true stdout_logfile=$(get_current_file 'log') stdout_logfile_maxbytes=1MB stdout_logfile_backups=0 EOF } # \u8bbe\u7f6e\u9632\u706b\u5899\u5f00\u653e\u7aef\u53e3 set_firewall() { if command_exists firewall-cmd; then if ! ( firewall-cmd --state >/dev/null 2>&1 ); then systemctl start firewalld >/dev/null 2>&1 fi if [ \"$?\" = \"0\" ]; then if [ -n \"$current_listen_port\" ]; then firewall-cmd --zone=public --remove-port=${current_listen_port}/udp >/dev/null 2>&1 fi if ! firewall-cmd --quiet --zone=public --query-port=${listen_port}/udp; then firewall-cmd --quiet --permanent --zone=public --add-port=${listen_port}/udp firewall-cmd --reload fi else cat >&1 <<-EOF \u8b66\u544a: \u81ea\u52a8\u6dfb\u52a0 firewalld \u89c4\u5219\u5931\u8d25 \u5982\u679c\u6709\u5fc5\u8981, \u8bf7\u624b\u52a8\u6dfb\u52a0\u7aef\u53e3 ${listen_port} \u7684\u9632\u706b\u5899\u89c4\u5219: firewall-cmd --permanent --zone=public --add-port=${listen_port}/udp firewall-cmd --reload EOF fi elif command_exists iptables; then if ! ( service iptables status >/dev/null 2>&1 ); then service iptables start >/dev/null 2>&1 fi if [ \"$?\" = \"0\" ]; then if [ -n \"$current_listen_port\" ]; then iptables -D INPUT -p udp --dport ${current_listen_port} -j ACCEPT >/dev/null 2>&1 fi if ! iptables -C INPUT -p udp --dport ${listen_port} -j ACCEPT >/dev/null 2>&1; then iptables -I INPUT -p udp --dport ${listen_port} -j ACCEPT >/dev/null 2>&1 service iptables save service iptables restart fi else cat >&1 <<-EOF \u8b66\u544a: \u81ea\u52a8\u6dfb\u52a0 iptables \u89c4\u5219\u5931\u8d25 \u5982\u6709\u5fc5\u8981, \u8bf7\u624b\u52a8\u6dfb\u52a0\u7aef\u53e3 ${listen_port} \u7684\u9632\u706b\u5899\u89c4\u5219: iptables -I INPUT -p udp --dport ${listen_port} -j ACCEPT service iptables save service iptables restart EOF fi fi } # \u9009\u62e9\u4e00\u4e2a\u5b9e\u4f8b select_instance() { if [ \"$(get_instance_count)\" -gt 1 ]; then cat >&1 <<-'EOF' \u5f53\u524d\u6709\u591a\u4e2a Kcptun \u5b9e\u4f8b (\u6309\u6700\u540e\u4fee\u6539\u65f6\u95f4\u6392\u5e8f): EOF local files=\"\" files=$(ls -lt '/etc/supervisor/conf.d/' | grep \"^-\" | awk '{print $9}' | grep \"^kcptun[0-9]*\\.conf$\") local i=0 local array=\"\" local id=\"\" for file in $files; do id=\"$(echo \"$file\" | grep -oE \"[0-9]+\")\" array=\"${array}${id}#\" i=$(expr $i + 1) echo \"(${i}) ${file%.*}\" done local sel=\"\" while true do read -p \"\u8bf7\u9009\u62e9 [1~${i}]: \" sel if [ -n \"$sel\" ]; then if ! is_number \"$sel\" || [ $sel -lt 1 ] || [ $sel -gt $i ]; then cat >&2 <<-EOF \u8bf7\u8f93\u5165\u6709\u6548\u6570\u5b57 1~${i}! EOF continue fi else cat >&2 <<-EOF \u8bf7\u8f93\u5165\u4e0d\u80fd\u4e3a\u7a7a\uff01 EOF continue fi current_instance_id=$(echo \"$array\" | cut -d '#' -f ${sel}) break done fi } # \u901a\u8fc7\u5f53\u524d\u670d\u52a1\u7aef\u73af\u5883\u83b7\u53d6 Kcptun \u670d\u52a1\u7aef\u6587\u4ef6\u540d get_kcptun_server_file() { if [ -z \"$file_suffix\" ]; then get_arch fi echo \"${KCPTUN_INSTALL_DIR}/server_$file_suffix\" } # \u8ba1\u7b97\u65b0\u5b9e\u4f8b\u7684 ID get_new_instance_id() { if [ -f \"/etc/supervisor/conf.d/kcptun.conf\" ]; then local i=2 while [ -f \"/etc/supervisor/conf.d/kcptun${i}.conf\" ] do i=$(expr $i + 1) done echo \"$i\" fi } # \u83b7\u53d6\u5df2\u5b89\u88c5\u7684 Kcptun \u7248\u672c get_installed_version() { local server_file=\"\" server_file=\"$(get_kcptun_server_file)\" if [ -f \"$server_file\" ]; then if [ ! -x \"$server_file\" ]; then chmod a+x \"$server_file\" fi echo \"$(${server_file} -v 2>/dev/null | awk '{print $3}')\" fi } # \u52a0\u8f7d\u5f53\u524d\u9009\u62e9\u5b9e\u4f8b\u7684\u914d\u7f6e\u6587\u4ef6 load_instance_config() { local config_file=\"\" config_file=\"$(get_current_file 'config')\" if [ ! -s \"$config_file\" ]; then cat >&2 <<-'EOF' \u5b9e\u4f8b\u914d\u7f6e\u6587\u4ef6\u4e0d\u5b58\u5728\u6216\u4e3a\u7a7a, \u8bf7\u68c0\u67e5! EOF exit 1 fi local config_content=\"\" config_content=\"$(cat ${config_file})\" if [ -z \"$(get_json_string \"$config_content\" '.listen')\" ]; then cat >&2 <<-EOF \u5b9e\u4f8b\u914d\u7f6e\u6587\u4ef6\u5b58\u5728\u9519\u8bef, \u8bf7\u68c0\u67e5! \u914d\u7f6e\u6587\u4ef6\u8def\u5f84: ${config_file} EOF exit 1 fi local lines=\"\" lines=\"$(get_json_string \"$config_content\" 'to_entries | map(\"\\(.key)=\\(.value | @sh)\") | .[]')\" OLDIFS=$IFS IFS=$(printf '\\n') for line in $lines; do eval \"$line\" done IFS=$OLDIFS if [ -n \"$listen\" ]; then listen_port=\"$(echo \"$listen\" | rev | cut -d ':' -f1 | rev)\" listen_addr=\"$(echo \"$listen\" | sed \"s/:${listen_port}$//\" | grep -oE '[0-9a-fA-F\\.:]*')\" listen=\"\" fi if [ -n \"$target\" ]; then target_port=\"$(echo \"$target\" | rev | cut -d ':' -f1 | rev)\" target_addr=\"$(echo \"$target\" | sed \"s/:${target_port}$//\" | grep -oE '[0-9a-fA-F\\.:]*')\" target=\"\" fi if [ -n \"$listen_port\" ]; then current_listen_port=\"$listen_port\" fi } # \u663e\u793a\u670d\u52a1\u7aef Kcptun \u7248\u672c\uff0c\u548c\u5ba2\u6237\u7aef\u6587\u4ef6\u7684\u4e0b\u8f7d\u5730\u5740 show_version_and_client_url() { local version=\"\" version=\"$(get_installed_version)\" if [ -n \"$version\" ]; then cat >&1 <<-EOF \u5f53\u524d\u5b89\u88c5\u7684 Kcptun \u7248\u672c\u4e3a: ${version} EOF fi if [ -n \"$kcptun_release_html_url\" ]; then cat >&1 <<-EOF \u8bf7\u81ea\u884c\u524d\u5f80: ${kcptun_release_html_url} \u624b\u52a8\u4e0b\u8f7d\u5ba2\u6237\u7aef\u6587\u4ef6 EOF fi } # \u663e\u793a\u5f53\u524d\u9009\u62e9\u5b9e\u4f8b\u7684\u4fe1\u606f show_current_instance_info() { local server_ip=\"\" server_ip=\"$(get_server_ip)\" printf '\u670d\u52a1\u5668IP: \\033[41;37m %s \\033[0m\\n' \"$server_ip\" printf '\u7aef\u53e3: \\033[41;37m %s \\033[0m\\n' \"$listen_port\" printf '\u52a0\u901f\u5730\u5740: \\033[41;37m %s:%s \\033[0m\\n' \"$target_addr\" \"$target_port\" show_configs() { local k; local v for k in \"$@\"; do v=\"$(eval echo \"\\$$k\")\" if [ -n \"$v\" ]; then printf '%s: \\033[41;37m %s \\033[0m\\n' \"$k\" \"$v\" fi done } show_configs \"key\" \"crypt\" \"mode\" \"mtu\" \"sndwnd\" \"rcvwnd\" \"datashard\" \\ \"parityshard\" \"dscp\" \"nocomp\" \"quiet\" \"tcp\" \"nodelay\" \"interval\" \"resend\" \\ \"nc\" \"acknodelay\" \"sockbuf\" \"smuxbuf\" \"keepalive\" \"streambuf\" \"smuxver\" show_version_and_client_url install_jq local client_config=\"\" # \u8fd9\u91cc\u8f93\u51fa\u7684\u662f\u5ba2\u6237\u7aef\u6240\u4f7f\u7528\u7684\u914d\u7f6e\u4fe1\u606f # \u5ba2\u6237\u7aef\u7684 *remoteaddr* \u7aef\u53e3\u53f7\u4e3a\u670d\u52a1\u7aef\u7684 *listen_port* # \u5ba2\u6237\u7aef\u7684 *localaddr* \u7aef\u53e3\u53f7\u88ab\u8bbe\u7f6e\u4e3a\u4e86\u670d\u52a1\u7aef\u7684\u52a0\u901f\u7aef\u53e3 client_config=\"$(cat <<-EOF { \"localaddr\": \":${target_port}\", \"remoteaddr\": \"${server_ip}:${listen_port}\", \"key\": \"${key}\" } EOF )\" gen_client_configs() { local k; local v for k in \"$@\"; do if [ \"$k\" = \"sndwnd\" ]; then v=\"$rcvwnd\" elif [ \"$k\" = \"rcvwnd\" ]; then v=\"$sndwnd\" else v=\"$(eval echo \"\\$$k\")\" fi if [ -n \"$v\" ]; then if is_number \"$v\" || [ \"$v\" = \"true\" ] || [ \"$v\" = \"false\" ]; then client_config=\"$(echo \"$client_config\" | $JQ_BIN -r \".${k}=${v}\")\" else client_config=\"$(echo \"$client_config\" | $JQ_BIN -r \".${k}=\\\"${v}\\\"\")\" fi fi done } gen_client_configs \"crypt\" \"mode\" \"mtu\" \"sndwnd\" \"rcvwnd\" \"datashard\" \\ \"parityshard\" \"dscp\" \"nocomp\" \"quiet\" \"tcp\" \"nodelay\" \"interval\" \"resend\" \\ \"nc\" \"acknodelay\" \"sockbuf\" \"smuxbuf\" \"keepalive\" \"streambuf\" \"smuxver\" cat >&1 <<-EOF \u53ef\u4f7f\u7528\u7684\u5ba2\u6237\u7aef\u914d\u7f6e\u6587\u4ef6\u4e3a: ${client_config} EOF local mobile_config=\"key=${key}\" gen_mobile_configs() { local k; local v for k in \"$@\"; do if [ \"$k\" = \"sndwnd\" ]; then v=\"$rcvwnd\" elif [ \"$k\" = \"rcvwnd\" ]; then v=\"$sndwnd\" else v=\"$(eval echo \"\\$$k\")\" fi if [ -n \"$v\" ]; then if [ \"$v\" = \"false\" ]; then continue elif [ \"$v\" = \"true\" ]; then mobile_config=\"${mobile_config};${k}\" else mobile_config=\"${mobile_config};${k}=${v}\" fi fi done } gen_mobile_configs \"crypt\" \"mode\" \"mtu\" \"sndwnd\" \"rcvwnd\" \"datashard\" \\ \"parityshard\" \"dscp\" \"nocomp\" \"quiet\" \"tcp\" \"nodelay\" \"interval\" \"resend\" \\ \"nc\" \"acknodelay\" \"sockbuf\" \"smuxbuf\" \"keepalive\" \"streambuf\" \"smuxver\" cat >&1 <<-EOF \u624b\u673a\u7aef\u53c2\u6570\u53ef\u4ee5\u4f7f\u7528: ${mobile_config} EOF } do_install() { check_root disable_selinux installed_check set_kcptun_config install_deps install_kcptun install_supervisor gen_kcptun_config set_firewall start_supervisor enable_supervisor cat >&1 <<-EOF \u606d\u559c! Kcptun \u670d\u52a1\u7aef\u5b89\u88c5\u6210\u529f\u3002 EOF show_current_instance_info cat >&1 <<-EOF Kcptun \u5b89\u88c5\u76ee\u5f55: ${KCPTUN_INSTALL_DIR} \u5df2\u5c06 Supervisor \u52a0\u5165\u5f00\u673a\u81ea\u542f, Kcptun \u670d\u52a1\u7aef\u4f1a\u968f Supervisor \u7684\u542f\u52a8\u800c\u542f\u52a8 \u66f4\u591a\u4f7f\u7528\u8bf4\u660e: ${0} help \u5982\u679c\u8fd9\u4e2a\u811a\u672c\u5e2e\u5230\u4e86\u4f60\uff0c\u4f60\u53ef\u4ee5\u8bf7\u4f5c\u8005\u559d\u74f6\u53ef\u4e50: https://blog.kuoruan.com/donate \u4eab\u53d7\u52a0\u901f\u7684\u5feb\u611f\u5427\uff01 EOF } # \u5378\u8f7d\u64cd\u4f5c do_uninstall() { check_root cat >&1 <<-'EOF' \u4f60\u9009\u62e9\u4e86\u5378\u8f7d Kcptun \u670d\u52a1\u7aef EOF any_key_to_continue echo \"\u6b63\u5728\u5378\u8f7d Kcptun \u670d\u52a1\u7aef\u5e76\u505c\u6b62 Supervisor...\" if command_exists supervisorctl; then supervisorctl shutdown fi if command_exists systemctl; then systemctl stop supervisord.service elif command_exists serice; then service supervisord stop fi ( set -x rm -f \"/etc/supervisor/conf.d/kcptun*.conf\" rm -rf \"$KCPTUN_INSTALL_DIR\" rm -rf \"$KCPTUN_LOG_DIR\" ) cat >&1 <<-'EOF' \u662f\u5426\u540c\u65f6\u5378\u8f7d Supervisor ? \u6ce8\u610f: Supervisor \u7684\u914d\u7f6e\u6587\u4ef6\u5c06\u540c\u65f6\u88ab\u5220\u9664 EOF read -p \"(\u9ed8\u8ba4: \u4e0d\u5378\u8f7d) \u8bf7\u9009\u62e9 [y/n]: \" yn if [ -n \"$yn\" ]; then case \"$(first_character \"$yn\")\" in y|Y) if command_exists systemctl; then systemctl disable supervisord.service rm -f \"/lib/systemd/system/supervisord.service\" \\ \"/etc/systemd/system/supervisord.service\" elif command_exists service; then if [ -z \"$lsb_dist\" ]; then get_os_info fi case \"$lsb_dist\" in ubuntu|debian|raspbian) ( set -x update-rc.d -f supervisord remove ) ;; fedora|centos|redhat|oraclelinux|photon) ( set -x chkconfig supervisord off chkconfig --del supervisord ) ;; esac rm -f '/etc/init.d/supervisord' fi ( set -x # \u65b0\u7248\u4f7f\u7528 pip \u5378\u8f7d if command_exists pip; then pip uninstall -y supervisor 2>/dev/null || true fi # \u65e7\u7248\u4f7f\u7528 easy_install \u5378\u8f7d if command_exists easy_install; then rm -rf \"$(easy_install -mxN supervisor | grep 'Using.*supervisor.*\\.egg' | awk '{print $2}')\" fi rm -rf '/etc/supervisor/' rm -f '/usr/local/bin/supervisord' \\ '/usr/local/bin/supervisorctl' \\ '/usr/local/bin/pidproxy' \\ '/usr/local/bin/echo_supervisord_conf' \\ '/usr/bin/supervisord' \\ '/usr/bin/supervisorctl' \\ '/usr/bin/pidproxy' \\ '/usr/bin/echo_supervisord_conf' ) ;; n|N|*) start_supervisor ;; esac fi cat >&1 <<-EOF \u5378\u8f7d\u5b8c\u6210, \u6b22\u8fce\u518d\u6b21\u4f7f\u7528\u3002 \u6ce8\u610f: \u811a\u672c\u6ca1\u6709\u81ea\u52a8\u5378\u8f7d python-pip \u548c python-setuptools\uff08\u65e7\u7248\u811a\u672c\u4f7f\u7528\uff09 \u5982\u6709\u9700\u8981, \u4f60\u53ef\u4ee5\u81ea\u884c\u5378\u8f7d\u3002 EOF } # \u66f4\u65b0 do_update() { pre_ckeck cat >&1 <<-EOF \u4f60\u9009\u62e9\u4e86\u68c0\u67e5\u66f4\u65b0, \u6b63\u5728\u5f00\u59cb\u64cd\u4f5c... EOF if get_shell_version_info; then local shell_path=$0 if [ $new_shell_version -gt $SHELL_VERSION ]; then cat >&1 <<-EOF \u53d1\u73b0\u4e00\u952e\u5b89\u88c5\u811a\u672c\u66f4\u65b0, \u7248\u672c\u53f7: ${new_shell_version} \u66f4\u65b0\u8bf4\u660e: $(printf '%s\\n' \"$shell_change_log\") EOF any_key_to_continue mv -f \"$shell_path\" \"$shell_path\".bak download_file \"$new_shell_url\" \"$shell_path\" chmod a+x \"$shell_path\" sed -i -r \"s/^CONFIG_VERSION=[0-9]+/CONFIG_VERSION=${CONFIG_VERSION}/\" \"$shell_path\" sed -i -r \"s/^INIT_VERSION=[0-9]+/INIT_VERSION=${INIT_VERSION}/\" \"$shell_path\" rm -f \"$shell_path\".bak clear cat >&1 <<-EOF \u5b89\u88c5\u811a\u672c\u5df2\u66f4\u65b0\u5230 v${new_shell_version}, \u6b63\u5728\u8fd0\u884c\u65b0\u7684\u811a\u672c... EOF bash \"$shell_path\" update exit 0 fi if [ $new_config_version -gt $CONFIG_VERSION ]; then cat >&1 <<-EOF \u53d1\u73b0 Kcptun \u914d\u7f6e\u66f4\u65b0, \u7248\u672c\u53f7: v${new_config_version} \u66f4\u65b0\u8bf4\u660e: $(printf '%s\\n' \"$config_change_log\") \u9700\u8981\u91cd\u65b0\u8bbe\u7f6e Kcptun EOF any_key_to_continue instance_reconfig sed -i \"s/^CONFIG_VERSION=${CONFIG_VERSION}/CONFIG_VERSION=${new_config_version}/\" \\ \"$shell_path\" fi if [ $new_init_version -gt $INIT_VERSION ]; then cat >&1 <<-EOF \u53d1\u73b0\u670d\u52a1\u542f\u52a8\u811a\u672c\u6587\u4ef6\u66f4\u65b0, \u7248\u672c\u53f7: v${new_init_version} \u66f4\u65b0\u8bf4\u660e: $(printf '%s\\n' \"$init_change_log\") EOF any_key_to_continue download_startup_file set -sed -i \"s/^INIT_VERSION=${INIT_VERSION}/INIT_VERSION=${new_init_version}/\" \\ \"$shell_path\" fi fi echo \"\u5f00\u59cb\u83b7\u53d6 Kcptun \u7248\u672c\u4fe1\u606f...\" get_kcptun_version_info local cur_tag_name=\"\" cur_tag_name=\"$(get_installed_version)\" if [ -n \"$cur_tag_name\" ] && is_number \"$cur_tag_name\" && [ ${#cur_tag_name} -eq 8 ]; then cur_tag_name=v\"$cur_tag_name\" fi if [ -n \"$kcptun_release_tag_name\" ] && [ \"$kcptun_release_tag_name\" != \"$cur_tag_name\" ]; then cat >&1 <<-EOF \u53d1\u73b0 Kcptun \u65b0\u7248\u672c ${kcptun_release_tag_name} $([ \"$kcptun_release_prerelease\" = \"true\" ] && printf \"\\033[41;37m \u6ce8\u610f: \u8be5\u7248\u672c\u4e3a\u9884\u89c8\u7248, \u8bf7\u8c28\u614e\u66f4\u65b0 \\033[0m\") \u66f4\u65b0\u8bf4\u660e: $(printf '%s\\n' \"$kcptun_release_body\") EOF any_key_to_continue install_kcptun start_supervisor show_version_and_client_url else cat >&1 <<-'EOF' \u672a\u53d1\u73b0 Kcptun \u66f4\u65b0... EOF fi } # \u6dfb\u52a0\u5b9e\u4f8b instance_add() { pre_ckeck cat >&1 <<-'EOF' \u4f60\u9009\u62e9\u4e86\u6dfb\u52a0\u5b9e\u4f8b, \u6b63\u5728\u5f00\u59cb\u64cd\u4f5c... EOF current_instance_id=\"$(get_new_instance_id)\" set_kcptun_config gen_kcptun_config set_firewall start_supervisor cat >&1 <<-EOF \u606d\u559c, \u5b9e\u4f8b kcptun${current_instance_id} \u6dfb\u52a0\u6210\u529f! EOF show_current_instance_info } # \u5220\u9664\u5b9e\u4f8b instance_del() { pre_ckeck if [ -n \"$1\" ]; then if is_number \"$1\"; then if [ \"$1\" != \"1\" ]; then current_instance_id=\"$1\" fi else cat >&2 <<-EOF \u53c2\u6570\u6709\u8bef, \u8bf7\u4f7f\u7528 $0 del <id> <id> \u4e3a\u5b9e\u4f8bID, \u5f53\u524d\u5171\u6709 $(get_instance_count) \u4e2a\u5b9e\u4f8b EOF exit 1 fi fi cat >&1 <<-EOF \u4f60\u9009\u62e9\u4e86\u5220\u9664\u5b9e\u4f8b kcptun${current_instance_id} \u6ce8\u610f: \u5b9e\u4f8b\u5220\u9664\u540e\u65e0\u6cd5\u6062\u590d EOF any_key_to_continue # \u83b7\u53d6\u5b9e\u4f8b\u7684 supervisor \u914d\u7f6e\u6587\u4ef6 supervisor_config_file=\"$(get_current_file 'supervisor')\" if [ ! -f \"$supervisor_config_file\" ]; then echo \"\u4f60\u9009\u62e9\u7684\u5b9e\u4f8b kcptun${current_instance_id} \u4e0d\u5b58\u5728!\" exit 1 fi current_config_file=\"$(get_current_file 'config')\" current_log_file=\"$(get_current_file 'log')\" current_snmp_log_file=\"$(get_current_file 'snmp')\" ( set -x rm -f \"$supervisor_config_file\" \\ \"$current_config_file\" \\ \"$current_log_file\" \\ \"$current_snmp_log_file\" ) start_supervisor cat >&1 <<-EOF \u5b9e\u4f8b kcptun${current_instance_id} \u5220\u9664\u6210\u529f! EOF } # \u663e\u793a\u5b9e\u4f8b\u4fe1\u606f instance_show() { pre_ckeck if [ -n \"$1\" ]; then if is_number \"$1\"; then if [ \"$1\" != \"1\" ]; then current_instance_id=\"$1\" fi else cat >&2 <<-EOF \u53c2\u6570\u6709\u8bef, \u8bf7\u4f7f\u7528 $0 show <id> <id> \u4e3a\u5b9e\u4f8bID, \u5f53\u524d\u5171\u6709 $(get_instance_count) \u4e2a\u5b9e\u4f8b EOF exit 1 fi fi echo \"\u4f60\u9009\u62e9\u4e86\u67e5\u770b\u5b9e\u4f8b kcptun${current_instance_id} \u7684\u914d\u7f6e, \u6b63\u5728\u8bfb\u53d6...\" load_instance_config echo \"\u5b9e\u4f8b kcptun${current_instance_id} \u7684\u914d\u7f6e\u4fe1\u606f\u5982\u4e0b:\" show_current_instance_info } # \u663e\u793a\u5b9e\u4f8b\u65e5\u5fd7 instance_log() { pre_ckeck if [ -n \"$1\" ]; then if is_number \"$1\"; then if [ \"$1\" != \"1\" ]; then current_instance_id=\"$1\" fi else cat >&2 <<-EOF \u53c2\u6570\u6709\u8bef, \u8bf7\u4f7f\u7528 $0 log <id> <id> \u4e3a\u5b9e\u4f8bID, \u5f53\u524d\u5171\u6709 $(get_instance_count) \u4e2a\u5b9e\u4f8b EOF exit 1 fi fi echo \"\u4f60\u9009\u62e9\u4e86\u67e5\u770b\u5b9e\u4f8b kcptun${current_instance_id} \u7684\u65e5\u5fd7, \u6b63\u5728\u8bfb\u53d6...\" local log_file=\"\" log_file=\"$(get_current_file 'log')\" if [ -f \"$log_file\" ]; then cat >&1 <<-EOF \u5b9e\u4f8b kcptun${current_instance_id} \u7684\u65e5\u5fd7\u4fe1\u606f\u5982\u4e0b: \u6ce8: \u65e5\u5fd7\u5b9e\u65f6\u5237\u65b0, \u6309 Ctrl+C \u9000\u51fa\u65e5\u5fd7\u67e5\u770b EOF tail -n 20 -f \"$log_file\" else cat >&2 <<-EOF \u672a\u627e\u5230\u5b9e\u4f8b kcptun${current_instance_id} \u7684\u65e5\u5fd7\u6587\u4ef6... EOF exit 1 fi } # \u91cd\u65b0\u914d\u7f6e\u5b9e\u4f8b instance_reconfig() { pre_ckeck if [ -n \"$1\" ]; then if is_number \"$1\"; then if [ \"$1\" != \"1\" ]; then current_instance_id=\"$1\" fi else cat >&2 <<-EOF \u53c2\u6570\u6709\u8bef, \u8bf7\u4f7f\u7528 $0 reconfig <id> <id> \u4e3a\u5b9e\u4f8bID, \u5f53\u524d\u5171\u6709 $(get_instance_count) \u4e2a\u5b9e\u4f8b EOF exit 1 fi fi cat >&1 <<-EOF \u4f60\u9009\u62e9\u4e86\u91cd\u65b0\u914d\u7f6e\u5b9e\u4f8b kcptun${current_instance_id}, \u6b63\u5728\u5f00\u59cb\u64cd\u4f5c... EOF if [ ! -f \"$(get_current_file 'supervisor')\" ]; then cat >&2 <<-EOF \u4f60\u9009\u62e9\u7684\u5b9e\u4f8b kcptun${current_instance_id} \u4e0d\u5b58\u5728! EOF exit 1 fi local sel=\"\" cat >&1 <<-'EOF' \u8bf7\u9009\u62e9\u64cd\u4f5c: (1) \u91cd\u65b0\u914d\u7f6e\u5b9e\u4f8b\u6240\u6709\u9009\u9879 (2) \u76f4\u63a5\u4fee\u6539\u5b9e\u4f8b\u914d\u7f6e\u6587\u4ef6 EOF read -p \"(\u9ed8\u8ba4: 1) \u8bf7\u9009\u62e9: \" sel echo [ -z \"$sel\" ] && sel=\"1\" case \"$(first_character \"$sel\")\" in 2) echo \"\u6b63\u5728\u6253\u5f00\u914d\u7f6e\u6587\u4ef6, \u8bf7\u624b\u52a8\u4fee\u6539...\" local config_file=\"\" config_file=\"$(get_current_file 'config')\" edit_config_file() { if [ ! -f \"$config_file\" ]; then return 1 fi if command_exists vim; then vim \"$config_file\" elif command_exists vi; then vi \"$config_file\" elif command_exists gedit; then gedit \"$config_file\" else echo \"\u672a\u627e\u5230\u53ef\u7528\u7684\u7f16\u8f91\u5668, \u6b63\u5728\u8fdb\u5165\u5168\u65b0\u914d\u7f6e...\" return 1 fi load_instance_config } if ! edit_config_file; then set_kcptun_config fi ;; 1|*) load_instance_config set_kcptun_config ;; esac gen_kcptun_config set_firewall if command_exists supervisorctl; then supervisorctl restart \"kcptun${current_instance_id}\" if [ \"$?\" != \"0\" ]; then cat >&2 <<-'EOF' \u91cd\u542f Supervisor \u5931\u8d25, Kcptun \u65e0\u6cd5\u6b63\u5e38\u5de5\u4f5c! \u8bf7\u67e5\u770b\u65e5\u5fd7\u83b7\u53d6\u539f\u56e0\uff0c\u6216\u8005\u53cd\u9988\u7ed9\u811a\u672c\u4f5c\u8005\u3002 EOF exit 1 fi else start_supervisor fi cat >&1 <<-EOF \u606d\u559c, Kcptun \u670d\u52a1\u7aef\u914d\u7f6e\u5df2\u66f4\u65b0! EOF show_current_instance_info } #\u624b\u52a8\u5b89\u88c5 manual_install() { pre_ckeck cat >&1 <<-'EOF' \u4f60\u9009\u62e9\u4e86\u81ea\u5b9a\u4e49\u7248\u672c\u5b89\u88c5, \u6b63\u5728\u5f00\u59cb\u64cd\u4f5c... EOF local tag_name=\"$1\" while true do if [ -z \"$tag_name\" ]; then cat >&1 <<-'EOF' \u8bf7\u8f93\u5165\u4f60\u60f3\u5b89\u88c5\u7684 Kcptun \u7248\u672c\u7684\u5b8c\u6574 TAG EOF read -p \"(\u4f8b\u5982: v20160904): \" tag_name if [ -z \"$tag_name\" ]; then echo \"\u8f93\u5165\u65e0\u6548, \u8bf7\u91cd\u65b0\u8f93\u5165!\" continue fi fi if [ \"$tag_name\" = \"SNMP_Milestone\" ]; then echo \"\u4e0d\u652f\u6301\u6b64\u7248\u672c, \u8bf7\u91cd\u65b0\u8f93\u5165!\" tag_name=\"\" continue fi local version_num=\"\" version_num=$(echo \"$tag_name\" | grep -oE \"[0-9]+\" || \"0\") if [ ${#version_num} -eq 8 ] && [ $version_num -le 20160826 ]; then echo \"\u4e0d\u652f\u6301\u5b89\u88c5 v20160826 \u53ca\u4ee5\u524d\u7248\u672c\" tag_name=\"\" continue fi echo \"\u6b63\u5728\u83b7\u53d6\u4fe1\u606f\uff0c\u8bf7\u7a0d\u5019...\" get_kcptun_version_info \"$tag_name\" if [ \"$?\" != \"0\" ]; then cat >&2 <<-EOF \u672a\u627e\u5230\u5bf9\u5e94\u7248\u672c\u4e0b\u8f7d\u5730\u5740 (TAG: ${tag_name}), \u8bf7\u91cd\u65b0\u8f93\u5165! \u4f60\u53ef\u4ee5\u524d\u5f80: ${KCPTUN_TAGS_URL} \u67e5\u770b\u6240\u6709\u53ef\u7528 TAG EOF tag_name=\"\" continue else cat >&1 <<-EOF \u5df2\u627e\u5230 Kcptun \u7248\u672c\u4fe1\u606f, TAG: ${tag_name} EOF any_key_to_continue install_kcptun \"$tag_name\" start_supervisor show_version_and_client_url break fi done } pre_ckeck() { check_root if ! is_installed; then cat >&2 <<-EOF \u9519\u8bef: \u68c0\u6d4b\u5230\u4f60\u8fd8\u6ca1\u6709\u5b89\u88c5 Kcptun\uff0c \u6216\u8005 Kcptun \u7a0b\u5e8f\u6587\u4ef6\u5df2\u635f\u574f\uff0c \u8bf7\u8fd0\u884c\u811a\u672c\u6765\u91cd\u65b0\u5b89\u88c5 Kcptun \u670d\u52a1\u7aef\u3002 EOF exit 1 fi } # \u76d1\u6d4b\u662f\u5426\u5b89\u88c5\u4e86 kcptun is_installed() { if [ -d '/usr/share/kcptun' ]; then cat >&1 <<-EOF \u68c0\u6d4b\u53d1\u73b0\u4f60\u7531\u65e7\u7248\u5347\u7ea7\u5230\u4e86\u65b0\u7248 \u65b0\u7248\u4e2d\u5c06\u9ed8\u8ba4\u5b89\u88c5\u76ee\u5f55\u8bbe\u7f6e\u4e3a\u4e86 ${KCPTUN_INSTALL_DIR} \u811a\u672c\u4f1a\u81ea\u52a8\u5c06\u6587\u4ef6\u4ece\u65e7\u7248\u76ee\u5f55 /usr/share/kcptun \u79fb\u52a8\u5230\u65b0\u7248\u76ee\u5f55 ${KCPTUN_INSTALL_DIR} EOF any_key_to_continue ( set -x cp -rf '/usr/share/kcptun' \"$KCPTUN_INSTALL_DIR\" && \\ rm -rf '/usr/share/kcptun' ) fi if [ -d '/etc/supervisor/conf.d/' ] && [ -d \"$KCPTUN_INSTALL_DIR\" ] && \\ [ -n \"$(get_installed_version)\" ]; then return 0 fi return 1 } # \u68c0\u67e5\u662f\u5426\u5df2\u7ecf\u5b89\u88c5 installed_check() { local instance_count=\"\" instance_count=\"$(get_instance_count)\" if is_installed && [ $instance_count -gt 0 ]; then cat >&1 <<-EOF \u68c0\u6d4b\u5230\u4f60\u5df2\u5b89\u88c5 Kcptun \u670d\u52a1\u7aef, \u5df2\u914d\u7f6e\u7684\u5b9e\u4f8b\u4e2a\u6570\u4e3a ${instance_count} \u4e2a EOF while true do cat >&1 <<-'EOF' \u8bf7\u9009\u62e9\u4f60\u5e0c\u671b\u7684\u64cd\u4f5c: (1) \u8986\u76d6\u5b89\u88c5 (2) \u91cd\u65b0\u914d\u7f6e (3) \u6dfb\u52a0\u5b9e\u4f8b(\u591a\u7aef\u53e3) (4) \u68c0\u67e5\u66f4\u65b0 (5) \u67e5\u770b\u914d\u7f6e (6) \u67e5\u770b\u65e5\u5fd7\u8f93\u51fa (7) \u81ea\u5b9a\u4e49\u7248\u672c\u5b89\u88c5 (8) \u5220\u9664\u5b9e\u4f8b (9) \u5b8c\u5168\u5378\u8f7d (10) \u9000\u51fa\u811a\u672c EOF read -p \"(\u9ed8\u8ba4: 1) \u8bf7\u9009\u62e9 [1~10]: \" sel [ -z \"$sel\" ] && sel=1 case $sel in 1) echo \"\u5f00\u59cb\u8986\u76d6\u5b89\u88c5 Kcptun \u670d\u52a1\u7aef...\" load_instance_config return 0 ;; 2) select_instance instance_reconfig ;; 3) instance_add ;; 4) do_update ;; 5) select_instance instance_show ;; 6) select_instance instance_log ;; 7) manual_install ;; 8) select_instance instance_del ;; 9) do_uninstall ;; 10) ;; *) echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165\u6709\u6548\u6570\u5b57 1~10!\" continue ;; esac exit 0 done fi } action=${1:-\"install\"} case \"$action\" in install|uninstall|update) do_${action} ;; add|reconfig|show|log|del) instance_${action} \"$2\" ;; manual) manual_install \"$2\" ;; help) usage 0 ;; *) usage 1 ;; esac"
        },
        {
            "filename": "file_633.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripts\\ovz-bbr\\file_633.sh",
            "content": "#!/bin/sh : <<-'EOF' Copyright 2017-2019 Xingwang Liao <kuoruan@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. EOF export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin # Haproxy-lkl \u670d\u52a1\u540d\u79f0 SERVICE_NAME='haproxy-lkl' # Haproxy-lkl \u9ed8\u8ba4\u5b89\u88c5\u8def\u5f84\uff0c\u4fee\u6539\u4e4b\u540e\u9700\u8981\u540c\u65f6\u4fee\u6539\u670d\u52a1\u542f\u52a8\u6587\u4ef6 HAPROXY_LKL_DIR=\"/usr/local/$SERVICE_NAME\" BASE_URL='https://github.com/kuoruan/shell-scripts/raw/master/ovz-bbr' HAPROXY_BIN_URL=\"${BASE_URL}/bin/haproxy.linux2628_x86_64\" HAPROXY_LKL_BIN_URL=\"${BASE_URL}/bin/haproxy-lkl.sh\" HAPROXY_LKL_SERVICE_FILE_DEBIAN_URL=\"${BASE_URL}/startup/haproxy-lkl.init.debain\" HAPROXY_LKL_SERVICE_FILE_REDHAT_URL=\"${BASE_URL}/startup/haproxy-lkl.init.redhat\" HAPROXY_LKL_SYSTEMD_FILE_URL=\"${BASE_URL}/startup/haproxy-lkl.systemd\" LKL_LIB_URL=\"${BASE_URL}/lib64/liblkl-hijack.so-20170724\" LKL_LIB_MD5='b50fc6a7ccfc70c76f44506814e7e18b' # \u9700\u8981 BBR \u52a0\u901f\u7684\u7aef\u53e3 ACCELERATE_PORT= clear cat >&2 <<-'EOF' ####################################################### # OpenVZ BBR \u4e00\u952e\u5b89\u88c5\u811a\u672c # # \u8be5\u811a\u672c\u7528\u4e8e\u5728 OpenVZ \u670d\u52a1\u5668\u4e0a\u5b89\u88c5\u914d\u7f6e Google BBR # # \u811a\u672c\u4f5c\u8005: Xingwang Liao <kuoruan@gmail.com> # # \u4f5c\u8005\u535a\u5ba2: https://blog.kuoruan.com/ # # Github: https://github.com/kuoruan/shell-scripts # # QQ\u4ea4\u6d41\u7fa4: 43391448, 68133628 # # 633945405 # ####################################################### EOF command_exists() { command -v \"$@\" >/dev/null 2>&1 } check_root() { local user=\"$(id -un 2>/dev/null || true)\" if [ \"$user\" != \"root\" ]; then cat >&2 <<-'EOF' \u6743\u9650\u9519\u8bef, \u8bf7\u4f7f\u7528 root \u7528\u6237\u8fd0\u884c\u6b64\u811a\u672c! EOF exit 1 fi } check_ovz() { if [ ! -d /proc/vz ]; then cat >&2 <<-'EOF' \u5f53\u524d\u670d\u52a1\u5668\u597d\u50cf\u4e0d\u662f OpenVZ \u67b6\u6784\uff0c\u4f60\u53ef\u4ee5\u76f4\u63a5\u66f4\u6362\u5185\u6838\u4ee5\u542f\u7528 BBR\u3002 \u5f53\u7136\uff0c\u4f60\u4e5f\u53ef\u4ee5\u7ee7\u7eed\u5b89\u88c5\u3002 EOF any_key_to_continue fi } check_ldd() { local ldd_version=\"$(ldd --version 2>/dev/null | grep 'ldd' | rev | cut -d ' ' -f1 | rev)\" if [ -n \"$ldd_version\" ]; then if [ \"${ldd_version%.*}\" -eq \"2\" -a \"${ldd_version#*.}\" -lt \"14\" ] || \\ [ \"${ldd_version%.*}\" -lt \"2\" ]; then cat >&2 <<-EOF \u5f53\u524d\u670d\u52a1\u5668\u7684 glibc \u7248\u672c\u4e3a $ldd_version\u3002 \u6700\u4f4e\u7248\u672c\u9700\u6c42 2.14\uff0c\u4f4e\u4e8e\u8fd9\u4e2a\u7248\u672c\u65e0\u6cd5\u6b63\u5e38\u4f7f\u7528\u3002 \u8bf7\u5148\u66f4\u65b0 glibc \u4e4b\u540e\u518d\u8fd0\u884c\u811a\u672c\u3002 EOF exit 1 fi else cat >&2 <<-EOF \u83b7\u53d6 glibc \u7248\u672c\u5931\u8d25\uff0c\u8bf7\u624b\u52a8\u68c0\u67e5\uff1a ldd --version \u6700\u4f4e\u7248\u672c\u9700\u6c42 2.14\uff0c\u4f4e\u4e8e\u8fd9\u4e2a\u7248\u672c\u53ef\u80fd\u65e0\u6cd5\u6b63\u5e38\u4f7f\u7528\u3002 EOF ( set -x; ldd --version 2>/dev/null ) any_key_to_continue fi } check_arch() { architecture=$(uname -m) case $architecture in amd64|x86_64) ;; *) cat 1>&2 <<-EOF \u5f53\u524d\u811a\u672c\u4ec5\u652f\u6301 64 \u4f4d\u7cfb\u7edf\uff0c\u4f60\u7684\u7cfb\u7edf\u4e3a: $architecture \u4f60\u53ef\u4ee5\u5c1d\u8bd5\u4ece\u6e90\u7801\u7f16\u8bd1\u5b89\u88c5 Linux Kernel Library https://github.com/lkl/linux EOF exit 1 ;; esac } any_key_to_continue() { echo \"\u8bf7\u6309\u4efb\u610f\u952e\u7ee7\u7eed\u6216 Ctrl + C \u9000\u51fa\" local saved=\"$(stty -g)\" stty -echo stty cbreak dd if=/dev/tty bs=1 count=1 2> /dev/null stty -raw stty echo stty $saved } get_os_info() { lsb_dist='' dist_version='' if command_exists lsb_release; then lsb_dist=\"$(lsb_release -si)\" fi if [ -z \"$lsb_dist\" ] && [ -r /etc/lsb-release ]; then lsb_dist=\"$(. /etc/lsb-release && echo \"$DISTRIB_ID\")\" fi if [ -z \"$lsb_dist\" ] && [ -r /etc/debian_version ]; then lsb_dist='debian' fi if [ -z \"$lsb_dist\" ] && [ -r /etc/fedora-release ]; then lsb_dist='fedora' fi if [ -z \"$lsb_dist\" ] && [ -r /etc/oracle-release ]; then lsb_dist='oracleserver' fi if [ -z \"$lsb_dist\" ] && [ -r /etc/centos-release ]; then lsb_dist='centos' fi if [ -z \"$lsb_dist\" ] && [ -r /etc/redhat-release ]; then lsb_dist='redhat' fi if [ -z \"$lsb_dist\" ] && [ -r /etc/photon-release ]; then lsb_dist='photon' fi if [ -z \"$lsb_dist\" ] && [ -r /etc/os-release ]; then lsb_dist=\"$(. /etc/os-release && echo \"$ID\")\" fi lsb_dist=\"$(echo \"$lsb_dist\" | tr '[:upper:]' '[:lower:]')\" if [ \"${lsb_dist}\" = \"redhatenterpriseserver\" ]; then lsb_dist='redhat' fi case \"$lsb_dist\" in ubuntu) if command_exists lsb_release; then dist_version=\"$(lsb_release --codename | cut -f2)\" fi if [ -z \"$dist_version\" ] && [ -r /etc/lsb-release ]; then dist_version=\"$(. /etc/lsb-release && echo \"$DISTRIB_CODENAME\")\" fi ;; debian|raspbian) dist_version=\"$(cat /etc/debian_version | sed 's/\\/.*//' | sed 's/\\..*//')\" case \"$dist_version\" in 9) dist_version=\"stretch\" ;; 8) dist_version=\"jessie\" ;; 7) dist_version=\"wheezy\" ;; esac ;; oracleserver) lsb_dist=\"oraclelinux\" dist_version=\"$(rpm -q --whatprovides redhat-release --queryformat \"%{VERSION}\\n\" | sed 's/\\/.*//' | sed 's/\\..*//' | sed 's/Server*//')\" ;; fedora|centos|redhat) dist_version=\"$(rpm -q --whatprovides ${lsb_dist}-release --queryformat \"%{VERSION}\\n\" | sed 's/\\/.*//' | sed 's/\\..*//' | sed 's/Server*//' | sort | tail -1)\" ;; \"vmware photon\") lsb_dist=\"photon\" dist_version=\"$(. /etc/os-release && echo \"$VERSION_ID\")\" ;; *) if command_exists lsb_release; then dist_version=\"$(lsb_release --codename | cut -f2)\" fi if [ -z \"$dist_version\" ] && [ -r /etc/os-release ]; then dist_version=\"$(. /etc/os-release && echo \"$VERSION_ID\")\" fi ;; esac if [ -z \"$lsb_dist\" -o -z \"$dist_version\" ]; then cat >&2 <<-EOF \u65e0\u6cd5\u786e\u5b9a\u670d\u52a1\u5668\u7cfb\u7edf\u7248\u672c\u4fe1\u606f\u3002 \u8bf7\u8054\u7cfb\u811a\u672c\u4f5c\u8005\u3002 EOF exit 1 fi } install_deps() { ip_support_tuntap() { command_exists ip && ip tuntap >/dev/null 2>&1 } case \"$lsb_dist\" in ubuntu|debian|raspbian) local did_apt_get_update= apt_get_update() { if [ -z \"$did_apt_get_update\" ]; then ( set -x; sleep 3; apt-get update ) did_apt_get_update=1 fi } if ! command_exists wget; then apt_get_update ( set -x; sleep 3; apt-get install -y -q wget ca-certificates ) fi if ! command_exists ip; then apt_get_update ( set -x; sleep 3; apt-get install -y -q iproute ) fi if ! command_exists timeout; then apt_get_update ( set -x; sleep 3; apt-get install -y -q coreutils ) fi if ! command_exists iptables; then apt_get_update ( set -x; sleep 3; apt-get install -y -q iptables ) fi if ! ip_support_tuntap; then apt_get_update ( set -x; sleep 3; apt-get install -y -q uml-utilities ) fi ;; fedora|centos|redhat|oraclelinux|photon) if [ \"$lsb_dist\" = \"fedora\" ] && [ \"$dist_version\" -ge \"22\" ]; then if ! command_exists wget; then ( set -x; sleep 3; dnf -y -q install wget ca-certificates ) fi if ! command_exists ip; then ( set -x; sleep 3; dnf -y -q install iproute ) fi if ! command_exists timeout; then ( set -x; sleep 3; dnf -y -q install coreutils ) fi if ! command_exists iptables; then ( set -x; sleep 3; dnf -y -q install iptables ) fi if ! ip_support_tuntap && ! command_exists tunctl; then ( set -x; sleep 3; dnf -y -q install tunctl ) fi elif [ \"$lsb_dist\" = \"photon\" ]; then if ! command_exists wget; then ( set -x; sleep 3; tdnf -y install wget ca-certificates ) fi if ! command_exists ip; then ( set -x; sleep 3; tdnf -y install iproute ) fi if ! command_exists timeout; then ( set -x; sleep 3; tdnf -y install coreutils ) fi if ! command_exists iptables; then ( set -x; sleep 3; tdnf -y install iptables ) fi if ! ip_support_tuntap && ! command_exists tunctl; then ( set -x; sleep 3; tdnf -y install tunctl ) fi else if ! command_exists wget; then ( set -x; sleep 3; yum -y -q install wget ca-certificates ) fi if ! command_exists ip; then ( set -x; sleep 3; yum -y -q install iproute ) fi if ! command_exists timeout; then ( set -x; sleep 3; yum -y -q install coreutils ) fi if ! command_exists iptables firewall-cmd; then ( set -x; sleep 3; yum -y -q install iptables ) fi if ! ip_support_tuntap && ! command_exists tunctl; then ( set -x; sleep 3; yum -y -q install tunctl ) fi fi ;; *) cat >&2 <<-EOF \u6682\u65f6\u4e0d\u652f\u6301\u5f53\u524d\u7cfb\u7edf\uff1a${lsb_dist} ${dist_version} EOF exit 1 ;; esac } check_nat_create() { if ( command_exists ip && ip tuntap >/dev/null 2>&1 ); then ( set -x ip tuntap del dev lkl-tap-test mode tap >/dev/null 2>&1 ip tuntap add dev lkl-tap-test mode tap ) elif command_exists tunctl; then ( set -x tunctl -d lkl-tap-test >/dev/null 2>&1 tunctl -t lkl-tap-test ) else cat >&2 <<-'EOF' \u65e0\u6cd5\u627e\u5230\u5df2\u5b89\u88c5\u7684 ip \u547d\u4ee4(\u652f\u6301 tuntap) \u6216\u8005 tunctl \u5e94\u8be5\u662f\u811a\u672c\u81ea\u52a8\u5b89\u88c5\u5931\u8d25\u4e86\u3002 \u8bf7\u624b\u52a8\u5b89\u88c5 iproute \u548c tunctl EOF exit 1 fi if [ \"$?\" != \"0\" ]; then cat >&2 <<-'EOF' \u65e0\u6cd5\u521b\u5efa NAT \u7f51\u7edc\u3002 \u7531\u4e8e\u67d0\u4e9b\u670d\u52a1\u5546\u7684 VPS \u65e0\u6cd5\u521b\u5efa NAT \u7f51\u7edc\uff0c \u6240\u4ee5\u4e0d\u652f\u6301\u7528\u6b64\u65b9\u6cd5\u5f00\u542f BBR\uff0c\u5b89\u88c5\u811a\u672c\u5c06\u4f1a\u9000\u51fa\u3002 EOF exit 1 fi } download_file() { local url=$1 local file=$2 ( set -x; wget -O \"$file\" --no-check-certificate \"$url\" ) if [ \"$?\" != \"0\" ]; then cat >&2 <<-EOF \u4e00\u4e9b\u6587\u4ef6\u4e0b\u8f7d\u5931\u8d25\uff01\u5b89\u88c5\u811a\u672c\u9700\u8981\u80fd\u8bbf\u95ee\u5230 github.com\uff0c\u8bf7\u68c0\u67e5\u670d\u52a1\u5668\u7f51\u7edc\u3002 \u6ce8\u610f: \u4e00\u4e9b\u56fd\u5185\u670d\u52a1\u5668\u53ef\u80fd\u65e0\u6cd5\u6b63\u5e38\u8bbf\u95ee github.com\u3002 EOF exit 1 fi } install_haproxy() { ( set -x mkdir -p \"${HAPROXY_LKL_DIR}\"/etc \\ \"${HAPROXY_LKL_DIR}\"/lib64 \\ \"${HAPROXY_LKL_DIR}\"/sbin ) if ! grep -q '^haproxy:' '/etc/passwd'; then ( set -x useradd -U -s '/usr/sbin/nologin' -d '/nonexistent' haproxy 2>/dev/null ) fi local haproxy_bin=\"${HAPROXY_LKL_DIR}/sbin/haproxy\" download_file \"$HAPROXY_BIN_URL\" \"$haproxy_bin\" chmod +x \"$haproxy_bin\" if ! ( $haproxy_bin -v 2>/dev/null | grep -q 'HA-Proxy' ); then cat >&2 <<-EOF HAproxy \u53ef\u6267\u884c\u6587\u4ef6\u65e0\u6cd5\u6b63\u5e38\u8fd0\u884c \u53ef\u80fd\u662f glibc \u7248\u672c\u8fc7\u4f4e\uff0c\u6216\u8005\u6587\u4ef6\u4e0d\u9002\u7528\u4e8e\u4f60\u7684\u7cfb\u7edf\u3002 \u8bf7\u8054\u7cfb\u811a\u672c\u4f5c\u8005\uff0c\u5bfb\u6c42\u652f\u6301\u3002 EOF ( set -x ldd --version ) exit 1 fi local haproxy_lkl_bin=\"${HAPROXY_LKL_DIR}/sbin/${SERVICE_NAME}\" download_file \"$HAPROXY_LKL_BIN_URL\" \"$haproxy_lkl_bin\" sed -i -r \"s#^HAPROXY_LKL_DIR=.*#HAPROXY_LKL_DIR='\"${HAPROXY_LKL_DIR}\"'#\" \\ \"$haproxy_lkl_bin\" set_interface() { local has_vnet=0 if command_exists ip; then ip -o link show | grep -q 'venet0' has_vnet=$? elif command_exists ifconfig; then ifconfig -s | grep -q 'venet0' has_vnet=$? fi if [ \"$has_vnet\" != 0 ]; then cat >&2 <<-EOF \u68c0\u6d4b\u53d1\u73b0\u4f60\u7684\u516c\u7f51\u63a5\u53e3\u4e0d\u662f venet0\uff0c\u9700\u8981\u4f60\u624b\u52a8\u8f93\u5165\u4e00\u4e0b\u7f51\u7edc\u63a5\u53e3\u540d\u79f0\u3002 \u6211\u4eec\u4f1a\u6839\u636e\u7f51\u7edc\u63a5\u53e3\u8bbe\u7f6e\u8f6c\u53d1\u89c4\u5219\uff0c\u5982\u679c\u7f51\u7edc\u63a5\u53e3\u540d\u79f0\u8bbe\u7f6e\u4e0d\u6b63\u786e\uff0c \u5916\u90e8\u7f51\u7edc\u5c06\u65e0\u6cd5\u6b63\u5e38\u8bbf\u95ee\u5230\u5185\u90e8\u670d\u52a1\u7aef\u53e3\u3002 * \u7f51\u7edc\u63a5\u53e3\u662f\u5177\u6709\u516c\u7f51 IP \u7684\u63a5\u53e3\u540d\u79f0\u3002 \u4f60\u53ef\u4ee5\u4ece\u4e0b\u9762\u7684\u4fe1\u606f\u4e2d\u627e\u5230\u4f60\u7684\u516c\u7f51\u63a5\u53e3\u540d\u79f0: EOF if command_exists ip; then ip addr show else ifconfig fi local input= while : do read -p \"\u8bf7\u8f93\u5165\u4f60\u7684\u7f51\u7edc\u63a5\u53e3\u540d\u79f0(\u4f8b\u5982: eth0): \" input echo if [ -n \"$input\" ]; then sed -i -r \"s#^INTERFACE=.*#INTERFACE='\"${input}\"'#\" \"$haproxy_lkl_bin\" else echo \"\u8f93\u5165\u4fe1\u606f\u4e0d\u80fd\u4e3a\u7a7a\uff0c\u8bf7\u91cd\u65b0\u8f93\u5165\uff01\" continue fi break done fi } set_interface chmod +x \"$haproxy_lkl_bin\" local haproxy_lkl_startup_file= local haproxy_lkl_startup_file_url= if command_exists systemctl; then haproxy_lkl_startup_file=\"/lib/systemd/system/${SERVICE_NAME}.service\" haproxy_lkl_startup_file_url=\"${HAPROXY_LKL_SYSTEMD_FILE_URL}\" download_file \"$haproxy_lkl_startup_file_url\" \"$haproxy_lkl_startup_file\" elif command_exists service; then haproxy_lkl_startup_file=\"/etc/init.d/${SERVICE_NAME}\" case \"$lsb_dist\" in ubuntu|debian|raspbian) haproxy_lkl_startup_file_url=\"${HAPROXY_LKL_SERVICE_FILE_DEBIAN_URL}\" download_file \"$haproxy_lkl_startup_file_url\" \"$haproxy_lkl_startup_file\" chmod +x \"$haproxy_lkl_startup_file\" ;; fedora|centos|redhat|oraclelinux|photon) haproxy_lkl_startup_file_url=\"${HAPROXY_LKL_SERVICE_FILE_REDHAT_URL}\" download_file \"$haproxy_lkl_startup_file_url\" \"$haproxy_lkl_startup_file\" chmod +x \"$haproxy_lkl_startup_file\" ;; *) echo \"\u6ca1\u6709\u9002\u5408\u5f53\u524d\u7cfb\u7edf\u7684\u670d\u52a1\u542f\u52a8\u811a\u672c\u6587\u4ef6\u3002\" exit 1 ;; esac else cat >&2 <<-'EOF' \u5f53\u524d\u670d\u52a1\u5668\u672a\u5b89\u88c5 systemctl \u6216\u8005 service \u547d\u4ee4\uff0c\u65e0\u6cd5\u914d\u7f6e\u670d\u52a1\u3002 \u8bf7\u5148\u624b\u52a8\u5b89\u88c5 systemd \u6216\u8005 service \u4e4b\u540e\u518d\u8fd0\u884c\u811a\u672c\u3002 EOF exit 1 fi echo \"$ACCELERATE_PORT\" > \"${HAPROXY_LKL_DIR}/etc/port-rules\" } install_lkl_lib() { local lib_file=\"${HAPROXY_LKL_DIR}/lib64/liblkl-hijack.so\" local retry=0 download_lkl_lib() { download_file \"$LKL_LIB_URL\" \"$lib_file\" if command_exists md5sum; then ( set -x echo \"${LKL_LIB_MD5} ${lib_file}\" | md5sum -c ) if [ \"$?\" != \"0\" ]; then if [ \"$retry\" -lt \"3\" ]; then echo \"\u6587\u4ef6\u6821\u9a8c\u5931\u8d25\uff013 \u79d2\u540e\u91cd\u65b0\u4e0b\u8f7d...\" retry=`expr $retry + 1` sleep 3 download_lkl_lib else cat >&2 <<-EOF Linux \u5185\u6838\u6587\u4ef6\u6821\u9a8c\u5931\u8d25\u3002 \u901a\u5e38\u662f\u7f51\u7edc\u539f\u56e0\u9020\u6210\u6587\u4ef6\u4e0b\u8f7d\u4e0d\u5168\u3002 EOF exit 1 fi fi fi } download_lkl_lib chmod +x \"$lib_file\" } enable_ip_forward() { local ip_forword=\"$(sysctl -n 'net.ipv4.ip_forward' 2>/dev/null)\" if [ -z \"$ip_forword\" -o \"$ip_forword\" != \"1\" ]; then ( set -x echo \"net.ipv4.ip_forward = 1\" >> /etc/sysctl.conf sysctl -p /etc/sysctl.conf 2>/dev/null ) fi } set_config() { is_port() { local port=$1 expr $port + 1 >/dev/null 2>&1 && \\ [ \"$port\" -ge \"1\" -a \"$port\" -le \"65535\" ] } local input= if [ -z \"$ACCELERATE_PORT\" ] || ! is_port \"$ACCELERATE_PORT\"; then while : do read -p \"\u8bf7\u8f93\u5165\u9700\u8981\u52a0\u901f\u7684\u7aef\u53e3 [1~65535]: \" input echo if [ -n \"$input\" ] && is_port $input; then ACCELERATE_PORT=\"$input\" else echo \"\u8f93\u5165\u6709\u8bef, \u8bf7\u8f93\u5165 1~65535 \u4e4b\u95f4\u7684\u6570\u5b57!\" continue fi break done fi cat >&2 <<-EOF --------------------------- \u52a0\u901f\u7aef\u53e3 = ${ACCELERATE_PORT} --------------------------- EOF any_key_to_continue } is_running() { ( set -x sleep 3 # https://bugs.centos.org/view.php?id=12407 # ping may not work with IPv4 under OpenVZ on CentOS 7 # ping -q -c3 10.0.0.2 2>/dev/null timeout 2 bash -c \"</dev/tcp/10.0.0.2/${ACCELERATE_PORT}\" 2>/dev/null ) return $? } enable_service() { if command_exists systemctl; then ( set -x systemctl daemon-reload systemctl enable \"${SERVICE_NAME}.service\" ) elif command_exists service; then case \"$lsb_dist\" in ubuntu|debian|raspbian) ( set -x update-rc.d -f \"${SERVICE_NAME}\" defaults ) ;; fedora|centos|redhat|oraclelinux|photon) ( set -x chkconfig --add \"${SERVICE_NAME}\" chkconfig \"${SERVICE_NAME}\" on ) ;; esac fi } start_service() { if command_exists systemctl; then ( set -x sleep 3 systemctl start \"$SERVICE_NAME\" ) else ( set -x sleep 3 service \"$SERVICE_NAME\" start ) fi if [ \"$?\" != \"0\" ] || ! is_running; then do_uninstall cat >&2 <<-EOF \u5f88\u9057\u61be\uff0c\u670d\u52a1\u542f\u52a8\u5931\u8d25\u3002 \u4f60\u53ef\u4ee5\u67e5\u770b\u4e0a\u9762\u7684\u65e5\u5fd7\u6765\u83b7\u53d6\u539f\u56e0\uff0c \u6216\u8005\uff0c\u4f60\u53ef\u4ee5\u5230\u6211\u4eec\u7684\u7fa4\u91cc\u53cd\u9988\u4e00\u4e0b\u3002 EOF exit 1 fi } end_install() { clear cat >&2 <<-EOF \u606d\u559c\uff01BBR \u5b89\u88c5\u5b8c\u6210\u5e76\u6210\u529f\u542f\u52a8 \u5df2\u52a0\u901f\u7684\u7aef\u53e3: ${ACCELERATE_PORT} \u4f60\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539\u6587\u4ef6: ${HAPROXY_LKL_DIR}/etc/port-rules \u6765\u914d\u7f6e\u9700\u8981\u52a0\u901f\u7684\u7aef\u53e3\u6216\u7aef\u53e3\u8303\u56f4\u3002 EOF if command_exists systemctl; then cat >&2 <<-EOF \u8bf7\u4f7f\u7528 systemctl {start|stop|restart} ${SERVICE_NAME} \u6765 {\u5f00\u542f|\u5173\u95ed|\u91cd\u542f} \u670d\u52a1 EOF else cat >&2 <<-EOF \u8bf7\u4f7f\u7528 service ${SERVICE_NAME} {start|stop|restart} \u6765 {\u5f00\u542f|\u5173\u95ed|\u91cd\u542f} \u670d\u52a1 EOF fi cat >&2 <<-EOF \u670d\u52a1\u5df2\u81ea\u52a8\u52a0\u5165\u5f00\u673a\u542f\u52a8\uff0c\u8bf7\u653e\u5fc3\u4f7f\u7528\u3002 \u5982\u679c\u8fd9\u4e2a\u811a\u672c\u5e2e\u5230\u4e86\u4f60\uff0c\u4f60\u53ef\u4ee5\u8bf7\u4f5c\u8005\u559d\u74f6\u53ef\u4e50: https://blog.kuoruan.com/donate \u4eab\u53d7\u52a0\u901f\u7684\u5feb\u611f\u5427\uff01 EOF } do_uninstall() { check_root get_os_info if command_exists systemctl; then systemctl stop \"${SERVICE_NAME}.service\" 2>/dev/null ( set -x systemctl disable \"${SERVICE_NAME}.service\" 2>/dev/null rm -f \"/lib/systemd/system/${SERVICE_NAME}.service\" ) elif command_exists service; then service \"${SERVICE_NAME}\" stop 2>/dev/null case \"$lsb_dist\" in ubuntu|debian|raspbian) ( set -x update-rc.d -f \"${SERVICE_NAME}\" remove 2>/dev/null ) ;; fedora|centos|redhat|oraclelinux|photon) ( set -x chkconfig \"${SERVICE_NAME}\" off 2>/dev/null chkconfig --del \"${SERVICE_NAME}\" 2>/dev/null ) ;; esac ( set -x rm -f \"/etc/init.d/${SERVICE_NAME}\" ) fi ( set -x ${HAPROXY_LKL_DIR}/sbin/${SERVICE_NAME} -c 2>/dev/null rm -rf \"${HAPROXY_LKL_DIR}\" ) } do_install() { check_root check_ovz check_ldd check_arch get_os_info set_config install_deps enable_ip_forward check_nat_create install_haproxy install_lkl_lib start_service enable_service end_install } action=${1:-\"install\"} case \"$action\" in install|uninstall) do_${action} ;; *) cat >&2 <<-EOF \u53c2\u6570\u6709\u8bef\uff0c\u8bf7\u4f7f\u7528 $(basename $0) install|uninstall EOF exit 255 esac"
        },
        {
            "filename": "file_634.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell-scripts\\ovz-bbr\\bin\\file_634.sh",
            "content": "#!/bin/sh : <<-'EOF' Copyright 2017 Xingwang Liao <kuoruan@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. EOF INTERFACE='venet0' HAPROXY_LKL_DIR='/usr/local/haproxy-lkl' LKL_TAP_NAME='lkl' LKL_IN_CHAIN_NAME='LKL_IN' HAPROXY_CFG_FILE=\"${HAPROXY_LKL_DIR}/etc/haproxy.cfg\" PIDFILE= LOGFILE='/dev/null' RETVAL=0 usage() { cat >&2 <<-EOF Usage: $(basename $0) [options] Valid options are: -p <pidfile> Writes pid to this file -l <logfile> Writes log to this file -c Clear haproxy-lkl iptables rules -h Show this help message EOF exit $1 } command_exists() { command -v \"$@\" >/dev/null 2>&1 } make_file_dir() { local file=\"$1\" local dir=\"$(dirname $file)\" if [ ! -d \"$dir\" ]; then mkdir -p \"$dir\" 2>/dev/null fi touch \"$file\" 2>/dev/null } pre_check() { if [ -z \"$INTERFACE\" ]; then cat >&2 <<-EOF Error: Please set your network interface first. * Edit $0 and set INTERFACE at the top. EOF exit 1 fi if [ -z \"$HAPROXY_LKL_DIR\" ]; then cat >&2 <<-EOF Error: Please set your haproxy lkl install dir first. * Edit $0 and set HAPROXY_LKL_DIR at the top. * Default is /usr/local/haproxy-lkl EOF exit 1 fi notice_wrong_interface() { cat >&2 <<-EOF Error: You have set a wrong network interface. * Edit $0 and reset the INTERFACE at the top. EOF exit 1 } if command_exists ip; then if ! ( ip -o link show | grep -q \"$INTERFACE\" ); then notice_wrong_interface fi elif command_exists ifconfig; then if ! ( ifconfig -s | grep -q \"$INTERFACE\" ); then notice_wrong_interface fi else cat >&2 <<-'EOF' Error: Can't find command ip or ifconfig. Please install first. EOF exit 1 fi if ! command_exists iptables; then cat >&2 <<-'EOF' Error: Can't find iptables. Please install first. EOF exit 1 fi } clear_iptables_rules() { iptables -t nat -D PREROUTING -i ${INTERFACE} -j ${LKL_IN_CHAIN_NAME} 2>/dev/null iptables -t nat -F ${LKL_IN_CHAIN_NAME} 2>/dev/null iptables -t nat -X ${LKL_IN_CHAIN_NAME} 2>/dev/null } set_network() { if ( command_exists ip && ip tuntap >/dev/null 2>&1 ); then ip tuntap del dev ${LKL_TAP_NAME} mode tap 2>/dev/null ip tuntap add dev ${LKL_TAP_NAME} mode tap 2>/dev/null elif command_exists tunctl; then tunctl -d ${LKL_TAP_NAME} >/dev/null 2>&1 tunctl -t ${LKL_TAP_NAME} -u haproxy >/dev/null 2>&1 else cat >&2 <<-'EOF' Error: Can't find command ip (with tuntap) or tunctl. Please install first. EOF exit 1 fi if command_exists ip; then ip addr add dev ${LKL_TAP_NAME} 10.0.0.1/24 2>/dev/null ip link set dev ${LKL_TAP_NAME} up 2>/dev/null elif command_exists ifconfig; then ifconfig ${LKL_TAP_NAME} 10.0.0.1 netmask 255.255.255.0 up fi clear_iptables_rules iptables -P FORWARD ACCEPT 2>/dev/null iptables -t nat -N ${LKL_IN_CHAIN_NAME} 2>/dev/null iptables -t nat -A PREROUTING -i ${INTERFACE} -j ${LKL_IN_CHAIN_NAME} 2>/dev/null } generate_config() { local port_rules_file=\"${HAPROXY_LKL_DIR}/etc/port-rules\" if [ ! -r \"$port_rules_file\" ]; then cat >&2 <<-EOF Error: Can't read port rules file: ${port_rules_file} Please check. EOF exit 1 fi local port_rule_lines=\"$(grep -v '^#' ${port_rules_file} | \\ sed 's/[[:space:]]//g' | sed '/^$/d' 2>/dev/null)\" if [ -z \"$port_rule_lines\" ]; then cat >&2 <<-EOF Error: Can't find rules in your port rules file: ${port_rules_file} Please check. EOF exit 1 fi touch \"$HAPROXY_CFG_FILE\" 2>/dev/null if [ ! -w \"$HAPROXY_CFG_FILE\" ]; then cat >&2 <<-EOF Error: Can't create HAproxy config file or we don't have write permission to file: ${HAPROXY_CFG_FILE} Please check. EOF exit 1 fi cat >\"$HAPROXY_CFG_FILE\" <<-EOF # Autogenerate by port rules file # Config will lost after restart haproxy-lkl # Do not edit this file. global user haproxy group haproxy defaults mode tcp timeout connect 5s timeout client 30s timeout server 30s backend local server srv 10.0.0.1 EOF local legal_rules= local i=0 add_rule() { local ports=\"$1\" legal_rules=\"$(printf \"%s\\n%s\" \"${legal_rules}\" \"${ports}\")\" i=`expr $i + 1` cat >>\"$HAPROXY_CFG_FILE\" <<-EOF frontend proxy-${i} bind 10.0.0.2:${ports} default_backend local EOF iptables -t nat -A ${LKL_IN_CHAIN_NAME} -p tcp \\ --dport \"$(echo \"$ports\" | tr '-' ':')\" -j DNAT \\ --to-destination 10.0.0.2 2>/dev/null } is_port() { local port=$1 `expr $port + 1 >/dev/null 2>&1` && \\ [ \"$port\" -ge \"1\" -a \"$port\" -le \"65535\" ] return $? } local start_port= local end_port= for line in $port_rule_lines; do start_port=\"$(echo $line | cut -d '-' -f1)\" end_port=\"$(echo $line | cut -d '-' -f2)\" if [ -n \"$start_port\" -a -n \"$end_port\" ]; then if ( is_port \"$start_port\" && is_port \"$end_port\" ); then add_rule \"$line\" fi elif [ -n \"$start_port\" ]; then if is_port \"$start_port\"; then add_rule \"$start_port\" fi fi done if [ \"$i\" = \"0\" ]; then cat >&2 <<-EOF Error: Port rules file format error Please check ${port_rules_file} EOF exit 1 fi if [ -w \"$port_rules_file\" ]; then cat >\"$port_rules_file\" <<-EOF # You can config HAproxy-lkl ports in this file. # Eg. 8800 or 8800-8810 # It is the port(s) you want accelerate. # One port(port range) per line. ${legal_rules} EOF fi } start_haproxy_lkl() { local haproxy_bin=\"${HAPROXY_LKL_DIR}/sbin/haproxy\" local lkl_lib=\"${HAPROXY_LKL_DIR}/lib64/liblkl-hijack.so\" if [ ! -f \"$haproxy_bin\" ]; then cat >&2 <<-EOF Error: Can't find haproxy bin. Please put haproxy in $(dirname ${haproxy_bin}) EOF exit 1 fi if [ ! -f \"$lkl_lib\" ]; then cat >&2 <<-EOF Error: Can't find Linux kernel library. Please put liblkl-hijack.so in $(dirname ${lkl_lib}) EOF exit 1 fi if [ ! -s \"$HAPROXY_CFG_FILE\" ]; then cat >&2 <<-EOF Error: HAproxy config file is empty. May be insufficient disk space. ${HAPROXY_CFG_FILE} EOF exit 1 fi [ ! -x \"$haproxy_bin\" ] && chmod +x \"$haproxy_bin\" LD_PRELOAD=\"$lkl_lib\" \\ LKL_HIJACK_NET_QDISC='root|fq' \\ LKL_HIJACK_SYSCTL='net.ipv4.tcp_wmem=4096 65536 67108864' \\ LKL_HIJACK_NET_IFTYPE=tap \\ LKL_HIJACK_NET_IFPARAMS=\"$LKL_TAP_NAME\" \\ LKL_HIJACK_NET_IP=10.0.0.2 \\ LKL_HIJACK_NET_NETMASK_LEN=24 \\ LKL_HIJACK_NET_GATEWAY=10.0.0.1 \\ LKL_HIJACK_OFFLOAD=0x8883 \\ $haproxy_bin -f \"$HAPROXY_CFG_FILE\" >\"$LOGFILE\" 2>&1 & } do_start() { pre_check set_network generate_config local pid= start_haproxy_lkl && pid=$! || RETVAL=$? if [ -n \"$pid\" -a -n \"$PIDFILE\" ]; then echo \"$pid\" >\"$PIDFILE\" 2>/dev/null fi } while getopts \"p:l:hc\" opt; do case \"$opt\" in c) clear_iptables_rules exit 0 ;; p) if [ -n \"$OPTARG\" ]; then PIDFILE=\"$OPTARG\" make_file_dir \"$PIDFILE\" fi ;; l) if [ -n \"$OPTARG\" ]; then LOGFILE=\"$OPTARG\" make_file_dir \"$LOGFILE\" fi ;; h) usage 0 ;; [?]) usage 1 ;; esac done do_start exit $RETVAL"
        },
        {
            "filename": "file_635.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\ShellScripting_Automation\\file_635.sh",
            "content": "#!/bin/sh CICD=true WORKSPACE=/opt/ JOB_BASE_NAME=Test_demo BUILD_NUMBER=10 if [ $CICD = true ] then echo \"CI/CD pipe line check\" file=\"${WORKSPACE}/basic_report.html\" REPORTNAME=${JOB_BASE_NAME}_${BUILD_NUMBER}.Test_demo_10 echo \"CICD Check starting\" if [ -f \"$file\" ]; then echo \"testReport file found sending to artifactory\" #curl -H X-JFrog-Art-Api:Token -T $file https://oneartifactorycloud/artifactory/CICD/Reports/$REPORTNAME.html else echo \"testReport file not found\" fi fi"
        },
        {
            "filename": "file_636.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\ShellScripting_Automation\\file_636.sh",
            "content": "#!/bin/bash version=\"1.2.3.4\" for line in $(cat jiraid.txt) do curl -X PUT -u \"your_atlassian_jira_username:your_atlassian_jira_token\" --data '{\"update\":{\"labels\":[{\"add\":\"DEMO_NEW\"}]}}' -H \"Content-Type: application/json\" https://singam.atlassian.net/rest/api/3/issue/$line done"
        },
        {
            "filename": "file_637.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\ShellScripting_Automation\\file_637.sh",
            "content": "#!/bin/bash array=(helloservice hiservice nameservice managerservice teamservice) for line in \"${array[@]}\" do COUNT=`ps -ef | grep helloservice | grep -v grep | wc -l`. RUNNING , 3 MAX=2 echo $line echo $COUNT if [ $COUNT -gt $MAX ] then echo $line PROCS=`ps -ef| grep $line | grep -v grep | awk '{print $2, $11, $12, $13}' | sort -k 4` JAR=`echo \"${PROCS}\" | awk -F\"-Djar_name=| \" '{print $5}'` echo $JAR JAR_RUN=`echo $JAR | sed 's/ /,/g'` echo $JAR_RUN cd /apps/nnos/test/scripts ./mail.sh $line $JAR_RUN $COUNT fi done"
        },
        {
            "filename": "file_638.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\ShellScripting_Automation\\file_638.sh",
            "content": "#!/bin/bash cd /opt/logs/ find . -type f -name '*log*' -exec cp '{}' /opt/logs/Log_Backup \\; cd /opt/logs/Log_Backup find /opt/logs/Log_Backup -type f -name '*log*' > include-file tar -cvf $(hostname)_$(date +%Y-%m-%d).tar.gz -T include-file exit"
        },
        {
            "filename": "file_639.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\ShellScripting_Automation\\file_639.sh",
            "content": "#!/bin/bash may_date=`date -d '2023-04-01 +30 days' '+%Y-%m-%d'` echo $may_date TWO=2 april_date=`date -d '2023-04-03 -2 days' '+%Y-%m-%d'` echo $april_date"
        },
        {
            "filename": "file_640.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\ShellScripting_Automation\\file_640.sh",
            "content": "/usr/sbin/sendmail -i -t << Subject: $1 server process status From: To: Hi Team, Please check for $1 service in TEST server which has $3 process running with below list of KIT IDs $2 Regards, ShineInCareer MESSAGE_END"
        },
        {
            "filename": "file_641.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\ShellScripting_Automation\\file_641.sh",
            "content": "#SEND AN EMAIL TO TEAM AFTER THE VERSION IS INCREMENTED cat > jira.html <<'EOF' <html> <body> <p><strong>MODULE_VERSION - {{module_version}}</strong></p> <table border=\"1\" cellspacing=\"0\" cellpadding=\"2.5\" valign=\"top\" width=\"100%\" align=\"justify\" style=\"width: 100%; max-width: 1200px; background-color: #ffffff\"> <tr> <th>Key</th> </tr> EOF # MULTIPLE FILES READ paste jiraid.txt version.txt | while read take; do cat >> jira.html <<EOF <tr> <td>$read</td> <td>$take</td> </tr> EOF done"
        },
        {
            "filename": "file_642.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\ShellScripting_Automation\\file_642.sh",
            "content": "#!/bin/bash # Function to check if Docker is installed checkDockerInstalled() { if ! command -v docker &>/dev/null; then echo \"Docker is not installed.\" return 1 else echo \"Docker is already installed.\" return 0 fi } # Function to install Docker installDocker() { if ! checkDockerInstalled; then echo \"##############################################################################################################################\" echo \"Docker is an open platform for developing, shipping, and running applications.\" echo \"It enables you to separate your applications from your infrastructure so you can deliver software quickly.\" echo \"\" echo \"Please select your operating system/distribution to install Docker:\" echo \"##############################################################################################################################\" echo \"\" PS3=\"Select your OS/Distribution: \" select os_option in \\ \"Ubuntu 20.04 or 22.04\" \\ \"Debian\" \\ \"CentOS\" \\ \"Fedora\" \\ \"Amazon Linux\" \\ \"OpenSUSE\" \\ \"Quit\" do case $REPLY in 1) installDockerUbuntu ;; 2) installDockerDebian ;; 3) installDockerCentOS ;; 4) installDockerFedora ;; 5) installDockerAmazonLinux ;; 6) installDockerOpenSUSE ;; 7) exit ;; *) echo \"Invalid selection, please try again...\" ;; esac done else echo \"Exiting script as Docker is already installed.\" exit 0 fi } # Function to install Docker on Ubuntu installDockerUbuntu() { clear echo \"Installing Docker on Ubuntu...\" sudo apt update sudo apt install -y docker.io echo \"Docker installed successfully!\" exit 0 } # Function to install Docker on Debian installDockerDebian() { clear echo \"Installing Docker on Debian...\" sudo apt update sudo apt install -y docker.io echo \"Docker installed successfully!\" exit 0 } # Function to install Docker on CentOS installDockerCentOS() { clear echo \"Installing Docker on CentOS...\" sudo yum install -y docker sudo systemctl start docker sudo systemctl enable docker echo \"Docker installed successfully!\" exit 0 } # Function to install Docker on Fedora installDockerFedora() { clear echo \"Installing Docker on Fedora...\" sudo dnf install -y docker sudo systemctl start docker sudo systemctl enable docker echo \"Docker installed successfully!\" exit 0 } # Function to install Docker on Amazon Linux installDockerAmazonLinux() { clear echo \"Installing Docker on Amazon Linux...\" sudo yum install -y docker sudo systemctl start docker sudo systemctl enable docker echo \"Docker installed successfully!\" exit 0 } # Function to install Docker on OpenSUSE installDockerOpenSUSE() { clear echo \"Installing Docker on OpenSUSE...\" sudo zypper install -y docker sudo systemctl start docker sudo systemctl enable docker echo \"Docker installed successfully!\" exit 0 } # Call the installDocker function to start the installation process installDocker"
        },
        {
            "filename": "file_643.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\ShellScripting_Automation\\file_643.sh",
            "content": "#!/bin/sh curl -X PUT -u \"singampallipraveenkumar@gmail.com:XkO2YJUvaof4fsvLAqtM63EA\"--data '{\"update\":{\"labels\":[{\"add\":\"DEMO\"}]}}' --header \"Content-Type: application/json\" \"Authorization: Basic XkO2YJUvaof4fsvLAqtM63EA\" https://singam.atlassian.net/rest/api/3/issue/SA-1"
        },
        {
            "filename": "file_644.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\ShellScripting_Automation\\file_644.sh",
            "content": "Hi Hello how are you This is devops course From Singam My manager is good Manager is able to manage all things version=1.2.3.4 tenth session will be handson"
        },
        {
            "filename": "file_645.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_645.sh",
            "content": "echo \"We are trying this practical from linux EC2\" echo \"We are from batch-25 and learning git/gihub\""
        },
        {
            "filename": "file_646.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_646.sh",
            "content": "#!/bin/bash #this script is for if-elif-fi echo \"Please enter value of a\" read a echo \"Please enter vaule of b\" read b if [ $a == $b ] then echo \"a is equal to b\" elif [ $a -gt $b ] then echo \"a is greater than b\" elif [ $a -lt $b ] then echo \"a is less than b\" else echo \"None of the condition met\" fi echo \"I have changed this branch\""
        },
        {
            "filename": "file_647.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_647.sh",
            "content": "#!/bin/bash a=\"abc\" b=\"efg\" if [ $a = $b ] then echo \"$a = $b : a is equal to b\" else echo \"$a != $b: a is not equal to b\" fi if [ $a != $b ] then echo \"$a != $b : a is not equal to b\" else echo \"$a = $b: a is equal to b\" fi if [ -z $a ] then echo \"-z $a : string length is zero\" else echo \"-z $a : string length is not zero\" fi if [ -n $a ] then echo \"-n $a : string length is not zero\" else echo \"-n $a : string length is zero\" fi"
        },
        {
            "filename": "file_648.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_648.sh",
            "content": "#!/bin/sh echo \"Please enter the vaule of a\" read a echo \"Please enter the vaule of b\" read b if [ $a != $b ] then echo \"$a != $b : a is not equal to b\" else echo \"$a = $b: a is equal to b\" fi if [ $a -lt 100 -a $b -gt 15 ] then echo \"$a -lt 100 -a $b -gt 15 : returns true\" else echo \"$a -lt 100 -a $b -gt 15 : returns false\" fi if [ $a -lt 100 -o $b -gt 100 ] then echo \"$a -lt 100 -o $b -gt 100 : returns true\" else echo \"$a -lt 100 -o $b -gt 100 : returns false\" fi if [ $a -lt 5 -o $b -gt 100 ] then echo \"$a -lt 100 -o $b -gt 100 : returns true\" else echo \"$a -lt 100 -o $b -gt 100 : returns false\" fi"
        },
        {
            "filename": "file_649.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_649.sh",
            "content": "#!/bin/sh for i in 1 2 3 4 5 do echo \"Looping ... number $i\" done"
        },
        {
            "filename": "file_650.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_650.sh",
            "content": "#!/bin/bash i=1 for day in Mon Tue Wed Thu Fri do echo \"Weekday $((i++)) : $day\" done"
        },
        {
            "filename": "file_651.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_651.sh",
            "content": "#!/bin/sh a=0 while [ $a -lt 10 ] do echo $a a=`expr $a + 1` done"
        },
        {
            "filename": "file_652.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_652.sh",
            "content": "#!/bin/sh #We have defined a hello world function here Hello () { echo \"Hello World\" } # calling our function Hello"
        },
        {
            "filename": "file_653.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_653.sh",
            "content": "# Calling one function from another number_one () { echo \"This is the first function speaking...\" number_two } number_two () { echo \"This is now the second function speaking...\" } # Calling function one. number_one"
        },
        {
            "filename": "file_654.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_654.sh",
            "content": "new script"
        },
        {
            "filename": "file_655.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_655.sh",
            "content": "#!/bin/bash #This script is to read input from the user/console echo \"Value of a\" read a echo \"Value of b\" read b echo \"Hello value of a is $a and value of b is $b\" echo \"Do you understand the script?\""
        },
        {
            "filename": "file_656.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_656.sh",
            "content": "#!/bin/bash #this is to check if the shell scripts picks up env variables echo \"This is error script\" # sample script echo \"This is my system path $PATH\" #Set a JDK_HOME env variable export JDK_HOME=/bin/jdk echo \"my new JDK home is=$JDK_HOME\""
        },
        {
            "filename": "file_657.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_657.sh",
            "content": "#!/bin/bash #This is creation and calling of shell variable --- defining variables Class=Young-minds Batch=25 PROFESSION=AWS/DevSecOps/Azure DevOps echo \"Class Name is $Class, Batch number $Batch, We are learning $PROFESSION\""
        },
        {
            "filename": "file_658.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_658.sh",
            "content": "#!/bin/sh #This script is to make variable read only, means we cannot set the value of NAME variable again NAME=Young-Minds readonly NAME NAME=DEVOPS echo \"my name is: $NAME\""
        },
        {
            "filename": "file_659.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_659.sh",
            "content": "#!/bin/bash # test of few of the fixed variables echo \"script name: $0\" echo \"1st cmdls: $1\" echo \"2nd cmdla: $2\" echo \"cmdla list: $@\" echo \"no of cmdl: $#\""
        },
        {
            "filename": "file_660.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_660.sh",
            "content": "#!/bin/bash #to check the output value of exit status ls -lrt echo $? echo \"here if the value is 0 this command is sucessful\""
        },
        {
            "filename": "file_661.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_661.sh",
            "content": "#!/bin/bash a=10 b=20 val1=`expr $a + $b` echo \"a + b : $val1\" val2=`expr $a - $b` echo \"a - b : $val2\" val3=`expr $a \\* $b` echo \"a * b : $val3\" val4=`expr $b / $a` echo \"b / a : $val4\" val5=`expr $b % $a` echo \"b % a : $val5\" if [ $a == $b ] then echo \"a is equal to b\" elif [ $a -gt $b ] then echo \"a is greater than b\" elif [ $a -lt $b ] then echo \"a is less than b\" else echo \"None of the condition met\" fi"
        },
        {
            "filename": "file_662.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_662.sh",
            "content": "#!/bin/bash #this is a script for just a if else a=10 b=20 if [ $a -gt $b ] then echo \"a is greater than b\" fi if [ $a -lt $b ] then echo \"a is less than b\" fi"
        },
        {
            "filename": "file_663.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shellscripts\\file_663.sh",
            "content": "#!/bin/bash #This script is to check if and else a=10 b=20 if [ $a -gt $b ] then echo \"a is greater than b\" else echo \"a is smaller than b\" fi"
        },
        {
            "filename": "file_664.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shelly.hs\\test\\data\\file_664.sh",
            "content": "#!/usr/bin/env bash echo -n \"Hello!\""
        },
        {
            "filename": "file_665.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shelly.hs\\test\\examples\\file_665.sh",
            "content": "#!/bin/sh echo \"starting\" sleep 2 echo \"finished\""
        },
        {
            "filename": "file_666.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shelly.hs\\test\\examples\\file_666.sh",
            "content": "#!/bin/sh while true; do echo \"hello\" sleep 1 done"
        },
        {
            "filename": "file_667.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shelly.hs\\test\\examples\\file_667.sh",
            "content": "#!/bin/bash echo hi"
        },
        {
            "filename": "file_668.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shell_Script\\file_668.sh",
            "content": "#!/bin/bash #################################### install_home=\"/etc/shadowsocks/\" # \u5b89\u88c5\u76ee\u5f55 port=888; # \u7aef\u53e3 password=\"password\" # \u5bc6\u7801 encrypt=\"chacha20-ietf-poly1305\" # \u52a0\u5bc6\u65b9\u5f0f #################################### systemctl stop firewalld systemctl disable firewalld rm -rf $install_home mkdir -p $install_home yum update -y yum -y install epel-release yum install -y python-pip git gcc gcc-c++ make pip install --upgrade pip pip install setuptools # pip install shadowsocks pip install git+https://github.com/shadowsocks/shadowsocks.git@master cd $install_home cat > $install_home/config.json <<EOF { \"server\":\"0.0.0.0\", \"server_port\":$port, \"password\":\"$password\", \"method\":\"$encrypt\" } EOF wget https://github.com/jedisct1/libsodium/releases/download/1.0.15/libsodium-1.0.15.tar.gz tar zxvf libsodium-1.0.15.tar.gz cd libsodium-1.0.15 ./configure make && make install echo \"/usr/local/lib\" > /etc/ld.so.conf.d/usr_local_lib.conf ldconfig start_cmd=\"ssserver -c \"$install_home\"config.json -d start\" $start_cmd echo 'shadowsocks \u670d\u52a1\u5df2\u542f\u52a8' sleep 3 echo $start_cmd >> /etc/rc.local chmod +x /etc/rc.d/rc.local echo \"\u5b89\u88c5\u6210\u529f,\u5df2\u52a0\u5165\u5f00\u673a\u81ea\u542f,\u7aef\u53e3:$port \u5bc6\u7801:$password \u52a0\u5bc6\u65b9\u5f0f:$encrypt\""
        },
        {
            "filename": "file_669.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shell_Script\\file_669.sh",
            "content": "#!/bin/bash mkdir temp-kernel && cd temp-kernel wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.13.7/linux-headers-4.13.7-041307_4.13.7-041307.201710141430_all.deb wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.13.7/linux-headers-4.13.7-041307-generic_4.13.7-041307.201710141430_amd64.deb wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.13.7/linux-image-4.13.7-041307-generic_4.13.7-041307.201710141430_amd64.deb dpkg -i *.deb cd .. rm -rf temp-kernel echo \"net.core.default_qdisc=fq\" >> /etc/sysctl.conf echo \"net.ipv4.tcp_congestion_control=bbr\" >> /etc/sysctl.conf echo '10s \u540e\u91cd\u542f\u751f\u6548' sleep 10 reboot"
        },
        {
            "filename": "file_670.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shell_Script\\file_670.sh",
            "content": "#!/bin/bash apt update apt install gcc make wget mkdir nginx_build_install cd nginx_build_install wget https://nginx.org/download/nginx-1.12.1.tar.gz wget https://zlib.net/zlib-1.2.11.tar.gz wget https://ftp.pcre.org/pub/pcre/pcre-8.41.tar.gz wget https://www.openssl.org/source/openssl-1.0.2l.tar.gz tar zxvf nginx-1.12.1.tar.gz mv nginx-1.12.1 nginx tar zxvf zlib-1.2.11.tar.gz mv zlib-1.2.11 zlib tar zxvf pcre-8.41.tar.gz mv pcre-8.41 pcre tar zxvf openssl-1.0.2l.tar.gz mv openssl-1.0.2l openssl cd nginx ./configure \\ --with-zlib=../zlib \\ --with-pcre --with-pcre=../pcre \\ --with-http_ssl_module --with-openssl=../openssl \\ --with-http_v2_module make && make install echo 'nginx make install success'"
        },
        {
            "filename": "file_671.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shell_Script\\file_671.sh",
            "content": "apt update apt install gcc make ruby -y gem install redis wget http://download.redis.io/releases/redis-4.0.1.tar.gz tar zxvf redis-4.0.1.tar.gz cd redis-4.0.1 make cd .. mkdir cluster-test && cd cluster-test mkdir 7000 7001 7002 7003 7004 7005 cp ../redis-4.0.1/src/redis-cli ./ cp ../redis-4.0.1/src/redis-trib.rb ./ cp ../redis-4.0.1/src/redis-server 7000 cp ../redis-4.0.1/src/redis-server 7001 cp ../redis-4.0.1/src/redis-server 7002 cp ../redis-4.0.1/src/redis-server 7003 cp ../redis-4.0.1/src/redis-server 7004 cp ../redis-4.0.1/src/redis-server 7005 cat > 7000/redis.conf <<EOF port 7000 cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 daemonize yes protected-mode no EOF cat > 7001/redis.conf <<EOF port 7001 cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 daemonize yes protected-mode no EOF cat > 7002/redis.conf <<EOF port 7002 cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 daemonize yes protected-mode no EOF cat > 7003/redis.conf <<EOF port 7003 cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 daemonize yes protected-mode no EOF cat > 7004/redis.conf <<EOF port 7004 cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 daemonize yes protected-mode no EOF cat > 7005/redis.conf <<EOF port 7005 cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 daemonize yes protected-mode no EOF cat > start-all.sh <<EOF cd 7000 ./redis-server redis.conf cd ../7001 ./redis-server redis.conf cd ../7002 ./redis-server redis.conf cd ../7003 ./redis-server redis.conf cd ../7004 ./redis-server redis.conf cd ../7005 ./redis-server redis.conf EOF chmod 755 start-all.sh ./start-all.sh ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 \\ 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005"
        },
        {
            "filename": "file_672.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shell_Script\\file_672.sh",
            "content": "#!/bin/bash src_ip=127.0.0.1 src_port=6379 dest_ip=127.0.0.1 dest_port=6379 src_key_prefix=TEST dest_key_prefix=TEST2 i=1 redis-cli -h $src_ip -p $src_port hgetall \"$src_key_prefix\" |awk \"NR%2==1\"| while read key do value=`redis-cli -h $dest_ip -p $dest_port hget \"$dest_key_prefix\" $key` if [ \"$value\" = \"\" ]; then result=`redis-cli -h $src_ip -p $src_port hget \"$src_key_prefix\" $key` redis-cli -h $dest_ip -p $dest_port hset \"$dest_key_prefix\" \"$key\" \"$result\" else echo '<<<<>>>>' fi echo \"$i migrate key $key\" ((i++)) done"
        },
        {
            "filename": "file_673.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shell_Script\\file_673.sh",
            "content": "#!/bin/bash #################################### install_home=\"/etc/shadowsocks/\" # \u5b89\u88c5\u76ee\u5f55 port=888; # \u7aef\u53e3 password=\"password\" # \u5bc6\u7801 encrypt=\"chacha20-ietf-poly1305\" # \u52a0\u5bc6\u65b9\u5f0f #################################### rm -rf $install_home mkdir -p $install_home apt update apt install -y python-pip git gcc g++ make pip install --upgrade pip pip install setuptools # pip install shadowsocks pip install git+https://github.com/shadowsocks/shadowsocks.git@master cd $install_home cat > $install_home/config.json <<EOF { \"server\":\"0.0.0.0\", \"server_port\":$port, \"password\":\"$password\", \"method\":\"$encrypt\" } EOF wget https://github.com/jedisct1/libsodium/releases/download/1.0.13/libsodium-1.0.13.tar.gz tar zxvf libsodium-1.0.13.tar.gz cd libsodium-1.0.13 ./configure make && make install && ldconfig start_cmd=\"ssserver -c \"$install_home\"config.json -d start\" $start_cmd echo 'shadowsocks \u670d\u52a1\u5df2\u542f\u52a8' sleep 3 touch /etc/rc.local echo \"#!/bin/sh -e\" > /etc/rc.local echo $start_cmd >> /etc/rc.local echo \"exit 0\" chmod 755 /etc/rc.local echo \"\u5b89\u88c5\u6210\u529f,\u5df2\u52a0\u5165\u5f00\u673a\u81ea\u542f,\u7aef\u53e3:$port \u5bc6\u7801:$password \u52a0\u5bc6\u65b9\u5f0f:$encrypt\""
        },
        {
            "filename": "file_674.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shell_Script\\file_674.sh",
            "content": "#!/bin/bash #################################### install_home=\"/etc/shadowsocks/\" # \u5b89\u88c5\u76ee\u5f55 port=888; # \u7aef\u53e3 password=\"password\" # \u5bc6\u7801 encrypt=\"aes-256-cfb\" # \u52a0\u5bc6\u65b9\u5f0f #################################### rm -rf $install_home mkdir -p $install_home apt update apt install -y python-pip git pip install --upgrade pip pip install setuptools # pip install shadowsocks pip install git+https://github.com/shadowsocks/shadowsocks.git@master cd $install_home cat > $install_home/config.json <<EOF { \"server\":\"0.0.0.0\", \"server_port\":$port, \"password\":\"$password\", \"method\":\"$encrypt\" } EOF start_cmd=\"ssserver -c \"$install_home\"config.json -d start\" $start_cmd echo 'shadowsocks \u670d\u52a1\u5df2\u542f\u52a8' sleep 3 touch /etc/rc.local echo \"#!/bin/sh -e\" > /etc/rc.local echo $start_cmd >> /etc/rc.local echo \"exit 0\" chmod 755 /etc/rc.local echo \"\u5b89\u88c5\u6210\u529f,\u5df2\u52a0\u5165\u5f00\u673a\u81ea\u542f,\u7aef\u53e3:$port \u5bc6\u7801:$password \u52a0\u5bc6\u65b9\u5f0f:$encrypt\""
        },
        {
            "filename": "file_675.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shell_Script\\file_675.sh",
            "content": "#!/bin/bash SpringBoot=$2 if [ \"$1\" = \"\" ]; then echo -e \"\\033[0;31m \u672a\u8f93\u5165\u64cd\u4f5c\u540d \\033[0m \\033[0;34m {start|stop|restart|status} \\033[0m\" exit 1 fi if [ \"$SpringBoot\" = \"\" ]; then echo -e \"\\033[0;31m \u672a\u8f93\u5165\u5e94\u7528\u540d \\033[0m\" exit 1 fi function start() { count=`ps -ef |grep java|grep $SpringBoot|grep -v grep|wc -l` if [ $count != 0 ];then echo \"$SpringBoot is running...\" else echo \"Start $SpringBoot success...\" nohup java -jar $SpringBoot > /dev/null 2>&1 & fi } function stop() { echo \"Stop $SpringBoot\" boot_id=`ps -ef |grep java|grep $SpringBoot|grep -v grep|awk '{print $2}'` count=`ps -ef |grep java|grep $SpringBoot|grep -v grep|wc -l` if [ $count != 0 ];then kill $boot_id count=`ps -ef |grep java|grep $SpringBoot|grep -v grep|wc -l` boot_id=`ps -ef |grep java|grep $SpringBoot|grep -v grep|awk '{print $2}'` kill -9 $boot_id fi } function restart() { stop sleep 2 start } function status() { count=`ps -ef |grep java|grep $SpringBoot|grep -v grep|wc -l` if [ $count != 0 ];then echo \"$SpringBoot is running...\" else echo \"$SpringBoot is not running...\" fi } case $1 in start) start;; stop) stop;; restart) restart;; status) status;; *) echo -e \"\\033[0;31m Usage: \\033[0m \\033[0;34m sh $0 {start|stop|restart|status} {SpringBootJarName} \\033[0m \\033[0;31m Example: \\033[0m \\033[0;33m sh $0 start esmart-test.jar \\033[0m\" esac"
        },
        {
            "filename": "file_676.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shell_Script\\Check_script\\bash\\file_676.sh",
            "content": "#!/bin/bash ##Filename: CentOS_Check_Script.sh ##Date: 2019-03-01 ##Description: Security detection script echo \"##########################################################################\" echo \"# #\" echo \"# health check script #\" echo \"# #\" echo \"#\u8b66\u544a:\u672c\u811a\u672c\u53ea\u662f\u4e00\u4e2a\u68c0\u67e5\u7684\u64cd\u4f5c,\u672a\u5bf9\u670d\u52a1\u5668\u505a\u4efb\u4f55\u4fee\u6539,\u7ba1\u7406\u5458\u53ef\u4ee5\u6839\u636e\u6b64\u62a5\u544a #\" echo \"#\u8fdb\u884c\u76f8\u5e94\u7684\u5b89\u5168\u6574\u6539 #\" echo \"##########################################################################\" echo \" \" #read -p \"=====================Are You Ready,Please press enter==================\" echo \" \" echo \"##########################################################################\" echo \"# #\" echo \"# \u4e3b\u673a\u5b89\u5168\u68c0\u6d4b #\" echo \"# #\" echo \"##########################################################################\" echo \" \" echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u7cfb\u7edf\u57fa\u672c\u4fe1\u606f<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" hostname=$(uname -n) system=$(cat /etc/os-release | grep \"^NAME\" | awk -F\\\" '{print $2}') version=$(cat /etc/redhat-release | awk '{print $4$5}') kernel=$(uname -r) platform=$(uname -p) address=$(ip addr | grep inet | grep -v \"inet6\" | grep -v \"127.0.0.1\" | awk '{ print $2; }' | tr '\\n' '\\t' ) cpumodel=$(cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq) cpu=$(cat /proc/cpuinfo | grep 'processor' | sort | uniq | wc -l) machinemodel=$(dmidecode | grep \"Product Name\" | sed 's/^[ \\t]*//g' | tr '\\n' '\\t' ) date=$(date) echo \"\u4e3b\u673a\u540d: $hostname\" echo \"\u7cfb\u7edf\u540d\u79f0: $system\" echo \"\u7cfb\u7edf\u7248\u672c: $version\" echo \"\u5185\u6838\u7248\u672c: $kernel\" echo \"\u7cfb\u7edf\u7c7b\u578b: $platform\" echo \"\u672c\u673aIP\u5730\u5740: $address\" echo \"CPU\u578b\u53f7: $cpumodel\" echo \"CPU\u6838\u6570: $cpu\" echo \"\u673a\u5668\u578b\u53f7: $machinemodel\" echo \"\u7cfb\u7edf\u65f6\u95f4: $date\" echo \" \" echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u8d44\u6e90\u4f7f\u7528\u60c5\u51b5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" summemory=$(free -h |grep \"Mem:\" | awk '{print $2}') freememory=$(free -h |grep \"Mem:\" | awk '{print $4}') usagememory=$(free -h |grep \"Mem:\" | awk '{print $3}') uptime=$(uptime | awk '{print $2\" \"$3\" \"$4\" \"$5}' | sed 's/,$//g') loadavg=$(uptime | awk '{print $9\" \"$10\" \"$11\" \"$12\" \"$13}') echo \"\u603b\u5185\u5b58\u5927\u5c0f: $summemory\" echo \"\u5df2\u4f7f\u7528\u5185\u5b58\u5927\u5c0f: $usagememory\" echo \"\u53ef\u4f7f\u7528\u5185\u5b58\u5927\u5c0f: $freememory\" echo \"\u7cfb\u7edf\u8fd0\u884c\u65f6\u95f4: $uptime\" echo \"\u7cfb\u7edf\u8d1f\u8f7d: $loadavg\" echo \"=============================dividing line================================\" echo \"\u5185\u5b58\u72b6\u6001:\" vmstat 2 5 echo \"=============================dividing line================================\" echo \"\u50f5\u5c38\u8fdb\u7a0b:\" ps -ef | grep zombie | grep -v grep if [ $? == 1 ];then echo \">>>\u65e0\u50f5\u5c38\u8fdb\u7a0b\" else echo \">>>\u6709\u50f5\u5c38\u8fdb\u7a0b------[\u9700\u8c03\u6574]\" fi echo \"=============================dividing line================================\" echo \"\u8017CPU\u6700\u591a\u7684\u8fdb\u7a0b:\" ps auxf |sort -nr -k 3 |head -5 echo \"=============================dividing line================================\" echo \"\u8017\u5185\u5b58\u6700\u591a\u7684\u8fdb\u7a0b:\" ps auxf |sort -nr -k 4 |head -5 echo \"=============================dividing line================================\" echo \"\u73af\u5883\u53d8\u91cf:\" env echo \"=============================dividing line================================\" echo \"\u8def\u7531\u8868:\" route -n echo \"=============================dividing line================================\" echo \"\u76d1\u542c\u7aef\u53e3:\" netstat -tunlp echo \"=============================dividing line================================\" echo \"\u5f53\u524d\u5efa\u7acb\u7684\u8fde\u63a5:\" netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' echo \"=============================dividing line================================\" echo \"\u5f00\u673a\u542f\u52a8\u7684\u670d\u52a1:\" systemctl list-unit-files | grep enabled echo \" \" echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u7cfb\u7edf\u7528\u6237\u60c5\u51b5<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" echo \"\u6d3b\u52a8\u7528\u6237:\" w | tail -n +2 echo \"=============================dividing line================================\" echo \"\u7cfb\u7edf\u6240\u6709\u7528\u6237:\" cut -d: -f1,2,3,4 /etc/passwd echo \"=============================dividing line================================\" echo \"\u7cfb\u7edf\u6240\u6709\u7ec4:\" cut -d: -f1,2,3 /etc/group echo \"=============================dividing line================================\" echo \"\u5f53\u524d\u7528\u6237\u7684\u8ba1\u5212\u4efb\u52a1:\" crontab -l echo \" \" echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u8eab\u4efd\u9274\u522b\u5b89\u5168<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" grep -i \"^password.*requisite.*pam_cracklib.so\" /etc/pam.d/system-auth > /dev/null if [ $? == 0 ];then echo \">>>\u5bc6\u7801\u590d\u6742\u5ea6:\u5df2\u8bbe\u7f6e\" else grep -i \"pam_pwquality\\.so\" /etc/pam.d/system-auth > /dev/null if [ $? == 0 ];then echo \">>>\u5bc6\u7801\u590d\u6742\u5ea6:\u5df2\u8bbe\u7f6e\" else echo \">>>\u5bc6\u7801\u590d\u6742\u5ea6:\u672a\u8bbe\u7f6e,\u8bf7\u52a0\u56fa\u5bc6\u7801--------[\u9700\u8c03\u6574]\" fi fi echo \"=============================dividing line================================\" awk -F\":\" '{if($2!~/^!|^*/){print \">>>(\"$1\")\" \" \u662f\u4e00\u4e2a\u672a\u88ab\u9501\u5b9a\u7684\u8d26\u6237,\u8bf7\u7ba1\u7406\u5458\u68c0\u67e5\u662f\u5426\u662f\u53ef\u7591\u8d26\u6237--------[\u9700\u8c03\u6574]\"}}' /etc/shadow echo \"=============================dividing line================================\" more /etc/login.defs | grep -E \"PASS_MAX_DAYS\" | grep -v \"#\" |awk -F' ' '{if($2!=90){print \">>>\u5bc6\u7801\u8fc7\u671f\u5929\u6570\u662f\"$2\"\u5929,\u8bf7\u7ba1\u7406\u5458\u6539\u621090\u5929------[\u9700\u8c03\u6574]\"}}' echo \"=============================dividing line================================\" grep -i \"^auth.*required.*pam_tally2.so.*$\" /etc/pam.d/sshd > /dev/null if [ $? == 0 ];then echo \">>>\u767b\u5165\u5931\u8d25\u5904\u7406:\u5df2\u5f00\u542f\" else echo \">>>\u767b\u5165\u5931\u8d25\u5904\u7406:\u672a\u5f00\u542f,\u8bf7\u52a0\u56fa\u767b\u5165\u5931\u8d25\u9501\u5b9a\u529f\u80fd----------[\u9700\u8c03\u6574]\" fi echo \" \" echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u8bbf\u95ee\u63a7\u5236\u5b89\u5168<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" echo \"\u7cfb\u7edf\u4e2d\u5b58\u5728\u4ee5\u4e0b\u975e\u7cfb\u7edf\u9ed8\u8ba4\u7528\u6237:\" more /etc/passwd |awk -F \":\" '{if($3>500){print \">>>/etc/passwd\u91cc\u9762\u7684\"$1 \"\u7684UID\u4e3a\"$3\"\uff0c\u8be5\u8d26\u6237\u975e\u7cfb\u7edf\u9ed8\u8ba4\u8d26\u6237\uff0c\u8bf7\u7ba1\u7406\u5458\u786e\u8ba4\u662f\u5426\u4e3a\u53ef\u7591\u8d26\u6237--------[\u9700\u8c03\u6574]\"}}' echo \"=============================dividing line================================\" echo \"\u7cfb\u7edf\u7279\u6743\u7528\u6237:\" awk -F: '$3==0 {print $1}' /etc/passwd echo \"=============================dividing line================================\" echo \"\u7cfb\u7edf\u4e2d\u7a7a\u53e3\u4ee4\u8d26\u6237:\" awk -F: '($2==\"!!\") {print $1\"\u8be5\u8d26\u6237\u4e3a\u7a7a\u53e3\u4ee4\u8d26\u6237\uff0c\u8bf7\u7ba1\u7406\u5458\u786e\u8ba4\u662f\u5426\u4e3a\u65b0\u589e\u8d26\u6237\uff0c\u5982\u679c\u4e3a\u65b0\u5efa\u8d26\u6237\uff0c\u8bf7\u914d\u7f6e\u5bc6\u7801-------[\u9700\u8c03\u6574]\"}' /etc/shadow echo \" \" echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u5b89\u5168\u5ba1\u8ba1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" echo \"\u6b63\u5e38\u60c5\u51b5\u4e0b\u767b\u5f55\u5230\u672c\u673a30\u5929\u5185\u7684\u6240\u6709\u7528\u6237\u7684\u5386\u53f2\u8bb0\u5f55:\" last | head -n 30 echo \"=============================dividing line================================\" echo \"\u67e5\u770bsyslog\u65e5\u5fd7\u5ba1\u8ba1\u670d\u52a1\u662f\u5426\u5f00\u542f:\" if service rsyslog status | egrep \" active \\(running\";then echo \">>>\u7ecf\u5206\u6790,syslog\u670d\u52a1\u5df2\u5f00\u542f\" else echo \">>>\u7ecf\u5206\u6790,syslog\u670d\u52a1\u672a\u5f00\u542f\uff0c\u5efa\u8bae\u901a\u8fc7service rsyslog start\u5f00\u542f\u65e5\u5fd7\u5ba1\u8ba1\u529f\u80fd---------[\u9700\u8c03\u6574]\" fi echo \"=============================dividing line================================\" echo \"\u67e5\u770bsyslog\u65e5\u5fd7\u662f\u5426\u5f00\u542f\u5916\u53d1:\" if more /etc/rsyslog.conf | egrep \"@...\\.|@..\\.|@.\\.|\\*.\\* @...\\.|\\*\\.\\* @..\\.|\\*\\.\\* @.\\.\";then echo \">>>\u7ecf\u5206\u6790,\u5ba2\u6237\u7aefsyslog\u65e5\u5fd7\u5df2\u5f00\u542f\u5916\u53d1--------[\u9700\u8c03\u6574]\" else echo \">>>\u7ecf\u5206\u6790,\u5ba2\u6237\u7aefsyslog\u65e5\u5fd7\u672a\u5f00\u542f\u5916\u53d1---------[\u65e0\u9700\u8c03\u6574]\" fi echo \"=============================dividing line================================\" echo \"\u5ba1\u8ba1\u7684\u8981\u7d20\u548c\u5ba1\u8ba1\u65e5\u5fd7:\" more /etc/rsyslog.conf | grep -v \"^[$|#]\" | grep -v \"^$\" echo \"=============================dividing line================================\" echo \"\u7cfb\u7edf\u4e2d\u5173\u952e\u6587\u4ef6\u4fee\u6539\u65f6\u95f4:\" ls -ltr /bin/ls /bin/login /etc/passwd /bin/ps /etc/shadow|awk '{print \">>>\u6587\u4ef6\u540d\uff1a\"$9\" \"\"\u6700\u540e\u4fee\u6539\u65f6\u95f4\uff1a\"$6\" \"$7\" \"$8}' echo \" ############################################################################################### # ls\u6587\u4ef6:\u662f\u5b58\u50a8ls\u547d\u4ee4\u7684\u529f\u80fd\u51fd\u6570,\u88ab\u5220\u9664\u4ee5\u540e,\u5c31\u65e0\u6cd5\u6267\u884cls\u547d\u4ee4 # # login\u6587\u4ef6:login\u662f\u63a7\u5236\u7528\u6237\u767b\u5f55\u7684\u6587\u4ef6,\u4e00\u65e6\u88ab\u7be1\u6539\u6216\u5220\u9664,\u7cfb\u7edf\u5c06\u65e0\u6cd5\u5207\u6362\u7528\u6237\u6216\u767b\u9646\u7528\u6237 # # /etc/passwd\u662f\u4e00\u4e2a\u6587\u4ef6,\u4e3b\u8981\u662f\u4fdd\u5b58\u7528\u6237\u4fe1\u606f # # /bin/ps \u8fdb\u7a0b\u67e5\u770b\u547d\u4ee4\u529f\u80fd\u652f\u6301\u6587\u4ef6,\u6587\u4ef6\u635f\u574f\u6216\u88ab\u66f4\u6539\u540e,\u65e0\u6cd5\u6b63\u5e38\u4f7f\u7528ps\u547d\u4ee4 # # /etc/shadow\u662f/etc/passwd\u7684\u5f71\u5b50\u6587\u4ef6,\u5bc6\u7801\u5b58\u653e\u5728\u8be5\u6587\u4ef6\u5f53\u4e2d,\u5e76\u4e14\u53ea\u6709root\u7528\u6237\u53ef\u8bfb # ###############################################################################################\" echo \"=============================dividing line================================\" echo \"\u68c0\u67e5\u91cd\u8981\u65e5\u5fd7\u6587\u4ef6\u662f\u5426\u5b58\u5728:\" log_secure=/var/log/secure log_messages=/var/log/messages log_cron=/var/log/cron log_boot=/var/log/boot.log log_dmesg=/var/log/dmesg if [ -e \"$log_secure\" ]; then echo \">>>/var/log/secure\u65e5\u5fd7\u6587\u4ef6\u5b58\u5728\" else echo \">>>/var/log/secure\u65e5\u5fd7\u6587\u4ef6\u4e0d\u5b58\u5728------[\u9700\u8c03\u6574]\" fi if [ -e \"$log_messages\" ]; then echo \">>>/var/log/messages\u65e5\u5fd7\u6587\u4ef6\u5b58\u5728\" else echo \">>>/var/log/messages\u65e5\u5fd7\u6587\u4ef6\u4e0d\u5b58\u5728------[\u9700\u8c03\u6574]\" fi if [ -e \"$log_cron\" ]; then echo \">>>/var/log/cron\u65e5\u5fd7\u6587\u4ef6\u5b58\u5728\" else echo \">>>/var/log/cron\u65e5\u5fd7\u6587\u4ef6\u4e0d\u5b58\u5728--------[\u9700\u8c03\u6574]\" fi if [ -e \"$log_boot\" ]; then echo \">>>/var/log/boot.log\u65e5\u5fd7\u6587\u4ef6\u5b58\u5728\" else echo \">>>/var/log/boot.log\u65e5\u5fd7\u6587\u4ef6\u4e0d\u5b58\u5728--------[\u9700\u8c03\u6574]\" fi if [ -e \"$log_dmesg\" ]; then echo \">>>/var/log/dmesg\u65e5\u5fd7\u6587\u4ef6\u5b58\u5728\" else echo \">>>/var/log/dmesg\u65e5\u5fd7\u6587\u4ef6\u4e0d\u5b58\u5728--------[\u9700\u8c03\u6574]\" fi echo \" \" echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u5269\u4f59\u4fe1\u606f\u4fdd\u62a4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" echo \"\u5206\u533a\u60c5\u51b5:\" echo \"\u5982\u679c\u78c1\u76d8\u7a7a\u95f4\u5229\u7528\u7387\u8fc7\u9ad8\uff0c\u8bf7\u53ca\u65f6\u8c03\u6574---------[\u9700\u8c03\u6574]\" df -h echo \"=============================dividing line================================\" echo \"\u53ef\u7528\u5757\u8bbe\u5907\u4fe1\u606f:\" lsblk echo \"=============================dividing line================================\" echo \"\u6587\u4ef6\u7cfb\u7edf\u4fe1\u606f:\" more /etc/fstab | grep -v \"^#\" | grep -v \"^$\" echo \" \" echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u5165\u4fb5\u9632\u8303\u5b89\u5168<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" echo \"\u7cfb\u7edf\u5165\u4fb5\u884c\u4e3a:\" more /var/log/secure |grep refused if [ $? == 0 ];then echo \"\u6709\u5165\u4fb5\u884c\u4e3a\uff0c\u8bf7\u5206\u6790\u5904\u7406--------[\u9700\u8c03\u6574]\" else echo \">>>\u65e0\u5165\u4fb5\u884c\u4e3a\" fi echo \"=============================dividing line================================\" echo \"\u7528\u6237\u9519\u8bef\u767b\u5165\u5217\u8868:\" lastb | head > /dev/null if [ $? == 1 ];then echo \">>>\u65e0\u7528\u6237\u9519\u8bef\u767b\u5165\u5217\u8868\" else echo \">>>\u7528\u6237\u9519\u8bef\u767b\u5165--------[\u9700\u8c03\u6574]\" lastb | head fi echo \"=============================dividing line================================\" echo \"ssh\u66b4\u529b\u767b\u5165\u4fe1\u606f:\" more /var/log/secure | grep \"Failed\" > /dev/null if [ $? == 1 ];then echo \">>>\u65e0ssh\u66b4\u529b\u767b\u5165\u4fe1\u606f\" else more /var/log/secure|awk '/Failed/{print $(NF-3)}'|sort|uniq -c|awk '{print \">>>\u767b\u5165\u5931\u8d25\u7684IP\u548c\u5c1d\u8bd5\u6b21\u6570: \"$2\"=\"$1\"\u6b21---------[\u9700\u8c03\u6574]\";}' fi echo \" \" echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u6076\u610f\u4ee3\u7801\u9632\u8303<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" echo \"\u68c0\u67e5\u662f\u5426\u5b89\u88c5\u75c5\u6bd2\u8f6f\u4ef6:\" crontab -l | grep clamscan.sh > /dev/null if [ $? == 0 ];then echo \">>>\u5df2\u5b89\u88c5ClamAV\u6740\u6bd2\u8f6f\u4ef6\" crontab -l | grep freshclam.sh > /dev/null if [ $? == 0 ];then echo \">>>\u5df2\u90e8\u7f72\u5b9a\u65f6\u66f4\u65b0\u75c5\u6bd2\u5e93\" fi else echo \">>>\u672a\u5b89\u88c5ClamAV\u6740\u6bd2\u8f6f\u4ef6,\u8bf7\u90e8\u7f72\u6740\u6bd2\u8f6f\u4ef6\u52a0\u56fa\u4e3b\u673a\u9632\u62a4--------[\u65e0\u9700\u8c03\u6574]\" fi echo \" \" echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\u8d44\u6e90\u63a7\u5236\u5b89\u5168<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" echo \"\u67e5\u770b\u662f\u5426\u5f00\u542f\u4e86xinetd\u670d\u52a1:\" if ps -elf |grep xinet |grep -v \"grep xinet\";then echo \">>>xinetd\u670d\u52a1\u6b63\u5728\u8fd0\u884c\uff0c\u8bf7\u68c0\u67e5\u662f\u5426\u53ef\u4ee5\u628axinetd\u670d\u52a1\u5173\u95ed--------[\u65e0\u9700\u8c03\u6574]\" else echo \">>>xinetd\u670d\u52a1\u672a\u5f00\u542f-------[\u65e0\u9700\u8c03\u6574]\" fi echo \"=============================dividing line================================\" echo \"\u67e5\u770b\u662f\u5426\u5f00\u542f\u4e86ssh\u670d\u52a1:\" if service sshd status | grep -E \"listening on|active \\(running\\)\"; then echo \">>>SSH\u670d\u52a1\u5df2\u5f00\u542f\" else echo \">>>SSH\u670d\u52a1\u672a\u5f00\u542f--------[\u9700\u8c03\u6574]\" fi echo \"=============================dividing line================================\" echo \"\u67e5\u770b\u662f\u5426\u5f00\u542f\u4e86Telnet-Server\u670d\u52a1:\" if more /etc/xinetd.d/telnetd 2>&1|grep -E \"disable=no\"; then echo \">>>Telnet-Server\u670d\u52a1\u5df2\u5f00\u542f\" else echo \">>>Telnet-Server\u670d\u52a1\u672a\u5f00\u542f--------[\u65e0\u9700\u8c03\u6574]\" fi echo \"=============================dividing line================================\" ps axu | grep iptables | grep -v grep || ps axu | grep firewalld | grep -v grep if [ $? == 0 ];then echo \">>>\u9632\u706b\u5899\u5df2\u542f\u7528\" iptables -nvL --line-numbers else echo \">>>\u9632\u706b\u5899\u672a\u542f\u7528--------[\u9700\u8c03\u6574]\" fi echo \"=============================dividing line================================\" echo \"\u67e5\u770b\u7cfb\u7edfSSH\u8fdc\u7a0b\u8bbf\u95ee\u8bbe\u7f6e\u7b56\u7565(host.deny\u62d2\u7edd\u5217\u8868):\" if more /etc/hosts.deny | grep -E \"sshd\"; then echo \">>>\u8fdc\u7a0b\u8bbf\u95ee\u7b56\u7565\u5df2\u8bbe\u7f6e--------[\u9700\u8c03\u6574]\" else echo \">>>\u8fdc\u7a0b\u8bbf\u95ee\u7b56\u7565\u672a\u8bbe\u7f6e--------[\u65e0\u9700\u8c03\u6574]\" fi echo \"=============================dividing line================================\" echo \"\u67e5\u770b\u7cfb\u7edfSSH\u8fdc\u7a0b\u8bbf\u95ee\u8bbe\u7f6e\u7b56\u7565(hosts.allow\u5141\u8bb8\u5217\u8868):\" if more /etc/hosts.allow | grep -E \"sshd\"; then echo \">>>\u8fdc\u7a0b\u8bbf\u95ee\u7b56\u7565\u5df2\u8bbe\u7f6e--------[\u9700\u8c03\u6574]\" else echo \">>>\u8fdc\u7a0b\u8bbf\u95ee\u7b56\u7565\u672a\u8bbe\u7f6e--------[\u65e0\u9700\u8c03\u6574]\" fi echo \"=============================dividing line================================\" echo \"\u5f53hosts.allow\u548chost.deny\u76f8\u51b2\u7a81\u65f6,\u4ee5hosts.allow\u8bbe\u7f6e\u4e3a\u51c6\" echo \"=============================dividing line================================\" grep -i \"TMOUT\" /etc/profile /etc/bashrc if [ $? == 0 ];then echo \">>>\u5df2\u8bbe\u7f6e\u767b\u5165\u8d85\u65f6\u9650\u5236\" else echo \">>>\u672a\u8bbe\u7f6e\u767b\u5165\u8d85\u65f6\u9650\u5236,\u8bf7\u8bbe\u7f6e,\u8bbe\u7f6e\u65b9\u6cd5:\u5728/etc/profile\u6216\u8005/etc/bashrc\u91cc\u9762\u6dfb\u52a0\u53c2\u6570TMOUT=600 --------[\u9700\u8c03\u6574]\" fi echo \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>end<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\""
        },
        {
            "filename": "file_677.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\Shell_Script\\Protective_Script\\file_677.sh",
            "content": "#!/bin/bash ##Filename: OS-centOS-Protective_v0.1.sh ##Author: Browser ##Date: 2019-02-24 ##Description: Operating system security reinforcement #########################variables############################ restart_flag=1 ostype='unknow' ###########################ostype############################ if [ -f /etc/redhat-release ];then grep -i 'centos' /etc/redhat-release > /dev/null if [ $? == 0 ];then ostype='centos' fi grep -i 'redhat' /etc/redhat-release > /dev/null if [ $? == 0 ];then ostype='redhat' fi fi if [ -f /etc/centos-release ];then grep -i 'centos' /etc/centos-release > /dev/null if [ $? == 0 ];then ostype='centos' fi fi echo -e \"###########################################################################################\" echo -e \"\\033[1;31m OS type is $ostype \\033[0m\" echo -e \"###########################################################################################\" #######################restart_ssh################################ function restart_ssh(){ if [ $restart_flag == 0 ];then echo -e \"\\033[1;31mPlease restart SSH service manully by using 'service sshd restart' or 'systemctl restart sshd'\\033[0m\" fi } ###########################\u6587\u4ef6\u5907\u4efd############################ function backup(){ if [ ! -x \"backup\" ]; then mkdir backup if [ -f /etc/pam.d/system-auth ];then cp /etc/pam.d/system-auth backup/system-auth.bak elif [ -f /etc/pam.d/common-password ];then cp /etc/pam.d/common-password backup/common-password.bak fi if [ -f ~/.ssh/authorized_keys ];then cp ~/.ssh/authorized_keys backup/authorized_keys.bak fi cp /etc/pam.d/sshd backup/sshd.bak cp /etc/sudoers backup/sudoers.bak cp /etc/ssh/sshd_config backup/sshd_config.bak cp /etc/profile backup/profile.bak cp /etc/pam.d/su backup/su.bak echo -e \"###########################################################################################\" echo -e \"\\033[1;31m Auto backup successfully \\033[0m\" echo -e \"###########################################################################################\" else echo -e \"###########################################################################################\" echo -e \"\\033[1;31mBackup file already exist, to avoid overwriting these files, backup will not perform again\\033[0m \" echo -e \"###########################################################################################\" fi } ###########################\u6267\u884c\u5907\u4efd############################ backup ###########################\u6587\u4ef6\u8fd8\u539f############################ function recover(){ if [ -f backup/system-auth.bak ];then cp -rf backup/system-auth.bak /etc/pam.d/system-auth elif [ -f backup/common-password.bak ];then cp -rf backup/common-password.bak /etc/pam.d/common-password fi if [ -f backup/authorized_keys.bak ];then cp -rf backup/authorized_keys.bak ~/.ssh/authorized_keys fi cp -rf backup/sshd.bak /etc/pam.d/sshd cp -rf backup/sudoers.bak /etc/sudoers cp -rf backup/sshd_config.bak /etc/ssh/sshd_config cp -rf backup/profile.bak /etc/profile source /etc/profile cp -rf backup/su.bak /etc/pam.d/su restart_flag=0 echo -e \"\\033[1;31m 8\u3001 Recover success \\033[0m\" } ###########################\u53e3\u4ee4\u590d\u6742\u5ea6\u8bbe\u7f6e############################ function password(){ echo \"#########################################################################################\" echo -e \"\\033[1;31m 2\u3001 set password complexity requirements \\033[0m\" echo \"#########################################################################################\" if [ -f /etc/pam.d/system-auth ];then config=\"/etc/pam.d/system-auth\" elif [ -f /etc/pam.d/common-password ];then config=\"/etc/pam.d/common-password\" else echo -e \"\\033[1;31m Doesn't support this OS \\033[0m\" return 1 fi grep -i \"^password.*requisite.*pam_cracklib.so\" $config > /dev/null if [ $? == 0 ];then sed -i \"s/^password.*requisite.*pam_cracklib\\.so.*$/password requisite pam_cracklib.so retry=3 difok=3 minlen=12 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1/g\" $config echo -e \"\\033[1;31m\u5bc6\u7801\u4fee\u6539\u91cd\u8bd53\u6b21\u673a\u4f1a\uff0c\u65b0\u5bc6\u7801\u4e0e\u8001\u5bc6\u7801\u5fc5\u987b\u67093\u5b57\u7b26\u4e0d\u540c\uff0c\u6700\u5c0f\u5bc6\u7801\u957f\u5ea612\u4e2a\u5b57\u7b26\uff0c\u5305\u542b\u5927\u5199\u5b57\u7b26\u81f3\u5c11\u4e00\u4e2a\uff0c\u5c0f\u5199\u5b57\u6bcd\u81f3\u5c11\u4e00\u4e2a\uff0c\u6570\u5b57\u81f3\u5c11\u4e00\u4e2a\uff0c\u7279\u6b8a\u5b57\u7b26\u81f3\u5c11\u4e00\u4e2a\\033[0m\" else grep -i \"pam_pwquality\\.so\" $config > /dev/null if [ $? == 0 ];then sed -i \"s/password.*requisite.*pam_pwquality\\.so.*$/password requisite pam_pwquality.so retry=3 difok=3 minlen=12 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1/g\" $config echo -e \"\\033[1;31m\u5bc6\u7801\u4fee\u6539\u91cd\u8bd53\u6b21\u673a\u4f1a\uff0c\u65b0\u5bc6\u7801\u4e0e\u8001\u5bc6\u7801\u5fc5\u987b\u67093\u5b57\u7b26\u4e0d\u540c\uff0c\u6700\u5c0f\u5bc6\u7801\u957f\u5ea612\u4e2a\u5b57\u7b26\uff0c\u5305\u542b\u5927\u5199\u5b57\u7b26\u81f3\u5c11\u4e00\u4e2a\uff0c\u5c0f\u5199\u5b57\u6bcd\u81f3\u5c11\u4e00\u4e2a\uff0c\u6570\u5b57\u81f3\u5c11\u4e00\u4e2a\uff0c\u7279\u6b8a\u5b57\u7b26\u81f3\u5c11\u4e00\u4e2a\\033[0m\" else echo 'password requisite pam_cracklib.so retry=3 difok=3 minlen=12 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1' >> $config echo -e \"\\033[1;31m\u5bc6\u7801\u4fee\u6539\u91cd\u8bd53\u6b21\u673a\u4f1a\uff0c\u65b0\u5bc6\u7801\u4e0e\u8001\u5bc6\u7801\u5fc5\u987b\u67093\u5b57\u7b26\u4e0d\u540c\uff0c\u6700\u5c0f\u5bc6\u7801\u957f\u5ea612\u4e2a\u5b57\u7b26\uff0c\u5305\u542b\u5927\u5199\u5b57\u7b26\u81f3\u5c11\u4e00\u4e2a\uff0c\u5c0f\u5199\u5b57\u6bcd\u81f3\u5c11\u4e00\u4e2a\uff0c\u6570\u5b57\u81f3\u5c11\u4e00\u4e2a\uff0c\u7279\u6b8a\u5b57\u7b26\u81f3\u5c11\u4e00\u4e2a\\033[0m\" fi fi if [ $? == 0 ];then echo -e \"\\033[37;5m [Password complexity set success] \\033[0m\" else echo -e \"\\033[31;5m [Password complexity set failed] \\033[0m\" exit 1 fi } ################################\u65b0\u589e\u8d85\u7ea7\u7ba1\u7406\u5458\u7528\u6237################################ function create_user(){ echo \"#########################################################################################\" echo -e \"\\033[1;31m 3\u3001Create openroot account \\033[0m\" echo \"#########################################################################################\" read -p \"Be sure to create an openroot account?[y/n]:\" case $REPLY in y) grep -i 'openroot' /etc/passwd if [ $? == 0 ];then echo -e \"\\033[1;31m An openroot account has been created \\033[0m\" else read -p \"Please enter your password:\" PASSWD useradd -g root openroot;echo \"$PASSWD\" | passwd --stdin openroot > /dev/null if [ $? == 0 ];then echo -e \"\\033[1;31m openroot account created successfully \\033[0m\" grep -i \"openroot\" /etc/sudoers if [ $? != 0 ];then chmod u+w /etc/sudoers > /dev/null sed -i '/^root.*ALL=(ALL).*$/a\\openroot ALL=(ALL) NOPASSWD:ALL' /etc/sudoers > /dev/null if [ $? == 0 ];then echo -e \"\\033[37;5m [Permissions set success] \\033[0m\" else echo -e \"\\033[31;5m [Permissions set failed] \\033[0m\" fi chmod u-w /etc/sudoers > /dev/null else echo -e \"\\033[1;31m Permissions have already been set \\033[0m\" fi else echo -e \"\\033[1;31m openroot account created failed \\033[0m\" exit 1 fi fi ;; n) ;; *) create_user esac } ############################\u9650\u5236\u8d85\u7ea7\u7ba1\u7406\u5458\u7528\u6237\u8fdc\u7a0b\u767b\u5f55############################ function remote_login(){ echo \"#########################################################################################\" echo -e \"\\033[1;31m 4\u3001Set Remote Login Configuration(SSH) \\033[0m\" echo \"#########################################################################################\" #set Protocol 2 echo >> /etc/ssh/sshd_config grep -i '^Protocol' /etc/ssh/sshd_config > /dev/null if [ $? == 0 ];then sed -i 's/^Protocol.*$/Protocol 2/g' /etc/ssh/sshd_config if [ $? != 0 ];then echo -e \"\\033[31;5m [##Error##]: Cannot to set Protocol to '2' \\033[0m\" else echo -e \"\\033[37;5m [Success: Set SSH Protocol to 2] \\033[0m\" fi else echo 'Protocol 2' >> /etc/ssh/sshd_config echo -e \"\\033[37;5m [Success: Set SSH Protocol to 2] \\033[0m\" fi read -p \"Disable root remote login?[y/n](Please make sure you have created at least one another account):\" case $REPLY in y) grep -i '^PermitRootLogin no' /etc/ssh/sshd_config > /dev/null if [ $? == 1 ];then grep -i '.*PermitRootLogin yes' /etc/ssh/sshd_config >/dev/null if [ $? == 0 ];then sed -i 's/.*PermitRootLogin yes/PermitRootLogin no/g' /etc/ssh/sshd_config if [ $? != 0 ];then echo -e \"\\033[31;5m [##Error##]cannot to set PermitRootLogin to 'no' \\033[0m\" else echo -e \"\\033[37;5m Disable root remote login[Success] \\033[0m\" restart_flag=0 fi else echo 'PermitRootLogin no' >> /etc/ssh/sshd_config echo -e \"\\033[37;5m Disable root remote login[Success] \\033[0m\" restart_flag=0 fi else echo -e \"\\033[37;5m Already disable root remote login \\033[0m\" fi ;; n) ;; *) remote_login ;; esac } #######################\u914d\u7f6e\u7cfb\u7edf\u5386\u53f2\u547d\u4ee4\u64cd\u4f5c\u8bb0\u5f55\u548c\u5b9a\u65f6\u5e10\u6237\u81ea\u52a8\u767b\u51fa\u65f6\u95f4################################ function set_history_tmout(){ echo \"#########################################################################################\" echo -e \"\\033[1;31m 5\u3001set history and timeout \\033[0m\" echo \"#########################################################################################\" read -p \"set history size, format, and TMOUT?[y/n]:\" case $REPLY in y) #history_size grep -i \"^HISTSIZE=\" /etc/profile >/dev/null if [ $? == 0 ];then #history\u8bb0\u5f55\u4fdd\u7559\u4e00\u4e07\u6761 sed -i \"s/^HISTSIZE=.*$/HISTSIZE=10000/g\" /etc/profile else echo 'HISTSIZE=10000' >> /etc/profile fi echo -e \"\\033[1;31m HISTSIZE has been set to 10000 \\033[0m\" #history_format grep -i \"^export HISTTIMEFORMAT=\" /etc/profile > /dev/null if [ $? == 0 ];then sed -i 's/^export HISTTIMEFORMAT=.*$/export HISTTIMEFORMAT=\"%F %T `whoami`\"/g' /etc/profile else echo 'export HISTTIMEFORMAT=\"%F %T `whoami` \"' >> /etc/profile fi echo -e '\\033[1;31m HISTTIMEFORMAT has been set to \"Number-Time-User-Command\" \\033[0m' #TIME_OUT read -p \"set shell TMOUT?[300-600]seconds:\" tmout : ${tmout:=600} grep -i \"^TMOUT=\" /etc/profile > /dev/null if [ $? == 0 ];then sed -i \"s/^TMOUT=.*$/TMOUT=$tmout/g\" /etc/profile else echo \"TMOUT=$tmout\" >> /etc/profile fi source /etc/profile echo -e \"\\033[37;5m [Success] \\033[0m\" ;; n) ;; *) set_history_tmout;; esac } #######################SSH\u7aef\u53e3\u914d\u7f6e################################ function ssh_port(){ echo \"#########################################################################################\" echo -e \"\\033[1;31m 6\u3001set ssh port \\033[0m\" echo \"#########################################################################################\" read -p 'change ssh port?[y/n]:' case $REPLY in y) read -p 'please input the new ssh port(recommend to between 1024 and 65534, please make sure the port is not in used):' port ##\u9a8c\u8bc1\u7aef\u53e3\u662f\u5426\u88ab\u5360\u7528 if [[ $port -gt 1024 && $port -lt 65535 ]];then netstat -tlnp|awk -v port=$port '{lens=split($4,a,\":\");if(a[lens]==port){exit 2}}' >/dev/null #2>&1 res=$? if [ $res == 2 ];then echo -e \"\\033[1;31m The port $port is already in used, try again \\033[0m\" ssh_port elif [ $res == 1 ];then echo -e \"\\033[31;5m [##Error##] \\033[0m\" exit 1 else ##\u4fee\u6539ssh\u7aef\u53e3 grep -i \"^#Port \" /etc/ssh/sshd_config > /dev/null if [ $? == 0 ];then sed -i \"s/^#Port.*$/Port $port/g\" /etc/ssh/sshd_config else grep -i \"^Port \" /etc/ssh/sshd_config > /dev/null if [ $? == 0 ];then sed -i \"s/^Port.*$/Port $port/g\" /etc/ssh/sshd_config else echo \"Port $port\" >> /etc/ssh/sshd_config fi fi echo -e \"\\033[37;5m [Success] \\033[0m\" restart_flag=0 fi else echo -e \"\\033[31;5m [##The port $port is error, please input new ssh port between 1024 and 65534 ##] \\033[0m\" ssh_port fi ;; n) ;; *) echo -e \"\\033[31;5m [##Error##]:invalid input \\033[0m\" ssh_port ;; esac } #######################Logon failure handling################################ function logon(){ echo \"#########################################################################################\" echo -e \"\\033[1;31m 7\u3001set logon failure handling \\033[0m\" echo \"#########################################################################################\" logonconfig=/etc/pam.d/sshd read -p 'Are you sure set logon failure handling?[y/n]:' case $REPLY in y) grep -i \"^auth.*required.*pam_tally2.so.*$\" $logonconfig > /dev/null if [ $? == 0 ];then sed -i \"s/auth.*required.*pam_tally2.so.*$/auth required pam_tally2.so deny=3 unlock_time=300 even_deny_root root_unlock_time=300/g\" $logonconfig > /dev/null else sed -i '/^#%PAM-1.0/a\\auth required pam_tally2.so deny=3 unlock_time=300 even_deny_root root_unlock_time=300' $logonconfig > /dev/null fi if [ $? == 0 ];then echo \"#########################################################################################\" echo -e \"\\033[37;5m [Logon failure handling set success] \\033[0m\" echo -e \"\\033[1;31m\u9650\u5236\u767b\u5165\u5931\u8d25\u4e09\u6b21\uff0c\u666e\u901a\u8d26\u53f7\u9501\u5b9a5\u5206\u949f\uff0croot\u8d26\u53f7\u9501\u5b9a5\u5206\u949f\\033[0m\" echo \"#########################################################################################\" else echo \"#########################################################################################\" echo -e \"\\033[31;5m [Logon failure handling set failed] \\033[0m\" echo \"#########################################################################################\" exit 1 fi ;; n) ;; *) echo -e \"\\033[31;5m [##Error##]:invalid input \\033[0m\" logon ;; esac } #######################main################################ function main(){ echo -e \"\\033[1;31m ######################################################################################### # Menu # # 1:ALL protective # # 2:Set Password Complexity Requirements # # 3:Create openroot account # # 4:Set Remote Login Configuration(SSH) # # 5:Set Shell History and TMOUT # # 6:Set SSH Port # # 7:Set Logon failure handling # # 8:Recover Configuration # # 9:Exit # ######################################################################################### \\033[0m\" read -p \"Please choice[1-9]:\" case $REPLY in 1) password create_user remote_login set_history_tmout ssh_port logon restart_ssh ;; 2) password ;; 3) create_user ;; 4) remote_login restart_ssh ;; 5) set_history_tmout ;; 6) ssh_port restart_ssh ;; 7) logon restart_ssh ;; 8) recover restart_ssh ;; 9) exit 0 ;; *) echo -e \"\\033[31;5m invalid input \\033[0m\" main ;; esac } ###################### main"
        },
        {
            "filename": "file_678.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_678.sh",
            "content": "#!/bin/bash shellName=`ps | grep $$ | awk '{print $4}'` if [ \"$shellName\" == \"zsh\" ]; then read \"cerpath?\u8bf7\u8f93\u5165\u8bc1\u4e66\u5b58\u653e\u76ee\u5f55: \" read \"domains?\u8bf7\u8f93\u5165\u57df\u540d(\u591a\u4e2a\u4ee5\u7a7a\u683c\u5206\u5272): \" read \"reloadcmd?\u8bf7\u8f93\u5165\u91cd\u8f7d\u547d\u4ee4(\u975e\u5fc5\u9009): \" else read -p \"\u8bf7\u8f93\u5165\u8bc1\u4e66\u5b58\u653e\u76ee\u5f55: \" cerpath read -p \"\u8bf7\u8f93\u5165\u57df\u540d(\u591a\u4e2a\u4ee5\u7a7a\u683c\u5206\u5272): \" domains read -p \"\u8bf7\u8f93\u5165\u91cd\u8f7d\u547d\u4ee4(\u975e\u5fc5\u9009): \" reloadcmd fi if [ \"$cerpath\" == \"\" ] || [ \"$domains\" == \"\" ]; then echo -e \"\\033[31merror: cerpath or domains is blank!\" exit 1 else mkdir -p $cerpath fi allDomian=($domains) for domainName in ${allDomian[@]}; do installcert+=\" -d $domainName\" done ~/.acme.sh/acme.sh --installcert $installcert \\ --keypath $cerpath/${allDomian[0]}.key \\ --capath $cerpath/ca.cer \\ --fullchainpath $cerpath/${allDomian[0]}.cer \\ --reloadcmd \"$reloadcmd\""
        },
        {
            "filename": "file_679.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_679.sh",
            "content": "#!/bin/bash set -e # Nginx and module dependencies NGINX_VERSION=\"1.17.9\" NGINX_LUA_MODULE_VERSION=\"0.10.15\" NGINX_LUA_RESTY_CORE_VERSION=\"0.1.17\" NGINX_LUA_RESTY_LRUCACHE_VERSION=\"0.09\" NGINX_NJS_VERSION=\"0.3.9\" HEADERS_MORE_VERSION=\"0.33\" LUA_ENABLE=\"false\" LUAJIT_VERSION=\"2.0.2\" LUAJIT_MAIN_VERSION=\"2.0\" LUAJIT_LIB=\"/usr/local/lib\" LUAJIT_INC=\"/usr/local/include/luajit-${LUAJIT_MAIN_VERSION}\" PREFIX=$1 # build args CONFIG_ARGS=\"\\ --prefix=${PREFIX:-/usr/local/nginx} \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --pid-path=/var/run/nginx.pid \\ --lock-path=/var/run/nginx.lock \\ --http-client-body-temp-path=/var/cache/nginx/client_temp \\ --http-proxy-temp-path=/var/cache/nginx/proxy_temp \\ --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \\ --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \\ --http-scgi-temp-path=/var/cache/nginx/scgi_temp \\ --user=nginx \\ --group=nginx \\ --with-debug \\ --with-compat \\ --with-file-aio \\ --with-threads \\ --with-http_addition_module \\ --with-http_auth_request_module \\ --with-http_dav_module \\ --with-http_flv_module \\ --with-http_gunzip_module \\ --with-http_gzip_static_module \\ --with-http_mp4_module \\ --with-http_random_index_module \\ --with-http_realip_module \\ --with-http_secure_link_module \\ --with-http_slice_module \\ --with-http_ssl_module \\ --with-http_stub_status_module \\ --with-http_sub_module \\ --with-http_v2_module \\ --with-mail \\ --with-mail_ssl_module \\ --with-stream \\ --with-stream_realip_module \\ --with-stream_ssl_module \\ --with-stream_ssl_preread_module \\ --with-http_geoip_module=dynamic \\ --with-stream_geoip_module=dynamic \\ --with-http_image_filter_module=dynamic \\ --with-http_perl_module=dynamic \\ --with-http_xslt_module=dynamic \\ --add-dynamic-module=/usr/src/njs-${NGINX_NJS_VERSION}/nginx \\ --add-module=/usr/src/headers-more-nginx-module-${HEADERS_MORE_VERSION} \\ \" # download module dependencies function download(){ echo -e \"\\033[32mdownload files...\\033[0m\" download_dir=\"nginx_src\" if [ ! -d \"${download_dir}\" ];then mkdir ${download_dir} fi if [ ! -f \"${download_dir}/nginx-${NGINX_VERSION}.tar.gz\" ]; then curl -fSL http://nginx.org/download/nginx-${NGINX_VERSION}.tar.gz \\ -o ${download_dir}/nginx-${NGINX_VERSION}.tar.gz fi if [ ! -f \"${download_dir}/lua-nginx-module-v${NGINX_LUA_MODULE_VERSION}.tar.gz\" ]; then curl -fSL https://github.com/openresty/lua-nginx-module/archive/v${NGINX_LUA_MODULE_VERSION}.tar.gz \\ -o ${download_dir}/lua-nginx-module-v${NGINX_LUA_MODULE_VERSION}.tar.gz fi if [ ! -f \"${download_dir}/headers-more-nginx-module-v${HEADERS_MORE_VERSION}.tar.gz\" ]; then curl -fSL https://github.com/openresty/headers-more-nginx-module/archive/v${HEADERS_MORE_VERSION}.tar.gz \\ -o ${download_dir}/headers-more-nginx-module-v${HEADERS_MORE_VERSION}.tar.gz fi if [ ! -f \"${download_dir}/njs-${NGINX_NJS_VERSION}.tar.gz\" ]; then curl -fSL https://github.com/nginx/njs/archive/${NGINX_NJS_VERSION}.tar.gz \\ -o ${download_dir}/njs-${NGINX_NJS_VERSION}.tar.gz fi if [ ! -f \"${download_dir}/LuaJIT-${LUAJIT_VERSION}.tar.gz\" ] && [ \"${LUA_ENABLE}\" == \"true\" ]; then curl -fSL http://luajit.org/download/LuaJIT-${LUAJIT_VERSION}.tar.gz \\ -o ${download_dir}/LuaJIT-${LUAJIT_VERSION}.tar.gz fi if [ ! -f \"${download_dir}/lua-resty-core-v${NGINX_LUA_RESTY_CORE_VERSION}.tar.gz\" ] && [ \"${LUA_ENABLE}\" == \"true\" ]; then curl -fSL https://github.com/openresty/lua-resty-core/archive/v${NGINX_LUA_RESTY_CORE_VERSION}.tar.gz \\ -o ${download_dir}/lua-resty-core-v${NGINX_LUA_RESTY_CORE_VERSION}.tar.gz fi if [ ! -f \"${download_dir}/lua-resty-lrucache-v${NGINX_LUA_RESTY_LRUCACHE_VERSION}.tar.gz\" ] && [ \"${LUA_ENABLE}\" == \"true\" ]; then curl -fSL https://github.com/openresty/lua-resty-lrucache/archive/v${NGINX_LUA_RESTY_LRUCACHE_VERSION}.tar.gz \\ -o ${download_dir}/lua-resty-lrucache-v${NGINX_LUA_RESTY_LRUCACHE_VERSION}.tar.gz fi tar -zxC /usr/src -f ${download_dir}/nginx-${NGINX_VERSION}.tar.gz tar -zxC /usr/src -f ${download_dir}/headers-more-nginx-module-v${HEADERS_MORE_VERSION}.tar.gz tar -zxC /usr/src -f ${download_dir}/njs-${NGINX_NJS_VERSION}.tar.gz if [ \"${LUA_ENABLE}\" == \"true\" ]; then tar -zxC /usr/src -f ${download_dir}/lua-nginx-module-v$NGINX_LUA_MODULE_VERSION.tar.gz tar -zxC /usr/src -f ${download_dir}/LuaJIT-$LUAJIT_VERSION.tar.gz tar -zxC /usr/src -f ${download_dir}/lua-resty-core-v${NGINX_LUA_RESTY_CORE_VERSION}.tar.gz tar -zxC /usr/src -f ${download_dir}/lua-resty-lrucache-v${NGINX_LUA_RESTY_LRUCACHE_VERSION}.tar.gz fi } # install build dependencies function install_build_dep(){ echo -e \"\\033[32minstall build dependencies...\\033[0m\" apt install build-essential -y apt build-dep nginx -y } # install Lua function install_lua(){ echo -e \"\\033[32minstall Lua ${LUAJIT_VERSION} ...\\033[0m\" cd /usr/src/LuaJIT-${LUAJIT_VERSION} make -j$(getconf _NPROCESSORS_ONLN) make install } # install lua-resty-core function install_lua_resty_core(){ echo -e \"\\033[32minstall lua-resty-core ${NGINX_LUA_RESTY_CORE_VERSION} ...\\033[0m\" cd /usr/src/lua-resty-core-${NGINX_LUA_RESTY_CORE_VERSION} make install } # install lua-resty-lrucache function install_lua_resty_lrucache(){ echo -e \"\\033[32minstall lua-resty-lrucache ${NGINX_LUA_RESTY_LRUCACHE_VERSION} ...\\033[0m\" cd /usr/src/lua-resty-lrucache-${NGINX_LUA_RESTY_LRUCACHE_VERSION} make install } # install nginx function install_nginx(){ echo -e \"\\033[32minstall nginx ${NGINX_VERSION} ...\\033[0m\" cd /usr/src/nginx-${NGINX_VERSION} if [ \"${LUA_ENABLE}\" == \"true\" ]; then CONFIG_ARGS=\"${CONFIG_ARGS} --add-module=/usr/src/lua-nginx-module-${NGINX_LUA_MODULE_VERSION}\" fi ./configure ${CONFIG_ARGS} make -j$(getconf _NPROCESSORS_ONLN) make install mkdir -p /var/cache/nginx/{client_temp,proxy_temp,fastcgi_temp,uwsgi_temp,scgi_temp} } function adduser(){ echo -e \"\\033[32madd nginx user ...\\033[0m\" getent group nginx >/dev/null || groupadd -r nginx getent passwd nginx >/dev/null || useradd -r -g nginx -s /sbin/nologin -c \"nginx user\" nginx chown -R nginx:nginx /var/cache/nginx } # clean function clean(){ echo -e \"\\033[32mcleaning files...\\033[0m\" rm -rf /usr/src/* } download install_build_dep if [ \"${LUA_ENABLE}\" == \"true\" ]; then install_lua install_lua_resty_core install_lua_resty_lrucache fi install_nginx adduser clean"
        },
        {
            "filename": "file_680.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_680.sh",
            "content": "#!/bin/bash set -e # Tengine and module dependencies TENGINE_VERSION=\"2.2.0\" NGINX_LUA_MODULE_VERSION=\"0.2.0\" OPENSSL_VERSION=\"1.0.2j\" HEADERS_MORE_VERSION=\"0.32\" UPSTREAM_CHECK_VERSION=\"0.3.0\" DEVEL_KIT_VERSION=\"0.3.0\" NGINX_CT_VERSION=\"1.3.2\" LUAJIT_VERSION=\"2.0.4\" LUAJIT_MAIN_VERSION=\"2.0\" LUAJIT_LIB=\"/usr/local/lib\" LUAJIT_INC=\"/usr/local/include/luajit-$LUAJIT_MAIN_VERSION\" PREFIX=$1 # build args CONFIG_ARGS=\"\\ --prefix=${PREFIX:-/usr/local/tengine} \\ --pid-path=/var/run/nginx.pid \\ --lock-path=/var/run/nginx.lock \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_addition_module \\ --with-http_sub_module \\ --with-http_dav_module \\ --with-http_flv_module \\ --with-http_mp4_module \\ --with-http_gunzip_module \\ --with-http_gzip_static_module \\ --with-http_random_index_module \\ --with-http_secure_link_module \\ --with-http_stub_status_module \\ --with-http_auth_request_module \\ --with-threads \\ --with-http_slice_module \\ --with-mail \\ --with-mail_ssl_module \\ --with-file-aio \\ --with-http_v2_module \\ --with-openssl=/usr/src/openssl-${OPENSSL_VERSION} \\ --add-module=/usr/src/lua-nginx-module-${NGINX_LUA_MODULE_VERSION} \\ --http-client-body-temp-path=/tmp/client_body_temp \\ --http-proxy-temp-path=/tmp/proxy_temp \\ --http-fastcgi-temp-path=/tmp/fastcgi_temp \\ --http-uwsgi-temp-path=/tmp/uwsgi_temp \\ --http-scgi-temp-path=/tmp/scgi_temp \\ \" # install build dependencies function _installdep(){ echo -e \"\\033[32minstall build dependencies...\\033[0m\" yum install gcc glibc glibc-devel make pcre \\ pcre-devel zlib zlib-devel kernel-devel \\ curl gnupg libxslt libxslt-devel gd-devel \\ geoip-devel perl-devel perl-ExtUtils-Embed \\ lua lua-devel patch -y } # download module dependencies function _downloadfiles(){ echo -e \"\\033[32mdownload module dependencies...\\033[0m\" curl -fSL http://tengine.taobao.org/download/tengine-${TENGINE_VERSION}.tar.gz -o tengine.tar.gz curl -fSL https://www.openssl.org/source/openssl-${OPENSSL_VERSION}.tar.gz -o openssl-${OPENSSL_VERSION}.tar.gz curl -fSL https://github.com/openresty/lua-nginx-module/archive/v${NGINX_LUA_MODULE_VERSION}.tar.gz -o lua-nginx-module-v${NGINX_LUA_MODULE_VERSION}.tar.gz curl -fSL https://github.com/openresty/headers-more-nginx-module/archive/v${HEADERS_MORE_VERSION}.tar.gz -o headers-more-nginx-module-v${HEADERS_MORE_VERSION}.tar.gz curl -fSL https://github.com/yaoweibin/nginx_upstream_check_module/archive/v${UPSTREAM_CHECK_VERSION}.tar.gz -o nginx_upstream_check_module-v${UPSTREAM_CHECK_VERSION}.tar.gz curl -fSL https://github.com/simpl/ngx_devel_kit/archive/v${DEVEL_KIT_VERSION}.tar.gz -o ngx_devel_kit-v${DEVEL_KIT_VERSION}.tar.gz curl -fSL http://luajit.org/download/LuaJIT-$LUAJIT_VERSION.tar.gz -o LuaJIT-$LUAJIT_VERSION.tar.gz curl -fSL https://raw.githubusercontent.com/cloudflare/sslconfig/master/patches/openssl__chacha20_poly1305_draft_and_rfc_ossl102j.patch -o openssl__chacha20_poly1305_draft_and_rfc_ossl102j.patch #curl -fSL https://raw.githubusercontent.com/cloudflare/sslconfig/master/patches/nginx__dynamic_tls_records.patch -o nginx__dynamic_tls_records.patch #curl -fSL https://raw.githubusercontent.com/cloudflare/sslconfig/master/patches/nginx__http2_spdy.patch -o nginx__http2_spdy.patch curl -fSL https://github.com/grahamedgecombe/nginx-ct/archive/v${NGINX_CT_VERSION}.tar.gz -o nginx-ct-v${NGINX_CT_VERSION}.tar.gz tar -zxC /usr/src -f tengine.tar.gz tar -zxC /usr/src -f openssl-${OPENSSL_VERSION}.tar.gz tar -zxC /usr/src -f lua-nginx-module-v${NGINX_LUA_MODULE_VERSION}.tar.gz tar -zxC /usr/src -f headers-more-nginx-module-v${HEADERS_MORE_VERSION}.tar.gz tar -zxC /usr/src -f nginx_upstream_check_module-v${UPSTREAM_CHECK_VERSION}.tar.gz tar -zxC /usr/src -f lua-nginx-module-v$NGINX_LUA_MODULE_VERSION.tar.gz tar -zxC /usr/src -f ngx_devel_kit-v${DEVEL_KIT_VERSION}.tar.gz tar -zxC /usr/src -f LuaJIT-$LUAJIT_VERSION.tar.gz tar -zxC /usr/src -f nginx-ct-v${NGINX_CT_VERSION}.tar.gz rm -f tengine.tar.gz rm -f openssl-${OPENSSL_VERSION}.tar.gz rm -f lua-nginx-module-v${NGINX_LUA_MODULE_VERSION}.tar.gz rm -f headers-more-nginx-module-v${HEADERS_MORE_VERSION}.tar.gz rm -f nginx_upstream_check_module-v${UPSTREAM_CHECK_VERSION}.tar.gz rm -f ngx_devel_kit-v${DEVEL_KIT_VERSION}.tar.gz rm -f LuaJIT-$LUAJIT_VERSION.tar.gz rm -f nginx-ct-v${NGINX_CT_VERSION}.tar.gz #mv nginx__dynamic_tls_records.patch /usr/src/nginx-${NGINX_VERSION} #mv nginx__http2_spdy.patch /usr/src/nginx-${NGINX_VERSION} mv openssl__chacha20_poly1305_draft_and_rfc_ossl102j.patch /usr/src/openssl-${OPENSSL_VERSION} } # patch to nginx function _patch_nginx(){ echo -e \"\\033[32mpatch to nginx...\\033[0m\" cd /usr/src/nginx-$NGINX_VERSION patch -p1 < nginx__dynamic_tls_records.patch patch -p1 < nginx__http2_spdy.patch } # patch to openssl function _patch_openssl(){ echo -e \"\\033[32mpatch to openssl...\\033[0m\" cd /usr/src/openssl-${OPENSSL_VERSION} patch -p1 < openssl__chacha20_poly1305_draft_and_rfc_ossl102j.patch } # install openssl function install_openssl(){ echo -e \"\\033[32minstall openssl $OPENSSL_VERSION ...\\033[0m\" cd /usr/src/openssl-${OPENSSL_VERSION} ./config shared zlib-dynamic make && make install echo -e \"\\033[32mbackup old files...\\033[0m\" mv /usr/bin/openssl /usr/bin/openssl.old || true mv /usr/include/openssl /usr/include/openssl.old || true # link new file ln -s /usr/local/ssl/bin/openssl /usr/bin/openssl ln -s /usr/local/ssl/include/openssl /usr/include/openssl mv /usr/lib/libssl.so /usr/lib/libssl.so.old || true mv /usr/local/lib64/libssl.so /usr/local/lib64/libssl.so.old || true # link new lib ln -s /usr/local/ssl/lib/libssl.so /usr/lib/libssl.so ln -s /usr/local/ssl/lib/libssl.so /usr/local/lib64/libssl.so # reload lib echo \"/usr/local/ssl/lib\" >> /etc/ld.so.conf ldconfig -v } # install Lua function install_lua(){ echo -e \"\\033[32minstall Lua $LUAJIT_VERSION ...\\033[0m\" cd /usr/src/LuaJIT-$LUAJIT_VERSION make -j$(getconf _NPROCESSORS_ONLN) make install } # install nginx function install_nginx(){ echo -e \"\\033[32minstall nginx $NGINX_VERSION ...\\033[0m\" cd /usr/src/tengine-$TENGINE_VERSION ./configure $CONFIG_ARGS --with-debug make -j$(getconf _NPROCESSORS_ONLN) make install } # clean function _clean(){ echo -e \"\\033[32mcleaning files...\\033[0m\" rm -rf /usr/src/* } _installdep _downloadfiles #_patch_nginx _patch_openssl install_openssl install_lua install_nginx _clean"
        },
        {
            "filename": "file_681.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_681.sh",
            "content": "#!/usr/bin/env bash set -e VERSION=${VERSION:-\"2.3.0\"} BUILD_DIR=$(mktemp -d -t caddy2_build-XXXXXXXXXX) function clean(){ info \"Clean build dir: ${BUILD_DIR}\" rm -rf ${BUILD_DIR} } function build(){ info \"Create build dir: ${BUILD_DIR}\" mkdir -p ${BUILD_DIR}/{etc/caddy,usr/{bin,share/caddy},lib/systemd/system} info \"Dir tree:\" tree ${BUILD_DIR} info \"Install xcaddy...\" go get -u github.com/caddyserver/xcaddy/cmd/xcaddy info \"Building caddy...\" xcaddy build v${VERSION} --output ${BUILD_DIR}/usr/bin/caddy \\ --with github.com/abiosoft/caddy-exec \\ --with github.com/caddy-dns/cloudflare \\ --with github.com/caddy-dns/dnspod \\ --with github.com/caddy-dns/duckdns \\ --with github.com/caddy-dns/gandi \\ --with github.com/caddy-dns/route53 \\ --with github.com/greenpau/caddy-auth-jwt \\ --with github.com/greenpau/caddy-auth-portal \\ --with github.com/greenpau/caddy-trace \\ --with github.com/hairyhenderson/caddy-teapot-module \\ --with github.com/kirsch33/realip \\ --with github.com/porech/caddy-maxmind-geolocation \\ --with github.com/mholt/caddy-webdav } function create_config(){ info \"Clone deb config repo: https://github.com/caddyserver/dist.git\" git clone https://github.com/caddyserver/dist.git ${BUILD_DIR}/caddy_config info \"Copy config...\" cp ${BUILD_DIR}/caddy_config/init/caddy.service ${BUILD_DIR}/lib/systemd/system/caddy.service cp ${BUILD_DIR}/caddy_config/init/caddy-api.service ${BUILD_DIR}/lib/systemd/system/caddy-api.service cp ${BUILD_DIR}/caddy_config/config/Caddyfile ${BUILD_DIR}/etc/caddy/Caddyfile cp ${BUILD_DIR}/caddy_config/welcome/index.html ${BUILD_DIR}/usr/share/caddy/index.html cp -r ${BUILD_DIR}/caddy_config/scripts ${BUILD_DIR}/scripts rm -rf ${BUILD_DIR}/caddy_config info \"Dir tree:\" tree ${BUILD_DIR} } function package(){ info \"Create deb package...\" (cd ${BUILD_DIR} && \\ docker run --rm -it -v `pwd`:/pkg_files -w /pkg_files -v `pwd`/dist:/dist mritd/fpm \\ fpm -s dir -t deb -n caddy2 -p /dist/caddy2_v${VERSION}.deb \\ -v ${VERSION} \\ --vendor \"mritd <mritd@linux.com>\" \\ --maintainer \"mritd <mritd@linux.com>\" \\ --after-install /pkg_files/scripts/postinstall.sh \\ --before-remove /pkg_files/scripts/preremove.sh \\ --after-remove /pkg_files/scripts/postremove.sh \\ --deb-systemd /pkg_files/lib/systemd/system/caddy.service \\ --no-deb-systemd-auto-start \\ --no-deb-systemd-restart-after-upgrade \\ etc usr lib) mv ${BUILD_DIR}/dist/caddy2_v${VERSION}.deb . } function info(){ echo -e \"\\033[32mINFO: $@\\033[0m\" } function warn(){ echo -e \"\\033[33mWARN: $@\\033[0m\" } function err(){ echo -e \"\\033[31mERROR: $@\\033[0m\" } build create_config package clean"
        },
        {
            "filename": "file_682.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_682.sh",
            "content": "#/bin/bash echo -e \"\\033[30m \u9ed1\u8272\u5b57 \\033[0m\" echo -e \"\\033[31m \u7ea2\u8272\u5b57 \\033[0m\" echo -e \"\\033[32m \u7eff\u8272\u5b57 \\033[0m\" echo -e \"\\033[33m \u9ec4\u8272\u5b57 \\033[0m\" echo -e \"\\033[34m \u84dd\u8272\u5b57 \\033[0m\" echo -e \"\\033[35m \u7d2b\u8272\u5b57 \\033[0m\" echo -e \"\\033[36m \u5929\u84dd\u5b57 \\033[0m\" echo -e \"\\033[37m \u767d\u8272\u5b57 \\033[0m\" echo -e \"\\033[40;37m \u9ed1\u5e95\u767d\u5b57 \\033[0m\" echo -e \"\\033[41;37m \u7ea2\u5e95\u767d\u5b57 \\033[0m\" echo -e \"\\033[42;37m \u7eff\u5e95\u767d\u5b57 \\033[0m\" echo -e \"\\033[43;37m \u9ec4\u5e95\u767d\u5b57 \\033[0m\" echo -e \"\\033[44;37m \u84dd\u5e95\u767d\u5b57 \\033[0m\" echo -e \"\\033[45;37m \u7d2b\u5e95\u767d\u5b57 \\033[0m\" echo -e \"\\033[46;37m \u5929\u84dd\u5e95\u767d\u5b57 \\033[0m\" echo -e \"\\033[47;30m \u767d\u5e95\u9ed1\u5b57 \\033[0m\""
        },
        {
            "filename": "file_683.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_683.sh",
            "content": "#!/bin/bash set -e CONSUL_VERSION=\"1.2.1\" CONSUL_DONWLOAD_URL=\"https://releases.hashicorp.com/consul/${CONSUL_VERSION}/consul_${CONSUL_VERSION}_linux_amd64.zip\" preinstall(){ if ! command -v unzip >/dev/null 2>&1; then echo -e \"\\033[31mError: unzip not found!\\033[0m\" exit 1 fi getent group consul >/dev/null || groupadd -r consul getent passwd consul >/dev/null || useradd -r -g consul -d /var/lib/consul -s /sbin/nologin -c \"consul user\" consul if [ ! -d /var/lib/consul ]; then mkdir /var/lib/consul chown -R consul:consul /var/lib/consul chmod -R 0755 /var/lib/consul fi if [ ! -d /etc/consul ]; then mkdir /etc/consul fi } postinstall(){ # Initial installation systemctl --no-reload preset consul.service >/dev/null 2>&1 || : systemctl enable consul rm -f consul_${CONSUL_VERSION}_linux_amd64.zip } preuninstall(){ # Package removal, not upgrade systemctl --no-reload disable --now consul.service > /dev/null 2>&1 || : } install(){ wget ${CONSUL_DONWLOAD_URL} unzip consul_${CONSUL_VERSION}_linux_amd64.zip -d /usr/local/bin chmod +x /usr/local/bin/consul cat > /etc/consul/consul.json <<EOF { \"datacenter\": \"dc1\", \"data_dir\": \"/var/lib/consul\", \"disable_update_check\": true, \"log_level\": \"INFO\", \"node_name\": \"consul1\", \"server\": true, \"ui\": true, \"bootstrap_expect\": 1, \"bind_addr\": \"192.168.1.11\", \"client_addr\": \"192.168.1.11\", \"retry_join\": [\"192.168.1.12\",\"192.168.1.13\"], \"retry_interval\": \"10s\", \"protocol\": 3, \"raft_protocol\": 3, \"enable_debug\": false, \"rejoin_after_leave\": true, \"enable_syslog\": false } EOF cat >/lib/systemd/system/consul.service <<EOF [Unit] Description=Consul Server After=network.target After=network-online.target Wants=network-online.target [Service] Type=simple WorkingDirectory=/var/lib/consul/ User=consul # set GOMAXPROCS to number of processors ExecStart=/bin/bash -c \"GOMAXPROCS=$(nproc) /usr/local/bin/consul agent -config-file /etc/consul/consul.json\" Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF } uninstall(){ systemctl stop consul || true rm -rf consul_1.0.7_linux_amd64.zip \\ /usr/local/bin/consul \\ /etc/consul \\ /var/lib/consul \\ /lib/systemd/system/consul.service systemctl daemon-reload userdel consul } if [ \"$1\" == \"install\" ]; then preinstall install postinstall elif [ \"$1\" == \"uninstall\" ]; then preuninstall uninstall else echo -e \"\\033[31mError: command not support!\\033[0m\" exit 1 fi"
        },
        {
            "filename": "file_684.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_684.sh",
            "content": "#!/bin/bash set -e REGISTRY_TOKEN=`sudo cat ~/.docker/config.json | base64 | tr -d '\\n'` REGISTRY_ADDRESS=${1} NAMESPACE=${2} if [ \"\" == \"${REGISTRY_ADDRESS}\" ]; then echo -e \"\\033[33mWARNING: REGISTRY_ADDRESS is blank,use default value ==> reg.mritd.me\\033[0m\" REGISTRY_ADDRESS=\"reg.mritd.me\" fi if [ \"\" == \"${NAMESPACE}\" ]; then echo -e \"\\033[33mWARNING: NAMESPACE is blank,use default value ==> default\\033[0m\" NAMESPACE=\"default\" fi tee imagePullSecret.yaml <<EOF apiVersion: v1 kind: Secret metadata: name: ${REGISTRY_ADDRESS} namespace: ${NAMESPACE} data: .dockerconfigjson: ${REGISTRY_TOKEN} type: kubernetes.io/dockerconfigjson EOF kubectl create -f imagePullSecret.yaml kubectl patch serviceaccounts default -p \"{\\\"imagePullSecrets\\\":[{\\\"name\\\":\\\"${REGISTRY_ADDRESS}\\\"}]}\" -n ${NAMESPACE} rm -f imagePullSecret.yaml"
        },
        {
            "filename": "file_685.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_685.sh",
            "content": "#!/usr/bin/env bash set -e EXITCODE=0 # bits of this were adapted from lxc-checkconfig # see also https://github.com/lxc/lxc/blob/lxc-1.0.2/src/lxc/lxc-checkconfig.in possibleConfigs=( '/proc/config.gz' \"/boot/config-$(uname -r)\" \"/usr/src/linux-$(uname -r)/.config\" '/usr/src/linux/.config' ) if [ $# -gt 0 ]; then CONFIG=\"$1\" else : \"${CONFIG:=\"${possibleConfigs[0]}\"}\" fi if ! command -v zgrep &> /dev/null; then zgrep() { zcat \"$2\" | grep \"$1\" } fi kernelVersion=\"$(uname -r)\" kernelMajor=\"${kernelVersion%%.*}\" kernelMinor=\"${kernelVersion#$kernelMajor.}\" kernelMinor=\"${kernelMinor%%.*}\" is_set() { zgrep \"CONFIG_$1=[y|m]\" \"$CONFIG\" > /dev/null } is_set_in_kernel() { zgrep \"CONFIG_$1=y\" \"$CONFIG\" > /dev/null } is_set_as_module() { zgrep \"CONFIG_$1=m\" \"$CONFIG\" > /dev/null } color() { local codes=() if [ \"$1\" = 'bold' ]; then codes=(\"${codes[@]}\" '1') shift fi if [ \"$#\" -gt 0 ]; then local code= case \"$1\" in # see https://en.wikipedia.org/wiki/ANSI_escape_code#Colors black) code=30 ;; red) code=31 ;; green) code=32 ;; yellow) code=33 ;; blue) code=34 ;; magenta) code=35 ;; cyan) code=36 ;; white) code=37 ;; esac if [ \"$code\" ]; then codes=(\"${codes[@]}\" \"$code\") fi fi local IFS=';' echo -en '\\033['\"${codes[*]}\"'m' } wrap_color() { text=\"$1\" shift color \"$@\" echo -n \"$text\" color reset echo } wrap_good() { echo \"$(wrap_color \"$1\" white): $(wrap_color \"$2\" green)\" } wrap_bad() { echo \"$(wrap_color \"$1\" bold): $(wrap_color \"$2\" bold red)\" } wrap_warning() { wrap_color >&2 \"$*\" red } check_flag() { if is_set_in_kernel \"$1\"; then wrap_good \"CONFIG_$1\" 'enabled' elif is_set_as_module \"$1\"; then wrap_good \"CONFIG_$1\" 'enabled (as module)' else wrap_bad \"CONFIG_$1\" 'missing' EXITCODE=1 fi } check_flags() { for flag in \"$@\"; do echo -n \"- \" check_flag \"$flag\" done } check_command() { if command -v \"$1\" > /dev/null 2>&1; then wrap_good \"$1 command\" 'available' else wrap_bad \"$1 command\" 'missing' EXITCODE=1 fi } check_device() { if [ -c \"$1\" ]; then wrap_good \"$1\" 'present' else wrap_bad \"$1\" 'missing' EXITCODE=1 fi } check_distro_userns() { source /etc/os-release 2> /dev/null || /bin/true if [[ \"${ID}\" =~ ^(centos|rhel)$ && \"${VERSION_ID}\" =~ ^7 ]]; then # this is a CentOS7 or RHEL7 system grep -q \"user_namespace.enable=1\" /proc/cmdline || { # no user namespace support enabled wrap_bad \" (RHEL7/CentOS7\" \"User namespaces disabled; add 'user_namespace.enable=1' to boot command line)\" EXITCODE=1 } fi } if [ ! -e \"$CONFIG\" ]; then wrap_warning \"warning: $CONFIG does not exist, searching other paths for kernel config ...\" for tryConfig in \"${possibleConfigs[@]}\"; do if [ -e \"$tryConfig\" ]; then CONFIG=\"$tryConfig\" break fi done if [ ! -e \"$CONFIG\" ]; then wrap_warning \"error: cannot find kernel config\" wrap_warning \" try running this script again, specifying the kernel config:\" wrap_warning \" CONFIG=/path/to/kernel/.config $0 or $0 /path/to/kernel/.config\" exit 1 fi fi wrap_color \"info: reading kernel config from $CONFIG ...\" white echo echo 'Generally Necessary:' echo -n '- ' cgroupSubsystemDir=\"$(awk '/[, ](cpu|cpuacct|cpuset|devices|freezer|memory)[, ]/ && $3 == \"cgroup\" { print $2 }' /proc/mounts | head -n1)\" cgroupDir=\"$(dirname \"$cgroupSubsystemDir\")\" if [ -d \"$cgroupDir/cpu\" ] || [ -d \"$cgroupDir/cpuacct\" ] || [ -d \"$cgroupDir/cpuset\" ] || [ -d \"$cgroupDir/devices\" ] || [ -d \"$cgroupDir/freezer\" ] || [ -d \"$cgroupDir/memory\" ]; then echo \"$(wrap_good 'cgroup hierarchy' 'properly mounted') [$cgroupDir]\" else if [ \"$cgroupSubsystemDir\" ]; then echo \"$(wrap_bad 'cgroup hierarchy' 'single mountpoint!') [$cgroupSubsystemDir]\" else wrap_bad 'cgroup hierarchy' 'nonexistent??' fi EXITCODE=1 echo \" $(wrap_color '(see https://github.com/tianon/cgroupfs-mount)' yellow)\" fi if [ \"$(cat /sys/module/apparmor/parameters/enabled 2> /dev/null)\" = 'Y' ]; then echo -n '- ' if command -v apparmor_parser &> /dev/null; then wrap_good 'apparmor' 'enabled and tools installed' else wrap_bad 'apparmor' 'enabled, but apparmor_parser missing' echo -n ' ' if command -v apt-get &> /dev/null; then wrap_color '(use \"apt-get install apparmor\" to fix this)' elif command -v yum &> /dev/null; then wrap_color '(your best bet is \"yum install apparmor-parser\")' else wrap_color '(look for an \"apparmor\" package for your distribution)' fi EXITCODE=1 fi fi flags=( NAMESPACES {NET,PID,IPC,UTS}_NS CGROUPS CGROUP_CPUACCT CGROUP_DEVICE CGROUP_FREEZER CGROUP_SCHED CPUSETS MEMCG KEYS VETH BRIDGE BRIDGE_NETFILTER NF_NAT_IPV4 IP_NF_FILTER IP_NF_TARGET_MASQUERADE NETFILTER_XT_MATCH_{ADDRTYPE,CONNTRACK,IPVS} IP_NF_NAT NF_NAT NF_NAT_NEEDED # required for bind-mounting /dev/mqueue into containers POSIX_MQUEUE ) check_flags \"${flags[@]}\" if [ \"$kernelMajor\" -lt 4 ] || ([ \"$kernelMajor\" -eq 4 ] && [ \"$kernelMinor\" -lt 8 ]); then check_flags DEVPTS_MULTIPLE_INSTANCES fi echo echo 'Optional Features:' { check_flags USER_NS check_distro_userns } { check_flags SECCOMP } { check_flags CGROUP_PIDS } { CODE=${EXITCODE} check_flags MEMCG_SWAP MEMCG_SWAP_ENABLED if [ -e /sys/fs/cgroup/memory/memory.memsw.limit_in_bytes ]; then echo \" $(wrap_color '(cgroup swap accounting is currently enabled)' bold black)\" EXITCODE=${CODE} elif is_set MEMCG_SWAP && ! is_set MEMCG_SWAP_ENABLED; then echo \" $(wrap_color '(cgroup swap accounting is currently not enabled, you can enable it by setting boot option \"swapaccount=1\")' bold black)\" fi } { if is_set LEGACY_VSYSCALL_NATIVE; then echo -n \"- \" wrap_bad \"CONFIG_LEGACY_VSYSCALL_NATIVE\" 'enabled' echo \" $(wrap_color '(dangerous, provides an ASLR-bypassing target with usable ROP gadgets.)' bold black)\" elif is_set LEGACY_VSYSCALL_EMULATE; then echo -n \"- \" wrap_good \"CONFIG_LEGACY_VSYSCALL_EMULATE\" 'enabled' elif is_set LEGACY_VSYSCALL_NONE; then echo -n \"- \" wrap_bad \"CONFIG_LEGACY_VSYSCALL_NONE\" 'enabled' echo \" $(wrap_color '(containers using eglibc <= 2.13 will not work. Switch to' bold black)\" echo \" $(wrap_color ' \"CONFIG_VSYSCALL_[NATIVE|EMULATE]\" or use \"vsyscall=[native|emulate]\"' bold black)\" echo \" $(wrap_color ' on kernel command line. Note that this will disable ASLR for the,' bold black)\" echo \" $(wrap_color ' VDSO which may assist in exploiting security vulnerabilities.)' bold black)\" # else Older kernels (prior to 3dc33bd30f3e, released in v4.40-rc1) do # not have these LEGACY_VSYSCALL options and are effectively # LEGACY_VSYSCALL_EMULATE. Even older kernels are presumably # effectively LEGACY_VSYSCALL_NATIVE. fi } if [ \"$kernelMajor\" -lt 4 ] || ([ \"$kernelMajor\" -eq 4 ] && [ \"$kernelMinor\" -le 5 ]); then check_flags MEMCG_KMEM fi if [ \"$kernelMajor\" -lt 3 ] || ([ \"$kernelMajor\" -eq 3 ] && [ \"$kernelMinor\" -le 18 ]); then check_flags RESOURCE_COUNTERS fi if [ \"$kernelMajor\" -lt 3 ] || ([ \"$kernelMajor\" -eq 3 ] && [ \"$kernelMinor\" -le 13 ]); then netprio=NETPRIO_CGROUP else netprio=CGROUP_NET_PRIO fi flags=( BLK_CGROUP BLK_DEV_THROTTLING IOSCHED_CFQ CFQ_GROUP_IOSCHED CGROUP_PERF CGROUP_HUGETLB NET_CLS_CGROUP $netprio CFS_BANDWIDTH FAIR_GROUP_SCHED RT_GROUP_SCHED IP_NF_TARGET_REDIRECT IP_VS IP_VS_NFCT IP_VS_PROTO_TCP IP_VS_PROTO_UDP IP_VS_RR ) check_flags \"${flags[@]}\" if ! is_set EXT4_USE_FOR_EXT2; then check_flags EXT3_FS EXT3_FS_XATTR EXT3_FS_POSIX_ACL EXT3_FS_SECURITY if ! is_set EXT3_FS || ! is_set EXT3_FS_XATTR || ! is_set EXT3_FS_POSIX_ACL || ! is_set EXT3_FS_SECURITY; then echo \" $(wrap_color '(enable these ext3 configs if you are using ext3 as backing filesystem)' bold black)\" fi fi check_flags EXT4_FS EXT4_FS_POSIX_ACL EXT4_FS_SECURITY if ! is_set EXT4_FS || ! is_set EXT4_FS_POSIX_ACL || ! is_set EXT4_FS_SECURITY; then if is_set EXT4_USE_FOR_EXT2; then echo \" $(wrap_color 'enable these ext4 configs if you are using ext3 or ext4 as backing filesystem' bold black)\" else echo \" $(wrap_color 'enable these ext4 configs if you are using ext4 as backing filesystem' bold black)\" fi fi echo '- Network Drivers:' echo \" - \\\"$(wrap_color 'overlay' blue)\\\":\" check_flags VXLAN BRIDGE_VLAN_FILTERING | sed 's/^/ /' echo ' Optional (for encrypted networks):' check_flags CRYPTO CRYPTO_AEAD CRYPTO_GCM CRYPTO_SEQIV CRYPTO_GHASH \\ XFRM XFRM_USER XFRM_ALGO INET_ESP INET_XFRM_MODE_TRANSPORT | sed 's/^/ /' echo \" - \\\"$(wrap_color 'ipvlan' blue)\\\":\" check_flags IPVLAN | sed 's/^/ /' echo \" - \\\"$(wrap_color 'macvlan' blue)\\\":\" check_flags MACVLAN DUMMY | sed 's/^/ /' echo \" - \\\"$(wrap_color 'ftp,tftp client in container' blue)\\\":\" check_flags NF_NAT_FTP NF_CONNTRACK_FTP NF_NAT_TFTP NF_CONNTRACK_TFTP | sed 's/^/ /' # only fail if no storage drivers available CODE=${EXITCODE} EXITCODE=0 STORAGE=1 echo '- Storage Drivers:' echo \" - \\\"$(wrap_color 'aufs' blue)\\\":\" check_flags AUFS_FS | sed 's/^/ /' if ! is_set AUFS_FS && grep -q aufs /proc/filesystems; then echo \" $(wrap_color '(note that some kernels include AUFS patches but not the AUFS_FS flag)' bold black)\" fi [ \"$EXITCODE\" = 0 ] && STORAGE=0 EXITCODE=0 echo \" - \\\"$(wrap_color 'btrfs' blue)\\\":\" check_flags BTRFS_FS | sed 's/^/ /' check_flags BTRFS_FS_POSIX_ACL | sed 's/^/ /' [ \"$EXITCODE\" = 0 ] && STORAGE=0 EXITCODE=0 echo \" - \\\"$(wrap_color 'devicemapper' blue)\\\":\" check_flags BLK_DEV_DM DM_THIN_PROVISIONING | sed 's/^/ /' [ \"$EXITCODE\" = 0 ] && STORAGE=0 EXITCODE=0 echo \" - \\\"$(wrap_color 'overlay' blue)\\\":\" check_flags OVERLAY_FS | sed 's/^/ /' [ \"$EXITCODE\" = 0 ] && STORAGE=0 EXITCODE=0 echo \" - \\\"$(wrap_color 'zfs' blue)\\\":\" echo -n \" - \" check_device /dev/zfs echo -n \" - \" check_command zfs echo -n \" - \" check_command zpool [ \"$EXITCODE\" = 0 ] && STORAGE=0 EXITCODE=0 EXITCODE=$CODE [ \"$STORAGE\" = 1 ] && EXITCODE=1 echo check_limit_over() { if [ \"$(cat \"$1\")\" -le \"$2\" ]; then wrap_bad \"- $1\" \"$(cat \"$1\")\" wrap_color \" This should be set to at least $2, for example set: sysctl -w kernel/keys/root_maxkeys=1000000\" bold black EXITCODE=1 else wrap_good \"- $1\" \"$(cat \"$1\")\" fi } echo 'Limits:' check_limit_over /proc/sys/kernel/keys/root_maxkeys 10000 echo exit $EXITCODE"
        },
        {
            "filename": "file_686.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_686.sh",
            "content": "#!/bin/bash docker ps -a | grep \"Exited\" | awk '{print $1 }'|xargs docker stop docker ps -a | grep \"Exited\" | awk '{print $1 }'|xargs docker rm docker images | grep none | grep -v REPOSITORY | awk '{print $3 }' | xargs docker rmi"
        },
        {
            "filename": "file_687.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_687.sh",
            "content": "#!/usr/bin/env bash CONTAINER=$1 if [ ! ${CONTAINER} ]; then echo \"CONTAINER is empty!\" exit 1 fi docker inspect --format '{{.State.Pid}} {{printf \"%.13s\" .ID}} {{.Name}}' ${CONTAINER} | \\ while read CONTAINER_PID CONTAINER_ID CONTAINER_NAME; do echo ${CONTAINER_ID} ${CONTAINER_NAME} ${CONTAINER_PID} nsenter -t ${CONTAINER_PID} -n netstat -pan | grep ESTABLISHED done"
        },
        {
            "filename": "file_688.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_688.sh",
            "content": "#!/bin/bash set -e OS_TYPE=$1 PROXY_ADDRESS=$2 if [ \"${PROXY_ADDRESS}\" == \"\" ]; then echo -e \"\\033[31mError: PROXY_ADDRESS is blank!\\033[0m\" echo -e \"\\033[32mUse: sudo $0 centos|ubuntu 1.2.3.4:1080\\033[0m\" exit 1 fi if [ \"${OS_TYPE}\" == \"\" ];then echo -e \"\\033[31mError: OS_TYPE is blank!\\033[0m\" echo -e \"\\033[32mUse: sudo $0 centos|ubuntu\\033[0m\" exit 1 elif [ \"${OS_TYPE}\" == \"centos\" ];then mkdir /etc/systemd/system/docker.service.d || true tee /etc/systemd/system/docker.service.d/socks5-proxy.conf <<-EOF [Service] Environment=\"ALL_PROXY=socks5://${PROXY_ADDRESS}\" EOF elif [ \"${OS_TYPE}\" == \"ubuntu\" ];then mkdir /lib/systemd/system/docker.service.d || true tee /lib/systemd/system/docker.service.d/socks5-proxy.conf <<-EOF [Service] Environment=\"ALL_PROXY=socks5://${PROXY_ADDRESS}\" EOF fi systemctl daemon-reload systemctl restart docker systemctl show docker --property Environment"
        },
        {
            "filename": "file_689.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_689.sh",
            "content": "#!/bin/bash set -e if [ \"$1\" == \"\" ]; then echo -e \"\\033[31mError: imageName is blank!\\033[0m\" exit 1 elif [ \"$1\" == \"all\" ]; then for imageName in `docker images | grep -v \"REPOSITORY\" | awk '{print $1\":\"$2}'`; do docker save $imageName > `echo $imageName | tr '/' '_' | tr ':' '_'`.tar done else docker save $1 > `echo $1 | tr '/' '_' | tr ':' '_'`.tar fi"
        },
        {
            "filename": "file_690.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_690.sh",
            "content": "#!/bin/bash KUBE_API_SERVER=$1 CERT_DIR=${2:-\"/etc/kubernetes/ssl\"} kubectl config set-cluster default-cluster --server=${KUBE_API_SERVER} \\ --certificate-authority=${CERT_DIR}/k8s-root-ca.pem \\ --embed-certs=true \\ --kubeconfig=admin.kubeconfig kubectl config set-credentials default-admin \\ --certificate-authority=${CERT_DIR}/k8s-root-ca.pem \\ --embed-certs=true \\ --client-key=${CERT_DIR}/admin-key.pem \\ --client-certificate=${CERT_DIR}/admin.pem \\ --kubeconfig=admin.kubeconfig kubectl config set-context default-system --cluster=default-cluster \\ --user=default-admin \\ --kubeconfig=admin.kubeconfig kubectl config use-context default-system --kubeconfig=admin.kubeconfig"
        },
        {
            "filename": "file_691.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_691.sh",
            "content": "#!/bin/bash #set -x # Shows you the largest objects in your repo's pack file. # Written for osx. # # @see http://stubbisms.wordpress.com/2009/07/10/git-script-to-show-largest-pack-objects-and-trim-your-waist-line/ # @author Antony Stubbs # set the internal field spereator to line break, so that we can iterate easily over the verify-pack output IFS=$'\\n'; # list all objects including their size, sort by size, take top 10 objects=`git verify-pack -v .git/objects/pack/pack-*.idx | grep -Ev \"non delta|chain length|git/objects\" | tr -s \" \" | sort -k3gr | head -n30` echo \"All sizes are in kB's. The pack column is the size of the object, compressed, inside the pack file.\" output=\"size,SHA,location\" for y in $objects do # extract the size in KB size=$((`echo $y | cut -f 3 -d ' '`/1024)) # extract the SHA sha=`echo $y | cut -f 1 -d ' '` # find the objects location in the repository tree other=`git rev-list --all --objects | grep $sha` #lineBreak=`echo -e \"\\n\"` output=\"${output}\\n${size},${other}\" done echo -e $output | column -t -s ', '"
        },
        {
            "filename": "file_692.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_692.sh",
            "content": "#!/bin/sh obj_name=\"$1\" shift git log \"$@\" --pretty=format:'%T %h %s' \\ | while read tree commit subject ; do if git ls-tree -r $tree | grep -q \"$obj_name\" ; then echo $commit \"$subject\" fi done"
        },
        {
            "filename": "file_693.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_693.sh",
            "content": "#!/bin/bash git rev-list --objects --all | grep \"$(git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -5 | awk '{print$1}')\" git filter-branch --force --index-filter 'git rm -rf --cached --ignore-unmatch BIGFILE' --prune-empty --tag-name-filter cat -- --all git push origin master --force rm -rf .git/refs/original/ git reflog expire --expire=now --all git gc --prune=now"
        },
        {
            "filename": "file_694.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_694.sh",
            "content": "#!/bin/bash git config --global user.name mritd git config --global user.email mritd1234@gmail.com git config --global core.editor vim git config --global push.default simple git config --global core.excludesfile ~/.global_gitignore git config --global user.signingkey 1C78FD62CEA2C04B79EA459F7CB6F1DA9030B819 git config --global commit.gpgsign true git config --global gpg.program gpg git config --global core.quotepath false echo \".idea\" >> ~/.global_gitignore"
        },
        {
            "filename": "file_695.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_695.sh",
            "content": "#!/bin/bash yum update -y yum install epel-release -y yum install tmux wget lrzsz vim net-tools zsh bind-utils yum-utils ctags git htop -y sh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\""
        },
        {
            "filename": "file_696.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_696.sh",
            "content": "#!/bin/bash # This script is use to automatically configure Conoha LAN IP # reference https://www.conoha.jp/conoben/archives/10174 IPADDR=$1 if [ \"$IPADDR\" == \"\" ]; then echo -e \"\\033[33merror: ip address is blank\\033[0m\" echo -e \"\\033[32muse ./init_private_neiwork.sh IPADDRESS NETMASK [ETH_BUMBER] [MAC_ADDRESS]\\033[0m\" exit 1 fi NETMASK=$2 if [ \"$NETMASK\" == \"\" ]; then echo -e \"\\033[33merror: netmask is blank\\033[0m\" echo -e \"\\033[32muse ./init_private_neiwork.sh IPADDRESS NETMASK [ETH_BUMBER] [MAC_ADDRESS]\\033[0m\" exit 1 fi ETH_BUMBER=$3 if [ \"$ETH_BUMBER\" == \"\" ]; then ETH_BUMBER=\"eth1\" fi MAC_ADDRESS=$4 if [ \"$MAC_ADDRESS\" == \"\" ]; then yum update -y >> /dev/null 2>&1 && yum upgrade -y >> /dev/null 2>&1 && yum install net-tools >> /dev/null 2>&1 MAC_ADDRESS=`ifconfig \"$ETH_BUMBER\" | grep ether | awk -F\" \" '{print $2}'` if [ \"$MAC_ADDRESS\" == \"\" ]; then echo -e \"\\033[33mget MAC_ADDRESS\" echo -e \"\\033[33mget MAC_ADDRESS failed! please input MAC_ADDRESS!\" exit 1 fi fi echo -e \"\\033[32mupdate /etc/sysconfig/network-scripts/ifcfg-$ETH_BUMBER...\\033[0m\" echo \"\" # setting network tee /etc/sysconfig/network-scripts/ifcfg-$ETH_BUMBER <<EOF DEVICE=$ETH_BUMBER TYPE=Ethernet HWADDR=$MAC_ADDRESS ONBOOT=yes NM_CONTROLLED=no BOOTPROTO=static IPADDR=$IPADDR NETMASK=$NETMASK EOF echo \"\" echo -e \"\\033[32mupdate /etc/iproute2/rt_tables...\\033[0m\" echo \"\" tee /etc/iproute2/rt_tables <<EOF 201 gate1 EOF echo \"\" echo -e \"\\033[32mupdate /etc/sysconfig/network-scripts/rule-$ETH_BUMBER...\\033[0m\" echo \"\" tee /etc/sysconfig/network-scripts/rule-$ETH_BUMBER <<EOF from $IPADDR table gate1 EOF echo \"\" echo -e \"\\033[32mupdate /etc/sysconfig/network-scripts/route-$ETH_BUMBER...\\033[0m\" echo \"\" tee /etc/sysconfig/network-scripts/route-$ETH_BUMBER <<EOF default via $IPADDR table gate1 EOF echo \"\" echo -e \"\\033[32mrestart network...\\033[0m\" systemctl restart network"
        },
        {
            "filename": "file_697.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_697.sh",
            "content": "#!/bin/bash set -e TZ='Asia/Shanghai' OS_RELEASE=\"$(lsb_release -cs)\" SOURCES_LIST_URL='https://git.io/fhQ6B' DOCKER_LIST_URL='https://git.io/fhQ68' OZ_DOWNLOAD_URL='https://github.com/robbyrussell/oh-my-zsh.git' OZ_CONFIG_DOWNLOAD_URL='https://git.io/fh9U2' OZ_SYNTAX_HIGHLIGHTING_DOWNLOAD_URL='https://github.com/zsh-users/zsh-syntax-highlighting.git' VIM_CONFIG_DOWNLOAD_URL='https://git.io/fh9rI' VIM_PLUGINS_DOWNLOAD_URL='https://git.io/fh9r3' DOCKER_CONFIG_DOWNLOAD_URL='https://git.io/fh9Ui' CTOP_DOWNLOAD_URL='https://github.com/bcicen/ctop/releases/download/v0.7.2/ctop-0.7.2-linux-amd64' DOCKER_COMPOSE_DOWNLOAD_URL=\"https://github.com/docker/compose/releases/download/1.23.2/docker-compose-Linux-x86_64\" HEY_DOWNLOAD_URL=\"https://storage.googleapis.com/hey-release/hey_linux_amd64\" BAT_DOWNLOAD_URL=\"https://github.com/sharkdp/bat/releases/download/v0.12.1/bat-v0.12.1-x86_64-unknown-linux-gnu.tar.gz\" PERF_TOOLS_DOWNLOAD_URL=\"https://github.com/brendangregg/perf-tools\" TERMSHARK_DOWNLOAD_URL=\"https://github.com/gcla/termshark/releases/download/v2.1.1/termshark_2.1.1_linux_x64.tar.gz\" function setlocale(){ if [ ! -f /etc/locale.gen.bak ]; then cp /etc/locale.gen /etc/locale.gen.bak echo 'en_US.UTF-8 UTF-8' > /etc/locale.gen echo 'zh_CN.UTF-8 UTF-8' >> /etc/locale.gen fi locale-gen --purge localectl set-locale LANG=en_US.UTF-8 } function sysupdate(){ if [ ! -f /etc/apt/sources.list.bak ]; then cp /etc/apt/sources.list /etc/apt/sources.list.old curl -fsSL ${SOURCES_LIST_URL} | sed \"s@{{OS_RELEASE}}@${OS_RELEASE}@gi\" > /etc/apt/sources.list fi apt update -y apt upgrade -y apt install -y apt-transport-https ca-certificates software-properties-common \\ wget vim zsh git htop tzdata conntrack ipvsadm ipset stress sysstat axel apt autoremove -y apt autoclean -y } function settimezone(){ timedatectl set-timezone ${TZ} } function install_ohmyzsh(){ if [ ! -d ~/.oh-my-zsh ]; then git clone --depth=1 ${OZ_DOWNLOAD_URL} ~/.oh-my-zsh git clone ${OZ_SYNTAX_HIGHLIGHTING_DOWNLOAD_URL} ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting curl -fsSL ${OZ_CONFIG_DOWNLOAD_URL} > ~/.zshrc chsh -s $(grep /zsh$ /etc/shells | tail -1) fi } function config_vim(){ curl -fsSL ${VIM_CONFIG_DOWNLOAD_URL} > ~/.vimrc mkdir -p ~/.vim/pack/plugins/{start,opt} cd ~/.vim/pack/plugins/start for addr in `curl -fsSL ${VIM_PLUGINS_DOWNLOAD_URL}`; do git clone ${addr} done } function install_docker(){ if [ \"${OS_RELEASE}\" == \"focal\" ]; then apt install docker.io -y apt-mark hold docker.io else curl -fsSL ${DOCKER_LIST_URL} | sed \"s@{{OS_RELEASE}}@${OS_RELEASE}@gi\" > /etc/apt/sources.list.d/docker.list curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | apt-key add - apt update -y apt install docker-ce -y apt-mark hold docker-ce fi curl -fsSL ${DOCKER_CONFIG_DOWNLOAD_URL} > docker.service SYSTEMD_EDITOR=\"mv docker.service\" systemctl edit docker systemctl daemon-reload && systemctl restart docker } function install_ctop(){ curl -fsSL ${CTOP_DOWNLOAD_URL} > /usr/local/bin/ctop chmod +x /usr/local/bin/ctop } function install_dc(){ curl -fsSL ${DOCKER_COMPOSE_DOWNLOAD_URL} > /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose } function install_hey(){ curl -fsSL ${HEY_DOWNLOAD_URL} > /usr/local/bin/hey chmod +x /usr/local/bin/hey } function install_bat(){ curl -fsSL ${BAT_DOWNLOAD_URL} > bat.tar.gz tar -zxf bat.tar.gz mv bat-*/bat /usr/local/bin/bat rm -rf bat* } function install_pert-tools(){ git clone --depth 1 ${PERF_TOOLS_DOWNLOAD_URL} /usr/local/perf-tools } function install_termshark(){ curl -fsSL ${TERMSHARK_DOWNLOAD_URL} > termshark.tar.gz tar -zxf termshark.tar.gz mv termshark*/termshark /usr/local/bin/termshark rm -rf termshark* apt install tshark -y } function install_osquery(){ OSQUERY_KEY=1484120AC4E9F8A1A577AEEE97A80C63C9D8B80B apt-key adv --keyserver keyserver.ubuntu.com --recv-keys ${OSQUERY_KEY} add-apt-repository 'deb [arch=amd64] https://pkg.osquery.io/deb deb main' -y apt-get update -y apt-get install osquery -y } setlocale sysupdate settimezone config_vim install_ohmyzsh install_docker install_dc #install_ctop #install_hey #install_bat #install_termshark #install_osquery"
        },
        {
            "filename": "file_698.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_698.sh",
            "content": "set -e VERSION=\"${1}\" if [ -z \"${VERSION}\" ]; then VERSION=\"1.6.9\" echo \"No CoreDNS version specified, use default version: ${VERSION}!\" fi COREDNS_URL=\"https://github.com/coredns/coredns/releases/download/v${VERSION}/coredns_${VERSION}_linux_amd64.tgz\" COREDNS_CONF=\"https://raw.githubusercontent.com/mritd/config/master/coredns/Corefile\" SYSUSERS_CONF=\"https://raw.githubusercontent.com/coredns/deployment/master/systemd/coredns-sysusers.conf\" TEMPFILES_CONF=\"https://raw.githubusercontent.com/coredns/deployment/master/systemd/coredns-tmpfiles.conf\" SERVICE_CONF=\"https://raw.githubusercontent.com/coredns/deployment/master/systemd/coredns.service\" curl -sSL ${COREDNS_URL} > coredns.tar.gz curl -sSL ${SYSUSERS_CONF} > /usr/lib/sysusers.d/coredns-sysusers.conf curl -sSL ${TEMPFILES_CONF} > /usr/lib/tmpfiles.d/coredns-tmpfiles.conf curl -sSL ${SERVICE_CONF} > /lib/systemd/system/coredns.service #tar -zxf coredns.tar.gz --strip-components=1 -C /usr/bin tar -zxf coredns.tar.gz -C /usr/bin systemd-sysusers systemd-tmpfiles --create systemctl daemon-reload if [ ! -d \"/etc/coredns\" ]; then mkdir -p /etc/coredns fi curl -sSL ${COREDNS_CONF} > /etc/coredns/Corefile touch /etc/coredns/hosts rm -f coredns.tar.gz"
        },
        {
            "filename": "file_699.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_699.sh",
            "content": "#!/bin/bash tee /usr/local/bin/proxy <<EOF #!/bin/bash http_proxy=http://192.168.1.21:8123 https_proxy=http://192.168.1.21:8123 \\$* EOF chmod +x /usr/local/bin/proxy"
        },
        {
            "filename": "file_700.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_700.sh",
            "content": "#!/bin/sh if [ -z \"${1}\" ]; then echo \"Usage: ${0} <image> --enable-security-manager\" exit 1 fi target_image=\"${1}\" dockerfile=\" FROM ${target_image} WORKDIR /var/tmp RUN printf ' \\\\ public class DNSTTLPolicy { \\\\ public static void main(String args[]) { \\\\ System.out.printf(\\\"Implementation DNS TTL for JVM in Docker image based on '${target_image}' is %%d seconds\\\\\\\\n\\\", sun.net.InetAddressCachePolicy.get()); \\\\ } \\\\ }' >DNSTTLPolicy.java RUN javac DNSTTLPolicy.java -XDignore.symbol.file CMD java DNSTTLPolicy ENTRYPOINT java DNSTTLPolicy \" dockerfile_security_manager=\" FROM ${target_image} WORKDIR /var/tmp RUN printf ' \\\\ public class DNSTTLPolicy { \\\\ public static void main(String args[]) { \\\\ System.out.printf(\\\"Implementation DNS TTL for JVM in Docker image based on '${target_image}' (with security manager enabled) is %%d seconds\\\\\\\\n\\\", sun.net.InetAddressCachePolicy.get()); \\\\ } \\\\ }' >DNSTTLPolicy.java RUN printf ' \\\\ grant { \\\\ permission java.security.AllPermission; \\\\ };' >all-permissions.policy RUN javac DNSTTLPolicy.java -XDignore.symbol.file CMD java -Djava.security.manager -Djava.security.policy==all-permissions.policy DNSTTLPolicy ENTRYPOINT java -Djava.security.manager -Djava.security.policy==all-permissions.policy DNSTTLPolicy \" target_dockerfile=\"${dockerfile}\" if [ -n \"${2}\" ] && [ \"${2}\" == \"--enable-security-manager\" ]; then target_dockerfile=\"${dockerfile_security_manager}\" fi tag_name=\"jvm-dns-ttl-policy\" output_file=\"$(mktemp)\" function cleanup() { rm \"${output_file}\" docker rmi \"${tag_name}\" >/dev/null } trap \"cleanup; exit\" SIGHUP SIGINT SIGTERM echo \"Building Docker image based on ${target_image} ...\" >&2 docker build -t \"${tag_name}\" - <<<\"${target_dockerfile}\" &>\"${output_file}\" if [ \"$?\" -ne 0 ]; then >&2 echo \"Error building test image:\" cat \"${output_file}\" cleanup exit 1 fi echo \"Testing DNS TTL ...\" >&2 docker run --rm \"${tag_name}\" &>\"${output_file}\" if [ \"$?\" -ne 0 ]; then >&2 echo \"Error running test image:\" cat \"${output_file}\" cleanup exit 1 fi cat \"${output_file}\" cleanup"
        },
        {
            "filename": "file_701.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_701.sh",
            "content": "#!/bin/bash if [ \"${shellName}\" == \"zsh\" ]; then read \"images?\u8bf7\u8f93\u5165\u5f85\u5bfc\u51fa\u7684\u955c\u50cf\u540d\u79f0: \" else read -p \"\u8f93\u5165\u5f85\u5bfc\u51fa\u7684\u955c\u50cf\u540d\u79f0: \" images fi if [ \"${images}\" = \"\" ]; then echo \"Error: image Name is blank!\" exit 1 fi allImages=(${images}) for imageName in ${allImages[@]}; do echo \"Export image: ${imageName}...\" docker save ${imageName} > `echo ${imageName} | tr '/' '_' | tr ':' '_'`.tar; echo \"done!\" done"
        },
        {
            "filename": "file_702.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\shell_scripts\\file_702.sh",
            "content": "#!/bin/bash VERSION=$1 VERSION2=$2 function version_gt() { test \"$(echo \"$@\" | tr \" \" \"\\n\" | sort -V | head -n 1)\" != \"$1\"; } function version_le() { test \"$(echo \"$@\" | tr \" \" \"\\n\" | sort -V | head -n 1)\" == \"$1\"; } function version_lt() { test \"$(echo \"$@\" | tr \" \" \"\\n\" | sort -rV | head -n 1)\" != \"$1\"; } function version_ge() { test \"$(echo \"$@\" | tr \" \" \"\\n\" | sort -rV | head -n 1)\" == \"$1\"; } if version_gt $VERSION $VERSION2; then echo \"$VERSION is greater than $VERSION2\" fi if version_le $VERSION $VERSION2; then echo \"$VERSION is less than or equal to $VERSION2\" fi if version_lt $VERSION $VERSION2; then echo \"$VERSION is less than $VERSION2\" fi if version_ge $VERSION $VERSION2; then echo \"$VERSION is greater than or equal to $VERSION2\" fi"
        },
        {
            "filename": "file_703.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\file_703.sh",
            "content": "#!/bin/bash author=233boy # github=https://github.com/233boy/v2ray # bash fonts colors red='\\e[31m' yellow='\\e[33m' gray='\\e[90m' green='\\e[92m' blue='\\e[94m' magenta='\\e[95m' cyan='\\e[96m' none='\\e[0m' _red() { echo -e ${red}$@${none}; } _blue() { echo -e ${blue}$@${none}; } _cyan() { echo -e ${cyan}$@${none}; } _green() { echo -e ${green}$@${none}; } _yellow() { echo -e ${yellow}$@${none}; } _magenta() { echo -e ${magenta}$@${none}; } _red_bg() { echo -e \"\\e[41m$@${none}\"; } is_err=$(_red_bg \u9519\u8bef!) is_warn=$(_red_bg \u8b66\u544a!) err() { echo -e \"\\n$is_err $@\\n\" && exit 1 } warn() { echo -e \"\\n$is_warn $@\\n\" } # root [[ $EUID != 0 ]] && err \"\u5f53\u524d\u975e ${yellow}ROOT\u7528\u6237.${none}\" # yum or apt-get, ubuntu/debian/centos cmd=$(type -P apt-get || type -P yum) [[ ! $cmd ]] && err \"\u6b64\u811a\u672c\u4ec5\u652f\u6301 ${yellow}(Ubuntu or Debian or CentOS)${none}.\" # systemd [[ ! $(type -P systemctl) ]] && { err \"\u6b64\u7cfb\u7edf\u7f3a\u5c11 ${yellow}(systemctl)${none}, \u8bf7\u5c1d\u8bd5\u6267\u884c:${yellow} ${cmd} update -y;${cmd} install systemd -y ${none}\u6765\u4fee\u590d\u6b64\u9519\u8bef.\" } # wget installed or none is_wget=$(type -P wget) # x64 case $(uname -m) in amd64 | x86_64) is_jq_arch=amd64 is_core_arch=\"64\" ;; *aarch64* | *armv8*) is_jq_arch=arm64 is_core_arch=\"arm64-v8a\" ;; *) err \"\u6b64\u811a\u672c\u4ec5\u652f\u6301 64 \u4f4d\u7cfb\u7edf...\" ;; esac is_core=v2ray is_core_name=V2Ray is_core_dir=/etc/$is_core is_core_bin=$is_core_dir/bin/$is_core is_core_repo=v2fly/$is_core-core is_conf_dir=$is_core_dir/conf is_log_dir=/var/log/$is_core is_sh_bin=/usr/local/bin/$is_core is_sh_dir=$is_core_dir/sh is_sh_repo=$author/$is_core is_pkg=\"wget unzip\" is_config_json=$is_core_dir/config.json tmp_var_lists=( tmpcore tmpsh tmpjq is_core_ok is_sh_ok is_jq_ok is_pkg_ok ) # tmp dir tmpdir=$(mktemp -u) [[ ! $tmpdir ]] && { tmpdir=/tmp/tmp-$RANDOM } # set up var for i in ${tmp_var_lists[*]}; do export $i=$tmpdir/$i done # load bash script. load() { . $is_sh_dir/src/$1 } # wget add --no-check-certificate _wget() { [[ $proxy ]] && export https_proxy=$proxy wget --no-check-certificate $* } # print a mesage msg() { case $1 in warn) local color=$yellow ;; err) local color=$red ;; ok) local color=$green ;; esac echo -e \"${color}$(date +'%T')${none}) ${2}\" } # show help msg show_help() { echo -e \"Usage: $0 [-f xxx | -l | -p xxx | -v xxx | -h]\" echo -e \" -f, --core-file <path> \u81ea\u5b9a\u4e49 $is_core_name \u6587\u4ef6\u8def\u5f84, e.g., -f /root/${is_core}-linux-64.zip\" echo -e \" -l, --local-install \u672c\u5730\u83b7\u53d6\u5b89\u88c5\u811a\u672c, \u4f7f\u7528\u5f53\u524d\u76ee\u5f55\" echo -e \" -p, --proxy <addr> \u4f7f\u7528\u4ee3\u7406\u4e0b\u8f7d, e.g., -p http://127.0.0.1:2333 or -p socks5://127.0.0.1:2333\" echo -e \" -v, --core-version <ver> \u81ea\u5b9a\u4e49 $is_core_name \u7248\u672c, e.g., -v v5.4.1\" echo -e \" -h, --help \u663e\u793a\u6b64\u5e2e\u52a9\u754c\u9762\\n\" exit 0 } # install dependent pkg install_pkg() { cmd_not_found= for i in $*; do [[ ! $(type -P $i) ]] && cmd_not_found=\"$cmd_not_found,$i\" done if [[ $cmd_not_found ]]; then pkg=$(echo $cmd_not_found | sed 's/,/ /g') msg warn \"\u5b89\u88c5\u4f9d\u8d56\u5305 >${pkg}\" $cmd install -y $pkg &>/dev/null if [[ $? != 0 ]]; then [[ $cmd =~ yum ]] && yum install epel-release -y &>/dev/null $cmd update -y &>/dev/null $cmd install -y $pkg &>/dev/null [[ $? == 0 ]] && >$is_pkg_ok else >$is_pkg_ok fi else >$is_pkg_ok fi } # download file download() { case $1 in core) link=https://github.com/${is_core_repo}/releases/latest/download/${is_core}-linux-${is_core_arch}.zip [[ $is_core_ver ]] && link=\"https://github.com/${is_core_repo}/releases/download/${is_core_ver}/${is_core}-linux-${is_core_arch}.zip\" name=$is_core_name tmpfile=$tmpcore is_ok=$is_core_ok ;; sh) link=https://github.com/${is_sh_repo}/releases/latest/download/code.zip name=\"$is_core_name \u811a\u672c\" tmpfile=$tmpsh is_ok=$is_sh_ok ;; jq) link=https://github.com/jqlang/jq/releases/download/jq-1.7.1/jq-linux-$is_jq_arch name=\"jq\" tmpfile=$tmpjq is_ok=$is_jq_ok ;; esac msg warn \"\u4e0b\u8f7d ${name} > ${link}\" if _wget -t 3 -q -c $link -O $tmpfile; then mv -f $tmpfile $is_ok fi } # get server ip get_ip() { export \"$(_wget -4 -qO- https://one.one.one.one/cdn-cgi/trace | grep ip=)\" &>/dev/null [[ -z $ip ]] && export \"$(_wget -6 -qO- https://one.one.one.one/cdn-cgi/trace | grep ip=)\" &>/dev/null } # check background tasks status check_status() { # dependent pkg install fail [[ ! -f $is_pkg_ok ]] && { msg err \"\u5b89\u88c5\u4f9d\u8d56\u5305\u5931\u8d25\" is_fail=1 } # download file status if [[ $is_wget ]]; then [[ ! -f $is_core_ok ]] && { msg err \"\u4e0b\u8f7d ${is_core_name} \u5931\u8d25\" is_fail=1 } [[ ! -f $is_sh_ok ]] && { msg err \"\u4e0b\u8f7d ${is_core_name} \u811a\u672c\u5931\u8d25\" is_fail=1 } [[ ! -f $is_jq_ok ]] && { msg err \"\u4e0b\u8f7d jq \u5931\u8d25\" is_fail=1 } else [[ ! $is_fail ]] && { is_wget=1 [[ ! $is_core_file ]] && download core & [[ ! $local_install ]] && download sh & [[ $jq_not_found ]] && download jq & get_ip wait check_status } fi # found fail status, remove tmp dir and exit. [[ $is_fail ]] && { exit_and_del_tmpdir } } # parameters check pass_args() { while [[ $# -gt 0 ]]; do case $1 in online) err \"\u5982\u679c\u60f3\u8981\u5b89\u88c5\u65e7\u7248\u672c, \u8bf7\u8f6c\u5230: https://github.com/233boy/v2ray/tree/old\" ;; -f | --core-file) [[ -z $2 ]] && { err \"($1) \u7f3a\u5c11\u5fc5\u9700\u53c2\u6570, \u6b63\u786e\u4f7f\u7528\u793a\u4f8b: [$1 /root/$is_core-linux-64.zip]\" } || [[ ! -f $2 ]] && { err \"($2) \u4e0d\u662f\u4e00\u4e2a\u5e38\u89c4\u7684\u6587\u4ef6.\" } is_core_file=$2 shift 2 ;; -l | --local-install) [[ ! -f ${PWD}/src/core.sh || ! -f ${PWD}/$is_core.sh ]] && { err \"\u5f53\u524d\u76ee\u5f55 (${PWD}) \u975e\u5b8c\u6574\u7684\u811a\u672c\u76ee\u5f55.\" } local_install=1 shift 1 ;; -p | --proxy) [[ -z $2 ]] && { err \"($1) \u7f3a\u5c11\u5fc5\u9700\u53c2\u6570, \u6b63\u786e\u4f7f\u7528\u793a\u4f8b: [$1 http://127.0.0.1:2333 or -p socks5://127.0.0.1:2333]\" } proxy=$2 shift 2 ;; -v | --core-version) [[ -z $2 ]] && { err \"($1) \u7f3a\u5c11\u5fc5\u9700\u53c2\u6570, \u6b63\u786e\u4f7f\u7528\u793a\u4f8b: [$1 v1.8.1]\" } is_core_ver=v${2#v} shift 2 ;; -h | --help) show_help ;; *) echo -e \"\\n${is_err} ($@) \u4e3a\u672a\u77e5\u53c2\u6570...\\n\" show_help ;; esac done [[ $is_core_ver && $is_core_file ]] && { err \"\u65e0\u6cd5\u540c\u65f6\u81ea\u5b9a\u4e49 ${is_core_name} \u7248\u672c\u548c ${is_core_name} \u6587\u4ef6.\" } } # exit and remove tmpdir exit_and_del_tmpdir() { rm -rf $tmpdir [[ ! $1 ]] && { msg err \"\u54e6\u8c41..\" msg err \"\u5b89\u88c5\u8fc7\u7a0b\u51fa\u73b0\u9519\u8bef...\" echo -e \"\u53cd\u9988\u95ee\u9898) https://github.com/${is_sh_repo}/issues\" echo exit 1 } exit } # main main() { # check old version [[ -f $is_sh_bin && -d $is_core_dir/bin && -d $is_sh_dir && -d $is_conf_dir ]] && { err \"\u68c0\u6d4b\u5230\u811a\u672c\u5df2\u5b89\u88c5, \u5982\u9700\u91cd\u88c5\u8bf7\u4f7f\u7528${green} ${is_core} reinstall ${none}\u547d\u4ee4.\" } # check parameters [[ $# -gt 0 ]] && pass_args $@ # show welcome msg clear echo echo \"........... $is_core_name script by $author ..........\" echo # start installing... msg warn \"\u5f00\u59cb\u5b89\u88c5...\" [[ $is_core_ver ]] && msg warn \"${is_core_name} \u7248\u672c: ${yellow}$is_core_ver${none}\" [[ $proxy ]] && msg warn \"\u4f7f\u7528\u4ee3\u7406: ${yellow}$proxy${none}\" # create tmpdir mkdir -p $tmpdir # if is_core_file, copy file [[ $is_core_file ]] && { cp -f $is_core_file $is_core_ok msg warn \"${yellow}${is_core_name} \u6587\u4ef6\u4f7f\u7528 > $is_core_file${none}\" } # local dir install sh script [[ $local_install ]] && { >$is_sh_ok msg warn \"${yellow}\u672c\u5730\u83b7\u53d6\u5b89\u88c5\u811a\u672c > $PWD ${none}\" } timedatectl set-ntp true &>/dev/null [[ $? != 0 ]] && { msg warn \"${yellow}\\e[4m\u63d0\u9192!!! \u65e0\u6cd5\u8bbe\u7f6e\u81ea\u52a8\u540c\u6b65\u65f6\u95f4, \u53ef\u80fd\u4f1a\u5f71\u54cd\u4f7f\u7528 VMess \u534f\u8bae.${none}\" } # install dependent pkg install_pkg $is_pkg & # jq if [[ $(type -P jq) ]]; then >$is_jq_ok else jq_not_found=1 fi # if wget installed. download core, sh, jq, get ip [[ $is_wget ]] && { [[ ! $is_core_file ]] && download core & [[ ! $local_install ]] && download sh & [[ $jq_not_found ]] && download jq & get_ip } # waiting for background tasks is done wait # check background tasks status check_status # test $is_core_file if [[ $is_core_file ]]; then unzip -qo $is_core_ok -d $tmpdir/testzip &>/dev/null [[ $? != 0 ]] && { msg err \"${is_core_name} \u6587\u4ef6\u65e0\u6cd5\u901a\u8fc7\u6d4b\u8bd5.\" exit_and_del_tmpdir } for i in ${is_core} geoip.dat geosite.dat; do [[ ! -f $tmpdir/testzip/$i ]] && is_file_err=1 && break done [[ $is_file_err ]] && { msg err \"${is_core_name} \u6587\u4ef6\u65e0\u6cd5\u901a\u8fc7\u6d4b\u8bd5.\" exit_and_del_tmpdir } fi # get server ip. [[ ! $ip ]] && { msg err \"\u83b7\u53d6\u670d\u52a1\u5668 IP \u5931\u8d25.\" exit_and_del_tmpdir } # create sh dir... mkdir -p $is_sh_dir # copy sh file or unzip sh zip file. if [[ $local_install ]]; then cp -rf $PWD/* $is_sh_dir else unzip -qo $is_sh_ok -d $is_sh_dir fi # create core bin dir mkdir -p $is_core_dir/bin # copy core file or unzip core zip file if [[ $is_core_file ]]; then cp -rf $tmpdir/testzip/* $is_core_dir/bin else unzip -qo $is_core_ok -d $is_core_dir/bin fi # add alias echo \"alias $is_core=$is_sh_bin\" >>/root/.bashrc # core command ln -sf $is_sh_dir/$is_core.sh $is_sh_bin # jq [[ $jq_not_found ]] && mv -f $is_jq_ok /usr/bin/jq # chmod chmod +x $is_core_bin $is_sh_bin /usr/bin/jq # create log dir mkdir -p $is_log_dir # show a tips msg msg ok \"\u751f\u6210\u914d\u7f6e\u6587\u4ef6...\" # create systemd service load systemd.sh is_new_install=1 install_service $is_core &>/dev/null # create condf dir mkdir -p $is_conf_dir load core.sh # create a tcp config add tcp # remove tmp dir and exit. exit_and_del_tmpdir ok } # start. main $@"
        },
        {
            "filename": "file_704.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\file_704.sh",
            "content": "#!/bin/bash args=$@ is_sh_ver=v4.22 . /etc/v2ray/sh/src/init.sh"
        },
        {
            "filename": "file_705.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\src\\file_705.sh",
            "content": "_open_bbr() { sed -i '/net.ipv4.tcp_congestion_control/d' /etc/sysctl.conf sed -i '/net.core.default_qdisc/d' /etc/sysctl.conf echo \"net.ipv4.tcp_congestion_control = bbr\" >>/etc/sysctl.conf echo \"net.core.default_qdisc = fq\" >>/etc/sysctl.conf sysctl -p &>/dev/null echo _green \"..\u5df2\u7ecf\u542f\u7528 BBR \u4f18\u5316....\" echo } _try_enable_bbr() { local _test1=$(uname -r | cut -d\\. -f1) local _test2=$(uname -r | cut -d\\. -f2) if [[ $_test1 -eq 4 && $_test2 -ge 9 ]] || [[ $_test1 -ge 5 ]]; then _open_bbr else err \"\u4e0d\u652f\u6301\u542f\u7528 BBR \u4f18\u5316.\" fi }"
        },
        {
            "filename": "file_706.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\src\\file_706.sh",
            "content": "caddy_config() { is_caddy_site_file=$is_caddy_conf/${host}.conf case $1 in new) mkdir -p $is_caddy_dir $is_caddy_dir/sites $is_caddy_conf cat >$is_caddyfile <<-EOF # don't edit this file # # for more info, see https://233boy.com/$is_core/caddy-auto-tls/ # \u4e0d\u8981\u7f16\u8f91\u8fd9\u4e2a\u6587\u4ef6 # # \u66f4\u591a\u76f8\u5173\u8bf7\u9605\u8bfb\u6b64\u6587\u7ae0: https://233boy.com/$is_core/caddy-auto-tls/ # https://caddyserver.com/docs/caddyfile/options { admin off http_port $is_http_port https_port $is_https_port } import $is_caddy_conf/*.conf import $is_caddy_dir/sites/*.conf EOF ;; *ws*) cat >${is_caddy_site_file} <<<\" ${host}:${is_https_port} { reverse_proxy ${path} 127.0.0.1:${port} import ${is_caddy_site_file}.add }\" ;; *h2*) cat >${is_caddy_site_file} <<<\" ${host}:${is_https_port} { reverse_proxy ${path} h2c://127.0.0.1:${port} import ${is_caddy_site_file}.add }\" ;; *grpc*) cat >${is_caddy_site_file} <<<\" ${host}:${is_https_port} { reverse_proxy /${path}/* h2c://127.0.0.1:${port} import ${is_caddy_site_file}.add }\" ;; proxy) cat >${is_caddy_site_file}.add <<<\" reverse_proxy https://$proxy_site { header_up Host {upstream_hostport} }\" ;; esac [[ $1 != \"new\" && $1 != 'proxy' ]] && { [[ ! -f ${is_caddy_site_file}.add ]] && echo \"# see https://233boy.com/$is_core/caddy-auto-tls/\" >${is_caddy_site_file}.add } }"
        },
        {
            "filename": "file_707.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\src\\file_707.sh",
            "content": "#!/bin/bash protocol_list=( VMess-TCP VMess-mKCP VMess-QUIC VMess-H2-TLS VMess-WS-TLS VMess-gRPC-TLS VLESS-H2-TLS VLESS-WS-TLS VLESS-gRPC-TLS # VLESS-XTLS-uTLS-REALITY Trojan-H2-TLS Trojan-WS-TLS Trojan-gRPC-TLS Shadowsocks # Dokodemo-Door VMess-TCP-dynamic-port VMess-mKCP-dynamic-port VMess-QUIC-dynamic-port Socks ) ss_method_list=( aes-128-gcm aes-256-gcm chacha20-ietf-poly1305 # xchacha20-ietf-poly1305 # 2022-blake3-aes-128-gcm # 2022-blake3-aes-256-gcm # 2022-blake3-chacha20-poly1305 ) header_type_list=( none srtp utp wechat-video dtls wireguard ) mainmenu=( \"\u6dfb\u52a0\u914d\u7f6e\" \"\u66f4\u6539\u914d\u7f6e\" \"\u67e5\u770b\u914d\u7f6e\" \"\u5220\u9664\u914d\u7f6e\" \"\u8fd0\u884c\u7ba1\u7406\" \"\u66f4\u65b0\" \"\u5378\u8f7d\" \"\u5e2e\u52a9\" \"\u5176\u4ed6\" \"\u5173\u4e8e\" ) info_list=( \"\u534f\u8bae (protocol)\" \"\u5730\u5740 (address)\" \"\u7aef\u53e3 (port)\" \"\u7528\u6237ID (id)\" \"\u4f20\u8f93\u534f\u8bae (network)\" \"\u4f2a\u88c5\u7c7b\u578b (type)\" \"\u4f2a\u88c5\u57df\u540d (host)\" \"\u8def\u5f84 (path)\" \"\u4f20\u8f93\u5c42\u5b89\u5168 (TLS)\" \"mKCP seed\" \"\u5bc6\u7801 (password)\" \"\u52a0\u5bc6\u65b9\u5f0f (encryption)\" \"\u94fe\u63a5 (URL)\" \"\u76ee\u6807\u5730\u5740 (remote addr)\" \"\u76ee\u6807\u7aef\u53e3 (remote port)\" \"\u6d41\u63a7 (flow)\" \"SNI (serverName)\" \"\u6307\u7eb9 (Fingerprint)\" \"\u516c\u94a5 (Public key)\" \"\u7528\u6237\u540d (Username)\" ) change_list=( \"\u66f4\u6539\u534f\u8bae\" \"\u66f4\u6539\u7aef\u53e3\" \"\u66f4\u6539\u57df\u540d\" \"\u66f4\u6539\u8def\u5f84\" \"\u66f4\u6539\u5bc6\u7801\" \"\u66f4\u6539 UUID\" \"\u66f4\u6539\u52a0\u5bc6\u65b9\u5f0f\" \"\u66f4\u6539\u4f2a\u88c5\u7c7b\u578b\" \"\u66f4\u6539\u76ee\u6807\u5730\u5740\" \"\u66f4\u6539\u76ee\u6807\u7aef\u53e3\" \"\u66f4\u6539\u5bc6\u94a5\" \"\u66f4\u6539 SNI (serverName)\" \"\u66f4\u6539\u52a8\u6001\u7aef\u53e3\" \"\u66f4\u6539\u4f2a\u88c5\u7f51\u7ad9\" \"\u66f4\u6539 mKCP seed\" \"\u66f4\u6539\u7528\u6237\u540d (Username)\" ) servername_list=( www.amazon.com www.microsoft.com www.apple.com dash.cloudflare.com dl.google.com aws.amazon.com ) is_random_ss_method=${ss_method_list[$(shuf -i 0-${#ss_method_list[@]} -n1) - 1]} is_random_header_type=${header_type_list[$(shuf -i 1-5 -n1)]} # random dont use none is_random_servername=${servername_list[$(shuf -i 0-${#servername_list[@]} -n1) - 1]} msg() { echo -e \"$@\" } msg_ul() { echo -e \"\\e[4m$@\\e[0m\" } # pause pause() { echo echo -ne \"\u6309 $(_green Enter \u56de\u8f66\u952e) \u7ee7\u7eed, \u6216\u6309 $(_red Ctrl + C) \u53d6\u6d88.\" read -rs -d $'\\n' echo } get_uuid() { tmp_uuid=$(cat /proc/sys/kernel/random/uuid) } get_ip() { [[ $ip || $is_no_auto_tls || $is_gen ]] && return export \"$(_wget -4 -qO- https://one.one.one.one/cdn-cgi/trace | grep ip=)\" &>/dev/null [[ ! $ip ]] && export \"$(_wget -6 -qO- https://one.one.one.one/cdn-cgi/trace | grep ip=)\" &>/dev/null [[ ! $ip ]] && { err \"\u83b7\u53d6\u670d\u52a1\u5668 IP \u5931\u8d25..\" } } get_port() { is_count=0 while :; do ((is_count++)) if [[ $is_count -ge 233 ]]; then err \"\u81ea\u52a8\u83b7\u53d6\u53ef\u7528\u7aef\u53e3\u5931\u8d25\u6b21\u6570\u8fbe\u5230 233 \u6b21, \u8bf7\u68c0\u67e5\u7aef\u53e3\u5360\u7528\u60c5\u51b5.\" fi tmp_port=$(shuf -i 445-65535 -n 1) [[ ! $(is_test port_used $tmp_port) && $tmp_port != $port ]] && break done } get_pbk() { is_tmp_pbk=($($is_core_bin x25519 | sed 's/.*://')) is_private_key=${is_tmp_pbk[0]} is_public_key=${is_tmp_pbk[1]} } show_list() { PS3='' COLUMNS=1 select i in \"$@\"; do echo; done & wait # i=0 # for v in \"$@\"; do # ((i++)) # echo \"$i) $v\" # done # echo } is_test() { case $1 in number) echo $2 | egrep '^[1-9][0-9]?+$' ;; port) if [[ $(is_test number $2) ]]; then [[ $2 -le 65535 ]] && echo ok fi ;; port_used) [[ $(is_port_used $2) && ! $is_cant_test_port ]] && echo ok ;; domain) echo $2 | egrep -i '^\\w(\\w|\\-|\\.)?+\\.\\w+$' ;; path) echo $2 | egrep -i '^\\/\\w(\\w|\\-|\\/)?+\\w$' ;; uuid) echo $2 | egrep -i '[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}' ;; esac } is_port_used() { if [[ $(type -P netstat) ]]; then [[ ! $is_used_port ]] && is_used_port=\"$(netstat -tunlp | sed -n 's/.*:\\([0-9]\\+\\).*/\\1/p' | sort -nu)\" echo $is_used_port | sed 's/ /\\n/g' | grep ^${1}$ return fi if [[ $(type -P ss) ]]; then [[ ! $is_used_port ]] && is_used_port=\"$(ss -tunlp | sed -n 's/.*:\\([0-9]\\+\\).*/\\1/p' | sort -nu)\" echo $is_used_port | sed 's/ /\\n/g' | grep ^${1}$ return fi is_cant_test_port=1 msg \"$is_warn \u65e0\u6cd5\u68c0\u6d4b\u7aef\u53e3\u662f\u5426\u53ef\u7528.\" msg \"\u8bf7\u6267\u884c: $(_yellow \"${cmd} update -y; ${cmd} install net-tools -y\") \u6765\u4fee\u590d\u6b64\u95ee\u9898.\" } # ask input a string or pick a option for list. ask() { case $1 in set_ss_method) is_tmp_list=(${ss_method_list[@]}) is_default_arg=$is_random_ss_method is_opt_msg=\"\\n\u8bf7\u9009\u62e9\u52a0\u5bc6\u65b9\u5f0f:\\n\" is_opt_input_msg=\"(\u9ed8\u8ba4\\e[92m $is_default_arg\\e[0m):\" is_ask_set=ss_method ;; set_header_type) is_tmp_list=(${header_type_list[@]}) is_default_arg=$is_random_header_type [[ $(grep -i tcp <<<\"$is_new_protocol-$net\") ]] && { is_tmp_list=(none http) is_default_arg=none } is_opt_msg=\"\\n\u8bf7\u9009\u62e9\u4f2a\u88c5\u7c7b\u578b:\\n\" is_opt_input_msg=\"(\u9ed8\u8ba4\\e[92m $is_default_arg\\e[0m):\" is_ask_set=header_type [[ $is_use_header_type ]] && return ;; set_protocol) is_tmp_list=(${protocol_list[@]}) [[ $is_no_auto_tls ]] && { unset is_tmp_list for v in ${protocol_list[@]}; do [[ $(grep -i tls$ <<<$v) ]] && is_tmp_list=(${is_tmp_list[@]} $v) done } is_opt_msg=\"\\n\u8bf7\u9009\u62e9\u534f\u8bae:\\n\" is_ask_set=is_new_protocol ;; set_change_list) is_tmp_list=() for v in ${is_can_change[@]}; do is_tmp_list+=(\"${change_list[$v]}\") done is_opt_msg=\"\\n\u8bf7\u9009\u62e9\u66f4\u6539:\\n\" is_ask_set=is_change_str is_opt_input_msg=$3 ;; string) is_ask_set=$2 is_opt_input_msg=$3 ;; list) is_ask_set=$2 [[ ! $is_tmp_list ]] && is_tmp_list=($3) is_opt_msg=$4 is_opt_input_msg=$5 ;; get_config_file) is_tmp_list=(\"${is_all_json[@]}\") is_opt_msg=\"\\n\u8bf7\u9009\u62e9\u914d\u7f6e:\\n\" is_ask_set=is_config_file ;; mainmenu) is_tmp_list=(\"${mainmenu[@]}\") is_ask_set=is_main_pick is_emtpy_exit=1 ;; esac msg $is_opt_msg [[ ! $is_opt_input_msg ]] && is_opt_input_msg=\"\u8bf7\u9009\u62e9 [\\e[91m1-${#is_tmp_list[@]}\\e[0m]:\" [[ $is_tmp_list ]] && show_list \"${is_tmp_list[@]}\" while :; do echo -ne $is_opt_input_msg read REPLY [[ ! $REPLY && $is_emtpy_exit ]] && exit [[ ! $REPLY && $is_default_arg ]] && export $is_ask_set=$is_default_arg && break [[ \"$REPLY\" == \"${is_str}2${is_get}3${is_opt}3\" && $is_ask_set == 'is_main_pick' ]] && { msg \"\\n${is_get}2${is_str}3${is_msg}3b${is_tmp}o${is_opt}y\\n\" && exit } if [[ ! $is_tmp_list ]]; then [[ $(grep port <<<$is_ask_set) ]] && { [[ ! $(is_test port \"$REPLY\") ]] && { msg \"$is_err \u8bf7\u8f93\u5165\u6b63\u786e\u7684\u7aef\u53e3, \u53ef\u9009(1-65535)\" continue } if [[ $(is_test port_used $REPLY) && $is_ask_set != 'door_port' ]]; then msg \"$is_err \u65e0\u6cd5\u4f7f\u7528 ($REPLY) \u7aef\u53e3.\" continue fi } [[ $(grep path <<<$is_ask_set) && ! $(is_test path \"$REPLY\") ]] && { [[ ! $tmp_uuid ]] && get_uuid msg \"$is_err \u8bf7\u8f93\u5165\u6b63\u786e\u7684\u8def\u5f84, \u4f8b\u5982: /$tmp_uuid\" continue } [[ $(grep uuid <<<$is_ask_set) && ! $(is_test uuid \"$REPLY\") ]] && { [[ ! $tmp_uuid ]] && get_uuid msg \"$is_err \u8bf7\u8f93\u5165\u6b63\u786e\u7684 UUID, \u4f8b\u5982: $tmp_uuid\" continue } [[ $(grep ^y$ <<<$is_ask_set) ]] && { [[ $(grep -i ^y$ <<<\"$REPLY\") ]] && break msg \"\u8bf7\u8f93\u5165 (y)\" continue } [[ $REPLY ]] && export $is_ask_set=$REPLY && msg \"\u4f7f\u7528: ${!is_ask_set}\" && break else [[ $(is_test number \"$REPLY\") ]] && is_ask_result=${is_tmp_list[$REPLY - 1]} [[ $is_ask_result ]] && export $is_ask_set=\"$is_ask_result\" && msg \"\u9009\u62e9: ${!is_ask_set}\" && break fi msg \"\u8f93\u5165${is_err}\" done unset is_opt_msg is_opt_input_msg is_tmp_list is_ask_result is_default_arg is_emtpy_exit } # create file create() { case $1 in server) is_tls=none get new # file name if [[ $host ]]; then is_config_name=$2-${host}.json else is_config_name=$2-${port}.json fi is_json_file=$is_conf_dir/$is_config_name # get json [[ $is_change || ! $json_str ]] && get protocol $2 case $net in ws | h2 | grpc | http) is_listen='\"listen\": \"127.0.0.1\"' ;; *) is_listen='\"listen\": \"0.0.0.0\"' ;; esac is_sniffing='sniffing:{enabled:true,destOverride:[\"http\",\"tls\"]}' is_new_json=$(jq '{inbounds:[{tag:'\\\"$is_config_name\\\"',port:'\"$port\"','\"$is_listen\"',protocol:'\\\"$is_protocol\\\"','\"$json_str\"','\"$is_sniffing\"'}]}' <<<{}) if [[ $is_dynamic_port ]]; then [[ ! $is_dynamic_port_range ]] && get dynamic-port is_new_dynamic_port_json=$(jq '{inbounds:[{tag:'\\\"$is_config_name-link.json\\\"',port:'\\\"$is_dynamic_port_range\\\"','\"$is_listen\"',protocol:\"vmess\",'\"$is_stream\"','\"$is_sniffing\"',allocate:{strategy:\"random\"}}]}' <<<{}) fi [[ $is_test_json ]] && return # tmp test # only show json, dont save to file. [[ $is_gen ]] && { msg jq <<<$is_new_json msg [[ $is_new_dynamic_port_json ]] && jq <<<$is_new_dynamic_port_json && msg return } # del old file [[ $is_config_file ]] && is_no_del_msg=1 && del $is_config_file # save json to file cat <<<$is_new_json >$is_json_file [[ $is_new_dynamic_port_json ]] && { is_dynamic_port_link_file=$is_json_file-link.json cat <<<$is_new_dynamic_port_json >$is_dynamic_port_link_file } if [[ $is_new_install ]]; then # config.json create config.json else # use api add config api add $is_json_file $is_dynamic_port_link_file &>/dev/null fi # caddy auto tls [[ $is_caddy && $host && ! $is_no_auto_tls ]] && { create caddy $net } # restart core [[ $is_api_fail ]] && manage restart & ;; client) is_tls=tls is_client=1 get info $2 [[ ! $is_client_id_json ]] && err \"($is_config_name) \u4e0d\u652f\u6301\u751f\u6210\u5ba2\u6237\u7aef\u914d\u7f6e.\" is_new_json=$(jq '{outbounds:[{tag:'\\\"$is_config_name\\\"',protocol:'\\\"$is_protocol\\\"','\"$is_client_id_json\"','\"$is_stream\"'}]}' <<<{}) if [[ $is_full_client ]]; then is_dns='dns:{servers:[{address:\"223.5.5.5\",domain:[\"geosite:cn\",\"geosite:geolocation-cn\"],expectIPs:[\"geoip:cn\"]},\"1.1.1.1\",\"8.8.8.8\"]}' is_route='routing:{rules:[{type:\"field\",outboundTag:\"direct\",ip:[\"geoip:cn\",\"geoip:private\"]},{type:\"field\",outboundTag:\"direct\",domain:[\"geosite:cn\",\"geosite:geolocation-cn\"]}]}' is_inbounds='inbounds:[{port:2333,listen:\"127.0.0.1\",protocol:\"socks\",settings:{udp:true},sniffing:{enabled:true,destOverride:[\"http\",\"tls\"]}}]' is_outbounds='outbounds:[{tag:'\\\"$is_config_name\\\"',protocol:'\\\"$is_protocol\\\"','\"$is_client_id_json\"','\"$is_stream\"'},{tag:\"direct\",protocol:\"freedom\"}]' is_new_json=$(jq '{'$is_dns,$is_route,$is_inbounds,$is_outbounds'}' <<<{}) fi msg jq <<<$is_new_json msg ;; caddy) load caddy.sh [[ $is_install_caddy ]] && caddy_config new [[ ! $(grep \"$is_caddy_conf\" $is_caddyfile) ]] && { msg \"import $is_caddy_conf/*.conf\" >>$is_caddyfile } [[ ! -d $is_caddy_conf ]] && mkdir -p $is_caddy_conf caddy_config $2 manage restart caddy & ;; config.json) get_port is_log='log:{access:\"/var/log/'\"$is_core\"'/access.log\",error:\"/var/log/'\"$is_core\"'/error.log\",loglevel:\"warning\"}' is_dns='dns:{}' is_api='api:{tag:\"api\",services:[\"HandlerService\",\"LoggerService\",\"StatsService\"]}' is_stats='stats:{}' is_policy_system='system:{statsInboundUplink:true,statsInboundDownlink:true,statsOutboundUplink:true,statsOutboundDownlink:true}' is_policy='policy:{levels:{\"0\":{handshake:'\"$((${tmp_port:0:1} + 1))\"',connIdle:'\"${tmp_port:0:3}\"',uplinkOnly:'\"$((${tmp_port:2:1} + 1))\"',downlinkOnly:'\"$((${tmp_port:3:1} + 3))\"',statsUserUplink:true,statsUserDownlink:true}},'\"$is_policy_system\"'}' is_ban_ad='{type:\"field\",domain:[\"geosite:category-ads-all\"],marktag:\"ban_ad\",outboundTag:\"block\"}' is_ban_bt='{type:\"field\",protocol:[\"bittorrent\"],marktag:\"ban_bt\",outboundTag:\"block\"}' is_ban_cn='{type:\"field\",ip:[\"geoip:cn\"],marktag:\"ban_geoip_cn\",outboundTag:\"block\"}' is_openai='{type:\"field\",domain:[\"domain:openai.com\"],marktag:\"fix_openai\",outboundTag:\"direct\"}' is_routing='routing:{domainStrategy:\"IPIfNonMatch\",rules:[{type:\"field\",inboundTag:[\"api\"],outboundTag:\"api\"},'\"$is_ban_bt\"','\"$is_ban_cn\"','\"$is_openai\"',{type:\"field\",ip:[\"geoip:private\"],outboundTag:\"block\"}]}' is_inbounds='inbounds:[{tag:\"api\",port:'\"$tmp_port\"',listen:\"127.0.0.1\",protocol:\"dokodemo-door\",settings:{address:\"127.0.0.1\"}}]' is_outbounds='outbounds:[{tag:\"direct\",protocol:\"freedom\"},{tag:\"block\",protocol:\"blackhole\"}]' is_server_config_json=$(jq '{'\"$is_log\"','\"$is_dns\"','\"$is_api\"','\"$is_stats\"','\"$is_policy\"','\"$is_routing\"','\"$is_inbounds\"','\"$is_outbounds\"'}' <<<{}) cat <<<$is_server_config_json >$is_config_json manage restart & ;; esac } # change config file change() { is_change=1 is_dont_show_info=1 if [[ $2 ]]; then case ${2,,} in full) is_change_id=full ;; new) is_change_id=0 ;; port) is_change_id=1 ;; host) is_change_id=2 ;; path) is_change_id=3 ;; pass | passwd | password) is_change_id=4 ;; id | uuid) is_change_id=5 ;; ssm | method | ss-method | ss_method) is_change_id=6 ;; type | header | header-type | header_type) is_change_id=7 ;; dda | door-addr | door_addr) is_change_id=8 ;; ddp | door-port | door_port) is_change_id=9 ;; key | publickey | privatekey) is_change_id=10 ;; sni | servername | servernames) is_change_id=11 ;; dp | dyp | dynamic | dynamicport | dynamic-port) is_change_id=12 ;; web | proxy-site) is_change_id=13 ;; seed | kcpseed | kcp-seed | kcp_seed) is_change_id=14 ;; *) [[ $is_try_change ]] && return err \"\u65e0\u6cd5\u8bc6\u522b ($2) \u66f4\u6539\u7c7b\u578b.\" ;; esac fi [[ $is_try_change ]] && return [[ $is_dont_auto_exit ]] && { get info $1 } || { [[ $is_change_id ]] && { is_change_msg=${change_list[$is_change_id]} [[ $is_change_id == 'full' ]] && { [[ $3 ]] && is_change_msg=\"\u66f4\u6539\u591a\u4e2a\u53c2\u6570\" || is_change_msg= } [[ $is_change_msg ]] && _green \"\\n\u5feb\u901f\u6267\u884c: $is_change_msg\" } info $1 [[ $is_auto_get_config ]] && msg \"\\n\u81ea\u52a8\u9009\u62e9: $is_config_file\" } is_old_net=$net [[ $is_protocol == 'vless' && ! $is_reality ]] && net=v$net [[ $is_protocol == 'trojan' ]] && net=t$net [[ $is_dynamic_port ]] && net=${net}d [[ $3 == 'auto' ]] && is_auto=1 # if is_dont_show_info exist, cant show info. is_dont_show_info= # if not prefer args, show change list and then get change id. [[ ! $is_change_id ]] && { ask set_change_list is_change_id=${is_can_change[$REPLY - 1]} } case $is_change_id in full) add $net ${@:3} ;; 0) # new protocol is_set_new_protocol=1 add ${@:3} ;; 1) # new port is_new_port=$3 [[ $host && ! $is_caddy ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u7aef\u53e3, \u56e0\u4e3a\u6ca1\u5565\u610f\u4e49.\" if [[ $is_new_port && ! $is_auto ]]; then [[ ! $(is_test port $is_new_port) ]] && err \"\u8bf7\u8f93\u5165\u6b63\u786e\u7684\u7aef\u53e3, \u53ef\u9009(1-65535)\" [[ $is_new_port != 443 && $(is_test port_used $is_new_port) ]] && err \"\u65e0\u6cd5\u4f7f\u7528 ($is_new_port) \u7aef\u53e3\" fi [[ $is_auto ]] && get_port && is_new_port=$tmp_port [[ ! $is_new_port ]] && ask string is_new_port \"\u8bf7\u8f93\u5165\u65b0\u7aef\u53e3:\" if [[ $is_caddy && $host ]]; then net=$is_old_net is_https_port=$is_new_port load caddy.sh caddy_config $net manage restart caddy & info else add $net $is_new_port fi ;; 2) # new host is_new_host=$3 [[ ! $host ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u57df\u540d.\" [[ ! $is_new_host ]] && ask string is_new_host \"\u8bf7\u8f93\u5165\u65b0\u57df\u540d:\" old_host=$host # del old host add $net $is_new_host ;; 3) # new path is_new_path=$3 [[ ! $path ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u8def\u5f84.\" [[ $is_auto ]] && get_uuid && is_new_path=/$tmp_uuid [[ ! $is_new_path ]] && ask string is_new_path \"\u8bf7\u8f93\u5165\u65b0\u8def\u5f84:\" add $net auto auto $is_new_path ;; 4) # new password is_new_pass=$3 if [[ $net == 'ss' || $is_trojan || $is_socks_pass ]]; then [[ $is_auto ]] && get_uuid && is_new_pass=$tmp_uuid else err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u5bc6\u7801.\" fi [[ ! $is_new_pass ]] && ask string is_new_pass \"\u8bf7\u8f93\u5165\u65b0\u5bc6\u7801:\" trojan_password=$is_new_pass ss_password=$is_new_pass is_socks_pass=$is_new_pass add $net ;; 5) # new uuid is_new_uuid=$3 [[ ! $uuid ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539 UUID.\" [[ $is_auto ]] && get_uuid && is_new_uuid=$tmp_uuid [[ ! $is_new_uuid ]] && ask string is_new_uuid \"\u8bf7\u8f93\u5165\u65b0 UUID:\" add $net auto $is_new_uuid ;; 6) # new method is_new_method=$3 [[ $net != 'ss' ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u52a0\u5bc6\u65b9\u5f0f.\" [[ $is_auto ]] && is_new_method=$is_random_ss_method [[ ! $is_new_method ]] && { ask set_ss_method is_new_method=$ss_method } add $net auto auto $is_new_method ;; 7) # new header type is_new_header_type=$3 [[ ! $header_type ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u4f2a\u88c5\u7c7b\u578b.\" [[ $is_auto ]] && { is_new_header_type=$is_random_header_type if [[ $net == 'tcp' ]]; then is_tmp_header_type=(none http) is_new_header_type=${is_tmp_header_type[$(shuf -i 0-1 -n1)]} fi } [[ ! $is_new_header_type ]] && { ask set_header_type is_new_header_type=$header_type } add $net auto auto $is_new_header_type ;; 8) # new remote addr is_new_door_addr=$3 [[ $net != 'door' ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u76ee\u6807\u5730\u5740.\" [[ ! $is_new_door_addr ]] && ask string is_new_door_addr \"\u8bf7\u8f93\u5165\u65b0\u7684\u76ee\u6807\u5730\u5740:\" door_addr=$is_new_door_addr add $net ;; 9) # new remote port is_new_door_port=$3 [[ $net != 'door' ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u76ee\u6807\u7aef\u53e3.\" [[ ! $is_new_door_port ]] && { ask string door_port \"\u8bf7\u8f93\u5165\u65b0\u7684\u76ee\u6807\u7aef\u53e3:\" is_new_door_port=$door_port } add $net auto auto $is_new_door_port ;; 10) # new is_private_key is_public_key is_new_private_key=$3 is_new_public_key=$4 [[ ! $is_reality ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u5bc6\u94a5.\" if [[ $is_auto ]]; then get_pbk add $net else [[ $is_new_private_key && ! $is_new_public_key ]] && { err \"\u65e0\u6cd5\u627e\u5230 Public key.\" } [[ ! $is_new_private_key ]] && ask string is_new_private_key \"\u8bf7\u8f93\u5165\u65b0 Private key:\" [[ ! $is_new_public_key ]] && ask string is_new_public_key \"\u8bf7\u8f93\u5165\u65b0 Public key:\" if [[ $is_new_private_key == $is_new_public_key ]]; then err \"Private key \u548c Public key \u4e0d\u80fd\u4e00\u6837.\" fi is_private_key=$is_new_private_key is_test_json=1 # create server $is_protocol-$net | $is_core_bin -test &>/dev/null create server $is_protocol-$net $is_core_bin -test <<<\"$is_new_json\" &>/dev/null if [[ $? != 0 ]]; then err \"Private key \u65e0\u6cd5\u901a\u8fc7\u6d4b\u8bd5.\" fi is_private_key=$is_new_public_key # create server $is_protocol-$net | $is_core_bin -test &>/dev/null create server $is_protocol-$net $is_core_bin -test <<<\"$is_new_json\" &>/dev/null if [[ $? != 0 ]]; then err \"Public key \u65e0\u6cd5\u901a\u8fc7\u6d4b\u8bd5.\" fi is_private_key=$is_new_private_key is_public_key=$is_new_public_key is_test_json= add $net fi ;; 11) # new serverName is_new_servername=$3 [[ ! $is_reality ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539 serverName.\" [[ $is_auto ]] && is_new_servername=$is_random_servername [[ ! $is_new_servername ]] && ask string is_new_servername \"\u8bf7\u8f93\u5165\u65b0\u7684 serverName:\" is_servername=$is_new_servername [[ $(grep -i \"^233boy.com$\" <<<$is_servername) ]] && { err \"\u4f60\u5e72\u561b\uff5e\u54ce\u5466\uff5e\" } add $net ;; 12) # new dynamic-port is_new_dynamic_port_start=$3 is_new_dynamic_port_end=$4 [[ ! $is_dynamic_port ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u52a8\u6001\u7aef\u53e3.\" if [[ $is_auto ]]; then get dynamic-port add $net else [[ $is_new_dynamic_port_start && ! $is_new_dynamic_port_end ]] && { err \"\u65e0\u6cd5\u627e\u5230\u52a8\u6001\u7ed3\u675f\u7aef\u53e3.\" } [[ ! $is_new_dynamic_port_start ]] && ask string is_new_dynamic_port_start \"\u8bf7\u8f93\u5165\u65b0\u7684\u52a8\u6001\u5f00\u59cb\u7aef\u53e3:\" [[ ! $is_new_dynamic_port_end ]] && ask string is_new_dynamic_port_end \"\u8bf7\u8f93\u5165\u65b0\u7684\u52a8\u6001\u7ed3\u675f\u7aef\u53e3:\" add $net auto auto auto $is_new_dynamic_port_start $is_new_dynamic_port_end fi ;; 13) # new proxy site is_new_proxy_site=$3 [[ ! $is_caddy && ! $host ]] && { err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u4f2a\u88c5\u7f51\u7ad9.\" } [[ ! -f $is_caddy_conf/${host}.conf.add ]] && err \"\u65e0\u6cd5\u914d\u7f6e\u4f2a\u88c5\u7f51\u7ad9.\" [[ ! $is_new_proxy_site ]] && ask string is_new_proxy_site \"\u8bf7\u8f93\u5165\u65b0\u7684\u4f2a\u88c5\u7f51\u7ad9 (\u4f8b\u5982 example.com):\" proxy_site=$(sed 's#^.*//##;s#/$##' <<<$is_new_proxy_site) [[ $(grep -i \"^233boy.com$\" <<<$proxy_site) ]] && { err \"\u4f60\u5e72\u561b\uff5e\u54ce\u5466\uff5e\" } || { load caddy.sh caddy_config proxy manage restart caddy & } msg \"\\n\u5df2\u66f4\u65b0\u4f2a\u88c5\u7f51\u7ad9\u4e3a: $(_green $proxy_site) \\n\" ;; 14) # new kcp seed is_new_kcp_seed=$3 [[ ! $kcp_seed ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539 mKCP seed.\" [[ $is_auto ]] && get_uuid && is_new_kcp_seed=$tmp_uuid [[ ! $is_new_kcp_seed ]] && ask string is_new_kcp_seed \"\u8bf7\u8f93\u5165\u65b0 mKCP seed:\" kcp_seed=$is_new_kcp_seed add $net ;; 15) # new socks user [[ ! $is_socks_user ]] && err \"($is_config_file) \u4e0d\u652f\u6301\u66f4\u6539\u7528\u6237\u540d (Username).\" ask string is_socks_user \"\u8bf7\u8f93\u5165\u65b0\u7528\u6237\u540d (Username):\" add $net ;; esac } # delete config. del() { [[ $is_conf_dir_empty ]] && return # not found any json file. # get a config file [[ ! $is_config_file ]] && get info $1 if [[ $is_config_file ]]; then if [[ $is_main_start && ! $is_no_del_msg ]]; then msg \"\\n\u662f\u5426\u5220\u9664\u914d\u7f6e\u6587\u4ef6?: $is_config_file\" pause fi api del $is_conf_dir/\"$is_config_file\" $is_dynamic_port_file &>/dev/null rm -rf $is_conf_dir/\"$is_config_file\" $is_dynamic_port_file [[ $is_api_fail && ! $is_new_json ]] && manage restart & [[ ! $is_no_del_msg ]] && _green \"\\n\u5df2\u5220\u9664: $is_config_file\\n\" [[ $is_caddy ]] && { is_del_host=$host [[ $is_change ]] && { [[ ! $old_host ]] && return # no host exist or not set new host; is_del_host=$old_host } [[ $is_del_host && $host != $old_host ]] && { rm -rf $is_caddy_conf/$is_del_host.conf $is_caddy_conf/$is_del_host.conf.add [[ ! $is_new_json ]] && manage restart caddy & } } fi if [[ ! $(ls $is_conf_dir | grep .json) && ! $is_change ]]; then warn \"\u5f53\u524d\u914d\u7f6e\u76ee\u5f55\u4e3a\u7a7a! \u56e0\u4e3a\u4f60\u521a\u521a\u5220\u9664\u4e86\u6700\u540e\u4e00\u4e2a\u914d\u7f6e\u6587\u4ef6.\" is_conf_dir_empty=1 fi [[ $is_dont_auto_exit ]] && unset is_config_file } # uninstall uninstall() { if [[ $is_caddy ]]; then is_tmp_list=(\"\u5378\u8f7d $is_core_name\" \"\u5378\u8f7d ${is_core_name} & Caddy\") ask list is_do_uninstall else ask string y \"\u662f\u5426\u5378\u8f7d ${is_core_name}? [y]:\" fi manage stop &>/dev/null manage disable &>/dev/null rm -rf $is_core_dir $is_log_dir $is_sh_bin /lib/systemd/system/$is_core.service sed -i \"/alias $is_core=/d\" /root/.bashrc # uninstall caddy; 2 is ask result if [[ $REPLY == '2' ]]; then manage stop caddy &>/dev/null manage disable caddy &>/dev/null rm -rf $is_caddy_dir $is_caddy_bin /lib/systemd/system/caddy.service fi [[ $is_install_sh ]] && return # reinstall _green \"\\n\u5378\u8f7d\u5b8c\u6210!\" msg \"\u811a\u672c\u54ea\u91cc\u9700\u8981\u5b8c\u5584? \u8bf7\u53cd\u9988\" msg \"\u53cd\u9988\u95ee\u9898) $(msg_ul https://github.com/${is_sh_repo}/issues)\\n\" } # manage run status manage() { [[ $is_dont_auto_exit ]] && return case $1 in 1 | start) is_do=start is_do_msg=\u542f\u52a8 is_test_run=1 ;; 2 | stop) is_do=stop is_do_msg=\u505c\u6b62 ;; 3 | r | restart) is_do=restart is_do_msg=\u91cd\u542f is_test_run=1 ;; *) is_do=$1 is_do_msg=$1 ;; esac case $2 in caddy) is_do_name=$2 is_run_bin=$is_caddy_bin is_do_name_msg=Caddy ;; *) is_do_name=$is_core is_run_bin=$is_core_bin is_do_name_msg=$is_core_name ;; esac systemctl $is_do $is_do_name [[ $is_test_run && ! $is_new_install ]] && { sleep 2 if [[ ! $(pgrep -f $is_run_bin) ]]; then is_run_fail=${is_do_name_msg,,} [[ ! $is_no_manage_msg ]] && { msg warn \"($is_do_msg) $is_do_name_msg \u5931\u8d25\" _yellow \"\u68c0\u6d4b\u5230\u8fd0\u884c\u5931\u8d25, \u81ea\u52a8\u6267\u884c\u6d4b\u8bd5\u8fd0\u884c.\" get test-run _yellow \"\u6d4b\u8bd5\u7ed3\u675f, \u8bf7\u6309 Enter \u9000\u51fa.\" } fi } } # use api add or del inbounds api() { [[ $is_core_ver_lt_5 ]] && { warn \"$is_core_ver \u7248\u672c\u4e0d\u652f\u6301\u4f7f\u7528 API \u64cd\u4f5c. \u8bf7\u5347\u7ea7\u5185\u6838\u7248\u672c: $is_core update core\" is_api_fail=1 return } [[ ! $1 ]] && err \"\u65e0\u6cd5\u8bc6\u522b API \u7684\u53c2\u6570.\" [[ $is_core_stop ]] && { warn \"$is_core_name \u5f53\u524d\u5904\u4e8e\u505c\u6b62\u72b6\u6001.\" is_api_fail=1 return } case $1 in add) is_api_do=adi ;; del) is_api_do=rmi ;; s) is_api_do=stats ;; t | sq) is_api_do=statsquery ;; esac [[ ! $is_api_do ]] && is_api_do=$1 [[ ! $is_api_port ]] && { is_api_port=$(jq '.inbounds[] | select(.tag == \"api\") | .port' $is_config_json) [[ $? != 0 ]] && { warn \"\u8bfb\u53d6 API \u7aef\u53e3\u5931\u8d25, \u65e0\u6cd5\u4f7f\u7528 API \u64cd\u4f5c.\" return } } $is_core_bin api $is_api_do --server=127.0.0.1:$is_api_port ${@:2} [[ $? != 0 ]] && { is_api_fail=1 } } # add a config add() { is_lower=${1,,} if [[ $is_lower ]]; then case $is_lower in tcp | kcp | quic | tcpd | kcpd | quicd) is_new_protocol=VMess-$(sed 's/^K/mK/;s/D$/-dynamic-port/' <<<${is_lower^^}) ;; ws | h2 | grpc | vws | vh2 | vgrpc | tws | th2 | tgrpc) is_new_protocol=$(sed -E \"s/^V/VLESS-/;s/^T/Trojan-/;/^(W|H|G)/{s/^/VMess-/};s/G/g/\" <<<${is_lower^^})-TLS ;; # r | reality) # is_new_protocol=VLESS-XTLS-uTLS-REALITY # ;; ss) is_new_protocol=Shadowsocks ;; door) is_new_protocol=Dokodemo-Door ;; socks) is_new_protocol=Socks ;; http) is_new_protocol=local-$is_lower ;; *) for v in ${protocol_list[@]}; do [[ $(egrep -i \"^$is_lower$\" <<<$v) ]] && is_new_protocol=$v && break done [[ ! $is_new_protocol ]] && err \"\u65e0\u6cd5\u8bc6\u522b ($1), \u8bf7\u4f7f\u7528: $is_core add [protocol] [args... | auto]\" ;; esac fi # no prefer protocol [[ ! $is_new_protocol ]] && ask set_protocol case ${is_new_protocol,,} in *-tls) is_use_tls=1 is_use_host=$2 is_use_uuid=$3 is_use_path=$4 is_add_opts=\"[host] [uuid] [/path]\" ;; vmess*) is_use_port=$2 is_use_uuid=$3 is_use_header_type=$4 is_use_dynamic_port_start=$5 is_use_dynamic_port_end=$6 [[ $(grep dynamic-port <<<$is_new_protocol) ]] && is_dynamic_port=1 if [[ $is_dynamic_port ]]; then is_add_opts=\"[port] [uuid] [type] [start_port] [end_port]\" else is_add_opts=\"[port] [uuid] [type]\" fi ;; # *reality*) # is_reality=1 # is_use_port=$2 # is_use_uuid=$3 # is_use_servername=$4 # ;; shadowsocks) is_use_port=$2 is_use_pass=$3 is_use_method=$4 is_add_opts=\"[port] [password] [method]\" ;; *door) is_use_port=$2 is_use_door_addr=$3 is_use_door_port=$4 is_add_opts=\"[port] [remote_addr] [remote_port]\" ;; socks) is_socks=1 is_use_port=$2 is_use_socks_user=$3 is_use_socks_pass=$4 is_add_opts=\"[port] [username] [password]\" ;; *http) is_use_port=$2 is_add_opts=\"[port]\" ;; esac [[ $1 && ! $is_change ]] && { msg \"\\n\u4f7f\u7528\u534f\u8bae: $is_new_protocol\" # err msg tips is_err_tips=\"\\n\\n\u8bf7\u4f7f\u7528: $(_green $is_core add $1 $is_add_opts) \u6765\u6dfb\u52a0 $is_new_protocol \u914d\u7f6e\" } # remove old protocol args if [[ $is_set_new_protocol ]]; then case $is_old_net in tcp) unset header_type net ;; kcp | quic) kcp_seed= [[ $(grep -i tcp <<<$is_new_protocol) ]] && header_type= ;; h2 | ws | grpc) old_host=$host if [[ ! $is_use_tls ]]; then host= else [[ $is_old_net == 'grpc' ]] && { path=/$path } fi [[ ! $(grep -i trojan <<<$is_new_protocol) ]] && is_trojan= ;; reality) [[ ! $(grep -i reality <<<$is_new_protocol) ]] && is_reality= ;; ss) [[ $(is_test uuid $ss_password) ]] && uuid=$ss_password ;; esac [[ $is_dynamic_port && ! $(grep dynamic-port <<<$is_new_protocol) ]] && { is_dynamic_port= } [[ ! $(is_test uuid $uuid) ]] && uuid= fi # no-auto-tls only use h2,ws,grpc if [[ $is_no_auto_tls && ! $is_use_tls ]]; then err \"$is_new_protocol \u4e0d\u652f\u6301\u624b\u52a8\u914d\u7f6e tls.\" fi # prefer args. if [[ $2 ]]; then for v in is_use_port is_use_uuid is_use_header_type is_use_host is_use_path is_use_pass is_use_method is_use_door_addr is_use_door_port is_use_dynamic_port_start is_use_dynamic_port_end; do [[ ${!v} == 'auto' ]] && unset $v done if [[ $is_use_port ]]; then [[ ! $(is_test port ${is_use_port}) ]] && { err \"($is_use_port) \u4e0d\u662f\u4e00\u4e2a\u6709\u6548\u7684\u7aef\u53e3. $is_err_tips\" } [[ $(is_test port_used $is_use_port) ]] && { err \"\u65e0\u6cd5\u4f7f\u7528 ($is_use_port) \u7aef\u53e3. $is_err_tips\" } port=$is_use_port fi if [[ $is_use_door_port ]]; then [[ ! $(is_test port ${is_use_door_port}) ]] && { err \"(${is_use_door_port}) \u4e0d\u662f\u4e00\u4e2a\u6709\u6548\u7684\u76ee\u6807\u7aef\u53e3. $is_err_tips\" } door_port=$is_use_door_port fi if [[ $is_use_uuid ]]; then [[ ! $(is_test uuid $is_use_uuid) ]] && { err \"($is_use_uuid) \u4e0d\u662f\u4e00\u4e2a\u6709\u6548\u7684 UUID. $is_err_tips\" } uuid=$is_use_uuid fi if [[ $is_use_path ]]; then [[ ! $(is_test path $is_use_path) ]] && { err \"($is_use_path) \u4e0d\u662f\u6709\u6548\u7684\u8def\u5f84. $is_err_tips\" } path=$is_use_path fi if [[ $is_use_header_type || $is_use_method ]]; then is_tmp_use_name=\u52a0\u5bc6\u65b9\u5f0f is_tmp_list=${ss_method_list[@]} [[ ! $is_use_method ]] && { is_tmp_use_name=\u4f2a\u88c5\u7c7b\u578b ask set_header_type } for v in ${is_tmp_list[@]}; do [[ $(egrep -i \"^${is_use_header_type}${is_use_method}$\" <<<$v) ]] && is_tmp_use_type=$v && break done [[ ! ${is_tmp_use_type} ]] && { warn \"(${is_use_header_type}${is_use_method}) \u4e0d\u662f\u4e00\u4e2a\u53ef\u7528\u7684${is_tmp_use_name}.\" msg \"${is_tmp_use_name}\u53ef\u7528\u5982\u4e0b: \" for v in ${is_tmp_list[@]}; do msg \"\\t\\t$v\" done msg \"$is_err_tips\\n\" exit 1 } ss_method=$is_tmp_use_type header_type=$is_tmp_use_type fi if [[ $is_dynamic_port && $is_use_dynamic_port_start ]]; then get dynamic-port-test fi [[ $is_use_pass ]] && ss_password=$is_use_pass [[ $is_use_host ]] && host=$is_use_host [[ $is_use_door_addr ]] && door_addr=$is_use_door_addr [[ $is_use_servername ]] && is_servername=$is_use_servername [[ $is_use_socks_user ]] && is_socks_user=$is_use_socks_user [[ $is_use_socks_pass ]] && is_socks_pass=$is_use_socks_pass fi if [[ $is_use_tls ]]; then if [[ ! $is_no_auto_tls && ! $is_caddy && ! $is_gen ]]; then # test auto tls [[ $(is_test port_used 80) || $(is_test port_used 443) ]] && { get_port is_http_port=$tmp_port get_port is_https_port=$tmp_port warn \"\u7aef\u53e3 (80 \u6216 443) \u5df2\u7ecf\u88ab\u5360\u7528, \u4f60\u4e5f\u53ef\u4ee5\u8003\u8651\u4f7f\u7528 no-auto-tls\" msg \"\\e[41m no-auto-tls \u5e2e\u52a9(help)\\e[0m: $(msg_ul https://233boy.com/$is_core/no-auto-tls/)\\n\" msg \"\\n Caddy \u5c06\u4f7f\u7528\u975e\u6807\u51c6\u7aef\u53e3\u5b9e\u73b0\u81ea\u52a8\u914d\u7f6e TLS, HTTP:$is_http_port HTTPS:$is_https_port\\n\" msg \"\u8bf7\u786e\u5b9a\u662f\u5426\u7ee7\u7eed???\" pause } is_install_caddy=1 fi # set host [[ ! $host ]] && ask string host \"\u8bf7\u8f93\u5165\u57df\u540d:\" # test host dns get host-test else # for main menu start, dont auto create args if [[ $is_main_start ]]; then # set port [[ ! $port ]] && ask string port \"\u8bf7\u8f93\u5165\u7aef\u53e3:\" case ${is_new_protocol,,} in *tcp* | *kcp* | *quic*) [[ ! $header_type ]] && ask set_header_type ;; socks) # set user [[ ! $is_socks_user ]] && ask string is_socks_user \"\u8bf7\u8bbe\u7f6e\u7528\u6237\u540d:\" # set password [[ ! $is_socks_pass ]] && ask string is_socks_pass \"\u8bf7\u8bbe\u7f6e\u5bc6\u7801:\" ;; shadowsocks) # set method [[ ! $ss_method ]] && ask set_ss_method # set password [[ ! $ss_password ]] && ask string ss_password \"\u8bf7\u8bbe\u7f6e\u5bc6\u7801:\" ;; esac # set dynamic port [[ $is_dynamic_port && ! $is_dynamic_port_range ]] && { ask string is_use_dynamic_port_start \"\u8bf7\u8f93\u5165\u52a8\u6001\u5f00\u59cb\u7aef\u53e3:\" ask string is_use_dynamic_port_end \"\u8bf7\u8f93\u5165\u52a8\u6001\u7ed3\u675f\u7aef\u53e3:\" get dynamic-port-test } fi fi # Dokodemo-Door if [[ $is_new_protocol == 'Dokodemo-Door' ]]; then # set remote addr [[ ! $door_addr ]] && ask string door_addr \"\u8bf7\u8f93\u5165\u76ee\u6807\u5730\u5740:\" # set remote port [[ ! $door_port ]] && ask string door_port \"\u8bf7\u8f93\u5165\u76ee\u6807\u7aef\u53e3:\" fi # Shadowsocks 2022 if [[ $(grep 2022 <<<$ss_method) ]]; then # test ss2022 password [[ $ss_password ]] && { is_test_json=1 # create server Shadowsocks | $is_core_bin -test &>/dev/null create server Shadowsocks $is_core_bin -test <<<\"$is_new_json\" &>/dev/null if [[ $? != 0 ]]; then warn \"Shadowsocks \u534f\u8bae ($ss_method) \u4e0d\u652f\u6301\u4f7f\u7528\u5bc6\u7801 ($(_red_bg $ss_password))\\n\\n\u4f60\u53ef\u4ee5\u4f7f\u7528\u547d\u4ee4: $(_green $is_core ss2022) \u751f\u6210\u652f\u6301\u7684\u5bc6\u7801.\\n\\n\u811a\u672c\u5c06\u81ea\u52a8\u521b\u5efa\u53ef\u7528\u5bc6\u7801:)\" ss_password= # create new json. json_str= fi is_test_json= } fi # install caddy if [[ $is_install_caddy ]]; then get install-caddy fi # create json create server $is_new_protocol # show config info. info } # get config info # or somes required args get() { case $1 in addr) is_addr=$host [[ ! $is_addr ]] && { get_ip is_addr=$ip } ;; new) [[ ! $host ]] && get_ip [[ ! $port ]] && get_port && port=$tmp_port [[ ! $uuid ]] && get_uuid && uuid=$tmp_uuid ;; file) is_file_str=$2 [[ ! $is_file_str ]] && is_file_str='.json$' # is_all_json=(\"$(ls $is_conf_dir | egrep $is_file_str)\") readarray -t is_all_json <<<\"$(ls $is_conf_dir | egrep -i \"$is_file_str\" | sed '/dynamic-port-.*-link/d' | head -233)\" # limit max 233 lines for show. [[ ! $is_all_json ]] && err \"\u65e0\u6cd5\u627e\u5230\u76f8\u5173\u7684\u914d\u7f6e\u6587\u4ef6: $2\" [[ ${#is_all_json[@]} -eq 1 ]] && is_config_file=$is_all_json && is_auto_get_config=1 [[ ! $is_config_file ]] && { [[ $is_dont_auto_exit ]] && return ask get_config_file } ;; info) get file $2 if [[ $is_config_file ]]; then is_json_str=$(cat $is_conf_dir/\"$is_config_file\") is_json_data_base=$(jq '.inbounds[0]|.protocol,.port,.settings.clients[0].id,.settings.clients[0].password,.settings.method,.settings.password,.settings.address,.settings.port,.settings.detour.to,.settings.accounts[0].user,.settings.accounts[0].pass' <<<$is_json_str) [[ $? != 0 ]] && err \"\u65e0\u6cd5\u8bfb\u53d6\u6b64\u6587\u4ef6: $is_config_file\" is_json_data_more=$(jq '.inbounds[0]|.streamSettings|.network,.security,.tcpSettings.header.type,.kcpSettings.seed,.kcpSettings.header.type,.quicSettings.header.type,.wsSettings.path,.httpSettings.path,.grpcSettings.serviceName' <<<$is_json_str) is_json_data_host=$(jq '.inbounds[0]|.streamSettings|.grpc_host,.wsSettings.headers.Host,.httpSettings.host[0]' <<<$is_json_str) is_json_data_reality=$(jq '.inbounds[0]|.streamSettings|.realitySettings.serverNames[0],.realitySettings.publicKey,.realitySettings.privateKey' <<<$is_json_str) is_up_var_set=(null is_protocol port uuid trojan_password ss_method ss_password door_addr door_port is_dynamic_port is_socks_user is_socks_pass net is_reality tcp_type kcp_seed kcp_type quic_type ws_path h2_path grpc_path grpc_host ws_host h2_host is_servername is_public_key is_private_key) [[ $is_debug ]] && msg \"\\n------------- debug: $is_config_file -------------\" i=0 for v in $(sed 's/\"\"/null/g;s/\"//g' <<<\"$is_json_data_base $is_json_data_more $is_json_data_host $is_json_data_reality\"); do ((i++)) [[ $is_debug ]] && msg \"$i-${is_up_var_set[$i]}: $v\" export ${is_up_var_set[$i]}=\"${v}\" done for v in ${is_up_var_set[@]}; do [[ ${!v} == 'null' ]] && unset $v done path=\"${ws_path}${h2_path}${grpc_path}\" host=\"${ws_host}${h2_host}${grpc_host}\" header_type=\"${tcp_type}${kcp_type}${quic_type}\" if [[ $is_reality == 'reality' ]]; then net=reality else is_reality= fi [[ ! $kcp_seed ]] && is_no_kcp_seed=1 is_config_name=$is_config_file if [[ $is_dynamic_port ]]; then is_dynamic_port_file=$is_conf_dir/$is_dynamic_port is_dynamic_port_range=$(jq -r '.inbounds[0].port' $is_dynamic_port_file) [[ $? != 0 ]] && err \"\u65e0\u6cd5\u8bfb\u53d6\u52a8\u6001\u7aef\u53e3\u6587\u4ef6: $is_dynamic_port\" fi if [[ $is_caddy && $host && -f $is_caddy_conf/$host.conf ]]; then is_tmp_https_port=$(egrep -o \"$host:[1-9][0-9]?+\" $is_caddy_conf/$host.conf | sed s/.*://) fi [[ $is_tmp_https_port ]] && is_https_port=$is_tmp_https_port [[ $is_client && $host ]] && port=$is_https_port get protocol $is_protocol-$net fi ;; protocol) get addr # get host or server ip is_lower=${2,,} net= case $is_lower in vmess*) is_protocol=vmess if [[ $is_dynamic_port ]]; then is_server_id_json='settings:{clients:[{id:'\\\"$uuid\\\"'}],detour:{to:'\\\"$is_config_name-link.json\\\"'}}' else is_server_id_json='settings:{clients:[{id:'\\\"$uuid\\\"'}]}' fi is_client_id_json='settings:{vnext:[{address:'\\\"$is_addr\\\"',port:'\"$port\"',users:[{id:'\\\"$uuid\\\"'}]}]}' ;; vless*) is_protocol=vless is_server_id_json='settings:{clients:[{id:'\\\"$uuid\\\"'}],decryption:\"none\"}' is_client_id_json='settings:{vnext:[{address:'\\\"$is_addr\\\"',port:'\"$port\"',users:[{id:'\\\"$uuid\\\"',encryption:\"none\"}]}]}' if [[ $is_reality ]]; then is_server_id_json='settings:{clients:[{id:'\\\"$uuid\\\"',flow:\"xtls-rprx-vision\"}],decryption:\"none\"}' is_client_id_json='settings:{vnext:[{address:'\\\"$is_addr\\\"',port:'\"$port\"',users:[{id:'\\\"$uuid\\\"',encryption:\"none\",flow:\"xtls-rprx-vision\"}]}]}' fi ;; trojan*) is_protocol=trojan [[ ! $trojan_password ]] && trojan_password=$uuid is_server_id_json='settings:{clients:[{password:'\\\"$trojan_password\\\"'}]}' is_client_id_json='settings:{servers:[{address:'\\\"$is_addr\\\"',port:'\"$port\"',password:'\\\"$trojan_password\\\"'}]}' is_trojan=1 ;; shadowsocks*) is_protocol=shadowsocks net=ss [[ ! $ss_method ]] && ss_method=$is_random_ss_method [[ ! $ss_password ]] && { ss_password=$uuid [[ $(grep 2022 <<<$ss_method) ]] && ss_password=$(get ss2022) } is_client_id_json='settings:{servers:[{address:'\\\"$is_addr\\\"',port:'\"$port\"',method:'\\\"$ss_method\\\"',password:'\\\"$ss_password\\\"',}]}' json_str='settings:{method:'\\\"$ss_method\\\"',password:'\\\"$ss_password\\\"',network:\"tcp,udp\"}' ;; dokodemo-door*) is_protocol=dokodemo-door net=door json_str='settings:{port:'\"$door_port\"',address:'\\\"$door_addr\\\"',network:\"tcp,udp\"}' ;; *http*) is_protocol=http net=http json_str='settings:{\"timeout\": 233}' ;; *socks*) is_protocol=socks net=socks [[ ! $is_socks_user ]] && is_socks_user=233boy [[ ! $is_socks_pass ]] && is_socks_pass=$uuid json_str='settings:{auth:\"password\",accounts:[{user:'\\\"$is_socks_user\\\"',pass:'\\\"$is_socks_pass\\\"'}],udp:true,ip:\"0.0.0.0\"}' ;; *) err \"\u65e0\u6cd5\u8bc6\u522b\u534f\u8bae: $is_config_file\" ;; esac [[ $net ]] && return # if net exist, dont need more json args case $is_lower in *tcp*) net=tcp [[ ! $header_type ]] && header_type=none is_stream='streamSettings:{network:\"tcp\",tcpSettings:{header:{type:'\\\"$header_type\\\"'}}}' json_str=''\"$is_server_id_json\"','\"$is_stream\"'' ;; *kcp* | *mkcp) net=kcp [[ ! $header_type ]] && header_type=$is_random_header_type [[ ! $is_no_kcp_seed && ! $kcp_seed ]] && kcp_seed=$uuid is_stream='streamSettings:{network:\"kcp\",kcpSettings:{seed:'\\\"$kcp_seed\\\"',header:{type:'\\\"$header_type\\\"'}}}' json_str=''\"$is_server_id_json\"','\"$is_stream\"'' ;; *quic*) net=quic [[ ! $header_type ]] && header_type=$is_random_header_type is_stream='streamSettings:{network:\"quic\",quicSettings:{header:{type:'\\\"$header_type\\\"'}}}' json_str=''\"$is_server_id_json\"','\"$is_stream\"'' ;; *ws* | *websocket) net=ws [[ ! $path ]] && path=\"/$uuid\" is_stream='streamSettings:{network:\"ws\",security:'\\\"$is_tls\\\"',wsSettings:{path:'\\\"$path\\\"',headers:{Host:'\\\"$host\\\"'}}}' json_str=''\"$is_server_id_json\"','\"$is_stream\"'' ;; *grpc* | *gun) net=grpc [[ ! $path ]] && path=\"$uuid\" [[ $path ]] && path=$(sed 's#/##g' <<<$path) is_stream='streamSettings:{network:\"grpc\",grpc_host:'\\\"$host\\\"',security:'\\\"$is_tls\\\"',grpcSettings:{serviceName:'\\\"$path\\\"'}}' json_str=''\"$is_server_id_json\"','\"$is_stream\"'' ;; *h2* | *http*) net=h2 [[ ! $path ]] && path=\"/$uuid\" is_stream='streamSettings:{network:\"h2\",security:'\\\"$is_tls\\\"',httpSettings:{path:'\\\"$path\\\"',host:['\\\"$host\\\"']}}' json_str=''\"$is_server_id_json\"','\"$is_stream\"'' ;; *reality*) net=reality [[ ! $is_servername ]] && is_servername=$is_random_servername [[ ! $is_private_key ]] && get_pbk is_stream='streamSettings:{network:\"tcp\",security:\"reality\",realitySettings:{dest:'\\\"${is_servername}\\:443\\\"',serverNames:['\\\"${is_servername}\\\"',\"\"],publicKey:'\\\"$is_public_key\\\"',privateKey:'\\\"$is_private_key\\\"',shortIds:[\"\"]}}' if [[ $is_client ]]; then is_stream='streamSettings:{network:\"tcp\",security:\"reality\",realitySettings:{serverName:'\\\"${is_servername}\\\"',\"fingerprint\": \"ios\",publicKey:'\\\"$is_public_key\\\"',\"shortId\": \"\",\"spiderX\": \"/\"}}' fi json_str=''\"$is_server_id_json\"','\"$is_stream\"'' ;; *) err \"\u65e0\u6cd5\u8bc6\u522b\u4f20\u8f93\u534f\u8bae: $is_config_file\" ;; esac ;; dynamic-port) # create random dynamic port if [[ $port -ge 60000 ]]; then is_dynamic_port_end=$(shuf -i $(($port - 2333))-$port -n1) is_dynamic_port_start=$(shuf -i $(($is_dynamic_port_end - 2333))-$is_dynamic_port_end -n1) else is_dynamic_port_start=$(shuf -i $port-$(($port + 2333)) -n1) is_dynamic_port_end=$(shuf -i $is_dynamic_port_start-$(($is_dynamic_port_start + 2333)) -n1) fi is_dynamic_port_range=\"$is_dynamic_port_start-$is_dynamic_port_end\" ;; dynamic-port-test) # test dynamic port [[ ! $(is_test port ${is_use_dynamic_port_start}) || ! $(is_test port ${is_use_dynamic_port_end}) ]] && { err \"\u65e0\u6cd5\u6b63\u786e\u5904\u7406\u52a8\u6001\u7aef\u53e3 ($is_use_dynamic_port_start-$is_use_dynamic_port_end) \u8303\u56f4.\" } [[ $(is_test port_used $is_use_dynamic_port_start) ]] && { err \"\u52a8\u6001\u7aef\u53e3 ($is_use_dynamic_port_start-$is_use_dynamic_port_end), \u4f46 ($is_use_dynamic_port_start) \u7aef\u53e3\u65e0\u6cd5\u4f7f\u7528.\" } [[ $(is_test port_used $is_use_dynamic_port_end) ]] && { err \"\u52a8\u6001\u7aef\u53e3 ($is_use_dynamic_port_start-$is_use_dynamic_port_end), \u4f46 ($is_use_dynamic_port_end) \u7aef\u53e3\u65e0\u6cd5\u4f7f\u7528.\" } [[ $is_use_dynamic_port_end -le $is_use_dynamic_port_start ]] && { err \"\u65e0\u6cd5\u6b63\u786e\u5904\u7406\u52a8\u6001\u7aef\u53e3 ($is_use_dynamic_port_start-$is_use_dynamic_port_end) \u8303\u56f4.\" } [[ $is_use_dynamic_port_start == $port || $is_use_dynamic_port_end == $port ]] && { err \"\u52a8\u6001\u7aef\u53e3 ($is_use_dynamic_port_start-$is_use_dynamic_port_end) \u8303\u56f4\u548c\u4e3b\u7aef\u53e3 ($port) \u51b2\u7a81.\" } is_dynamic_port_range=\"$is_use_dynamic_port_start-$is_use_dynamic_port_end\" ;; host-test) # test host dns record; for auto *tls required. [[ $is_no_auto_tls || $is_gen ]] && return get_ip get ping if [[ ! $(grep $ip <<<$is_host_dns) ]]; then msg \"\\n\u8bf7\u5c06 ($(_red_bg $host)) \u89e3\u6790\u5230 ($(_red_bg $ip))\" msg \"\\n\u5982\u679c\u4f7f\u7528 Cloudflare, \u5728 DNS \u90a3; \u5173\u95ed (Proxy status / \u4ee3\u7406\u72b6\u6001), \u5373\u662f (DNS only / \u4ec5\u9650 DNS)\" ask string y \"\u6211\u5df2\u7ecf\u786e\u5b9a\u89e3\u6790 [y]:\" get ping if [[ ! $(grep $ip <<<$is_host_dns) ]]; then _cyan \"\\n\u6d4b\u8bd5\u7ed3\u679c: $is_host_dns\" err \"\u57df\u540d ($host) \u6ca1\u6709\u89e3\u6790\u5230 ($ip)\" fi fi ;; ssss | ss2022) openssl rand -base64 32 [[ $? != 0 ]] && err \"\u65e0\u6cd5\u751f\u6210 Shadowsocks 2022 \u5bc6\u7801, \u8bf7\u5b89\u88c5 openssl.\" ;; ping) # is_ip_type=\"-4\" # [[ $(grep \":\" <<<$ip) ]] && is_ip_type=\"-6\" # is_host_dns=$(ping $host $is_ip_type -c 1 -W 2 | head -1) is_dns_type=\"a\" [[ $(grep \":\" <<<$ip) ]] && is_dns_type=\"aaaa\" is_host_dns=$(_wget -qO- --header=\"accept: application/dns-json\" \"https://one.one.one.one/dns-query?name=$host&type=$is_dns_type\") ;; log | logerr) msg \"\\n \u63d0\u9192: \u6309 $(_green Ctrl + C) \u9000\u51fa\\n\" [[ $1 == 'log' ]] && tail -f $is_log_dir/access.log [[ $1 == 'logerr' ]] && tail -f $is_log_dir/error.log ;; install-caddy) _green \"\\n\u5b89\u88c5 Caddy \u5b9e\u73b0\u81ea\u52a8\u914d\u7f6e TLS.\\n\" load download.sh download caddy load systemd.sh install_service caddy &>/dev/null is_caddy=1 _green \"\u5b89\u88c5 Caddy \u6210\u529f.\\n\" ;; reinstall) is_install_sh=$(cat $is_sh_dir/install.sh) uninstall bash <<<$is_install_sh ;; test-run) systemctl list-units --full -all &>/dev/null [[ $? != 0 ]] && { _yellow \"\\n\u65e0\u6cd5\u6267\u884c\u6d4b\u8bd5, \u8bf7\u68c0\u67e5 systemctl \u72b6\u6001.\\n\" return } is_no_manage_msg=1 if [[ ! $(pgrep -f $is_core_bin) ]]; then _yellow \"\\n\u6d4b\u8bd5\u8fd0\u884c $is_core_name ..\\n\" manage start &>/dev/null if [[ $is_run_fail == $is_core ]]; then _red \"$is_core_name \u8fd0\u884c\u5931\u8d25\u4fe1\u606f:\" $is_core_bin $is_with_run_arg -c $is_config_json -confdir $is_conf_dir else _green \"\\n\u6d4b\u8bd5\u901a\u8fc7, \u5df2\u542f\u52a8 $is_core_name ..\\n\" fi else _green \"\\n$is_core_name \u6b63\u5728\u8fd0\u884c, \u8df3\u8fc7\u6d4b\u8bd5\\n\" fi if [[ $is_caddy ]]; then if [[ ! $(pgrep -f $is_caddy_bin) ]]; then _yellow \"\\n\u6d4b\u8bd5\u8fd0\u884c Caddy ..\\n\" manage start caddy &>/dev/null if [[ $is_run_fail == 'caddy' ]]; then _red \"Caddy \u8fd0\u884c\u5931\u8d25\u4fe1\u606f:\" $is_caddy_bin run --config $is_caddyfile else _green \"\\n\u6d4b\u8bd5\u901a\u8fc7, \u5df2\u542f\u52a8 Caddy ..\\n\" fi else _green \"\\nCaddy \u6b63\u5728\u8fd0\u884c, \u8df3\u8fc7\u6d4b\u8bd5\\n\" fi fi ;; esac } # show info info() { if [[ ! $is_protocol ]]; then get info $1 fi # is_color=$(shuf -i 41-45 -n1) is_color=44 case $net in tcp | kcp | quic) is_can_change=(0 1 5 7) is_info_show=(0 1 2 3 4 5) is_vmess_url=$(jq -c '{v:2,ps:'\\\"233boy-${net}-$is_addr\\\"',add:'\\\"$is_addr\\\"',port:'\\\"$port\\\"',id:'\\\"$uuid\\\"',aid:\"0\",net:'\\\"$net\\\"',type:'\\\"$header_type\\\"',path:'\\\"$kcp_seed\\\"'}' <<<{}) is_url=vmess://$(echo -n $is_vmess_url | base64 -w 0) is_tmp_port=$port [[ $is_dynamic_port ]] && { is_can_change+=(12) is_tmp_port=\"$port & \u52a8\u6001\u7aef\u53e3: $is_dynamic_port_range\" } [[ $kcp_seed ]] && { is_info_show+=(9) is_can_change+=(14) } is_info_str=($is_protocol $is_addr \"$is_tmp_port\" $uuid $net $header_type $kcp_seed) ;; ss) is_can_change=(0 1 4 6) is_info_show=(0 1 2 10 11) is_url=\"ss://$(echo -n ${ss_method}:${ss_password} | base64 -w 0)@${is_addr}:${port}#233boy-$net-${is_addr}\" is_info_str=($is_protocol $is_addr $port $ss_password $ss_method) ;; ws | h2 | grpc) is_color=45 is_can_change=(0 1 2 3 5) is_info_show=(0 1 2 3 4 6 7 8) is_url_path=path [[ $net == 'grpc' ]] && { path=$(sed 's#/##g' <<<$path) is_url_path=serviceName } [[ $is_protocol == 'vmess' ]] && { is_vmess_url=$(jq -c '{v:2,ps:'\\\"233boy-$net-$host\\\"',add:'\\\"$is_addr\\\"',port:'\\\"$is_https_port\\\"',id:'\\\"$uuid\\\"',aid:\"0\",net:'\\\"$net\\\"',host:'\\\"$host\\\"',path:'\\\"$path\\\"',tls:'\\\"tls\\\"'}' <<<{}) is_url=vmess://$(echo -n $is_vmess_url | base64 -w 0) } || { [[ $is_trojan ]] && { uuid=$trojan_password is_can_change=(0 1 2 3 4) is_info_show=(0 1 2 10 4 6 7 8) } is_url=\"$is_protocol://$uuid@$host:$is_https_port?encryption=none&security=tls&type=$net&host=$host&${is_url_path}=$(sed 's#/#%2F#g' <<<$path)#233boy-$net-$host\" } [[ $is_caddy ]] && is_can_change+=(13) is_info_str=($is_protocol $is_addr $is_https_port $uuid $net $host $path 'tls') ;; reality) is_color=41 is_can_change=(0 1 5 10 11) is_info_show=(0 1 2 3 15 8 16 17 18) is_info_str=($is_protocol $is_addr $port $uuid xtls-rprx-vision reality $is_servername \"ios\" $is_public_key) is_url=\"$is_protocol://$uuid@$ip:$port?encryption=none&security=reality&flow=xtls-rprx-vision&type=tcp&sni=$is_servername&pbk=$is_public_key&fp=ios#233boy-$net-$is_addr\" ;; door) is_can_change=(0 1 8 9) is_info_show=(0 1 2 13 14) is_info_str=($is_protocol $is_addr $port $door_addr $door_port) ;; socks) is_can_change=(0 1 15 4) is_info_show=(0 1 2 19 10) is_info_str=($is_protocol $is_addr $port $is_socks_user $is_socks_pass) is_url=\"socks://$(echo -n ${is_socks_user}:${is_socks_pass} | base64 -w 0)@${is_addr}:${port}#233boy-$net-${is_addr}\" ;; http) is_can_change=(0 1) is_info_show=(0 1 2) is_info_str=($is_protocol 127.0.0.1 $port) ;; esac [[ $is_dont_show_info || $is_gen || $is_dont_auto_exit ]] && return # dont show info msg \"-------------- $is_config_name -------------\" for ((i = 0; i < ${#is_info_show[@]}; i++)); do a=${info_list[${is_info_show[$i]}]} if [[ ${#a} -eq 11 || ${#a} -ge 13 ]]; then tt='\\t' else tt='\\t\\t' fi msg \"$a $tt= \\e[${is_color}m${is_info_str[$i]}\\e[0m\" done if [[ $is_new_install ]]; then warn \"\u9996\u6b21\u5b89\u88c5\u8bf7\u67e5\u770b\u811a\u672c\u5e2e\u52a9\u6587\u6863: $(msg_ul https://233boy.com/$is_core/$is_core-script/)\" fi if [[ $is_url ]]; then msg \"------------- ${info_list[12]} -------------\" msg \"\\e[4;${is_color}m${is_url}\\e[0m\" fi if [[ $is_no_auto_tls ]]; then is_tmp_path=$path [[ $net == 'grpc' ]] && is_tmp_path=\"/$path/*\" msg \"------------- no-auto-tls INFO -------------\" msg \"\u7aef\u53e3(port): $port\" msg \"\u8def\u5f84(path): $is_tmp_path\" msg \"\\e[41m\u5e2e\u52a9(help)\\e[0m: $(msg_ul https://233boy.com/$is_core/no-auto-tls/)\" fi footer_msg } # footer msg footer_msg() { [[ $is_core_stop && ! $is_new_json ]] && warn \"$is_core_name \u5f53\u524d\u5904\u4e8e\u505c\u6b62\u72b6\u6001.\" [[ $is_caddy_stop && $host ]] && warn \"Caddy \u5f53\u524d\u5904\u4e8e\u505c\u6b62\u72b6\u6001.\" ####### \u8981\u70b913\u8138\u5417\u53ea\u4f1a\u6539\u6211\u94fe\u63a5\u7684\u5c0f\u4eba ####### unset c n m s b msg \"------------- END -------------\" msg \"\u5173\u6ce8(tg): $(msg_ul https://t.me/tg2333)\" msg \"\u6587\u6863(doc): $(msg_ul https://233boy.com/$is_core/$is_core-script/)\" msg \"\u63a8\u5e7f(ads): \u673a\u573a\u63a8\u8350($is_core_name services): $(msg_ul https://g${c}e${n}t${m}j${s}m${b}s.com/)\\n\" ####### \u8981\u70b913\u8138\u5417\u53ea\u4f1a\u6539\u6211\u94fe\u63a5\u7684\u5c0f\u4eba ####### } # URL or qrcode url_qr() { is_dont_show_info=1 info $2 if [[ $is_url ]]; then [[ $1 == 'url' ]] && { msg \"\\n------------- $is_config_name & URL \u94fe\u63a5 -------------\" msg \"\\n\\e[${is_color}m${is_url}\\e[0m\\n\" footer_msg } || { link=\"https://233boy.github.io/tools/qr.html#${is_url}\" msg \"\\n------------- $is_config_name & QR code \u4e8c\u7ef4\u7801 -------------\" msg if [[ $(type -P qrencode) ]]; then qrencode -t ANSI \"${is_url}\" else msg \"\u8bf7\u5b89\u88c5 qrencode: $(_green \"$cmd update -y; $cmd install qrencode -y\")\" fi msg msg \"\u5982\u679c\u65e0\u6cd5\u6b63\u5e38\u663e\u793a\u6216\u8bc6\u522b, \u8bf7\u4f7f\u7528\u4e0b\u9762\u7684\u94fe\u63a5\u6765\u751f\u6210\u4e8c\u7ef4\u7801:\" msg \"\\n\\e[4;${is_color}m${link}\\e[0m\\n\" footer_msg } else [[ $1 == 'url' ]] && { err \"($is_config_name) \u65e0\u6cd5\u751f\u6210 URL \u94fe\u63a5.\" } || { err \"($is_config_name) \u65e0\u6cd5\u751f\u6210 QR code \u4e8c\u7ef4\u7801.\" } fi } # update core, sh, caddy update() { case $1 in 1 | core | $is_core) is_update_name=core is_show_name=$is_core_name is_run_ver=v${is_core_ver##* } is_update_repo=$is_core_repo ;; 2 | sh) is_update_name=sh is_show_name=\"$is_core_name \u811a\u672c\" is_run_ver=$is_sh_ver is_update_repo=$is_sh_repo ;; 3 | caddy) [[ ! $is_caddy ]] && err \"\u4e0d\u652f\u6301\u66f4\u65b0 Caddy.\" is_update_name=caddy is_show_name=\"Caddy\" is_run_ver=$is_caddy_ver is_update_repo=$is_caddy_repo ;; *) err \"\u65e0\u6cd5\u8bc6\u522b ($1), \u8bf7\u4f7f\u7528: $is_core update [core | sh | caddy] [ver]\" ;; esac [[ $2 ]] && is_new_ver=v${2#v} [[ $is_run_ver == $is_new_ver ]] && { msg \"\\n\u81ea\u5b9a\u4e49\u7248\u672c\u548c\u5f53\u524d $is_show_name \u7248\u672c\u4e00\u6837, \u65e0\u9700\u66f4\u65b0.\\n\" exit } load download.sh if [[ $is_new_ver ]]; then msg \"\\n\u4f7f\u7528\u81ea\u5b9a\u4e49\u7248\u672c\u66f4\u65b0 $is_show_name: $(_green $is_new_ver)\\n\" else get_latest_version $is_update_name [[ $is_run_ver == $latest_ver ]] && { msg \"\\n$is_show_name \u5f53\u524d\u5df2\u7ecf\u662f\u6700\u65b0\u7248\u672c\u4e86.\\n\" exit } msg \"\\n\u53d1\u73b0 $is_show_name \u65b0\u7248\u672c: $(_green $latest_ver)\\n\" is_new_ver=$latest_ver fi download $is_update_name $is_new_ver msg \"\u66f4\u65b0\u6210\u529f, \u5f53\u524d $is_show_name \u7248\u672c: $(_green $is_new_ver)\\n\" msg \"$(_green \u8bf7\u67e5\u770b\u66f4\u65b0\u8bf4\u660e: https://github.com/$is_update_repo/releases/tag/$is_new_ver)\\n\" [[ $is_update_name == 'core' ]] && $is_core restart [[ $is_update_name == 'caddy' ]] && manage restart $is_update_name & } # main menu; if no prefer args. is_main_menu() { msg \"\\n------------- $is_core_name script $is_sh_ver by $author -------------\" msg \"$is_core_ver: $is_core_status\" msg \"\u7fa4\u7ec4 (Chat): $(msg_ul https://t.me/tg233boy)\" is_main_start=1 ask mainmenu case $REPLY in 1) add ;; 2) change ;; 3) info ;; 4) del ;; 5) ask list is_do_manage \"\u542f\u52a8 \u505c\u6b62 \u91cd\u542f\" manage $REPLY & msg \"\\n\u7ba1\u7406\u72b6\u6001\u6267\u884c: $(_green $is_do_manage)\\n\" ;; 6) is_tmp_list=(\"\u66f4\u65b0$is_core_name\" \"\u66f4\u65b0\u811a\u672c\") [[ $is_caddy ]] && is_tmp_list+=(\"\u66f4\u65b0Caddy\") ask list is_do_update null \"\\n\u8bf7\u9009\u62e9\u66f4\u65b0:\\n\" update $REPLY ;; 7) uninstall ;; 8) msg load help.sh show_help ;; 9) ask list is_do_other \"\u542f\u7528BBR \u67e5\u770b\u65e5\u5fd7 \u67e5\u770b\u9519\u8bef\u65e5\u5fd7 \u6d4b\u8bd5\u8fd0\u884c \u91cd\u88c5\u811a\u672c \u8bbe\u7f6eDNS\" case $REPLY in 1) load bbr.sh _try_enable_bbr ;; 2) get log ;; 3) get logerr ;; 4) get test-run ;; 5) get reinstall ;; 6) load dns.sh dns_set ;; esac ;; 10) load help.sh about ;; esac } # check prefer args, if not exist prefer args and show main menu main() { case $1 in a | add | gen | no-auto-tls) [[ $1 == 'gen' ]] && is_gen=1 [[ $1 == 'no-auto-tls' ]] && is_no_auto_tls=1 add ${@:2} ;; api | bin | convert | tls | run | uuid) [[ $is_core_ver_lt_5 ]] && { warn \"$is_core_ver \u7248\u672c\u4e0d\u652f\u6301\u4f7f\u7528\u547d\u4ee4. \u8bf7\u5347\u7ea7\u5185\u6838\u7248\u672c: $is_core update core\" return } is_run_command=$1 if [[ $1 == 'bin' ]]; then $is_core_bin ${@:2} else # [[ $is_run_command == 'pbk' ]] && is_run_command=x25519 $is_core_bin $is_run_command ${@:2} fi ;; bbr) load bbr.sh _try_enable_bbr ;; c | config | change) change ${@:2} ;; client | genc) [[ $1 == 'client' ]] && is_full_client=1 create client $2 ;; d | del | rm) del $2 ;; dd | ddel | fix | fix-all) case $1 in fix) [[ $2 ]] && { change $2 full } || { is_change_id=full && change } return ;; fix-all) is_dont_auto_exit=1 msg for v in $(ls $is_conf_dir | grep .json$ | sed '/dynamic-port-.*-link/d'); do msg \"fix: $v\" change $v full done _green \"\\nfix \u5b8c\u6210.\\n\" ;; *) is_dont_auto_exit=1 [[ ! $2 ]] && { err \"\u65e0\u6cd5\u627e\u5230\u9700\u8981\u5220\u9664\u7684\u53c2\u6570\" } || { for v in ${@:2}; do del $v done } ;; esac is_dont_auto_exit= [[ $is_api_fail ]] && manage restart & [[ $is_del_host ]] && manage restart caddy & ;; dns) load dns.sh dns_set ${@:2} ;; debug) is_debug=1 get info $2 warn \"\u5982\u679c\u9700\u8981\u590d\u5236; \u8bf7\u628a *uuid, *password, *host, *key \u7684\u503c\u6539\u5199, \u4ee5\u907f\u514d\u6cc4\u9732.\" ;; fix-config.json) create config.json ;; fix-caddyfile) if [[ $is_caddy ]]; then load caddy.sh caddy_config new manage restart caddy & _green \"\\nfix \u5b8c\u6210.\\n\" else err \"\u65e0\u6cd5\u6267\u884c\u6b64\u64cd\u4f5c\" fi ;; i | info) info $2 ;; ip) get_ip msg $ip ;; log | logerr) get $@ ;; url | qr) url_qr $@ ;; un | uninstall) uninstall ;; u | up | update | U | update.sh) is_update_name=$2 is_update_ver=$3 [[ ! $is_update_name ]] && is_update_name=core [[ $1 == 'U' || $1 == 'update.sh' ]] && { is_update_name=sh is_update_ver= } if [[ $2 == 'dat' ]]; then load download.sh download dat msg \"$(_green \u66f4\u65b0 geoip.dat geosite.dat \u6210\u529f.)\\n\" manage restart & else update $is_update_name $is_update_ver fi ;; ssss | ss2022) get $@ ;; s | status) msg \"\\n$is_core_ver: $is_core_status\\n\" [[ $is_caddy ]] && msg \"Caddy $is_caddy_ver: $is_caddy_status\\n\" ;; start | stop | r | restart) [[ $2 && $2 != 'caddy' ]] && err \"\u65e0\u6cd5\u8bc6\u522b ($2), \u8bf7\u4f7f\u7528: $is_core $1 [caddy]\" manage $1 $2 & ;; t | test) get test-run ;; reinstall) get $1 ;; get-port) get_port msg $tmp_port ;; main) is_main_menu ;; v | ver | version) [[ $is_caddy_ver ]] && is_caddy_ver=\"/ $(_blue Caddy $is_caddy_ver)\" msg \"\\n$(_green $is_core_ver) / $(_cyan $is_core_name script $is_sh_ver) $is_caddy_ver\\n\" ;; xapi) api ${@:2} ;; h | help | --help) load help.sh show_help ${@:2} ;; *) is_try_change=1 change test $1 if [[ $is_change_id ]]; then unset is_try_change [[ $2 ]] && { change $2 $1 ${@:3} } || { change } else err \"\u65e0\u6cd5\u8bc6\u522b ($1), \u83b7\u53d6\u5e2e\u52a9\u8bf7\u4f7f\u7528: $is_core help\" fi ;; esac }"
        },
        {
            "filename": "file_708.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\src\\file_708.sh",
            "content": "is_dns_list=( 1.1.1.1 8.8.8.8 https://dns.google/dns-query https://cloudflare-dns.com/dns-query https://family.cloudflare-dns.com/dns-query set none ) dns_set() { if [[ $1 ]]; then case ${1,,} in 11 | 1111) is_dns_use=${is_dns_list[0]} ;; 88 | 8888) is_dns_use=${is_dns_list[1]} ;; gg | google) is_dns_use=${is_dns_list[2]} ;; cf | cloudflare) is_dns_use=${is_dns_list[3]} ;; nosex | family) is_dns_use=${is_dns_list[4]} ;; set) if [[ $2 ]]; then is_dns_use=${2,,} else ask string is_dns_use \"\u8bf7\u8f93\u5165 DNS: \" fi ;; none) is_dns_use=none ;; *) err \"\u65e0\u6cd5\u8bc6\u522b DNS \u53c2\u6570: $@\" ;; esac else is_tmp_list=(${is_dns_list[@]}) ask list is_dns_use null \"\\n\u8bf7\u9009\u62e9 DNS:\\n\" if [[ $is_dns_use == \"set\" ]]; then ask string is_dns_use \"\u8bf7\u8f93\u5165 DNS: \" fi fi if [[ $is_dns_use == \"none\" ]]; then cat <<<$(jq '.dns={}' $is_config_json) >$is_config_json else cat <<<$(jq '.dns.servers=[\"'${is_dns_use/https/https+local}'\"]' $is_config_json) >$is_config_json fi manage restart & msg \"\\n\u5df2\u66f4\u65b0 DNS \u4e3a: $(_green $is_dns_use)\\n\" }"
        },
        {
            "filename": "file_709.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\src\\file_709.sh",
            "content": "get_latest_version() { case $1 in core) name=$is_core_name url=\"https://api.github.com/repos/${is_core_repo}/releases/latest?v=$RANDOM\" ;; sh) name=\"$is_core_name \u811a\u672c\" url=\"https://api.github.com/repos/$is_sh_repo/releases/latest?v=$RANDOM\" ;; caddy) name=\"Caddy\" url=\"https://api.github.com/repos/$is_caddy_repo/releases/latest?v=$RANDOM\" ;; esac latest_ver=$(_wget -qO- $url | grep tag_name | egrep -o 'v([0-9.]+)') [[ ! $latest_ver ]] && { err \"\u83b7\u53d6 ${name} \u6700\u65b0\u7248\u672c\u5931\u8d25.\" } unset name url } download() { latest_ver=$2 [[ ! $latest_ver && $1 != 'dat' ]] && get_latest_version $1 # tmp dir tmpdir=$(mktemp -u) [[ ! $tmpdir ]] && { tmpdir=/tmp/tmp-$RANDOM } mkdir -p $tmpdir case $1 in core) name=$is_core_name tmpfile=$tmpdir/$is_core.zip link=\"https://github.com/${is_core_repo}/releases/download/${latest_ver}/${is_core}-linux-${is_core_arch}.zip\" download_file unzip -qo $tmpfile -d $is_core_dir/bin chmod +x $is_core_bin ;; sh) name=\"$is_core_name \u811a\u672c\" tmpfile=$tmpdir/sh.zip link=\"https://github.com/${is_sh_repo}/releases/download/${latest_ver}/code.zip\" download_file unzip -qo $tmpfile -d $is_sh_dir chmod +x $is_sh_bin ;; dat) name=\"geoip.dat\" tmpfile=$tmpdir/geoip.dat link=\"https://github.com/Loyalsoldier/v2ray-rules-dat/releases/latest/download/geoip.dat\" download_file name=\"geosite.dat\" tmpfile=$tmpdir/geosite.dat link=\"https://github.com/Loyalsoldier/v2ray-rules-dat/releases/latest/download/geosite.dat\" download_file cp -f $tmpdir/*.dat $is_core_dir/bin/ ;; caddy) name=\"Caddy\" tmpfile=$tmpdir/caddy.tar.gz # https://github.com/caddyserver/caddy/releases/download/v2.6.4/caddy_2.6.4_linux_amd64.tar.gz link=\"https://github.com/${is_caddy_repo}/releases/download/${latest_ver}/caddy_${latest_ver:1}_linux_${caddy_arch}.tar.gz\" download_file [[ ! $(type -P tar) ]] && { rm -rf $tmpdir err \"\u8bf7\u5b89\u88c5 tar\" } tar zxf $tmpfile -C $tmpdir cp -f $tmpdir/caddy $is_caddy_bin chmod +x $is_caddy_bin ;; esac rm -rf $tmpdir unset latest_ver } download_file() { if ! _wget -t 5 -c $link -O $tmpfile; then rm -rf $tmpdir err \"\\n\u4e0b\u8f7d ${name} \u5931\u8d25.\\n\" fi }"
        },
        {
            "filename": "file_710.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\src\\file_710.sh",
            "content": "show_help() { case $1 in api | convert | tls | run | uuid | version) $is_core_bin help $1 ${@:2} ;; *) [[ $1 ]] && warn \"\u672a\u77e5\u9009\u9879 '$1'\" msg \"$is_core_name script $is_sh_ver by $author\" msg \"Usage: $is_core [options]... [args]... \" msg help_info=( \"\u57fa\u672c:\" \" v, version \u663e\u793a\u5f53\u524d\u7248\u672c\" \" ip \u8fd4\u56de\u5f53\u524d\u4e3b\u673a\u7684 IP\" # \" pbk \u540c\u7b49\u4e8e $is_core x25519\" \" get-port \u8fd4\u56de\u4e00\u4e2a\u53ef\u7528\u7684\u7aef\u53e3\\n\" # \" ss2022 \u8fd4\u56de\u4e00\u4e2a\u53ef\u7528\u4e8e Shadowsocks 2022 \u7684\u5bc6\u7801\\n\" \"\u4e00\u822c:\" \" a, add [protocol] [args... | auto] \u6dfb\u52a0\u914d\u7f6e\" \" c, change [name] [option] [args... | auto] \u66f4\u6539\u914d\u7f6e\" \" d, del [name] \u5220\u9664\u914d\u7f6e**\" \" i, info [name] \u67e5\u770b\u914d\u7f6e\" \" qr [name] \u4e8c\u7ef4\u7801\u4fe1\u606f\" \" url [name] URL \u4fe1\u606f\" \" log \u67e5\u770b\u65e5\u5fd7\" \" logerr \u67e5\u770b\u9519\u8bef\u65e5\u5fd7\\n\" \"\u66f4\u6539:\" \" dp, dynamicport [name] [start | auto] [end] \u66f4\u6539\u52a8\u6001\u7aef\u53e3\" \" full [name] [...] \u66f4\u6539\u591a\u4e2a\u53c2\u6570\" \" id [name] [uuid | auto] \u66f4\u6539 UUID\" \" host [name] [domain] \u66f4\u6539\u57df\u540d\" \" port [name] [port | auto] \u66f4\u6539\u7aef\u53e3\" \" path [name] [path | auto] \u66f4\u6539\u8def\u5f84\" \" passwd [name] [password | auto] \u66f4\u6539\u5bc6\u7801\" # \" key [name] [Private key | atuo] [Public key] \u66f4\u6539\u5bc6\u94a5\" \" type [name] [type | auto] \u66f4\u6539\u4f2a\u88c5\u7c7b\u578b\" \" method [name] [method | auto] \u66f4\u6539\u52a0\u5bc6\u65b9\u5f0f\" # \" sni [name] [ ip | domain] \u66f4\u6539 serverName\" \" seed [name] [seed | auto] \u66f4\u6539 mKCP seed\" \" new [name] [...] \u66f4\u6539\u534f\u8bae\" \" web [name] [domain] \u66f4\u6539\u4f2a\u88c5\u7f51\u7ad9\\n\" \"\u8fdb\u9636:\" \" dns [...] \u8bbe\u7f6e DNS\" \" dd, ddel [name...] \u5220\u9664\u591a\u4e2a\u914d\u7f6e**\" \" fix [name] \u4fee\u590d\u4e00\u4e2a\u914d\u7f6e\" \" fix-all \u4fee\u590d\u5168\u90e8\u914d\u7f6e\" \" fix-caddyfile \u4fee\u590d Caddyfile\" \" fix-config.json \u4fee\u590d config.json\\n\" \"\u7ba1\u7406:\" \" un, uninstall \u5378\u8f7d\" \" u, update [core | sh | dat | caddy] [ver] \u66f4\u65b0\" \" U, update.sh \u66f4\u65b0\u811a\u672c\" \" s, status \u8fd0\u884c\u72b6\u6001\" \" start, stop, restart [caddy] \u542f\u52a8, \u505c\u6b62, \u91cd\u542f\" \" t, test \u6d4b\u8bd5\u8fd0\u884c\" \" reinstall \u91cd\u88c5\u811a\u672c\\n\" \"\u6d4b\u8bd5:\" \" client [name] \u663e\u793a\u7528\u4e8e\u5ba2\u6237\u7aef JSON, \u4ec5\u4f9b\u53c2\u8003\" \" debug [name] \u663e\u793a\u4e00\u4e9b debug \u4fe1\u606f, \u4ec5\u4f9b\u53c2\u8003\" \" gen [...] \u540c\u7b49\u4e8e add, \u4f46\u53ea\u663e\u793a JSON \u5185\u5bb9, \u4e0d\u521b\u5efa\u6587\u4ef6, \u6d4b\u8bd5\u4f7f\u7528\" \" genc [name] \u663e\u793a\u7528\u4e8e\u5ba2\u6237\u7aef\u90e8\u5206 JSON, \u4ec5\u4f9b\u53c2\u8003\" \" no-auto-tls [...] \u540c\u7b49\u4e8e add, \u4f46\u7981\u6b62\u81ea\u52a8\u914d\u7f6e TLS, \u53ef\u7528\u4e8e *TLS \u76f8\u5173\u534f\u8bae\" \" xapi [...] \u540c\u7b49\u4e8e $is_core api, \u4f46 API \u540e\u7aef\u4f7f\u7528\u5f53\u524d\u8fd0\u884c\u7684 $is_core_name \u670d\u52a1\\n\" \"\u5176\u4ed6:\" \" bbr \u542f\u7528 BBR, \u5982\u679c\u652f\u6301\" \" bin [...] \u8fd0\u884c $is_core_name \u547d\u4ee4, \u4f8b\u5982: $is_core bin help\" \" api, convert, tls, run, uuid [...] \u517c\u5bb9 $is_core_name \u547d\u4ee4\" \" h, help \u663e\u793a\u6b64\u5e2e\u52a9\u754c\u9762\\n\" ) for v in \"${help_info[@]}\"; do msg \"$v\" done msg \"\u8c28\u614e\u4f7f\u7528 del, ddel, \u6b64\u9009\u9879\u4f1a\u76f4\u63a5\u5220\u9664\u914d\u7f6e; \u65e0\u9700\u786e\u8ba4\" msg \"\u53cd\u9988\u95ee\u9898) $(msg_ul https://github.com/${is_sh_repo}/issues) \" msg \"\u6587\u6863(doc) $(msg_ul https://233boy.com/$is_core/$is_core-script/)\" ;; esac } about() { ####### \u8981\u70b913\u8138\u5417\u53ea\u4f1a\u6539\u6211\u94fe\u63a5\u7684\u5c0f\u4eba ####### unset c n m s b msg msg \"\u7f51\u7ad9: $(msg_ul https://233boy.com)\" msg \"\u9891\u9053: $(msg_ul https://t.me/tg2333)\" msg \"\u7fa4\u7ec4: $(msg_ul https://t.me/tg233boy)\" msg \"Github: $(msg_ul https://github.com/${is_sh_repo})\" msg \"Twitter: $(msg_ul https://twitter.com/ai233boy)\" msg \"$is_core_name site: $(msg_ul https://www.v2fly.org)\" msg \"$is_core_name core: $(msg_ul https://github.com/${is_core_repo})\" msg ####### \u8981\u70b913\u8138\u5417\u53ea\u4f1a\u6539\u6211\u94fe\u63a5\u7684\u5c0f\u4eba ####### }"
        },
        {
            "filename": "file_711.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\src\\file_711.sh",
            "content": "#!/bin/bash author=233boy # github=https://github.com/233boy/v2ray # bash fonts colors red='\\e[31m' yellow='\\e[33m' gray='\\e[90m' green='\\e[92m' blue='\\e[94m' magenta='\\e[95m' cyan='\\e[96m' none='\\e[0m' _red() { echo -e ${red}$@${none}; } _blue() { echo -e ${blue}$@${none}; } _cyan() { echo -e ${cyan}$@${none}; } _green() { echo -e ${green}$@${none}; } _yellow() { echo -e ${yellow}$@${none}; } _magenta() { echo -e ${magenta}$@${none}; } _red_bg() { echo -e \"\\e[41m$@${none}\"; } _rm() { rm -rf \"$@\" } _cp() { cp -rf \"$@\" } _sed() { sed -i \"$@\" } _mkdir() { mkdir -p \"$@\" } is_err=$(_red_bg \u9519\u8bef!) is_warn=$(_red_bg \u8b66\u544a!) err() { echo -e \"\\n$is_err $@\\n\" [[ $is_dont_auto_exit ]] && return exit 1 } warn() { echo -e \"\\n$is_warn $@\\n\" } # load bash script. load() { . $is_sh_dir/src/$1 } # wget add --no-check-certificate _wget() { # [[ $proxy ]] && export https_proxy=$proxy wget --no-check-certificate \"$@\" } # yum or apt-get cmd=$(type -P apt-get || type -P yum) # x64 case $(arch) in amd64 | x86_64) is_core_arch=\"64\" caddy_arch=\"amd64\" ;; *aarch64* | *armv8*) is_core_arch=\"arm64-v8a\" caddy_arch=\"arm64\" ;; *) err \"\u6b64\u811a\u672c\u4ec5\u652f\u6301 64 \u4f4d\u7cfb\u7edf...\" ;; esac is_core=v2ray is_core_name=V2Ray is_core_dir=/etc/$is_core is_core_bin=$is_core_dir/bin/$is_core is_core_repo=v2fly/$is_core-core is_conf_dir=$is_core_dir/conf is_log_dir=/var/log/$is_core is_sh_bin=/usr/local/bin/$is_core is_sh_dir=$is_core_dir/sh is_sh_repo=$author/$is_core is_pkg=\"wget unzip jq qrencode\" is_config_json=$is_core_dir/config.json is_caddy_bin=/usr/local/bin/caddy is_caddy_dir=/etc/caddy is_caddy_repo=caddyserver/caddy is_caddyfile=$is_caddy_dir/Caddyfile is_caddy_conf=$is_caddy_dir/$author is_caddy_service=$(systemctl list-units --full -all | grep caddy.service) is_http_port=80 is_https_port=443 # core ver is_core_ver=$($is_core_bin version | head -n1 | cut -d \" \" -f1-2) if [[ $(grep -o ^[0-9] <<<${is_core_ver#* }) -lt 5 ]]; then # core version less than 5, e.g, v4.45.2 is_core_ver_lt_5=1 if [[ $(grep 'run -config' /lib/systemd/system/v2ray.service) ]]; then sed -i 's/run //' /lib/systemd/system/v2ray.service systemctl daemon-reload fi else is_with_run_arg=run if [[ ! $(grep 'run -config' /lib/systemd/system/v2ray.service) ]]; then sed -i 's/-config/run -config/' /lib/systemd/system/v2ray.service systemctl daemon-reload fi fi if [[ $(pgrep -f $is_core_bin) ]]; then is_core_status=$(_green running) else is_core_status=$(_red_bg stopped) is_core_stop=1 fi if [[ -f $is_caddy_bin && -d $is_caddy_dir && $is_caddy_service ]]; then is_caddy=1 # fix caddy run; ver >= 2.8.2 [[ ! $(grep '\\-\\-adapter caddyfile' /lib/systemd/system/caddy.service) ]] && { load systemd.sh install_service caddy systemctl restart caddy & } is_caddy_ver=$($is_caddy_bin version | head -n1 | cut -d \" \" -f1) is_tmp_http_port=$(egrep '^ {2,}http_port|^http_port' $is_caddyfile | egrep -o [0-9]+) is_tmp_https_port=$(egrep '^ {2,}https_port|^https_port' $is_caddyfile | egrep -o [0-9]+) [[ $is_tmp_http_port ]] && is_http_port=$is_tmp_http_port [[ $is_tmp_https_port ]] && is_https_port=$is_tmp_https_port if [[ $(pgrep -f $is_caddy_bin) ]]; then is_caddy_status=$(_green running) else is_caddy_status=$(_red_bg stopped) is_caddy_stop=1 fi fi load core.sh # old sh ver is_old_dir=/etc/v2ray/233boy is_old_conf=/etc/v2ray/233blog_v2ray_backup.conf if [[ -f $is_old_conf && -d $is_old_dir ]]; then load old.sh fi [[ ! $args ]] && args=main main $args"
        },
        {
            "filename": "file_712.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\src\\file_712.sh",
            "content": "is_old_list=( TCP TCP_HTTP WebSocket \"WebSocket + TLS\" HTTP/2 mKCP mKCP_utp mKCP_srtp mKCP_wechat-video mKCP_dtls mKCP_wireguard QUIC QUIC_utp QUIC_srtp QUIC_wechat-video QUIC_dtls QUIC_wireguard TCP_dynamicPort TCP_HTTP_dynamicPort WebSocket_dynamicPort mKCP_dynamicPort mKCP_utp_dynamicPort mKCP_srtp_dynamicPort mKCP_wechat-video_dynamicPort mKCP_dtls_dynamicPort mKCP_wireguard_dynamicPort QUIC_dynamicPort QUIC_utp_dynamicPort QUIC_srtp_dynamicPort QUIC_wechat-video_dynamicPort QUIC_dtls_dynamicPort QUIC_wireguard_dynamicPort VLESS_WebSocket_TLS ) # del old file del_old_file() { # old sh bin _v2ray_sh=\"/usr/local/sbin/v2ray\" rm -rf $_v2ray_sh $is_old_conf $is_old_dir $is_core_dir/233blog_v2ray_config.json /usr/bin/v2ray # del alias sed -i \"#$_v2ray_sh#d\" /root/.bashrc exit } # read old config . $is_old_conf is_old=${is_old_list[$v2ray_transport - 1]} case $v2ray_transport in 3 | 20) is_old_use= ;; 4) is_old_use=ws ;; 5) is_old_use=h2 ;; 33) is_old_use=vws ;; *) is_test_old_use=($(sed 's/_dynamicPort//;s/_/ /' <<<$is_old)) is_old_use=${is_test_old_use[0]#m} is_old_header_type=${is_test_old_use[1]} [[ ! $is_old_header_type ]] && is_old_header_type=none ;; esac if [[ $is_old_use && ! $is_old_header_type ]]; then # not use caddy auto tls [[ ! $caddy ]] && is_old_use= fi # add old config if [[ $is_old_use ]]; then is_tmp_list=(\"\u5220\u9664\u65e7\u914d\u7f6e\" \"\u6062\u590d: $is_old\") ask list is_do_upgrade null \"\\n\u662f\u5426\u6062\u590d\u65e7\u914d\u7f6e:\\n\" [[ $REPLY == '1' ]] && { _green \"\\n\u5220\u9664\u5b8c\u6210!\\n\" del_old_file } _green \"\\n\u5f00\u59cb\u6062\u590d...\\n\" # upgrade caddy if [[ $caddy ]]; then get install-caddy # bak caddy files mv -f $is_caddyfile $is_caddyfile.233.bak mv -f $is_caddy_dir/sites $is_caddy_dir/sites.233.bak load caddy.sh caddy_config new fi is_change=1 is_dont_auto_exit=1 is_dont_show_info=1 if [[ $shadowsocks ]]; then for v in ${ss_method_list[@]}; do [[ $(egrep -i \"^${ssciphers}$\" <<<$v) ]] && ss_method=$v && break done if [[ $ss_method ]]; then add ss $ssport $sspass $ss_method fi fi if [[ $socks ]]; then add socks $socks_port $socks_username $socks_userpass fi port=$v2ray_port uuid=$v2ray_id is_no_kcp_seed=1 header_type=$is_old_header_type [[ $caddy ]] && host=$domain path=/$path [[ ! $path_status ]] && path= if [[ $(grep dynamic <<<$is_old) ]]; then is_dynamic_port=1 is_dynamic_port_range=\"$v2ray_dynamicPort_start-$v2ray_dynamicPort_end\" add ${is_old_use}d else add $is_old_use fi if [[ $path_status ]]; then change $is_config_name web $proxy_site fi is_dont_auto_exit= is_dont_show_info= [[ $is_api_fail ]] && manage restart & [[ $caddy ]] && manage restart caddy info $is_config_name else ask string y \"\u662f\u5426\u5220\u9664\u65e7\u914d\u7f6e? [y]:\" _green \"\\n\u5220\u9664\u5b8c\u6210!\\n\" fi del_old_file"
        },
        {
            "filename": "file_713.sh",
            "path": "D:/LLLM Data/linux_data/github_shell_scripts\\v2ray\\src\\file_713.sh",
            "content": "install_service() { case $1 in xray | v2ray) is_doc_site=https://xtls.github.io/ [[ $1 == 'v2ray' ]] && is_doc_site=https://www.v2fly.org/ cat >/lib/systemd/system/$is_core.service <<<\" [Unit] Description=$is_core_name Service Documentation=$is_doc_site After=network.target nss-lookup.target [Service] #User=nobody User=root NoNewPrivileges=true ExecStart=$is_core_bin run -config $is_config_json -confdir $is_conf_dir Restart=on-failure RestartPreventExitStatus=23 LimitNPROC=10000 LimitNOFILE=1048576 PrivateTmp=true ProtectSystem=full #CapabilityBoundingSet=CAP_NET_ADMIN CAP_NET_BIND_SERVICE #AmbientCapabilities=CAP_NET_ADMIN CAP_NET_BIND_SERVICE [Install] WantedBy=multi-user.target\" ;; caddy) cat >/lib/systemd/system/caddy.service <<<\" #https://github.com/caddyserver/dist/blob/master/init/caddy.service [Unit] Description=Caddy Documentation=https://caddyserver.com/docs/ After=network.target network-online.target Requires=network-online.target [Service] Type=notify User=root Group=root ExecStart=$is_caddy_bin run --environ --config $is_caddyfile --adapter caddyfile ExecReload=$is_caddy_bin reload --config $is_caddyfile --adapter caddyfile TimeoutStopSec=5s LimitNPROC=10000 LimitNOFILE=1048576 PrivateTmp=true ProtectSystem=full #AmbientCapabilities=CAP_NET_BIND_SERVICE [Install] WantedBy=multi-user.target\" ;; esac # enable, reload systemctl enable $1 systemctl daemon-reload }"
        }
    ]
}